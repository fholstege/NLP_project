<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Causality, Unintended Consequences and Deducing Shared Causes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Steven</forename><forename type="middle">M</forename><surname>Shugan</surname></persName>
							<email>steven.shugan@cba.ufl.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Warrington College of Business</orgName>
								<orgName type="institution" key="instit2">University of Florida</orgName>
								<address>
									<addrLine>201B Bryan Hall</addrLine>
									<postBox>P.O. Box 117155</postBox>
									<postCode>32611</postCode>
									<settlement>Gainesville</settlement>
									<region>Florida</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Causality, Unintended Consequences and Deducing Shared Causes</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 e 1526-548X 07 2606 0731</idno>
					</monogr>
					<idno type="DOI">10.1287/mksc.1070.0338</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-13T12:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>causality</term>
					<term>common cause</term>
					<term>shared causes</term>
					<term>deduction</term>
					<term>inference</term>
					<term>scientific method</term>
					<term>structural equations</term>
					<term>scientific method</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>D espite warnings against inferring causality from observed correlations or statistical dependence, some articles do. Observed correlation is neither necessary nor sufficient to infer causality as defined by the term's everyday usage. For example, a deterministic causal process creates pseudorandom numbers; yet, we observe no correlation between the numbers. Child height correlates with spelling ability because age causes both. Moreover, order is problematic-we hear train whistles before observing trains, yet trains cause whistles.</p><p>Scientific methods specifically prohibit inferring causal theories from specific observations (i.e., effects) because, in part, many credible causes are perfectly consistent with available observations. Moreover, actions inferred from effects have more unintended consequences than actions based on sound deductive causal theories because causal theories predict multiple effects. However, an often overlooked but key feature of these theories is that we describe the cause with more variables than the effect. Consequently, inductive processes might appear deductive as the number of effects increases relative to the number of potential causes. For example, in real criminal trials, jurors judge whether sufficient evidence exists to infer guilt. In contrast, determining guilt in criminal mystery novels is deductive because the number of clues (i.e., effects) is large relative to the number of potential suspects (i.e., causes). We can make inferential tasks resemble deductive tasks by increasing the number of effects (i.e., variables) relative to the number of potential causes and seeking a shared cause for all observed effects. Moreover, under some conditions, the method of seeking shared causes might approach deductive reasoning when the number of causes is strictly limited. At least, the resulting number of possible causal theories is far less than the number generated from repeated observations of a single effect (i.e., variable).</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Taboos on Causal Claims</head><p>Most scientific disciplines, people, and organizations implicitly claim insights into causal processes. Those insights allow learning, decisions, predictions, diagnoses, and attributions (e.g., giving credit and placing blame). Causality and so-called causal models (e.g., <ref type="bibr" target="#b18">Fornell and</ref><ref type="bibr">Larcker 1981, Bagozzi and</ref><ref type="bibr" target="#b2">Yi 1988)</ref> remain popular. We researchers, however, seem schizophrenic about causality. We refer to causal theories as mathematical models, never mentioning causality. <ref type="bibr">Maruyama (1998, p. 9)</ref> states: "the term 'causal modeling' fairly quickly fell into disfavor Editorial pages are not part of the regular Marketing Science page budget. We thank the INFORMS Society of Marketing Science for paying for all editorial pages. We also thank the Society for granting every page supplement requested by the current editor.</p><p>We welcome and often post responses to editorials. Please see mktsci.pubs.informs.org. * Steven M. Shugan is the Russell Berrie Eminent Scholar and Professor.</p><p>in the minds of at least a subset of social scientists, who objected to any use of the term 'causal' with nonexperimental data. The term 'causal' was replaced by the less controversial and very descriptive term 'structural equations'." Statistical textbooks emphatically avoid references to causality, focusing on correlation and statistical dependence, yet these textbooks refer to spurious correlations as if some correlations are causal. Some research implies that independent variables cause dependent variables <ref type="bibr" target="#b51">(Shugan 2006)</ref>, although the difference involves error rather than causality. Some researchers claim experimental methods can detect causality, whereas others warn of confounding variables (e.g., <ref type="bibr" target="#b11">Cox 1992</ref><ref type="bibr" target="#b25">, Greenland et al. 1999</ref>. Some researchers claim that although single equations capture only correlations or, more generally, statistical dependence, multiple equations (i.e., causal structural models) can somehow make correlations causal. Some researchers claim to build only predictive models while simultaneously appealing to casual explanations. To avoid the terms cause <ref type="bibr">Marketing Science 26(6), pp. 731-741, © 2007 INFORMS</ref> and effect, we refer to exogenous and endogenous variables, but these terms are also problematic, as their definitions remain "subtle and sometimes controversial" <ref type="bibr">(Greene 1997, p. 712)</ref>. Macroeconomist Kevin <ref type="bibr">Hoover (2001, p. 7)</ref> states: "causal language has fallen into disrepute many modern macroeconomists, instinctively or self-consciously avoid it." Despite new creative approaches to examining causality, including nonparametric structural equation models <ref type="bibr" target="#b45">(Pearl 2003)</ref>, graphical methods <ref type="bibr" target="#b44">(Pearl 1995</ref><ref type="bibr" target="#b35">, Krider et al. 2005</ref>, and triangulating methodologies (Deshpande 1983), many researchers only insinuate causality while avoiding the term.</p><p>One explanation for avoiding causality is that the scientific method provides clever tools (e.g., randomized experiments) for testing causal theories derived from basic principles. Experiments can also test multiple causes (e.g., <ref type="bibr" target="#b19">Gourville and Soman 2005)</ref>. However, sometimes, we seek to uncover the cause of an effect (e.g., a new product failure, a stock market advance). This inductive objective is problematic. Inductive approaches are fraught with danger because of their inherently unscientific underpinnings. For example, there exist infinite explanations that fit any observation and, of course, deriving and testing a theory on the same observation is tautological. Moreover, actions based on inductive reasoning often cause unintended consequences because we focus on changing the effect, rather than on inferring a deductive causal theory that would allow prediction of multiple consequences.</p><p>Scottish economist David Hume <ref type="bibr">(Jones 1969, p. 319</ref>) argued that causality was only a perception without physical reality. Perhaps we create causality only when we measure it. Hence, causality is similar to beauty, taste, anger, inspiration, epiphany, insight, thought, anticipation, and perception of cadence with no physical reality. Researchers avoid causal claims for good reason.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Why Causality Lacks a Conceptual Definition</head><p>After thousands of years, at least since the inception of Aristotle's four causal types, scholars continue to debate the meaning and implications of causality. Incredibly, this deceptively simple concept apparently remains elusive, as misconceptions, conflicting approaches, and fundamental disagreements thwart the investigation of causality. Rather than reviewing the gargantuan literature on causality, let us consider a few examples illustrating some conceptual and practical difficulties relating to causality.</p><p>• Suppose Kim, who likes very few flavors, buys a candy because it is chocolate. Consequently, if the candy were not chocolate, Kim should not buy. If something causes an effect, the absence of the cause should eliminate the effect (i.e., often called a counterfactual). However, if the candy were vanilla, Kim would still buy, because Kim likes vanilla. The cause appears unnecessary for the effect.</p><p>• Suppose Lee, a salesperson, loses a client because he fails to provide sufficient service support. Consequently, not providing support appears to cause the client's loss. However, the firm's CEO also fails to provide that support. The dubious conclusion is that the CEO not providing service must have caused the client's loss. Maybe lack of service support itself is the cause, but maybe the client's unreasonably high expectations regarding support is the cause. The cause appears ambiguous.</p><p>• In the preceding example, we could blame the CEO for hiring Lee and, consequently, the CEO might be the true cause for losing the client. However, the board of directors hired the CEO, so perhaps, the board is the cause. Wait, the shareholders voted for the board and, hence, the shareholders are the cause. Maybe the company founders who determined the organization structure are the cause. Every cause appears to have its own cause, ad infinitum.</p><p>• Similarly, if all events have causes, everything is part of the same causal chain, and we have no influence over causality. For example, from the moment a firm is founded (and before), every decision by management is predictably caused by past events. Hence, to break the chain, some events must not be causes. Unfortunately, we lack an unambiguous method of distinguishing events with causes from those without causes.</p><p>• Suppose a buyer purchases one unit of our product. The purchase is certainly not the cause of successful sales. However, if no consumers purchase, there would be no success. Perhaps all buyers must be the cause, but one buyer alone could cause success by purchasing a sufficient quantity. Perhaps quantity is the cause, but then successful sales merely cause successful sales.</p><p>• A sales decrease must always follow a previous increase; otherwise, sales would always be zero. Hence, sales increases are necessary and sufficient (assuming bounded sales) for sales decreases. However, few would argue that sales increases cause sales decreases. Similarly, day fails to cause night, despite night always following day. It seems that necessary sequences still contradict causality.</p><p>• Suppose astute future psychologists can predict perfectly human behavior. Given that psychologists remain human, they can predict their own behavior, including their own predictions. Given that everything is predictable, events apparently inevitably unfold with destiny, and no cause exists beyond history itself. Everything in the past simply causes the future. The creation of the firm, the product, distribution, the firm's history of decisions, the buyer's past experiences, and so on, cause the buyer's purchase. Related to determinism, this conclusion contradicts the concept of any exogenous decision and has troubled many researchers, at least since French mathematician Pierre-Simon Laplace's thought experiments involving determinism <ref type="bibr">(Earman 1986, pp. 5-7)</ref>.</p><p>• Similarly, causality might be simply a linear time line. For example, we construct a function S t that describes sales as a function of time t. The function predicts the future, the present, and the past sales. The function captures all the relevant decisions (advertising, the economy, prices, etc.) as a function of time t. The concept of causality is irrelevant and merely confuses matters.</p><p>• We theorize that latent unobservable utilities cause buyers to purchase products. Although direct observations of utility are impossible, we infer them from behavior. However, perhaps invisible, undetectable, mythical fairies cause purchase behavior, and we implicitly infer their utilities. Certainly, claiming an unobservable cause is problematic and unscientific, because causal theories with unobservable (i.e., hidden) variables are often tautological.</p><p>• Understanding causality only has value if causes and effects reoccur. However, no two situations are identical in every respect. We might drive home every night. Although we appear to return to the same situation or state, we have not. On the trip home, we have interacted and influenced other drivers, pedestrians, vendors (gas stations, drugstores) and, perhaps, have had profound effects unknown to us.</p><p>• Similarly, suppose firms find that lowering product quality causes profits to increase; however, they are unable to guarantee that the effect will persist. It might take time for current customers to find alternative offerings, for competitors to enter the market, and for customers to recognize lower durability and reliability. More importantly, everyone might learn. Hence, causes never have the same effects.</p><p>• We dismiss obviously necessary causes. For example, we require the stellar sun for the buyer to exist, but we seldom consider that the stellar sun causes purchasing behavior.</p><p>• No one cause appears necessary. There are hundreds of ways, for example, to cause a buyer to purchase a product.</p><p>• No cause appears sufficient. A buyer will fail to purchase a product unless we have a buyer, a product, needs, money, distribution, oxygen for the buyer, and so on.</p><p>• Causal questions often lack answers. For example, we ask whether advertising increases sales. Advertising does and does not. Worse, sales can increase or decrease without advertising.</p><p>• The concept of randomness necessitates a complete lack of causality because, if there were a cause, the variable would not be random.</p><p>• Capturing all intuitive definitions of causality is difficult, if not impossible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Causes Can Follow Effects in Time</head><p>David Hume viewed causality as psychological impressions created from repeatedly observing the same sequence of events so that "on its next occurrence, the first impression of the sequence will again be followed by the second" <ref type="bibr">(Jones 1969, p. 319)</ref>. For example, when one is first viewing a movie, scenes occur without causality (e.g., a bus is late and two people meet). After repeated viewing, the moviegoer infers that the late bus causes the meeting.</p><p>Most researchers accept Hume's sequential ordering, so that causes precede effects. <ref type="bibr">Reichenbach (2000, p. 27)</ref> attempts to define causality without appeal to sequential orderings, but acknowledges that " when we are asked how to distinguish the cause from the effect, we usually say that the cause is the one that precedes the other in time." However, some researchers discuss true backward causality <ref type="bibr">(Dowe 2007)</ref>.</p><p>Unfortunately, we can observe effects before their causes, at least, the intuitive causes. For example, we hear train whistles before the train, but the train is the cause. Retail orders for Christmas occur before Christmas, but Christmas causes the orders. Emergency workers observe phone calls to 911 before observing people in distress, but 911 calls do not cause the distress (see <ref type="bibr" target="#b51">Shugan (2006)</ref> for other examples). Experimentation could theoretically disentangle causality, but observed causes can follow observed effects in time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Probabilistic Causality-Not a Panacea</head><p>Some researchers argue that probabilistic causality could potentially solve the causality enigmas (e.g., <ref type="bibr" target="#b22">Granger 1988</ref><ref type="bibr" target="#b48">, Pratt and Schlaifer 1988</ref><ref type="bibr" target="#b57">, Zellner 1988</ref>). These researchers debate whether probabilistic uncertainty implies truly random discrete processes, as encountered in quantum mechanics, or Bayesian uncertainty reflecting the decision maker's ignorance <ref type="bibr" target="#b46">(Popper 1950)</ref>. Either interpretation allows inference of causal relationships and unobserved common causes from covariance matrices <ref type="bibr">(Spirtes et al. 1988, 65-71)</ref>.</p><p>Despite the merits of probabilistic causality, if understanding deterministic causality is frustrating, then introducing uncertainty, random disturbances, and sampling error clouds understanding, at best. At worst, probabilistic interpretations could hide fundamental logical inconsistencies similar to the manner in Marketing Science 26(6), pp. 731-741, © 2007 INFORMS which appeals to uncertainty can sustain bad theories <ref type="bibr" target="#b51">(Shugan 2006)</ref>.</p><p>For example, we might argue that a suspected pathogen causes a disease, but the pathogen is absent from some afflicted individuals while found in some nonafflicted persons. Correlation or statistical dependence can be irrelevant or, worse, misleading. The suspected pathogen might be innocuous while the true pathogen populates all afflicted individuals and only afflicted individuals. Maybe if the brakes fail to always stop the car, we need a better causal theory of braking. Retreating to probabilistic interpretations of causality can prolong the rejection of false theories or inhibit the development of better theories. Although probabilistic interpretations allow creative refinement of nearly correct ideas, many renowned researchers specifically caution against proposing any theory derived from specific empirical observations, and they argue that such proposals violate the fundamental tenets of scientific methodology (e.g., <ref type="bibr" target="#b17">Einstein 1919</ref><ref type="bibr" target="#b47">, Popper 2002</ref>. Even advocates of probabilistic approaches warn that searching for causality "is hard to achieve except when large effects are involved" <ref type="bibr">(Cox and Wermuth 2004, p. 303)</ref>, making errors relatively small. Simultaneity is another problem. It is difficult, for example, to disentangle whether loyalty causes multiple purchases or the reverse or both <ref type="bibr" target="#b28">(Gupta and Zeithaml 2006)</ref>. Probabilistic causality is insufficient.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Causality Without Correlation</head><p>Statistical textbooks are replete with examples of correlation without causality. For example, children's spelling skills correlate with foot size, but age causes both. The number of churches correlates with the number of crimes, but city size causes both. Shark attacks correlate with barbeques, but warm weather causes both. Hence, common causes create correlations. Moreover, the causal direction is often unclear (e.g., <ref type="bibr">Moorman et al. 2005, Keller and</ref><ref type="bibr" target="#b34">Lehmann 2006)</ref>. Alcoholic drinking might cause depression, or depression might cause drinking <ref type="bibr" target="#b51">(Shugan 2006)</ref>.</p><p>In contrast, most textbooks incorrectly assert that observed correlation is necessary for causality. The existence of pseudorandomness (uncorrelated numbers generated by entirely deterministic causal processes) seems sufficient to prove observed correlation is unnecessary. For an everyday example, consider the case of a skilled driver steering an automobile down a curved two-way highway. With expert steering, the driver maintains an equal distance between the car and the median strip, keeping this distance constant. Consequently, there is no observed correlation between that distance and the steering wheel's alignment, despite general agreement that steering is precisely the cause of the observed distance.</p><p>Often, understanding and properly managing control variables will eliminate or reverse expected observed correlations. Increasing quality should cause higher sales, but firms raise prices, eliminating observed correlations between quality and sales. Eating low fat foods should cause weight loss, but consumers increase their consumption, eliminating the expected observed correlation. Perhaps these paradoxical examples result from choosing the wrong variables or from ignoring the right variables. However, causality exists without observed correlations.</p><p>Causality Without Change <ref type="bibr" target="#b20">Granger (1969)</ref> and others have proposed clever tests for revealing causal relationships by measuring changes in causes and effects. For example, when (1) increases in advertising expenditures precede increases in consumption, and (2) increases in consumption are unrelated to subsequent increases in advertising expenditures, then we conclude that advertising causes consumptions, rather than the reverse. Parenthetically, for advertising, Granger tests reveal evidence for causality in both directions <ref type="bibr" target="#b0">(Ashley et al. 1980</ref>). Granger tests can also reveal whether objective quality causes perceived quality <ref type="bibr" target="#b41">(Mitra and Golder 2006)</ref>.</p><p>However, neither the cause nor the effect needs to change. The sun's gravity causes the earth's orbit, yet the sun's gravity remains constant. Providing great, consistent service causes the firm's sales to grow; yet, constant service causes changes in sales. An airplane pilot causes a constant altitude by continually changing the controls. A wall causes a roof to remain stationary. Although experiments might pursue manipulations involving change, rather than controlling for change, the manipulation can create change not present in reality.</p><p>More generally, change itself depends on the observer's perspective. A buyer on vacation observes a change in the layout of a local Walgreen's store (compared to home). However, local buyers observe no change. Microsoft Windows XP users find favorable changes in Windows Vista while Apple Computer users find unfavorable changes. Attempting to hold perspective constant ultimately requires that all observers experience the same history. Causality can exist without change.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Why Causes Have More Detail than Effects</head><p>When building a model or theory, we make 90% of the assumptions when we select which variables to observe and, implicitly, which not to observe. The selected variables assume possible causes and effects. More importantly, we implicitly assume that history repeats itself when the selected variables take the same values.</p><p>The claim is that two situations are alike (if not identical) when the variables assume the same values. Therefore, knowledge about one situation allows us to predict others. The proposed relationships between the variables should persist, regardless of changes in unobserved variables.</p><p>As noted earlier, no two situations are identical. History never truly repeats itself because it always grows longer. Whereas the selected variables might return to previous values, many other variables assume new values. Moreover, previously absent variables might appear. For example, launching a new product today differs from launching one tomorrow, because a day has passed. People grow older; new people are born; technology advances; some people learn while others forget. Markets change by the day, if not by the minute.</p><p>Only on our small set of selected variables are two situations identical, at least with respect to interrelationships. For example, we return home each night to the same location, but we interacted with the environment (e.g., breathed the air, created sounds, disturbed some animals, fed some insects), influenced other people (e.g., purchased items, encountered congested traffic, changed the future of others) and, certainly, aged physically. Given that situations always differ, both causes and effects must involve a limited number of observed variables. Moreover, the relationships between these variables must persist, regardless of changes in unobserved variables. Satisfying this requirement is easier when we describe the cause in more detail than the effect. Consequently, the cause is less likely to recur than the effect because we place greater limits on admissible causes, i.e., situations when we make predictions.</p><p>For example, we predict a single variable, sales, from a cause consisting of advertising, price, distribution, product features, and so on. Hence, the cause requires that many variables assume specific values. The effect, in contrast, requires prediction of only one variable. Having more detailed causes eases the task of deducing effects, because we potentially use more information to predict less. Moreover, we put more conditions on the cause because a situation causes only one outcome but many situations produce the same outcome. The reverse is also true. When inferring causes from effects, adding more detail to effects eases the task of inferring causes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Simple Definition of Causality</head><p>Researchers, attempting to celebrate the general applicability of their theories, promote terminology resembling everyday language. Statisticians use the term "significance" but quickly disavow any association with the everyday meaning of practical or important. Accountants use the term "asset value" but disavow any association resembling the everyday meaning of worth. The concept of "work" in physics dramatically differs from the everyday meaning. The terms have precise unambiguous definitions despite their appeal to generality.</p><p>When defining terms, we should sacrifice the relevance (and ambiguity) of everyday language for the more precise (and narrow). When defining causality, for example, <ref type="bibr" target="#b21">Granger (1980)</ref>  Common language often lacks mathematical precision. For example, mathematical statements are either true or false. Verbal statements, in contrast, can be inconsistent, meaningless, ambiguous, or nonsensical. Statements such as "yellow is large," "I am lying," and "ugly can be beautiful" are neither true nor false. The same is true of evidence for a causal theory. Some evidence is neither consistent nor inconsistent but merely irrelevant or meaningless.</p><p>Therefore, let us adopt the narrow definition of causality inspired by Bayesian decision theory (e.g., see <ref type="bibr" target="#b9">Buzzell 1962</ref><ref type="bibr" target="#b23">, Green 1963</ref><ref type="bibr" target="#b50">, Savage 1972</ref><ref type="bibr" target="#b5">, Berger 1980</ref>. Decisions are actions that cause different outcomes. Causes are actions defined on control variables, and effects are outcomes with particular characteristics. For example, the decision (the cause) is launching a new product or not. The effects are outcomes possessing particular characteristics (gains in reputation, short-term profits, long-term profits, cash flow, sales growth, etc.).</p><p>Decision makers could be uncertain about which actions produce which outcomes, but that uncertainty reflects insufficient information (i.e., Bayesian uncertainty) about causality while outcomes are deterministic. Exhaustive observation would resolve all uncertainty. Decisions recur when one is facing the same actions and outcomes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimentation and Controls</head><p>Arguably, the greatest advance for determining causality, and perhaps science as well, was English statistician Sir Ronald Fisher's ingenious randomized experiment. Today, most researchers argue that only controlled experiments reveal causality. <ref type="bibr">Holland (1986, p. 959</ref>) states that "it takes two causes to define an effect" and his motto is "no causation without manipulation." <ref type="bibr">Box et al. (1978, p. 495)</ref>   <ref type="bibr">(Sorensen 1992, p. 57)</ref> are routine for theoretical scientific inquiries into causality <ref type="bibr" target="#b6">(Bishop 1999)</ref> Experiments examine effects with and without the cause. The control (i.e., without the cause) tests whether the cause is necessary. Then, we test whether the cause is sufficient. For example, to examine the effect of advertising, we must both not advertise and advertise. Naturally occurring data lacks essential information because, in this example, decision makers choose advertising levels based on the perceived effect, thereby eliminating necessary observations. If we observe a perfect relationship between firm market share and firm profits, we remain ignorant of whether larger market shares cause larger profits, larger profits cause larger market shares, good management causes both, or public data are missing for profitable smaller share companies (perhaps, because they are private or have been acquired).</p><p>However, experiments seem less necessary when deductive causal theories make sufficiently unexpected predictions (i.e., inconsistent with other theories) that allow falsification. For example, consider physicist Sir Arthur Stanley Eddington's confirmation of physicist Albert Einstein's predictions that light would bend around the sun during a solar eclipse as predicted by the theory of relativity (e.g., <ref type="bibr">Will 1993, p. 171)</ref>. Similar predictions provide evidence of causality without experimental data. Hence, nonexperimental predictions, when nonobvious and unique, might be useful.</p><p>Moreover, constructing control groups can be difficult, if not impossible. First, observer effects can cause measurement to alter observation. For example, television networks and other programmers change content when Nielsen measures audience size (e.g., <ref type="bibr" target="#b37">Lowry 2002)</ref>.</p><p>The Heisenberg uncertainty principle, often confused with observer effects, at least until 1935 <ref type="bibr">(Bohr 1935, McKerrow and</ref><ref type="bibr" target="#b40">McKerrow 1991)</ref>, states that gaining accuracy on one variable's measurement decreases accuracy for other variables. Although the uncertainty principle only applies to duality properties of subatomic particles, there are analogous situations. For example, we are unable to measure simultaneously an automobile's ability to accelerate and brake at a point on a hilly road. We must first measure acceleration, then braking. To measure acceleration, more accurately, we spend more time accelerating (say, from 10 to 20 miles per hour). However, more time causes the automobile's position to shift and makes the braking measurement less accurate because the road's gradient and the engine's state have changed. Braking and acceleration are conjugate properties of the automobile. Both are real; both can be measured; but not together.</p><p>This problem also inflicts experimental controls. The control can never be simultaneous with the cause. For example, we are unable to launch and not launch a new product in a city at the same time. We must assume, for example, that without a launch, control and test cities remain identical over time. The longer the experiment, the more likely the cities diverge.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Determining Effects and Unintended Consequences</head><p>The scientific method requires that we deduce causal theories from principles <ref type="bibr" target="#b17">(Einstein 1919</ref><ref type="bibr" target="#b47">, Popper 2002</ref>, rigorously derive testable observable implications (i.e., effects), scrutinize the consistency of deduced effects with subsequent observation, and always make predictions before making observations (i.e., not inferring explanations after making observations). Perhaps it is best to avoid inadvertent tester bias, and different researchers should propose and test theories. For example, <ref type="bibr" target="#b16">Einstein et al. (1935)</ref>, using a thought (Gedanken) experiment, deduced a disturbing prediction of quantum mechanical theory regarding nonlocal causality. Years later, John Stewart <ref type="bibr" target="#b4">Bell (1964)</ref> conceptually designed an experiment for testing the prediction. Years later, Alain <ref type="bibr">Aspect et al. (1981)</ref> creatively implemented the experiment.</p><p>The scientific method allows straightforward deduction of many effects. For example, compensation theories predict salesperson behavior on many variables <ref type="bibr" target="#b3">(Basu et al. 1985, Lal and</ref><ref type="bibr" target="#b36">Staelin 1986)</ref>. Different commission schemes, in contrast to fixed-salary schemes, should produce different time allocations for higher potential customers, higher margin products, travel, postsales support, and many other observable effects <ref type="bibr" target="#b29">(Hauser et al. 1994)</ref>.</p><p>Moreover, good causal theories should predict all effects or consequences of causal actions (i.e., actions intended to cause an effect). Inference, in contrast, limits our attention to one effect rather than predicting all effects of causal actions. Unintended consequences (i.e., unexpected effects) become problematic when inferring causes from effects.</p><p>For example, legislation mandating worthwhile safety features in automobiles raises the price of automobiles, encourages buyers to delay purchases, increases the average age of automobiles, increases the number of older, badly maintained automobiles on the road, and so on. Economic theory predicts all of these consequences.</p><p>Unexpected consequences often occur when one is inferring an action to remedy undesirable features of a single effect. For example, to remedy last minute unsold seats, an airline might offer regular last-minute discounts. Unexpected effects of discounting might include some passengers delaying purchases to obtain discounts <ref type="bibr" target="#b13">(Desiraju and</ref><ref type="bibr">Shugan 1999, Xie and</ref><ref type="bibr" target="#b56">Shugan 2001)</ref>. Similarly, increasing sales volume with price promotions causes other effects, such as encouraging forward buying, inventorying items and causing some buyers not to purchase at regular prices. A reasonable causal theory of buyer behavior would predict these unintended consequences. In contrast, inferring causal actions from single effects often spawns unintended effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Determining Causes and the Perils of Inference</head><p>Although scientific methods warn against inference, we must sometimes find a cause from an effect, particularly an unexpected effect such as a precipitous sales decline or an epidemic outbreak. Something is unexpected when our extant causal theory fails. Consequently, we perilously infer a cause to determine appropriate future actions without a causal theory.</p><p>As noted earlier, the scientific method makes a clear distinction between induction and deduction. Inductive inference allows invaluable activities (e.g., testing, learning, etc.). However, inference without a priori theory is dangerous and generally considered unscientific, because inference is prone to uncorrectable errors. There are numerous, if not infinite, explanations for any specific observation (e.g., a stock market decline). More seriously, inferential procedures cement incorrect inchoate theories because confirmation bias amplifies confirming features of the observation reinforcing erroneous inferences. The process deteriorates.</p><p>Rather than reviewing the related gargantuan literature, consider a few examples of the perils of inference.</p><p>• Philosopher Carl Gustav Hempel's famous proof shows that observing white shirts provides inferential evidence that ravens are black, because observing a black raven is logically equivalent (i.e., the contrapositive) to observing a not raven that is not black <ref type="bibr" target="#b30">(Hempel 1945)</ref>. Simply stated, any observation not conflicting with a theory becomes inferential support for the theory. Deductive theory, in contrast, narrows relevant evidence to very specific falsifiable predictions, perhaps concerning raven genetics.</p><p>• Unlike deduction, inductive inferences are rarely replicable. Experts can infer different conclusions from the same observations.</p><p>• Inductive inference is subject to many psychological biases. Psychologist Peter Cathcart Wason's famous experiments <ref type="bibr" target="#b54">(Wason 1968</ref>) found that most people are unable to infer extremely simple underlying processes from sequences of numbers (e.g., 2, 4, 6). His four-card experiments suggest great difficulty correcting wrong inferences.</p><p>• We observe many calendars in nonleap years-None contains February 29 th . Any inference about February 29 th in other years is wrong. Inference only allows generalizations within the same population with no method for knowing that population (e.g., other calendars in the same year, English-language calendars, etc.).</p><p>• <ref type="bibr">Holland (1986, p. 959)</ref>, for example, notes " the 'cause' of a given effect is always subject to revision as our knowledge about the phenomenon increases. For example, do bacteria cause disease? Well, yes until we dig deeper and find that it is the toxins the bacteria produce that really cause the disease; and this is really not it either. Certain chemical reactions are the real causes and so on, ad infinitum." The inferred cause appears subjective.</p><p>• Pete made a bad marketing decision causing an undesirable effect, so Pete is the cause and eliminating Pete prevents the future effect. However, Pete has learned from the experience and he would do better with future decisions. Valid inferences might not persist and become useless for prediction.</p><p>• Very high ticket prices for a celebrity's concert upsets loyal fans. Focusing on the effect (upset loyal fans), the celebrity lowers ticket prices for future concerts and brokers buy all tickets before the fans. Inference of causal actions from specific events often spawns many unexpected consequences.</p><p>Deductive causal theory can solve all of these problems by predicting when and why particular effects will occur. Testable predictions test the theory. More importantly, deductive theories produce fewer unexpected effects because they allow predictions on many variables in many domains. For example, trying to reduce salesperson travel expenses, we observe expenses and find high meal costs, so we limit spending on meals. Deductive theories of incentives predict unintended consequences on many variables. For example, salespeople should be reluctant to entertain new clients; salespeople should spend their budgets on less productive activities; the best salespeople might take jobs at other employers; and so on. Maybe better solutions include redesigning sales territories, negotiating hotel rates, or providing salespeople with better information regarding effective entertainment strategies.</p><p>Parenthetically, unlike dictionary definitions of inferential induction that emphasize inferring general principles from specific observations, statistical technologies define inference differently. Estimation technology usually uses predetermined formulae (not inferred from observation) to calculate parameters that maximize the consistency of the theory with observations and, subsequently, report that consistency. End-users can make their own inferences. Bayesian technologies use predetermined formulae</p><p>Marketing Science 26(6), pp. 731-741, © 2007 INFORMS that allow decision makers to assimilate new information. Bayesian inference only dictates changes in uncertainty. Although both technologies claim property rights to the word "probability" and advocate conflicting definitions, the two technologies are compatible because they are suitable for different tasks. The highly criticized Bayesian prior probability distribution might hinder the task of falsification while being indispensable for decision-making tasks. Neither technology truly infers general theories from specific observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Unique Cause</head><p>There are possibly infinite true causes for an effect when causes themselves have causes. For practical purposes, let the relevant cause imply the most economical action, i.e., the action that minimizes the cost function across all actions achieving the desired features of resulting effects. For example, actions preventing new product failures include having no new products, disbanding our business, or changing a product attribute. Actions preventing epidemic outbreaks include eliminating people, relocating people, or stopping transmission. The last actions seem the most economical.</p><p>The most economical action within a causal chain is usually closest to the effect. For example, the president hires the marketing vice president, who hires a market research firm, which uses a forecasting model, which encourages a new product launch that subsequently fails. The most economical action would involve the forecasting model, provided it achieves the desired effect. For precise definitions, the terminology (i.e., primitives) of decision theory suffices. Finally, although there may be no unique economical action that works, assuming so would be counter-productive if it did exist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Making Inference Deductive (or Near Deductive)</head><p>Although scientific methods specifically prohibit inferring causal theories from specific observations because many credible causes can be perfectly consistent with available observations, when the number of possible causes is relatively small, the task becomes deductive. For example, consider the typical inferential crime mystery in which a suspected perpetrator (i.e., the cause) commits a crime (i.e., an effect). The criminal trial parallels statistical inference. Prosecutors present evidence. Jurors decide whether sufficient evidence exists to infer guilt, given a reasonable doubt (i.e., a type I error). As an inferential process, mistakes are possible. Juries sometimes convict the innocent and exonerate the guilty. Hence, the prosecutor's socalled proof is a misnomer, only representing inductive consistency between the prosecutor's beliefs and observed evidence. Parenthetically, courts explicitly prohibit Bayesian analysis by rarely allowing the use of a suspect's past criminal history to form a Bayesian prior probability distribution.</p><p>In contrast, the criminal mystery novel seems similar. The reader observes the evidence. The reader infers guilt or innocence. Readers can be wrong. However, this task is deductive. Deductive logic and a few simple mathematical equations reveal, without error, the perpetrator's identity.</p><p>The critical difference between real criminal trials and mystery novels is the limited set of potential perpetrators relative to the number of clues. Hence, the number of potential causal theories (i.e., suspects) is smaller than the number of observed effects (i.e., clues). We transform an inferential task into a deductive task by increasing the number of effects relative to the number of potential causes.</p><p>Deductive prediction commonly involves using many observable causal variables to deduce conclusions about a smaller number of effects. For example, increasing product awareness, availability, quality, reliability, and durability increases sales. Hence, live variables predict one (i.e., sales).</p><p>Inductive inference lacks this property. Induction often involves going from the few to the many. Hence, dramatically increasing the number of observed effects (i.e., variables) might allow deduction. Similarly, more clues allow unique identification of the guilt perpetrator. Analogously, inferential statistics become descriptive statistics when we obtain a census for the entire population. Perhaps increasing the number of observed effects (i.e., variables) will allow inference of a single cause, making the process resemble deduction. For example, physician Jerome <ref type="bibr" target="#b26">Groopman (2007)</ref> advocates encouraging patients to provide richer sets of symptoms (i.e., effects), rather than inferring the most likely cause of prominent symptoms.</p><p>Note that increasing the number of observed effects differs from observing repeated instances of the same effect. Observing more effects increases the number of observed variables, rather than the number of observations of the same variables. For example, repeated observations of sales at different outlets differ from chronicling all unexpected observations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shared Causes</head><p>By expanding the number of observed effects (or variables), we attempt to infer a shared cause for all the observed effects. By not trying to better fit the cause to a single effect (or single variable), we avoid the usual deficiencies associated with inductive approaches such as overlying on situation-specific factors (i.e., over-fitting). If a causal action occurs, then it should cause multiple observable effects beyond the specific outcome of interest. These other predictable effects might be simultaneous with the effect of interest or nearby (in time and space). Better theories provide richer predictions and, consequently, produce a greater variety of specific predictions. For example, the rich theory of rational consumer expectations makes predictions on every consumer decision in many different situations.</p><p>Having a sufficient number of observed effects might greatly limit the number of consistent causal theories. For example, other unexpected observations occurring with sales declines might include loss of customers, low purchase rates, low levels of customer satisfaction, many product returns, bad customer perceptions, distributor concerns, and so on.</p><p>Although finding shared causes fails to replicate a deductive process, it does increase the number of observed effects relative to the number of potential causes, at least, obvious causes. Moreover, under some conditions, the method of seeking shared causes might converge to deductive reasoning when the number of causal theories is strictly limited. At least, the resulting set of causal theories is far less than the number generated from repeated observations of a single effect. Unfortunately, some relevant causal theories might be inconspicuous. Hence, although observing many effects might simulate deduction, errors remain possible.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shared Causes-A New Product Example</head><p>Consider two previous examples-the new product failure and the epidemic. In the case of the new product, we can look for other effects. For example, have there been other recent failures? The products from other firms might have failed; other products from the same firm might have failed. That might indicate specific causes beyond defective product attributes, such as a faulty new product development process, a flawed distribution channel, a poorly run organization, an unsound corporate strategy, an unworkable environment, and so on. However, more importantly, as we increase the number of observed events, we should be able to limit the number of candidate causal theories. For example, if many other new products succeeded before and after the failure, the cause must be more specific to this product.</p><p>The strategy is finding a shared cause for all observed effects. Increasing the number of observed effects narrows the number of potential shared causes. Rather than trying to explain an effect by seeking other instances of the effect, we seek observations of other local effects. This process should ultimately eliminate all but one shared cause. Seeking a shared cause simulates a more deductive approach. Of course, seeking a shared cause remains inferential unless the number of candidate causes is both limited and known.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Shared Causes-An Epidemic Example</head><p>Plague Bacillus inflicted massive human disaster across the world, devastating and decimating both cities and countries. Candidate causes for the disease included the star's unfavorable constellations, comets, supernatural powers, and poisoning of wells by Jews "who paid for this with tortures inflicted on them by the panicked population" <ref type="bibr">(Gross 1995, p. 7609)</ref>. Centuries later, facing government resistance, physician Alexandre Emile John Yersin visited plague-ravaged Hong Kong. An English priest, Father Vigano, magnanimously supplied Yersin with a small shack for a crude laboratory. Bribing two English sailors <ref type="bibr">(Marriott 2004, p. 136</ref>) at great personal risk, Yersin gained access to the hospital morgue. Microobservation of abnormalities in plague fatalities consistently revealed rod-shaped microbes. Yersin tested the causal theory by injecting the microbes into guinea pigs that subsequently died with large quantities of the microbe.</p><p>Unlike other researchers who focused on laboratory observation of fatalities, Yersin also made extensive environmental observations, finding other effects of the plague. Among recorded observations were large numbers of dead rats. In plague-ravaged Long-Tcheon Indochina, bacteriologist Paul-Louis Simond, inspired by Yersin, also expanded observation to outside the laboratory. Unlike others, he examined blisters on workers' feet, finding high levels of plague bacilli <ref type="bibr">(Marriott 2004, p. 236)</ref>. He observed geographic separation between outbreaks <ref type="bibr">(Marriott 2004, p. 237)</ref>. He observed that, "one day, in a wool factory, employees arriving in the morning noticed a large number of dead rats on the floor. Twenty laborers were ordered to clean the floor of the dead animals. Within 3 days, 10 of them developed plague, whereas none of the other employees became ill" <ref type="bibr">(Gross 1995, p. 7610)</ref>. Making further observations on still more variables (e.g., the nature of the contact, when the contact occurred), Simond found a shared cause-contact with recently deceased rats (i.e., rats that were not living but not cold dead). Investigating all events occurring during death, he found that "immediately after the rat dies, when its corpse cools off, the rat flea (Xenopsylla cheopis) leaves the dead rat and jumps on other healthy rats or, if no rats are available, they jump on men or women." Using very crude laboratory equipment (e.g., paper bags), Simond tested the causal theory. Simond, for example, showed that inflicted rats with no fleas did not transmit the plague to other rats.</p><p>Yersin and Simond isolated the shared cause by expanding the number of observed effects. Other researchers (e.g., Shibasaburo Kitasato) also isolated microbes but limited observations to the laboratory. The cause of transmission revealed itself (after many Marketing Science 26(6), pp. 731-741, © 2007 INFORMS centuries of arduous effort by investigators) only after expanding the number of observed effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions</head><p>Researchers avoid causal claims for very good reasons. Causality often lacks both conceptual and operational definitions capturing the everyday intuitive definitions for causality. Moreover, intuitive causal relationships seem to violate scholarly definitions. For example, observed causes can follow observed effects in time. Causality can exist with or without observed correlation between the cause and the effect. Causality can exist without observing any change. Perhaps it is best to adopt a specific definition of causality-a causal action produces effects having particular features. We use the most economical (i.e., lowest-cost) causal action. Our causal models, then, predict the effects of actions.</p><p>When building causal models for prediction, we make 90% of the assumptions when we select which variables to observe and, implicitly, which not to observe. Causes and effects are limited to those variables. An often overlooked but key feature of modeling is that we describe the cause with more variables than the effect. Qualitatively, we describe the effect in less detail than the cause. This is a key difference between inference and deduction.</p><p>For example, a real criminal trial involves inference. Jurors decide whether sufficient evidence exists to infer guilt, given reasonable doubt (i.e., a type I error). In contrast, determining guilt in a criminal mystery novel is deductive because the number of clues (i.e., effects) is large relative to the number of potential suspects (i.e., causes). We transform an inferential task into a deductive task by increasing the number of effects relative to the number of potential causes.</p><p>One reason scientific methods specifically prohibit inferring causal theories from specific observations is that many credible causes are perfectly consistent with available observations, as evidenced by most political and scientific debates. This is the well-known shortcoming of inductive reasoning.</p><p>However, when the number of possible causes is sufficiently small, the task becomes deductive. Consequently, inductive tasks might also approach deductive tasks when we expand the number of observed effects (i.e., variables). Note that increasing the number of effects is not equivalent to observing repeated instances of the same effect. Observing more effects increases the number of observed variables rather than the number of observations of the original variables. Yersin and Simond solving of the Bacillus plague puzzle provides an example.</p><p>By increasing the number of observed effects (i.e., variables), we limit the number of possible shared causes, i.e., causes that predict all of the observed effects. A sufficient number of observed effects might greatly limit the number of consistent causal theories. Although the method of seeking shared causes fails to replicate deductive processes, it might approach one. Moreover, under some conditions, the method of seeking shared causes might converge to deductive reasoning when the number of candidate causal theories is strictly limited. At least the resulting number of causal theories is far less than the number generated from repeated observations over a single effect or a much smaller number than the universe of candidate causal theories.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>state: "Broadly speaking, to find out what happens when you change Marketing Science 26(6), pp. 731-741, © 2007 INFORMS something, it is necessary to change it." Even Danish physicist Hans Christian Ørsted's famous method involving thought experiments</figDesc><table /></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Advertising and aggregate consumption: An analysis of causality</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ashley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W J</forename><surname>Granger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schmalensee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1149" to="1167" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Experimental test of Bell&apos;s inequalities using time-varying analyzers</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aspect</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Dalibard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Roger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Rev. Lett</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">25</biblScope>
			<biblScope unit="page" from="1804" to="1807" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">On the evaluation of structural equation models</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Bagozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acad. Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="74" to="94" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A theory of salesforce compensation plans</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Basu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Staelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="267" to="291" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">On the Einstein-Podolsky-Rosen paradox</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Bell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="195" to="200" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Statistical Decision Theory and Bayesian Analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Berger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>Springer-Verlag</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Why thought experiments are not arguments</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Bishop</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophy Sci</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="534" to="541" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Can quantum-mechanical description of physical reality be considered complete?</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bohr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Rev</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="696" to="702" />
			<date type="published" when="1935" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Statistics for Experimenters: An Introduction To Design, Data Analysis, and Model Building</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E P</forename><surname>Box</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Pelham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hunter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">G</forename><surname>Hunter</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978" />
			<publisher>John Wiley and Sons, Inc</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Decision theory and marketing management</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Buzzell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="7" to="16" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A comment on the coefficient of determination for binary responses</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wermuth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. Statist. Rev</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="285" to="305" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Causality: Some statistical aspects</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Cox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Statist. Soc., Ser. A</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="291" to="301" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Paradigms lost: On theory and method in research in marketing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Deshpande</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="101" to="110" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Strategic service pricing and yield management</title>
		<author>
			<persName><forename type="first">R</forename><surname>Desiraju</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shugan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="56" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Backwards causation and the direction of causal processes</title>
		<author>
			<persName><forename type="first">P</forename><surname>Dowe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mind</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">418</biblScope>
			<biblScope unit="page" from="227" to="248" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Primer on Determinism</title>
		<author>
			<persName><forename type="first">J</forename><surname>Earman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Series in Philosophy of Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<date type="published" when="1986" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Can quantum-mechanical description of physical reality be considered complete?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Einstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Podolsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Rosen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Physical Rev</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="777" to="780" />
			<date type="published" when="1935" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The Collected Papers of Albert Einstein</title>
		<author>
			<persName><forename type="first">A</forename><surname>Einstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Berlin Years: Writings</title>
				<editor>
			<persName><forename type="first">Alfred</forename><forename type="middle">J</forename><surname>Engel</surname></persName>
		</editor>
		<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1918" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="221" to="236" />
		</imprint>
	</monogr>
	<note>Berliner Tageblatt</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Evaluating structural equation models with unobservable variables and measurement error</title>
		<author>
			<persName><forename type="first">C</forename><surname>Fornell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">F</forename><surname>Larcker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="50" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Overchoice and assortment type: When and why variety backfires</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Gourville</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Soman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="382" to="395" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Investigating causal relations by econometric models and cross-spectral methods</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W J</forename><surname>Granger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="424" to="438" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Testing for causality: A personal viewpoint</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W J</forename><surname>Granger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econom. Dynam. Control</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="329" to="352" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Some recent development in a concept of causality</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">W J</forename><surname>Granger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bayesian decision theory in pricing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Green</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="14" />
			<date type="published" when="1963" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Econometric analysis</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Greene</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1997" />
			<publisher>Prentice Hall</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Confounding and collapsibility in causal inference</title>
		<author>
			<persName><forename type="first">S</forename><surname>Greenland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Robins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statist. Sci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="46" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">How Doctors Think</title>
		<author>
			<persName><forename type="first">J</forename><surname>Groopman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Houghton Mifflin</title>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">How the plague bacillus and its transmission through fleas were discovered: Reminiscences from my years at the Pasteur Institute in Paris</title>
		<author>
			<persName><forename type="first">L</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. National Acad. Sci. U.S.A</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="7609" to="7611" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Customer metrics and their impact on financial performance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zeithaml</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="718" to="739" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Customer satisfaction incentives</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Simester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wernerfelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="327" to="350" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Studies in the logic of confirmation. Mind (A quarterly review of</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Hempel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychology and Philosophy)</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">213</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="1945" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Statistics and causal inference</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Holland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">396</biblScope>
			<biblScope unit="page" from="945" to="960" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Causality in Macroeconomics</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hoover</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Hobbes To Hume: A History of Western Philosophy. Harcourt, Brace, and World</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Jones</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1969" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Brands and branding: Research findings and future priorities</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="740" to="759" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The lead-lag puzzle of demand and distribution: A graphical method applied to movies</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Krider</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Weinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="635" to="645" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Salesforce compensation plans in environments with asymmetric information</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Staelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="179" to="198" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Pressing the flesh in the ratings war</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lowry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Los Angeles Times</title>
		<imprint>
			<biblScope unit="page">18</biblScope>
			<date type="published" when="2002-02-13" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Plague: A Story of Science, Rivalry, and the Scourge That Won&apos;t Go Away Laws of Imitation. Henry Holt and Company</title>
		<author>
			<persName><forename type="first">E</forename><surname>Marriott</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Basics of Structural Equation Modeling</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Maruyama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<pubPlace>Sage, Thousand Oaks, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Naturalistic misunderstanding of the Heisenberg uncertainty principle</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Mckerrow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Mckerrow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Educational Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="20" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">How does objective quality affect perceived quality? Short-term effects, long-term effects, and asymmetries</title>
		<author>
			<persName><surname>Mitra</surname></persName>
		</author>
		<author>
			<persName><surname>Debanjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><surname>Golder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="230" to="247" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The effect of standardized information on firm survival and marketing strategies</title>
		<author>
			<persName><forename type="first">C</forename><surname>Moorman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Du</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Mela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="263" to="274" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Probabilistic Reasoning in Intelligent Systems: Networks of Plausible Inference</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>Elsevier Science and Technology Books</publisher>
			<pubPlace>Amsterdam, The Netherlands</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Causal diagrams for empirical research</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="669" to="688" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Statistics and causal inference: A review</title>
		<author>
			<persName><forename type="first">Judea</forename><surname>Pearl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Test</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="281" to="345" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Indeterminism in quantum physics and in classical physics. Part I</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Popper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British J. Philos. Sci</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="117" to="133" />
			<date type="published" when="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">The Logic of Scientific Discovery. Routledge, London</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Popper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<pubPlace>UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">On the interpretation and observation of laws</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Pratt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schlaifer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="23" to="52" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Direction of Time</title>
		<author>
			<persName><forename type="first">H</forename><surname>Reichenbach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>Dover Publications Inc</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">The Foundations of Statistics</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Savage</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972" />
			<publisher>Dover Publications Inc</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Errors in the variables, unobserved heterogeneity, and other ways of hiding statistical error</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Shugan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="216" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Thought Experiments</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Sorensen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>Oxford, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Causation, Prediction, and Search. Adaptive Computation and Machine Learning Series</title>
		<author>
			<persName><forename type="first">P</forename><surname>Spirtes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Glymour</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Reasoning about a rule</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Wason</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quart. J. Experiment. Psych</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="281" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Theory and Experiment in Gravitational Physics</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Will</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Electronic tickets, smart cards, and online prepayments: When and how to advance sell</title>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Shugan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="219" to="243" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Causality and causal laws in economics</title>
		<author>
			<persName><forename type="first">Arnold</forename><surname>Zellner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
