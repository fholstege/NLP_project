<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Fateful First Consumer Review</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2021-02-03">February 3, 2021</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sungsik</forename><surname>Park</surname></persName>
							<email>sungsik.park@moore.sc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Darla Moore School of Business</orgName>
								<orgName type="institution">University of South Carolina</orgName>
								<address>
									<postCode>29201</postCode>
									<settlement>Columbia</settlement>
									<region>South Carolina</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Woochoel</forename><surname>Shin</surname></persName>
							<email>wshin@ufl.edu</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Warrington College of Business</orgName>
								<orgName type="institution" key="instit2">University of Florida</orgName>
								<address>
									<postCode>32611</postCode>
									<settlement>Gainesville</settlement>
									<region>Florida</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jinhong</forename><surname>Xie</surname></persName>
							<email>jinhong.xie@warrington.ufl.edu</email>
							<affiliation key="aff1">
								<orgName type="institution" key="instit1">Warrington College of Business</orgName>
								<orgName type="institution" key="instit2">University of Florida</orgName>
								<address>
									<postCode>32611</postCode>
									<settlement>Gainesville</settlement>
									<region>Florida</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Fateful First Consumer Review</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
						<imprint>
							<date type="published" when="2021-02-03">February 3, 2021</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.2020.1264</idno>
					<note type="submission">Received: April 3, 2020 Revised: July 15, 2020 Accepted: July 26, 2020</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-13T12:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper uncovers the striking power of a product's first consumer review. Our analytical model suggests that two key metrics of online consumer reviews, valence and volume, are not independent, but instead evolve interdependently. This interdependence forms a mechanism to transfer a (dis)advantage from a product's first review to both a long-lasting (dis)advantage in future word-of-mouth (WOM) valence and an increasing (dis)advantage in future WOM volume. As a result, a single consumer review can significantly influence the fate of a given product. These theoretical predictions, although seemingly unlikely, are supported by our empirical investigations. For example, more than 30% of vacuum cleaner models offered by both Amazon.com and BestBuy.com receive first reviews of opposite valence on the two platforms. Those with a negative first review subsequently suffer a loss in both valence and volume vis-à-vis their counterparts with a positive first review, even after 36 months. More strikingly, the first-review effect on WOM volume increases over time. Our findings reveal a crucial weakness in the user-generated information mechanism. As a consumption-based information source, it creates an information-availability bias such that when a product receives a negative first review, it not only suffers low initial sales, but also loses the opportunity to correct the possible negative bias via subsequent reviews. These findings have substantial implications for online sellers, e-commerce platform providers, and consumers.</p><p>History: K. Sudhir served as the senior editor and David Godes served as associate editor for this article. Funding: W. Shin gratefully acknowledges financial support from the Brian R. Gamache Endowed Professorship at the University of Florida. J. Xie gratefully acknowledges financial support from the JCPenney Endowed Professorship at the University of Florida.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In today's markets, consumers increasingly depend on online word of mouth (WOM) as a reliable source of information in their purchase decisions (Pew Research Center 2016). According to recent consumer surveys, 90% of consumers report that their buying decisions are influenced by online consumer reviews <ref type="bibr">(Dimensional Research 2013)</ref>, and 88% of consumers trust online reviews as much as personal recommendations <ref type="bibr" target="#b8">(BrightLocal, 2014)</ref>. Motivated by the practical significance, academic interest in online consumer reviews has surged and the literature provides extensive evidence to support the impact of online reviews on consumer purchasing behavior (e.g., <ref type="bibr" target="#b20">Godes and Mayzlin 2004</ref><ref type="bibr" target="#b29">, Liu 2006</ref><ref type="bibr" target="#b10">, Chen and Xie 2008</ref><ref type="bibr" target="#b13">, Chintagunta et al. 2010</ref><ref type="bibr" target="#b38">, Sun 2012</ref><ref type="bibr" target="#b2">, Ameri et al. 2019</ref>. Recently, three meta-analyses concluded that the two key metrics of online WOM, valence and volume, are directly linked to product sales <ref type="bibr" target="#b18">(Floyd et al. 2014</ref><ref type="bibr" target="#b43">, You et al. 2015</ref><ref type="bibr" target="#b5">, Babić Rosario et al. 2016</ref>.</p><p>Given the strong linkage between online WOM and sales, the importance of obtaining favorable consumer reviews to product success cannot be overemphasized. The literature has suggested that consumer reviews are affected by product-specific characteristics, such as functionality, brand image, and price (e.g., <ref type="bibr" target="#b26">Li and Hitt 2008</ref><ref type="bibr" target="#b11">, Chen et al. 2011</ref><ref type="bibr" target="#b21">, Godes and Silva 2012</ref><ref type="bibr" target="#b14">, De Langhe et al. 2016</ref><ref type="bibr" target="#b30">, Luca and Zervas 2016</ref>. Thus, if the same product is available at a similar price on multiple online retail platforms, its online reviews should be similar across platforms. However, many market observations contradict this expectation, as shown in Table <ref type="table" target="#tab_0">1</ref>.</p><p>All three products listed in Table <ref type="table" target="#tab_0">1</ref> are available at both Amazon.com and Walmart.com. <ref type="bibr">1</ref> Although both platforms use the same five-star evaluation scale, online reviews of these products are markedly different across these two platforms. First, consider Product A, offered at the same price on both platforms. Its average review rating is 4 stars at Amazon, but only 2.2 stars at Walmart, with 303 reviews at Amazon but only four reviews at Walmart. Second, even in instances where different platforms charge different prices, consumer reviews vary across the platforms, although not necessarily because of the cross-platform price differential. For example, both Products B and C are sold at a lower price at Amazon than at Walmart. However, Amazon's lower price is a disadvantage in online WOM for Product B, but an advantage in online WOM for Product C. Such cross-platform inconsistency in consumer reviews is not limited to these three products or between the two websites presented in Table <ref type="table" target="#tab_0">1</ref>. Rather, it exists in many product categories across various online platforms.</p><p>These observations raise several questions. Why does a product with favorable reviews on one online platform receive an unfavorable review on another? Is this a more general phenomenon than we have so far realized? What fundamental market forces drive such substantial cross-platform inconsistency? Is it possible to predict the direction of such inconsistencies in online WOM? What are the important implications to firms' online WOM management policies, especially given the significance of online WOM to a product's success? Answers to these questions are of significance both from theoretical and practical perspectives.</p><p>To answer these questions, this paper investigates the evolution of online consumer reviews, both theoretically and empirically. We begin by developing a theoretical model that characterizes the process of online WOM evolution. By explicitly modeling the influence of online reviews on consumer purchase decisions, as well as the process of updating online reviews, we discover that the two key metrics of online WOM, valence and volume, are not independent; rather, they evolve interdependently following a positive or negative feedback pattern. Specifically, our analysis reveals that at any given time, the current WOM valence positively impacts future WOM volume, and the current WOM volume positively or negatively impacts future WOM valence, depending on whether the current WOM valence has an upward or a downward bias.</p><p>We show that such interdependence between WOM valence and volume is fundamentally driven by the distinctive characteristics of consumer reviews as a unique information source. Unlike other types of product information (such as advertising and thirdparty product reviews), online consumer reviews are, by definition, posted by users based on their personal consumption experience, which implies that the availability of consumer reviews for a given product is conditional on its adoption. First, this conditional availability of consumer reviews creates the dependence of WOM volume on valence. In other words, at any given time, an increase in a product's average review rating leads to more sales, which, in turn, boosts its future review-posting volume. Second, though less intuitive, this conditional availability of consumer reviews also creates the dependence of WOM valence on volume through the updating process of WOM valence. Specifically, at any given time, a product's average review rating is updated as the weighted average of two components: (1) the previous average rating, which is based on previously posted reviews, and (2) the incremental average rating, which is based on newly posted reviews. The larger the volume of the newly posted reviews, the stronger their impact on the updated valence.</p><p>Understanding the interdependence between WOM valence and volume is vital because, as will be shown by our theoretical analysis, this interdependence endows a product's first consumer review with striking power. In today's information-rich environment, where online shoppers have a staggering amount of user-generated information detailing other shoppers' consumption experiences, it is hard to believe that a single consumer review could exert a significant influence over the fate of a given product. We find, however, that a product's first consumer review has a persistent impact on the product's entire WOM history, measured by both volume and valence. More surprisingly, the impact of the first review on future  <ref type="bibr">(April 13, 2016)</ref>.</p><p>Park, Shin, and Xie: The Fateful First Consumer Review</p><p>Marketing <ref type="bibr">Science, 2021</ref><ref type="bibr">, vol. 40, no. 3, pp. 481-507, © 2021</ref> WOM volume does not diminish, but rather, it intensifies over time. Our theoretical analysis leads to four specific predictions regarding the first-review effect, as summarized in Table <ref type="table" target="#tab_1">2</ref> (see predictions A1-A4). The first two predictions focus on the first review's overall effect on WOM valence and volume, and the last two predictions focus on the first review's dynamic effect on WOM valence and volume. These predictions suggest a persistent and even increasing first-review effect, which is counterintuitive and seemingly unlikely because a single review, however persuasive it may be, is likely to be buried down in the list as subsequent reviews are posted. Thus, intuitively, other reviews should eventually cancel out the impact of the initial review. To gain some external validity, we test these theoretical predictions based on field data. Specifically, we conduct an empirical study using a sample of 177 vacuum cleaner models sold simultaneously on two different retail platforms, Amazon and BestBuy.com (referred to as "Best Buy" hereafter). We empirically examine the relationships between a product's cross-platform difference in its first review and its cross-platform difference in future WOM valence and volume by developing an econometric model that controls other crossplatform differences (such as differences in price) and platform-specific effects. Consistent with predictions A1 and A2, our results reveal that when the same product is offered on the two platforms, both the average review rating and the number of reviews are significantly lower on the platform with a negative first review than on that with a positive first review. <ref type="bibr">2</ref> Our results also support the dynamic patterns of the firstreview effect predicted in A3 and A4. The first-review effect on WOM valence becomes weaker as time passes, but it does not disappear even after an extended period of time. Specifically, our estimates suggest that a negative first review decreases the average rating by 0.29 stars, even one year after the first review posting. Our results also support the counterintuitive snowball effect of the first review on WOM volume (i.e., the impact of the first review on the number of reviews increases with time). Specifically, our estimates reveal that, on average, a product with a negative first review receives 14.98 fewer reviews at the end of the 6th month and 36.49 fewer reviews at the end of the 12th month than a product with a positive first review.</p><p>We supplement our empirical analysis with various robustness checks, which generate the following results. First, the first-review effects hold for different lengths of observation window. Specifically, using the data set of one-, two-, and three-year observation windows, we can confirm that the first-review effect persists even after a significant period of time. More surprisingly, the snowball effect is even supported under an observation window as long as three years. Second, the first-review effect survives some potential alternative explanations. In particular, our analysis shows that the first-review effect is unlikely to be driven by the distinct tastes of consumers in different platforms that favor certain unobserved product characteristics. Moreover, even after accounting for an increase in volume resulting from a front-page placement, we still observe the first-review effect. Third, the firstreview effect is not specific to a certain product category or platform, but is a general finding across various contexts. Our analysis reveals that the data from another category (toasters) support all of our predictions, and so do those from another pair of platforms (Amazon U.S. versus Amazon Canada). Finally, the first-review effect is robust to alternative assumptions on price variations and platform heterogeneity. More specifically, we obtain the same results even after accounting for temporal price variation. Furthermore, even when the magnitude of the first-review effect is assumed to be different across platforms, we still observe the persistence of the first-review effect. While all of the above analyses suggest the robustness of our findings, one caveat is that our analysis focuses on product categories whereby the online WOM is likely to sway consumer choices. For some other categories, however, the first-review effect may be weak or even absent. Our additional analysis shows that consumers' reliance on nonreview information weakens the first-review effect on the WOM volume. This suggests that boundary conditions may exist for the first-review effect and that the relative strength of the influence of nonreview information is one such condition.</p><p>Taken together, our empirical studies provide evidence that supports our theoretical predictions and The first-review effect on WOM valence A product has a higher average rating after a positive first review than a negative first review.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A2</head><p>The first-review effect on WOM volume A product has a higher number of reviews after a positive first review than a negative first review.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A3</head><p>The first-review effect on the dynamics of WOM valence The advantage in the average rating due to the advantage from a positive first review decreases with time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A4</head><p>The first-review effect on the dynamics of WOM volume</p><p>The advantage in the number of reviews due to the advantage from a positive first review increases with time (i.e., the snowball effect).</p><p>Park, Shin, and Xie: The Fateful First Consumer Review</p><p>Marketing <ref type="bibr">Science, 2021</ref><ref type="bibr">, vol. 40, no. 3, pp. 481-507, © 2021</ref> demonstrates the formidable and protracted influence of a product's first review on its future online WOM valence and volume. This paper contributes to online WOM research and practice. In recent years, scholars have made significant efforts to study the consequences of online WOM. In particular, many papers have investigated the influence of online WOM on sales (e.g., <ref type="bibr" target="#b29">Liu 2006</ref><ref type="bibr" target="#b40">, Trusov et al. 2009</ref><ref type="bibr" target="#b13">, Chintagunta et al. 2010</ref><ref type="bibr" target="#b11">, Chen et al. 2011</ref><ref type="bibr" target="#b28">, Libai et al. 2013</ref><ref type="bibr" target="#b31">, Ludwig et al. 2013</ref>, as well as the boundary conditions for such influences (e.g., <ref type="bibr" target="#b19">Forman et al. 2008</ref><ref type="bibr" target="#b46">, Zhu and Zhang 2010</ref><ref type="bibr" target="#b24">, Ho-Dac et al. 2013</ref>. Based on the results of a large number of empirical studies, recent meta-analyses concluded that two key metrics of WOM, volume and valence, significantly affect sales <ref type="bibr" target="#b18">(Floyd et al. 2014</ref><ref type="bibr" target="#b43">, You et al. 2015</ref><ref type="bibr" target="#b5">, Babić Rosario et al. 2016</ref>. In this paper, we uncover the interdependence between these two key metrics of online WOM and derive a crucial implication of such interdependence: the powerful first-review effect. Our research findings make the following contributions.</p><p>First, whereas "big data" is one of the hottest buzzphrases in today's business world, our research brings attention to the significance of "small" data. The first review, even though it is a single data point, has the potential to sway the entire evolution path of online consumer reviews and, thus, the fate of the product. As will become clear in our theoretical model, the power of the first review is created by the interdependence between WOM valence and volume. Fundamentally, this interdependence forms a mechanism that transfers a (dis)advantage in a product's first review rating to (1) a long-lasting (dis)advantage in future WOM valence and (2) an increasing (dis)advantage in future WOM volume. Therefore, the first review, although small in size, holds significant predictive power. These findings call for proactive strategies in managing the first review. In the early stages of a product's life cycle, a special effort should be put forth to preemptively minimize the possibility of a negative first review. Moreover, if the first review turns out to be negative, immediate action should be taken to reverse its negative impact.</p><p>Second, whereas the literature has attributed various advantages to consumer reviews, such as higher credibility, up-to-date information, and nuanced communication <ref type="bibr">Xie 2008, Ranard et al. 2016)</ref>, our research identifies a significant weakness of online consumer reviews. Specifically, because the availability of consumer reviews is conditional on the adoption of the product, not all products have the same chance of receiving informative consumer reviews. For example, a product with low initial sales (which can be caused simply by an unfavorable first review) would fail to generate a viable number of reviews, and such a low review volume would further harm the product's sales.</p><p>Thus, if a product receives an unfavorable initial review, consumers may lose the opportunity to learn about the product altogether, which also potentially deprives them of the chance to enjoy a high-quality product. Our data set shows that 288 out of 1,155 vacuum cleaner models received a negative first review on Amazon, which suggests that about onefourth of all models offered by this platform may fail to provide informative review information. Uncovering this important weakness of online consumer reviews is crucial, because consumer reviews are gaining greater significance in today's market, and firms are increasingly paying attention to them compared with other communication channels. Our findings regarding the availability bias of consumer reviews indicates that blindly following this trend might lead to a suboptimal mix of marketing communication efforts. By recognizing this important limitation of online consumer reviews, firms could develop an effective communication strategy that takes into account the complementarity between consumer-generated information and firm-initiated marketing activities.</p><p>Third, our research advances the literature of review dynamics. Whereas most existing studies have focused on WOM valence dynamics (e.g., <ref type="bibr" target="#b26">Li and Hitt 2008</ref><ref type="bibr" target="#b42">, Wu and Huberman 2008</ref><ref type="bibr" target="#b21">, Godes and Silva 2012</ref>, our research examines the dynamics of both valence and volume and, more importantly, jointly considers the evolution of both. This approach allows us to uncover the path dependence of both valence and volume from the very first review, which cannot be explained by considering the evolution of the valence independently of that of the volume. Moreover, studies of the dynamics of WOM valence have suggested opposite patterns: a downward time trend (i.e., <ref type="bibr">Hitt 2008, Wu and</ref><ref type="bibr" target="#b42">Huberman 2008)</ref> or an upward time trend (i.e., <ref type="bibr" target="#b21">Godes and Silva 2012)</ref>. Our paper, in contrast, proposes and empirically demonstrates that both a downward and an upward trend can exist simultaneously for the same product: WOM valence increases with time on a platform where the first review is negative, but decreases with time on a platform where the first review is positive. <ref type="bibr" target="#b33">Moe and Schweidel (2012)</ref> find a positive relationship between the valence of the ratings environment and review-posting incidence. By modeling the interdependence between WOM valence and volume, our research demonstrates that (a) a (dis)advantage in the first review will transfer to a (dis)advantage in both WOM valence and volume, which can explain a positive relationship between the valence of the ratings environment and review-posting incidence, and (b) the (dis)advantage in WOM volume that results from the (dis)advantage of the first rating increases rather than decreases over time. The latter finding, fundamentally driven by the joint evolution of <ref type="bibr">Xie: The Fateful First Consumer Review Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</ref> WOM valence and volume, cannot be explained by consumer motivation <ref type="bibr" target="#b33">(Moe and Schweidel 2012)</ref>.</p><p>Finally, our results highlight the asymmetric influence of positive and negative first reviews on the information value of the online review process in general. A positive first review, regardless of how biased it might be, facilitates informative online WOM. Even with a significant upward bias, a positive first review leads to a high future WOM volume, which, as more reviews are posted, will effectively correct any initial bias. However, a negative first review is destructive to online WOM. An unfavorable first review reduces the number of consumers who will experience the product and potentially provide additional reviews. As a result, there is little chance to correct the initial bias, and the online WOM will fail to offer sufficient product information. This finding is in stark contrast to the work of <ref type="bibr" target="#b34">Muchnik et al. (2013)</ref>, who observe bias correction in the evaluation of news article comments after a negatively manipulated initial rating but positive herding after a positively manipulated initial rating. The crucial difference is that the valence and volume of the submitted evaluations in their context are independent of each other. In the experimental setting of <ref type="bibr" target="#b34">Muchnik et al. (2013)</ref>, participants cannot observe the ratings before clicking through the comments, suggesting that the consumption of the content (of comments) is independent of previous ratings. In the context of product reviews, however, the valence of previous reviews affects sales in the subsequent periods, because consumers tend to prefer what they have been told are better products. In addition, an evaluation can be made conditional on the purchase of the product, and, thus, the valence of previous reviews affects the volume of subsequent reviews through sales. Review volume, in turn, influences the overall valence of reviews, because bias in the first review may or may not be corrected by future review volume. Therefore, interdependence between volume and valence is key to understanding the firstreview effect in the context of online product reviews.</p><p>The rest of this paper is organized as follows. In Section 2, we develop a theoretical model to study the interdependence of valence and volume of online WOM, which generates predictions about the impact of the first review. In Section 3, we empirically test each of these theoretical predictions using data collected from the field. In Section 4, we explore a boundary condition of the first-review effects both theoretically and empirically. Finally, in Section 5, we summarize our findings and discuss future research opportunities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Theoretical Analysis</head><p>To develop a conceptual understanding of the firstreview effect, in this section, we provide a theoretical analysis of online WOM. Our model is highly stylized for the purposes of illustration, but includes essential components of online WOM evolution well-documented by extant empirical studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">A Model of Online WOM</head><p>In this section, we present our model of online WOM evolution that describes how reviews are generated as well as how reviews influence consumers' purchase decisions. Consider a product of quality α ∈ (0,1). Because an individual rating for the product is determined by idiosyncratic experience of individual consumers, we model the individual rating w i as a sampling process from a Bernoulli distribution with the success probability given as the true quality α. In other words, w i is given as 1 (positive) with probability α but 0 (negative) with probability 1 − α. Thus, the average review rating in any given period t is r t Σ n t i 1 w i n t (t ≥ 1), where n t is the total number of reviews in that period. <ref type="bibr">3</ref> Next, consider a consumer who evaluates a product to purchase in period t. Her valuation of the product depends on both the perceived quality and the fit of the product with her taste. First, she infers the quality of the product by reading the reviews that previous users have written. In particular, she uses the average rating r t−1 as an unbiased estimator of the true quality α. Second, each consumer knows her exact preference and evaluates the fit of the product based on that preference. A consumer lowers her valuation of the product in proportion to the mismatch between her own taste and the product, which we denote by x. Because consumers are heterogeneous in their tastes, we assume that x follows U[0,1]. Together, the valuation of a consumer is given by v t v 0 + βr t−1 − τ • x, where v 0 is the baseline valuation (independent of the quality), β represents consumer's sensitivity to quality, and τ is the mismatch cost. Note that a consumer in this model uses the reviews to infer the quality but not the fit of the product, implying that our model is more relevant to the product category in which quality carries much more weight in the purchase decision than the fit does.</p><p>Based on her valuation v t and the price p of the product, a consumer makes a purchase decision. Because we consider a rational consumer, her decision is not influenced by behavioral biases that have been documented in the WOM literature (e.g., <ref type="bibr" target="#b0">Adomavicius et al. 2013)</ref>. Given the uncertainty concerning product quality, we assume that consumers are risk-averse and derive the following exponential utility: U t 1 − e −(v t −p) (for other applications of this utility formulation; see <ref type="bibr" target="#b22">Holmström and Milgrom 1987</ref><ref type="bibr" target="#b23">, Holmström and Tirole 1993</ref><ref type="bibr" target="#b25">, Kornish and Li 2010</ref><ref type="bibr" target="#b17">, Feng and Xie 2012</ref>. In this specific formulation, for simplicity, we have normalized the Arrow-Pratt risk aversion parameter to be one. However, other values of the risk aversion parameter do not qualitatively change our <ref type="bibr">Xie: The Fateful First Consumer Review Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</ref> results as long as the parameter is greater than zero, that is, consumers are risk averse. Given this utility, the consumer buys the product if and only if her expected utility from purchase is greater than that of no purchase:</p><formula xml:id="formula_0">E[U t ] 1 − e −(v 0 +βr t−1 −τx−p− β 2 r t−1 (1−r t−1 ) 2n t−1</formula><p>) ≥ 1 − e 0 ( 0) (see the appendix for a detailed derivation of the expected utility).</p><p>In each period, M consumers newly arrive in the market. Then, from the expected utility, we can derive the sales of period t as follows:</p><formula xml:id="formula_1">s t M τ (v 0 + βr t−1 − p − β 2 • r t−1 (1−r t−1 ) 2n t−1</formula><p>). Note that the sales are greater with reviews than without them, which is translated into</p><formula xml:id="formula_2">βr t−1 − β 2 • r t−1 (1−r t−1 ) 2n t−1</formula><p>≥ 0, for all r t−1 and n t−1 . To ensure that this condition holds, we assume β ≤ 2. Moreover, for any realization of the review rating, the sales should not be negative. Thus, in our analysis, we focus on the parameter space where p ≤ v 0 holds. <ref type="bibr">4</ref> Finally, among the consumers making a purchase, only a fraction will write a review, as noted in a recent empirical study <ref type="bibr" target="#b3">(Anderson and Simester 2014)</ref>. To capture the review-updating process in a parsimonious way, we use a constant propensity to write a review, δ ∈ (0, 1], implying that the total number of newly arriving reviews in period t (denoted by N t ) follows Binomial(s t , δ). <ref type="bibr">5</ref> Then the total number of reviews in period t is updated as n t n t−1 + N t (t ≥ 1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Evolution of Online WOM</head><p>Based on the model described thus far, we investigate the evolution of online WOM. We specifically examine how the two key variables of online WOM (valence and volume) evolve from period to period. For this purpose, in this section, we fix the valence and the volume of period t (r t and n t ) and examine how the expected valence and volume of period t + 1 are updated. First, recall that the two metrics of online WOM affect the expected sales of the next period through</p><formula xml:id="formula_3">E[s t+1 |r t , n t ] M τ (v 0 + βr t − p − β 2 •r t (1−r t )<label>2n t</label></formula><p>). Because N t+1 follows Binomial(s t+1 , δ), the expected number of reviews is as follows:</p><formula xml:id="formula_4">E[n t+1 |r t , n t ] n t + E[N t+1 |r t , n t ] n t + δ • E[s t+1 |r t , n t ] n t + δM τ ( v 0 + βr t − p − β 2 • r t (1 − r t )<label>2n t</label></formula><p>) .</p><p>(1)</p><p>Next, let h t denote the total number of positive reviews in period t, and let H t represent the number of newly arriving positive reviews in period t. These definitions imply h t+1 h t + H t+1 . Then by definition, the expected average rating in period t + 1 is given as follows:</p><formula xml:id="formula_5">E[r t+1 |r t , n t ] E [ h t+1 n t+1 |r t , n t ] E [ h t + H t+1 n t+ N t+1 |r t , n t ] .<label>(2)</label></formula><p>Equations ( <ref type="formula" target="#formula_24">1</ref>) and (2) describe the period-to-period transition of the valence and the volume, which determines the evolution over time of these two metrics. Interestingly, these equations show that the current state of each metric is affected by not only its own previous state but also that of the other metric. An important implication of this observation is that the valence and the volume of online WOM evolve interdependently. On systematically investigating the relationship between the two variables, we obtain the following theorem.</p><p>Theorem 1 (Interdependence Between Valence and Volume of Online Consumer Reviews). Two key metrics of online consumer reviews, valence and volume, evolve interdependently with positive or negative feedback. Specifically, in any given period t (≥1), (b) the volume of newly posted reviews (N t+1 n t+1 − n t ) influences the valence (E[r t+1 ])</p><p>i. positively if the previous valence is biased downward (i.e., r t &lt; α),</p><p>ii. negatively if the previous valence is biased upward (i.e., r t &gt; α).</p><p>For proofs, see the appendix. The theorem describes how the two metrics influence each other in their evolution. To understand part (a) of the theorem, recall from previous research that positive reviews from the previous period enhance the product's sales <ref type="bibr" target="#b43">(You et al. 2015</ref><ref type="bibr" target="#b5">, Babić Rosario et al. 2016</ref></p><formula xml:id="formula_6">): ∂E[s t+1 ]</formula><p>∂r t &gt; 0. Moreover, note that only consumers who have purchased the product post online reviews, implying that each review posting is conditional on the adoption of the product. Therefore, the volume of consumer reviews in any given period will be positively affected by the level of sales: <ref type="bibr">6</ref> This finding implies that online consumer reviews may provide insufficient information, depending on the current level of sales. Especially, in the case of low sales, consumers could suffer from this information availability bias. Taken together, these two inequalities imply that the valence of consumer reviews increases the volume of reviews in the subsequent period:</p><formula xml:id="formula_7">∂E[n t+1 ] ∂E[s t+1 ] &gt; 0.</formula><formula xml:id="formula_8">∂E[n t+1 ] ∂r t ∂E[n t+1 ] ∂E[s t+1 ] • ∂E[s t+1 ]</formula><p>∂r t &gt; 0. Part (b) of the theorem discusses the impact of the volume on the future valence of the online reviews. In this case, unlike in part (a), the impact may be either positive or negative, depending on the magnitude of the current valence relative to the true quality of the product. To understand this, note that, in any period, the valence is the weighted average of the valence of all previously posted reviews and that of newly posted reviews, with the weight being the volume of each group of reviews. Thus, if the valence in the previous period is more negative than that of the newly posted reviews, a greater volume of newly posted reviews will render the valence of the current period more positive. However, if the valence in the (a) the current valence r t positively influences the future volume (E[n t+1 ]); <ref type="bibr">Xie: The Fateful First Consumer Review Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</ref> previous period is more positive than that of the newly posted reviews, a greater volume of newly posted reviews will turn the valence of the current period more negative. On average, the valence of the newly posted reviews is consistent with the true quality of the product. Thus, if the realized valence of already posted reviews happens to be lower than the product's true quality, a greater volume of newly posted reviews will elevate the future valence. However, if the realized valence is higher than the true quality, a greater volume of newly posted reviews will lower the future valence.</p><p>An important implication of Theorem 1 is that evolution patterns of the two key metrics of online WOM, valence and volume, can be accurately captured only when their interaction is considered. Given the evolution patterns characterized thus far, it is evident that previous reviews can influence both the valence and the volume of subsequent reviews. Such influence leads to the possibility that the very first review might have a significant impact on the evolution of both the valence and the volume of the entire set of reviews. We examine this possibility in the next subsection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">The First-Review Effect</head><p>In this section, we examine how the first review might influence both the valence and the volume of subsequent reviews. For this purpose, we start from the initial period (t 0), where the very first review is posted. At this initial period, the first review is exogenously given as either positive (r 0 1) or negative (r 0 0). Then, depending on the valence of the first review, we separately trace the evolution of valence and volume using superscript k ∈ {+ , −}, where k</p><formula xml:id="formula_9">+ if r 0 1 and k − if r 0 0. By comparing E[n + t ] and E[n − t ] as well as E[r + t ] and E[r − t ]</formula><p>, we derive predictions regarding the impact of the first review on the valence and the volume of online WOM in every subsequent period. Note that because these predictions are made in period 0 where n k t and r k t (t ≥ 1) have not been realized yet, we examine their expected values. However, doing so complicates the analysis and we thus resort to the numerical simulation in deriving our predictions. See Online Appendix A1 for the detailed procedure and the results of the numerical analysis.</p><p>Proposition 1 (First-Review Effect: Overall Impact). A product's first consumer review persistently influences its future consumer reviews. Specifically, a higher rating in the first review leads to (a) a higher average rating and (b) a higher number of reviews in any given period. Formally,</p><formula xml:id="formula_10">E [ r + t ] &gt; E [ r − t ] and E [ n + t ] &gt; E [ n − t ]</formula><p>, for all t.</p><p>(3)</p><p>The previous proposition shows that both the valence and the volume of WOM crucially depend on the valence of the first review. More specifically, when the first review is positive, both the average rating and the total number of reviews are higher than when the first review is negative. Below, we provide intuitions for the valence and the volume results, respectively. In general, many idiosyncratic factors affect the valence of each individual review. Thus, one would not expect the first review to affect the average rating in subsequent periods in any significant way. Nevertheless, the first part of the proposition states that a positive first review generates a higher average rating in every subsequent period. To understand this rationale, recall that the valence in any period is the weighted average of the valence of all previously posted reviews and the average rating of newly posted reviews. Moreover, the average rating of newly posted reviews does not depend on the valence of the first review. Therefore, any advantage in the average rating of the previous period is likely to persist in the average rating of the next period, implying that the average rating in subsequent periods will be more positive if the first review is positive than if it is negative.</p><p>Proposition 1 also shows that a greater number of reviews will be generated after a positive first review than after a negative one. Two different mechanisms contribute to this result. First, recall from the first part of the proposition that a higher rating in the first review results in higher average ratings in subsequent periods. Because consumers are more likely to purchase a product when online reviews are favorable <ref type="bibr" target="#b43">(You et al. 2015</ref><ref type="bibr" target="#b5">, Babić Rosario et al. 2016</ref>), sales will be greater after a positive first review than after a negative one. Then, in the subsequent period, a greater volume of WOM will follow. Second, more reviews reduce consumers' uncertainty about the quality of the product regardless of the valence of the reviews, because more reviews reflect greater sales, which in turn work as a social proof that the product quality is sufficiently high to warrant purchase <ref type="bibr">(Bikhchandani et al. 1998, Zhang and</ref><ref type="bibr" target="#b45">Liu 2012)</ref>. Thus, consumers are more attracted to a product when making a purchase decision if they see a large number of posted reviews. Hence, more reviews lead to greater sales and, in turn, to a greater volume of WOM, which establishes a positive feedback loop between sales and WOM volume. Both of these two effects (the direct impact of WOM valence on sales and the positive feedback loop between sales and volume) work together to generate a greater volume of WOM from a positive than from a negative first review.</p><p>Given the well-documented impact of WOM valence and volume on sales <ref type="bibr" target="#b43">(You et al. 2015</ref><ref type="bibr" target="#b5">, Babić Rosario et al. 2016</ref>), these results have important implications. Our results suggest that a product of the same quality may generate different amounts of WOM with different average ratings, thus achieving different levels of sales, all depending on the valence of the <ref type="bibr">Xie: The Fateful First Consumer Review Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</ref> first review. More importantly, this impact persists over time; thus, any negative impact due to a negative first review is very hard to reverse without costly intervention. Therefore, when launching a new product, it is critical that the first review be positive.</p><p>Given that the first-review effect persists, an interesting question is how the magnitude of this effect changes over time. To examine this issue, we study the evolution of the valence and the volume of consumer reviews and obtain the following result.</p><p>Proposition 2 (First-Review Effect: Dynamics Over Time).</p><p>(a) The first-review effect on valence diminishes over time:</p><formula xml:id="formula_11">E[Δr t ] &gt; E[Δr t+1 ], for all t,<label>(4)</label></formula><p>where Δr t r + t − r − t and Δr t+1 r</p><formula xml:id="formula_12">+ t+1 − r − t+1 . (b)</formula><p>The first-review effect on volume intensifies over time:</p><formula xml:id="formula_13">E[Δn t ] &lt; E[Δn t+1 ], for all t,<label>( 5 )</label></formula><p>where Δn t n + t − n − t and Δn t+1 n + t+1 − n − t+1 . The previous result characterizes the evolution of the valence and the volume of WOM as a function of the valence of the first review. The first part of the proposition shows that the impact of the first review on the valence of WOM becomes weaker as time passes. This weakening occurs because any bias in the first review is corrected as more reviews arrive. Recall that the valence of an individual review is drawn from a Bernoulli distribution with a success probability α (i.e., the product's true quality). The law of large numbers suggests that the average rating will converge to this true quality over the long term. Thus, if the average rating was too high at the beginning (r 0 1), it will decrease to α; but if it was initially too low (r 0 0), it will rise to α. Therefore, the first-review effect on the valence becomes weaker over time, although, as Proposition 1 suggests, it does not completely disappear.</p><p>In contrast, the first-review effect on WOM volume not only persists but is also reinforced as time passes, according to the second part of the proposition. This result is obtained because, in every period, the number of newly arriving reviews is greater when the first review is positive than when it is negative. Note that Proposition 1 discusses the total volume of WOM in each period as a function of the first review. However, the same intuition applies to the newly arriving reviews in each period. In particular, because, by part (a) of Proposition 1, the positive first review shifts the valence of overall WOM upward, consumers are more likely to purchase the product and, thus, the number of newly arriving reviews in every period is likely to be greater when the first review is positive than when it is negative. Therefore, because of the difference in the first review, the incremental number of reviews accumulates in each period, which strengthens the impact of the first review on the overall volume period by period. This result implies that a small difference at the beginning could lead to a drastic divergence at the end. In this sense, the online WOM phenomenon is subject to a severe path dependence, where the very first review determines the evolution path, and thus the fate of a product.</p><p>Overall, our theoretical analysis implies that a negative first review is detrimental to the performance of a product in several different ways. First, with a negative first review, the valence of WOM remains negative for a significant amount of time, which reduces sales, according to recent meta-analyses <ref type="bibr" target="#b43">(You et al. 2015</ref><ref type="bibr" target="#b5">, Babić Rosario et al. 2016</ref>. At the same time, the volume of WOM for the product is lower, which again leads to lower sales, as shown by the aforementioned meta-analyses. Moreover, even though a negative bias in the average rating of a product can be corrected over time, it may have little or no chance of correction because of a lower review volume. In an extreme case, a product may not even take off as a result of a negative first review, resulting in only mediocre sales at best, and thus may not obtain many additional reviews, keeping the online sentiment toward the product negative. Therefore, we should not consider the first review as just a single review, but rather as the most influential review that, as such, must be properly managed.</p><p>So far, our theoretical analysis has generated four testable predictions regarding the significance of the first review, which we present in Table <ref type="table" target="#tab_0">2 (A1-A4</ref>). Given their counterintuitive nature, it is necessary to subject each of these predictions to empirical tests. In the next section, we present empirical studies to test these predictions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Empirical Analysis</head><p>In this section, we report the results of our empirical investigations into the first-review effect. We use vacuum cleaners as the empirical context of our analysis because, in this category, consumers' purchase decisions are likely to be heavily influenced by product reviews. Note that vacuum cleaners are privately consumed durable goods with infrequent product trials and thus are susceptible to online WOM <ref type="bibr" target="#b43">(You et al. 2015)</ref>. Furthermore, our analysis of review texts reveals that consumers of vacuum cleaners consider more vertical attributes (i.e., quality) than horizontal ones (i.e., fit) in their purchase decisions (see Online Appendix B2 for details), which indicates that the vacuum cleaner category provides an appropriate context to test our theory.</p><p>To identify the first-review effect, we compare the volume and the valence of WOM when the first review is positive with those when it is negative. Our study specifically uses a sample of products that simultaneously appear on two different retail platforms, Amazon and Best Buy, and examines how <ref type="bibr">Xie: The Fateful First Consumer Review Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</ref> different first reviews on different platforms could make a difference in the valence and the volume of the online reviews for the same product. In what follows, we first present our data as well as initial evidence that our theoretical predictions are in line with the empirical observations. We then describe formal tests of the theory in greater detail. Later, we also discuss the robustness of our results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data</head><p>We collect online review information as well as product characteristics on vacuum cleaners from both Amazon and Best Buy. For completeness, we cover in our data set all the vacuum cleaners with at least one review from both Amazon and Best Buy at the time of data collection <ref type="bibr">(January 6, 2015)</ref>. This results in a total of 177 vacuum cleaner models in our data set. For each of these products, we collect the number of reviews, the order of each review, the date each review was posted, the rating of each review, the review texts, and the price of the product from both platforms. Table <ref type="table" target="#tab_2">3</ref> provides summary statistics of this data set.</p><p>Given these data, for each product, we calculate the average rating as well as the number of reviews each month since the first review was posted, which allows us to have multiple observations of the average rating and the number of reviews for each product across time. Note, however, that different products in our data set have different numbers of observations because they were launched, and their first reviews were posted, at different points in time. Thus, for products launched closer to the data collection time, observations are truncated earlier, thus resulting in a smaller number of observations. Although we do not expect this data structure to cause any selection bias in the overall impact of the first review, the evolution pattern of WOM might be heavily influenced by products with longer durations. To minimize such an asymmetric influence while maintaining the representativeness of the sample, we confine our observation window to one year, during which about 71% of the products in the sample cover the whole observation period, whereas the remaining 29% have observations truncated at some point before the end of the observation period. In Section 3.6.1, we consider observation windows of different lengths to demonstrate the robustness of our findings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Initial Evidence</head><p>Our theory concerns the valence and the volume of WOM as a function of the valence of the first review. We classify the first review as positive if its rating is strictly greater than three stars and as negative otherwise, following Amazon's dichotomization scheme. In our data set, 31.07% of 177 products exhibit inconsistent first reviews across the two platforms, according to this classification. Specifically, 21 products obtain a positive first review on Amazon and a negative one on Best Buy, whereas 34 products have a negative first review on Amazon and a positive one on Best Buy. By examining these two groups of products, one can potentially identify the first-review effect. We thus calculate both the average star rating and the average number of reviews on each platform for these two groups. We report the results in Table <ref type="table" target="#tab_3">4</ref>. First, Table <ref type="table" target="#tab_3">4</ref> shows that the first group of products (with a  positive first review on Amazon and a negative one on Best Buy) has a higher average rating as well as a higher number of reviews on Amazon than on Best Buy. This observation is in line with the first-review effect (i.e., a positive first review leads to more reviews with a higher average rating). Second, the other group (with a negative first review on Amazon and a positive one on Best Buy) exhibits a lower average rating but a higher number of reviews on Amazon than on Best Buy. Although the average rating moves in the same direction as our theory predicts, the result on the number of reviews seems to contradict the firstreview effect. However, Table <ref type="table" target="#tab_3">4</ref> also suggests that this might be due to a platform-specific effect. Specifically, we find that the products sold from both platforms on average receive 0.26 fewer stars but 48.49 more reviews on Amazon, across all samples (fifth row of Table <ref type="table" target="#tab_3">4</ref>). Thus, we need to control for the platformspecific effect for fair comparisons. To do so, we additionally conduct a nonparametric test that does not depend on the platform-specific effect. We will also formally address this issue when we develop our empirical model in the next section.</p><p>As an alternative test, we conduct the Wilcoxon signed-rank test. In this test, we can avoid the problem of unequal baselines across the two platforms by using ranks instead of raw data. Thus, for the two groups of products with different first reviews across the two platforms, we test whether the average ranks of the products on one platform are comparable to those of the same products on the other. However, because both the average rating and the number of reviews vary over time, to determine the ranking of products, we fix the time at the end of one year and consider only products that reach this particular time period. In this sample, 37 products have inconsistent first reviews. The first row of Table <ref type="table" target="#tab_4">5</ref> reports the results from the comparison of these 37 products, where lower numbers imply higher rankings. As shown in this table, products typically rank higher for both the average rating and the number of reviews across the two platforms if the first review is positive rather than negative. To see whether these results are specific to the observation timing or the size of the sample, we also run the same test for a sample of 46 products that reached the end of the sixth month and report the results in the second row of Table <ref type="table" target="#tab_4">5</ref>. As can be seen from the table, we obtain qualitatively the same results, that is, in both metrics, the rankings are significantly higher for the same product when its first review is positive, rather than negative. Therefore, our preliminary analysis of the data supports the first-review effect: a positive first review generates more reviews with higher ratings than does a negative first review.</p><p>The above analyses have shown the static firstreview effect. To examine the dynamic effect, we plot the evolution of the average ratings and the number of reviews in Figure <ref type="figure" target="#fig_0">1</ref>. Note that in the figure, we control for both the platform-specific and the product-specific effects by plotting the residuals from the regression on these effects. The left panel of Figure <ref type="figure" target="#fig_0">1</ref> first confirms the static first-review effect on the WOM valence: the average rating is higher when the first review is positive than when it is negative. Moreover, it shows that the difference in the average rating decreases with time. Nonetheless, the difference does not disappear even after a year, implying that the first-review effect on the valence persists for a significant amount of time. The right panel of Figure <ref type="figure" target="#fig_0">1</ref> also reaffirms the static first-review effect on the WOM volume: a positive first review generates more reviews than a negative first review. More interestingly, the figure indicates that the difference in the number of reviews increases over time, thus confirming the dynamic effect of the first review on the volume. Overall, we find support from our data set for both static and dynamic first-review effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Identification Strategy</head><p>As noted above, our identification of the first-review effect is based on the cross-platform comparison of the review metrics of the same product. This implies that we can identify the first-review effect while controlling for unobserved heterogeneity specific to the product (for a similar approach, see also <ref type="bibr" target="#b12">Chevalier and Mayzlin 2006)</ref>. To better understand this, note that unobserved product-specific effects such as product quality may affect both the first review and later reviews. In general, such common factors for both dependent and independent variables, if not controlled, may lead to the endogeneity bias in the estimates. However, our estimation uses the withinproduct variation across two platforms, which, by definition, is independent of the product quality or other product-specific effects. Thus, the productspecific effects do not influence our estimation. Moreover, within-product variation in the reviews comes from each individual reviewer's unique experience of the product. Thus, within-product variation in the first review may well be exogenous to within-product variation in the other reviews (and hence, in our dependent measures, the average rating and the number of reviews). Therefore, in our identification strategy, endogeneity (due to unobserved product-specific effects) is unlikely to be an issue.</p><p>Our identification strategy also implies that the linear and separable platform-specific effects are differenced out in our estimation. However, it is possible that there might exist product-platform specific effects. Although our current approach does not directly rule out this possibility, in a later section, we show that such product-platform specific effects are unlikely to exist and that even if they do, the first-review effect still survives, using the second-differencing approach (see Section 3.6.2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.4.</head><p>The First-Review Effect on the Valence of WOM 3.4.1. Model and Estimation. In this section, we formally test our predictions on the impact of the first review on the valence of WOM (i.e., A1 and A3). Recall that A1 states that the average rating of a product is higher when its first review is positive than when it is negative. The same hypothesis also implies that this should hold for every period t. Moreover, A3 states that the first-review effect on the average rating diminishes over time. Note that the average rating of a product changes with time, as new reviews arrive. Thus, the average rating is specific not only to the product, but also to the time elapsed since the first review was posted. Therefore, we adopt the panel structure and consider the following model:</p><formula xml:id="formula_14">AR j it β j 0 + β 1 FNegative j i + β j 2 ln( FDuration it ) + β 3 FNegative j i × ln( FDuration it ) + X j it Γ j + µ i + ε j it , (<label>6</label></formula><formula xml:id="formula_15">)</formula><p>where subscript i is the indicator for the product, subscript t is the indicator for the period, and superscript j is the indicator for the platform (j A, B; A is Amazon, and B is Best Buy); AR j it is the average rating of product i at period t in platform j; FNegative j i is a dummy variable representing the valence of the first review of product i in platform j, following Amazon's dichotomization scheme presented above (1 negative; 0 positive); and FDuration it represents the duration of the first review of product i at period t, as measured by the number of months. Note that this is not a calendar date but the elapsed time since Notes. To construct the figure, we respectively regress the average ratings (left panel) and the standardized number of reviews (right panel) on the product characteristics (types and bag and cord dummies) and site-specific fixed effects. Then, we compute the average of residuals for each month depending on the valence of the first review. For a fair comparison, we use a sample of products with at least 12-month-period observations. Note that the number of reviews is standardized at the platform level.</p><p>Park, Shin, and Xie: The Fateful First Consumer Review</p><p>Marketing <ref type="bibr">Science, 2021</ref><ref type="bibr">, vol. 40, no. 3, pp. 481-507, © 2021</ref> the first review posting. Moreover, FDuration it always takes the same value as the period: FDuration it t. In the regression, because of a curvilinear relationship between the average rating and the duration of the first review, we use the log transformation of the duration. <ref type="bibr">7</ref> To capture potentially different rates of temporal change in the average ratings of the two platforms, we use platform-specific coefficients for the FDuration (β j 2 ). The matrix X j it contains control variables, including the log of the product price, the log of the number of words in the first review (WC), consumer search volume on Google (both at category and brand levels), product type dummies, product feature indicators, and the volume. <ref type="bibr">8</ref> We include these variables to control product specific and product-platform specific effects that might affect the evolution of online WOM. For example, a product's price might correlate with the valence of its reviews, the first review may be more influential if its review text is lengthy, and it is also possible that the WOM volume may influence the average ratings. Note, however, that using the volume itself will distort the estimate for the first-review effect on the valence, because the effect through the volume will be cut out. To capture the full effect of the first review on the valence while controlling for the volume, we use a volume variable that is independent of the first-review effect. In particular, we use the residual from the regression of the volume on FNegative, ln( FDuration), FNegative × ln( FDuration), and all controls in the matrix X j it other than the volume variable itself (see Online Appendix B3, for more details on this first-review-independent volume variable). <ref type="bibr">9</ref> Last, µ i captures the unobserved heterogeneity specific to the product, and ε j it represents an unobserved heterogeneity specific to both the product and the platform, both of which are not explained by the independent variables. We assume the errors to be normally distributed with a mean of zero.</p><p>Recall that we identify the first-review effect by the cross-website variation of the same product. To implement this identification strategy, we difference the average ratings in the two platforms for each product i and each period t. By doing this, we also eliminate the linear and separable product-level fixed effects. We thus obtain the following estimation equation:</p><formula xml:id="formula_16">ΔAR it β 0 + β 1 ΔFNegative i + β 2 ln( FDuration it ) + β 3 ΔFNegative i × ln( FDuration it ) + Γ A X A it − Γ B X B it + ε it ,<label>(7)</label></formula><p>where</p><formula xml:id="formula_17">β 0 ≡ β A 0 − β B 0 , β 2 ≡ β A 2 − β B 2 , ΔAR it ≡ AR A it − AR B it , and ΔFNegative it ≡ FNegative A it − FNegative B it .</formula><p>Note that for the control variables taking the same value across the two platforms (i.e., product type dummies and product feature indicators), Γ A and Γ B will not be separately identified, but only their difference will be. These coefficients capture the product-platform specific effects, such as the stronger preference of Amazon consumers for a certain product type. For other controls, both Γ A and Γ B can be separately identified. The error term (ε it ε A it − ε B it ) is the difference in the error terms and, thus, is also normally distributed with a mean of zero. Therefore, the error term still captures unobserved heterogeneity specific to the product. This also implies that errors are likely to be correlated across periods within a product. In this case, ordinary least squares (OLS) still produces consistent estimates of the model parameters, but the standard errors will be underestimated <ref type="bibr" target="#b6">(Bertrand et al. 2004</ref>). Hence, we estimate our main parameters using OLS, but we also cluster standard errors by product to account for potential serial correlation <ref type="bibr" target="#b27">(Liang and Zeger 1986)</ref>. In our estimation, we only use 138 products from our data set that received at least two reviews from both platforms, because with only one review, the average rating and FNegative are almost perfectly correlated. Note that these 138 products include those with inconsistent first reviews across the two platforms, and also those with consistent first reviews, with the former identifying the first-review effect and the latter capturing the baseline difference across the two platforms.</p><p>3.4.2. Results. We report our estimation results in column (1) of Table <ref type="table" target="#tab_5">6</ref>. The table shows that the data support both of our predictions regarding the valence of WOM (i.e., A1 and A3). To see this, note that the coefficient for ΔFNegative (i.e., β 1 ) represents the firstreview effect on the valence in the first period (t 1), whereas that for ΔFNegative • ln( FDuration) (i.e., β 3 ) captures the dynamic effect of the first review. According to column (1) of Table <ref type="table" target="#tab_5">6</ref>,β 1 is negative and significant (β 1 −1.314, p &lt; 0.01), which implies that the average rating of the first month is lower when the first review is negative than when it is positive.</p><p>Column (1) of Table <ref type="table" target="#tab_5">6</ref> also shows thatβ 3 is positive and significant (β 3 0.412, p &lt; 0.01), suggesting that since the first month, the effect of the first review weakens over time. Based on these estimates, we examine specific predictions in A1 and A3.</p><p>First, we examine whether the first review indeed influences the average rating in every period (A1). In particular, we test whether the average rating is lower when the first review is negative than when it is positive for the entire sample period (t 1,2, . . ., 12). As reported in Table <ref type="table">7</ref>, for every t, we find that β 1 + ln(t)β 3 is negative and significant (p &lt; 0.01 for t 1, . . ., 9; p &lt; 0.05 for t 10, 11; p &lt; 0.1 for t 12). As an alternative test, we separately estimate each of the period-specific first-review effects by interacting ΔFNegative with each period dummy and examine their signs. The results in Table <ref type="table" target="#tab_7">8</ref> show that the estimates for all these interaction terms are significant (p &lt; 0.05). These results confirm that the firstreview effect on the valence is consistent with the prediction A1.</p><p>Second, we examine the dynamic effect of the first review (A3). As noted above, the estimate of ΔFNegative • ln( FDuration) (β 3 ) shows the sign opposite to that of the estimate of ΔFNegative (β 1 ). This result indicates that the difference in the average ratings caused by the first review decreases over time. Yet, the effect does not disappear for an extended period of time, as A1 suggests. For example, our estimation results predict that receiving a negative (rather than positive) first review for a product reduces the average rating by 0.58 stars by the end of the sixth month (β 1 + ln(6)β 3 −0.58), and by 0.29 stars by the end of the first year (β 1 + ln(12)β 3 −0.29). According to our estimates, even after 12 months, the average rating is expected to be lower when the first review is negative than when it is positive. More surprisingly, as Section 3.6.1 will later show, our estimation with longer observation windows Table <ref type="table">7</ref>. Period-Specific First-Review Effects Based on the Estimates in Tables <ref type="table" target="#tab_5">6 and 9</ref> FDuration(t)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dependent variable: Valence</head><p>Dependent variable: Volumê</p><formula xml:id="formula_18">β 1 + ln(t)β 3</formula><p>p-value for H0: suggests that a negative first review significantly decreases the average ratings even after 36 months. Thus, the first-review effect persists over time. Even though the average rating should theoretically converge to the true quality in the long run, it would take a significant amount of time to do so, because a negative first review induces a lower volume of subsequent reviews, as shown in Proposition 1(b). 10 Therefore, the valence of the first review has a nontrivial and persistent impact on the valence of the overall WOM. Finally, we estimate Equation ( <ref type="formula" target="#formula_16">7</ref>) with month fixed effects included in order to control for any potential seasonality. As shown in column (2) of Table <ref type="table" target="#tab_5">6</ref>, we find very similar estimates for both β 1 and β 3 . This implies that either seasonality or some time effects cannot explain our results.</p><formula xml:id="formula_19">β 1 + ln(t)β 3 0β 1 + (t − 2) •β 3 p-value for H0: β 1 + (t − 2) • β 3 0 1 −1.</formula><p>3.5. The First-Review Effect on the Volume of WOM 3.5.1. Model and Estimation. We now turn to the impact of the first review on the volume of WOM. In particular, we test predictions A2 and A4: in any period, the number of reviews is greater when the first review is positive than when it is negative; the gap in the number of reviews not only persists, but also intensifies as time passes. To test these predictions, we consider the following model: for t ≥ 2, NR j it</p><formula xml:id="formula_20">β j 0 + β 1 FNegative j i + β j 2 FDuration it−2 + β 3 FNegative j i × FDuration it−2 +X j it Γ j + µ i + ε j it ,<label>(8)</label></formula><p>whereÑR j it represents product i's standardized number of reviews received up to period t in platform j, and all independent variables are defined as in the previous section, except that we include both lagged first-review-independent valence and lagged first-review-independent volume in X j it (see Online Appendix B3 for details). <ref type="bibr">11</ref> Because of the inclusion of lagged variables, we estimate the model with the data only from the second period and on. Accordingly, we use FDuration it−2 to capture the dynamic effect after the second period. Finally, in our model, we use the dependent variable after standardizing it at the platform level:ÑR j it (NR j it − NR j )/σ j , where NR j and σ j respectively refer to the mean and the standard deviation of the number of reviews (NR j it ). This is to make the two platforms comparable by removing the substantial difference in the variation of their number of reviews. <ref type="bibr">12</ref> As in the previous study, we identify the firstreview effect by differencing Equation ( <ref type="formula" target="#formula_20">8</ref>) for the two platforms for each product in each time period. We thus estimate the following equation:</p><formula xml:id="formula_21">ΔÑR it β 0 + β 1 ΔFNegative i + β 2 FDuration it−2 + β 3 ΔFNegative i × FDuration it−2 + Γ A X A it − Γ B X B it + ε it ,<label>( 9 )</label></formula><p>where ΔÑR it ≡ÑR A it −ÑR B it , and β 0 , β 2 , and ΔFNegative i are defined as before. We estimate Equation (9) using OLS with standard errors clustered at the product level.</p><p>3.5.2. Results. We report the estimation results in column (1) of Table <ref type="table" target="#tab_9">9</ref>. The estimates suggest that our data support both A2 and A4. Among the coefficients of our interests, the coefficient of ΔFNegative i (β 1 ) represents the first-review effect on the volume in the second period (t 2), and that of ΔFNegative i × FDuration it−2 (β 3 ) captures the dynamic effect of the first review. Table <ref type="table" target="#tab_9">9</ref> shows thatβ 1 is negative yet statistically insignificant (β 1 −0.019, p 0.181), which indicates that in the second period, the first review has only an insignificant effect on the number of reviews, although its direction is consistent with the prediction in A2. This happens probably because in initial periods, the volume of reviews is too small to exhibit any significant difference (note that, e.g., in the second period, each product, on average, receives only 10.24 reviews). However, the same table also shows thatβ 3 is negative and significant (β 3 −0.054, p &lt; 0.01), which, together with the β 1 estimate, suggests that the   negative first review (compared with the positive one) decreases the number of reviews more period by period. Based on these estimates, the predictions A2 and A4 can be confirmed as follows.</p><p>First, to examine whether the first review positively influences the number of reviews in all subsequent periods, we computeβ 1 +β 3 • FDuration it−2 for each value of t (t 2, 3, . . . , 12). As shown in Table <ref type="table">7</ref>, we obtain negative and significant values (p &lt; 0.01) in all periods except the second period (t 2). Moreover, we estimate period-specific first-review effects on the volume by interacting ΔFNegative i with period dummies and find that the estimated first-review effects are all negative and significant (p &lt; 0.01) except for the second period (see Table <ref type="table" target="#tab_7">8</ref>). Therefore, our empirical analysis suggests that the negative first review decreases the number of reviews in the subsequent periods, which confirms A2.</p><p>Next, we examine the snowball effect (A4). Given that the static effect of the negative first review on the volume is negative, the negative (and significant) interaction between ΔFNegative i and FDuration it−2 (β 3 ) implies that such a static effect is intensified over time, thus confirming the snowball effect (A4). To illustrate this snowball effect, we calculate the estimated difference in the number of reviews (due to the first review) in the middle and at the end of the data period (i.e., period 6 and period 12). We find that a positive first review (compared with a negative first review) is expected to increase the number of reviews by 0.23 standard deviation ( β 1 + (6 − 2) •β 3 ) in period 6 and by 0.56 standard deviation ( β 1 + (12 − 2) •β 3 ) in period 12. To put this in perspective, on Amazon, products with a negative first review generate 14.98 and 36.49 fewer reviews compared with those with a positive first review in period 6 and in period 12, respectively. This suggests that the difference in the number of reviews increases over time. Therefore, our analysis confirms that the first review has a significant and even increasing impact on the WOM volume. Finally, as in the valence model, we reestimate Equation ( <ref type="formula" target="#formula_21">9</ref>) with month-level fixed effects included and find the qualitatively same results (see column (2) of Table <ref type="table" target="#tab_9">9</ref>). Thus, our results are unlikely to be explained by seasonality or time fixed effects.</p><p>We conclude this section by briefly discussing an empirical test of the mechanism behind our results. Recall from Section 2 that the first-review effect comes from the interdependence of the valence and the volume (as summarized in Theorem 1). Using the same data set, we find empirical support for both claims of Theorem 1, thus confirming the suggested  <ref type="bibr">Xie: The Fateful First Consumer Review Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</ref> theoretical mechanism for both types of first-review effects. The details of this analysis can be found in Online Appendix B4.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Robustness Checks</head><p>So far, we have identified the strong influence that the first review exerts on the valence and volume of a product's entire WOM. In this section, we examine the robustness of these findings by considering different observation windows, alternative explanations (unobserved product characteristics and the display effect), an alternative empirical model (simultaneous estimation), other contexts (a different category and a different pair of platforms), and alternative assumptions (temporal price variation and a platform-specific first-review effect). Our results show that the firstreview effects remain robust to all these considerations and, thus, are truly robust findings. In what follows, we discuss the motivation, the method, and results for each of these analyses.</p><p>3.6.1. Observation Windows. In our main analysis, we use an unbalanced panel data set with a one-year observation window. We choose one year to balance between two objectives: minimizing heterogeneity in duration and minimizing the loss of information. However, it is important to determine how sensitive our results are to this specific choice of observation window. We thus consider two other observation windows (two years and three years) and estimate Equations ( <ref type="formula" target="#formula_16">7</ref>) and ( <ref type="formula" target="#formula_21">9</ref>). Note that as the observation period becomes longer, the percentage of products reaching the end of the observation period decreases, whereas the total number of observations used in the estimation increases. We report the estimation results in column (1) (two-year window) and column (2) (threeyear window) of Table <ref type="table" target="#tab_0">10</ref> (valence study) and Table <ref type="table" target="#tab_0">11</ref> (volume study). The full results are reported in Tables C1 (valence study) and C2 (volume study) in Online Appendix C. In the valence study, we find that the estimates for the main effect of ΔFNegative and its interaction with ln( FDuration) are consistent in both direction and significance with those of our main analysis in both models. Moreover, the period-specific firstreview effect on the valence is negative and significant for all periods. In the volume study, the coefficients for both ΔFNegative and ΔFNegative • FDuration are negative and significant, providing even stronger evidence than the main analysis. Therefore, our results are robust to the length of the observation window. More importantly, by examining the first-review effects with longer observation windows, our analyses provide even stronger evidence for persistence as well as for the snowball effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.2.">Unobserved Product-Platform Specific Effects.</head><p>The first-review effect characterizes the relationship between the valence of the first review and the volume/ valence of the entire review. However, it is possible that this relationship could be partially driven by differences in taste concerning certain unobserved product characteristics between two distinct consumer populations on the two platforms. If such unobserved product-platform specific effects exist  <ref type="bibr">Xie: The Fateful First Consumer Review Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</ref> but are omitted from the estimation, our estimate for ΔFNegative will be biased, and in extreme cases, the estimated first-review effect may merely reflect a spurious correlation. We investigate this issue through three different analyses. These analyses show that product-platform specific effects are unlikely to exist, and that even if they did, the first-review effect would survive such effects. First, from our data, we do not find evidence that consumer tastes are different across the two platforms. In particular, we examine the average rating as one indication of the underlying preference and the number of reviews as a proxy of the popularity. In this analysis, we obtain these two preference measures across product groups defined by distinct characteristics (e.g., product types and product features) in two platforms and calculate the correlation of these measures across the two platforms. We find that the correlation between the average ratings of the two platforms is high (0.982 across types and 0.568 across features), and so is the correlation between the numbers of reviews (0.855 across types and 0.773 across features). This suggests that there is hardly any systematic difference in the preference for certain product characteristics between the two platforms' consumers.</p><p>Second, recall that unobserved product-platform specific effects would bias our results only to the extent that ΔFNegative correlates with these unobserved effects. In other words, to the extent we believe that ΔFNegative had been selected on the unobserved product-platform specific effects, our estimate of ΔFNegative will be biased. We thus examine whether such a belief is well grounded. Specifically, we build on the result of <ref type="bibr" target="#b1">Altonji et al. (2005)</ref>, who have proved that under mild conditions, "selection on the unobservables is the same as selection on the observables." 13 Thus, if ΔFNegative is not selected on observed controls, ΔFNegative will not be selected on the unobserved product-platform specific effects. To examine the potential selection of ΔFNegative on observed control variables, we estimate Equations ( <ref type="formula" target="#formula_16">7</ref>) and ( <ref type="formula" target="#formula_21">9</ref>), excluding all control variables, and then compare the estimates with those from the model with controls, that is, our original estimates in Tables <ref type="table" target="#tab_5">6 and 9</ref> (for other applications of the no-control specification for concerns regarding selection on unobservables, see <ref type="bibr" target="#b9">Cameron and Taber 2004</ref><ref type="bibr" target="#b1">, Altonji et al. 2005</ref><ref type="bibr" target="#b32">, Mayzlin et al. 2014</ref>. We report the estimation results from the no-control specification in column (3) of Tables <ref type="table" target="#tab_0">10  and 11</ref>. When we compare these results with those in Tables <ref type="table" target="#tab_5">6 and 9</ref>, we observe that the coefficients for the first review remain fairly stable with or without the inclusion of covariates. This result implies that ΔFNegative is less likely to be selected on observables and, thus, on unobservables as well. Hence, our findings on the first-review effect are unlikely to be driven by the unobserved product-platform specific effects.</p><p>Finally, we find consistent results regarding the firstreview effect on the WOM volume, even after eliminating any potential unobserved product-platform  <ref type="bibr">, , vol. 40, no. 3, pp. 481-507, © 2021</ref> specific effects. In the presence of the productplatform fixed effects (γ j i ), the Equation ( <ref type="formula" target="#formula_20">8</ref>) can be rewritten as follows:</p><formula xml:id="formula_22">NR j it β j 0 + β 1 FNegative j i + β j 2 FDuration it−2 + β 3 FNegative j i × FDuration it−2 + X j it Γ j + µ i + γ j i + ε j it .<label>(10)</label></formula><p>The first-differencing of Equation ( <ref type="formula" target="#formula_22">10</ref>) across the two platforms yields the following:</p><formula xml:id="formula_23">ΔÑR it β 0 + β 1 ΔFNegative i + β 2 FDuration it−2 + β 3 ΔFNegative i × FDuration it−2 + Γ A X A it − Γ B X B it + γ A i − γ B i + ε it .<label>(11)</label></formula><p>In Equation ( <ref type="formula" target="#formula_23">11</ref>), the product-level fixed effects (µ i ) is differenced out, yet the product-platform fixed effects (γ A i − γ B i ) is not. Furthermore, we can remove the latter by using the second-differencing approach in which we take the difference of Equation ( <ref type="formula" target="#formula_23">11</ref>) across time (for a similar approach, see <ref type="bibr" target="#b12">Chevalier and Mayzlin 2006)</ref>. In this case, even if the product-platform specific effects indeed exist, they will be eliminated, and the estimation will be free of the bias. The resulting estimation equation is given as</p><formula xml:id="formula_24">ΔNR it − ΔÑR it−1 β 2 + β 3 ΔFNegative i + Γ A ΔX A it − Γ B ΔX B it + u it , (<label>1 2 )</label></formula><p>where</p><formula xml:id="formula_25">ΔX j it ≡ X j it − X j it−1 and u it ε it − ε it−1 .</formula><p>Recall that the coefficient of our primary interest is β 3 , which represents an additional disadvantage from the negative first review in each period. The estimation results are reported in Table <ref type="table" target="#tab_0">12</ref>, which suggests thatβ 3 is negative and highly significant (p &lt; 0.01). This implies that, consistent with the main analysis, the disadvantage from a negative first review increases over time, thus supporting the snowball effect. Therefore, the firstreview effect on the volume survives any potential unobserved product-platform specific effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.3.">Display Effect.</head><p>Recall that our theoretical model suggests that the first review makes a difference in WOM volume because a positive first review induces a higher average rating, which in turn leads to increased sales. However, it is possible that higher sales and more WOM in the case of a positive first review might stem from a greater likelihood that the product receives a first-page listing in search results on the retail platform. To examine whether the first-review effect survives this display effect, we estimate the model of volume with an additional control variable, the first-page dummy, to which we assign a value of one if the product appears on the first page at the time of our data collection and zero otherwise. 14 Clearly, our first-page dummy variable is a static measure and may not be ideal for representing a potentially dynamic display effect. However, our additional analysis confirms that the first-page appearance typically remains stable (see Online Appendix B5). We thus use the first-page dummy variable to account for the display effect in our estimation. We report the results in column ( <ref type="formula" target="#formula_11">4</ref>) of Table <ref type="table" target="#tab_0">11</ref>. The full results are reported in column (4) of Table <ref type="table" target="#tab_1">C2</ref> in Online Appendix C. From this analysis, we first find that the first-page display effect indeed has a significant impact on the number of reviews both on Amazon and Best Buy. More importantly, however, even after controlling for the display effect, we still find a significant and increasing first-review effect on WOM volume. Therefore, the first-review effect on WOM volume is robust to the presence of the display effect. 15 3.6.4. Simultaneity Between Valence and Volume. Our theoretical analysis suggests that the valence and the volume of online WOM influence each other in their evolution. Thus, our empirical study controls for the effect of the two variables on each other by including first-review-independent volume and valence respectively. However, the question remains whether the potential simultaneity between the two variables might bias the estimated first-review effects. Although we do not find evidence that such simultaneity bias exists in our data (see Online Appendices B6 and B7 for the Hausman test and the robustness checks with alternative sets of volume/valence variables), we also show that the first-review effects remain stable even after explicitly accounting for the interdependency in the coevolving process of the two variables. In particular, we jointly estimate the valence equation and the volume equation on a seemingly unrelated regression framework using feasible generalized least squares <ref type="bibr" target="#b44">(Zellner 1962</ref>; for a similar application, see also <ref type="bibr" target="#b20">Godes and Mayzlin 2004)</ref>. The estimation results are presented in Table <ref type="table" target="#tab_0">13</ref>. The full results are reported in Table <ref type="table" target="#tab_2">C3</ref> in Online Appendix C. The table shows that coefficients of our interests are almost identical and significant, suggesting that the first-review effects are robust to the possibility of simultaneity bias.</p><p>3.6.5. Different Product Category. The empirical context for our main analysis is the market for vacuum cleaners. To strengthen the external validity of our results, we also examine the first-review effect using data from a different product category. We specifically choose toasters, because toasters and vacuum cleaners share characteristics typical of a product category that is sensitive to online WOM, such as private consumption, durability, and infrequent trials <ref type="bibr" target="#b43">(You et al. 2015)</ref>. As in our main study, we collect reviews and product information for all available toasters with at least one review on both Amazon and Best Buy, posted as of December 22, 2016. This results in a total of 113 products, among which 40.7% received inconsistent first reviews across the two platforms. We report summary statistics of this sample in Online Appendix B8. By using the toaster data, we estimate Equations ( <ref type="formula" target="#formula_16">7</ref>) and ( <ref type="formula" target="#formula_21">9</ref>) with observation windows of one, two, and three years. We use the same set of control variables as in the vacuum cleaner study, except for the product feature and the brand search volume on Google (which is either unavailable or too sparse to use). For the product type, we use the toaster dummy, which  separates out the toaster type (1) from the oven type (0). We report the estimation results in Table <ref type="table" target="#tab_0">14</ref> (valence study) and Table <ref type="table" target="#tab_0">15</ref> (volume study). The full results are reported in Tables C4 (valence study) and C5 (volume study) in Online Appendix C. These tables show that across all three observation windows, in the valence model,β 1 is negative and significant,β 3 is positive and significant, but the predicted firstreview effect (i.e.,β 1 + ln(t) •β 3 ) is negative and significant for all t 1, . . ., 12; in the volume model, botĥ β 1 andβ 3 are negative and significant. These results suggest that all of our predictions, A1-A4, are supported even in the toaster category. Therefore, our findings concerning the first-review effect are robust to the choice of product category.</p><p>3.6.6. Different Platforms. In our main analysis, we compare reviews of the same products sold on both Amazon and Best Buy. To examine whether our findings are specific to this choice of platforms or can be generalized, we repeat our analysis on a different pair of platforms: Amazon U.S. and Amazon Canada. <ref type="bibr">16</ref> By using this pair, we can also reduce the concern for unobserved product-platform specific effects (as discussed in Section 3.6.2). This is because the taste difference between their consumer populations, if such exists, is of a different type than that of the Amazon-Best Buy pairing, and thus, if the firstreview effect is also confirmed in this case, it is unlikely to be driven by unobserved product-platform specific effects. In this study, we also use the vacuum cleaner category and collect both reviews and product information that were available as of February 8, 2017. As before, we include in our sample all products with at least one review on both platforms, resulting in a total of 174 products. Of these, 29.9% received a first review of differing valence on each of the two platforms. We report summary statistics in Online Appendix B8.</p><p>Based on these data, we estimate Equations ( <ref type="formula" target="#formula_16">7</ref>) and ( <ref type="formula" target="#formula_21">9</ref>) using the same set of controls as in the Amazon-Best Buy study. Note that we convert the prices in Amazon Canada into U.S. dollars based on contemporaneous exchange rates. We also use one year as our observation window, because only a limited number of products reach the end of the second year. We report the estimation results in the first columns of Table <ref type="table" target="#tab_0">16</ref> (valence study), and Table <ref type="table" target="#tab_0">17</ref> (volume study). The full results are reported in column (1) of Tables C6 (valence study) and C7 (volume study) in Online Appendix C. We obtain qualitatively the same results in this study: in the valence study,β 1 −1.825 (p &lt; 0.01), β 3 0.434 (p &lt; 0.01), andβ 1 + ln(t) •β 3 &lt;0, ∀t 1, ..., 12, (p &lt; 0.01); in the volume study,β 1 0.049 (p 0.054) andβ 3 −0.050 (p &lt; 0.01), but the predicted firstreview effects (i.e.,β 1 +β 3 • FDuration it−2 ) are negative and significant in all periods other than the second and third periods, probably because of low volume in early periods. <ref type="bibr">17</ref> Therefore, all of our predictions, A1-A4, are supported on this alternative pair of platforms, and, thus, our findings regarding the first-review effect are robust to platform choice.</p><p>3.6.7. Temporal Price Variation. In our main study, we use static price data as one of the control variables. Although previous literature has taken the same approach (e.g., <ref type="bibr">Hitt 2008, Godes and</ref><ref type="bibr" target="#b21">Silva 2012)</ref>, it is based on an implicit assumption that prices do not change over time, or that at least temporal price variations are not contemporaneously correlated with both independent and dependent variables. Although we do not believe that this assumption distorts our results, 18 it is still useful to relax the assumption and confirm the first-review effect while using dynamic prices as a control. To conduct this analysis,  <ref type="bibr">Xie: The Fateful First Consumer Review Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</ref> we collect the historical price data for both Amazon U.S. and Amazon Canada from the website Keepa.com and merge them with the review data collected for the analysis in Section 3.6.6. However, Keepa.com has only been in service since 2014, and, thus, if a product's first review was posted prior to that date, price data are not available. Hence, in our analysis, we include only 56 products for which we could match the price history data with our review data from both Amazon U.S. and Amazon Canada. In this sample, 32.1% of the products received inconsistent first reviews across the two platforms. Using this data set, we estimate Equations ( <ref type="formula" target="#formula_16">7</ref>) and ( <ref type="formula" target="#formula_21">9</ref>) with the same set of control variables as used in the previous section (other than prices), based on the oneyear observation window. We report the estimation results in the second columns of Table <ref type="table" target="#tab_0">16</ref> (valence study) and Table <ref type="table" target="#tab_0">17</ref> (volume study). The full results are reported in column (2) of Tables C6 (valence study) and C7 (volume study) in Online Appendix C. As can be easily seen, the signs of the coefficients of our interests are consistent with our theoretical predictions, and we find supports for all the predictions, A1-A4. Therefore, the first-review effect holds regard-less of the assumption on temporal price variation.</p><p>3.6.8. Platform-Specific First-Review Effects. Recall that we base our identification of the first-review effect on the comparison of reviews for the same products with inconsistent first reviews across the two platforms. To implement this identification strategy, we have considered common coefficients for ΔFNegative and its interaction with FDuration on the two platforms. In doing so, we implicitly assume that the magnitude of the first-review effect is identical across the two platforms. However, it is possible that the first-review effect could be different across platforms. Hence, we examine the sensitivity of our results to the assumption of identical versus platform-specific firstreview effects.</p><p>For this purpose, we replace β 1 and β 3 in Equations ( <ref type="formula" target="#formula_14">6</ref>) and ( <ref type="formula" target="#formula_20">8</ref>) with platform-specific parameters β j 1 and β j 3 and estimate the following equations:</p><formula xml:id="formula_26">ΔAR it β 0 + β A 1 FNegative A i − β B 1 FNegative B i + β 2 ln( FDuration it ) + β A 3 FNegative A i × ln( FDuration it ) − β B 3 FNegative B i × ln( FDuration it ) + X A it Γ A − X B it Γ B + ε it ,<label>(13)</label></formula><formula xml:id="formula_27">ΔÑR it β 0 + β A 1 FNegative A i − β B 1 FNegative B i + β 2 FDuration it + β A 3 FNegative A i × FDuration it − β B 3 FNegative B i × FDuration it + X A it Γ A − X B it Γ B + ε it . (<label>14</label></formula><formula xml:id="formula_28">)</formula><p>This model uses a different identification strategy: identification of β j 1 and β j 3 now derives from crossproduct variation within a platform, rather than from cross-platform variation of given products. Note that the product-specific effects are still controlled for, but do not appear in the above estimation equations because they are differenced out. We report the estimation results in column (5) of Tables <ref type="table" target="#tab_0">10 and 11</ref>.   <ref type="bibr">Xie: The Fateful First Consumer Review Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</ref> The full results are reported in column (5) of Tables <ref type="table" target="#tab_0">C1  and C2</ref> in Online Appendix C. As shown in these tables, we can replicate our results with platformspecific first-review parameters. In particular, in the valence study, the signs of all the relevant first-review effect parameters for both platforms are consistent with our predictions and significant. Moreover, the predicted first-review effect based on these estimates is negative and significant in all periods and on both platforms. In the volume study, all of the first-review effect coefficients are negative and statistically significant except the estimated coefficient of</p><formula xml:id="formula_29">FNegative B i (β B 1</formula><p>), which is insignificant. Here, the predicted firstreview effect is negative and significant in all periods on Amazon and after the second period on Best Buy. Therefore, we can confirm across all studies that the first review has a significant influence on both the valence and volume of online WOM, regardless of whether it is common or distinct across different platforms.</p><p>Finally, one may wonder whether the first-review effects are indeed different across platforms. To answer this question, we compare the estimates of the first-review effect parameters for each pair of platforms used in all of our analysis. First, we find that the first-review effect on the valence is greater on Best Buy than on Amazon. This is probably because any bias in the first review is more easily corrected on Amazon because of its large volume of reviews. Second, the first-review effect on WOM volume is larger on Amazon than on Best Buy. This might be due to a larger customer base on Amazon, which amplifies the sales increase more after a positive first review (versus a negative first review).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Extension</head><p>So far, we have theoretically uncovered the interdependence of online review valence and volume in their evolution, from which we derived four testable predictions on how an advantage in the first review translates to long-lasting advantages in the valence and even increasing advantages in the volume of later periods. All of these predictions were strongly supported by the data collected on the vacuum cleaner category from Amazon and Best Buy. We also have shown that our empirical findings are robust to a different category or a different platform. This strong empirical support may motivate one to wonder whether the magnitude of the first-review effect would differ across different product categories and, if so, what could moderate the magnitude.</p><p>In answering these questions, we note that, in reality, consumers make purchase decisions based not only on online consumer reviews but also other nonreview information such as offline WOM, firminitiated communications, or observation of other consumers' usage. Although our theoretical model as well as the empirical context (i.e., the vacuum cleaner category) focus on the categories where online WOM plays a dominant role in consumers' decisions, as the influence of nonreview information increases, the first-review effect may become weaker. We thus extend our (theoretical and empirical) analyses to cases where consumers' purchase decisions are influenced by both review and nonreview information and examine the impact of nonreview information on the strength of the first-review effect.</p><p>Recall that our theoretical model assumes that consumers form quality perception from reviews with some noise (minus the disutility from the taste mismatch). Assuming that nonreview information is overall unbiased, consumers' valuation can be revised as</p><formula xml:id="formula_30">v t v 0 + β[(1 − γ) • r t−1 + γ • α] − τ • x,</formula><p>where γ ∈[0,1] measures their relative reliance on nonreview information. Note that this formulation includes our main model as a special case (with γ 0). On numerically analyzing this general model (with the details deferred to Online Appendix A2), we obtain the following results.</p><p>Result 1 (Impact of Nonreview Information). As consumers rely more on the nonreview information, (a) the first-review effect on the volume becomes weaker, (b) the first-review effect on the valence can get either stronger or weaker.</p><p>To understand these results, first note that as consumers rely more on the nonreview information, the impact of the first review on the consumers' valuation in later periods will become smaller. This, in turn, decreases the impact of the first review on the future  sales, eventually leading to a weaker first-review effect on the number of reviews. Therefore, in a category with a weaker WOM influence, the first review has much weaker impact on the future WOM volume. This explains our first finding, that is, part (a) of Result 1. However, the same does not hold for the first-review effect on the WOM valence. The finding in part (b), though less intuitive, is the consequence of part (a). To see this, note that the weaker first-review effect on the volume implies that greater dependence on nonreview information decreases the number of newly posted reviews when the first review is positive, but increases it when the first review is negative. Thus, as the influence of nonreview information increases, a positive bias in the first review is less likely to be corrected in future ratings, but a negative bias is more likely to be corrected. Overall, the persistence of the bias of the first review in the future valence could be either stronger or weaker depending on the relative size of the above two effects. Therefore, even in a category with weaker online WOM effect, the firstreview effect on the valence may be either stronger or weaker. These two distinct theoretical predictions warrant empirical validation. According to a recent metaanalysis <ref type="bibr" target="#b43">(You et al. 2015)</ref>, online WOM is likely to have a strong influence on product sales in categories of privately consumed and infrequently purchased durable goods such as vacuum cleaners. This metaanalysis result suggests that in a category where a product is publicly consumed and, hence, other consumers' adoptions are easily observed, product sales are less likely to be affected by the online WOM <ref type="bibr" target="#b43">(You et al. 2015)</ref>. In such a category, consumers are more likely to use the nonreview information. We identify digital cameras as one category that would serve as a good example of such a category. <ref type="bibr">19</ref> We thus examine the first-review effect in the digital camera category by collecting both product and review data from Amazon U.S. and Amazon Canada. We obtain 190 cameras in our data set after matching the products with at least a single review from the two platforms and report the summary statistics in Online Appendix B8. Based on this data set, we estimate Equations ( <ref type="formula" target="#formula_16">7</ref>) and ( <ref type="formula" target="#formula_21">9</ref>) and report the results in Tables <ref type="table" target="#tab_0">18 and 19</ref>. We report full results in Tables <ref type="table" target="#tab_7">C8 and C9</ref> in Online Appendix C.</p><p>Although our theory is agnostic about the magnitude of the first-review effect on the valence of WOM in this category, we continue to find strong evidence for it. According to Table <ref type="table" target="#tab_0">18</ref>, the estimate for ΔFNegative(β 1 ) is negative and significant ( p &lt; 0.01), and the estimate for ΔFNegative × ln( FDuration)(β 3 ) is positive and statistically significant (p &lt; 0.01). The predicted first-review effect in each period (β 1 + ln(t) •β 3 ) is also negative and significant ( p &lt; 0.01).</p><p>We also find the support for the first-review effect on the WOM volume. Table <ref type="table" target="#tab_0">19</ref> shows that the coefficient for ΔFNegative is not significant, whereas the estimated coefficient for ΔFNegative × FDuration(β 3 ) is negative and significant (p &lt; 0.01). To compare the magnitude of the first-review effect on WOM volume between vacuum cleaners and digital cameras, we jointly estimate the product-category-specific firstreview effects by pooling the data of the two categories. We find no evidence of significant difference in the effect between two categories from period 2 to period 6. However, the effect becomes significantly greater for vacuum cleaners than for digital cameras from period 7 to period 12 (p &lt; 0.01). This result is consistent with the above theoretical predictions. In sum, our investigation shows that the relative strength of the first-review effect varies across the product category, depending on the level of consumers' reliance on nonreview information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>Two key metrics of WOM, valence and volume, have been independently found to influence the sales of a product <ref type="bibr" target="#b18">(Floyd et al. 2014</ref><ref type="bibr" target="#b43">, You et al. 2015</ref><ref type="bibr" target="#b5">, Babić Rosario et al. 2016</ref>. The central question of this paper is whether these two metrics are interrelated and, if so, what implications this interdependence might have for the management of online consumer reviews. Our theoretical model of consumer purchase decisions and the review updating process establishes the interdependence of valence and volume of online consumer reviews, which leads us to derive the powerful impact of the first consumer review. Specific predictions of the first-review effect are empirically validated. We summarize the main findings of the paper as follows:</p><p>• The valence and volume of online consumer reviews influence each other in their evolution paths, as a consequence of the conditional availability of online reviews.</p><p>• The valence of the first review positively affects the valence of the entire set of reviews. Although this effect may decrease over the long term, it is persistently observed for an extended time period, even 36 months after the first review posting.</p><p>• The valence of the first review also positively affects the overall volume of reviews. Because of the positive feedback loop between sales and WOM volume, this effect grows stronger over time, engendering strong path dependence for online consumer reviews.</p><p>The results of our study have important theoretical and practical implications. First, our findings bring to the fore the significance of a single review. Specifically, we demonstrate both theoretically and empirically that a product's first consumer review powerfully influences the entire evolution path of online <ref type="bibr">Xie: The Fateful First Consumer Review Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</ref> consumer reviews for that product and, thus, potentially determines its fate. In particular, when the first review is negative, the commanding first-review effect could curb the chances of the product's market success, thus significantly hurting the seller. Our research findings increase awareness of this important first-review effect while also highlighting the need for scholars and practitioners to develop effective preemptive strategies to reduce the chances of a product receiving a negative first review, as well as management strategies that can soften the impact of a negative first review after the fact. For example, a review platform may want to set up a policy where it suppresses reviews until the product receives a certain number of reviews so that consumers may see the reviews when the overall reviews reflect the true quality of the product.</p><p>Second, our work brings attention to a potential weakness of online consumer reviews. Our results suggest that a negative first review dramatically reduces the overall number of reviews. Thus, with a negative first review, the body of consumer reviews for that product may become less informative, either because any biased information in consumer reviews remains uncorrected or because consumers may even lose the opportunity to learn about the product at all. This finding implies that consumer reviews could become less reliable as a source of information and as a communication channel, depending on the valence of the first review. In today's market, businesses are increasingly shifting their attention and investment from firmto user-generated information. Our research points to the need to integrate these two types of information into an effective overall communication strategy.</p><p>Third, our results on the asymmetric influence of the positive and negative first reviews also have interesting implications for promotional review policies. Recent empirical studies find evidence that firms have a high incentive to post positive reviews of their own products but negative reviews for those of their competitors <ref type="bibr">(Mayzlin et al. 2014, Luca and</ref><ref type="bibr" target="#b30">Zervas 2016)</ref>. Our findings suggest that promotional reviews, if posted as the first review, are very influential. Although such reviews may be created unethically, they actually help to facilitate informative online WOM if they promote the firms' own products, because a positive first review leads to high WOM volume. In this case, any upward bias in the initial promotional review would be corrected as more genuine consumer reviews were posted. However, posting such reviews first with the objective of harming a competitor can severely damage online WOM, because an unfavorable first review reduces sales and, thus, the number of subsequent reviews. Consequently, the initial downward bias derived from a negative promotional review is less likely to be corrected, and the online WOM may fail to offer sufficient product information, which could severely harm the viability of the product being reviewed. Hence, it is important to consider such asymmetry when an online retail platform develops its review management policy, especially its policy regarding promotional reviews.</p><p>Our paper makes unique contributions to the literature on review dynamics. Thus far, the literature has focused on the individual reviewer's motivation and its impact on the evolution of the review valence (e.g., <ref type="bibr" target="#b26">Li and Hitt 2008</ref><ref type="bibr" target="#b42">, Wu and Huberman 2008</ref><ref type="bibr" target="#b21">, Godes and Silva 2012</ref><ref type="bibr" target="#b33">, Moe and Schweidel 2012</ref>. By contrast, we examine the dynamics of both valence and volume and, more importantly, consider their evolution jointly. This approach allows us to uncover the path dependence of both valence and volume from the very first review, which cannot be explained by considering the evolution of the valence independently from that of the volume. Our most novel finding, the increasing impact of the first review on WOM volume, can be explained by the conditional availability of the reviews as modeled in our paper, but not by individual reviewer motivation, as suggested in the literature.</p><p>Finally, this paper is not without limitations, which also point to a few interesting avenues for future research. First, our study focuses on the valence of the first review. However, other characteristics of the first review, such as the timing of the review or the reviewer's reputation, might significantly influence future reviews. This suggests an interesting avenue for future research. Second, our model abstracts away from firms' strategic decisions to influence reviews, given our objective of establishing a first-review effect. Future research might investigate the impact of a firm's actions concerning its own profits, consumer surplus, and the review-generation process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix. Proofs</head><p>Derivation of the Expected Utility of the Consumer (EU t ) First, note that E[U] E[1 − e −(v0+βrt−1 −τx−p) ]</p><p>1 − e −(v0 −τx−p) E[e −βrt−1 ], where r t−1 is a sample mean of random variable w i (i 1, 2, . . ., n t−1 ), and thus asymptotically follows N ( α, α(1−α)</p><p>nt−1 ) by the central limit theorem. However, because consumers do not observe α, in deriving the expected utility, they use r t−1 and rt−1(1−rt−1) nt−1 , respectively, as estimators of α and α(1−α) nt−1 . Then, in the perspective of consumers, e −βrt−1 follows a lognormal distribution LN ( − βr t−1 , β 2 rt−1(1−rt−1) nt− <ref type="formula" target="#formula_24">1</ref>) , <ref type="bibr">Xie: The Fateful First Consumer Review Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</ref> implying E[e −βrt−1 ] e −βrt−1+ β 2 r t−1 (1−r t−1 ) 2n t−1</p><p>. Therefore, we have</p><formula xml:id="formula_31">E[U t ] 1 − e − ( v0+βrt−1 −τx−p− β 2 r t−1 (1−r t−1 ) 2n t−1</formula><p>) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Derivation of the Sales (s t )</head><p>A customer purchases the product if and only if</p><formula xml:id="formula_32">E[U t ] 1 − e − ( v0+βrt−1 −τx−p− β 2 r t−1 (1−r t−1 ) 2n t−1 ) ≥ 0, which is equivalent to x ≤ 1 τ ( v 0 + βr t−1 − p − β 2 rt−1(1−rt−1) 2nt−1 )</formula><p>. Because x~U[0,1], in each period, among M consumers arriving in the market,</p><formula xml:id="formula_33">M × 1 τ ( v 0 + βr t−1 − p − β 2 rt−1(1−rt−1)</formula><p>2nt− <ref type="formula" target="#formula_24">1</ref>) consumers will buy the product. Therefore, the total sales in period t is given as s t M τ</p><formula xml:id="formula_34">( v 0 + βr t−1 − p − β 2 rt−1(1−rt−1) 2nt−1</formula><p>) . )</p><p>. Thus, by the chain rule, <ref type="bibr">∂E[nt+1 |nt, rt]</ref> ∂rt</p><formula xml:id="formula_35">∂E[nt+1 |nt, rt] ∂E[st+1 |nt, rt] ∂E[st+1 |nt, rt] ∂rt δM τ ( β − β 2 (1−2rt)<label>2nt</label></formula><p>) . Then, <ref type="bibr">∂E[nt+1 |nt, rt]</ref> ∂rt ≥ 0 is equivalent to 2n t ≥ β(1 − 2r t ), which always holds because n t ≥ 1, r t ≥ 0, and β ≤ 2. Note that the equality holds when n t 1, r t 0, and β 2, which can happen only at t 0, which is the period of the very first review. Therefore, for any t ≥ 1, we have <ref type="bibr">∂E[nt+1 |nt, rt]</ref> ∂rt &gt; 0.</p><p>Part (b). Recall that N t+1 denotes the volume of the newly posted reviews: N t+1 ≡ n t+1 − n t . By definition, we have .</p><p>Then we have</p><formula xml:id="formula_36">E[r t+1 |n t , r t ] E [ r t • ( 1 − N t+1 n t + N t+1 ) + H t+1 n t + N t+1 ⃒ ⃒ ⃒ ⃒ n t , r t ] r t • ( 1 − E [ N t+1 n t + N t+1 ⃒ ⃒ ⃒ ⃒ n t , r t ]) + E [ H t+1 n t + N t+1 ⃒ ⃒ ⃒ ⃒ n t , r t ] r t • ( 1 − E [ N t+1 n t + N t+1 ⃒ ⃒ ⃒ ⃒ n t , r t ]) + α • E [ N t+1 n t + N t+1 ⃒ ⃒ ⃒ ⃒ n t , r t ] r t + (α − r t ) • E [ N t+1 n t + N t+1 ⃒ ⃒ ⃒ ⃒ n t , r t ] Therefore, ∂E[rt+1 |nt, rt] ∂Nt+1 (α − r t ) • E [ ∂ ∂Nt+1 ( Nt+1 nt+Nt+1 )⃒ ⃒ ⃒ ⃒ n t , r t ] (α − r t ) • E [ nt (nt+Nt+1) 2 ⃒ ⃒ ⃒ ⃒ n t , r t ]</formula><p>&gt; 0 if and only if α &gt; r t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Endnotes</head><p>1 For brevity, we will refer to these online platforms as "Amazon" and "Walmart," respectively, from this point on. <ref type="bibr">2</ref> In the examples given in Table <ref type="table" target="#tab_0">1</ref>, their cross-platform (dis)advantage in WOM valence and volume are also associated with their crossplatform (dis)advantage in the first-review rating.</p><p>3 In this formulation, r t is a sample mean of random variable w i (i 1,2, . . ., n t ), and thus asymptotically follows N(α, α(1 − α)/n t ) by the central limit theorem, which implies that products with more extreme qualities have lower variance in their average ratings. <ref type="bibr">4</ref> We use an exogenous price in our model, because we do not find empirical evidence that sellers react to user reviews by adjusting their prices (see Online Appendix B1 for this empirical analysis).</p><p>5 Although prior research finds that the most and the least satisfied consumers are more likely to engage in WOM <ref type="bibr">(Anderson 1998, West and</ref><ref type="bibr" target="#b41">Broniarczyk 1998)</ref>, for simplicity, we use the constant propensity to write a review. <ref type="bibr">6</ref> We acknowledge that some reviews might be written without purchase of the products <ref type="bibr" target="#b3">(Anderson and Simester 2014)</ref>. However, the presence of reviews without purchase does not change the impact of the current valence on the future volume. 7 Even without the log transformation, we could obtain qualitatively same results, although the current model with the log transformation fits better with the data. 8 Among these controls, the product type dummies are indicator variables for vacuum cleaner types as classified by Amazon: canister, handheld, robotic, stick, or upright. For identification, we include only four indicators, while setting the canister type as the baseline type. As the product feature indicators, we include two dummies: one for bagged vacuum cleaners and another for corded vacuum cleaners. These are coded as one if the product has the feature and as zero otherwise. Last, all the control variables in X it other than consumer search volume and the volume are time invariant. <ref type="bibr">9</ref> One might view the first-review effect on the valence as consisting of the direct effect and the indirect effect, with the latter being the effect through the volume. Our first-review-independent volume variable controls the influence of the volume on the valence but still allows us to capture the full effect of the first review. 10 Within our data frame, the eventual convergence of the average rating is not observed. However, our model predicts it could happen outside of our data period. Although the linear model could even predict the reversal of the first-review effect, this is simply due to extrapolation and the limitation of the model. 11 This follows our theoretical mechanism presented in Section 2.2, which states that the lagged valence and the lagged volume influence the current volume. Note that Online Appendix B4 provides empirical support for this mechanism.</p><p>12 Note that standardization is not necessary for the valence model in Equations ( <ref type="formula" target="#formula_14">6</ref>) and ( <ref type="formula" target="#formula_16">7</ref>) because the variation in the average ratings is fairly comparable between the two platforms (as noted in Table <ref type="table" target="#tab_2">3</ref>). <ref type="bibr">13</ref> The conditions are that (1) the observed control variables are randomly chosen among all possible controls and (2) the number of observed and unobserved variables are large and none of the factors dominates the distribution of the main variable (i.e., FNegative or the outcome variable (i.e., valence and volume). 14 In constructing this variable, we use product type as a search criterion because this is the first filter that the retailers provide saliently on both Amazon and Best Buy. The small assortment size of product types on Best Buy makes it unnecessary to use multiple search criteria. <ref type="bibr">15</ref> For completeness, we also estimate the valence model with the inclusion of the first-page dummy. We obtain qualitatively the same results (see column (4) of Table <ref type="table" target="#tab_0">10</ref>). 16 Amazon U.S. and Amazon Canada have totally independent websites with separate consumer reviews even for identical products sold on both platforms. In January 2017, however, Amazon Canada <ref type="bibr">Xie: The Fateful First Consumer Review Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</ref> started providing their customers with a link to Amazon U.S. product reviews. Hence, in our analysis, we only use product reviews posted before January 1, 2017. <ref type="bibr">17</ref> The positive and marginally significant β 1 is probably due to the functional form of Equation ( <ref type="formula" target="#formula_21">9</ref>). Once we estimate the period-specific first-review effects, the coefficient for the second period becomes insignificant, and the coefficients for the rest of periods are negative and significant. <ref type="bibr">18</ref> The results of the no-control specifications (see Section 3.6.2) suggest that the estimates of our primary interests are robust to the inclusion or exclusion of price. Moreover, using daily price data from both Amazon and Best Buy, we find that firms do not change their prices in response to newly posted product reviews (see Online Appendix B1 for details of this analysis). <ref type="bibr">19</ref> We conduct an additional analysis to confirm that product sales are affected by the online WOM more in the vacuum cleaner category than in the digital camera category (see Online Appendix B9 for details).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. (Color online) Evolution of the Valence (Left) and the Volume (Right) by the First Review Valence</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>ΔFNegative × I( FDuration 1) −1.259*** 0.222 ΔFNegative × I( FDuration 2) −1.042*** 0.194 −0.014 0.023 ΔFNegative × I( FDuration 3) −0.917*** 0.192 −0.072*** 0.021 ΔFNegative × I( FDuration 4) −0.840*** 0.203 −0.127*** 0.016 ΔFNegative × I( FDuration 5) −0.638*** 0.178 −0.190*** 0.019 ΔFNegative × I( FDuration 6) −0.535*** 0.184 −0.235*** 0.017 ΔFNegative × I( FDuration 7) −0.500*** 0.177 −0.294*** 0.019 ΔFNegative × I( FDuration 8) −0.448** 0.176 −0.341*** 0.024 ΔFNegative × I( FDuration 9) −0.355** 0.152 −0.370*** 0.021 ΔFNegative × I( FDuration 10) −0.338** 0.149 −0.456*** 0.027 ΔFNegative × I( FDuration 11) −0.329** 0.128 −0.509*** 0.028 ΔFNegative × I( FDuration 12) −0.320** 0.132 −0.552*** 0.031 Notes. Standard errors (SEs) are clustered at the product level. The term I( FDuration t) is an indicator that takes a value of one if FDuration is equal to t and zero otherwise. **p &lt; 0.05; ***p &lt; 0.01.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>(Color online) Inconsistency in Online Reviews: Some Examples Note. The products (date when the data were recorded) are as follows: A, Canon Powershot ELPH 115 (June 6, 2014); B, Toastmaster TM-103TR Stainless Steel 4 Slice Toaster Oven (April 16, 2016); C, Sealy Baby Firm Rest Crib Mattress</figDesc><table><row><cell></cell><cell cols="3">Average rating</cell><cell cols="3">Number of reviews</cell><cell></cell><cell>Price</cell><cell></cell></row><row><cell>Product</cell><cell>Amazon</cell><cell></cell><cell cols="2">Walmart Amazon</cell><cell></cell><cell cols="2">Walmart Amazon</cell><cell></cell><cell>Walmart</cell></row><row><cell>A</cell><cell>4.0</cell><cell>&gt;</cell><cell>2.2</cell><cell>303</cell><cell>&gt;</cell><cell>4</cell><cell>79.00</cell><cell>=</cell><cell>79.00</cell></row><row><cell>B</cell><cell>2.5</cell><cell>&lt;</cell><cell>4.0</cell><cell>8</cell><cell>&lt;</cell><cell>81</cell><cell>36.68</cell><cell>&lt;</cell><cell>39.80</cell></row><row><cell>C</cell><cell>4.2</cell><cell>&gt;</cell><cell>3.0</cell><cell>328</cell><cell>&gt;</cell><cell>2</cell><cell>80.99</cell><cell>&lt;</cell><cell>89.99</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Theoretical Predictions A1</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Summary Statistics</figDesc><table><row><cell></cell><cell></cell><cell>Amazon</cell><cell></cell><cell>Best Buy</cell></row><row><cell></cell><cell>Mean</cell><cell cols="3">Standard deviation Mean Standard deviation</cell></row><row><cell>Proportion of negative first reviews</cell><cell>0.254</cell><cell>0.437</cell><cell>0.181</cell><cell>0.386</cell></row><row><cell>Average rating</cell><cell>3.849</cell><cell>0.627</cell><cell>4.070</cell><cell>0.864</cell></row><row><cell>Number of reviews</cell><cell>380.655</cell><cell>673.972</cell><cell>58.226</cell><cell>104.865</cell></row><row><cell>Price</cell><cell>168.014</cell><cell>128.128</cell><cell>184.850</cell><cell>139.899</cell></row><row><cell>Word count in the first review</cell><cell>275.712</cell><cell>346.265</cell><cell>51.345</cell><cell>67.934</cell></row><row><cell cols="2">Number of days since the first review 1,101.175</cell><cell>804.593</cell><cell>778.492</cell><cell>613.688</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Volume and Valence of WOM by the Valence of the First Review Park, Shin, and Xie: The Fateful First Consumer Review Marketing Science,  , vol. 40, no. 3, pp. 481-507, © 2021 </figDesc><table><row><cell>First Review</cell><cell></cell><cell></cell><cell cols="2">Average rating</cell><cell cols="3">Number of reviews</cell><cell></cell></row><row><cell cols="8">Amazon Best Buy Amazon Best Buy Difference Amazon Best Buy Difference</cell><cell>Sample size</cell></row><row><cell>(+)</cell><cell>(−)</cell><cell>3.974</cell><cell>2.835</cell><cell>1.138***</cell><cell>66.143</cell><cell>14.952</cell><cell>51.190**</cell><cell>21</cell></row><row><cell>(−)</cell><cell>(+)</cell><cell>3.046</cell><cell>4.264</cell><cell>−1.218***</cell><cell>41.147</cell><cell>18.970</cell><cell>22.176*</cell><cell>34</cell></row><row><cell>(+)</cell><cell>(+)</cell><cell>4.099</cell><cell>4.386</cell><cell>−0.286***</cell><cell>92.216</cell><cell>35.108</cell><cell>57.108***</cell><cell>111</cell></row><row><cell>(−)</cell><cell>( −)</cell><cell>3.151</cell><cell>2.857</cell><cell>0.293</cell><cell>55.182</cell><cell>17.545</cell><cell>37.636**</cell><cell>11</cell></row><row><cell>All samples</cell><cell></cell><cell>3.823</cell><cell>4.083</cell><cell>−0.260***</cell><cell>77.011</cell><cell>28.525</cell><cell>48.486***</cell><cell>177</cell></row></table><note>Note. This table is based on the paired product-level observations in the last month of each observation window.*p &lt; 0.10; **p &lt; 0.05; ***p &lt; 0.01 (paired t-test).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 5 .</head><label>5</label><figDesc>Wilcoxon Signed-Rank Test</figDesc><table><row><cell></cell><cell cols="3">Ranks for average rating</cell><cell cols="3">Ranks for number of reviews</cell><cell></cell></row><row><cell></cell><cell cols="2">First review</cell><cell></cell><cell cols="2">First review</cell><cell></cell><cell></cell></row><row><cell>Period</cell><cell>(+)</cell><cell>(−)</cell><cell>Difference</cell><cell>(+)</cell><cell>(−)</cell><cell>Difference</cell><cell>Sample size</cell></row><row><cell>One year</cell><cell>60.324</cell><cell>89.081</cell><cell>−28.757***</cell><cell>64.946</cell><cell>74.000</cell><cell>−9.054*</cell><cell>37</cell></row><row><cell>Six months</cell><cell>75.870</cell><cell>113.739</cell><cell>−37.870***</cell><cell>77.174</cell><cell>91.652</cell><cell>−14.478**</cell><cell>46</cell></row><row><cell cols="3">*p &lt; 0.10; **p &lt; 0.05; ***p &lt; 0.01.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note> Xie: The Fateful First Consumer Review   Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS   </note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 6 .</head><label>6</label><figDesc>First-Review Effects on the Valence of WOM</figDesc><table><row><cell></cell><cell></cell><cell>(1)</cell><cell></cell><cell>(2)</cell></row><row><cell></cell><cell>Estimate</cell><cell>Standard error</cell><cell>Estimate</cell><cell>Standard error</cell></row><row><cell>ΔFNegative</cell><cell>−1.314***</cell><cell>0.228</cell><cell>−1.313***</cell><cell>0.225</cell></row><row><cell>ln( FDuration)</cell><cell>−0.122***</cell><cell>0.034</cell><cell>−0.120***</cell><cell>0.035</cell></row><row><cell>ΔFNegative × ln( FDuration)</cell><cell>0.412***</cell><cell>0.079</cell><cell>0.415***</cell><cell>0.077</cell></row><row><cell>ln (Price A )</cell><cell>−0.331</cell><cell>0.311</cell><cell>−0.340</cell><cell>0.310</cell></row><row><cell>ln (Price B )</cell><cell>−0.279</cell><cell>0.330</cell><cell>0.284</cell><cell>0.330</cell></row><row><cell>ln(WC A )</cell><cell>0.107</cell><cell>0.072</cell><cell>0.109</cell><cell>0.072</cell></row><row><cell>ln(WC B )</cell><cell>0.121*</cell><cell>0.066</cell><cell>−0.121*</cell><cell>0.066</cell></row><row><cell>Type handheld</cell><cell>−0.019</cell><cell>0.367</cell><cell>−0.007</cell><cell>0.370</cell></row><row><cell>Type robotic</cell><cell>0.060</cell><cell>0.379</cell><cell>0.068</cell><cell>0.379</cell></row><row><cell>Type stick</cell><cell>−0.097</cell><cell>0.321</cell><cell>−0.094</cell><cell>0.322</cell></row><row><cell>Type upright</cell><cell>−0.044</cell><cell>0.279</cell><cell>−0.046</cell><cell>0.280</cell></row><row><cell>Bagged</cell><cell>−0.335</cell><cell>0.293</cell><cell>−0.327</cell><cell>0.294</cell></row><row><cell>Corded</cell><cell>0.034</cell><cell>0.158</cell><cell>0.044</cell><cell>0.158</cell></row><row><cell>Search product A</cell><cell>−0.007</cell><cell>0.004</cell><cell>−0.013*</cell><cell>0.008</cell></row><row><cell>Search product B</cell><cell>0.007*</cell><cell>0.004</cell><cell>−0.013</cell><cell>0.009</cell></row><row><cell>Search brand A</cell><cell>−0.003</cell><cell>0.006</cell><cell>−0.004</cell><cell>0.007</cell></row><row><cell>Search brand B</cell><cell>−0.008</cell><cell>0.005</cell><cell>0.009*</cell><cell>0.005</cell></row><row><cell>First-review-independent volume A</cell><cell>0.081*</cell><cell>0.041</cell><cell>0.085**</cell><cell>0.042</cell></row><row><cell>First-review-independent volume B</cell><cell>0.015</cell><cell>0.030</cell><cell>−0.015</cell><cell>0.030</cell></row><row><cell>Month fixed effects</cell><cell>No</cell><cell></cell><cell>Yes</cell><cell></cell></row><row><cell>Observations</cell><cell>1,488</cell><cell></cell><cell>1,488</cell><cell></cell></row><row><cell>R 2</cell><cell>0.2390</cell><cell></cell><cell>0.2467</cell><cell></cell></row></table><note>Note. Standard errors are clustered at the product level.*p &lt; 0.10; **p &lt; 0.05; ***p &lt; 0.01.Park, Shin, and Xie: The Fateful First Consumer ReviewMarketingScience, 2021, vol. 40, no. 3, pp. 481-507, © 2021 </note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 8 .</head><label>8</label><figDesc>Period-Specific First-Review Effects    </figDesc><table><row><cell cols="2">Dependent</cell><cell cols="2">Dependent</cell></row><row><cell>variable:</cell><cell></cell><cell>variable:</cell><cell></cell></row><row><cell>Valence</cell><cell></cell><cell>Volume</cell><cell></cell></row><row><cell>Estimate</cell><cell>SE</cell><cell>Estimate</cell><cell>SE</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Park, Shin, and Xie: The Fateful First Consumer Review    </figDesc><table><row><cell>Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 9 .</head><label>9</label><figDesc>First-Review Effects on the Volume of WOM</figDesc><table><row><cell></cell><cell></cell><cell>(1)</cell><cell></cell><cell>(2)</cell></row><row><cell></cell><cell>Estimate</cell><cell>Standard error</cell><cell>Estimate</cell><cell>Standard error</cell></row><row><cell>ΔFNegative</cell><cell>−0.019</cell><cell>0.015</cell><cell>−0.018</cell><cell>0.014</cell></row><row><cell>FDuration</cell><cell>0.065***</cell><cell>0.002</cell><cell>0.065***</cell><cell>0.002</cell></row><row><cell>ΔFNegative × FDuration</cell><cell>−0.054***</cell><cell>0.003</cell><cell>−0.054***</cell><cell>0.003</cell></row><row><cell>ln (Price A )</cell><cell>−0.128***</cell><cell>0.027</cell><cell>−0.129***</cell><cell>0.027</cell></row><row><cell>ln (Price B )</cell><cell>0.206***</cell><cell>0.025</cell><cell>−0.206***</cell><cell>0.025</cell></row><row><cell>ln(WC A )</cell><cell>0.133***</cell><cell>0.008</cell><cell>0.133***</cell><cell>0.008</cell></row><row><cell>ln(WC B )</cell><cell>0.063***</cell><cell>0.010</cell><cell>−0.063***</cell><cell>0.010</cell></row><row><cell>Type handheld</cell><cell>−0.252***</cell><cell>0.032</cell><cell>−0.247***</cell><cell>0.031</cell></row><row><cell>Type robotic</cell><cell>0.702***</cell><cell>0.047</cell><cell>0.704***</cell><cell>0.048</cell></row><row><cell>Type stick</cell><cell>0.243***</cell><cell>0.032</cell><cell>0.242***</cell><cell>0.033</cell></row><row><cell>Type upright</cell><cell>−0.126***</cell><cell>0.021</cell><cell>−0.125***</cell><cell>0.021</cell></row><row><cell>Bagged</cell><cell>−0.116***</cell><cell>0.023</cell><cell>−0.116***</cell><cell>0.023</cell></row><row><cell>Corded</cell><cell>−0.268***</cell><cell>0.027</cell><cell>−0.265***</cell><cell>0.027</cell></row><row><cell>Search product A</cell><cell>−1.62E-03</cell><cell>1.24E-03</cell><cell>−0.003*</cell><cell>0.002</cell></row><row><cell>Search product B</cell><cell>−2.48E-03**</cell><cell>1.06E-03</cell><cell>0.003*</cell><cell>0.002</cell></row><row><cell>Search brand A</cell><cell>0.005***</cell><cell>0.002</cell><cell>0.005***</cell><cell>0.002</cell></row><row><cell>Search brand B</cell><cell>0.013***</cell><cell>0.002</cell><cell>−0.013***</cell><cell>0.002</cell></row><row><cell>Lagged first-review-independent valence A</cell><cell>−0.004</cell><cell>0.009</cell><cell>−0.005</cell><cell>0.009</cell></row><row><cell>Lagged first-review-independent valence B</cell><cell>0.011</cell><cell>0.010</cell><cell>−0.010</cell><cell>0.010</cell></row><row><cell>Lagged first-review-independent volume A</cell><cell>1.169***</cell><cell>0.014</cell><cell>1.170***</cell><cell>0.014</cell></row><row><cell>Lagged first-review-independent volume B</cell><cell>1.097***</cell><cell>0.010</cell><cell>−1.09***</cell><cell>0.010</cell></row><row><cell>Month fixed effects</cell><cell>No</cell><cell></cell><cell>Yes</cell><cell></cell></row><row><cell>Observations</cell><cell>1,648</cell><cell></cell><cell>1,648</cell><cell></cell></row><row><cell>R 2</cell><cell>0.9776</cell><cell></cell><cell>0.9779</cell><cell></cell></row></table><note>Note. Standard errors are clustered at the product level. *p &lt; 0.10; **p &lt; 0.05; ***p &lt; 0.01.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 10 .</head><label>10</label><figDesc>Robustness Check: Valence of WOM</figDesc><table><row><cell></cell><cell>(1)</cell><cell>(2)</cell><cell>(3)</cell><cell>(4)</cell><cell>(5)</cell></row><row><cell></cell><cell>Observation window:</cell><cell>Observation window:</cell><cell>No control</cell><cell>Display</cell><cell>Platform-Specific</cell></row><row><cell></cell><cell>2 years</cell><cell>3 years</cell><cell>specification</cell><cell>effect</cell><cell>first-review effect</cell></row><row><cell>ΔFNegative</cell><cell>−1.418***</cell><cell>−1.475***</cell><cell>−1.309***</cell><cell>−1.325***</cell><cell></cell></row><row><cell></cell><cell>(0.242)</cell><cell>(0.259)</cell><cell>(0.226)</cell><cell>(0.226)</cell><cell></cell></row><row><cell>ln( FDuration)</cell><cell>−0.092***</cell><cell>−0.072**</cell><cell>−0.109***</cell><cell>−0.128***</cell><cell>−0.083**</cell></row><row><cell></cell><cell>(0.034)</cell><cell>(0.036)</cell><cell>(0.031)</cell><cell>(0.035)</cell><cell>(0.033)</cell></row><row><cell>ΔFNegative × ln( FDuration)</cell><cell>0.361***</cell><cell>0.389***</cell><cell>0.408***</cell><cell>0.416***</cell><cell></cell></row><row><cell></cell><cell>(0.080)</cell><cell>(0.086)</cell><cell>(0.077)</cell><cell>(0.078)</cell><cell></cell></row><row><cell>FNegative A</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>−0.979***</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(0.246)</cell></row><row><cell>FNegative B</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>−1.787***</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(0.273)</cell></row><row><cell>FNegative A × ln( FDuration)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.330***</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(0.078)</cell></row><row><cell>FNegative B × ln( FDuration)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.534***</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(0.114)</cell></row><row><cell>Observations</cell><cell>2,528</cell><cell>3,105</cell><cell>1,488</cell><cell>1,488</cell><cell>1,488</cell></row><row><cell>R 2</cell><cell>0.2670</cell><cell>0.2463</cell><cell>0.1636</cell><cell>0.2478</cell><cell>0.2634</cell></row></table><note>Note. Standard errors are clustered at the product level and are reported in the parentheses.*p &lt; 0.10; **p &lt; 0.05; ***p &lt; 0.01.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 11 .</head><label>11</label><figDesc>Robustness Check: Volume of WOM Standard errors are clustered at the product level and are reported in the parentheses.</figDesc><table><row><cell></cell><cell>(1)</cell><cell>(2)</cell><cell>(3)</cell><cell>(4)</cell><cell>(5)</cell></row><row><cell></cell><cell>Observation window:</cell><cell>Observation window:</cell><cell></cell><cell></cell><cell>Platform-Specific</cell></row><row><cell></cell><cell>2 years</cell><cell>3 years</cell><cell>No control specification</cell><cell>Display effect</cell><cell>first-review effect</cell></row><row><cell>ΔFNegative</cell><cell>−0.097***</cell><cell>−0.065***</cell><cell>0.009</cell><cell>−0.018</cell><cell></cell></row><row><cell></cell><cell>(0.014)</cell><cell>(0.014)</cell><cell>(0.043)</cell><cell>(0.014)</cell><cell></cell></row><row><cell>FDuration</cell><cell>0.034***</cell><cell>0.023***</cell><cell>0.059***</cell><cell>0.065***</cell><cell>0.074***</cell></row><row><cell></cell><cell>(0.001)</cell><cell>(0.001)</cell><cell>(0.015)</cell><cell>(0.002)</cell><cell>(0.003)</cell></row><row><cell>ΔFNegative × FDuration</cell><cell>−0.020***</cell><cell>−0.018***</cell><cell>−0.028*</cell><cell>−0.054***</cell><cell></cell></row><row><cell></cell><cell>(0.003)</cell><cell>(0.002)</cell><cell>(0.016)</cell><cell>(0.003)</cell><cell></cell></row><row><cell>FNegative A</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>−0.049**</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(0.021)</cell></row><row><cell>FNegative B</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.007</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(0.023)</cell></row><row><cell>FNegative A × FDuration</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>−0.071***</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(0.003)</cell></row><row><cell>FNegative B × FDuration</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>−0.029***</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(0.004)</cell></row><row><cell>Observations</cell><cell>2,709</cell><cell>3,307</cell><cell>1,648</cell><cell>1,648</cell><cell>1,648</cell></row><row><cell>R 2</cell><cell>0.9808</cell><cell>0.9807</cell><cell>0.0279</cell><cell>0.9783</cell><cell>0.9826</cell></row><row><cell>Note.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>*p &lt; 0.10; **p &lt; 0.05; ***p &lt; 0.01.-Park, Shin, and Xie: The Fateful First Consumer Review Marketing Science</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 12 .</head><label>12</label><figDesc>Second-Differencing Model: Volume of WOM</figDesc><table><row><cell>Estimate</cell><cell>Standard error</cell></row></table><note>Notes. Standard errors are clustered at the product level. First-and second-period observations are dropped in the regression because of the use of lagged proxies and second differencing. **p &lt; 0.05; ***p &lt; 0.01.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 13 .</head><label>13</label><figDesc>Seemingly Unrelated Regression</figDesc><table><row><cell></cell><cell>Valence equation</cell><cell>Volume equation</cell></row><row><cell>ΔFNegative</cell><cell>−1.380***</cell><cell>−0.005</cell></row><row><cell></cell><cell>(0.140)</cell><cell>(0.019)</cell></row><row><cell>ln( FDuration)</cell><cell>−0.139***</cell><cell></cell></row><row><cell></cell><cell>(0.039)</cell><cell></cell></row><row><cell>FDuration</cell><cell></cell><cell>0.074***</cell></row><row><cell></cell><cell></cell><cell>(0.002)</cell></row><row><cell>ΔFNegative × ln( FDuration)</cell><cell>0.444***</cell><cell></cell></row><row><cell></cell><cell>(0.076)</cell><cell></cell></row><row><cell>ΔFNegative × FDuration</cell><cell></cell><cell>−0.065***</cell></row><row><cell></cell><cell></cell><cell>(0.003)</cell></row><row><cell>Observations</cell><cell>1,347</cell><cell>1,347</cell></row><row><cell>R 2</cell><cell>0.2261</cell><cell>0.9764</cell></row><row><cell>*p &lt; 0.10; **p &lt; 0.05; ***p &lt; 0.01.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 14 .</head><label>14</label><figDesc>Toasters: Valence of WOM</figDesc><table><row><cell cols="2">Park, Shin, and Xie: The Fateful First Consumer Review</cell><cell></cell><cell></cell></row><row><cell cols="2">Marketing Science, 2021, vol. 40, no. 3, pp. 481-507, © 2021 INFORMS</cell><cell></cell><cell></cell></row><row><cell></cell><cell>(1)</cell><cell>(2)</cell><cell>(3)</cell></row><row><cell></cell><cell>Observation window:</cell><cell>Observation window:</cell><cell>Observation window:</cell></row><row><cell></cell><cell>1 year</cell><cell>2 years</cell><cell>3 years</cell></row><row><cell>ΔFNegative</cell><cell>−2.049***</cell><cell>−2.009***</cell><cell>−2.010***</cell></row><row><cell></cell><cell>(0.239)</cell><cell>(0.248)</cell><cell>(0.265)</cell></row><row><cell>ln( FDuration)</cell><cell>−0.141***</cell><cell>−0.140***</cell><cell>−0.141***</cell></row><row><cell></cell><cell>(0.051)</cell><cell>(0.050)</cell><cell>(0.052)</cell></row><row><cell>ΔFNegative × ln( FDuration)</cell><cell>0.551***</cell><cell>0.398***</cell><cell>0.396***</cell></row><row><cell></cell><cell>(0.096)</cell><cell>(0.095)</cell><cell>(0.097)</cell></row><row><cell>Observations</cell><cell>872</cell><cell>1,767</cell><cell>2,378</cell></row><row><cell>R 2</cell><cell>0.4180</cell><cell>0.4154</cell><cell>0.3823</cell></row></table><note>Note. Standard errors are clustered at the product level and are reported in the parentheses.*p &lt; 0.10; **p &lt; 0.05; ***p &lt; 0.01.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 15 .</head><label>15</label><figDesc>Toasters: Volume of WOM Standard errors are clustered at the product level and are reported in the parentheses.</figDesc><table><row><cell></cell><cell>(1)</cell><cell>(2)</cell><cell>(3)</cell></row><row><cell></cell><cell>Observation window:</cell><cell>Observation window:</cell><cell>Observation window:</cell></row><row><cell></cell><cell>1 year</cell><cell>2 years</cell><cell>3 years</cell></row><row><cell>ΔFNegative</cell><cell>−0.074***</cell><cell>−0.112***</cell><cell>−0.071***</cell></row><row><cell></cell><cell>(0.023)</cell><cell>(0.017)</cell><cell>(0.011)</cell></row><row><cell>FDuration</cell><cell>0.044***</cell><cell>0.021***</cell><cell>0.007***</cell></row><row><cell></cell><cell>(0.004)</cell><cell>(0.001)</cell><cell>(0.001)</cell></row><row><cell>ΔFNegative × FDuration</cell><cell>−0.050***</cell><cell>−0.022***</cell><cell>−0.017***</cell></row><row><cell></cell><cell>(0.003)</cell><cell>(0.001)</cell><cell>(0.001)</cell></row><row><cell>Observations</cell><cell>1,110</cell><cell>1,994</cell><cell>2,597</cell></row><row><cell>R 2</cell><cell>0.9714</cell><cell>0.9889</cell><cell>0.9933</cell></row><row><cell>Note.</cell><cell></cell><cell></cell><cell></cell></row></table><note>**p &lt; 0.05; ***p &lt; 0.01.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 16 .</head><label>16</label><figDesc>Amazon U.S. vs. Amazon Canada: Valence of WOM</figDesc><table><row><cell></cell><cell>(1)</cell><cell>(2)</cell></row><row><cell></cell><cell>Static prices</cell><cell>Dynamic prices</cell></row><row><cell>ΔFNegative</cell><cell>−1.825***</cell><cell>−1.206***</cell></row><row><cell></cell><cell>(0.197)</cell><cell>(0.319)</cell></row><row><cell>ln( FDuration)</cell><cell>−0.061</cell><cell>−0.029</cell></row><row><cell></cell><cell>(0.045)</cell><cell>(0.061)</cell></row><row><cell>ΔFNegative × ln( FDuration)</cell><cell>0.434***</cell><cell>0.436***</cell></row><row><cell></cell><cell>(0.083)</cell><cell>(0.144)</cell></row><row><cell>Observations</cell><cell>1,249</cell><cell>436</cell></row><row><cell>R 2</cell><cell>0.4046</cell><cell>0.2696</cell></row><row><cell cols="3">Note. Standard errors are clustered at the product level and are</cell></row><row><cell>reported in the parentheses.</cell><cell></cell><cell></cell></row><row><cell>*p &lt; 0.10; ***p &lt; 0.01.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 17 .</head><label>17</label><figDesc>Amazon U.S. vs. Amazon Canada: Volume of WOM Standard errors are clustered at the product level and are reported in the parentheses.</figDesc><table><row><cell></cell><cell>(1)</cell><cell>(2)</cell></row><row><cell></cell><cell>Static prices</cell><cell>Dynamic prices</cell></row><row><cell>ΔFNegative</cell><cell>0.049*</cell><cell>−0.060</cell></row><row><cell></cell><cell>(0.025)</cell><cell>(0.053)</cell></row><row><cell>FDuration</cell><cell>0.028***</cell><cell>0.029***</cell></row><row><cell></cell><cell>(0.003)</cell><cell>(0.006)</cell></row><row><cell>ΔFNegative × FDuration</cell><cell>−0.050***</cell><cell>−0.053***</cell></row><row><cell></cell><cell>(0.005)</cell><cell>(0.012)</cell></row><row><cell>Observations</cell><cell>1,612</cell><cell>491</cell></row><row><cell>R 2</cell><cell>0.9655</cell><cell>0.9635</cell></row><row><cell>Note.</cell><cell></cell><cell></cell></row></table><note>*p &lt; 0.10; **p &lt; 0.05; ***p &lt; 0.01.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 18 .</head><label>18</label><figDesc>Camera: Valence of WOM</figDesc><table><row><cell></cell><cell>Estimate</cell><cell>Standard error</cell></row><row><cell>ΔFNegative</cell><cell>−1.723***</cell><cell>0.210</cell></row><row><cell>ln( FDuration)</cell><cell>−0.063</cell><cell>0.039</cell></row><row><cell>ΔFNegative × ln( FDuration)</cell><cell>0.341***</cell><cell>0.073</cell></row><row><cell>Observations</cell><cell>1,317</cell><cell></cell></row><row><cell>R 2</cell><cell>0.4105</cell><cell></cell></row><row><cell cols="3">Notes. Standard errors are clustered at the product level.</cell></row><row><cell>**p &lt; 0.05; ***p &lt; 0.01.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 19 .</head><label>19</label><figDesc>Camera: Volume of WOM Park, Shin, and Xie: The Fateful First Consumer Review</figDesc><table><row><cell></cell><cell>Estimate</cell><cell>Standard error</cell></row><row><cell>ΔFNegative</cell><cell>0.017</cell><cell>0.017</cell></row><row><cell>FDuration</cell><cell>0.063***</cell><cell>0.003</cell></row><row><cell>ΔFNegative × FDuration</cell><cell>−0.034***</cell><cell>0.003</cell></row><row><cell>Observations</cell><cell>1,879</cell><cell></cell></row><row><cell>R 2</cell><cell>0.9664</cell><cell></cell></row></table><note>Notes. Standard errors are clustered at the product level. ***p &lt; 0.01.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head></head><label></label><figDesc>Proof of Theorem 1 Part (a). In period t,we have E[n t+1 |n t ,r t ] n t + δ •E[s t+1 |n t ,r t ],where E[s t+1 |n t , r t ] M</figDesc><table><row><cell>τ</cell><cell>( v 0 + βr t − p −</cell><cell>β 2 rt(1−rt) 2nt</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head></head><label></label><figDesc>Moreover, noting that H t+1 follows Binomial(N t+1 , α), by the law of iterated expectations,</figDesc><table><row><cell>r t+1</cell><cell cols="2">h t + H t+1 n t + N t+1 r t • n t n t + N t+1</cell><cell>+</cell><cell cols="3">h t n t + N t+1 H t+1 n t + N t+1</cell><cell>+</cell><cell>H t+1 n t + N t+1 r t • ( 1 − n t + N t+1 N t+1</cell><cell>)</cell><cell>+</cell><cell>H t+1 n t + N t+1</cell><cell>.</cell></row><row><cell>E [</cell><cell>H t+1 n t + N t+1</cell><cell cols="3">⃒ ⃒ ⃒ ⃒ n t , r t</cell><cell>]</cell><cell cols="5">E E α • E [ E [ [ αN t+1 H t+1 n t + N t+1 n t + N t+1 ⃒ ⃒ ⃒ ⃒ n t , r t ⃒ ⃒ ⃒ ⃒ n t , r t , N t+1 ] [ N t+1 n t + N t+1 ⃒ ⃒ ⃒ n t , r t ⃒ ]</cell><cell>]⃒ ⃒ ⃒ ⃒ n t , r t</cell><cell>]</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This paper is partially based on the first author's doctoral dissertation at the University of Florida. The authors thank the editor, associate editor, two anonymous reviewers, Martijn de Jong, Yong Liu, Jiwoong Shin, Steve Shugan, Catherine Tucker, Ying Xie, and Juanjuan Zhang for their helpful comments and discussions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Do recommender systems manipulate consumer preferences? A study of anchoring effects</title>
		<author>
			<persName><forename type="first">G</forename><surname>Adomavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Bockstedt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Curley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Systems Res</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="956" to="975" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Selection on observed and unobserved variables: Assessing the effectiveness of Catholic schools</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Altonji</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Elder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Taber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Political Econom</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="151" to="184" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Word of mouth, observed adoptions, and anime-watching decisions: The role of the personal vs. the community network</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ameri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Honka</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="567" to="583" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reviews without a purchase: Low ratings, loyal customers, and deception</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Simester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="249" to="269" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Customer satisfaction and word of mouth</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Service Res</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="17" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The effect of electronic word of mouth on sales: A meta-analytic review of platform, product, and metric factors</title>
		<author>
			<persName><forename type="first">Babić</forename><surname>Rosario</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sotgiu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Valck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Bijmolt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="318" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">How much should we trust differences-in-differences estimates? Quart</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bertrand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Duflo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econom</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="249" to="275" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Learning from the behavior of others: Conformity, fads, and informational cascades</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bikhchandani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hirshleifer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Welch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econom. Perspect</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="151" to="170" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Local consumer review survey</title>
		<author>
			<persName><surname>Brightlocal</surname></persName>
		</author>
		<ptr target="https://www.brightlocal.com/wp-content/uploads/2014/07/Local-Consumer-Review-Survey-20141.pdf" />
		<imprint>
			<date type="published" when="2014-04-21" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Estimation of educational borrowing constraints using returns to schooling</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Cameron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Taber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Political Econom</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="132" to="182" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Online consumer review: Word-of-mouth as a new element of marketing communication mix</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="477" to="491" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Online social interactions: A natural experiment on word of mouth vs. observational learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="238" to="254" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The effect of word of mouth on sales: Online book reviews</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mayzlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="345" to="354" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The effects of online user reviews on movie box office performance: Accounting for sequential rollout and aggregation across local markets</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Chintagunta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gopinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkataraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="944" to="957" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Navigating by the stars: Investigating the actual and perceived validity of online user ratings</title>
		<author>
			<persName><forename type="first">B</forename><surname>De Langhe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>Fernbach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Lichtenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="817" to="833" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Customer service and business results: A survey of customer service from mid-size companies</title>
	</analytic>
	<monogr>
		<title level="j">Dimensional Research</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Accessed</forename></persName>
		</author>
		<ptr target="https://d16cvnquvjw7pr.cloudfront.net/resources/whitepapers/Zendesk_WP_Customer_Service_and_Business_Results.pdf" />
		<imprint>
			<date type="published" when="2016-04-23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Research note-performance-based advertising: Advertising as signals of product quality</title>
		<author>
			<persName><forename type="first">J</forename><surname>Feng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Systems Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1030" to="1041" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
	<note>3-part-2</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">How online product reviews affect retail sales: A meta-analysis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Floyd</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Freling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Alhoqail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">Y</forename><surname>Cho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Freling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Retailing</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="217" to="232" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Examining the relationship between reviews and sales: The role of reviewer identity disclosure in electronic markets</title>
		<author>
			<persName><forename type="first">C</forename><surname>Forman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wiesenfeld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Systems Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="291" to="313" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Using online conversations to study word-of-mouth communication</title>
		<author>
			<persName><forename type="first">D</forename><surname>Godes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mayzlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="545" to="560" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Sequential and temporal dynamics of online opinion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Godes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="448" to="473" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Aggregation and linearity in the provision of intertemporal incentives</title>
		<author>
			<persName><forename type="first">B</forename><surname>Holmström</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Milgrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="303" to="328" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Market liquidity and performance monitoring</title>
		<author>
			<persName><forename type="first">B</forename><surname>Holmström</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Tirole</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Political Econom</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="678" to="709" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The effects of positive and negative online customer reviews: Do brand strength and category maturity matter?</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Ho-Dac</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Carson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">L</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="37" to="53" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Optimal referral bonuses with asymmetric information: Firm-offered and interpersonal incentives</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Kornish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="121" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Self-selection and information role of online product reviews</title>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Hitt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Systems Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="456" to="474" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Longitudinal data analysis using generalized linear models</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">Y</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Zeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="13" to="22" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Decomposing the value of word-ofmouth seeding programs: Acceleration vs. expansion</title>
		<author>
			<persName><forename type="first">B</forename><surname>Libai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Peres</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="176" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Word of mouth for movies: Its dynamics and impact on box office revenue</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="74" to="89" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fake it till you make it: Reputation, competition, and Yelp review fraud</title>
		<author>
			<persName><forename type="first">M</forename><surname>Luca</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zervas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3412" to="3427" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">More than words: The influence of affective content and linguistic style matches in online reviews on conversion rates</title>
		<author>
			<persName><forename type="first">S</forename><surname>Ludwig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">De</forename><surname>Ruyter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Friedman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Brüggen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Wetzels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pfann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="87" to="103" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Promotional reviews: An empirical investigation of online review manipulation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mayzlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Dover</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chevalier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. Econom. Rev</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2421" to="2455" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Online product opinions: Incidence, evaluation, and evolution</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Moe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Schweidel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="372" to="386" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Social influence bias: A randomized experiment</title>
		<author>
			<persName><forename type="first">L</forename><surname>Muchnik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Aral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Taylor</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">341</biblScope>
			<biblScope unit="issue">6146</biblScope>
			<biblScope unit="page" from="647" to="651" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Online shopping and e-commerce</title>
		<author>
			<persName><surname>Pew Research</surname></persName>
		</author>
		<author>
			<persName><surname>Center</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Accessed</forename></persName>
		</author>
		<ptr target="https://www.pewresearch.org/internet/2016/12/19/online-shopping-and-e-commerce/" />
		<imprint>
			<date type="published" when="2020-06-24" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Yelp reviews of hospital care can supplement and inform traditional surveys of the patient experience of care</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Ranard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Werner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Antanavicius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">A</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">F</forename><surname>Meisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Asch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Merchant</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health Affairs</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="697" to="705" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">How does the variance of product ratings matter?</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="696" to="707" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">Shin</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xie</forename></persName>
		</author>
		<title level="m">The Fateful First Consumer Review Marketing Science</title>
				<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="481" to="507" />
		</imprint>
	</monogr>
	<note>© 2021 INFORMS</note>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Effects of word-of-mouth vs. traditional marketing: Findings from an internet social networking site</title>
		<author>
			<persName><forename type="first">M</forename><surname>Trusov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bucklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pauwels</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="90" to="102" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Integrating multiple opinions: The role of aspiration level on consumer response to critic consensus</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">M</forename><surname>West</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Broniarczyk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="38" to="51" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Internet and Network Economics</title>
		<author>
			<persName><forename type="first">F</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Huberman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="s">Lecture Notes in Computer Science</title>
		<editor>Papadimitrou C, Zhang S</editor>
		<imprint>
			<biblScope unit="volume">5385</biblScope>
			<biblScope unit="page" from="334" to="341" />
			<date type="published" when="2008" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
	<note>How public opinion forms</note>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A meta-analysis of electronic word-of-mouth elasticity</title>
		<author>
			<persName><forename type="first">Y</forename><surname>You</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Vadakkepatt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Joshi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="19" to="39" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">An efficient method of estimating seemingly unrelated regressions and tests for aggregation bias</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zellner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">298</biblScope>
			<biblScope unit="page" from="348" to="368" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Rational herding in microloan markets</title>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="892" to="912" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Impact of online consumer reviews on sales: The moderating role of product and consumer characteristics</title>
		<author>
			<persName><forename type="first">F</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="133" to="148" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<author>
			<persName><forename type="first">Shin</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Xie</forename></persName>
		</author>
		<title level="m">The Fateful First Consumer Review Marketing Science</title>
				<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="481" to="507" />
		</imprint>
	</monogr>
	<note>© 2021 INFORMS</note>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
