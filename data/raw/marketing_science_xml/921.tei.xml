<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Multicollinearity and Measurement Error in Structural Equation Models: Implications for Theory Testing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Rajdeep</forename><surname>Grewal</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Cote</surname></persName>
							<email>cote@vancouver.wsu.edu</email>
						</author>
						<author>
							<persName><forename type="first">Hans</forename><surname>Baumgartner</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Smeal College of Business Administration</orgName>
								<orgName type="institution" key="instit2">Pennsylvania State University</orgName>
								<address>
									<postCode>16802-3007</postCode>
									<settlement>University Park</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Washington State University</orgName>
								<address>
									<addrLine>14204 Salmon Creek Avenue</addrLine>
									<postCode>98686</postCode>
									<settlement>Vancouver, Washington</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Smeal College of Business Administration</orgName>
								<orgName type="institution">Pennsylvania State University</orgName>
								<address>
									<postCode>16802-3007</postCode>
									<settlement>University Park</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Multicollinearity and Measurement Error in Structural Equation Models: Implications for Theory Testing</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 e 1526-548X 04 2304 0519</idno>
					</monogr>
					<idno type="DOI">10.1287/mksc.1040.0070</idno>
					<note type="submission">received June 26, 2002, and was with the author 12 months for 2 revisions; processed by Michel Wedel.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please scroll down for article-it is on subsequent pages</head><p>With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning opportunities for individual professionals, and organizations of all types and sizes, to better understand and use O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Perhaps due to its ability to account for measurement error and manage multiple endogenous constructs, structural equation modeling (SEM) has become a commonly used tool for theory testing <ref type="bibr" target="#b33">(Steenkamp and Baumgartner 2000)</ref>. Important methodological advances, such as methods for treating heterogeneity <ref type="bibr" target="#b2">(Ansari et al. 2000</ref><ref type="bibr" target="#b19">, Jedidi et al. 1997</ref>, have broadened the scope of the technique, and even marketing practitioners are adopting it in growing numbers <ref type="bibr" target="#b14">(Grapentine 2000)</ref>. The widespread use <ref type="bibr">(and misuse)</ref> of SEM has led to a growing literature that addresses various application problems <ref type="bibr">Homburg 1996, Hulland et al. 1996)</ref>. One of these problems is multicollinearity, i.e., high correlations among the latent exogenous constructs. Unfortunately, little is known about the effects of multicollinearity in SEM, and researchers frequently pay little attention to it. For example, 42 articles using either confirmatory factor analysis (CFA) or SEM were published in the 1999 and 2000 issues of the Journal of Marketing, Journal of Marketing Research, and Journal of the Academy of Marketing Science. 1 Potential multicollinearity problems could be assessed for 31 of the studies through the published correlation matrix. Nine studies (29%) reported high correlations ( = 0 75 to 0.95) among latent constructs. Despite these high correlations, not a single article discussed how multicollinearity might have affected the results. Such oversight could be critical because managing multicollinearity is a growing concern in applied research and theory development <ref type="bibr" target="#b11">(Farley et al. 1998)</ref>.</p><p>The dismissal of multicollinearity problems appears to have two basic causes. First, some ambiguity exists about whether multicollinearity is really a problem in SEM. Many researchers seem to think that structural equation models are robust against multicollinearity <ref type="bibr" target="#b25">(Malhotra et al. 1999)</ref>, with some going so far as to explicitly state that SEM can remedy multicollinearity problems. For example, <ref type="bibr">Verbeke and Bagozzi (2000, p. 93</ref>) used LISREL to "avoid problems of Marketing Science 23(4), pp. 519-529, © 2004 INFORMS multicollinearity." Similarly, <ref type="bibr">Maruyama (1998, p. 61)</ref> argues that "structural equation approaches can help deal with some cases where the correlations among predictors are large." One reason for this optimism seems to be that if highly correlated variables can be regarded as indicators of a common underlying construct, multicollinearity problems can be avoided. In contrast, some researchers have warned that multicollinearity can lead to SEM estimates far from the true parameters and large standard errors of the estimates <ref type="bibr" target="#b17">(Jagpal 1982</ref><ref type="bibr" target="#b14">, Grapentine 2000</ref>.</p><p>Second, researchers may ignore multicollinearity because of practical considerations. Existing guidelines about when multicollinearity is likely to cause problems are often ambiguous, procedures for mitigating multicollinearity are frequently of limited usefulness and, most importantly, little is known about how to deal with multicollinearity in the context of SEM. The best solution would be to avoid multicollinearity problems in the first place. However, as <ref type="bibr">Rindskopf (1984, p. 111</ref>) notes, " <ref type="bibr">[t]</ref>he exact values that might cause or prevent the problems discussed are rather fuzzy." Since the conditions that cause multicollinearity problems are unclear, it is difficult to avoid these conditions. Thus, researchers easily dismiss messy multicollinearity problems by assuming SEM is robust, or ignore the problems because little is known about multicollinearity. <ref type="bibr">2</ref> The disregard for multicollinearity problems raises important questions. Is it true, as some claim, that SEM can be used to deal with multicollinearity? If not, then how can we minimize the effects of multicollinearity? These uncertainties led <ref type="bibr">Kaplan (1994, p. 211)</ref> to suggest that "examin <ref type="bibr">[ing]</ref> the effects of increasing multicollinearity on <ref type="bibr">[SEM]</ref> parameter estimates and standard errors is an important area for future research." To illuminate these issues, we report two Monte Carlo simulation experiments in which we vary the level of multicollinearity, measurement error, amount of explained variance, relative importance of the exogenous variables, and sample size. We study the effects of multicollinearity on the accuracy of coefficient and standard-error estimates, as well as inferences errors. Our research takes important steps toward identifying conditions under which 2 Theoretically, as <ref type="bibr">Rindskopf (1984, p. 115</ref>) notes, "the problem of multicollinearity can be viewed as another [special] case of empirical underidentification" (also see <ref type="bibr" target="#b22">Kenny 1979)</ref>. When models are empirically underidentified, estimates are likely to be unstable and may not accurately reflect population values. Unfortunately, it is unclear at what point empirical underidentification will become a problem. As <ref type="bibr">Rindskopf (1984, p. 111)</ref> states, "The exact values that might cause or prevent the problems discussed [empirical underidentification] are rather fuzzy." All we know is that once multicollinearity reaches a critical point, the structural equation model will become underidentified and parameter estimates may be problematic. multicollinearity and measurement error in SEM are likely to cause misleading tests of theory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Background</head><p>The literature on multicollinearity can be divided into three major topics: (1) under what conditions multicollinearity will occur; (2) how multicollinearity problems can be detected; and (3) how multicollinearity should be managed. Our review of the literature will show that we know relatively little about the conditions that lead to multicollinearity problems in SEM. Although we do have tools for detecting when multicollinearity may be affecting estimates, these techniques are often ambiguous. Lastly, there are some remedial actions that can be taken when multicollinearity exists, but they may be difficult to implement, and in general the evidence regarding their practical effectiveness is limited.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">When Does Multicollinearity Pose</head><p>a Problem in SEM? <ref type="bibr" target="#b27">Mason and Perreault (1991)</ref> have documented the conditions under which multicollinearity may pose problems in regression. They show that multicollinearity leads to inaccurate estimates of coefficients and standard errors as well as inference errors, but they also argue that the problem should not be viewed in isolation, and that a high R 2 and large sample size can offset the problems caused by multicollinearity. Although these factors should also be relevant in the context of SEM, their work is silent about certain issues that are specific to SEM, most notably, measurement error. The ability of SEM to incorporate measurement error makes it difficult to assess the impact of multicollinearity on parameter estimates <ref type="bibr" target="#b7">(Bollen 1989)</ref>. <ref type="bibr" target="#b27">Mason and Perreault (1991)</ref> show that increasing explained variance in the dependent variable mitigates the effects of multicollinearity. Removing measurement error should increase the amount of variance explained by the structural model and, by extension, mitigate multicollinearity. However, measurement error also attenuates correlations among the exogenous variables. The presence of measurement error is likely to mask the true correlation among latent exogenous constructs. Thus, controlling for measurement error should result in higher correlations among the exogenous constructs than not controlling for measurement error. <ref type="bibr">3</ref> As <ref type="bibr">Maruyama (1998, p. 61</ref>) points out, "although latent variable approaches help in most instances by removing measurement and specification error from variables, they ironically may make high multicollinearity appear in cases where it 521 previously has not been a problem" (also see <ref type="bibr">Larcker 1981b, Heise 1969)</ref>. <ref type="bibr">4</ref> Thus, it is unclear if eliminating measurement error will mitigate multicollinearity due to the beneficial effect of an increase in R 2 or exacerbate it by increasing the correlations among the exogenous constructs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Detecting Multicollinearity</head><p>Various tools have been proposed to diagnose situations in which multicollinearity among the predictors may create estimation and inference problems, although little is known about the usefulness of these techniques for SEM. <ref type="bibr" target="#b20">Kaplan (1994)</ref> offers one of the few discussions of conditioning problems (of which multicollinearity is a special case) for SEM. He reviews several general methods that can be used to detect multicollinearity, including inspection of the (1) correlation matrix of the predictor variables, (2) correlation matrix of the path coefficients, (3) determinant of the correlation matrix of the predictor variables, (4) sign of the path coefficients, and (5) variance inflation factors. However, he calls these methods "more or less ad hoc" <ref type="bibr">(Kaplan 1994, p. 201</ref>). Kaplan also proposes a general conditioning diagnostic for structural equation models based on the condition number of the correlation matrix of the estimated parameters. Although the procedure is useful for detecting highly collinear parameter estimates, it may not be able to diagnose multicollinearity among the observed variables. Further, as condition indices are model specific, rules of thumb about what constitutes a large condition number may be misleading <ref type="bibr" target="#b7">(Bollen 1989)</ref>. <ref type="bibr" target="#b32">Schmidt and Muller (1978)</ref> also discuss the problem of multicollinearity in the context of SEM and argue that in multistage models typical of many applications of SEM, commonly used multicollinearity diagnostics should be applied "at every stage of a given 'causal model' " (p. 267). They discuss three specific methods for assessing multicollinearity: (1) the multiple correlation between the independent variables;</p><p>(2) the Haitovsky test, which assesses singularity of the correlation matrix of the independent variables; and (3) the determinant and eigenvalues of the correlation matrix of the independent variables. However, these methods have limitations because they do not provide clear guidelines about when multicollinearity is likely to cause inference errors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Managing Multicollinearity</head><p>When one of the telltale signs of multicollinearity occurs (nonsignificant coefficient estimates even though the overall regression is highly significant, "wrong" signs of the coefficients, unstable parameter estimates), researchers generally feel compelled to do something about the problem. Unfortunately, many of the solutions are ad hoc (e.g., dropping a variable, which may lead to a misspecification error, or restricting parameters, which is not always possible) or impractical (e.g., obtaining additional data that do not suffer from multicollinearity). Among the more formal remedies is ridge estimation, which introduces a small amount of bias in return for greater efficiency. <ref type="bibr" target="#b17">Jagpal (1982)</ref> developed a partial-least-squares (PLS)based ridge estimator to deal with multicollinearity in structural equation models (also see <ref type="bibr" target="#b32">Schmidt and</ref><ref type="bibr">Muller 1978, Maruyama 1998)</ref>. Although ridge estimation has been incorporated into SEM programs such as LISREL to deal with cases in which the variance-covariance matrix is not positive definite, little is known about the practical benefits of using ridge estimation in SEM contexts <ref type="bibr" target="#b21">(Kennedy 1992)</ref>. Alternatively, it is possible to move away from SEM and into the realm of regression by forming composite indicators (e.g., factor scores). In this case, various other estimation techniques, such as the equity estimator <ref type="bibr" target="#b23">(Krishnamurthi and Rangaswamy 1987)</ref>, are available. However, a serious problem with using composite indicators is that one of the main advantages of using SEM, the ability to explicitly account for measurement error, is lost. In general, none of the approaches for managing multicollinearity seems entirely satisfactory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">The Need to Identify Conditions That</head><p>Lead to Multicollinearity Problems In summary, although we have tools that can identify situations in which multicollinearity may cause problems, there are two issues with existing approaches. First, many of the guidelines are ambiguous (e.g., at what point is a correlation between independent variables too high) and potentially misleading (e.g., if condition numbers are model dependent, absolute rules of thumb are meaningless). Second, the major conclusion of <ref type="bibr" target="#b27">Mason and Perreault (1991)</ref> was that the "deleterious effect of a given level of multicollinearity should be viewed in conjunction with other factors known to affect estimation accuracy" (p. 268). Guidelines based solely on the amount of shared variance among predictor variables ignore this recommendation. Given that multicollinearity is difficult to mitigate once it is present in data, the best strategy would be to avoid the problem in the first place. Knowing the conditions likely to lead to multicollinearity problems and the factors that help offset its damaging effects can help researchers develop strategies to mitigate its effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Monte Carlo Simulations</head><p>To capture situations typically encountered by marketing researchers, Experiment 1 examines a scenario Marketing Science 23(4), pp. 519-529, © 2004 INFORMS with four latent exogenous variables and one latent endogenous variable, with four items for each latent construct <ref type="bibr" target="#b3">(Bagozzi and Baumgartner 1994</ref>, Panel A, Figure <ref type="figure">1</ref>). The levels of the design factors (i.e., multicollinearity, measurement error, R 2 , relative weights of the exogenous variables, and sample size) were manipulated to reflect conditions typically encountered by marketing researchers <ref type="bibr" target="#b27">(Mason and</ref><ref type="bibr">Perreault 1991, Baumgartner and</ref><ref type="bibr" target="#b4">Homburg 1996)</ref>. Since marketing researchers often deal with multiple endogenous variables and since SEM is particularly suited for this type of analysis, Experiment 2 extends Experiment 1 to the case of multiple endogenous variables (Panel B, Figure <ref type="figure">1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1</head><p>Models for the Two Experiments</p><formula xml:id="formula_0">* Panel A Experiment 1 Panel B Experiment 2 φ 21 ξ 1 γ 11 γ 12 γ 23 γ 21 β 31 β 32 η 1 η 2 η 3 ξ 2 ξ 3 ξ 1 γ 11 η 1 γ 12 γ 14 ξ 2 ξ 3 φ 21 φ 32 φ 31 ξ 4 *</formula><p>In both experiments each latent construct is measured by four items. For clarity, these item details are not depicted in the figure. Furthermore, we only depict relationships between latent constructs that were specified to be nonzero (positive). Similarly, we only depict nonzero correlations.</p><p>Based on the design factors and the specific values chosen for the other model components, we formulated various population covariance matrices and input these matrices into EQS version 5.7b to simulate our data <ref type="bibr" target="#b6">(Bentler and Wu 1995)</ref>. Following <ref type="bibr" target="#b0">Anderson and Gerbing (1984)</ref> and <ref type="bibr" target="#b28">Paxton et al. (2001)</ref>, we generated 200 proper solutions for each cell of the design. A solution was regarded as proper if (1) there were no convergence problems, (2) the covariance matrix of the latent variables was positive definite, and (3) there were no linear dependencies among the estimated parameters. 5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Design Factors</head><p>In Experiment 1 we replicated <ref type="bibr" target="#b27">Mason's and Perreault's (1991)</ref> multicollinearity ranges at four levels of 0.2 to 0.5, 0.4 to 0.65, 0.6 to 0.8, and 0.8 to 0.95. For example, at the first level of multicollinearity 3 has a correlation of 0.2 with 1 and 2 , and 1 and 2 are correlated at 0.5. In accordance with acceptable levels reported in the literature <ref type="bibr" target="#b9">(Cote and Buckley 1987)</ref>, we systematically varied measurement error at three levels. Specifically, the composite reliabilities of 1 through 4 and 1 were all set at 0.7, 0.8, or 0.9, with uniform loadings for all indicators on a given construct. Following Mason and Perreault, we also selected three levels of total explained variance in the endogenous construct (R 2 = 0 25, 0.50, or 0.75) and two sets of weights for the relative impact of the four exogenous constructs (2, 1, 0, 1 and 2, 2, 0, 1 for 11 , 12 , 13 , and 14 , respectively; Panel A of Figure <ref type="figure">1</ref>). Specifically, the impact of 1 on 1 was twice as large as the impact of 2 on 1 in the first case, but equal in the second case. Finally, we set sample size at two levels, using ratios of 3:1 and 6:1 for the number of observations to the number of parameters estimated <ref type="bibr" target="#b4">(Baumgartner and Homburg 1996)</ref>. Therefore, we have four levels of multicollinearity, three levels of measure reliability and R 2 , and two levels of coefficient weights and sample size, giving us 144 different combinations of the design factors. We generated 200 proper solutions for each cell, resulting in 28,800 sets of estimates.</p><p>In Experiment 2, multicollinearity was varied at three levels by systematically altering the correlation between 1 and 2 ( 21 = 0 4, 0.6, or 0.8; Panel B of Figure <ref type="figure">1</ref>). We also varied composite reliability at four levels (0.6, 0.7, 0.8, and 0.9), R 2 at three levels (0.25, 0.50, or 0.75-same for all endogenous variables), and sample size at two levels (i.e., ratios of 3:1 and 6:1 for the number of observations to the number of parameters estimated). Thus, we have three levels of multicollinearity and R 2 , four levels of measure reliability, and two levels of sample size, giving us 72 different combinations of the design factors. With 200 replications in each cell, there are 14,400 sets of estimates.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Simulation Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Experiment 1</head><p>We had to generate a total of 30,322 samples (an additional 5%) in order to obtain 200 proper solutions in each cell of the design. Most of the 1,522 improper solutions (96%) occurred in the highest multicollinearity condition ( 1 2 = 0 95 , and the incidence of improper solutions seems to be nonnegligible in these cases. For example, in the condition in which correlations ranged from 0.8 to 0.95, composite reliability was 0.7, sample size was 3:1, R 2 was 0.75, and 1 and 2 were unequal in magnitude, 44% of the solutions were improper. Thus, one difference relative to the findings of <ref type="bibr" target="#b27">Mason and Perreault (1991)</ref> is that very high levels of multicollinearity are likely to result in improper solutions, especially when composite reliability is low and sample size is small. Because we only consider proper solutions in the sequel, the findings are conditional on having obtained a proper solution.</p><p>To assess the efficacy of the design variables, we computed the accuracy of the estimated coefficients and their standard errors as the absolute difference between an estimate and its true value. <ref type="bibr">6</ref> The design variables explained 32%, 34%, 21%, and 12% of the variance in the accuracy of the estimated coefficients of 11 , 12 , 13 , and 14 , respectively (see Table <ref type="table" target="#tab_0">1</ref>). Similar to <ref type="bibr" target="#b27">Mason and Perreault (1991)</ref>, the explained variance for the accuracy of the estimated standard errors was much higher at 71%, 71%, 53%, and 41% for 11 , 12 , 13 , and 14 , respectively. Although several higher-order effects were significant because of the very large sample size, the four main effects of degree of multicollinearity, measure reliability, R 2 , and sample size generally accounted for most of the explained variance in each dependent variable (92% for the standard error of 14 and over 96% for the other parameters). Coefficient weights did not explain meaningful amounts of variance in the inaccuracy of coefficients and their standard errors. The adverse effects of multicollinearity were most pronounced for 11 and 12 , which was expected because multicollinearity was manipulated by varying the correlation between 1 and 2 . Over 70% of the explained variance in the inaccuracy of both the coefficients and standard errors was accounted for by multicollinearity in the case of 11 and 12 . Measure reliability, R 2 , and, to a lesser degree, sample size also explained substantial portions of the variance in the inaccuracy of coefficients and standard errors. Reliability was a particularly important influence in the case of the standard errors of the coefficients.</p><p>As theory testing usually involves ascertaining the direction (positive or negative) and significance of a parameter estimate, researchers are generally most Marketing Science 23(4), pp. 519-529, © 2004 INFORMS concerned about inference errors, specifically, Type II errors (i.e., failures to detect a significant effect). Thus, one needs to look at the results for the coefficients and standard errors in tandem. A high standard error can result in a Type II error even when the coefficient estimate is correct, as can a wrong coefficient estimate even when the standard error is correct. The percentage of Type II errors in each cell of the design is shown in Table <ref type="table" target="#tab_1">2</ref>. It is apparent that Type II error rates vary widely as a function of the design factors, ranging from 0 to almost 100%.</p><p>In order to provide a formal analysis of Type II error rates, we conducted a series of logit analyses. We used a hierarchical modeling procedure and began with a main-effects model, then introduced two-way interactions, followed by increasingly higher-order interactions. The pseudo-R 2 values for the maineffects model, based on the percentage improvement in the log-likelihood ratio, were 53%, 44%, and 31% for 11 , 12 , and 14 , respectively (there is no Type II error for 13 because the true value is zero). Although some of the higher-order interactions were significant because of the large sample size, they were substantively unimportant, as shown by the minor improvements in the pseudo-R 2 values (about 1%). Consistent with the findings for the accuracy of the coefficients and standard errors, Type II errors go  Note. REL, Reliability. * We use the following shading protocol: Type II error rate of less that 19.5% no shading and then the darkness increases in the range 20%-39.5%, 40%-59.5%, 60%-79.5%, and greater than 80%.</p><p>up as the level of multicollinearity increases, measure reliability deteriorates, R 2 decreases, and sample size gets smaller. For 11 and 12 the most important determinant of Type II error rates was multicollinearity, followed by R 2 , measure reliability (for 11 or sample size (for 12 , and coefficient weight. Although coefficient weight was not a significant influence on the inaccuracy of parameter estimates, the effect on Type II error rates makes sense because the magnitude of 12 is twice as high in the equalweight condition than in the unequal-weight condition. As one would expect, Type II error rates were higher in the equal-weight condition for 11 and lower in the equal-weight condition for 12 . For 14 , R 2 was the most important determinant of Type II error rates, followed by measure reliability, sample size, multicollinearity, and coefficient weight. Multicollinearity had a relatively small influence because 4 was specified to be uncorrelated with the other constructs.</p><p>It should be emphasized that the impact of multicollinearity on Type II error rates for 11 and 12 was substantial. Specifically, for 11 the average error rates were 8%, 17%, 39%, and 89% for increasing levels of multicollinearity, and for 12 , the corresponding figures were 18%, 31%, 53%, and 91%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Experiment 2</head><p>We had to generate 14,824 samples (an additional 3%) in order to obtain 200 proper solutions in each cell of the design. Most of the 424 improper solutions (86%) occurred in the lowest reliability condition. Improper solutions were particularly likely when reliability was low, sample size was small, and R 2 was high. Thus, while the first study showed that models with very high levels of multicollinearity are prone to improper solutions, the second study indicates that poor measure reliability is another major determinant of improper solutions. The difference in results between the two studies can be attributed to the different levels of multicollinearity and reliability used in the simulations (the highest level of multicollinearity was 0.95 in Experiment 1 and 0.8 in Experiment 2; the lowest level of reliability was 0.7 in Experiment 1 and 0.6 in Experiment 2).</p><p>The design factors explained 20%, 21%, 17%, 16%, 17%, 12%, 13%, and 9% of the variance in the accuracy of the coefficients and 83%, 84%, 86%, 71%, 74%, 81%, 83%, and 84% of the variance in the accuracy of the standard errors for 11 , 12 , 13 , 21 , 22 , 23 , 31 , and 32 , respectively (Table <ref type="table" target="#tab_0">1</ref>). Again, the main effects of 41.0 68.5 90.0 62.0 78.0 91.0 52.5 71.0 93.5 21.5 24.5 39.5 32.5 29.0 27.5 33.5 40.5 43.5 20.5 44.0 85.5 39.5 65.0 83.5 26.5 46.0 80.5 7.5 7.5 10.0 14.5 11.5 10.5 14.0 19.5 22.5 8.0 25.0 65.5 22.0 45.5 76.0 12.0 27.5 3.0 2.5 2.0 6.5 8.0 10.0 2.5 12.0 45.   Note. REL, Reliability. * We use the following shading protocol: Type II error rate of less than 19.5% no shading and then the darkness increases in the range 20%-39.5%, 40%-59.5%, 60%-79.5%, and greater than 80%. multicollinearity, measurement error, R 2 , and sample size accounted for most of the explained variance in the coefficients and standard errors (around 96%). In particular, multicollinearity, along with measure unreliability, was among the two most important determinants of inaccurate coefficients and standard errors for 11 and 12 , which is as expected because multicollinearity was manipulated by varying the correlation between 1 and 2 . In contrast, multicollinearity exerted relatively minor effects on 13 , 23 , 31 , and 32 because 3 was specified to be uncorrelated with the other exogenous constructs, and the correlation between 1 and 2 was generally small. Thus, when there are multiple endogenous variables, it seems that the damaging effects of multicollinearity at one stage of the model (between 1 and 2 do not transfer to another stage, as long as the correlation between constructs at the next stage is small.</p><p>The design factors again resulted in a significant percentage of Type II errors, which can be as high as 94% (Table <ref type="table" target="#tab_2">3</ref>). Based on logit analyses, the maineffects model yielded pseudo-R 2 values of 42%, 39%, 38%, 35%, 42%, and 33% for 11 , 12 , 21 , 23 , 31 , and Marketing Science 23(4), pp. 519-529, © 2004 INFORMS significant because of the large sample, did not explain substantively important portions of variance (less than 2%). Due to the limited number of Type II errors for 23 , 31 , and 23 in certain cells, higher-order interactions (and the main-effects model for 31 could not be estimated reliably, but visual inspection of the data indicated that there was little evidence of interaction effects. In general, Type II errors increase as the level of multicollinearity increases, measure reliability deteriorates, R 2 decreases, and sample size goes down. For 11 and 12 (which are most affected by high correlation between 1 and 2 , multicollinearity was the major determinant of Type II error rates, followed by R 2 , measure reliability, and sample size. Multicollinearity was a less important influence on Type II error rates for 21 , and it had little effect in the case of 23 , 31 , and 32 . Measure reliability was the major determinant of Type II error rates for 21 , 23 , and 32 . The Type II error rates for 11 and 12 as a function of multicollinearity were nontrivial, although not as high as in Experiment 1 since the highest level of multicollinearity was only 0.8 (rather than 0.95).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">General Discussion</head><p>The simulations show that high multicollinearity, in combination with low measure reliability, small sample size, and low explained variance in endogenous constructs, has several undesirable consequences. To begin with, the researcher may not be able to get a proper solution. Particularly in models with very high levels of collinearity (correlations among the exogenous variables greater than 0.9) and low measure reliability (composite reliability smaller than 0.7), improper solutions were quite common. Thus, improper solutions might be a signal of multicollinearity (and other model problems) and researchers should pay careful attention to them. Even when a proper solution can be obtained, multicollinearity can lead to inaccurate parameter estimates and a high incidence of Type II errors, particularly when reliability is weak, sample size is small, and explained variance is low.</p><p>Two things should be kept in mind, however. First, the adverse effects of multicollinearity on estimation accuracy occurred primarily at the most extreme levels of multicollinearity between 1 and 2 . Consistent with the findings of <ref type="bibr" target="#b27">Mason and Perreault (1991)</ref>, in the first experiment the highest correlation between the adverse effects of multicollinearity occurred at the highest level of multicollinearity. It should be noted, however, that high levels of multicollinearity may be less apparent in SEM than regression. Because of the attenuation created by measurement error, the crossconstruct correlations among indicators will be lower than the actual level of multicollinearity (i.e., correlations among the exogenous constructs). For example, in the first experiment the correlation between 1 and 2 was 0.95, but the correlation between the indicators of 1 and 2 was only 0.35 when reliability was 0.7, 0.48 when reliability was 0.8, and 0.66 when reliability was 0.9. Thus, correlations between the observed variables that look innocuous may induce fairly high levels of multicollinearity among the latent constructs.</p><p>Second, as pointed out by <ref type="bibr" target="#b27">Mason and Perreault (1991)</ref>, multicollinearity should not be viewed in isolation. It is also important to consider other factors that influence the accuracy of estimation results, and thus may either exacerbate or mitigate the harmful effects of multicollinearity. Consistent with <ref type="bibr" target="#b27">Mason and Perreault (1991)</ref>, our results showed that the deleterious effects of multicollinearity could be largely offset when the sample size was large and the independent variables explained a high proportion of the variance in the dependent variable. Extending the results of <ref type="bibr" target="#b27">Mason and Perreault (1991)</ref>, our findings show that measure reliability is another important influence on estimation accuracy. In fact, measure reliability was generally either the most important or second-most important determinant of the accuracy of the estimated coefficients and standard errors of 11 and 12 . Thus, researchers should not assume that because SEM takes measurement error into account and corrects paths for attenuation, measure unreliability is less of a problem. The present findings clearly show that whenever there is unreliability of measurement, estimation accuracy for both coefficients and standard errors suffers. In contrast, when measures are highly reliable, even fairly high levels of multicollinearity can be tolerated. An added benefit is that when reliability is high, correction for attenuation will not increase the correlation between latent constructs to unacceptably high levels.</p><p>The major consequence of inaccurate estimates of coefficients and standard errors is that the likelihood that a researcher will commit a Type II error can be substantial. The Type II error rates tabulated in Tables <ref type="table" target="#tab_1">2 and 3</ref> for the various conditions of both experiments suggest the following conclusions:</p><p>• When multicollinearity is extreme (around 0.95), Type II error rates are generally unacceptably high (over 80%).</p><p>• When multicollinearity is between 0.6 and 0.8, Type II error rates can be substantial (greater than 50% and frequently above 80%) when composite reliability is weak (0.7 or lower), R 2 is low (0.25), and sample size is relatively small (ratio of 3:1). However, as reliability improves (0.80 or higher), R 2 reaches 0.75, and sample becomes relatively large (ratio of 6:1), Type II error rates become negligible (below 5%).</p><p>• When multicollinearity is between 0.4 and 0.5, Type II error rates tend to be quite small, except when reliability is weak (0.7 or below), R 2 is low (0.25), and sample size is small (ratio of 3:1), in which case error rates can still be high (greater than 50%).</p><p>One interesting finding that emerged in Experiment 1 was that the Type II error rates in the 0.9 reliability conditions were sometimes substantially higher than those reported by <ref type="bibr" target="#b27">Mason and Perreault (1991)</ref>, whose simulations assumed perfect reliability (which is highly unrealistic in practice). As an example, consider the cell in which multicollinearity is 0.8 to 0.95, R 2 is 0.75, the weights of 11 and 12 are equal, and the sample size is relatively small (150 observations). In this case, <ref type="bibr" target="#b27">Mason and Perreault (1991)</ref> reported Type II error rates of 14% and 15% for 11 and 12 , respectively. We replicated these findings using our data-generation mechanism and SEM software (our figures were 15% and 16%, respectively). However, when reliability decreased to 0.9 (which most researchers would probably consider excellent), the error rates were 79% and 74%, respectively (Table <ref type="table" target="#tab_1">2</ref>). This vividly demonstrates the importance of reliable measurement for valid tests of theories, particularly when multicollinearity is high.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Avoiding Problems with Estimates Due to</head><p>Multicollinearity Because remedies for multicollinearity after the fact are of limited value, it would be wise for researchers to inoculate their studies against the harmful effects of excessive shared variance among the predictors. One recommendation is to include all-important influences on a dependent variable so that the R 2 's for all endogenous constructs are relatively high. Unfortunately, behavioral models often have low explanatory power <ref type="bibr" target="#b29">(Peterson et al. 1985)</ref>, so that this may not be an option. A more viable suggestion is to make sure that the sample size is adequate. In planning a study, researchers are admonished to consider the issue of expected effect sizes and determine the sample size needed to achieve reasonable levels of power <ref type="bibr" target="#b8">(Cohen 1992</ref><ref type="bibr" target="#b24">, MacCallum et al. 1996</ref>.</p><p>Probably the most important safeguard against the damaging effects of multicollinearity is to make sure that all constructs are measured as reliably as possible. It appears that there is no discrete cutoff between good and bad reliability. As reliability increases (even from 0.8 to 0.9 or higher), estimation accuracy improves and Type II errors go down. This finding means that researchers have to devote a lot of attention to measure development <ref type="bibr" target="#b31">(Rossiter 2003)</ref>. Prior to conducting a study, the construct has to be defined clearly, and then appropriate items have to be sampled from its domain. Because three to five good indicators of each construct should be available, prestudies are necessary to make sure that all items load highly on the intended construct, or additional measures should be included in the study so that a sufficient number of reliable items can be retained. Special care is necessary to distinguish reflective and formative measurement models, and to specify only reflective indicators as functions of underlying factors, because formative indicators are unlikely to achieve high internal consistency <ref type="bibr" target="#b18">(Jarvis et al. 2003)</ref>.</p><p>If these guidelines are not followed, there can be serious implications for theory testing, and even modest levels of multicollinearity will lead to high Type II errors rates. When Type II errors occur, researchers can easily derive misleading conclusions from their data (e.g., eliminate important variables from a model, ascribe the wrong sign or effect size to a variable), and inconsistencies across studies are likely.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Diagnosing and Controlling Potential</head><p>Multicollinearity Problems Commonly used methods for assessing the degree of multicollinearity, such as bivariate correlations, variance inflation factors, and condition numbers, were briefly discussed earlier. <ref type="bibr">7</ref> Here we will focus on a diagnostic that has not been discussed in the literature. The problem of multicollinearity is closely related to the issue of discriminant validity. If constructs are too highly correlated, they lack discriminant validity. Researchers who use SEM usually conduct measurement analyses prior to testing structural relationships, and often assess discriminant validity by testing whether the correlations (corrected for measurement error) among constructs differ from one. If this is not the case, multicollinearity is probably extreme, and the researcher will most <ref type="bibr">7</ref> For both the experiments, we examined the efficacy of condition numbers in signaling the cases impacted by multicollinearity. In Experiment 1, the mean condition number across all samples was 4.10 (median of 2.95). The maximum condition number was 53.16. Condition numbers greater than 30 occurred only in the highest multicollinearity condition. The correlations between the condition numbers and the Type II error rates for 11 , 12 , and 14 were 0.55, 0.48, and 0.22. In Experiment 2, the mean condition number across all samples was 2.25 (median of 2.02). The maximum condition number was 10.94. The correlations between the condition numbers and the Type II error rates for 11 and 12 were 0.46 and 0.44. <ref type="bibr" target="#b5">Belsley et al. (1980)</ref> suggest that condition indices of 5-10 indicate weak dependencies, and indices greater than 30 indicate moderate to strong dependencies. Thus, based on the condition numbers there are no strong dependencies in Experiment 2, but there are strong dependencies in the highest multicollinearity condition in Experiment 1.</p><p>Marketing Science 23(4), pp. 519-529, © 2004 INFORMS likely respecify the model because the distinct conceptual status of the constructs in question is questionable <ref type="bibr" target="#b1">(Anderson and Narus 1984)</ref>. It is therefore unlikely that structural equation models will contain constructs that are very highly correlated. However, correlations in the 0.7 or 0.8 range are fairly common, and they will probably be distinct from one. <ref type="bibr" target="#b12">Fornell and Larcker (1981a)</ref> have proposed another test of discriminant validity that is more demanding and involves comparing the squared correlation between two constructs to the average variance extracted statistic. The idea is that a construct should be more closely related to its own indicators than to other constructs. Since average variance extracted is a measure of reliability, and since multicollinearity and reliability are the two major influences on estimation accuracy and inference errors, the question arises whether the Fornell and Larcker discriminant validity criterion can be used to flag cases of severe multicollinearity. Using the data from the second experiment, we calculated whether 1 and 2 achieved discriminant validity and cross-classified this variable with Type II errors for 11 and 12 . Overall, the correlations between the two variables for 11 and 12 were −0.43 and −0.38, respectively. Thus, as expected inference errors were less likely when discriminant validity was achieved. Specifically, when the two constructs were distinct, the Type II error rates were only 5% and 9% for 11 and 12 , respectively. On the other hand, when 1 and 2 lacked discriminant validity, a Type II error occurred in 39% and 42% of the cases, respectively. These findings show that if the Fornell and Larcker criterion is satisfied, an inference error is unlikely. However, when the criterion is not satisfied, it does not necessarily mean that the chance of committing a Type II error is high.</p><p>If multicollinearity does create estimation problems, we recommend that SEM be used to conduct a measurement analysis and to obtain a covariance matrix among the latent constructs. The estimated covariance matrix can then be used as input into other data-analytic techniques that are more robust to multicollinearity, such as ridged partial least squares <ref type="bibr" target="#b17">(Jagpal 1982)</ref>. Preliminary evidence suggests that estimates of bivariate relationships between constructs are not adversely affected by multicollinearity. Specifically, we conducted an analysis in which CFA models were fit to the data from Experiment 2. We then compared the estimated correlations (as indicated in the standardized matrix) with the population values. Out of 15 possible comparisons, multicollinearity was significant in only five cases, and even then it accounted for at most 3% of the inaccuracy in the estimated correlations. Thus, as one might have expected a priori, multicollinearity does not seem to adversely affect the accuracy of estimated bivariate relationships among constructs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Limitations</head><p>Because of the complexity of structural equation models, there are many possible factors that might affect parameter estimation under conditions of multicollinearity. Our goal was to examine some basic factors affecting simple models. However, to fully understand the degree to which multicollinearity will affect estimates, additional factors and levels within these factors would need to be examined. For example, we have only examined models in which all indicators have similar levels of reliability. It is unclear how differences in measure reliability across constructs affect estimation, or whether nonuniform loadings on a construct lead to different results. Our findings will also have to be extended to other types of models. Complexities such as multigroup models, nonnormal distributions, nonrecursive models, and second-order factors may further complicate the effects of multicollinearity. In order to fully document the effects of multicollinearity, it may be necessary to develop a host of tables that are unique to various model conditions and structures.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Conclusion</head><p>We attempted to identify conditions that allow researchers to avoid the problems associated with multicollinearity in SEM. Our main conclusion is that good measure reliability, a model whose explanatory power is high, and a large sample size can effectively protect against the deleterious effects of multicollinearity unless the multicollinearity is severe. Since multicollinearity is not easily remedied once it is present (it is ultimately a data problem, in the sense that two or more "independent" variables do not have sufficient independent variation, rather than an estimation problem), and since deficiencies on other factors lead to nonnegligible inference errors even when multicollinearity is not particularly high, it behooves the researcher to pay careful attention to the conditions known to mitigate multicollinearity problems prior to conducting a study.</p><p>In the past, researchers have often assumed that because SEM takes into account measurement error and corrects paths for attenuation, measure unreliability is less of a problem. Our findings clearly show that this assumption is not warranted. Although SEM is better than techniques such as regression, which do not consider measurement error and therefore lead to inconsistent parameter estimates, measurement error strongly affects estimation accuracy for both coefficients and standard errors, and, as a consequence, increases the likelihood of Type II errors. Even when reliability is fairly high by conventional standards, measurement error can be damaging. Thus, nothing substitutes for good quality measures, and researchers should make every attempt to use reliable measures 529 that are discriminant from other constructs. Of course, the worst scenario is a situation in which a single item is employed to measure a construct and the presumed objectivity of the measure (e.g., the amount of sales and expenditures or other kinds of secondary data) is used to justify the lack of multi-item measurement. In this case, unreliability of measurement cannot even be assessed, and the damaging effects of unreliability are completely hidden.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>.0 79.0 93.5 99.0 50.5 72.5 92.0 99.5 77.5 80.0 82.5 88.5 37.5 62.5 89.0 99.0 79.0 88.5 94.5 99.5 75.5 78.0 81.5 87.5 REL=0.8 39.5 60.0 82.0 99.5 35.5 51.5 79.5 99.0 65.0 67.5 72.0 82.0 19.0 39.5 73.5 98.5 62.5 79.5 92.0 99.0 63.5 65.0 70.0 80.5 REL=0.9 21.0 41.5 69.0 97.5 17.0 39.5 63.0 96.0 53.5 56.0 59.0 67.5 7.5 17.5 48.5 95.5 47.5 65.0 81.5 97.0 51.0 53.5 55.5 64.5 Model R 2 = 0.5 REL=0.7 26.5 49.0 82.0 98.5 20.5 42.5 77.0 99.0 47.0 52.0 62.5 76.0 8.5 28.5 68.0 98.5 50.0 65.0 88.5 99.0 44.5 49.5 58.5</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Analysis of Variance Results for Estimates of Path Coefficients and Standard ErrorsNote. Only main effects are shown for simplicity.</figDesc><table><row><cell>Experiment 1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="5">% Variance explained in coefficient estimate</cell><cell></cell><cell></cell><cell cols="6">% Variance explained in estimate of standard error</cell><cell></cell></row><row><cell cols="2">Sources of variance</cell><cell>11</cell><cell>12</cell><cell></cell><cell>13</cell><cell></cell><cell>14</cell><cell></cell><cell>11</cell><cell></cell><cell>12</cell><cell>13</cell><cell></cell><cell></cell><cell>14</cell><cell></cell></row><row><cell>Overall model</cell><cell></cell><cell>32 07 a</cell><cell>33 80 a</cell><cell></cell><cell>21 35 a</cell><cell></cell><cell>12 39 a</cell><cell></cell><cell>71 31 a</cell><cell></cell><cell>71 36 a</cell><cell>53 48 a</cell><cell></cell><cell></cell><cell>40 96 a</cell><cell></cell></row><row><cell>Multicollinearity</cell><cell></cell><cell>22 38 a</cell><cell>24 21 a</cell><cell></cell><cell>8 61 a</cell><cell></cell><cell>0 39 a</cell><cell></cell><cell>52 01 a</cell><cell></cell><cell>52 37 a</cell><cell>24 83 a</cell><cell></cell><cell></cell><cell>8 46 a</cell><cell></cell></row><row><cell>Reliability</cell><cell></cell><cell>3 53 a</cell><cell>2 85 a</cell><cell></cell><cell>3 83 a</cell><cell></cell><cell>2 83 a</cell><cell></cell><cell>11 77 a</cell><cell></cell><cell>10 37 a</cell><cell>14 00 a</cell><cell></cell><cell></cell><cell>17 92 a</cell><cell></cell></row><row><cell>R-Square</cell><cell></cell><cell>4 54 a</cell><cell>5 86 a</cell><cell></cell><cell>6 90 a</cell><cell></cell><cell>6 70 a</cell><cell></cell><cell>2 41 a</cell><cell></cell><cell>2 27 a</cell><cell>4 03 a</cell><cell></cell><cell></cell><cell>4 47 a</cell><cell></cell></row><row><cell cols="2">Coefficient weights</cell><cell>0 00</cell><cell>0 00</cell><cell></cell><cell>0 02 d</cell><cell></cell><cell>0 02 d</cell><cell></cell><cell>0 01 b</cell><cell></cell><cell>0 00</cell><cell>0 01</cell><cell></cell><cell></cell><cell>0 05 a</cell><cell></cell></row><row><cell>Sample size</cell><cell></cell><cell>1 11 a</cell><cell>0 52 a</cell><cell></cell><cell>1 64 a</cell><cell></cell><cell>2 08 a</cell><cell></cell><cell>2 84 a</cell><cell></cell><cell>4 32 a</cell><cell>8 31 a</cell><cell></cell><cell></cell><cell>6 98 a</cell><cell></cell></row><row><cell>Experiment 2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sources of</cell><cell></cell><cell cols="6">% Variance explained in coefficient estimate</cell><cell></cell><cell cols="7">% Variance explained in estimate of standard error</cell><cell></cell></row><row><cell>variance</cell><cell>11</cell><cell>12</cell><cell>13</cell><cell>21</cell><cell>22</cell><cell>23</cell><cell>13</cell><cell>23</cell><cell>11</cell><cell>12</cell><cell>13</cell><cell>21</cell><cell>22</cell><cell>23</cell><cell>13</cell><cell>23</cell></row><row><cell>Overall model</cell><cell cols="16">20 05 a 20 66 a 16 56 a 15 61 a 16 70 a 12 38 a 13 10 a 8 96 a 83 11 a 83 77 a 85 53 a 70 62 a 73 79 a 80 67 a 82 96 a 83 81 a</cell></row><row><cell cols="7">Multicollinearity 5 41 a 6 48 a 0 19 a 2 77 a 4 04 a 0 02</cell><cell>0 00</cell><cell cols="9">0 08 b 24 82 a 25 80 a 1 56 a 12 18 a 16 02 a 0 12 a 0 03 a 0 67 a</cell></row><row><cell>Reliability</cell><cell cols="16">7 30 a 6 37 a 4 37 a 7 90 a 7 99 a 7 07 a 5 20 a 4 30 a 27 08 a 26 80 a 25 23 a 40 00 a 36 25 a 45 84 a 44 85 a 41 80 a</cell></row><row><cell>R-Square</cell><cell cols="16">5 11 a 5 56 a 8 26 a 2 03 a 2 15 a 2 46 a 2 23 a 2 19 a 21 27 a 21 26 a 43 40 a 5 47 a 8 26 a 18 25 a 19 10 a 20 88 a</cell></row><row><cell>Sample size</cell><cell cols="16">1 92 a 2 00 a 3 43 a 2 25 a 2 08 a 2 64 a 5 52 a 2 23 a 8 87 a 8 80 a 14 46 a 9 97 a 10 04 a 14 91 a 18 17 a 19 50 a</cell></row></table><note>a p &lt; 0 001 (F-test). b p &lt; 0 005 (F-test). c p &lt; 0 010 (F-test). d p &lt; 0 050 (F-test).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 Percentage</head><label>2</label><figDesc></figDesc><table /><note>of Type II Error Rates: Experiment 1 *</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 Percentage</head><label>3</label><figDesc></figDesc><table><row><cell>Collinearity level</cell><cell>Collinearity level</cell><cell>Collinearity level</cell><cell>Collinearity level</cell><cell>Collinearity level</cell><cell>Collinearity level</cell></row><row><cell>2</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>of Type II Error Rates: Experiment 2 * 11</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">During this period Marketing Science had only one article that used SEM. Thus, we decided not to include Marketing Science in the survey.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">It should be noted that removing measurement error can sometimes reduce correlations (for examples of such cases see  Buckley 1988, Fornell and<ref type="bibr" target="#b13">Larcker 1981b)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">For example,<ref type="bibr" target="#b14">Grapentine (2000)</ref> found that a correlation of 0.66 between two constructs increased to 0.95 after correcting for measurement error.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">A technical appendix, available either from the authors on request or the Marketing Science website, details the data-generation framework.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Marketing Science 23(4), pp.519-529, © 2004 INFORMS   </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">As the data for accuracy of the coefficients and standard errors were not normal, we applied a natural logarithm transformation before conducting the analysis of variance.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">and 2 was 0.95, and it was in this condition that the inaccuracy in the estimates of the path coefficients and standard errors was most pronounced. In the second experiment, in which the highest correlation between 1 and 2 was "only" 0.80, multicollinearity, although still an important influence on the accuracy of the estimation results, generally played a less pronounced role (Table1). Even in this case, most of</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors contributed equally. The authors appreciate helpful feedback from Donald R. Lehmann (Columbia University) and Edward E. Rigdon (Georgia State University). The article benefited from the feedback of the editor, the associate editor, and three anonymous Marketing Science reviewers.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">The effects of sampling error on convergence, improper solutions, and goodnessof-fit indices for maximum likelihood confirmatory factor analysis</title>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">C</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>David</surname></persName>
		</author>
		<author>
			<persName><surname>Gerbing</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="155" to="173" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A model of the distributor&apos;s perspective of distributor-manufacturer working relationships</title>
		<author>
			<persName><forename type="first">James</forename><forename type="middle">C</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>James</surname></persName>
		</author>
		<author>
			<persName><surname>Narus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="page" from="62" to="74" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A hierarchical Bayesian methodology for treating heterogeneity in structural equation models</title>
		<author>
			<persName><forename type="first">Asim</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kamel</forename><surname>Jedidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Jagpal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="328" to="347" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">The evaluation of structural equation models and hypothesis testing. Principles of Marketing Research</title>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">P</forename><surname>Bagozzi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans</forename><surname>Baumgartner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Blackwell Publishers</publisher>
			<biblScope unit="page" from="386" to="422" />
			<pubPlace>Oxford, England</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Applications of structural equation modeling in marketing and consumer research: A review</title>
		<author>
			<persName><forename type="first">Hans</forename><surname>Baumgartner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Christian</forename><surname>Homburg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Res. Marketing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="139" to="161" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Regression Diagnostics: Identifying Influential Data and Sources of Collinearity</title>
		<author>
			<persName><forename type="first">D</forename><surname>Belsley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Kuh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Welsch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<author>
			<persName><forename type="first">Peter</forename><forename type="middle">M</forename><surname>Bentler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Eric</surname></persName>
		</author>
		<author>
			<persName><surname>Wu</surname></persName>
		</author>
		<title level="m">EQS for Windows</title>
				<meeting><address><addrLine>Encino, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Multivariate Software, Inc</publisher>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Structural Equations and Latent Variables</title>
		<author>
			<persName><forename type="first">Kenneth</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>John Wiley &amp; Sons Inc</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A power primer</title>
		<author>
			<persName><forename type="first">Jacob</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Bull</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="155" to="159" />
			<date type="published" when="1992-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Estimating trait, method, and error variance: Generalizing across 70 construct validation studies</title>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Cote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Ronald</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="315" to="318" />
			<date type="published" when="1987-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Measurement error and theory testing in consumer research: An illustration of the importance of construct validation</title>
		<author>
			<persName><forename type="first">Joseph</forename><forename type="middle">A</forename><surname>Cote</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Ronald</forename><surname>Buckley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="579" to="582" />
			<date type="published" when="1988-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Designing the next best study for maximum impact</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">U</forename><surname>Farley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Donald</surname></persName>
		</author>
		<author>
			<persName><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lane</surname></persName>
		</author>
		<author>
			<persName><surname>Mann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="496" to="501" />
			<date type="published" when="1998-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Evaluating structural equation models with unobservable variables and measurement error</title>
		<author>
			<persName><surname>Fornell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">F</forename><surname>Claes</surname></persName>
		</author>
		<author>
			<persName><surname>Larcker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="39" to="50" />
			<date type="published" when="1981-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Structural equation models with unobservable variables and measurement error: Algebra and statistics</title>
		<author>
			<persName><surname>Fornell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">F</forename><surname>Claes</surname></persName>
		</author>
		<author>
			<persName><surname>Larcker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="382" to="388" />
			<date type="published" when="1981-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Path analysis vs. structural equation modeling</title>
		<author>
			<persName><forename type="first">Terry</forename><surname>Grapentine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="12" to="20" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Problems in path analysis and causal inference</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Heise</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methodology. Jossey-Bass</title>
		<editor>E. F. Borgatta</editor>
		<imprint>
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Use of causal models in marketing research: A review</title>
		<author>
			<persName><forename type="first">John</forename><surname>Hulland</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Yiu</forename><surname>Ho Chow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Shunyin</forename><surname>Lam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Res. Marketing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="181" to="197" />
			<date type="published" when="1996-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Multicollinearity in structural equation models with unobservable variables</title>
		<author>
			<persName><forename type="first">Harsharanheet</forename><forename type="middle">S</forename><surname>Jagpal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="431" to="439" />
			<date type="published" when="1982-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">A critical review of construct indicators and measurement model misspecification in marketing and consumer research</title>
		<author>
			<persName><forename type="first">Cheryl</forename><surname>Jarvis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Scott</forename><forename type="middle">B</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Philip</forename><forename type="middle">M</forename><surname>Mackenzie</surname></persName>
		</author>
		<author>
			<persName><surname>Podsakoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="199" to="218" />
			<date type="published" when="2003-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Finite-mixture structural equation models for response-based segmentation and unobserved heterogeneity</title>
		<author>
			<persName><surname>Jedidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Harsharanjeet</forename><forename type="middle">S</forename><surname>Kamel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Wayne</forename><forename type="middle">S</forename><surname>Jagpal</surname></persName>
		</author>
		<author>
			<persName><surname>Desarbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="59" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Estimator conditioning diagnostics for covariance structure models</title>
		<author>
			<persName><forename type="first">David</forename><surname>Kaplan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="200" to="229" />
			<date type="published" when="1994-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A Guide to Econometrics</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Kennedy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>MIT Press</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Correlation and Causality</title>
		<author>
			<persName><forename type="first">David</forename><forename type="middle">A</forename><surname>Kenny</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The equity estimator for marketing research</title>
		<author>
			<persName><forename type="first">Lakshman</forename><surname>Krishnamurthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Arvind</forename><surname>Rangaswamy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="336" to="357" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Power analysis and determination of sample size for covariance structure modeling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Maccallum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">W</forename><surname>Browne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Sugawara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Methods</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="130" to="149" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Marketing research: A state-of-the-art review and directions for the twenty-first century</title>
		<author>
			<persName><forename type="first">Naresh</forename><forename type="middle">K</forename><surname>Malhotra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Mark</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Susan</forename><forename type="middle">Bardi</forename><surname>Kleiser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acad. Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="160" to="183" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Basics of Structural Equation Modeling</title>
		<author>
			<persName><forename type="first">Geoffrey</forename><forename type="middle">M</forename><surname>Maruyama</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<pubPlace>Sage, Thousand Oaks, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Collinearity, power, and interpretation of multiple regression analysis</title>
		<author>
			<persName><forename type="first">Charlotte</forename><forename type="middle">H</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>William</surname></persName>
		</author>
		<author>
			<persName><surname>Perreault</surname><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="268" to="280" />
			<date type="published" when="1991-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Monte Carlo experiments: Design and implementation. Structural Equation Model</title>
		<author>
			<persName><forename type="first">Pamela</forename><surname>Paxton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Patrick</forename><forename type="middle">J</forename><surname>Curran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Kenneth</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jim</forename><surname>Kirby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Feinian</forename><surname>Chen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="287" to="312" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A meta-analysis of effect sizes in consumer behavior experiments</title>
		<author>
			<persName><forename type="first">Robert</forename><forename type="middle">A</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gerald</forename><surname>Albaum</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">F</forename><surname>Beltramini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="97" to="103" />
			<date type="published" when="1985-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Structural equation models: Empirical identification, heywood cases, and related problems</title>
		<author>
			<persName><forename type="first">David</forename><surname>Rindskopf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociological Methods Res</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="109" to="119" />
			<date type="published" when="1984-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The C-OAR-SE procedure for scale development in marketing</title>
		<author>
			<persName><forename type="first">John</forename><forename type="middle">R</forename><surname>Rossiter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Res. Marketing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="305" to="335" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">The problem of multicollinearity in a multistage causal alienation model: A comparison of ordinary least squares, maximum-likelihood, and ridge estimators</title>
		<author>
			<persName><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Edward</forename><forename type="middle">N</forename><surname>Peter</surname></persName>
		</author>
		<author>
			<persName><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quality Quantity</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="267" to="297" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">On the use of structural equation models for marketing modeling</title>
		<author>
			<persName><forename type="first">Jan</forename><forename type="middle">-</forename><surname>Steenkamp</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Benedict</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hans</forename><surname>Baumgartner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Res. Marketing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="195" to="202" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Sales call anxiety: Exploring what it means when fear rules a sales encounter</title>
		<author>
			<persName><forename type="first">Willem</forename><surname>Verbeke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Richard</forename><forename type="middle">P</forename><surname>Bagozzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="88" to="101" />
			<date type="published" when="2000-07" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
