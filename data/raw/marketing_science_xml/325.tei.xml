<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Buffer Effect: The Role of Color When Advertising Exposures Are Brief and Blurred</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-10-17">October 17, 2014.</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Michel</forename><surname>Wedel</surname></persName>
							<email>mwedel@rhsmith.umd.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Marketing</orgName>
								<orgName type="department" key="dep2">Robert H. Smith School of Business</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park, Maryland</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Rik</forename><surname>Pieters</surname></persName>
							<email>pieters@uvt.nl</email>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Marketing</orgName>
								<orgName type="department" key="dep2">School of Economics and Management</orgName>
								<orgName type="institution">Tilburg University</orgName>
								<address>
									<postCode>5000 LE</postCode>
									<settlement>Tilburg, Tilburg</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Buffer Effect: The Role of Color When Advertising Exposures Are Brief and Blurred</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
						<imprint>
							<date type="published" when="2014-10-17">October 17, 2014.</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.2014.0882</idno>
					<note type="submission">Received: November 23, 2012; accepted: August 18, 2014</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>advertising</term>
					<term>gist perception</term>
					<term>drift diffusion model</term>
					<term>Bayesian ANOVA</term>
					<term>color</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>W hat is the role that color plays in consumers' perception of the gist of ads during the increasingly brief and blurred exposures in practice? Two studies address this question. The first study manipulates the level of blur of the exposure and the presence or absence of color in the ad image, during exposures that lasted 100 milliseconds (msec). It reveals a buffer effect of color: color contributes little to gist perception when sufficient visual detail is available and ads are typical, but color enables consumers to continue to perceive the gist of ads accurately when the exposure is blurred. The second study finds that color inversion of the entire ad deteriorates gist perception, but that color inversion of the background scene does not affect gist perception when the exposure is blurred. This provides evidence that the color composition of the central object in the ad scene plays a key role in protecting the gist perception of advertising under adverse exposure conditions. The underlying mechanism is likely to be cognitive rather than sensory. Implications for advertising theory and design are discussed.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Imagine yourself standing in Times Square. You are bombarded with hundreds of colorful outdoor advertisements. You see most of them only at a distance and in the periphery of your vision, skimming them only briefly. Under these challenging conditions ads need to cut through and communicate their gist rapidly. Which types of ads do so? There is a pervasive belief among both advertising academics and professionals that color is critical in the first moment that ads make contact with consumers. One practitioner put it as follows: "Color is sure to play a key role in the success of your venture. After all, it's pretty much the first thing your consumers will notice." 1 Indeed, color was the dominant feature affecting the effectiveness of outdoor advertising in a large eye tracking study. <ref type="bibr">2</ref> Questions on the role of color during limited exposures are pertinent to many other advertising media as well. Eye tracking studies have shown such limited exposures not 1 http://www.advertisingideaspro.com/what-color-is-your-advertising -how-color-theory-can-make-your-marketing-more-effective.html, accessed August 19, 2014. 2 http://www.truckads.com/pdf-bin/EyeTrackingStudy.pdf, accessed August 19, 2014.</p><p>only for outdoor advertising but also for billboards in sports games, banner ads on websites, ads in magazines and newspapers, product placements in TV shows, commercials while zapping or fast forwarding, in-app advertising, and ads in video games (see <ref type="bibr" target="#b20">Wedel and Pieters 2008)</ref>.</p><p>At the very first moment of contact, before consumers even comprehend the message of an ad, they have to grasp its gist. That is, they need to quickly understand whether an image is an ad or something else, and if it is an ad, which product category and brand are being advertised <ref type="bibr" target="#b15">(Pieters and Wedel 2012)</ref>. Getting the gist of their ads across is increasingly challenging for advertisers because most ads do not receive more than a brief glance from consumers. The attention span of consumers is reported to have decreased by as much as 50% in the last decade. <ref type="bibr">3</ref> On top of that, these brief exposures are often blurred because they occur in motion, in the periphery of vision, under low lighting conditions, and/or at larger distances. Advertising professionals are well aware of these issues. As one expert states "If we can communicate the brand and its value, even through "blurred" peripheral vision, then we will be much more effective" <ref type="bibr">(Barden 2013, p. 73)</ref>.</p><p>Although the common belief is that color is critical, no research has yet investigated the proposition that color helps ads to quickly communicate their meaning during brief and blurred exposures. The present study aims to fill that gap. Our research does not address whether consumers have preferences for, or associate meanings with specific colors, about which much is known <ref type="bibr" target="#b8">(Labrecque et al. 2013)</ref>. The key question addressed here is whether and how color schemes influence consumers' rapid gist perception of ads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Color and Gist Perception of Advertising</head><p>Gist perception is the process of rapidly acquiring a holistic semantic representation of a scene: the essential meaning of the scene in terms of the categories that it belongs to <ref type="bibr" target="#b6">(Grill-Spector and Kanwisher 2005)</ref>, such as whether it is an ad or something else, is for cars or food, and for Ford or Lexus. Knowing that something is a Lexus car ad tells consumers whether or not the ad is relevant for them and whether it requires further attention or not <ref type="bibr" target="#b15">(Pieters and Wedel 2012)</ref>. It is tempting to assume that color may play a key role in this process. However, color has been found to have surprisingly little effect on rapid object recognition <ref type="bibr" target="#b2">(Biederman and</ref><ref type="bibr">Ju 1988, Wurm et al. 1993)</ref>, and research on the role of color in scene gist perception has yielded inconsistent findings. Some studies have found an overall positive effect of color on rapid scene perception <ref type="bibr">Rieger 2000, Wichmann et al. 2002)</ref>, but other studies report a positive effect only for certain scenes <ref type="bibr" target="#b14">(Oliva and Schyns 2000)</ref>, only on people's confidence in classifying scenes <ref type="bibr" target="#b25">(Yao and Einhäuser 2008)</ref>, or find no effect at all <ref type="bibr" target="#b18">(Rousselet et al. 2005)</ref>. This literature thus provides limited guidance in predicting the effect of color on gist perception of advertising. Color may operate via two possible mechanisms, sensory or cognitive <ref type="bibr" target="#b23">(Wu et al. 2014)</ref>. The sensory (bottom-up) color mechanism operates as follows. When exposure conditions limit the details that are visible in an ad, the boundaries of objects and regions disappear. Color may then help to delineate these boundaries, help consumers in perceiving the global layout of the ad scene, and separate objects from the background (a black car in an ad stands out from a green background even if exposure is brief or in the periphery). Color is processed independently from other sensory features such as edges and shapes <ref type="bibr" target="#b7">(Hanna and</ref><ref type="bibr">Remington 1996, Livingstone and</ref><ref type="bibr" target="#b10">Hubel 1987)</ref> and is added to the mental representation of the scene after the scene is segmented based on these other features. Then, color supports gist perception only when the image is degraded or ambiguous <ref type="bibr" target="#b21">(Wichmann et al. 2002)</ref>. This "color segmentation" mechanism implies that color has a buffering effect on gist perception of ads: it helps gist perception mostly under blurred exposure conditions.</p><p>The cognitive (top-down) mechanism works differently. Here, color helps gist perception because it is diagnostic for the ad and the category that is advertised (the blue color of the sky and the green color of the tree covered mountains have specific meanings and may be part of the memory representation of a typical car ad). Diagnostic colors could thus universally help to improve gist perception of ads. This is however not what is suggested by the literature. In their research on simple object recognition, <ref type="bibr" target="#b2">Biederman and Ju (1988)</ref> find evidence that a diagnostic color is a secondary perceptual feature that contributes to object recognition only when primary information about the shape of objects is degraded. <ref type="bibr" target="#b12">Mapelli and Behrmann (1997)</ref> reach a similar conclusion based on studies of a patient with agnosia. They find that color only supports object recognition if shape cues are ambiguous, and they conclude that color has a cognitive, not a sensory effect. It is presently unknown if these results extend to scene perception (mental representations of objects and scenes are quite different), but if they do, this "color diagnosticity" mechanism would support gist perception of ads under blurred exposure conditions (the coarse configuration of blue, green, and black color blobs may be sufficient to identify the ad as a car ad). To summarize, both the color segmentation and the color diagnosticity mechanisms suggest that under normal conditions color contributes little but that it buffers against detrimental effects of blurred and otherwise degraded exposures. But, the segmentation mechanism implies that any color can help to segment and thus to perceive the blurred scene, whereas the diagnosticity mechanism implies that the colors need to be diagnostic to act as a buffer.</p><p>Most gist perception research to date has used typical objects and scenes, but advertising often contains atypical objects and scenes, and the question is which role color schemes play there. A category of ads, such as "car ads," is represented in memory through a prototype: the mode of all exemplars of the category that have been experienced though repeated exposure <ref type="bibr" target="#b16">(Rosch 1973)</ref>. Typical ads come to mind faster (Grill-Spector and Kanwisher 2005) and require fewer resources to process <ref type="bibr" target="#b13">(Meyers-Levy and Peracchio 1995)</ref>. The memory representations of typical ads contain the spatial layout of the scene as well as one or more central diagnostic objects <ref type="bibr" target="#b0">(Bar 2004</ref><ref type="bibr" target="#b3">, Friedman 1979</ref><ref type="bibr" target="#b18">, Rousselet et al. 2005</ref>. Typical car ads often feature a car front and center; typical financial Marketing Science 34(1), pp. 134-143, © 2015 INFORMS ads often contain male service providers; typical skincare and fragrance ads mostly show a large pictorial of a female face or body in close-up. It has been debated whether scene gist perception results from the identification of a diagnostic object that is recognized first, or whether perception of the coarse scene layout precedes and facilitates object recognition, or that both occur simultaneously <ref type="bibr" target="#b0">(Bar 2004</ref><ref type="bibr" target="#b23">, Wu et al. 2014</ref>. The central diagnostic object in a typical ad may prime an ad schema that facilitates perception of the gist of the ad <ref type="bibr" target="#b3">(Friedman 1979</ref><ref type="bibr" target="#b0">, Bar 2004</ref>). When color is a diagnostic feature it may help in identifying the central object. But, when the central object is noncolor diagnostic, its color is an ambiguous cue that provides meaning only in the presence of coherent diagnostic cues in the ad, in particular the global layout of the ad and/or coarse color "blobs" in the ad scene (because car colors are not unique, the black color becomes diagnostic for a car only because the global layout of the ad is typical and contains blue sky and green mountains). The color scheme of the central object and/or background scene may or may not be part of the memory representation of a typical ad, depending on the extent to which it is shared among exemplars to which people are exposed <ref type="bibr" target="#b17">(Rosch and Mervis 1975</ref>). An ad may have a typical layout but an atypical color scheme (for example a car ad with a typical layout may show a yellow car), and layout and color are processed independently <ref type="bibr">(Bar 2004, Hanna and</ref><ref type="bibr" target="#b7">Remington 1996)</ref>. Atypical ads on the other hand, do not contain a central object and more often contain objects and color schemes that violate the expected ad schema. Processing these requires a slower and more extensive analysis. This may not be possible when the exposure is brief and/or blurred.</p><p>Thus, we predict that color does not in general have a main positive effect on gist perception of advertising, but that it protects gist perception of typical and not of atypical ads against the detrimental effects of blurring. Two studies were conducted to test these predictions. In addition, the studies examine two mechanisms-segmentation and diagnosticitythat may explain the buffer effect of color on gist perception of ads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Study 1</head><p>3.1. Procedures One hundred sixteen paid undergraduate students (53 men; mean age 23, ranging from 21 to 28) were randomly assigned to one condition of a 5 (blur: normal, low, medium, high, very high) × 2 (color: full color, grayscale) between-participants, × 2 (image: typical ads, atypical ads) within-participants, mixed design. Participants were exposed to 40 images, 32 ads and eight editorial pages. There were eight ads per product category, with four typical and four atypical ones, the categories being cars, financial services, food, and skincare. The stimuli were obtained from <ref type="bibr" target="#b15">Pieters and Wedel (2012)</ref>. The editorial pages were included as (20%) foils in the task. Image order was counterbalanced.</p><p>Typical (atypical) ads were selected based on their similarity (dissimilarity) to typical ads in a memory reproduction task. A sample of 38 trained judges (graduate students, 16 males) assessed the effectiveness of the classification of the 32 (full color) ads as typical and atypical on three five-point scales (reliability was 0.71). The classification of ads as typical and atypical was supported by a significant difference in perceived typicality for each product category (all p &gt; 0 001). Whereas typical ads are significantly more representative for their categories than atypical ones, typicality is a matter of degree and is to some extent idiosyncratic. Nonetheless, we will use the terminology "typical/atypical" in the remainder. Standard image processing software was used to manipulate the images of the ads. Images were left unchanged in the "normal" condition. Grayscale images were produced with 256 gray levels (8-bit). Images with five different levels of blur were produced with a Gaussian blur filter, with a radius of, respectively, four pixels (low), eight pixels (medium), 12 pixels (high), and 24 pixels (very high).</p><p>Participants sat in normally lit, individual cubicles, approximately 20-24 inches from a 17-inch computer screen with a maximum resolution of 1,024 × 768 pixels. The images were shown centrally, with a display area subtending approximately 20 (horizontal) and 26 (vertical) of visual angle at the viewing distance. Participants read the instructions on the screen and engaged in a practice trial, after which the data collection started. A fixation-cross (about 0.1 of visual angle) appeared for 900 msec. on the screen. Then an image was presented for 100 msec., which is well above the awareness threshold but insufficient to make multiple eye fixations. We choose exposures of 100 msec., because these reveal most distinctive effects of the image manipulations and have been used in prior gist perception research <ref type="bibr" target="#b15">(Pieters and Wedel 2012)</ref>. Note that the exposure time manipulation affects the duration of the visual input, but not the duration of processing that will continue beyond the exposure itself.</p><p>Immediately after image presentation, question 1 appeared on the screen: "Is it an advertisement or editorial?" along with two possible responses, which participants could select by a mouse click. Participants confirmed their response by clicking the "continue" button on the screen. If participants selected "editorial," a black screen appeared for 300 msec., after which a new trial began. If they selected "advertisement," a new screen appeared with question 2: "To which category does the ad belong?" with the response alternatives being, respectively, car, financial services, food, and skincare, which they could select by a mouse click and confirm by clicking on the continue button. Finally, a black screen appeared, and a new trial began. The number of accurate responses across categories and brands was recorded for both questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Analyses</head><p>We use a Bayesian approach to ANOVA <ref type="bibr" target="#b5">(Gelman 2005)</ref>. Relative to the standard ANOVA procedure, the Bayesian approach offers several welldocumented advantages. It provides accurate inferences based on finite samples of participants, accounts for distributional properties, and accommodates heterogeneity across individuals. Let i = 1 I denote individuals and j = 1 J denote ads. We are interested in the effects of the factors typical/atypical (T), color/grayscale (C), blur (B), and their interactions. The factor T varies within individuals. Let l j = 1 2 denote its level for ad j, with L = 16 ads for each level of T. We analyze the number of correct identifications of the ad, y a i l j , and the number of correct identifications of the product category, given the number of correct ad identifications, y c i l j . We assume these to follow binomial distributions, y a i l j ∼ Bin p a i l j L and y c i l j ∼ Bin p c i l j y a i l j . The within-participants models are specified as logit p a i l j</p><formula xml:id="formula_0">= 0 i + T i l j logit p c i l j = 0 i + T i l j (1)</formula><p>The parameters 0 i and 0 i are the constants. The parameters T i l j and T i l j represent the effects of the factor T (typical/atypical). We set T i 1 = 0, and T i 1 = 0, so that all effects are expressed relative to the original ad images. We index all parameters in Equation (1) by = 1 P , and collect them in i = i 1 P and i = i 1 P .</p><p>We account for heterogeneity in the withinparticipant effects in Equation ( <ref type="formula">1</ref>), and model the between-participant effects of the factors blur, color, and the B × C interaction as</p><formula xml:id="formula_1">i p = 0 p + B p m i + C p n i + BC p m i n i + i p i p = 0 p + B p m i + C p n i + BC p m i n i + i p (2)</formula><p>This equation contains all main and interaction effects of interest. The parameters 0 p and 0 p represent the population means of i p and i p in Equation (1). The parameters B p m i and B p m i represent the effects of blur on i p and i p , where m i is blur-level m for individual i. The parameters C p n i and C p n i represent the  effects of color, where n i is color level n for individual i. Finally, the parameters BC p m i n i and BC p m i n i represent the interaction effects of blur and color on i p and i p .</p><formula xml:id="formula_2">Because C p 1 = 0, C p 1 = 0, BC p m i 1 = 0, BC p 1 n i = 0, BC</formula><p>p m i 1 = 0, and BC p 1 n i = 0, all effects are relative to the original ad images.</p><p>For blur, rather than estimating four parameters, parsimonious contrasts are specified that are linear in the logarithm of the radius of the Gaussian blur filter, rescaled such that normal images have a value of zero (B m i B p m i = B p B m i and B p m i = B p B m i . This facilitates interpretation because all effects are now relative to the normal (nonblurred) ads. Similarly, for the B × C interactions we have BC p m i n i = BC p n i B m i and BC p m i n i = BC p n i B m i . The assumed distribution of the error terms is i p ∼ N 0 2 p and i p ∼ N 0 2 p . The models are estimated with WinBugs <ref type="bibr" target="#b11">(Lunn et al. 2000)</ref>. We report the posterior means, standard deviations, and Bayesian p-values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Results and Discussion</head><p>Table <ref type="table" target="#tab_1">1</ref> presents the results. Ad and category identification are significantly influenced by ad typicality (T): typical ads are identified more accurately as ads and their category is more accurately identified, as compared to atypical ads. The accuracy of ad and category identification is negatively affected by the degree of blur (B). There is no significant main effect of removing color (C): gist perception of normal color images is as accurate as that of grayscale images. However, and in support of the predictions, the interactions of color with blur (B × C) (only for ad identification) and typicality with blur (B × T), and the three-way interaction (B × C × T), are significant for both ad and category identification. These interaction effects are represented in Figure <ref type="figure" target="#fig_1">1</ref>.</p><p>We first discuss ad identification. Typical color ads are always more accurately identified than atypical color ads. Typical grayscale ads are more accurately identified than atypical grayscale ads when there is no blur or a low level of blur, but at higher levels of blur there is no difference. Identification accuracy of typical color and grayscale ads is the same when there is no blur. However, typical color ads are more accurately identified than typical grayscale ads when there is some level of blur. There is no difference between atypical color and grayscale ads in their accuracy of identification.</p><p>With respect to category identification, typical ads are always more accurately identified than atypical ads. Typical color ads are identified more accurately than typical grayscale ads for all levels of blur, but (similar to ad identification accuracy) there is no difference between typical color and grayscale ads when there is no blur. These results support the buffer theory of color effect of gist perception. They suggest that color is not merely a part of what makes an ad typical, in which case removal of color would have uniformly deteriorated gist perception, even for normal ads.</p><p>The Bayesian ANOVA provides an adequate statistical analysis, but is not a formal model of the underlying process. Therefore we apply the Bayesian drift diffusion model (DDM; <ref type="bibr" target="#b22">Wiecki et al. 2013</ref>) to provide a deeper analysis of the accuracy and response time of ad identification for typical ads (for which the buffer effect is manifested). Details are in the appendix. The DDM is a mathematical model of the cognitive process underlying perceptual decisions such as the ad identification decision. It captures key properties of perceptual decision data, such as more accurate decisions having shorter response times. The DDM assumes that during an ad/ed decision, sensory information is extracted from the image and continuously accumulated until a threshold is reached <ref type="bibr" target="#b19">(Smith and Ratcliff 2004)</ref>. Then the decision process terminates. Random fluctuations in the time course of the accumulating information reflect noise in the decision process. The parameters representing the drift of the accumulation ( and the decision threshold ( are the key primitives of the underlying process. The threshold reflects the decision criterion implemented by the participant: a lower threshold results in a faster but less accurate decision, everything else being equal. The drift rate reflects the strength of the visual signal: degraded (grayscale or blurred) images of ads contain less information, and are therefore predicted to result in a lower drift.</p><p>The DDM analysis of the ad identification accuracy and response time reveals that as ads become more blurred, the decision threshold is lowered by 10-15%, participants being less willing to spend time or effort in making a decision. For normal ad images and images with a low level of blur, color does not add any information over grayscale images (the drift parameters are the same). As the ad images become more blurred less and less information is extracted from the images, but now color provides additional information over grayscales: the drift rate is substantially higher, up to two to four times. This analysis reveals that color indeed provides incremental information only at higher levels of blur, but it does not tell us yet whether the mechanism is sensory (segmentation) or cognitive (diagnosticity). Study 2 investigates this by comparing typical color and grayscale ads with two versions of inverted color ads. If segmentation accounts for the buffer effect of color, ads with completely inverted colors should do equally well as normal colored ads, and both should do better than grayscale ads. If, however, diagnosticity accounts for the buffer effect of color, normal colored ads should do better than ads with all colors inverted, but should do as well as ads with inverted background colors and a normal colored central (diagnostic) object. Study 2 tests these predictions. To delve deeper into gist perception, it also investigates gist perception at the level of the category and brand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Study 2 4.1. Procedures</head><p>Two hundred eighty-three paid undergraduate students (131 men; age ranging from 21 to 28) were randomly assigned to one condition of a 2 (blur: normal, blurred) × 4 (color: full color, grayscale, inverted, inverted background) between-participants design (data were collected in two waves that were combined). Participants were exposed to 25 ads for five brands in each of five categories (different from study 1). Ads were selected to be typical for the categories: cars, financial services, food, skincare, and fragrance. In the "inverted color" condition images were obtained by reversing all colors, with red appearing cyan, green appearing magenta, and blue appearing yellow. In the "inverted background color" condition images were obtained by reversing all colors, except the colors of the brand logo and/or the central object.</p><p>Relative to the inverted color condition this leaves diagnosticity of the colors for the central object/brand intact. Images with a high level of blur were produced with a Gaussian blur filter of either a radius of 12 (inverted background color) or 24 (inverted color). Figure <ref type="figure" target="#fig_2">2</ref> provides an example of an ad under several of these conditions. The procedures were similar to those in study 1. Immediately after image presentation for 100 msec., question 1 appeared on the screen: "To which category does this ad belong?" along with five possible responses, after which a new screen appeared with question 2: "Which brand is being advertised?"  The response options were five brands from the category selected in response to question 1. The number of accurate responses across categories and brands was recorded for both questions. We use hierarchical Bayesian ANOVA to analyze the number of correct category identifications, y c i , out of J = 25, and the number of correct brand identifications y b i given the number of correct category identifications. The model is similar to that in study 1, but with P = 1, T i l j = 0, and T i l j = 0, because of the absence of a within-subject factor (all ads were typical).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Results and Discussion</head><p>Table <ref type="table" target="#tab_2">2</ref> presents the estimates. Category and brand identification are affected by blur (B), revealing the negative effects of removing visual detail from the images. For the normal ad images, removing color (C1) has a negative effect on category identification, but not on brand identification. Inverting all colors (C2) affects both category and brand identification negatively, but inverting only the background colors (C2) does not have a main effect. The C × B interaction is significant for both measures. These effects are represented in Figure <ref type="figure">3</ref>.</p><p>Blurred full color ads have somewhat lower category identification accuracy than the normal full color ads. This result differs from that in study 1 where we did not find an effect of removing color on category identification, but the effect here is relatively small (Figure <ref type="figure">3</ref>). In study 1 the ad identification question may have selected more typical ads for the category identification question that followed it. Whereas there is a dramatic drop in identification accuracy for grayscale and inverted color ads when the image becomes blurred, that is not the case for images with inverted background color. In particular, category identification accuracy for blurred images with inverted background colors is as high as that of full color blurred images, again revealing the buffer effect of color. The results for brand identification accuracy are similar. The brand in normal colored ads is almost equally well identified whether the ad is blurred or not. The drop in accuracy with increasing levels of blur for grayscale and inverted color ads is large. However, there is no effect of blurring on brand identification for images with (only) inverted background colors. Brand identification accuracy for these images is as high as that of full color images.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implications and Further Insights</head><p>This research provides evidence for the buffer effect of color on rapid ad, product category, and brand perception under blurred exposure conditions. It narrows the effect down to the color of the central diagnostic object. Even after exposures as little as 100 msec., the colors of the central object protect gist perception at the category and brand level against the detrimental effects of blurred exposures. These findings are important because they demonstrate that color per se does not necessarily protect gist perception. The buffer effect of color does not occur through improved scene segmentation. In that case the gist of normal color ads and inverted color ads would have been perceived equally accurately, and better than that of grayscale ads. Instead, the findings point to a cognitive mechanism: colors of the central object (a person, car, face, or food product) provide diagnostic cues that help gist perception.</p><p>The results have implications for advertising theory. First, they reveal that the buffer effect of color that was postulated for object recognition <ref type="bibr" target="#b2">(Biederman and Ju 1988)</ref> operates in scene perception as well, but is limited to typical scenes. Second, they reveal that the buffer effect is driven by a cognitive mechanism of color diagnosticity <ref type="bibr" target="#b12">(Mapelli and Behrmann 1997)</ref>, rather than a sensory mechanism of color segmentation. Third, although <ref type="bibr" target="#b23">Wu et al. (2014)</ref> conclude from a review of the literature that the role of object recognition in gist perception is still unclear, we provide evidence that the colors of the central object play a key role under blurred exposures. This is a new finding that may be surprising, given that previous research has found a limited role of color in object recognition <ref type="bibr" target="#b2">(Biederman and</ref><ref type="bibr">Ju 1988, Wurm et al. 1993)</ref>. However, most of that prior research presented the objects without context. We conjecture that the context provided by the spatial layout of typical ads facilitates identification of the central object, and that therefore color helps in identifying the central object only in the presence of diagnostic cues provided by the global layout of typical ads <ref type="bibr" target="#b0">(Bar 2004</ref><ref type="bibr" target="#b23">, Wu et al. 2014</ref><ref type="bibr" target="#b24">, Wurm et al. 1993</ref>.</p><p>The present results about the role of the color of the central object can be illuminated further by recent findings <ref type="bibr" target="#b9">(Larson et al. 2014</ref>) that during gist perception within the first 100 msec. covert attention is initially focused centrally and then rapidly expands outward into the periphery. Thus, within 100 msec. there is an advantage of central over peripheral information. Because color is predominantly processed in the (central) fovea of the retina, our results on the importance of the color of the central object are consistent with this.</p><p>The central object determines to a large extent whether an ad is perceived as typical or not. It is usually the product itself (food, cars), or a consumer of the product (facial care, perfumes). Many of these objects are color diagnostic: colors are unique and an intrinsic component of their mental representation <ref type="bibr" target="#b24">(Wurm et al. 1993)</ref>. The Nivea ad in Figure <ref type="figure" target="#fig_2">2</ref>, with its well-known blue and white coloring, presents an example. The color of the face helps its rapid recognition, which in turn supports identification of the (facial care) category, and of the brand. In contrast, many ads for fragrances use the color scheme of the brand throughout the entire ad as a creative technique. An example is a Gucci perfume ad in our study, which has its diagnostic red brand color overlaid across the entire ad, including the central object (a woman's face). The incongruent colors of the central object (red face) hamper rapid and accurate gist perception at the ad and category, and perhaps brand level.</p><p>This research used color inversion to disentangle two mechanisms that might account for the buffer effect of color. In advertising practice, color inversion is used as a creative tactic to produce color incongruity. An example is an ad for Cointreau (tagline: Glow with Cointreau) that used color inversion of the entire ad image (including the now blue faces of people) except for the central object (the brown Cointreau bottle). Because the Cointreau ad leaves the color of the central object unchanged, the inverted color scheme of the background is unlikely to hurt gist perception. Our study, however, did not address which colors are diagnostic for a specific category. In a follow-up study among 26 participants (graduate students), the strength of the association (1 = not, 5 = very strongly associated) between 13 colors and four product categories turned out to be unique (F -tests, p &gt; 0 001). The strongest associations &lt;3 0 on the scale) were for cars and financials with dark blue, white, and black; skincare with light blue, pink, and white; and food with yellow and red. This shows that in typical ads specific colors are diagnostic for a category, on which advertisers may capitalize.</p><p>Our methodology can be used as a tool to investigate the diagnosticity of the color scheme of specific ads. Although we did not find an effect of background colors across all ads and categories, its effect for some ads may be significant. From the data of study 2, we therefore estimated the odds ratio of the probabilities of identifying the category and brand R c , respectively, R b in ads with inverted background colors relative to normal ads. <ref type="bibr">4</ref> Odds ratios significantly lower than one indicate that background colors are diagnostic for the category and/or the brand. For example, for an ABN-AMRO ad (financials) R c = 0 622 (95% CI = 0 413, 0.909), and R b = 0 372 (0.110, 0.875). This ad has a characteristic yellow/green coloring that is thus diagnostic for both category and brand. Ads for Gauthier (fragrances; pink) R c = 0 888 (0.775, 0.999) and Gucci (fragrances; red) with R c = 0 758 (0.574, 0.971), have a background color scheme that is diagnostic only for the category. Yet other ads have colors that are diagnostic only for the brand: Alfa Romeo (cars; red/black) with R b = 0 673 (0.480, 0.903) and Honig (food; orange/white) with R b = 0 726 (0.523, 0.994). This illustrates how this methodology can be used to pretest color schemes of ads. <ref type="bibr">4</ref> The model was calibrated on data aggregated across participants for each ad: y N j ∼ Bin p N j I , with p N j ∼ Beta a c b c , a c b c ∼ Gamma 0 1 0 1 , for normal (N) ads, and similarly for inverted (I) ads. The odds ratio is computed as R = p I j /p N j .</p><p>This research considered blur as a barrier toward advertising effectiveness. However, blur is also used as a creative design technique in advertising photography, called "bokeh." It is used to focus attention on certain objects or to add visual imagery such as fast motion or stylishness. There are two common uses: background blur and motion blur, which can be achieved either by shutter speed settings during photography, or through digital processing of the image. Clarity of specific local regions is used to make them stand out from the blurred background, with the purpose of directing consumers' attention. For example, one of the ads in our study displays Knorr sauce mix packages in focus in the center on a checkout conveyer belt, with the conveyor belt, the cashier, and supermarket background blurred. Based on our findings, we speculate that background blur will not hurt, and may even help gist perception. Yet, more research is needed.</p><p>Clearly, rapid gist perception (ad, category, and brand) or "ad cut through" should be considered as a communication goal in advertising strategy. In the face of increasingly brief exposures to ads, advertisers can capitalize on the impressive ability of consumers to grasp their gist in one tenth of a second or less. Advertising gist perception is a crucial step toward attracting attention to the ad and building positive associations and attitudes about the brand. If there is a reason to believe that exposure conditions will be brief and blurred, advertisers need to consider gist perception goals, and the use of typical ads with diagnostic objects and color schemes becomes important. In view of rising advertising competition and falling consumer attention spans, we believe that this will be increasingly the case. As a case in point, take banner advertising. Banner ads are smaller ads (especially buttons, mini banners, skyscrapers, and so forth) on the right side of a Web page. Yet, these ads tend to be actively avoided by consumers, and exposures mostly occur in the periphery of vision. Such exposures are quite prevalent online because of the ease and speed of swiping, pinching, and scrolling on tablets and smartphones. Rapid perception of the gist of these online ads is even more important because of their intended direct response. Yet, few banner ads follow a typical layout, and most lack a diagnostic central object and coloring. This makes it difficult to rapidly perceive their gist. Gist perception of online advertising (including pop-up ads, leader boards, and hero ads, but also in-app and other mobile advertising) should be a key issue for advertising practice and an important topic for future research.</p><p>Even in conditions where consumers have the opportunity and motivation to prolong advertising exposure, gist perception may be critical. Grasping the gist of an ad is crucial for consumers to decide reverse holds for all other conditions. This indicates a dramatic shift in the perceptual decision process at very high levels of blur. Yet, at these higher levels of blur the drift rate of color images indicates that they provide two to four times as much information. Thus, mechanisms underlying the effects of blur and color are different. Participants respond to the additional resources required for processing more blurred images by lowering their decision threshold. At the same time, blurred color images provide more information for ad/ed identification, compensating for the lower threshold under higher blur and explaining the buffer effect.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 (</head><label>1</label><figDesc>Figure 1 (Color online) Buffer Effect of Color: Estimates for Study 1 (Predicted Means and 95% Credible Intervals Are Shown)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 Four</head><label>2</label><figDesc>Figure 2Four Versions of a Facial Care Ad (Study 2)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Wedel and Pieters: Role of Color When Advertising Exposures Are Brief and Blurred Marketing Science 34(1), pp. 134-143, © 2015 INFORMS 135</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>Parameters Estimates of the Bayesian ANOVA of Gist Perception: Study 1</figDesc><table><row><cell cols="3">Gist perception:</cell><cell cols="3">Gist perception:</cell></row><row><cell></cell><cell>ad</cell><cell></cell><cell cols="3">product category</cell></row><row><cell>Mean</cell><cell>SD</cell><cell>p-value</cell><cell>Mean</cell><cell>SD</cell><cell>p-value</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Parameter Estimates of the Bayesian ANOVA of Gist Perception: Study 2</figDesc><table><row><cell cols="3">Gist perception:</cell><cell cols="3">Gist perception:</cell></row><row><cell cols="3">product category</cell><cell></cell><cell>brand</cell></row><row><cell>Mean</cell><cell>SD</cell><cell cols="2">p-value Mean</cell><cell>SD</cell><cell>p-value</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">http://www.telegraph.co.uk/health/healthnews/3522781/Stress -of-modern-life-cuts-attention-spans-to-five-minutes.html, accessed August 19, 2014.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Parameters in a column sharing a superscript are not significantly different, for example, the differences between the mean thresholds for normal images and images at blur level 4 are not significant, but those between blur levels 4 and 8 are significant.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Marketing Science 34(1), pp. <ref type="bibr">134-143, © 2015 INFORMS</ref> whether or not to prolong exposure and acquire selfrelevant messages about the product and brand. If ad gist is not or incorrectly grasped, exposures may be prematurely terminated and message comprehension and attitude toward the ad and brand may suffer. Our research is a step toward understanding how to prevent this from occurring by providing insights in the role of color schemes in advertising gist perception under rudimentary exposure conditions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix. DDM Analysis of Ad/Ed Identification</head><p>To shed light on the perceptual process by which the effects of color and blur on gist perception emerge, we use a drift diffusion model to analyze the (0/1) accuracy and response time of ad identification of typical ads from study 1 (this is where the buffer effect of color emerged). DDMs are based on a stochastic diffusion process <ref type="bibr" target="#b19">(Smith and Ratcliff 2004)</ref>. They describe two alternative perceptual decisions, where choice outcomes (ad or ed) are represented by two thresholds separated by a distance i for each individual i. Stochastic evidence favoring either outcome accumulates at a rate i . The parameter i indicates the time/effort participants are willing to spend, and i reflects the strength of the sensory signal extracted from the stimulus and the efficiency of processing it. A parameter i shifts the onset of the time of accumulation, reflecting nondecision processes, such as motor responses. The termination of the stochastic diffusion at one of the thresholds gives rise to a decision (ad or ed) and an associated response time (t , the probability distribution of which has a closed form. Using this feature, <ref type="bibr" target="#b22">Wiecki et al. (2013)</ref> develop a hierarchical Bayesian formulation of the DDM and a Markov chain Monte Carlo estimation algorithm. Their hierarchical DDM (HDDM) accommodates a (normal) distribution of all parameters across participants with population parameters ,¯ , and¯ , and parameterizes them in terms of exogeneous variables. We employ this procedure, simultaneously allowing for 5% outliers in response times through a mixture formulation.</p><p>We test various models in which i and i depend on color and blur: models in which blur affects the threshold and color the drift (deviance information criterion (DIC) = 6,146), or vice versa (DIC = 6,088), in which color and blur (interactively) affect the threshold (DIC = 6,145), or the drift (DIC = 6,074), in which both affect the drift and in addition only color (DIC = 6,067), respectively, only blur (DIC = 6,062) affects the threshold. The results of the latter model, which fits the data best, are presented in Table <ref type="table">A</ref></p><p>The decision threshold¯ is significantly lower for higher (B8 to B24) levels of blur, by about 10-15%, as compared to normal images and lower levels of blur (B4). This reflects faster but less accurate decision making. For normal images (N) and those with a low level of blur (B4) there is no significant difference in the drift ¯ between color and grayscale images. At medium to very high levels of blur (B8-B24), the drift rate of grayscale images drops, and more so than for color images, indicating that less visual information is extracted from these images. At the highest level of blur the mean drift parameters are negative, indicating that correct responses are slower than incorrect ones, whereas the </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Visual objects in conscience</title>
		<author>
			<persName><forename type="first">M</forename><surname>Bar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Rev. Neuroscience</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="617" to="629" />
			<date type="published" when="2004-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><surname>Barden</surname></persName>
		</author>
		<title level="m">The Science Behind Why We Buy</title>
				<meeting><address><addrLine>Chichester, UK</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Surface versus edge-based determinants of visual recognition</title>
		<author>
			<persName><forename type="first">I</forename><surname>Biederman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Ju</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psych</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="38" to="64" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Framing pictures: The role of knowledge in automatized encoding and memory for gist</title>
		<author>
			<persName><forename type="first">A</forename><surname>Friedman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Experiment. Psych.: General</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="316" to="355" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sensory and cognitive contributions of color to the recognition of natural scenes</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Gegenfurtner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rieger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page" from="805" to="808" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Analysis of variance-why it is more important than ever</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="53" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Visual recognition: As soon as you know it is there, you know what it is</title>
		<author>
			<persName><forename type="first">K</forename><surname>Grill-Spector</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Kanwisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="152" to="160" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The representation of color and form in long-term memory</title>
		<author>
			<persName><forename type="first">A</forename><surname>Hanna</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Remington</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memory Cognition</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="322" to="330" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The marketers&apos; prismatic palette: A review of color research and future directions</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">I</forename><surname>Labrecque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">M</forename><surname>Patrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Milne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Marketing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="187" to="202" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The spatiotemporal dynamics of scene gist recognition</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">E</forename><surname>Freeman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Ringer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">C</forename><surname>Loschky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Experiment. Psych.: Human Perception Performance</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="471" to="487" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Psychophysical evidence for separate channels for the perception of form, color, movement, and depth</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Livingstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Hubel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Neuroscience</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="3416" to="3468" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Winbugs-A Bayesian modeling framework: Concepts, structure, and extensibility</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Lunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Spiegelhalter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statist. Comput</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="325" to="337" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The role of color in object recognition: Evidence from visual agnosia</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mapelli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Behrmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocase</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="237" to="247" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Understanding the effects of color: How the correspondence between available and required resources affects attitudes</title>
		<author>
			<persName><forename type="first">J</forename><surname>Meyers-Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">A</forename><surname>Peracchio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cons. Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="121" to="138" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Diagnostic colors mediate scene recognition</title>
		<author>
			<persName><forename type="first">A</forename><surname>Oliva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Schyns</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psych</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="176" to="210" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Ad gist: Ad communication in a single eye-fixation</title>
		<author>
			<persName><forename type="first">R</forename><surname>Pieters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="59" to="73" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">H</forename><surname>Rosch</surname></persName>
		</author>
		<title level="m">Natural categories. Cognitive Psych</title>
				<imprint>
			<date type="published" when="1973" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="328" to="350" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Family resemblances: Studies in the internal structure of categories</title>
		<author>
			<persName><forename type="first">E</forename><surname>Rosch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Mervis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psych</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="573" to="605" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">How long to get the gist of real-world natural scenes</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Rousselet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">R</forename><surname>Joubert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fabre-Thorpe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="852" to="877" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Psychology and neurobiology of simple decisions</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Neuroscience</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="161" to="168" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Eye-tracking for visual marketing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pieters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations and Trends ® in Marketing</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="231" to="320" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The contributions of color to recognition memory for natural scenes</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Wichmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">T</forename><surname>Sharpe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Gegenfurtner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Experiment. Psych.: Learning, Memory, Cognition</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="509" to="520" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">HDDM: Hierarchical Bayesian estimation of the drift-diffusion model in python</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">V</forename><surname>Wiecki</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sofer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers Neuroinformormatics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Guidance of visual attention by semantic information in real-world scenes</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Wick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pomplun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers Psych</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">54</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Color improves object recognition in normal and low vision</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">H</forename><surname>Wurm</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">E</forename><surname>Legge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Isenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Luebker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Experiment. Psych.: Human Perception Performance</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="899" to="911" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Color aids late but not early stages of rapid natural scene recognition</title>
		<author>
			<persName><forename type="first">Ayj</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Einhäuser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Vision</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="1" to="13" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
