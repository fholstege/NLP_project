<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Valuing Customer Portfolios with Endogenous Mass and Direct Marketing Interventions Using a Stochastic Dynamic Programming Decomposition</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-04-21">April 21, 2014.</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Mercedes</forename><surname>Esteban-Bravo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Business Administration</orgName>
								<orgName type="institution">Universidad Carlos III de Madrid</orgName>
								<address>
									<postCode>28903</postCode>
									<settlement>Getafe, Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Jose</forename><forename type="middle">M</forename><surname>Vidal-Sanz</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Business Administration</orgName>
								<orgName type="institution">Universidad Carlos III de Madrid</orgName>
								<address>
									<postCode>28903</postCode>
									<settlement>Getafe, Madrid</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName><forename type="first">Gökhan</forename><surname>Yildirim</surname></persName>
							<email>g.yildirim@lancaster.ac.uk</email>
							<affiliation key="aff1">
								<orgName type="department">Department of Management Science, Management School</orgName>
								<orgName type="institution">Lancaster University</orgName>
								<address>
									<postCode>LA1 4YX</postCode>
									<settlement>Bailrigg, Lancaster</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Valuing Customer Portfolios with Endogenous Mass and Direct Marketing Interventions Using a Stochastic Dynamic Programming Decomposition</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
						<imprint>
							<date type="published" when="2014-04-21">April 21, 2014.</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.2014.0848</idno>
					<note type="submission">Received: September 14, 2012; accepted: December 26, 2013; Preyas Desai served as the editor-in-chief and Duncan Simester served as associate editor for this article.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>CRM</term>
					<term>marketing resource allocation</term>
					<term>long-term effect of marketing activities</term>
					<term>stochastic dynamic programming</term>
					<term>dynamic panel-data models</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>T he customer relationship management allocation in marketing budgets is potentially misleading when it uses individual customer lifetime value estimations from historical data. Planned marketing interventions would change the purchasing behavior of different customers, and history-based decisions would thus be suboptimal. To cope with this inherent endogeneity, we model the optimal allocation of the marketing mix by accounting simultaneously for mass interventions and direct marketing interventions for each customer. This is a large stochastic dynamic problem that, in general, is computationally rather intractable as a result of the "curse of dimensionality." We present an algorithm to derive the optimal marketing policies (how the firm should allocate its marketing resources) and the expected present value of those decisions, which maximize the long-term profitability of firms. This allows the firm to value customers/segments and helps the firm to target those that maximize long-term profitability given the optimal marketing resources allocation. We apply the proposed approach in the context of a kitchen appliance manufacturer. The results identify the most effective marketing policies and the endogenous customer values. It is in this context that we also dynamically identify the most profitable customer and the short-and long-term effects of marketing activities on each customer.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Customers are a firm's main assets, and marketing departments increasingly adopt customer relationship management (CRM) programs to improve customer acquisition, expenditure, and retention. In essence, CRM involves a systematic allocation of differential resources to customers based on the individual value of these customers to the business. The resources allocated to each customer can be channeled through a mix of alternative interventions and can be complemented by mass actions. Marketing resource allocation has traditionally been based on heuristic rules (see <ref type="bibr" target="#b42">Mantrala 2002)</ref>, but the benefits of CRM policies are today justified by their impact on firms' returns <ref type="bibr" target="#b60">(Rust et al. 2004)</ref>. To plan the allocation of resources, managers therefore need to maximize the value of their customer base. Ideally, this concept is measured by the sum of customer lifetime values (CLV)-that is, the sum of net present values of cash flows between a customer and the firm <ref type="bibr" target="#b33">(Gupta et al. 2004, Gupta and</ref><ref type="bibr" target="#b29">Lehmann 2006)</ref>. The assessment of customers' values and the effectiveness of a marketing intervention are typically based on the econometric analysis of large customer databases.</p><p>CRM requires planning a portfolio of a mix of marketing intervention alternatives. Typically, the literature on budget allocation considers mass interventions from the marketing mix such as advertising, promotion, sales force, prices and price promotions, product, and distribution (for a review, see, e.g., <ref type="bibr">Steenburgh 2008, Shankar 2008)</ref>. The direct marketing literature typically considers a single intervention that is customized or at least tailored to small segments. For example, it is common to use certain pricing decisions <ref type="bibr" target="#b40">(Lewis 2005)</ref>, catalog mailing (see, e.g., <ref type="bibr" target="#b14">Bitran and Mondschein 1996</ref><ref type="bibr" target="#b26">, Gönül and Shi 1998</ref><ref type="bibr" target="#b25">, Gönül and Ter Hofstede 2006</ref><ref type="bibr" target="#b69">, Simester et al. 2006</ref>, couponing decisions (e.g., <ref type="bibr" target="#b5">Bawa and</ref><ref type="bibr">Shoemaker 1987, Rossi et al. 1996)</ref>, direct mailing <ref type="bibr" target="#b53">(Roberts and Berger 1989)</ref>, and relationship-oriented magazines <ref type="bibr" target="#b10">(Berry 1995</ref><ref type="bibr" target="#b12">, Bhattacharya and Bolton 1999</ref><ref type="bibr" target="#b44">, McDonald 1998</ref>.</p><p>Marketing Science 33(5), pp. 621-640, © 2014 INFORMS Planning optimal CRM interventions by maximizing the expected global CLVs is, by all means, a difficult task. In an attempt to address this, the standard CRM procedure allocates a marketing budget to each individual customer, after ranking customers by their CLV value <ref type="bibr" target="#b51">(Reinartz et al. 2005</ref><ref type="bibr" target="#b71">, Venkatesan and Kumar 2004</ref>. Assessing new marketing interventions using CLVs computed from historical data is potentially misleading. The planned CRM marketing interventions will change the purchasing behavior of different customers, changing their CLVs, turning the customers' rankings upside down, and making our history-based decisions suboptimal. To cope with this inherent endogeneity, the objective of a marketing mix allocation model should be a CLV measure computed as the optimal value achieved when the optimal CRM investment is implemented. The idea is that when the CLV is computed, we should take into account how customers will react to the changes in the CRM policies.</p><p>To avoid this endogeneity problem, some authors have tried to optimize the expected CLVs. <ref type="bibr" target="#b59">Rust and Verhoef (2005)</ref> optimize each individual customer's profitability year by year (which has been described as myopic planning). Alternatively, other authors have optimized the expected CLV using stochastic dynamic programming (SDP). Although this is a natural approach to solving this problem, SDP is affected by the "curse of dimensionality" (the complexity increases drastically with the size of the problems). Therefore, they consider a partial solution that ignores mass interventions (aimed at all customers) and that focuses on direct individual interventions so that the investment decision for each customer is independent and the standard SDP algorithms can be applied to the problem of the "decoupled decision." In this respect, <ref type="bibr" target="#b26">Gönül and Shi (1998)</ref> and <ref type="bibr" target="#b45">Montoya et al. (2010)</ref> study direct marketing problems, whereas <ref type="bibr" target="#b38">Khan et al. (2009)</ref> estimate the impact of multiple promotional retail instruments on customer behavior (e.g., discount coupons, free shipping offers, a loyalty program), designing a customized promotional schedule that solves a different SDP problem for each customer. Yet how to optimize simultaneously both types of interventions (mass and direct ones) is an unsolved issue because the SDP optimization problems are not separable among customers. Maximizing the expected CLVs of a customer's portfolio with multiple types of personalized and mass marketing interventions, accounting for long-term returns, and solving the endogeneity issue is what <ref type="bibr">Rust and Chung (2006, p. 575</ref>) call the "holy grail" of CRM.</p><p>In this paper, we provide a fully tailored approach for planning policies that maximize the expected CLV of all customers in the market by accounting for the endogeneity issues. Our approach considers that customer behavior follows a Markov model in which sales respond to mass and direct marketing interventions and in which marketing expenditures are allocated to maximize the sum of expected CLVs for all its customers. Because such models can become rather intractable in general, we propose a method to address this problem by splitting it into manageable pieces (subproblems) and by coordinating the solutions of these subproblems. With this approach, we obtain two main computational advantages. First, the subproblems are, by definition, smaller than the original problem and therefore are much faster to solve. Second, uncertainty can be easily handled in each of the subproblems. To validate the efficiency of the approach, we provide a proof of convergence and solve several stochastic dynamic CLV models. The numerical results show the effectiveness of the method in solving large-scale problems.</p><p>In addition, we present an empirical application and consider the case of a medium-sized international company based in Eastern Europe that manufactures and distributes wholesale built-in electrical appliances for kitchens. Because this is a firm with various forms of sales response, its marketing budget allocation strategy involves general marketing investments (mainly advertising and promotions in professional fairs) and personalized customer investments. In the present paper, we therefore investigate whether these two types of interventions differ across customers. The results show that companies should consider different strategies for different customers to achieve long-term profitability over all time periods.</p><p>The rest of this paper proceeds as follows. In §2, we provide a model for dynamically allocating marketing budgets in the context of CRM. The present model simultaneously considers direct marketing interventions tailored to each customer and mass marketing interventions aimed at the customer base. In §4, we present the proposed decomposition methodology. In §5, we illustrate the performance of the algorithm using numerical simulations and provide a proof of convergence. In §6, we present an empirical application of the model to customers of a manufacturer of kitchen appliances. Finally, in §7, we discuss the results and provide some concluding remarks. The appendix provides technical details about the algorithm implementation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">A Model for Optimal Dynamic Budget Allocation in CRM</head><p>Planning marketing interventions in CRM requires managers to allocate budgets dynamically by maximizing the sum of expected CLVs from all customers based on information on history of customer state. To address the optimal budget allocation problem, the firm must carry out two tasks (see, e.g., <ref type="bibr" target="#b34">Gupta et al. 2009</ref>).</p><p>• Task 1: To calculate CLV, a company has to estimate the customer response to marketing strategies. We model customer response as a Markov process <ref type="bibr">Lehmann 2003, 2005;</ref><ref type="bibr" target="#b37">Kamakura et al. 2005;</ref><ref type="bibr" target="#b32">Gupta and Zeithaml 2006)</ref>.</p><p>• Task 2: The company will be able to evaluate whether a marketing strategy is optimal by solving its decision problem, which includes all individual customer responses (see, e.g., <ref type="bibr" target="#b57">Rust and</ref><ref type="bibr" target="#b59">Verhoef 2005, Rust and</ref><ref type="bibr" target="#b58">Chung 2006)</ref>.</p><p>In other words, the basic problem that a company faces is determining optimal marketing strategies over time. This optimization problem is done subject to some dynamics that define how these strategies translate into sales and, in turn, into profits. Then, the first task is the study of these dynamics as a dynamic panel sales response model. We assume a market with I customers. The firm decides among possible strategies sequentially in each period of time t ∈ 0 1 2 3 , such as • e it , the direct marketing interventions on each customer i ∈ at period of time t, such as personalized advertising and directed promotional expenditures;</p><p>• A t , the mass marketing interventions at period of time t, such as the mass marketing investment; and</p><p>• P t , the prices for the different products. Note that the notation e t includes direct marketing interventions of all the customers.</p><p>There is a set of consumer states, S t , describing the sales-level state of each customer i ∈ at each period of time t depending on the decision variables A P e. However, the same approach can be easily adapted to other state variables (e.g., if S t are cash flows drawn from each customer). In a Markov process, all the historical information needed to model the customer behavior at each period of time to make a decision is captured in the set of states variables. The (timeinvariant) cumulative probability distribution that is conditional on previous decisions and previous state information, is</p><formula xml:id="formula_0">F s s A P e = Pr S t ≤ s S t−1 = s A t−1 = A P t−1 = P e t−1 = e</formula><p>which determines the probability of the event S t ≤ s given that the consumer was previously in state s, and the decision variables A P e denote the decision made after observing state S t−1 . We assume that individuals are statistically independent, so that F s s A P e = i∈ F i s i s i A P e i Two possible approaches for these probability distributions are as follows:</p><p>1. Finite-state problems: A finite number of possible states s 1 s m is considered for the sales to each individual. Then F i s i s i A P e i can be characterized by the transition matrix i A P e i , where the r s element is a probability i r l linking to subsequent states s r and s l , which depends on the marketing actions A P e i . Markov processes with a finite number of states are known as Markov chains.</p><p>2. Infinite-state problems: These postulate a sales response model for each customer in the panel,</p><formula xml:id="formula_1">S it = g i S it−1 A t−1 P t−1 e it−1 it (1)</formula><p>where sales responses can vary across customers to allow heterogeneity in the expected responses, and the error term it as an independent and identically distributed (i.i.d.) random variable with zero mean, statistically independent from S it−1 , A t−1 , P t−1 , e it−1 and cumulative probability distribution H i . Then,</p><formula xml:id="formula_2">F i s i s i A P e i = i g i s i A P e i i ≤s i H i d i</formula><p>The second approach is more flexible, and usually finite-state problems are regarded as a discrete approximation to processes with continuous states. Although this paper will focus on the general case of infinite states, we try to reconcile the generality of the model (1) with econometric convenience (postulating estimable models for which stationarity can be easily determined). Therefore, we henceforth consider that the company customer response is defined by a standard dynamic panel regression model</p><formula xml:id="formula_3">S it = S it−1 + g i A t−1 P t−1 e it−1 + it (2)</formula><p>where the error term it is assumed to be an i.i.d. random variable with zero mean and constant variance over time and is independent among customers. We will assume that the sales response from the previous period influences the sales responses of the current period at a constant rate &lt; 1. Because sales responses can vary across customers to allow heterogeneity in the expected responses, we assume that there are different transition probabilities for each customer as follows:</p><formula xml:id="formula_4">F i s i s i A P e i = Pr i ≤ s i − s i − g i A P e i = H i s i − s i − g i A P e i</formula><p>where H i • is the cumulative distribution of the error term it . The one-lag memory structure imposed here can be relaxed by considering p-lags autoregressive models in the space of states.</p><p>The dynamic model (2) can be estimated using standard econometric techniques for time series crosssection and/or dynamic panels. Firms increasingly store large panel databases with information on their customers, including social information (such as sociodemographic, geographic information, and lifestyle habits) and trade internal data (such as historical transaction records, customer feedback, and Web browsing records); see <ref type="bibr" target="#b17">Bose and Chen (2009)</ref>. The econometric literature Marketing Science 33(5), pp. 621-640, © 2014 INFORMS has developed a battery of linear and nonlinear models for the dynamic analysis of large data panels; marketing researchers have tailored these models for the prediction of future purchases at the customer level (e.g., <ref type="bibr" target="#b64">Schmittlein and Peterson 1994)</ref>. Using these tools, company managers often estimate the expected CLV for each customer based on its past behavior (generally in a context of ceteris paribus, omitting or fixing the marketing mix variables).</p><p>Managers are typically profit maximizers, and as such, they face the problem of determining the price and advertising investment that returns the greatest profit. Once the company has estimated the sales responses to different decision variables of interest over time, the company can undertake solving Task 2. In other words, the firm should choose the optimal CRM strategies that maximize the expected sum of its CLVs. This problem is a large-dimensional (discounted) SDP problem. Mathematically, we model a rational forward-looking firm that has to decide on CRM budget allocation strategies over time, A t , P t , e t , drawing profits r S t A t P t e t = i∈ r i S it A t P t e it</p><p>(3) at each period of time t ≥ 0 from all of their customers. <ref type="bibr">1</ref> In particular, we consider that</p><formula xml:id="formula_5">r i S it A t P t e it = P t −c 0 •S it −c i e it −c m A t /I (4)</formula><p>where c 0 is the unit cost, c i e it is the cost of individual marketing effort e it , and c m A t is the cost of general advertising actions A t . (Marketing actions are often in monetary units, so the cost functions are identity functions: c m A = A, c i e i = e i .) The objective of the firm is to maximize the expected net present value over the planning horizon, E 0 t≥0 t r S t A t P t e t , where ∈ 0 1 is the discount factor.</p><p>The decisions A t P t e t at each period of time are usually constrained to a set of feasible strategies (for example, requiring that the gross investment in marketing allocation must be nonnegative and below a certain limit). We can fix P t − c 0 = 1 for all t ≥ 0 (introducing constraints P t = 1 at any time and setting c 0 = 0) and then interpret S it directly as monetary cash flows drawn from individual i. Notice that the set of feasible strategies can be updated based on the state information S t . Therefore, the maximization problem considers A t P t e t ∈ S t for each time period, where S t is a nonempty compact set.</p><p>Definition 1 (Value Function). Conditionally on the initial state S 0 , define the maxim expected value of the discounted expected profit for the firm as V S 0 = max A t P t e t ∈ S t t≥0 E 0 t≥0 t r S t A t P t e t (5) which is known as the value function. <ref type="bibr">1</ref> We use the standard notation " =" for definitions.</p><p>Definition 2 (Policy Function). The value function is characterized by a time-invariant function of the states, known as the policy function A * s P * s e * s , such that V S 0 = E 0 t≥0 t r S t A * S t P * S t e * S t</p><p>The idea is that at each time t, after observing S t−1 , the optimal decisions can be determined with the mapping A * S t−1 P * S t−1 e * S t−1 , and the output S t is drawn from Pr S t ≤ s S t−1 A * S t−1 P * S t−1 e * S t−1 Some papers use the alternative notation Pr S t ≤ s S t−1 A t P t e t for the transition probability instead of Pr S t ≤ s S t−1 A t−1 P t−1 e t−1 . If the control decision is based on the conditioning state S t−1 , the optimization problem does not change, and with both formulations, we get the same policy function A * s P * s e * s and the same value function V s .</p><p>The computation of the value function V s involves solving an SDP problem in discrete time. Under general regularity conditions, value functions (and policy functions) are characterized by the Bellman equation <ref type="bibr" target="#b6">(Bellman 1955</ref><ref type="bibr" target="#b7">(Bellman , 1957</ref> To summarize, managers can optimize their decisionmaking process as 1. the policy rule A * s P * s e * s , which defines the optimal decision based on the sales s observed in the previous period; or 2. the value function V s , which gives managers the company value derived from the CLVs customer portfolio at the previous period of time.</p><p>We should note that there are clear advantages to using this approach: policy rules are simple (ease of understanding for managers) and adaptive (the decisions can be automatically updated as new state information becomes available). Note that they also can be used for simulation. For each period of time t, given S t drawn from the conditional distribution F s S t−1 A t−1 P t−1 e t−1 , the values A t = A * S t , P t = P * S t , and e t = e * S t can be used to simulate Monte Carlo scenarios for S t+1 recursively and then to compute numerically the expected path for the optimal policies E A t , E P t , and E e t and states E S t as well as confidence intervals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">An Overview of Algorithms for Solving SDP Problems</head><p>In dynamic programming, SDP problems may be solved by using Bellman's principle of optimality. There are only a few special types of dynamic problems, however, that can be solved analytically (see, e.g., <ref type="bibr">Ljungqvist and Sargent 2004, Chapter 4)</ref>. When no analytical representation of the value function is available, an approximation can be obtained numerically through approaches based on value iteration or policy function iteration. In Appendix A, we present a technical overview of these methods for both decision problems with finite states and with continuous states. Although the continuous problems are generally more difficult to handle, both types can be generally computed if the number of state variables is small. However, the computation of a large SDP problem remains one of the most challenging optimization problems. SDP problems can become intractable as the dimension of the state space increases (that is, the CPU time to calculate a value function increases exponentially in the dimension of the state space). This is known as the curse of dimensionality (a term coined by Richard Bellman, who was the first to recognize this problem); it appears in problems with just five-or six-dimensional state spaces (see <ref type="bibr">Bellman 1961, p. 94)</ref>, and in our context, it implies that we would not be able to solve problems with more than a small number of different clients. However, Bellman himself usually considered more simple Markovian structures, and with more sophisticated models, we often find problems with just four state variables.</p><p>These problems are associated with the integral E t V S t+1 = V s F ds S t A t P t e t , which is needed to evaluate the Bellman equation. The curse of dimensionality can be found in many problems related to the numerical approximation of integrals by discrete summations, regardless of whether we consider deterministic or Monte Carlo methods. For example, this is why it is virtually impossible to nonparametrically estimate density functions with more than three to four variables (although, a very smooth function could be estimated with up to six or seven variables; see <ref type="bibr">Silverman 1986, pp. 93-94)</ref>. For a dimension larger than five or six, the required samples are huge, and algorithms become so slow that they are infeasible. In its most basic form, the curse of dimensionality means that, for all types of discrete grids that we use, the size required to keep the approximation error below some tolerance grows exponentially with the dimension. Even with dynamic programming for discrete Markov chains (no integral is involved here), we find a numerical problem: the number of elementary algebraic operations required to solve the Bellman equation also grows exponentially with the number of state variables. For a discrete problem with five customers, a state grid of five elements, and a control grid of seven elements, the size of the transition matrix is 3 125 × 3 125 × 16 807. The largest matrix that can be created in MATLAB on 64-bit platforms is with about 231 elements. Alternatively, we could consider sparse matrix representation and/or parallel computing, but then the computational cost goes to search over indices and eventually we exhaust computer memory.</p><p>There is a relatively recent literature that can be used to improve the performance of classic SDP algorithms, known as approximate dynamic programming (ADP) methods (sometimes also called reinforced learning). The main idea of ADP is to replace the expectation in the Bellman equation with some sort of refined statistical approximation in an adaptive way. In particular, in each step the challenge of looping between all possible states is substituted with looping some states that some estimations consider important (see <ref type="bibr">Powell 2007, Adelman and</ref><ref type="bibr" target="#b0">Mersereau 2008)</ref>. These methods have proven successful in some problems (see <ref type="bibr" target="#b67">Simão et al. 2009</ref><ref type="bibr" target="#b68">Simão et al. , 2010</ref> but are known to have failed in many others; they can even diverge or suffer from an overflow. As a general rule, the convergence of ADP algorithms is not guaranteed <ref type="bibr">(Powell 2007, p. 120)</ref>. In contrast to heuristic ADP approaches, our method has guaranteed convergence.</p><p>In this paper, we aim to address this problem by splitting it into manageable pieces (subproblems) and by coordinating the solutions of these subproblems. The subproblems are, by definition, smaller than the original problem and therefore much faster to solve. This methodology lies within the general approach to decomposition algorithms. Based on mathematical programming, these algorithms may be divided into three categories: Dantzig-Wolfe decomposition, Benders decomposition, and augmented Lagrangian relaxation procedures. Both Dantzig-Wolfe decomposition <ref type="bibr" target="#b21">(Dantzig and Wolfe 1960)</ref> and Benders decomposition (see <ref type="bibr" target="#b9">Benders 1962</ref><ref type="bibr">, Geoffrion 1972</ref> are efficient schemes for dealing with convex optimization problems, and augmented Lagrangian relaxation (see <ref type="bibr" target="#b61">Ruszczynski 1995)</ref> attains an extension to nonconvex problems. In general, these approaches apply to problems that can be completely decoupled or that at least do not have common control variables. However, here we face a problem with constraints that cannot be completely separated because we have common controls, and this greatly complicates the computations. Some attempts to solve these types of SDP problems combine traditional decomposition algorithms and statistical sampling techniques. Sampling is used to create a scenario tree that represents uncertainty <ref type="bibr" target="#b35">(Heitsch and Römisch 2009)</ref>, and the original problem is then approximated by a finite deterministic one. As the dimension of the tree grows exponentially with the number of state variables, so does the complexity of Marketing Science 33(5), pp. 621-640, © 2014 INFORMS the deterministic problem. Decomposition methods are used to tackle this issue, as is the case in the Benders and Lagrangian schemes (see <ref type="bibr" target="#b13">Birge and Louveaux 1997)</ref>, but these methods may converge slowly in practice (see <ref type="bibr" target="#b20">Chun and Robinson 1995)</ref>. In contrast, the current paper first considers the decomposition of the original stochastic problem by using the law of iterated expectations on the value function, and after that, it solves new subproblems by using either value-iteration or policy-iteration algorithms. The approach implements a successive substitution iteration on the value functions of each subproblem, where one subproblem is solved using the previous value for another subproblem. The procedure is generally continued until the changes made by iteration are below some tolerance. In Appendix C, a proof of convergence for the algorithm is developed.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Solving SDP Problems Using a Bellman Decomposition Algorithm</head><p>In this section we present a new algorithm for solving the SDP problem (5) that circumvents the curse of dimensionality. The key idea of our methodology is to consider a set of smaller independent problems that have optimal solutions that coincide with the corresponding solution for the problem (5). The decomposition approach draws on the partition of the decision variables into individual and aggregate decisions, and this implies that there are subproblems that only consider individual decision variables and subproblems that only consider aggregate decision variables. To split the problem (5) into manageable subproblems, we consider the law of iterated expectations.</p><p>To simplify the exposition, we first consider the myopic problem:</p><formula xml:id="formula_6">v myop S t−1 = max A P e 1 e I E t−1 r 1 S 1t A P e 1 +r 2 S 2t A P e 2 +•••+r I S It A P e I</formula><p>where the expectation is defined with respect to a distribution F S t S t−1 e = i F S it S it−1 A P e i . Let A * , P * , e * denote the optimal decisions (which are measurable functions of S t−1 ) and R i S it e i = E r i S it e i A * P * S it e i . By the law of iterated expectations, we can formally express</p><formula xml:id="formula_7">v myop S t−1 = E R 1 S 1t e * 1 S 1t−1 +•••+E R I S It e * I S It−1 = i∈ max e i E R i S it e i S it−1</formula><p>The separable individual subproblems max e i • E R i S it e i S it−1 can be solved individually given A * P * . The advertising and pricing policies can be addressed as follows: given e * , if there exists a sufficient statisticsS = h S with low dimension such that</p><formula xml:id="formula_8">E i∈ r i S it A P e * i S t = E i∈ r i S it A P e * i S t = R S t A P</formula><p>then it also holds that the myopic problem can be written as</p><formula xml:id="formula_9">v myop S t−1 = E t−1 R S t A * P * = max A P E R S t A P S t−1</formula><p>where the decision variables A P common to all individuals are the solution of an aggregate subproblem just defined by the state variablesS t (with a significant reduction of the state dimension). In a sequential implementation, the optimal values of each subproblem are updated according to the most recent computed values (those corresponding to the last subproblems solved). In a parallel implementation, these values are updated from a previous iteration. This procedure is repeated until the optimality criteria for the myopic problem are satisfied.</p><p>Translating these ideas into a multistep dynamic decision model defined by objective Equations ( <ref type="formula">3</ref>) and ( <ref type="formula">4</ref>) and the dynamic constraints (2), we can consider r S t A t P t e t = P t − c 0 IS t − i∈ c i e it − c m A t whereS t is the average sales at time t and i∈ S it = IS t is the total sales. As a consequence, E r S t A t P t e * t S t A t P t = E r S t A t P t e * t S t A t P t = R S t A t P t asS t is a sufficient statistic for r S t A t P t e t . Then, the general policies A t , P t can be determined based on a single-state variableS t maximizing E R S t A t P t , which is not affected by the course of dimensionality. In addition,S t satisfies a simple recursive model</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>S t = S</head><p>t−1 +ḡ A t−1 P t−1 e t−1 +¯ t where¯ t = I −1 i∈ it andḡ A P e = i∈ g i A P e i /I. Notice also that the transition probability for this artificial-state variableS t is implicitly determined by the model as F s s A P e = G I s − s −ḡ A P e , where G I is the distribution of¯ t (it can be computed easily as a convolution). Also, the individual policy e it can be determined by maximizing R i S it e it = I • E r i S it A * t P * t e it S it e it , where S it satisfies (2) given A * t and P * t . In practice, the only restrictive condition that we will enforce affects the feasible decision set. We will assume that the feasible set S , where the decisions A P e are taken at each period of time, is a Cartesian product of subsets G S × e 1 S 1 × • • • × e I S I , where G S is the feasible set for general decisions A P that can be updated based on previous average sales, and × i∈ e i S i is the feasible set for individual decisions, so that S = A P e A P ∈ G S e ∈ × i∈ e i S i (6) Budgetary constraints cannot be accommodated here. However, we discuss how this assumption can be relaxed in the concluding section.</p><p>In summary, we define the following subproblems:</p><formula xml:id="formula_10">V i s i = max e it E 0 t≥0 t R i S it e it S i0 = s i for all i V s = max A t P t E 0 t≥0 t R S t A t P t S 0 =s (7)</formula><p>where R i S it e it and R S t A t P t are conditional expectations to the information subset at time t: </p><formula xml:id="formula_11">R i S it e it = I • E r i S</formula><p>given A * t , P * t , e * t the optimal decisions for time t. Subproblems V i s i i∈ andV s characterize the value function V • of the original SDP problem (5).</p><p>Proposition 3. The value functions defined in (7), with respective transition kernels (10), satisfy</p><formula xml:id="formula_13">V s = I −1 i∈ V i s i and V s =V s (9)</formula><p>Proof. By the law of iterated expectations, the subproblems V i s i for all i andV s satisfy where A t = A S t , P t = P S t , and e t = e S t . These equalities imply that V s = I −1 i∈ V i s i , and V s = V s almost everywhere.</p><formula xml:id="formula_14">E 0 t≥0 i∈ t r i S it A t P t e it = i∈ E 0 t≥0 t E r i S</formula><p>The advantage of these subproblems is that they are small by construction. For one set of subproblems, the decision variables are only the direct marketing intervention e it t≥0 . Once the solutions for these subproblems have been computed, the price and mass marketing intervention P t A t t≥0 are updated. This procedure is repeated until the convergence criteria for the problem (5) are satisfied.</p><p>To solve the subproblems separately, we need to know R i S it e it and R S t A t P t and the transition probabilities for V i s i andV s , respectively, given by i s i s i e i = E F i s i S it−1 A * t−1 P * t−1 e it−1 S it−1 = s i e it−1 = e i for all i</p><formula xml:id="formula_15">s s A P = E F s S t−1 A t−1 P t−1 e * t−1 S t−1 =s A t−1 = A P t−1 = P (10)</formula><p>However, this computation is not feasible because the optimal policy function A * P * e * is unknown.</p><p>To tackle this issue, we combine a decomposition approach with successive substitution iteration on the value functions of each subproblem, where one subproblem is solved using the previous value of another subproblem. Once the solutions for these subproblems have been computed, the decision variables are updated to their last computed values. The procedure is generally continued until the changes made in each iteration are below some tolerance. The main benefit of this approach is that it offers a convergence proof to the actual solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">The Algorithm</head><p>The general scheme of the algorithm is stated as follows: </p><formula xml:id="formula_16">s i s i e i = Pr S k it ≤ s i S k it−1 = s i e it−1 = e i i ∈ k s s A P = Pr S k t ≤s S k t−1 =s A t−1 = A P t−1 = P 2.3. Solve the SDP subproblems max e it ∈ i S it t≥0 E t≥0 t R k i S it e it S i0 = s i = V k i s i in e k it t≥0</formula><p>for each i ∈ , where i S it−1 = e i 0 ≤ e i ≤ē i S it−1 . </p><formula xml:id="formula_17">max sup t A k+1 t − A k t 1 + A k t sup t P k+1 t − P k t 1 + P k t sup t i e k+1</formula><p>it − e k it 1 + e k it &lt;</p><p>• Criterion 2:</p><formula xml:id="formula_18">sup S 0 I −1 i∈ V k+1 i S i0 −V k+1 S 0 1 + I −1 i∈ V k+1 i S i0 S 0 = I −1 i∈ S i0 &lt;</formula><p>where the superscript k denotes the current iteration and • is the supremum norm.</p><p>The specific details of the algorithm implementation are presented in Appendix B. Note that any classic method for solving the SDP problem such as value iteration or policy iteration can be applied in Steps 2.3 and 2.4 because the subproblems are small problems with just one state variable, using as an initial point the optimal policy computed in the previous iteration of the algorithm. Also, we deal with some of the same difficulties faced by traditional approachesthat is, how to compute the expectation and then solve the resulting optimization problem. In contrast to traditional approaches, we consider the approximation of the expectations via basis functions and combine collocation methods with numerical simulation. As a consequence, the resulting optimization problem is no longer a difficult problem. The convergence of the algorithm is discussed in Appendix C.</p><p>Note that the value function for the original problem V S 1 S I and the associated policy functions A P e S 1 S I cannot be graphically represented for more than two customers because of the dimension. However, graphical figures for these functions would be intuitive and user-friendly tools for marketing managers. Interestingly, our algorithm overcomes this problem by providing useful and visual tools for managers implementing CRM. After convergence of the algorithm at step k * to a numerical solution of the original problem, we can depict graphically in the plane the reduced value function V k * S and the associated reduced optimal policy functions A k * S P k * S to provide graphical rules for optimal planning of mass advertising and price (provided that the optimal individual e is implemented). Furthermore, we can depict in the plane the reduced value function V k * i S i and the associated reduced optimal policy function e k * i S i for the ith customer, providing a graphical rule for optimal planning of the marketing effort on individual i (provided that the optimal mass advertising and price have been implemented as well as the effort on other individuals).</p><p>After convergence, we can compute the classic policy functions A P e S 1 S I and value function V S 1 S I by implementing one iteration of the classic value method starting from the reduced value function V k * S . The norm of the Bellman equation at this iteration provides a validation for the computed solution.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Some Numerical Simulations</head><p>Let us consider a sales dynamic panel model of the form</p><formula xml:id="formula_19">S it = S it−1 + 1i + 1i e it−1 + 2i A t−1 + 3i P 4i t−1 + it where 1i 2i &gt; 0, &lt; 1, e it t≥1</formula><p>is the individual marketing effort, A t t≥1 is the mass marketing effort, P t t≥1 is the price, and it t≥1 is the independent white noise process N 0 I . We assume that e it t≥1 and A t t≥1 are given by a cost function c x = x , where &gt; 0. Then, given ∈ 0 1 , the firm aims to maximize the expected net present value E 0 t≥0 t r S t A t P t e t with r S t A t P t e t = P t − c 0</p><formula xml:id="formula_20">i∈ S it − c A t − i∈ c e it</formula><p>We have implemented our decomposition algorithm using MATLAB 7.6 on an Intel Core vPro i7 with machine precision 10 −16 . The algorithm stops whenever = 10 −8 . First, we consider a simplified model in which prices are considered as given, i.e., 3i = 0, and using a constant exogenous margin m 0 instead of P t − c 0 . For m 0 = 50, = 0 2, i = 60, 1i = 1 2, 2i = 1 2, and = 5, Table <ref type="table" target="#tab_5">1</ref> reports the number of iterations to  satisfy the stopping criteria and run times (in seconds) until convergence for different numbers of customers I as well as both policy iteration and value iteration algorithms to solve Steps 2.3 and 2.4 of the algorithm.</p><p>Next, we extend the basic model to the general case for which prices are considered a decision variable. For c 0 = 50, = 0 2, i = 60, 1i = 1 2, 2i = 1 2, 4i = −0 5, 3i = 0 5, and = 5, Table <ref type="table" target="#tab_6">2</ref> reports the run times (in seconds) until convergence for different numbers of customers I. The results show that the proposed algorithm is capable of solving the problem with many customers in a reasonable amount of computer time.</p><p>These results suggest that the proposed methodology is an effective and useful tool for solving these types of problems because it breaks down a high-dimensional problem into many low-dimensional ones, hence reducing the curse of dimensionality. It is noteworthy that the standard policy iteration approach cannot solve a problem with more than three customers.</p><p>Studying the computational time per step, we have found that the steps that require the most computation are those that solve the subproblems (between 70%-75% of the total computational effort). For each subproblem, we consider either a standard value iteration or policy iteration algorithm that updates the value or policy for all states at the same time. In practice, several well-known numerical techniques can be used to improve performance (e.g., exploiting sparsity in matrix operations, exploiting the information about the parametric model to speed the computation of the integrals). Our simulations are based on a standard implementation to make it clear how the basic method works.</p><p>Table <ref type="table" target="#tab_7">3</ref> reports run times (in seconds) until convergence, obtained from larger problems with a different number of customers. If we use value iteration, the 2,000 customers' problem is solved in 19 hours and 44 minutes, without using parallelization.</p><p>To solve larger-scale problems, we must implement the algorithm in a parallelized way. Scalability is the crucial advantage of decomposition operation research methods. One of the most common procedures to do this consists of implementing the code in High Performance Fortran (HPF), an extension of Fortran 90 that supports parallel computing. Some vendors of Fortran compilers incorporate HPF into their products, but most users have now moved to OpenMP, a parallel processor program that works with Fortran, C, and C++. Therefore, at each step of the algorithm all the individual subproblems would be computed in parallel. Clearly, parallelization is an advantage if the code is run on a parallel computer. Although here are many types of parallel computers-for example, those that use superscalar processors (which can issue multiple instructions per cycle from one instruction stream)-there are huge advantages if the code is run on a computer with multicore processor (which can issue multiple instructions per cycle from multiple instruction streams). Sometimes parallelizations are implemented in a network of computers communicated through the Internet (which is known as distributed computing), but we can use a single computer with many networked processors (known as a massively parallel processor).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Validation</head><p>This section provides empirical validation for the algorithm, and it shows a comparison with an ADP algorithm. ADP approaches are widely used because approximate value functions can work well in some problems, but if the approximations do not capture the true behavior of the value function, the algorithms can diverge. There is a wide variety of ADP algorithms. For our validation, we have chosen the standard Q-learning approach (see Figure <ref type="figure">8</ref>.4 in <ref type="bibr" target="#b47">Powell 2007)</ref>. We validate the quality of the solution using the Bellman operator, which is similar to the Bellman operator v defined in (A1). The true solution is a fixed point V such that Marketing Science 33(5), pp. 621-640, © 2014 INFORMS V = V . Therefore, we have studied the performance of both approaches computing the maximum relative error V − V / 1 + V , albeit the 1 in the denominator can be removed if V S is never null. To do so, after our algorithm converges to the limit point V k * S , we iterate a single step of classic value iteration to compute the typical value function V S . Table <ref type="table" target="#tab_8">4</ref> reports the numerical performance of both the ADP and proposed approaches for different numbers of customers. As a general overview, we can observe that the ADP approach is reasonable for small problems (I = 1), as is our proposed algorithm. However, the ADP approach is an approximation method, so the ADP solution is an optimal approximation of the actual solution (and the percentage error is about 12%). When I = 1, our approach just solves the actual Bellman equation (V = V ) discretized conveniently, as described in Appendix B. The contribution of the proposed approach can be better observed when considering I ≥ 2 customers. A standard ADP algorithm can suffer from the curse of dimensionality because it needs to discretize the state and action spaces.</p><p>ADP approaches are essentially approximation methods that replace the expectation of the value function in the Bellman equation with some sort of statistical approximation. For the case of one customer, the quality of the Q-learning solution is worse than the one provided by our algorithm, which in this case it is just a Bellman iteration (there is no decomposition needed). For I = 2, the ADP relative error V − V /V is locally larger for some states (the worst state renders an error of 36 99 versus 0 15 in our method), which is a direct consequence of the fact that not all states are visited. We have also computed V − V / V , which is equal to 0 99 for ADP and to 0 15 for our algorithm, showing that globally both methods work reasonably well for this size problem. But when the number of customers grows, the differences between both approaches become critical. Because ADP approaches do not exploit the structure of the problem, when considering five customers the ADP algorithm simply overflows. If we apply our method with I = 5 customers, the relative error is 0 55 (also V − V / V = 0 55). This level of accuracy may suffice for some applications, but perhaps not for all of them. A hybrid method could be applied to improve accuracy, alternating a  single iteration of the classic value function and our decomposition method initialized in the output of this iteration. This strategy could be used to reduce the relative error at a generally affordable cost, an issue which we have left for future research.</p><formula xml:id="formula_21">V − V /V (seconds) V − V /V<label>(</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">An Empirical Application of a Manufacturer of Kitchen Appliances</head><p>In this section we provide an empirical application of the method by considering a medium-sized international wholesale company based in Eastern Europe. (For reasons of confidentiality, the name of the company is withheld.) This company distributes and manufactures a large range of built-in electric kitchen appliances (such as cookers, ovens and hobs, cooker and chimney hoods, external motors, microwaves, dishwashers, washing machines, refrigerators, and related accessories). A large share of the company resources is devoted to general marketing activities (mainly advertising and promotions in professional fairs). The company intends to improve the marketing budget allocation on general advertising (fairs and magazines) and on the budget invested in developing sustainable personalized relationship with its clients (for instance, bearing the cost of entertaining and gifts when visiting clients). Here, we have an aggregate variable that comprises all of this one-to-one marketing effort. We use a monthly client panel with 7,002 observations from the company spanning from January 2005 to December 2008. The panel is unbalanced, but the vast majority of the clients purchase practically every month within the sample period. Because the company sells a range of products with different sales to each client, they aggregated their data, thus providing us with the monthly net profit drawn from each client. The data set consists of 2,180 products sold to 268 different clients located in four different geographical markets: Asia (which represents 4.24% of the sample), English North America (ENA, comprising the United States and Canada; 19.98%), Europe (40.43%), and Latin America and South America (LASA; 35.35%). Except for the issue of location, there are no other differences between these regions.</p><p>The data set includes cash flows from each customer, information on general marketing activities investments (such as magazines advertising or exhibitions), and investments in consumer marketing activities at the client level. On average, the general marketing activities investments of the company in our sample is approximately $1.3 million, and investments in consumer marketing activities are about $26,404 and are skewed to the right. Both data series are stable around this average, and in general, the company devotes 97% of the promotional budget to general advertising activities and the remaining 3% to individual advertising activities. In general, the company's policy is to apply different levels of individual advertising across its clients. The investment in mass and individual advertising does not vary significantly across location, but for those clients located in ENA, the investment on individual advertising is on average four times larger than the sample. The net return is not affected by the location of the company. Because we do not have sociodemographic characteristics of the different customers, we therefore model heterogeneity by using a dynamic panel with individual random effects. Despite its limitations, this database is particularly suitable for studying the interrelationships between profits and mass marketing and individual investments.</p><p>Let Y i t denote the financial cash flows (returns) obtained from client i at the period of time t, let e i t denote the individual marketing effort for client i at the period of time t, and let A t denote the general marketing effort at period of time t. Then the company aims to maximize the returns function:</p><formula xml:id="formula_22">r Y t A t e t = I i=1 Y it − A t − I i=1 e it (11)</formula><p>Our first step is to define the transition equation for returns. We consider the dynamic panel specification of a basic Markovian model, i.e.,</p><formula xml:id="formula_23">Y i t = Y i t−1 + 1 ln A t−1 + 2 ln e i t−1 + i + u it E u i t X i t = 0 E u i t = 0</formula><p>for all i t, where &lt; 1, u i t is white noise and i is a zero mean random coefficient accounting for individual heterogeneity in client profitability levels. The noise v it = i + u i t is autocorrelated due to the stability of i , and therefore the ordinary least squares and the within-group estimators are both inconsistent (as Y i t−1 is a regressor). Taking first differences in the model, we eliminate the specific group effects:</p><formula xml:id="formula_24">Y i t = Y i t−1 + X i t−1 + u i t t = 2 T (12)</formula><p>where X i t−1 = ln A t−1 ln e i t−1 . The errors u it are no longer independent but follow a noninvertible MA 1 . This equation can be estimated by instrumental variables (IVs), as proposed by <ref type="bibr">Andersen and Hsiao (1982)</ref>. It is convenient to use lags of the variable in levels Y i t−1 as an instrument (as well as lags of other exogenous regressors). Nonetheless, the IV estimator is not efficient because only a few moment conditions are used. <ref type="bibr" target="#b3">Arellano and Bond (1991)</ref> proposed a generalized method of moments estimator dealing with this problem. Because <ref type="bibr" target="#b3">Arellano and Bond (1991)</ref> estimators can perform poorly in certain cases, the method was refined by <ref type="bibr" target="#b16">Blundell and Bond (1998)</ref>, who include additional moment conditions (building on previous work by <ref type="bibr" target="#b4">Arellano and Bover 1995)</ref>. The model used in this paper was estimated in STATA using the Blundell-Bond refinement. We consider the Arellano-Bond estimation approach, which considers lagged levels as well as lagged differences as instruments. In particular, we compute the estimates using the command xtdpdsys implemented in STATA. Table <ref type="table" target="#tab_9">5</ref> reports the estimators of model ( <ref type="formula">12</ref>). The Wald global significance test is 1 299 38 distributed as a 2 3 with a p-value of 0 0000. In a model with one lag of the dependent variable, k strictly exogenous variables, and p = T − 2 periods from which to form moment equations, there are k + p × p + 1 /2 moment conditions (see <ref type="bibr" target="#b3">Arellano and Bond 1991)</ref>. Because the number of clients is n = 268, there are two strictly exogenous variables k = 2, and there are panel data of T = 48 periods of time, the number of instrument variable considered here is 1 083.</p><p>After the model coefficients have been estimated, because T is large, we can consistently estimate each specific intercept i . For each client we need to take time means on the panel regression equations and then replace T t=1 u it /T by zero (the expected value), finally getting the estimator of i . Then, we compute the values of i accounting for individual heterogeneity in client profitability levels as i = 1 − Ȳ i − 1 ln A − 2 ln e i whereȲ i t−1 ln A t−1 , and ln e i t−1 are the average values of returns, individual marketing effort, and general marketing effort by client i, respectively. Since this is a vector of 268 coordinates, one per client, these estimates are not reported because of the length. Using this approach, we model the complete heterogeneity of the clients. Our next step is to compute the optimal general advertising and marketing effort policies. We have applied the proposed decomposition method to the objective (11) and the transition Equation ( <ref type="formula">12</ref>) with 268 clients. We consider a state discretization with 10 scenarios (disguised sales levels at company request for confidentiality) for each segment sales variable and 20 equidistant knots for each variable control (policy). We have applied a policy iteration approach to solve each subproblem (although satisfactory results have been found using a value policy iteration approach). The proposed algorithm converges in 17 iterations (about 30 minutes), stopping when the convergence criteria for the global problem is satisfied with = 10 −4 (and setting the termination tolerance for the subproblems as = 10 −3 ). The results reveal the efficiency of States Individual value functions the methodology in terms of computing time and accuracy for practical purposes. All figures have been scaled to preserve the nondisclosure agreement for the data. In Figure <ref type="figure">1</ref>, individual reduced value functions V i s i are shown with respect to the different sales state levels. As a general rule, customers located in Europe have the largest value function in all sales states, whereas customers in LASA and Asia have the smallest expected returns in all sales states. European customers also require more marketing effort per individual than others, whereas Asia requires less marketing effort per individual.</p><p>In the estimated model the heterogeneity is confined to the intercept, which is why the reduced value solution are parallel. Figure <ref type="figure">2</ref> presents the histogram of intercepts of the individual reduced value functions. Clearly, each customer brings a different value to the company, which is consistent with the recent literature focusing on one-to-one marketing and the customer lifetime value in a dynamic setting <ref type="bibr" target="#b40">(Lewis 2005</ref><ref type="bibr" target="#b59">, Rust and Verhoef 2005</ref><ref type="bibr" target="#b38">, Khan et al. 2009</ref>). In Figure <ref type="figure">3</ref>, we show the optimal general marketing policy A s , demonstrating that the optimal budget allocated to general marketing activities decreases with respect to the states. In contrast, the companies behave optimally if the individual marketing effort essentially remains constant with respect to individual states, although the level of this effort is different for each client-larger in the case of the most profitable clients (located in Europe) and lower for the least profitable clients (located in Asia).</p><p>The optimal proportion of effort that the company should devote to the general advertising campaigns and one-to-one marketing is given in Table <ref type="table" target="#tab_10">6</ref>. The optimal decision recommends that a much larger share of communication budget should be invested in individual marketing effort rather than on general advertising, which is not what the company is actually doing. Interestingly, the marketing department is currently pondering this decision (the advisability of moving from general to one-to-one marketing), and our results can help them reformulate their strategy. Notice also that the relative weight of general advertising is reduced when the state variable level is larger.</p><p>This result contrasts with the current policy of the company (which devotes 97% of the promotional budget to general advertising activities and the remaining 3% to individual advertising activities). Our finding that the company obtains higher expected return by spending more on individual-level marketing relative to mass-level marketing is in line with <ref type="bibr" target="#b38">Khan et al. (2009)</ref>, who show that customized promotions are  Periods of time Expected net return more profitable than mass promotions. Our optimal allocation also justifies that the company should spend more on one-to-one marketing to boost its long-term customer profitability <ref type="bibr" target="#b46">(Peppers et al. 1999)</ref>.</p><p>Next, based on the optimal policy and the estimated panel model, we have simulated 1,000 paths of optimal cash flow realizations starting at the cash flow for the first period of the sample, and we have computed the expected net return and the 95% confidence interval for 20 periods of time (see Figure <ref type="figure">4</ref>). The monthly expected returns of the company in our simulation are $21 1 million with a standard deviation of 3 31 × 10 4 , whereas in the actual data set the average returns are $20 6 million with a standard deviation of 6 88 × 10 6 . During this period, the company draws an average of a half million dollars less than the expected monthly return based on the optimal SDP policy (but it also has higher variability).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusions</head><p>There is a growing interest among firms in customizing their marketing activities to smaller and smaller units of "individual stores, customers, and transactions" <ref type="bibr" target="#b18">(Bucklin et al. 1998)</ref>. This implies an enormous number of decisions and is on a scale that requires decision automation tools based on dynamic optimization of small unit panels.</p><p>In this paper, we make a computational contribution to solving SDP problems. This allows forward-looking firms to allocate their marketing budgets by optimizing the CLV of their customer base, simultaneously using customized and mass marketing interventions. The solvability of these models suffers from the curse of dimensionality, and from a modeling standpoint, this limits practitioners. In this sense, we have introduced a novel decomposition methodology for the computation of solutions for large-scale CRM problems. The proposed approach deflates the dimensionality of the models by breaking the problem into a set of smaller independent subproblems. With the numerical results revealing the efficiency of the methodology in terms of computing time and accuracy, it may be concluded that the proposed approach could be applied to many marketing problems with a similar structure.</p><p>We have shown that the decomposition method works well in practice, having been successfully applied to assess more than 260 customers of a medium-sized international wholesale company. In addition, we have presented a customer profitability analysis of the company, simultaneously considering the effect of direct marketing and mass marketing interventions at the customer level. We did not have access to specific information about each customer, and our heterogeneity analysis is relatively basic, including all heterogeneity in the individual intercepts. More interesting models can be estimated when this information is available. Note also that the presented framework considers the optimal decision for the firm based on the actual customer base. To extend this framework to a decisionmaking situation where potential customers could be attracted, we could consider an additional segment or residual customers in which the attractions and churn of new customers could be accounted for. (This segment would be affected by general advertising but not an individual marketing effort.)</p><p>Because CRM databases do not often involve panel data across several competitors, no competitive effects have been considered in this paper. To include competition, we should consider a behavioral model for several firms competing for the same customers with mass and customized marketing actions, with the equilibrium being given by the Markov perfect equilibrium (see <ref type="bibr" target="#b23">Dubé et al. 2005)</ref>. The decomposition algorithm presented in this paper could be a useful tool for addressing the formidable computational effort required to solve this problem. At the moment, however, this a problem best left for future research.</p><p>Marketing Science 33(5), pp. 621-640, © 2014 INFORMS There are other limitations as well as future research opportunities. The key idea of the proposed approach is to split a problem into manageable pieces (subproblems) and coordinate the solutions of these subproblems. Therefore, a crucial assumption seems to be the separability of the feasible decision set into individual and aggregate decisions. The separability of S apparently precludes the use of budgetary constraints, such as S = A P e i∈ c i e i + c m A ≤ M or (13)</p><formula xml:id="formula_25">S = A P e i∈ c i e i + c m A − P t − c 0 i∈ S i ≤ 0 (14)</formula><p>However, this limitation can be overcome considering the augmented Lagrangian relaxation approach (see <ref type="bibr" target="#b61">Ruszczynski 1995)</ref>. The basic idea is to introduce the coupled constraint into the objective function as a barrier term and then to decompose the problem into a set of subproblems, as in the proposed approach here. The separability of the subproblems is obtained by fixing the values of some variables. In particular, for the case of ( <ref type="formula">13</ref>), we would consider the augmented Lagrangian objective function:</p><p>r a S t t A t P t e t = i∈ r i S t A t P t e it − t i∈ c i e it − c m A t − M and we apply our algorithm to the augmented function r a S t t A t P t e t , considering t as another control variable (similar to A t P t ) with a feasibility constraint t ≥ 0. We leave the details for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Technical Review on Algorithms for SDP Problems</head><p>Except for relatively simple cases, the value function cannot be solved analytically, and some numerical algorithms must be implemented. Consider the Bellman operator v = max</p><p>A P e ∈ s r s A P e + v s F ds s A P e (A1)</p><p>transforming an arbitrary function v s of the state variables into another function v s . Obviously, that value function is a fixed point of , i.e., an element V = v * such that v * = v * . Solving a fixed-point equation is challenging, not just because the unknown is a function but also because v involves a maximum.</p><p>For a given feasible policy A P e s , which is not necessarily optimal, we also consider the mapping A P e v = r s A P e + v s F ds s A P e which is a function of s. The most commonly used algorithms to compute the value function (and the policy function) work with v and A P e v .</p><p>• The value iteration algorithm iterates v j ←− v j−1 , where the update is implemented for each state s, and its convergence is ensured under mild conditions using the fixed-point theorem for contractive mappings (see Appendix C). This was initially proposed by <ref type="bibr" target="#b6">Bellman (1955</ref><ref type="bibr" target="#b7">Bellman ( , 1957</ref> for discrete problems. Unfortunately, the speed can be slow, and when the dimension of the problem is large, it becomes useless.</p><p>• The policy function algorithm iterates in two steps: (1) policy improvement computing the policy associated with the previous iteration A P e j ← arg max A P e v j−1 which is computed for each state s; and (2) policy valuation computing the value function associated to the previous step v j ←− A P e j v j−1 . Under fairly general conditions, policy iteration can be shown to generate a monotonically improving sequence of functions v j ≥ v j−1 . This method was initially proposed by <ref type="bibr" target="#b36">Howard (1960)</ref>, and the convergence is studied by <ref type="bibr" target="#b49">Puterman and Brumelle (1979)</ref>, who also provided an interpretation of this method as a Newton algorithm. It is also possible to consider a hybrid, implementing several steps of value iteration before implementing a policy iteration (see <ref type="bibr" target="#b50">Puterman and Shin 1978)</ref>. We gain speed using a policy function, but in large problems, the curse of dimensionality takes its toll, and the method also becomes useless.</p><p>There is another approach that has been generally considered a theoretical result, but it is increasingly used as a computational algorithm. From the Bellman equation, for any function v s different from the fix point, it holds that v s ≥ v , so we can consider the value function as the solution to the linear program min v s F ds s A P e v s ≥ r s A P e + v s F ds s A P e for all s A P e</p><p>Unfortunately, there are an infinite number of constraints when the number of states and feasible controls is infinite. Semi-infinite programming algorithms can handle some of these problems, but the method is not widely used.</p><p>Alternatively, some authors work with the first-order conditions associated with the right-hand side of the Bellman equation, leading to an expression called the Euler equation, and try to solve it using the parameterized expectations approach (see <ref type="bibr" target="#b43">Marcet and Marshall 1994)</ref>. But in general, convergence is not guaranteed.</p><p>Clearly, all these algorithms can be directly applied only if the number of states is finite (i.e., the process follows a Markov chain) and the integral is a summation that can be analytically computed (provided that the number of states is not too high and the summations and maximization decisions for each state can be computed quickly). In the general case with continuous states, however, these algorithms are not feasible and are combined with elements from functional analysis.</p><p>Continuous SDP problems are usually solved by combining the ideas of value iteration and policy iteration with collocation methods. The basic idea of collocation methods is to consider a sequence of functions k k≥1 ⊂ B such that any function v ∈ B can be expressed asymptotically as a linear combination of these functions, or more formally, for all v ∈ B ,</p><formula xml:id="formula_26">inf k K k=1 v s − K k=1 k k s K→ −→ 0</formula><p>Therefore, we can express V s ≈ K k=1 k k s for some coefficients k and a large enough K. Several classes of functions can be used for the approximation (e.g., Chebyshev polynomial, splines, neural networks). When the state variable is multidimensional, the base functions are generally obtained by tensor products on univariate basis. The integer K is exponentially increased with the dimension to obtain a good approximation (this is one type of the curse of dimensionality). Notice that the continuous SDP problem can be approximated by another problem with finite states (only considering a finite partition k of the Euclidean state's space , we can approximating v by simple functions K k=1 k I s ∈ k , choosing a representative scenario s k for each element of the partition and interpreting k = v s k ).</p><p>The coefficients k K k=1 are unknown, and the collocation method approximates a functional equation in such a way that the approximated function fits exactly at the prespecified points of the domain. Then, Bellman's equation becomes The solution of this system is not trivial, and we first need to evaluate the conditional expectations k s F ds s m A P e (A4)</p><p>for states m = 1 K, often using a numerical integration methods.</p><p>The numerical computation of these K integrals by means of weighted sums requires some type of discretization. There are many procedures to do this: using deterministic Riemann sums, using Monte Carlo approximations based on simulations from F ds s m A P e or refinements such as importance sampling, using other quasi-Monte Carlo methods, or considering weighted deterministic sums based on simple functions as considered by <ref type="bibr" target="#b70">Tauchen (1986)</ref>; the last is the method that we will apply. In all these methods, the integrals are replaced by a weighted average at discrete points, and the number of required points required to have a good approach increases exponentially with the dimension of the state variables (this the origin of the curse of dimensionality). There is no solution for this problem. Any solution should exploit peculiarities of the model, as we are considering in this paper.</p><p>• The value iteration method considers the system = −1 and iterates the following:</p><formula xml:id="formula_27">←− −1</formula><p>from an initial point 0 .</p><p>• The policy iteration method uses the Newton iterative updating:</p><formula xml:id="formula_28">←− − − −1 −</formula><p>where is the Jacobian of the collocation function at that can be computed by applying the envelope theorem to the optimization problem in the definition of so that mj = j s F ds s m A P e</p><p>Notice that when the approximation method is based on simple functions, then is the identity function, and we can omit this factor. Each time the operator is applied, we must solve the maximization problem in m for all states s m ∈ s 1 s K . This can be done in a variety of ways, e.g., using a global optimization algorithm. In many applications, the maximization is carried out discretizing the decision space s m . Once we have converged, V s = K k=1 k k s , and the optimal policy is computed at each state s m ∈ s 1 s K , as the maximizing decision taken at m for the last iteration and the function is computed interpolating these points. The main problem with all the previous techniques is the curse of dimensionality <ref type="bibr" target="#b8">(Bellman 1961)</ref>. So far, researchers have only been able to solve numerically SDP problems with few state variables. For additional information, see <ref type="bibr" target="#b48">Puterman (1994)</ref> and <ref type="bibr" target="#b11">Bertsekas (2005)</ref>.</p><p>There are some variants of value iteration and policy iteration that aim to accelerate the algorithms. A popular one implements a Gauss-Seidel approach, where the update takes into account previous computations of the value function. This is typically implemented when the number of states is countable, or with collocation methods. For example, in a Gauss-Seidel value iteration we consider a sequence of states s m m∈ and update sequentially all the states v j ←− v j−1 , This corresponds to the Gauss-Seidel method to solve the nonlinear system of equations v s m = v s m m≥1 . Another example is the asynchronous value iteration based on the Gauss-Seidel value iteration, but the states are not updated in order but follow an arbitrary infinite sequence of states such that every state occurs infinitely often. But the method aims to visit all possible states. An alternative option is given by real-time methods, where the sequence of states is generated by simulating the Markovian system, but only the generated states are updated at each stage. At each step j, if state s m is selected, the optimal policy is computed only for that state as the argument maximizing r s m A P e + v j−1 s F ds s m A P e , and the optimum is used to update the value function at s m for all the remainder states v j+1 s = v j s . Then another state is generated from the state equation. The algorithm is faster, because the process does not necessarily explore the whole state space, but we do not necessarily obtain a globally defined optimal policy and in general convergence is not guaranteed. Similar ideas hold in the case of policy iteration, when the policy evaluation and policy improvement are only approximately implemented. These methods are generally known as ADP methods, which essentially plays with Monte Carlo simulations to estimate the value function. Instead of updating v for all possible states s (as in value iteration), in ADP only a few states s i are updated that are drawn from F s s i−1 A P e j−1 . Given the sampled updates, the value function is estimated using a recursive formulas (analogously to the recursive estimators proposed in the "stochastic approximation" literature). (For a review, see <ref type="bibr" target="#b47">Powell 2007.)</ref> In this context, researchers can set decisions to improve the quality of the Monte Carlo estimation (which is called "exploration") or the quality of the decision (which is called "exploitation"). But as we mentioned before, ADP does not always work well, and its convergence is not generally guaranteed. These algorithms are compatible with our methodology (in the sense that they can be used to solve each subproblem), but we do not emphasize their use.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. Algorithm Implementation</head><p>In this section we review the implementation of the algorithm. To understand the details of our approach, first read Appendix A, where we build on these ideas. The key points are the collocation and the discretization to numerically compute the required integrals to apply value iteration or policy function iteration in the subproblems.</p><p>Step 1. The first step follows the discretization technique. For the most part, we consider a grid of controls, A P e 1 e I , containing a discretization of the feasible decision set. In particular, we consider relatively large finite intervals for each decision and introduce N equidistant points for each decision.</p><p>Step 2.1. The second step is the definition of the scenario nodes and transition probabilities across scenario states. The unconditional distribution can be used to define a grid of representative state values, and the conditional distribution to compute the transition matrix across the elements of the grid. In particular, we consider model (2), S it = S it−1 + g i + it , where it = i + u it ∼ N 0 2 i with 2 = 2 + 2 u , and</p><formula xml:id="formula_29">S it S it−1 A P e ∼ N S it−1 + g i 2 S It S It−1 A P e ∼ N S It−1 +ḡ 2 I</formula><p>with g i = g i A P e i ,ḡ A P e = i g i A P e i /I. The stationary marginal distributions of S ti andS t are N g i A P e i / 1 − , 2 / 1 − 2 and N ḡ A P e i / 1 − , 2 / I • 1 − 2 , respectively. For the ith customer, we set scenarios in the interval S l i S u i , where</p><formula xml:id="formula_30">S l i = min A P e i g i A P e i 1 − − 5 2 1 − 2 S u i = max A P e i g i A P e i 1 − + 5 2 1 − 2</formula><p>Therefore, we cover five times the standard deviation from the most extreme mean values. After checking that max S l i 0 &lt; S u i we generate N scenarios distributed uniformly as</p><formula xml:id="formula_31">s i1 = max S l i 0 s iN = S u i s in = s i1 + s iN − s i1 N − 1 n − 1 n = 2 3 N − 1</formula><p>Next we define the product space of states I = I i=1 s i1 s iN . The discrete scenario grid I can be used to compute the Bellman problem, defining the value functions and the policy functions as mappings defined on I . Notice that we are considering equidistant points in the grid. If the states variable distribution is highly nonlinear with several modes, it could be convenient to increase the density of points in some locations of special interest. (This is not as relevant with Gaussian data.) The functional base used to approximate the value function is also relevant. Some functional bases provide better approximation using specific points (e.g., wavelets perform better using the dyadic points and Chebyshev polynomials using specific polynomial roots). In our context, based on simple functions, a uniform grid provides a good enough fit.</p><p>To implement our algorithm, it is convenient to think of an augmented space of states including mean sales. Consider the mean interval S l S u , with S l = i∈ S l i /I and S u = i∈ S u i /I, and generate N scenarios s 1 s N distributed uniformly in max S l 0 &lt; S u . Therefore, we can define the augmented space as</p><formula xml:id="formula_32">I+1 = s s s = s 1 s I ∈ I s 1 I i∈ s i</formula><p>where " " means thats is the scenario in s 1 s N closest to i∈ s i /I. Thus, a specific realization of the random vector S t S t will be approached by a vector s s ∈ I+1 . Given the structure of the problem, we can define the policy functions A k P k e k in the augmented space as a mapping:</p><formula xml:id="formula_33">A k P k e k I+1 s → A k s P k s e k 1 s 1 e k I s I ∈ A P e 1 e I</formula><p>The value function can be approximated in I+1 by a simple function:</p><formula xml:id="formula_34">v s s = n 1 n I n I+1 n 1 n I n I+1 • I i=1 I b n i −1 &lt; s i ≤ b n i • I b n I+1 −1 &lt;s ≤ b n I+1</formula><p>A smooth functional basis could be considered instead of simple functions, e.g., replacing the product of indicator functions by a tensor product of orthonormal polynomials.</p><p>Step 2.2. To marginalize the effect of some policy controls over the subproblem objective functions (8) and the transition probabilities, we apply the Monte Carlo method. First, given the policy A k P k e k , we recursively generate a sample S k</p><formula xml:id="formula_35">t A k t P k t e k t T t=1 as S k it = S k it−1 + g i A k t−1 P k t−1 e k it−1 + it i ∈ S k t−1 = I −1 i∈ S k it</formula><p>with i ∼ N 0 2 i I T and S k i0 = 0, and we recursively compute the associated controls as follows:</p><formula xml:id="formula_36">A k t = N n=1 A k s n I b n−1 &lt;S k t−1 ≤ b n P k t = N n=1 P k s n I b n−1 &lt;S k t−1 ≤ b n e k it = N n=1 e k i s in I b i n−1 &lt; S k i t−1 ≤ b i n i ∈</formula><p>where b n = s n+1 +s n /2 and b i n−1 = s i n+1 + s i n /2 for n = 1 N − 1, and we set b 0 = b i 0 = − and b N = b i N = + . The last expressions are used because the policy functions are defined for discrete scenarios-for example, we set A k t = A k s n wheneverS k t−1 ∈ b n−1 b n , which is the interval centered ins n . For the considered period of study T = 1 000, we simulate the behavior of sales, mass advertising, direct advertising, and prices for T + 100 times to discard the first 100s, but the figure T could be increased when the diameter of the feasible decision set or N increases. The computation of the sample should be done for each iteration, but it only takes a few seconds in all instances.</p><p>To properly define the objective function for each subproblem, we compute certain conditional expectations and transition kernels using the simulated sample S k t A k t P k t e k t T t=1 . First, for all i ∈ we compute the conditional expectations </p><formula xml:id="formula_37">P k in = E P k t S k it = s in , C k in = E c m A k t S k it = s</formula><formula xml:id="formula_38">R k i s in e it = I • P k in − c 0 • s in − c i e it − I −1 C k in R k s n A t P t = P t − c 0 • I •s n − i∈ c k in − c m A t</formula><p>The fastest method to compute the conditional expectations is based on a simple parametric regression model (e.g., specifying E P k t S k it = s i = p s i ). The model is estimated by a least squares method (e.g., minimizing T t=1 P k t − p S k it 2 ) for direct use (setting P k in = p s in ˆ K for each discrete scenario s in ). The parametric approach works well in our application. Alternatively, we can use a nonparametric estimator. For example, the Nadaraya-Watson estimator of E P k t S k it = s in is given by</p><formula xml:id="formula_39">E P k t S k it = s in = T t=1 P k t K h T S k it − s in T t=1 K h T S k it − s in</formula><p>where K h T u = h −1 T K u/h T for an arbitrary kernel density K • (e.g., a standard normal density) and a sequence of positive smoothing parameters h T such that h T + Th T −1 → 0. This approach avoids specification assumptions, but it requires larger sample sizes T than the parametric approach. In addition, an optimal selection of the smoothing parameter is crucial, which is time consuming. However, it might be convenient in some applications.</p><p>Next, we compute the marginal transition kernels k s i s i e i and k s s A P . There are several possibilities: parametric methods, semiparametric, and nonparametric. The fastest method is based on a parametric regression model,</p><formula xml:id="formula_40">E S k it S k it−1 e k it−1 = m i S k it−1 e k it−1 i , E S k t S k t−1 A k t−1 P k t−1 =m S k t−1 e k it−1</formula><p>. It estimates the model by a ordinary/nonlinear least squares method. In our applications, we consider this method for a linear parameter model without intercepting where the first regressor is in levels and the controls are in logarithms. Assuming that the errors are conditionally independent of the state variables, we can use the residualsû</p><formula xml:id="formula_41">it = S k it − m i S k it−1 e k it−1 ˆ i ū t =S k t −m S k t−1 A k t−1 P k t−1 ˆ</formula><p>to estimate the error densities g i u it ,ḡ ū t . In particular, we have assumed Gaussian distributions N 0 2 u i and N 0 2 u , respectively, and estimating the variances 2 u i and 2 u t with the mean squared residuals, we get</p><formula xml:id="formula_42">i s i s i e i = 1 u i s i − z − m i s i e i ˆ i ˆ u i dz = s i − m i s i e i ˆ i ˆ u i s s A P = 1 ū s − z −m s A P ˆ ˆ ū dz = ū t − s −m s A P ˆ ˆ ū</formula><p>Notice that if it is difficult to determine the residuals distribution, we could estimate g i u it ,ḡ ū t nonparametrically. For example, integrating the Rosenblatt-Parzen kernel density estimator, we obtain a cumulative conditional distribution: where K h T u = h −1 T K u/h T . This semiparametric method slows down the algorithm compared with the parametric case. The last alternative is a fully nonparametric estimator such as the cumulated integral of the conditional density estimator formulated by <ref type="bibr" target="#b55">Roussas (1967</ref><ref type="bibr" target="#b56">Roussas ( , 1969</ref>  </p><formula xml:id="formula_43">i s i s i e i = s i − 1 T − 2 T t=2 K h T û it − z − m i s i e i ˆ i</formula><formula xml:id="formula_44">S k t −z K h T S k t−1 −s K h T A k t−1 −A K h T P k t−1 −P • T t=2 K h T S k t−1 −s K h T A k t−1 −A K h T P k t−1 −P −1 dz</formula><p>This method requires very large simulated samples and is sensitive to the selection of the smoothing number that must be optimally determined. In general, we do not recommend it for this algorithm, but it might be useful in some applications.</p><p>To apply the collocation method for the Bellman equation associated with each subproblem, we have to integrate the basis functions with respect to i s i s i e i and s s A P , which requires a numerical integration method. We use <ref type="bibr">Tauchen's method (1986)</ref>  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C. Convergence Analysis</head><p>In this section, we discuss the convergence of the algorithm. Let be the Euclidean set where the decisions are taken. Assume that for each s, the set s ⊂ of admissible controls is a nonempty compact set with Cartesian product structure as described in ( <ref type="formula">6</ref>). The admissible state-controls pairs are given by = S A P e S ∈ A P e ∈ S and as usual, we assume that r S A P e is bounded on except for a null probability set. Under these conditions, the convergence of the classical value iteration method is based on central ideas from functional analysis. Consider the Bellman operator v defined in (A1). Obviously, that value function is a fixed point of , i.e., an element v * such that v * = v * . The value iteration algorithm considers an arbitrary function v 0 , and recursively computes v j = v j−1 . Under regularity conditions, the sequence v j j≥1 converges to a limit that is the value function v * .</p><p>The argument uses basic concepts of functional analysis. Convergence can be ensured provided that is a contractive operator in a complete metric space. If B is a complete 2 metric space, an operator B → B is called contractive if d v v ≤ cd v v for all v v ∈ B with parameter c ∈ 0 1 . Any contractive operator in a complete metric space has a unique fixed point v * and satisfies that v * = lim j→ j v 0 for any initial point v 0 ∈ B, so that the sequence v j = v j−1 = j v 0 converges to the fixed point, for an introduction see <ref type="bibr" target="#b39">Kolmogorov and Fomin (1970)</ref>. In particular, we consider the Banach space 3 B of bounded and Borelmeasurable real-valued functions defined on the Euclidean state's space and endowed with the supremum norm v = sup y v y . If the function r s A P e is bounded on , then it is easy to prove that v is a contractive operator on B with parameter ∈ 0 1 , and the fixed point V = V solves the SDP problem, 4 see, e.g., <ref type="bibr" target="#b22">Denardo (1967)</ref> and <ref type="bibr" target="#b15">Blackwell (1965)</ref>. Under stronger conditions on the SDP problem, the value function V can be proved to be continuous, Lipschitz, once/twice continuously differentiable.</p><p>Unfortunately, the implementation of the algorithms is unfeasible with more than three or four state variables because the computation of v requires approximation of the numerical integral v s F ds s A P e by an average at selected points, and the number of required points to provide an accurate estimate increases exponentially with the dimension of the state variables.</p><p>Next, we discuss the convergence of the presented algorithm. Associated with the value functions defined in (7), we consider the operators:</p><formula xml:id="formula_45">i V i A P s i = max e i ∈ i s i R i S it e it</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>+</head><p>V i s i F A P s i s i e i V e s = max A P ∈¯ s R S t A t P t + V s F e ds s A P where F A P s i s i e i , F e ds s A P are defined as in the algorithm Steps 2.1 and 2.3. The arguments that maximize</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 1Individual Reduced Value Function (Customer Value Associated with Its Cash Flow States)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 2Distribution of the Individual Reduced Value Function Intercepts</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 3General Marketing Effort Reduced Policy Function</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>evaluate the linear equation at K grid points s 1 s K ⊂ and solve the system in k K k=1 . The system (A2) can be expressed in matrix notation as = (A3)where the K × K matrix has element mk = k s m and the K × 1 vector has the mth element: ds s m A P e</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Marketing</head><label></label><figDesc>Science 33(5), pp. 621-640, © 2014 INFORMS where considers the previous updates in the value function. For each s m , we compute</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>we compute an approximation of the subproblem objective functions (8) evaluated at the discrete scenarios as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>to approximate the continuous transition kernel k s i s i e i and k s s A P by analogous finite-state transition matrix on the states grid s 1 s N , considering for all n m = 1 N , the transition from s n to s m : i nm e i = i b i m s in e i − i b i m−1 s in e i mean nm A P = b m s n A P − b m−1 s n A P where b i m = s i m+1 + s i m /2, b m = s m+1 +s m /2 for m = 1 N − 1, and we set b i 0 = b 0 = − and b i N = b N = + so that i n1 A P e = i b 1 s n e i , i nN A P e = 1 − b N −1 s n A P , and similarly for mean n1 A P and mean nN A P . To apply the collocation value iteration or policy iteration method (for details see Appendix A), the continuousstate expectations of the basis functions (A4) for each subproblem-namely, k s i ds s m e i and k s ds s m A P -are approximated by the expected values in the analogous discrete Markov chain N −1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>it A t P t e it S it e it</figDesc><table><row><cell>= E 0</cell><cell>t E</cell><cell>r i S it A t P t e it S t A t P t</cell></row><row><cell>t≥0</cell><cell>i∈</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1</head><label>1</label><figDesc>Properties of the Algorithm for Different Problem Sizes in a Model Without Prices</figDesc><table><row><cell></cell><cell>No. of</cell><cell cols="2">Stopping criteria</cell><cell>No. of</cell><cell>Computational time</cell></row><row><cell>Method</cell><cell cols="5">customers Criterion 1 Criterion 2 iterations (in seconds)</cell></row><row><cell>Policy</cell><cell>1</cell><cell>0 0000</cell><cell>0 0000</cell><cell>3</cell><cell>3 8922</cell></row><row><cell>iteration</cell><cell>5</cell><cell>0 0000</cell><cell>0 0007</cell><cell>4</cell><cell>11 0790</cell></row><row><cell></cell><cell>25</cell><cell>0 0000</cell><cell>0 0008</cell><cell>4</cell><cell>60 5070</cell></row><row><cell></cell><cell>50</cell><cell>0 0000</cell><cell>0 0009</cell><cell>4</cell><cell>166 9300</cell></row><row><cell></cell><cell>100</cell><cell>0 0000</cell><cell>0 0009</cell><cell>4</cell><cell>687 4300</cell></row><row><cell>Value</cell><cell>1</cell><cell>0 0000</cell><cell>0 0000</cell><cell>4</cell><cell>3 5335</cell></row><row><cell>iteration</cell><cell>5</cell><cell>0 0000</cell><cell>0 0007</cell><cell>3</cell><cell>8 6160</cell></row><row><cell></cell><cell>25</cell><cell>0 0000</cell><cell>0 0008</cell><cell>4</cell><cell>61 1350</cell></row><row><cell></cell><cell>50</cell><cell>0 0000</cell><cell>0 0009</cell><cell>4</cell><cell>169 0700</cell></row><row><cell></cell><cell>100</cell><cell>0 0000</cell><cell>0 0009</cell><cell>3</cell><cell>545 9600</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 2</head><label>2</label><figDesc>Properties of the Algorithm for Different Problem Sizes in a Model with Prices</figDesc><table><row><cell></cell><cell>No. of</cell><cell cols="2">Stopping criteria</cell><cell>No. of</cell><cell>Computational time</cell></row><row><cell>Method</cell><cell cols="5">customers Criterion 1 Criterion 2 iterations (in seconds)</cell></row><row><cell>Policy</cell><cell>1</cell><cell>0 0000</cell><cell>0 0527</cell><cell>3</cell><cell>5 9819</cell></row><row><cell>iteration</cell><cell>5</cell><cell>0 0000</cell><cell>0 0202</cell><cell>4</cell><cell>29 5548</cell></row><row><cell></cell><cell>25</cell><cell>0 0000</cell><cell>0 0202</cell><cell>4</cell><cell>150 4374</cell></row><row><cell></cell><cell>50</cell><cell>0 0000</cell><cell>0 0202</cell><cell>4</cell><cell>404 8369</cell></row><row><cell></cell><cell>100</cell><cell>0 0000</cell><cell>0 0202</cell><cell>2</cell><cell>873 8870</cell></row><row><cell>Value</cell><cell>1</cell><cell>0 0000</cell><cell>0 0115</cell><cell>6</cell><cell>11 2360</cell></row><row><cell>iteration</cell><cell>5</cell><cell>0 0000</cell><cell>0 0202</cell><cell>2</cell><cell>16 4847</cell></row><row><cell></cell><cell>25</cell><cell>0 0000</cell><cell>0 0202</cell><cell>2</cell><cell>83 7036</cell></row><row><cell></cell><cell>50</cell><cell>0 0000</cell><cell>0 0324</cell><cell>2</cell><cell>189 4250</cell></row><row><cell></cell><cell>100</cell><cell>0 0000</cell><cell>0 0202</cell><cell>2</cell><cell>663 1727</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3</head><label>3</label><figDesc>Run Times Until Convergence for Larger Sizes in a Model with Prices</figDesc><table><row><cell></cell><cell>No. of</cell><cell>No. of</cell><cell>Computational time</cell><cell></cell><cell>No. of</cell><cell>No. of</cell><cell>Computational time</cell></row><row><cell></cell><cell>customers</cell><cell>iterations</cell><cell>(in seconds)</cell><cell></cell><cell>customers</cell><cell>iterations</cell><cell>(in seconds)</cell></row><row><cell>Policy</cell><cell>250</cell><cell>5</cell><cell>1 456</cell><cell>Value</cell><cell>250</cell><cell>3</cell><cell>1 079</cell></row><row><cell>iteration</cell><cell>500</cell><cell>5</cell><cell>4 738</cell><cell>iteration</cell><cell>500</cell><cell>3</cell><cell>3 494</cell></row><row><cell></cell><cell>1 000</cell><cell>4</cell><cell>13 852</cell><cell></cell><cell>1 000</cell><cell>5</cell><cell>16 288</cell></row><row><cell></cell><cell>2 000</cell><cell>5</cell><cell>127 077</cell><cell></cell><cell>2 000</cell><cell>3</cell><cell>71 085</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="2">Validation for Our Method, and Comparison with Q-Learning</cell></row><row><cell>ADP</cell><cell>Our algorithm</cell></row><row><cell>CPU</cell><cell>CPU</cell></row><row><cell>Customers</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">Estimates of Model (12)</cell><cell></cell><cell></cell></row><row><cell>Y t−1</cell><cell>Coefficient</cell><cell>Std. error</cell><cell>z</cell><cell>P &gt; z</cell></row><row><cell>Y i t−1</cell><cell>0 038</cell><cell>0 035</cell><cell>10 84</cell><cell>0 00</cell></row><row><cell>A t−1</cell><cell>1 338 85</cell><cell>66 17</cell><cell>20 23</cell><cell>0 00</cell></row><row><cell>e i t−1</cell><cell>327 67</cell><cell>108 59</cell><cell>3 02</cell><cell>0 003</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 6</head><label>6</label><figDesc>Distribution of General and Individual Advertising Investment Following the Optimal Policies</figDesc><table><row><cell>States</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Marketing Science 33(5), pp.621-640, © 2014 INFORMS   </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">A metric space, B, is complete if it is equal to its closure.3  A Banach space is a normed linear space, which is complete with respect to the distance d v v = v − v defined from its norm.4  There are also extensions for the case where r s A P e is bounded on compact subsets by using other distances (see<ref type="bibr" target="#b52">Rincón-Zapatero and Rodríguez-Palmero 2003)</ref>.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank Alejandro Balbas and Francisco J. Prieto for their comments that helped improve the manuscript. The authors also thank the editor, associate editor, and three anonymous reviewers for their careful reading of the paper and their valuable comments. Research partly supported by the Ministerio de Ciencia e Innovación (Spain) [Grant ECO2011-30198] and Comunidad de Madrid (Spain) [Grant S0505/TIC-0230].</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Marketing Science 33(5), pp. 621-640, © 2014 INFORMS 639 these two problems are e i s i I i=1 and A s P s , respectively. The convergence of the decomposition algorithm can be deduced similarly to the proof of convergence of the policy iteration method, using the following arguments:</p><p>1. By construction, the solution to the functional equation system,</p><p>satisfies that V s = I −1 I i=1 V i s i A s P s =V s e i s i a.e., where V s is the value function of the original SDP problem.</p><p>2. The algorithm can be considered a recursion defined by a contractive operator. Consider some initial value V s ∈ B . Then we can write V = I −1 I i=1 V i for a vector V 1 V I with coordinates V i = i V s , where the operator i is defined as i v s = E t≥0 t R iv S it e iv S it S i0 = s i R iv S it e iv S it = E I • r i S it e iv S it P v S t A v S it S it and A v s P v s e v S are the policies rendering the value function v s . These operators satisfy i v ≤ v . The algorithm can be regarded as a sequence obtained by alternating the operators 1 I from B → B I defined by i = i i V , with the operator . In other words, it is a recursion defined by the operator =</p><p>The operator is a contractive operator on B since and i are Bellman operators (contractive with parameter ), v =</p><p>and we can apply a fixed-point theorem to the alternating operator to prove convergence to a fixed point satisfying (9). In the implementation of the algorithm, we use a Monte Carlo simulation and function approximation, and thus we are just considering an approximation of the previous operators. In general, the effect of using Monte Carlo and approximation methods in convergence of value iteration can be addressed using probability tools (see, e.g., <ref type="bibr" target="#b57">Rust 1997</ref><ref type="bibr" target="#b63">, Santos and Rust 2004</ref><ref type="bibr" target="#b62">, Santos and Peralta-Alva 2005</ref><ref type="bibr" target="#b2">, Antos et al. 2008</ref>. Discussing this issue would require a more technical paper, and we have not delved into these issues.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Relaxations of weakly coupled stochastic dynamic programs</title>
		<author>
			<persName><forename type="first">D</forename><surname>Adelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Mersereau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="712" to="727" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Formulation and estimation of dynamic models using panel data</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">W</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hsiao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="47" to="82" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Learning near-optimal policies with Bellman-residual minimization based fitted policy iteration and a single sample path</title>
		<author>
			<persName><forename type="first">A</forename><surname>Antos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Szepesvári</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Munos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learning Theory</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="89" to="129" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Some tests of specification for panel data: Monte Carlo evidence and an application to employment equations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arellano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Econom. Stud</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="277" to="297" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Another look at the instrumental variable estimation of error-components models</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arellano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Bover</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="29" to="51" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The effects of a direct mail coupon on brand choice behavior</title>
		<author>
			<persName><forename type="first">K</forename><surname>Bawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Shoemaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="370" to="376" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Functional equations in the theory of dynamic programming: Positivity and quasilinearity</title>
		<author>
			<persName><forename type="first">R</forename><surname>Bellman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="743" to="746" />
			<date type="published" when="1955" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Bellman</surname></persName>
		</author>
		<title level="m">Dynamic Programming</title>
				<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><surname>Bellman</surname></persName>
		</author>
		<title level="m">Adaptive Control Processes: A Guided Tour</title>
				<meeting><address><addrLine>Princeton, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Princeton University Press</publisher>
			<date type="published" when="1961" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Partioning procedures for solving mixed-variables programming problems</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">F</forename><surname>Benders</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Numer. Math</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="238" to="252" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Relationship marketing in services: Growing interest, emerging perspectives</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">L</forename><surname>Berry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Acad. Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="236" to="245" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Dynamic Programming and Optimal Control</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Bertsekas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Vols. I and II</title>
				<meeting><address><addrLine>Athena Scientific, Belmont, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>3rd ed.</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Relationship marketing in mass markets</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">B</forename><surname>Bhattacharya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">N</forename><surname>Bolton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Relationship Marketing</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Sheth</surname></persName>
			<persName><forename type="first">A</forename><surname>Parvatiyar</surname></persName>
		</editor>
		<meeting><address><addrLine>Sage, Thousand Oaks, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1999" />
			<biblScope unit="page" from="327" to="354" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Birge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">V</forename><surname>Louveaux</surname></persName>
		</author>
		<title level="m">Introduction to Stochastic Programming</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mailing decisions in the catalog sales industry</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Bitran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Mondschein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1364" to="1381" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Discounted dynamic programming</title>
		<author>
			<persName><forename type="first">D</forename><surname>Blackwell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Statist</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="226" to="235" />
			<date type="published" when="1965" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Initial conditions and moment restrictions in dynamic panel data models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="115" to="143" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Quantitative models for direct marketing: A review from systems perspective</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Eur. J. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">195</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">From decision support to decision automation: A 2020 vision</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bucklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jdc</forename><surname>Little</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Lett</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="235" to="246" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The estimation of conditional densities. Puri ML</title>
		<author>
			<persName><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Linton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Statistics and Probability: Papers in Honor of George Gregory Roussas</title>
				<meeting><address><addrLine>Leiden, The Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>VSP International Science Publishers</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="71" to="84" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Scenario analysis via bundle decomposition</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Chun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="63" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Decomposition principle for linear programs</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">B</forename><surname>Dantzig</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Wolfe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="101" to="111" />
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Contraction mappings in the theory underlying dynamic programming</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">V</forename><surname>Denardo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM Rev</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="165" to="177" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Recent advances in structural econometric modeling: Dynamics, product positioning and entry</title>
		<author>
			<persName><forename type="first">J-P</forename><surname>Dubé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sudhir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ching</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Draganska</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hartmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Lett</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="209" to="224" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Geoffrion AM (1972) Generalized Benders decomposition</title>
	</analytic>
	<monogr>
		<title level="j">J. Optim. Theory Appl</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="237" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">How to compute optimal catalog mailing decisions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gönül</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ter</forename><surname>Hofstede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="74" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Optimal mailing of catalogs: A new methodology using estimable structural dynamic programming models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gönül</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1249" to="1262" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Customers as assets. J. Interactive Marketing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="9" to="24" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Managing Customers as Investments: The Strategic Value of Customers in the Long Run</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Lehmann</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Wharton School Publishing</publisher>
			<pubPlace>Upper Saddle River, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Customer lifetime value and firm valuation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Relationship Marketing</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2/3</biblScope>
			<biblScope unit="page" from="87" to="110" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Allocating marketing resources. Working paper</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Steenburgh</surname></persName>
		</author>
		<ptr target="http://hbswk.hbs.edu/item/5868.html" />
		<imprint>
			<date type="published" when="2008" />
			<pubPlace>Harvard University, Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Marketing Science</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="621" to="640" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Customer metrics and their impact on financial performance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Zeithaml</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="718" to="739" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Valuing customers</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Stuart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="18" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">The value of a &quot;free&quot; customer. UC3M Working Paper 09-2-03</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Mela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Vidal-Sanz</surname></persName>
		</author>
		<ptr target="http://hdl.handle.net/10016/3883" />
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>University Carlos III de Madrid, Madrid</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Scenario tree modeling for multistage stochastic programs</title>
		<author>
			<persName><forename type="first">H</forename><surname>Heitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Römisch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Programming</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="371" to="406" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Howard</surname></persName>
		</author>
		<title level="m">Dynamic Programming and Markov Processes</title>
				<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Choice models and customer relationship management</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Kamakura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Mela</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bodapati</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Iyengar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Naik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Lett</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="279" to="291" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Dynamic customer management and the value of one-to-one marketing</title>
		<author>
			<persName><forename type="first">R</forename><surname>Khan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Singh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1063" to="1079" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">N</forename><surname>Kolmogorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Fomin</surname></persName>
		</author>
		<title level="m">Introductory Real Analysis</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Dover Publications</publisher>
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A dynamic programming approach to customer relationship pricing</title>
		<author>
			<persName><forename type="first">M</forename><surname>Lewis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="986" to="994" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Ljungqvist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Sargent</surname></persName>
		</author>
		<title level="m">Recursive Macroeconomic Theory</title>
				<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2004" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Allocating marketing resources</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mantrala</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Marketing</title>
				<editor>
			<persName><forename type="first">B</forename><forename type="middle">A</forename><surname>Weitz</surname></persName>
			<persName><forename type="first">R</forename><surname>Wensley</surname></persName>
		</editor>
		<meeting><address><addrLine>Sage, Thousand Oaks, CA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="page" from="409" to="435" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Convergence of approximate model solutions to rational expectations equilibria using the method of parameterized expectations. Kellogg Graduate School of Management Working Paper 73</title>
		<author>
			<persName><forename type="first">A</forename><surname>Marcet</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Marshall</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<pubPlace>Evanston, IL</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Northwestern University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Direct Marketing: An Integrated Approach</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Mcdonald</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Irwin-McGraw-Hill</publisher>
			<pubPlace>Boston</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Dynamic allocation of pharmaceutical detailing and sampling for long-term profitability</title>
		<author>
			<persName><forename type="first">R</forename><surname>Montoya</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jedidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="909" to="924" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Is your company ready for one-toone marketing?</title>
		<author>
			<persName><forename type="first">D</forename><surname>Peppers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dorf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard Bus. Rev</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="151" to="160" />
			<date type="published" when="1999-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Approximate Dynamic Programming: Solving the Curses of Dimensionality</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Powell</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>Hoboken, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Puterman</surname></persName>
		</author>
		<title level="m">Markov Decision Processes: Discrete Stochastic Dynamic Programming</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">On the convergence of policy iteration in stationary dynamic programming</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Puterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Brumelle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="60" to="69" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Modified policy iteration algorithms for discounted Markov decision problems</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Puterman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Shin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1127" to="1137" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Balancing acquisition and retention resources to maximize customer profitability</title>
		<author>
			<persName><forename type="first">W</forename><surname>Reinartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="63" to="79" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Existence and uniqueness of solutions to the Bellman equation in the unbounded case</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Rincón-Zapatero</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Rodríguez-Palmero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="317" to="318" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>Econometrica</note>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Berger</surname></persName>
		</author>
		<title level="m">Direct Marketing Management</title>
				<meeting><address><addrLine>Upper Saddle River, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice-Hall</publisher>
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">The value of purchase history data in target marketing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Mcculloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="321" to="340" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Nonparametric estimation in Markov processes</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Roussas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Inst. Statist. Math</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="73" to="87" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Nonparametric estimation of the transition distribution function of a Markov process</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Roussas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Statist</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1386" to="1400" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Using randomization to break the curse of dimensionality</title>
		<author>
			<persName><forename type="first">J</forename><surname>Rust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="487" to="516" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Marketing models of service and relationships</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Chung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="560" to="580" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Optimizing the marketing interventions mix in intermediate-term CRM</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Verhoef</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="477" to="489" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Return on marketing: Using customer equity to focus marketing strategy</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">N</forename><surname>Lemon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">A</forename><surname>Zeithaml</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="127" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">On convergence of an augmented Lagrangian decomposition method for sparse convex optimization</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ruszczynski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Oper. Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="634" to="656" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Accuracy of simulations for stochastic dynamic models</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Peralta-Alva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1939" to="1976" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Convergence properties of policy iteration</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Santos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Control Optim</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2094" to="2115" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Customer base analysis: An industrial purchase process application</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Schmittlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="67" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Strategic allocation of marketing resources: Methods and managerial insights</title>
		<author>
			<persName><forename type="first">V</forename><surname>Shankar</surname></persName>
		</author>
		<ptr target="http://ssrn.com/abstract=1270804" />
	</analytic>
	<monogr>
		<title level="m">Marketing Science Institute</title>
				<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note type="report_type">MSI Working Paper 08-207</note>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">Density Estimation for Statistics and Data Analysis</title>
		<author>
			<persName><forename type="first">W</forename><surname>Silverman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Chapman &amp; Hall</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">An approximate dynamic programming algorithm for large-scale fleet management: A case application</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Simão</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gifford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nienow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Sci</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="178" to="197" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Approximate dynamic programming captures fleet operations for Schneider National</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">P</forename><surname>Simão</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">B</forename><surname>Powell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Gifford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Nienow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Day</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interfaces</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Dynamic catalog mailing policies</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Simester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="683" to="696" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Finite state Markov-chain approximations to univariate and vector autoregressions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tauchen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econom. Lett</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="177" to="181" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">A customer lifetime value framework for customer selection and resource allocation strategy</title>
		<author>
			<persName><forename type="first">R</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="106" to="125" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
