<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Commentary-A Latent Variable Perspective of Copula Modeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2010-11-04">November 4, 2010.</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Edward</forename><forename type="middle">I</forename><surname>George</surname></persName>
							<email>edgeorge@wharton.upenn.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics</orgName>
								<orgName type="department" key="dep2">The Wharton School</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics</orgName>
								<orgName type="department" key="dep2">The Wharton School</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics</orgName>
								<orgName type="department" key="dep2">The Wharton School</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Shane</forename><forename type="middle">T</forename><surname>Jensen</surname></persName>
							<email>stjensen@wharton.upenn.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics</orgName>
								<orgName type="department" key="dep2">The Wharton School</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics</orgName>
								<orgName type="department" key="dep2">The Wharton School</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Statistics</orgName>
								<orgName type="department" key="dep2">The Wharton School</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Commentary-A Latent Variable Perspective of Copula Modeling</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2010-11-04">November 4, 2010.</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.1100.0579</idno>
					<note type="submission">Received: March 12, 2010; accepted: April 9, 2010; Eric Bradlow served as the</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayesian analysis</term>
					<term>latent variable</term>
					<term>likelihood</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please scroll down for article-it is on subsequent pages</head><p>With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning opportunities for individual professionals, and organizations of all types and sizes, to better understand and use O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Essential Ideas</head><p>Let us begin by congratulating <ref type="bibr" target="#b0">Danaher and Smith (2011)</ref> on an excellent contribution that serves as a lucid introduction to copula modeling, as well as providing a sensible Bayesian approach for its application to both continuous and discrete data. The essential concept we take away is that modeling dependence in multivariate data is facilitated by transforming the marginal data distributions to spaces where dependencies are more naturally represented.</p><p>This central idea is most clearly illustrated in the case where each component of the original multivariate data X 1 X p is a realization of a continuous random variable. Each continuous X j with cumulative distribution function (cdf) F j can be transformed to a desired random variable X j by first transforming X j to a uniform random variable, U j = F j X j and then transforming this to X j = G j U j where G j is the inverse of the cdf F j of X j .</p><p>The goal is to select marginal distributions for X j that have a natural dependence structure. For example, if X j is chosen to have a Gaussian distribution, as Danaher and Smith recommend, then X 1 X p are treated as a multivariate Gaussian vector with unknown covariance which could be estimated with the X j observations. The resulting dependence structure implicitly imposed on U 1 U p and hence on X 1 X p is the Gaussian copula. As Danaher and Smith point out, this idea extends to the general case by treating discrete X j as corresponding to a latent uniform variable U j which takes values according to their Equation (5). Equivalently, any random variable X j , with cdf F j , can be consid-ered as the realization of an underlying uniform U j via X j = G j U j , where</p><formula xml:id="formula_0">G j u = inf x u ≤ F j x (1)</formula><p>is the suitably defined inverse probability integral transform. From this perspective, the entire copula approach can be summarized by a unified probabilistic framework where a central set of uniforms U = U 1 U p simultaneously generate the original X = X 1 X p and transformed X = X 1 X p variables:</p><formula xml:id="formula_1">X G ←− U G * −→ X * (2)</formula><p>Conditional on the original data X, this framework provides a likelihood for inference about the newly introduced dependence structure. For instance, suppose F was the multivariate distribution contemplated for X , with parameter indexing the unknown dependence structure. Through (2), F provides a marginal likelihood</p><formula xml:id="formula_2">L x = D p x x p x dx (3)</formula><p>which enables inference about . Here, integration is only required over D, the range of those x * components corresponding to discrete components of x. This likelihood formulation is especially appealing since suitable F * can be coupled with a prior p , and then the integration in (3) can be approximated using Markov chain Monte Carlo sampling from the posterior p</p><p>x ∝ L x p . Danaher and Smith illustrate this methodology in the case of the Gaussian copula, employing a Gibbs sampler to simulate x given covariance and a random-walk Metropolis-Hastings algorithm to simulate given x . </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>23</head><p>For the simulation of , Danaher and Smith propose a clever method based on the decomposition ( <ref type="formula">14</ref>) that reduces the problem to simulating an unconstrained upper triangular matrix R. This proposal appears to place a prior on R that is uniform over its upper nondiagonal elements, which implicitly places a prior on . It would be useful if the authors could make p explicit and perhaps comment on its essential features.</p><p>Also, the random-walk Metropolis-Hastings procedure involves a tuning parameter for the proposal distribution, namely, the variance = 0 01. Presumably this value was chosen because it worked well in the examples presented. In general, however, we wonder if the authors would recommend diagnostics for the proper adjustment of this tuning parameter. Going further, potential improvements of this sampling procedure might be obtained by optimal or adaptive extensions <ref type="bibr" target="#b1">(Rosenthal 2011</ref>) of the Metropolis-Hastings strategy.</p><p>As <ref type="bibr" target="#b0">Danaher and Smith (2011)</ref> illustrate, the ability to simulate from p</p><p>x opens the floodgates for inference. In addition to obtaining the posterior mean of as in ( <ref type="formula">15</ref>), the simulated values can also be used to obtain predictive samples of X , U, and X values via (2). Such U values can be used for inference about Spearman correlation coefficients as in ( <ref type="formula">16</ref>), and such X values used to infer characteristics like total exposure as in their §4. These predictive samples are also useful for model validation by comparison with the original x or holdout samples. We are impressed by the gains of the Bayesian Gaussian copula approach over competing alternatives in each presented example.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Going Further?</head><p>It is clear that we appreciate the contributions of <ref type="bibr" target="#b0">Danaher and Smith (2011)</ref> and heartily endorse their methodology as a practical approach to modeling dependence, but there are a number of issues that merit further investigation. An important issue is the selection of a Gaussian copula to model the dependence structure in X 1 X p . Consider the website visit and spend analyses in Figure <ref type="figure">1</ref> of Danaher and Smith, where they illustrate the appeal of the Gaussian-copula model. Figure <ref type="figure">1</ref>(a) shows that the Pearson correlation will be nearly useless as a result of the extreme skewness of the original data. Figure <ref type="figure">1(b)</ref> shows that the transformation to bivariate uniform has worked beautifully to spread out the data remarkably evenly, and then Figure <ref type="figure">1</ref>(c) shows that transformation back to bivariate Gaussian shows pictureperfect normality on which Pearson's correlation is certainly meaningful.</p><p>The remarkably uniform appearance of the marginals in Figure <ref type="figure">1</ref>(b) suggests that the estimated transformations have worked perfectly. However, we worry that this evaluation is misleading because F j X j will tend to be more uniform than F j X j , a consequence of overfitting as a result of the use of "plugin" maximum likelihood estimatesˆ of the F j parameters. The subsequent effect would be that the X data would agree even more with the copula. This overfitting could be remedied by introducing priors for and taking a fully Bayesian approach to their estimation. By focusing on point estimates of , Danaher and Smith are ignoring uncertainty in their marginal distributions F j X j and are subsequently ignoring uncertainty in the copula because the copula parameters are estimated conditional on fixed F j X j . Interestingly, Figure <ref type="figure">1</ref>(d), featuring the transformation back to bivariate t looks quite reasonable as well, and it is not clear from the plots whether the Gaussian copula is preferable to the t-copula. Figure <ref type="figure">1</ref>(e) demonstrates the importance of the dependence revealed in Figures <ref type="figure">1(c</ref>) and 1(d). We certainly agree with Danaher and Smith that the much larger Pearson's correlation for the transformed data is more likely to alert the analyst to dependence compared with the Pearson's correlation for the original data. Of course, any of the three correlation measures reported in their Table <ref type="table">3</ref> would suffice for this purpose, and for screening purposes over many data sets, it may be most sensible to use the more robust Spearman's rank correlation.</p><p>We also agree that the Gaussian copula "does the job" in the examples presented in their paper and is clearly superior to simpler alternatives in terms of exploiting dependence. However, other copulabased models might provide an even better model for these applications. A promising direction for future research would be the development of alternative parametric copulas, such as mixtures of normals, which may have a suitable Bayesian implementation. Bayesian factors could then provide a natural justification for the model selection of one copula formulation over the others.</p><p>We end with a cautionary tale about Gaussian copulas in financial applications. Once seen as a "magic bullet" for evaluating portfolio risk in the financial industry, the Gaussian copula model is now seen as having failed miserably because of its inability to account for extreme correlations <ref type="bibr" target="#b2">(Salmon 2009)</ref>. One possible reason for this failure is that the level of correlation between financial asset values increases as their risk approaches extreme levels. This characteristic is directly at odds with the key Gaussian model assumption of independence between the mean levels and the variance-covariance structure. This independence is a blessing in many situations, but it is a curse in this case because the correlation between financial items cannot be tied to their level of risk.</p><p>Ultimately, Gaussian copula models may not be flexible enough for a host of applications in finance. Creating copula models that can more properly address extreme correlations between financial instruments is another potentially fruitful area for future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>George and Jensen: A Latent Variable Perspective of Copula Modeling</figDesc><table><row><cell>Marketing Science 30(1), pp. 22-24, © 2011 INFORMS</cell></row></table></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgment</head><p>The authors thank the editor, Eric Bradlow, for giving them the opportunity to comment on this promising contribution to statistical methodology.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Modeling multivariate distributions using copulas: Applications in marketing</title>
		<author>
			<persName><forename type="first">P</forename><surname>Danaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">S</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="21" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Optimal proposal distributions and adaptive</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Rosenthal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Markov Chain Monte Carlo: Methods and Applications</title>
				<editor>
			<persName><forename type="middle">S</forename><surname>Mcmc</surname></persName>
			<persName><forename type="first">A</forename><surname>Brooks</surname></persName>
			<persName><forename type="first">G</forename><surname>Gelman</surname></persName>
			<persName><forename type="first">X.-L</forename><surname>Jones</surname></persName>
			<persName><surname>Meng</surname></persName>
		</editor>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Recipe for disaster: The formula that killed Wall Street. Wired Magazine</title>
		<author>
			<persName><forename type="first">F</forename><surname>Salmon</surname></persName>
		</author>
		<ptr target="http://www.wired.com/techbiz/it/magazine/17-03/wp_quant" />
		<imprint>
			<date type="published" when="2009-02-23" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
