<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Consumer Preference Elicitation of Complex Products Using Fuzzy Support Vector Machine Active Learning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-03-02">March 2, 2016.</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dongling</forename><surname>Huang</surname></persName>
							<email>dongling.huang@csun.edu</email>
						</author>
						<author>
							<persName><forename type="first">Lan</forename><surname>Luo</surname></persName>
							<email>lluo@marshall.usc.edu</email>
						</author>
						<author>
							<persName><forename type="first">John</forename><surname>Hauser</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">David Nazarian College of Business and Economics</orgName>
								<orgName type="institution">California State University</orgName>
								<address>
									<postCode>91330</postCode>
									<settlement>Northridge, Northridge</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Marshall School of Business, University of Southern California</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Consumer Preference Elicitation of Complex Products Using Fuzzy Support Vector Machine Active Learning</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
						<imprint>
							<date type="published" when="2016-03-02">March 2, 2016.</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.2015.0946</idno>
					<note type="submission">Received: November 25, 2013; accepted: March 16, 2015; Pradeep Chintagunta, Dominique Hanssens, and</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>new product development</term>
					<term>support vector machines</term>
					<term>machine learning</term>
					<term>active learning</term>
					<term>adaptive questions</term>
					<term>conjoint analysis</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A s technology advances, new products (e.g., digital cameras, computer tablets, etc.) have become increasingly more complex. Researchers often face considerable challenges in understanding consumers' preferences for such products. This paper proposes an adaptive decompositional framework to elicit consumers' preferences for complex products. The proposed method starts with collaborative-filtered initial part-worths, followed by an adaptive question selection process that uses a fuzzy support vector machine active learning algorithm to adaptively refine the individual-specific preference estimate after each question. Our empirical and synthetic studies suggest that the proposed method performs well for product categories equipped with as many as 70 to 100 attribute levels, which is typically considered prohibitive for decompositional preference elicitation methods. In addition, we demonstrate that the proposed method provides a natural remedy for a long-standing challenge in adaptive question design by gauging the possibility of response errors on the fly and incorporating the results into the survey design. This research also explores in a live setting how responses from previous respondents may be used to facilitate active learning of the focal respondent's product preferences. Overall, the proposed approach offers new capabilities that complement existing preference elicitation methods, particularly in the context of complex products.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>As technology advances, new products (e.g., digital cameras, computer tablets, etc.) have become increasingly more complex. Researchers often face considerable challenges in understanding consumers' preferences for such products (e.g., <ref type="bibr" target="#b15">Green and</ref><ref type="bibr">Srinivasan 1990, Hauser and</ref><ref type="bibr" target="#b18">Rao 2004)</ref>. Conventional preference elicitation methods such as conjoint analysis often become infeasible in this context because the number of questions required to obtain accurate estimates increases rapidly with the number of attributes and/or attribute levels. Historically, researchers have relied primarily on compositional approaches to handle preference elicitation of such products (e.g., <ref type="bibr" target="#b41">Srinivasan 1988</ref><ref type="bibr" target="#b39">, Scholz et al. 2010</ref><ref type="bibr" target="#b32">, Netzer and Srinivasan 2011</ref>. Adaptive question selection algorithms have also been proposed for complex product preference elicitation due to their ability to rapidly reveal consumer's product preferences with relatively few questions (e.g., <ref type="bibr" target="#b32">Netzer and Srinivasan 2011)</ref>. While significantly enhancing our ability to understand consumers' preferences for complex products, the extant research has yet to address the following challenges.</p><p>First, although widely used in the literature, compositional approaches may encounter obstacles such as unrealistic settings, inaccurate attribute weighting, etc. (e.g., <ref type="bibr" target="#b15">Green and</ref><ref type="bibr">Srinivasan 1990, Sattler and</ref><ref type="bibr" target="#b38">Hensel-Börner 2000)</ref> Second, despite their high efficiency in uncovering consumers' product preferences, adaptive question selection methods are often subject to response errors that could misguide the selection of each subsequent question. Last, with the exception of <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> in the context of consideration heuristics elicitation, this line of research has yet to explore the possibility of using other respondents' data to facilitate active learning of the focal respondent's product preferences.</p><p>Our research proposes an adaptive decompositional framework in response to these challenges. The proposed method starts with a collaborative-filtered initial part-worths, followed by an adaptive question selection process using a fuzzy support vector machine (SVM) active learning algorithm to adaptively refine the individual-specific preference estimate after each question. Compared to extant preference elicitation methods, our research offers the following new capabilities:</p><p>• Our adaptive decompositional approach is computationally efficient for preference elicitation of complex products on the fly, as the algorithm primarily scales with the sample size of the training data, rather than the dimensionality of the data vector.</p><p>• While extant research either neglects response errors in adaptive question selection or sets possibility of error instance as a priori, our algorithm gauges the possibility of response errors on the fly and incorporates it into adaptive survey design.</p><p>• Although most adaptive question selection methods only use information from the focal respondent, we use responses from previous respondents in a live setting via collaborative filtering to facilitate active learning of the focal respondent's product preferences.</p><p>We illustrate the proposed method in two computerbased studies involving digital cameras (with 30+ attribute levels) and computer tablets (with 70+ attribute levels). Our empirical investigation demonstrates that the proposed method outperforms the self-explicated method, the adaptive Choice-Based Conjoint method, the traditional Choice-Based Conjoint method, and an upgrading method similar to <ref type="bibr" target="#b35">Park et al. (2008)</ref> in its ability to correctly predict validation choices. Our synthetic data experiments further demonstrate that the proposed method can rapidly and effectively elicit individual-level preference estimates even when the product category is equipped with more than 100 attribute levels. We also use synthetic data experiments to compare the scalability, parameter recovery, and predictive validity of the proposed algorithm with that of <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> for consideration questions and of <ref type="bibr" target="#b0">Abernethy et al. (2008)</ref> for choice questions. We show that the proposed question selection algorithm may be used in conjunction with or as a substitute for algorithms by <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> and <ref type="bibr" target="#b0">Abernethy et al. (2008)</ref> to uncover consumers' preferences for complex products. Overall, our empirical and synthetic studies suggest that the proposed approach offers a promising new method to complement existing preference elicitation methods.</p><p>The remainder of the paper is organized as follows. In §2, we discuss the relationship of this research to the extant literature. In §3, we present the proposed adaptive question design algorithm. In §4, we describe our two empirical applications. Details of our synthetic studies are presented in §5. The final section summarizes key results, discusses limitations of this research, and offers directions for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Relationship to Extant Literature</head><p>The algorithm used in our proposed framework is closely related to the machine learning literature with origins in computer science. An important application of machine learning is classification, in which machines "learn" to recognize complex patterns, to distinguish between exemplars based on their different patterns, and to make intelligent predictions on their classes. Many marketing problems require accurately classifying consumers and/or products (or both) (e.g., consumer segmentation; identification of desirable versus undesirable products). Therefore, marketing researchers have recently begun to embrace machine learning methods in the estimation of classic marketing problems (e.g., <ref type="bibr" target="#b5">Cui and Curry 2005;</ref><ref type="bibr" target="#b13">Evgeniou et al. 2005</ref><ref type="bibr" target="#b14">Evgeniou et al. , 2007</ref><ref type="bibr" target="#b21">Hauser et al. 2010)</ref>.</p><p>Built on this stream of literature, the current paper introduces SVM-based active learning into adaptive question design. Arguably the most popular statistical machine learning method in the past decade <ref type="bibr" target="#b43">(Toubia et al. 2007a)</ref>, SVM methods are well known for highdimensional classification problems (e.g., <ref type="bibr">Vapnik 1998, Tong and</ref><ref type="bibr" target="#b42">Koller 2001)</ref>. In particular, we use a fuzzy SVM method to adaptively select each subsequent question for each respondent on the fly. As a weighted variant of the soft margin SVM formulation (the soft margin SVM was initially introduced by <ref type="bibr" target="#b4">Cortes and Vapnik 1995)</ref>, the fuzzy SVM method assigns different weights to different data points to enable greater flexibility of error control. Since the early 2000s, the class of fuzzy SVM methods has gained notable popularity in the SVM literature, mainly due to its effectiveness in reducing the effect of noises/errors in the data (e.g., <ref type="bibr">Wang 2002, 2004;</ref><ref type="bibr" target="#b49">Wang et al. 2005;</ref><ref type="bibr" target="#b40">Shilton and Lai 2007;</ref><ref type="bibr" target="#b22">Heo and Gader 2009)</ref>. When used for preference elicitation of complex products, this algorithm exhibits a number of advantages over extant methods. One desirable property of the SVM-based active learning algorithm is that the optimization used to facilitate adaptive selection of each subsequent question can be transformed to a dual convex optimization problem <ref type="bibr" target="#b42">(Tong and Koller 2001)</ref>. In our context, the primal problem (Equations ( <ref type="formula">2</ref>) and ( <ref type="formula">4</ref>)) is also constructed to be convex. Therefore, the proposed algorithm not only offers an explicitly defined unique optimum but also is easily solvable by most software for problems with dimensions that are likely to be of interest to marketers. Indeed, the SVM-based classification is primarily scaled by the size of the training data (i.e., the number of questions presented to each consumer in our context), rather than the dimensionality of the data vector <ref type="bibr" target="#b10">(Dong et al. 2005)</ref>. Consequently, the SVM-based active learning method is particularly suitable for the problem at hand. In contrast, several alternative adaptive methods (such as the adaptive fast polyhedral methods by <ref type="bibr" target="#b47">Toubia et al. 2003</ref><ref type="bibr" target="#b45">Toubia et al. , 2004</ref><ref type="bibr" target="#b44">Toubia et al. , 2007b</ref> are scaled by the dimensionality of the product vector. This may become more computationally cumbersome as the dimension of product attributes/attribute levels increases. Moreover, while the Hessian-based adaptive methods (e.g., <ref type="bibr" target="#b0">Abernethy et al. 2008</ref><ref type="bibr" target="#b46">, Toubia et al. 2013</ref>) require discrete transformations when used for discrete attributes, the SVM-based active learning method is flexible enough to directly accommodate discrete and continuous product attributes.</p><p>Another unique advantage particularly related to the fuzzy SVM active learning method is that it enables researchers to gauge the possibility of response errors on the fly and to incorporate it into adaptive question selection. In the context of adaptive question design, response errors may be conceptualized as the random error component in consumer's utility function (e.g., <ref type="bibr" target="#b47">Toubia et al. 2003)</ref>. Empirical data suggest that response errors are approximately 21% of total utility <ref type="bibr" target="#b19">(Hauser and Toubia 2005)</ref>. Because each response error might set the adaptive question selection to the wrong path and negatively impact selection of all subsequent questions, the presence of such errors poses a long-standing challenge to the adaptive question design literature (e.g., <ref type="bibr" target="#b17">Hauser and</ref><ref type="bibr">Toubia 2005, Toubia et al. 2007a</ref>). To date, response errors have either been neglected (e.g., <ref type="bibr">Toubia et al. 2004, Netzer and</ref><ref type="bibr" target="#b32">Srinivasan 2011)</ref> or set as a priori possibility for all individuals and all questions (e.g., <ref type="bibr" target="#b47">Toubia et al. 2003</ref><ref type="bibr" target="#b44">Toubia et al. , 2007b</ref><ref type="bibr" target="#b46">Toubia et al. , 2013</ref><ref type="bibr" target="#b0">Abernethy et al. 2008;</ref><ref type="bibr" target="#b12">Dzyabura and Hauser 2011)</ref>. We demonstrate that the proposed method can be used not only to gauge possible response errors on the fly but also to reduce the effects of such noise in adaptive question selection.</p><p>Last, inspired by <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> who suggest that previous-respondent data may be used to improve elicitation of consideration heuristics, the proposed method uses responses from previous respondents via collaborative filtering to facilitate active learning of the focal respondent's product preferences. The concept of collaborative filtering has been applied in various contexts such as prediction of TV show preferences and movie recommendation systems <ref type="bibr" target="#b2">(Breese et al. 1998)</ref>. We illustrate that such a technique can be incorporated in adaptive question design using actual respondents in a live setting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Adaptive Question Selection for</head><p>Complex Product Preference Elicitation 3.1. Overall Flow Figure <ref type="figure">1</ref> depicts the overall flow of our adaptive question design. We begin by prompting the consumer to configure a product that he is most likely to purchase, taking into account any corresponding feature-dependent prices. Based on collaborative filtering between the focal and previous respondents' self-configured profiles, we obtain an individual-specific initial part-worths vector ( §3.2). Next, we provide each consumer with an option of selecting "must-have" and "unacceptable" product features. We use information obtained from such features to construct the pool of candidate profiles to be evaluated in the consideration stage, as it is infeasible to evaluate all profiles using active learning without excessive delays in between survey questions within our context ( §3.3). Conditional on the initial part-worths and the candidate pool of profiles obtained for each respondent, we use a two-stage consider-then-choose process where the consideration stage asks the respondent whether he would consider a product profile ( §3.4) and the choice stage asks the respondent to choose among competing product profiles ( §3.5). In both stages, we use fuzzy SVM active learning for adaptive question design, so that each subsequent question is individually customized to refine the consumer-specific preference estimate while accounting for possible response errors on the fly. We explain the underlying rationale of our overall framework below. The primary goal of the proposed method is to estimate a part-worths vector for each respondent j. Given that the scale of the part-worths vector is arbitrary <ref type="bibr" target="#b34">(Orme 2010)</ref>, before the respondent answers any question, we may visualize the feasible region of the part-worths being all of the points on the surface of a hypersphere with unit norm (i.e., w j ∈ W w j = 1). Such a feasible region is referred to as version space in <ref type="bibr" target="#b42">Tong and Koller (2001)</ref> and <ref type="bibr" target="#b23">Herbrich et al. (2001)</ref> and a polyhedron in <ref type="bibr" target="#b47">Toubia et al. (2003</ref><ref type="bibr" target="#b45">Toubia et al. ( , 2004</ref><ref type="bibr" target="#b43">Toubia et al. ( , 2007a</ref>. Conceptually, each answer given by the respondent provides constraint(s) that makes this feasible region smaller.</p><p>Given the large number of attributes/attribute levels associated with complex products and the limited number of questions we can ask each respondent, an informative first question would enable us to efficiently construct the initial region of the feasible partworths ( §3.2). Similarly, by constructing a candidate pool with the majority of profiles satisfying the "musthave" and "unacceptable" criteria, we can maximize our learning about the focal respondent's product preferences by asking whether he would consider a profile based on his favorability towards other product features ( §3.3). Essentially, the first two steps of our overall framework aim to construct a suitable foundation for the adaptive question selection later on.</p><p>We then use a consider-then-choice framework to elicit each respondent's product preference ( § §3.3 and 3.4). Specifically, our algorithm aims to uncover a set of part-worths estimates that are consistent with the consumer's answers to these questions. Historically, researchers have often used conjunctive rules to capture consumer's decision rules in the consideration process (e.g., <ref type="bibr" target="#b21">Hauser et al. 2010, Dzyabura and</ref>. It has been less common to use part-worths to characterize consumer's responses to consideration questions. Our synthetic data experiments reveal that, even when the true consideration model is driven by conjunctive decision rules, the part-worths estimate from our algorithm exhibits good ability to predict whether the respondent would consider a profile ( §5.1). Indeed, even if heuristic decision rules are adopted by some respondents (particularly in the consideration stage), such preferences will be partially captured in our individual-specific part-worths estimates that aim to optimally predict responses from these consumers. Therefore, while not explicitly portraying these respondents' consideration heuristics, our part-worths estimates serve as an approximation of the decision heuristics used by such individuals. <ref type="bibr">1</ref> Within this setup, we present an algorithm wherein we use a set of part-worths estimates to characterize a respondent's answers to consideration and choice decisions. In this context, we aim to select each subsequent consideration/choice question such that we can reduce the feasible region of the part-worths as rapidly as possible. Intuitively, one good way to achieve this goal is to choose a question that halves such a region <ref type="bibr" target="#b42">(Tong and Koller 2001;</ref><ref type="bibr" target="#b47">Toubia et al. 2003</ref><ref type="bibr" target="#b45">Toubia et al. , 2004</ref><ref type="bibr" target="#b44">Toubia et al. , 2007b</ref>. To accomplish this goal, we adapt the active learning approach proposed by <ref type="bibr" target="#b42">Tong and Koller (2001)</ref> to select each subsequent consideration/choice question on the fly. Similar to <ref type="bibr" target="#b47">Toubia et al. (2003</ref><ref type="bibr" target="#b45">Toubia et al. ( , 2004</ref><ref type="bibr" target="#b43">Toubia et al. ( , 2007a</ref>, this algorithm relies on intermediate individual-level partworths estimates to adaptively select each subsequent question. If the consumer makes no response errors, such an approach would rapidly shrink the feasible region of the part-worths. Nevertheless, response errors are often inevitable in practice. To reduce the effects of response errors, we adapt the fuzzy SVM estimation algorithm <ref type="bibr" target="#b30">(Lin and Wang 2002)</ref> in consideration and choice stages to obtain the intermediate part-worths. Under this algorithm, each part-worths estimate is obtained as an interior point within the current feasible region of part-worths, via a simultaneous optimization that balances between data-imposed constraints and weighted classification violation. Consequently, when selecting each subsequent question based on such intermediate part-worths estimates, the negative impact of response errors in the process of adaptive question selection would be alleviated.</p><p>We also conjecture that our current multistage framework may help reduce the effect of response errors. In adaptive question design, early response errors are considerably more detrimental than errors that occur toward the end of the adaptive survey (e.g., <ref type="bibr" target="#b17">Hauser and</ref><ref type="bibr">Toubia 2005, Toubia et al. 2007a)</ref>. Therefore, when presented with the less demanding self-configuration and consideration questions before the more challenging choice questions, respondents may be less likely to incur response errors early on. Pseudo code of our algorithm is provided in Web Appendix A (available as supplemental material at http://dx.doi.org/10.1287/ mksc.2015.0946). Screenshots of the survey interface from our computer tablet applications are presented in Web Appendix B.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Collaborative-Filtered Initial Part-Worths Vector</head><p>Our framework begins by asking each respondent to configure a product profile that he is most likely to purchase, taking into account any corresponding feature-dependent prices. 2 Such a self-configured product profile provides substantial information about a consumer's product preferences <ref type="bibr">Hauser 2011, Johnson and</ref><ref type="bibr" target="#b33">Orme 2007)</ref>. In our context, the information from the self-configured profile is used as follows.</p><p>First, we generate an initial individual-specific partworths vector based on collaborative filtering between the focal and previous respondents' self-configured product profiles. The basic intuition is that we may learn about the focal respondent's product preferences by examining the preferences of previous respondents who have configured similar product profiles. For example, if two respondents self-configured two identical computer tablets, they are likely to share some commonality in their overall preferences towards computer tablets. Analogous to the role of informative prior in the Bayesian literature, consumer-specific initial partworths obtained through collaborative filtering may enhance active learning of the focal respondent's product preference at the outset of our adaptive question selection. Specifically, after the focal respondent j configures a profile that he is most likely to purchase, the following equation is used to obtain the respondent's initial part-worths vectorw 0 j on the fly:</p><formula xml:id="formula_0">w 0 j = 1 j − 1 j−1 j =1 s j j •w j with s j j = c j • c j c j c j (1)</formula><p>wherew j is the estimated part-worths of previous respondent j with j = 1 j − 1. In Equation (1), c j denotes the vector that represents product features of the self-configured profile for the focal respondent j, c j represents the corresponding vector from previous respondent j , and s j j measures the degree of cosine similarity between vectors c j and c j .</p><p>The cosine similarity measure is widely used to capture the similarity between two vectors in informational retrieval and collaborative filtering literature (e.g., <ref type="bibr">2</ref> Following <ref type="bibr" target="#b27">Johnson and Orme (2007)</ref>, we include feature-dependent prices in the self-configuration task to increase the realism of this task (otherwise respondents may self-configure the most advanced product profile with the lowest price). In the subsequent consideration and choice questions, we follow <ref type="bibr" target="#b33">Orme (2007)</ref> by adopting a summed price approach with a plus/minus 30% random price variation in both empirical studies. <ref type="bibr" target="#b37">Salton and</ref><ref type="bibr">McGill 1986, Breese et al. 1998)</ref>. Given that our method uses aspect type coding with attribute-level dummies, this measure is bounded between 0 and 1. In particular, s j j = 0 if there is no overlap between c j and c j ; 0 &lt; s j j &lt; 1 if there is partial overlap between c j and c j ; and s j j = 1 if c j = c j . The resulting initial part-worths is then used to identify the next set of profiles shown to the consumer.</p><p>Second, we use information from the configurator to set the two initial anchoring points in our fuzzy SVM active learning algorithm. As a classification method, a well posed SVM problem entails training data from both classes. In our context, we first give the self-configured product profile (i.e., the respondent's favorite) a label of "1" (meaning that the consumer would consider it). Next, we select a profile among those that are the most different from the self-configured profile and give it a label of "−1." As such a profile is not unique, the "opposite" profile is randomly chosen among those that do not share any common feature with the selfconfigured profile (our synthetic data experiments suggest that, in over 99% of cases, consumers would not consider such an opposite profile). After the next set of profiles is queried based on the collaborative-filtered initial part-worths, we combine the two anchoring points with the newly labeled profiles in the training data to ensure that the SVM problem is well posed. When previous respondents are absent, only the two anchoring points are used to obtain the initial partworths vector for the focal respondent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Identify Must-Have and/or Unacceptable</head><p>Product Features After the configuration task, we provide each respondent with an option of selecting some "must-have" and "unacceptable" product features. In the context of complex products, it is often infeasible to evaluate all profiles using active learning without excessive delays between survey questions <ref type="bibr" target="#b12">(Dzyabura and Hauser 2011)</ref>. One major advantage of identifying the "musthave" and "unacceptable" product features is that such information can be leveraged to construct the pool of candidate profiles to be evaluated in the consideration stage. <ref type="bibr">3</ref> In particular, among all possible product profiles to be queried, we develop an individual-specific pool containing (e.g., 90%) profiles that satisfy the "unacceptable" and "must-have" criteria (denoted as N 1 j , with remaining profiles randomly chosen from those that do Marketing Science 35(3), pp. 445-464, © 2016 INFORMS not satisfy these criteria (denoted as N 2 j . <ref type="bibr">4</ref> The rationale for having the majority of profiles in the candidate pool satisfying the "must-have" and "unacceptable" criteria is that we can maximize our learning about the focal respondent's product preferences by asking whether he would consider a profile based on his favorability towards other product attributes. The remaining profiles are chosen to account for the possibility that some individuals may identify "desirable"/"undesirable" features as "must-haves"/"unacceptables" <ref type="bibr" target="#b27">(Johnson and Orme 2007)</ref>. As long as the size of N 2 j is sufficiently large, our adaptive algorithm will update the estimated part-worths vector so that profiles not satisfying the initial criteria may also be queried in subsequent survey questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Consideration-Based Fuzzy SVM Active</head><p>Learning We next present the consideration-based fuzzy SVM active learning algorithm. We first describe the algorithm used to estimate the individual-specific part-worths vector on the fly. Then we elaborate the algorithm used to adaptively select profiles queried in each subsequent question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.1.">Algorithm to Estimate Individual-Specific</head><p>Part-Worths on the Fly.</p><formula xml:id="formula_1">Let x i j i = 1 2 I j = 1 2</formula><p>J denote the aspect type coded product profile i labeled by respondent j as y i j = 1 to indicate that he would consider the profile and y i j = −1 if he would not consider it. Following the tradition in the conjoint literature, we use a main-effects only model where w I j • x i j denotes the utility estimate of product profile i i = 1 2 I for respondent j and I j being the utility estimate of his "no-choice" option after I profiles are labeled. The utility of the "no-choice" option represents the decision boundary where the consumer would only consider a profile if its utility is no less than the baseline utility associated with the "no-choice" option <ref type="bibr" target="#b16">(Haaijer et al. 2001</ref>). That is, consumer i will only consider profile j, i.e., y i j = 1, if w I j • x i j − I j ≥ 0; y i j = −1 otherwise. In this context, the primary purpose of the SVM estimation algorithm is to find an individual-specific part-worths (i.e.,w I j = w I j I j that can correctly classify labeled profiles into the two classes of "would consider" and "would not consider." Finding such a part-worths vector can be challenging in practice as (1) there may be response errors in the data, and (2) the true decision process may not be representable by a linear utility function as specified above. Regarding the first issue, we use a fuzzy SVM algorithm that assigns a different weight to each labeled profile along with a regularization parameter to enable classification violation when we present the algorithm later in this section. The second issue can be alleviated by using aspect type coded product utility or by introducing a nonlinear kernel to the SVM algorithm. Compared with the alternative continuous/attribute level order coding, the aspect type coded product utility functions enable greater flexibility to accommodate nonlinear preference within each attribute (e.g., the utility function does not require monotone preferences for screen size, such as smaller/bigger size is strictly better). Additionally, nonlinear kernels could be used if there are nonlinear preferences across attributes. For example, if prior knowledge suggests that interaction effects exist among two or more product attribute levels, the SVM estimation algorithm can be readily adapted to accommodate such a nonlinear utility function. <ref type="bibr" target="#b48">Vapnik (1998)</ref> and <ref type="bibr" target="#b13">Evgeniou et al. (2005)</ref> provide detailed discussions on the generalization of the SVM estimation algorithm to such nonlinear models, which also maintains its computational efficiency even with highly nonlinear utility functions.</p><p>For simplicity, we demonstrate our estimation algorithm below using the example of the main-effects only model. Formally, upon labeling of I profiles (i = 1 2 I), the following algorithm is used to estimate respondent j's part-worths vector <ref type="bibr" target="#b48">(Vapnik 1998</ref><ref type="bibr" target="#b42">, Tong and Koller 2001</ref><ref type="bibr" target="#b30">, Lin and Wang 2002</ref>:</p><formula xml:id="formula_2">min w I j I j i j 1 2 w I j + C I i=1 u i j i j s.t. y i j w I j • x i j − I j ≥ 1 − i j i j ≥ 0 (2)</formula><p>where C is an aggregate-level regularization parameter that allows a certain degree of prior misclassification at the aggregate level, i j is a slack variable that can be thought of as a measure of the amount of misclassification associated with profile i, and u i j assigns a different weight to each labeled profile. When u i j = 1, Equation (2) corresponds to the soft margin SVM algorithm.</p><p>The regularization parameter C in Equation ( <ref type="formula">2</ref>) must be determined outside the SVM optimization. <ref type="bibr">5</ref> While this parameter may partially absorb the negative impact of noises in the data by allowing a certain degree of prior misclassification at the aggregate level, we discuss below how the fuzzy membership method provides additional flexibility to gauge potential response errors on the fly.</p><p>Instead of assuming that all labeled data belong to one of the two classes with 100% accuracy, the fuzzy SVM method assigns a fuzzy membership to each labeled profile so that data points with a high probability of being corrupted by noises will be given lower values of fuzzy memberships <ref type="bibr" target="#b30">(Lin and Wang 2002)</ref>. Therefore, rather than giving each labeled data point equal weight in the optimization, profiles with higher probabilities of being meaningless will be given less weight in the estimation under the fuzzy SVM method.</p><p>In practice, researchers often do not have complete knowledge about the causes or nature of noises in the data. Therefore, in the machine learning literature, researchers have explored various approaches to discern noises/outliers in the data (e.g., <ref type="bibr">Wang 2002, 2004;</ref><ref type="bibr" target="#b49">Wang et al. 2005;</ref><ref type="bibr" target="#b40">Shilton and Lai 2007;</ref><ref type="bibr" target="#b22">Heo and Gader 2009)</ref>. We adopt a method similar to <ref type="bibr" target="#b30">Lin and Wang (2002)</ref> to assign each labeled profile with a fuzzy membership u i j (0 &lt; u i j ≤ 1) as follows:</p><formula xml:id="formula_3">u i j =              1 − x i j −x I j+ r I j+ + if y i j = 1 1 − x i j −x I j− r I j− + if y i j = −1 (3)</formula><p>where r I j± = max i∈N j± x i j −x I j± represents the radius of each class (with the two classes being consider versus not consider),x I j± = 1/N I j± i∈N j± x i j denotes each class's group center, N I j+ = i y i j = 1 and N I j− = i y i j = −1 indicates the number of profiles in each class upon labeling of I profiles; is a small positive number to ensure that all u i j &gt; 0. Because the respondent's true part-worths are unknown to researchers, given the two classes of labeled profiles, we use the center of each class to approximate our current best guess about a profile that is representative of its class. We then define the fuzzy membership as a function of the Euclidean distance of each labeled profile to its current class center. That is, given our current knowledge about the respondent's product preferences, we assess the possibility of response errors by examining to what extent the labeled profile differs from other labeled profiles in its class.</p><p>Therefore, depending on its distance to the current class center, the labeled profile may be assigned a 90% probability belonging to one class and a 10% probability of being meaningless, or a 20% probability belonging to one class and an 80% probability of being meaningless. In Equation (2), profiles with higher probabilities of being meaningless (i.e., profiles with smaller u i j estimates) are given less weight in the fuzzy SVM estimation algorithm.</p><p>We repeat the process outlined in Equations ( <ref type="formula">2</ref>) and (3) iteratively upon the labeling of each additional profile. Specifically, each time an additional profile is labeled, we assign it a fuzzy membership given the class center of prior labeled profiles in its class, and based on which updated part-worths is estimated. Next, we update our class center estimates and the u i j i = 1 2 I estimate for each labeled profile to date. As a result, as we gain additional information about respondent j's product preferences, the algorithm can be used to iteratively refine the part-worths estimate and the fuzzy membership estimates. Because we use the intermediate part-worths estimate to adaptively select each subsequent question, the proposed fuzzy SVM method can be used not only to gauge possible response errors in the data but also to reduce the effects of such noises in the adaptive question design.</p><p>We have also used synthetic data experiments to explore several alternative approaches to defining a profile's class membership probability, such as defining a profile's class membership as a function of its distances to both its own class center and the center of the opposite class, or imposing an underlying error distribution assumption similar to the Logit, Probit or the Gaussian Mixture models. To the extent that the estimation is feasible, we do not observe improvement in model performance by implementing such alternative weighing schemes (details are provided in Web Appendix C).</p><p>It is worth noting that the class of fuzzy SVM methods discussed above faces potential gains and losses in adaptive question selection. On the positive side, this method alleviates the negative effect of response errors if such errors exist (see more investigation on this matter in §5.3). On the negative side, if the respondent does not incur an error, our fuzzy membership estimates may render the estimation less efficient. Given that the slack variable i j in Equation ( <ref type="formula">2</ref>) equals 0 for all nonsupport vectors in the solution, the efficiency loss only occurs when the solutions to the optimization in Equation ( <ref type="formula">2</ref>) are affected by the u i j estimates associated with correctly classified support vectors. Synthetic data experiments reveal that, when used for data with no response errors, the fuzzy SVM active learning incurs a minor efficiency loss compared to the soft margin SVM active learning ( §5.3). Therefore, if researchers are uncertain about the degree of response errors in adaptive question design, the fuzzy SVM method described above may be used to alleviate the negative effect of possible response errors at the expense of a potentially minor efficiency loss. On the other hand, the soft margin SVM can be used to maximize the efficiency in active learning if prior experiences indicate that consumer's responses are highly deterministic (i.e., response errors play a negligible role). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">Algorithm to Adaptively Select Profiles to</head><p>Be Queried in Subsequent Question. In this section we discuss how we adaptively select the next set of profiles shown to the respondent based on the latest estimate of his individual-specific part-worths. We use an approach adapted from <ref type="bibr" target="#b42">Tong and Koller (2001)</ref>. Our primary goal is to query each subsequent profile in such a way that we can reduce the feasible region of the part-worths as rapidly as possible. Intuitively, one good way of achieving this goal is to choose a query that halves such a region.</p><p>Letw I j = w I j I j denote the part-worths vector obtained from the optimization in Equation ( <ref type="formula">2</ref>) after I profiles are labeled (w 0 j in Equation ( <ref type="formula">1</ref>) is used if no profiles have been labeled). In its simplest form, <ref type="bibr" target="#b42">Tong and Koller (2001)</ref> suggest that the next profile to be queried can be the one with the smallest distance (margin) to the current hyperplane estimate represented byw I j . In our context, the margin of an unlabeled profile is computed as m g j = w I j • x g j − I j , with g being the index of unlabeled profiles. <ref type="bibr" target="#b42">Tong and Koller (2001)</ref> show that, when the training data are symmetrically distributed and the feasible region of part-worths is nearly sphere shaped, active learning via this simple margin approach reduces the current version space by half.</p><p>In the context of adaptive question design, the training data are likely to be asymmetrically distributed and/or the feasible region of the current part-worths can be elongated. To overcome such restrictions in the simple margin approach, <ref type="bibr" target="#b42">Tong and Koller (2001)</ref> propose the ratio margin approach as an augmentation. While conceptually appealing, the ratio margin approach is considerably more computationally burdensome than the simple margin approach. Here, we use the following hybrid method to combine the two approaches.</p><p>Assume that, with the simple margin approach, we have narrowed down to S trial profiles that are closest to the current hyperplane estimate represented byw I j . We then take each trial profile s (s = 1 2 S) from this set, give it a hypothetical label of 1, calculate a new part-worths by combining this new trial profile with the labeled profiles, and obtain a hypothetical margin m s+ j . Next, we perform a similar calculation by relabeling this profile as −1, calculating the resulting part-worths vector, and obtaining a hypothetical margin m s− j . The ratio margin of this profile is defined as max m s+ j /m s− j m s− j /m s+ j . After repeating these for all of the S trial profiles, we pick the profile with the smallest ratio margin as the next profile shown to the consumer (i.e., min s=1 S max m s+ j /m s− j m s− j /m s+ j . By asking the consumer to reveal his preference for such a profile iteratively, we can rapidly reduce the current feasible region of the part-worths <ref type="bibr" target="#b42">(Tong and Koller 2001)</ref>.</p><p>In our empirical application, because more than one profile is shown to the respondent at one time (Figure <ref type="figure">B3</ref> in Web Appendix B), the set of profiles (e.g., five) with the smallest ratio margins under the most recent part-worths estimate is selected to query the respondent. Additionally, upon satisfying the smallest ratio margin criterion, if two or more profiles have the same ratio margins, the profiles with the shortest overall distances to both class centers will be chosen. We impose this modification to the original approach by <ref type="bibr" target="#b42">Tong and Koller (2001)</ref> so that, in the context of our fuzzy SVM estimation, if such profiles turn out to be correctly labeled support vectors, the efficiency loss will be minimized.</p><p>This process is repeated iteratively until Q1 questions are asked. As discussed in <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref>, the number of questions to be included may be chosen based on prior experience or managerial judgment. In our context, we conducted synthetic data experiments with identical product dimensions as the two studies in our empirical investigation to determine the number of questions to be asked. We discovered that the proposed method could correctly classify the majority of profiles in various contexts after eight screens of profiles are queried, with each screen composed of five profiles. Consequently, we adopted this stopping rule for the data collection in our empirical application. Similar approaches were used to determine the number of questions to be asked in the choice stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Choice-Based Fuzzy SVM Active Learning</head><p>Upon completion of the consideration stage, we use the latest part-worths estimate to compute the utilities of all candidate profiles for respondent j, from which a set of M j profiles is selected to be considered in the choice stage. Similar in spirit to the "uncertainty sampling" rule adopted in <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref>, the profiles are selected such that their utility estimates are the closest to the decision boundary determined by the most recent part-worths estimate.</p><p>In choice tasks, when an individual frequently opts for the no-choice option, we cannot efficiently learn about his favorability towards various product features. In contrast, we obtain substantially more information about how an individual makes trade-offs among different product features when he chooses one profile over the competing profile(s) in a choice set. Therefore, in addition to selecting profiles whose utility estimates are closest to the baseline utility estimate (i.e., the no-choice option), we use a selection rule in which the majority (e.g., 90%) of profiles in M j have utility estimates above the threshold defined by the "nochoice" option. The remaining profiles in M j have utility estimates less than the threshold to allow for potential estimation error from our consideration stage.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.1.">Algorithm to Estimate Individual-Specific</head><p>Part-Worths on the Fly. For simplicity, we illustrate our approach using the example of a choice question with two product profiles and a "no-choice" option. The general principles are applicable to choice questions consisting of more than two profiles. Let us denote the two profiles in the kth choice question as x kA j and x kB j . After a total of T responses from the respondent (including both at the consideration and the choice stages), depending on respondent j's choice among profile A, profile B, none of the two, we obtain the following information correspondingly:</p><formula xml:id="formula_4">Chose A: w T j • x kA j −x kB j ≥ 0 and w T j •x kA j ≥ T j Chose B: w T j • x kA j −x kB j &lt; 0 and w T j •x kB j ≥ T j Chose None: w T j •x kA j &lt; T j and w T j •x kB j &lt; T j (4)</formula><p>As shown in Equation ( <ref type="formula">4</ref>), we obtain two data points each time the respondent makes a choice. For all inequalities containing T j , the fuzzy membership of the labeled response can be obtained directly using Equation (3), with class center and radius estimates calculated from pooled responses from both the consideration and the choice stages. When the inequalities in Equation ( <ref type="formula">4</ref>) entail utility comparison between the two profiles, we denote x kAB j = x kA j − x kB j and rewrite such inequalities as w T j • x kAB j ≥ or &lt; 0. Next, we assign a fuzzy class membership to each data point obtained, with x kAB j replacing x i j in Equation ( <ref type="formula">3</ref>). Under such scenarios, the class center of each class captures the mean differences between the two profiles when one profile is favored over the other. Conceptually, if the position of x kAB j considerably deviates from its class center, it implies that the labeled response does not align with our current knowledge about the respondent's product preferences. Therefore, we assign a low class membership to such a response. Formally, the optimization we solve at this stage of the adaptive question design can be expressed as min</p><formula xml:id="formula_5">w T j T j i j kAB j 1 2 w T j + C I i=1 u i j i j + K k=1 u k j kAB j s.t. y i j w T j • x i j − T j ≥ 1 − i j y kAB j w T j • x kAB j ≥ 1 − kAB j i j kAB j ≥ 0 (5)</formula><p>with the first constraint denoting all labeled responses related to T j (hence including responses from both consideration and choice stages) and the second constraint containing all responses related to utility comparison between the two profiles. It is evident that this optimization remains convex.</p><p>Similar to §3.4.1, we update our fuzzy membership estimates for all prior labeled responses (including those obtained in the consideration stage) each time after the respondent makes a choice among the two product profiles and the no-choice option. Consequently, our fuzzy membership estimates are refined over time as we accumulate additional knowledge about the focal respondent's product preferences.</p><p>3.5.2. Algorithm to Adaptively Select Profiles in the Next Choice Question. Below we discuss how we identify the next set of profile pair (i.e., profile g 1 and profile g 2 to be shown to the respondent. In the choice stage, m</p><formula xml:id="formula_6">g1 g2 j = w T j • x g1 −x g2 , m g1 j = w T j •x g1 − T j</formula><p>, and m g2 j = w T j •x g2 − T j capture our most recent estimates of respondent j's relative preferences across the two profiles and the no-choice option. Based on these utility estimates, we first use the criterion min max m g1 g2 j m g1 j m g2 j for all g 1 g 2 ∈ M j to select a trial set of choice sets that we would consider for the next choice question. The utilities of all options in this choice set are a priori near equal. This corresponds to the utility balance criterion commonly adopted in the conjoint literature. As suggested by various prior studies (e.g., <ref type="bibr" target="#b25">Huber and Hansen 1986</ref><ref type="bibr" target="#b16">, Haaijer et al. 2001</ref><ref type="bibr" target="#b45">, Toubia et al. 2004</ref>, utility balanced questions are the most informative in further refining the part-worths estimates. This criterion is also consistent with the simple margin approach proposed by <ref type="bibr" target="#b42">Tong and Koller (2001)</ref>, which aims to cut the feasible region of part-worths approximately in half.</p><p>Given that labeled responses are likely to be asymmetrically distributed and/or the feasible region of part-worths may be elongated, we use a hybrid of simple margin and ratio margin approaches similar to that described in §3.4.2. After using a simple margin approach to obtain a trial set of choice sets, we first give this choice set a hypothetical response of choosing profile g 1 , calculating a new part-worths by combining this response with the prior obtained responses, and obtaining hypothetical margins m ratio margin criterion, if two or more choice sets have the same ratio margins, the choice set with the shortest overall distance to the corresponding class centers will be chosen to minimize efficiency loss. We repeat this process iteratively to shrink the feasible region of part-worths as rapidly as possible, until Q 2 questions are asked.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Empirical Investigation</head><p>In this section we describe two empirical studies involving digital cameras and computer tablets. Our pretest indicates that both product categories are of interest to the respondents' population (undergraduate students).</p><p>The overall complexity of the digital camera category (with 30+ attribute levels) is parallel to product categories studied in prior research that elicits consumers' preferences for complex products (e.g., <ref type="bibr" target="#b35">Park et al. 2008</ref><ref type="bibr" target="#b32">, Netzer and Srinivasan 2011</ref><ref type="bibr" target="#b39">, Scholz et al. 2010</ref>. The computer tablet category (with 70+ attribute levels) is considerably more complex than those used in extant methods, particularly in the context of decompositional preference elicitation methods. To keep our empirical applications meaningful and realistic, we conducted pretests to choose a set of attributes that the respondents typically consider. We then used retail websites such as BestBuy.com and Amazon.com to identify the ranges and values of attribute levels used in both empirical applications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Digital Camera Study</head><p>4.1.1. Research Design. A total of 425 participants are randomly assigned to one of the six preference measurement conditions. We included two conditions of the fuzzy SVM method: Condition 1: fuzzy SVM with collaborative filtering; Condition 2: fuzzy SVM without collaborative filtering. The overall flow of the two fuzzy SVM conditions follows Figure <ref type="figure">1</ref>, with the exception that in Condition 2 the initial part-worths is attained solely based on the focal respondent's selfconfigured product profile. We further compare the predictive validity of the proposed method with the following four benchmark methods: Condition 3: the self-explicated method; Condition 4: an upgrading method similar to <ref type="bibr" target="#b35">Park et al. (2008)</ref> with no incentive alignment; Condition 5: the adaptive Choice-Based Conjoint (ACBC); and Condition 6: the traditional Choice-Based Conjoint (CBC). The list of attributes and attribute levels included in our digital camera study is provided in Table <ref type="table" target="#tab_2">A1</ref> in Web Appendix D.</p><p>Similar to prior studies in the literature (e.g., <ref type="bibr">Scholz et al. 2010, Netzer and</ref><ref type="bibr" target="#b32">Srinivasan 2011)</ref>, participants in all conditions first complete the preference measurement task, followed by an external validation task and a post-survey feedback task. Identical across the six experimental conditions, the external validation task comprises two choice questions, each including two camera profiles. Generated using fractional factorial design, the profiles are carefully chosen so that one profile does not clearly dominate the other in each choice set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.2.">Results</head><p>. We obtain the individual-specific part-worths estimates from the two fuzzy SVM conditions using the fuzzy SVM estimation algorithm. The self-explicated estimates are obtained by multiplying the attribute importance weights with the corresponding desirability ratings <ref type="bibr" target="#b41">(Srinivasan 1988)</ref>. We use the hierarchical Bayesian estimation to obtain individuallevel part-worths estimates from the upgrading method, the ACBC method, and the CBC method.</p><p>Following the tradition in this literature (e.g., <ref type="bibr" target="#b13">Evgeniou et al. 2005</ref><ref type="bibr" target="#b32">, Netzer and Srinivasan 2011</ref><ref type="bibr" target="#b35">, Park et al. 2008</ref>, we use the hit rate of the external validity tasks to gauge the predictive validity of the six preference measurement methods (Table <ref type="table" target="#tab_2">1</ref>). <ref type="bibr">6</ref> We find that the two fuzzy SVM conditions perform significantly better than all benchmark methods in correctly predicting respondents' choices in hold-out tasks (p &lt; 0 05).</p><p>Comparing hit rates across the two fuzzy SVM conditions, we find that collaborative filtering improved predictions but not significantly (0.801 versus 0.779, p &gt; 0 05). This finding is consistent with empirical results from <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref>. It is possible that, after all of the consideration and choice questions are queried in our adaptive survey, incremental benefits from the collaborative filtered initial part-worths have diminished. This matter is explored further in synthetic data experiments in §5.4.</p><p>We also compared participants' responses to the post survey feedback questions across the six experimental conditions. Overall, participants provided more favorable feedback to the format and questions generated under the fuzzy SVM conditions than those from the benchmark methods (Table <ref type="table" target="#tab_4">A2</ref> in Web Appendix D). 7 <ref type="bibr">6</ref> We also tried to incorporate the Kullback-Leibler (KL) measure used by <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref>, <ref type="bibr" target="#b9">Ding et al. (2011), and</ref><ref type="bibr" target="#b20">Hauser et al. (2014)</ref> in our digital camera application. We discovered that this measure is only applicable with three or more validation tasks. Our digital camera application includes two choice validation tasks. In such cases, when the consumer chooses the profile on the left in one task and the profile on the right in the other task, the KL measure equals zero regardless of whether both predictions are correct, wrong or one is correct and one is wrong. Essentially, the KL measure does not discriminate whether observed and predicted choices are aligned when the total number of validation tasks is two. In our computer tablet study, we included six choice validation tasks and used the KL measure to gauge predictive validity. <ref type="bibr">7</ref> In both empirical applications, we also recorded the amount of time it takes for each participant to complete the survey. This information is provided in Tables <ref type="table" target="#tab_5">A3 and A4</ref> in Web Appendix D. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Computer Tablet Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Research Design.</head><p>In a second empirical study, we examine the performance of the proposed method for the more complex product category of computer tablets (with 70+ attribute levels). The complete list of attributes and attribute levels included in this study is provided in Figure <ref type="figure">A1</ref> in Web Appendix B. In addition to the different product category and the increased number of attribute levels, we made the following modifications in this empirical application. First, given the high complexity of the product category, we included a warm-up task so that the participants could get familiar with the different attribute levels before the preference measurement task. This task has been shown to improve the accuracy of preference elicitation <ref type="bibr" target="#b26">(Huber et al. 1993)</ref>. Specifically, we provided the list of 14 attributes used to describe computer tablets, followed by a brief verbal and graphic description for each attribute level, displayed for one attribute at a time.</p><p>Second, because a number of prior studies (e.g., <ref type="bibr" target="#b6">Ding 2007;</ref><ref type="bibr" target="#b7">Ding et al. 2005</ref><ref type="bibr" target="#b8">Ding et al. , 2009</ref><ref type="bibr" target="#b9">Ding et al. , 2011</ref><ref type="bibr" target="#b11">Dong et al. 2010;</ref><ref type="bibr" target="#b20">Hauser et al. 2014)</ref> suggest that incentive alignment offers benefits such as greater respondent involvement, less boredom, and higher data quality, we incorporated incentive alignment in this application. At the beginning of the experiment, we told the participants that we would award a computer tablet device to one randomly selected participant from this study, plus cash representing the difference between the price of the tablet device and $900. We set $900 as the maximum prize value because the majority of computer tablets cost less than $900 at the time of our study. The participants were told that the total number of participants for this study would be approximately 150 (i.e., the chance of winning is about 1 in 150). Because we wanted the preference elicitation tasks and the validation tasks to be incentive aligned, participants were told that we would randomly decide which of the two tasks to use when determining the final prize. We also told each participant that, if chosen as a winner, he would receive a computer tablet based on: (1) his choice from one of the validation questions or (2) his most preferred tablet among a list of 25 tablets, inferred from his answers to the preference elicitation questions. Following <ref type="bibr" target="#b9">Ding et al. (2011) and</ref><ref type="bibr" target="#b20">Hauser et al. (2014)</ref>, participants were told that this list was pre-determined by the researchers and that it would be made public after the study. Therefore, the respondents have incentives to answer the questions carefully and truthfully.</p><p>Last, we modified our validation procedure relative to the digital camera study. We included initial and delayed validation tasks as in <ref type="bibr" target="#b9">Ding et al. (2011)</ref> and <ref type="bibr" target="#b20">Hauser et al. (2014)</ref>. Following <ref type="bibr" target="#b20">Hauser et al. (2014)</ref>, the delayed validation questions were sent to the respondents by email one week after the preference measurement task. Additionally, we included both preand post-preference measurement validation questions as suggested by <ref type="bibr" target="#b32">Netzer and Srinivasan (2011)</ref>. Each respondent answered six validation choice questions, with three before the preference measurement task and three in the delayed validation task. As pointed out by <ref type="bibr" target="#b32">Netzer and Srinivasan (2011)</ref>, the standard validation task procedure used in our digital camera study might be susceptible to idiosyncrasies of the chosen validation questions. In the computer tablet study, we followed Netzer and Srinivasan (2011) by including a broader set of validation choice questions in the validation task. First, we used a fractional factorial design to generate a set of orthogonal balanced choice questions. Next, we scanned through the generated questions and retained only those comprising profiles available in the marketplace (as any one of the computer tablets in the validation questions could be awarded to a participant). To allow for appropriate comparison across conditions, we also followed <ref type="bibr" target="#b32">Netzer and Srinivasan (2011)</ref> by using the same sets of randomly drawn validation questions in all conditions.</p><p>In this study, 151 participants are randomly assigned to one of the four preference measurement conditions. To better understand the incremental benefit from including consideration questions in our adaptive question design, we compared the proposed method (Condition 1) to an alternative fuzzy SVM method in which the choice questions are presented immediately after the self-configuration task and the unacceptable and must-have questions (Condition 2). Furthermore, we included the self-explicated method (Condition 3) and the ACBC method (Condition 4) to replicate results from the first empirical application.</p><p>The flow of each experimental condition is described below. First, the participant was introduced to the study along with a basic description of the incentive alignment mechanism. Second, the participant was presented with the warm-up task. Third, three validation questions, each consisting of two tablet profiles, are shown to the participant. Fourth, the participant was presented with the preference measurement task  (which varies by experimental condition). Last, a week later, each participant received a follow-up email with a survey link to a second set of three validation questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.2.">Results</head><p>. Table <ref type="table" target="#tab_4">2</ref> reports the predictive validity of the four experimental conditions. In addition to the traditional hit rate measure, we used the KL divergence measure to gauge the degree of divergence from predicted choices to those that are observed in the validation data. The KL divergence measure is an information-theory-based measure of divergence <ref type="bibr" target="#b28">(Kullback and</ref><ref type="bibr">Leibler 1951, Chaloner and</ref><ref type="bibr" target="#b3">Verdinelli 1995)</ref>. <ref type="bibr" target="#b12">Dzyabura and Hauser (2011</ref><ref type="bibr" target="#b9">), Ding et al. (2011</ref><ref type="bibr" target="#b20">), and Hauser et al. (2014</ref> demonstrate that, for consideration data, the KL divergence measure provides an evaluation of predictive ability that is rigorous and which discriminates well. We followed the formulae provided in <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> to calculate the KL divergence measures. In our context, we conceptualize a false-positive prediction as the case wherein the respondent is predicted to choose a profile but did not actually choose it in a validation question; and a false-negative prediction as the case wherein the respondent is predicted not to choose a profile but actually chose it in a validation question. Because this measure evaluates divergence from perfect prediction, a smaller KL divergence measure indicates a better model prediction.</p><p>Consistent with findings from our digital camera application, the proposed method exhibits superior predictive ability when compared to the self-explicated and ACBC methods in both the initial and delayed validation tasks. We also find that the proposed method has smaller KL divergence than the fuzzy SVM condition without consideration questions (marginally significant at p &lt; 0 1). It is evident that the inclusion of consideration questions is helpful in improving preference elicitation in our context. It is possible that, when consideration questions are absent, respondents may encounter greater cognitive difficulty in making accurate trade-offs of choice questions. Respondents may also be less likely to incur early response errors (which are known to be detrimental in adaptive question design), when they are presented with the less demanding consideration questions before the more cognitively challenging choice tasks.</p><p>We also compared the KL divergence measure from the initial validation task with that from the delayed validation task within each experimental condition. No significant differences are observed. Therefore, when pooling results across the initial and delayed validation tasks for each respondent, the KL divergence measures follow the same pattern as the one discussed above. <ref type="bibr">8</ref> The hit rate comparisons are also provided in Table <ref type="table" target="#tab_4">2</ref>. The proposed method also outperforms the three benchmark methods in terms of hit rate.</p><p>One of the main advantages of adaptive question design is the opportunity to reduce respondents' cognitive burden by asking fewer questions. We further examine the out-of-sample performance of the proposed method when only the first q questions are used for each respondent (Table <ref type="table" target="#tab_5">3</ref>). We find that both the KL divergence and the hit rate measures gradually improve with the inclusion of self-configurator (q = 1), consideration questions (q = 2 to 9 with 8 screens of consideration questions with 5 profiles on each screen), and choice questions (q = 10 to 34), indicating that all of these questions positively contribute to our preference elicitation task. Table <ref type="table" target="#tab_5">3</ref> also reveals that the proposed method performs well with much fewer choice questions. In particular, the predictive validity after only 6-8 choice questions (i.e., q = 15 or 17) is already similar to the predictive validity with all 25 choice questions (i.e., q = 34). Indeed, after only the first 8 choice questions (i.e., q = 17), the proposed method already exhibits significantly better predictive validity than the selfexplicated and ACBC methods. This finding suggests that respondent burden in this application may be substantially reduced with a much shorter survey. This is consistent with <ref type="bibr" target="#b32">Netzer and Srinivasan (2011)</ref> who also </p><formula xml:id="formula_7">       Consideration questions                                             </formula><p>Choice questions report negligible improvement in predictive validity after 5-7 adaptive paired comparison questions.</p><p>Overall, in comparing the predictive ability of the proposed method with that of the ACBC and selfexplicated methods, our computer tablet application replicated results from the digital camera application. The comparison between the two fuzzy SVM conditions also shows that inclusion of consideration questions is useful in facilitating preference elicitation in our context. In addition, this application illustrates that the proposed method scales well when the focal product category is considerably more complex than those used in prior studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Synthetic Data Experiments</head><p>In this section we describe a series of synthetic data experiments conducted to complement our empirical investigation. In §5.1, we compare the performance of the proposed question selection algorithm with that of <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> for consideration questions when the true consideration decisions are conjunctive. In §5.2, we examine the performance of the proposed method with that of benchmark methods when the true consideration and choice decisions are based on a part-worths model. Under this comparison, we use the question selection algorithm in <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> as the benchmark question selection method for consideration questions and that in <ref type="bibr" target="#b0">Abernethy et al. (2008)</ref> as the benchmark method for choice questions. To investigate the applicability of these question selection methods to high-dimensional problems, in § §5.1 and 5.2, we examine the scalability of each algorithm when the focal product category is equipped with up to 100+ attribute levels. To ensure fair comparisons across methods, only the focal respondent's responses are used in the adaptive question selection in all comparisons described above. We also test the upper bound of parameter recovery and predictive validity by assuming no response errors in such comparisons. In §5.3, we compare the performances of the fuzzy SVM versus soft margin SVM active learning with and without response errors. In §5.4, we examine the improvements of collaborative-filtered initial part-worths over noninformative initial part-worths on parameter recovery and predictive validity. We report our main findings below. Additional implementation details can be found in Web Appendix E.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Using Proposed vs. Conjunctive Question</head><p>Selection When the True Consideration Decisions Are Conjunctive In §3 we describe a framework wherein a set of partworths is used to characterize consumer's responses to consideration and choice questions. In the literature, conjunctive-like criteria are often used to examine answers to consideration questions (e.g., <ref type="bibr">Bettman 1970</ref><ref type="bibr" target="#b21">, Hauser et al. 2010</ref>. Therefore, we conduct synthetic data experiments to examine the performance of the proposed question selection algorithm for consideration questions when the true consideration model is conjunctive. Specifically, the adaptive question selection algorithm in <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> is used as the benchmark method in this comparison.</p><p>Given our emphasis on complex products, we examine three scenarios in which the focal product category comprises 15, 25, and 35 attributes with three levels each. Under each scenario, we simulate 300 synthetic respondents (i.e., 300 conjunctive decision rules) as described in <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref>. We then  perform active learning for each participant where 40 consideration questions are adaptively selected, with each synthetic respondent labeling the profile as "would consider" or "would not consider" based on the underlying true conjunctive decision rule. To compare the relative performance of the two question selection methods, we generate 3,000 validation profiles for each synthetic respondent, with the respondent considering 1,500 profiles and not considering the remaining profiles under the respondent's true underlying conjunctive decision rule. Because each synthetic respondent considers 50% of the validation profiles, the null model that predicts "randomly considers profiles" would achieve a hit rate of 50%. Therefore, while the hit rate measure can be misleading for consideration data empirically, it provides a valid measure of predictive validity in our synthetic setting. Table <ref type="table" target="#tab_7">4</ref> provides comparison results. To compare the question selection methods, we keep the estimation method constant. Specifically, we present the comparison results using both the conjunctive estimation method as in <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> and the fuzzy SVM estimation method proposed in this paper. In terms of performance metrics, we use hit rate, KL divergence, and U 2 to measure predictive validity and parameter recovery <ref type="bibr">(Table 4(a)</ref>). The metric U 2 is an information-theoretic measure of parameter recovery <ref type="bibr" target="#b17">(Hauser 1978)</ref>. It measures the percentage of uncertainties explained by the model; with U 2 = 100% indicating perfect parameter recovery. <ref type="bibr">9</ref> To examine scalability of these two question selection methods, we also report the average time it takes to generate the next question in seconds <ref type="bibr">(Table 4(b)</ref>). The reported computing times are all based on Matlab code run on an Intel 3.2 GHz personal computer with a Windows 7 Operating System.</p><p>When the estimation method in <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> is used (i.e., for each attribute level, the model estimates a probability for which the respondent finds it acceptable), the question selection algorithm by <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> exhibits a superior hit rate, KL divergence, and U 2 to the focal question selection algorithm in almost all problem instances. <ref type="bibr">9</ref> While the original U 2 measure in <ref type="bibr" target="#b17">Hauser (1978)</ref> is based on choice probabilities, the fuzzy SVM estimation gives rise to dichotomous (e.g., consider versus not consider; choose product A versus product B) rather than probabilistic predictions. Therefore, when the fuzzy SVM algorithm is used for model estimation, we calculated the U 2 measure based on a logit transformation, with the deterministic component of the product utility calculated from the estimated part-worths given by the fuzzy SVM algorithm. Because the scale of utility estimates matters in the magnitude of U 2 (if we multiply the part-worths estimates by a constant, larger part-worths result in more extreme choice probabilities, hence more extreme U 2 estimate), we normalize the estimated part-worths to the scale of the true part-worths and use the relative U 2 (the U 2 calculated from the fuzzy SVM part-worths estimates divided by the U 2 calculated from the true part-worths) to remove the effect of scaling. This measure was not used in our empirical studies because the true part-worths are unknown empirically and it is ambiguous as to how to determine the baseline scale in our empirical comparisons. Indeed, when the product dimension is relatively moderate (15 attributes and 3 levels), <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref>'s method yields perfect parameter recovery and holdout prediction after 40 questions. Such results reveal that, when the true consideration model is conjunctive, the algorithm proposed by <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> works exceptionally well in estimating the probability that the respondent finds each attribute level acceptable.</p><p>Because our approach aims to obtain a set of partworths estimates for each respondent, we also compare the performance of the two question selection methods when the fuzzy SVM method is used for estimation. In such cases, an individual-specific part-worths vector is estimated after all 40 questions are queried under each question selection algorithm. The estimated partworths are then used to predict the validation profiles. Interestingly, we discover that, when the fuzzy SVM estimation is used, the proposed method outperforms the method used by <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> in terms of hit rate, KL divergence, and U 2 measures. Such results are likely to be driven by the fact that the <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> algorithm is specifically developed to uncover the probability for which the respondent considers each attribute level, rather than a utility estimate associated with the attribute level. Therefore, when the primary focus is to estimate partworths, this method does not perform as well, even when the true consideration model is conjunctive.</p><p>We further study scalability of the two methods by examining the average time it takes to generate the next question under each question selection algorithm. When the proposed question selection algorithm is used, on average it takes less than 0.25 seconds to generate the next question in all scenarios. By contrast, under the question selection algorithm by <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref>, the average time it takes to generate the next question is considerably longer (ranging from 2.856 seconds to 11.861 seconds in the three scenarios). Note that such discrepancies may diminish considerably if we were to optimize or code both algorithms in a more computationally efficient language such as C or C++.</p><p>Overall, our synthetic data experiments reveal the following. First, even when the true consideration model is conjunctive, the part-worths estimate from the proposed method exhibit a reasonably good ability to predict whether the respondent would consider a profile. Given that the part-worths model of consideration and the conjunctive model of consideration as in <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> aim to capture a set of linear decision rules in the consideration process, we believe that such findings are quite reasonable. Second, the proposed framework is not restricted to the question selection algorithm discussed in §3.4. Indeed, the algorithm by <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> could be used in conjunction with the proposed algorithm in a consider-then-choice framework to uncover consideration heuristics and conjoint part-worths. In such cases, different utility functions may also be used to separately model consumer's consideration and choice decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Performance Comparisons When True</head><p>Consideration and Choice Decisions Are Based on a Part-Worths Model We now compare the performance of the proposed method with that of benchmark methods when the true consideration and choice decisions are based on a part-worths model. For simplicity, we examine the case wherein the same utility function is used for consideration and choice decisions. If different partworths models were specified for consideration and choice questions, we expect that our key findings would not change qualitatively.</p><p>In each scenario under study, we perform active learning wherein 40 consideration questions are adaptively designed for each respondent, followed by 25 adaptive choice questions with 2 alternatives each. In the first benchmark condition, the question selection algorithm by <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> is used for the adaptive design of consideration questions. In the second benchmark condition, the question selection algorithm by <ref type="bibr" target="#b0">Abernethy et al. (2008)</ref> is used for the adaptive design of choice questions. Because the algorithm by <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> is designed for consideration questions only and that by Abernethy et al. ( <ref type="formula">2008</ref>) is for choice questions only, fuzzy SVM active learning is used as the question selection method for choice questions in the first benchmark condition and for consideration questions in the second benchmark condition to ensure fair comparison. For similar reasons, the fuzzy SVM method is used as the estimation method after all questions are queried in all three conditions.</p><p>As before, we examine three scenarios in which the focal product category comprises 15, 25, and 35 attributes with three levels each. Three-hundred synthetic respondents are simulated in each scenario. The part-worths for each respondent are randomly generated with (− , 0, ) for each attribute, with ∼ N 1 3 . To compare performances across conditions, 3,000 validation questions consisting of two profiles are generated for each respondent, with the respondent choosing the profile on the left 50% of the time and choosing the profile on the right in the remaining questions. Under this setup, the null model for the hit rate and U 2 is the one that predicts "randomly choose among the two profiles." In addition to the hit rate, KL divergence, and U 2 measures, we use mean absolute error (MAE) and root mean square error (RMSE) to measure the ability of each question selection method to recover the true part-worths. For comparability across methods, can be derived in closed form. Therefore, when the focal product consists of a large number of continuous attributes, this method is a good alternative for adaptive design of choice questions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Performance Comparisons Between Fuzzy SVM</head><p>and Soft Margin SVM Active Learning With and Without Response Errors A key advantage of our proposed method is its ability to gauge response errors on the fly. In this section, we investigate use of the fuzzy SVM active learning versus that of the soft margin SVM active learning without fuzzy membership probabilities. Because both methods scale well in high dimensional problems, we examine the case wherein the focal product category consists of 35 attributes with three levels each. We use methods similar to those used in §5.2 to simulate the true part-worths and the holdout profiles for the 300 synthetic respondents used in each problem instance.</p><p>We first investigate performance comparisons of the two methods when there are response errors. Given that the positions of response errors play an integral role in the performance of adaptive question design, we examine the two question selection methods' abilities to recover true part-worths and to predict holdout profiles under the scenarios of (1) early versus (2) middle versus (3) late response errors. To ensure fair comparisons, we set the instances of response errors at 15% across the three scenarios. In the early/middle/late response errors scenario, all response errors occur during the first/middle/late 1/3 of adaptive questions. For each synthetic respondent, we use random draws from a uniform distribution to determine the positions of the errors. Within each scenario, we hold error positions constant across the two question selection methods so that our results are comparable.</p><p>Our performance comparisons are reported in Table <ref type="table">6</ref>(a). 11 When response errors take place during early or middle portions of the adaptive study, the fuzzy SVM active learning method exhibits a superior ability to recover the true part-worths and to predict holdout questions than the soft-margin SVM active learning. Nevertheless, if response errors occur towards the end of the adaptive survey, both question selection methods perform similarly. This pattern is quite reasonable because early response errors are in general more detrimental than errors taking place later in adaptive question design. Given its primary goal of alleviating the negative effect from response errors on the fly, the fuzzy SVM active learning method provides the most improvement over the soft-margin SVM method when the impact of response errors is salient. In contrast, because the negative effect from response errors is limited when errors take place towards the end of the adaptive question selection, the advantage of using fuzzy SVM over soft margin SVM diminishes correspondingly.</p><p>We also examine performances of the two methods when respondents do not make any response error. As expected, use of the fuzzy SVM active learning incurred an efficiency loss, which originated from the less than perfect fuzzy membership probabilities assigned to the correctly labeled support vectors (Table <ref type="table">6(b)</ref>). Nevertheless, such an efficiency loss is relatively minor, possibly due to the fact that active learning is inherently less challenging in the absence of response errors. <ref type="bibr">11</ref> For simplicity, we report the performance metrics with 40 adaptive questions where each synthetic respondent labels the profile as "would consider" or "would not consider." Similar patterns are found when choice questions are added after the consideration questions.</p><p>In line with Table <ref type="table">6</ref>(a), the advantage of fuzzy SVM active learning is the most salient when errors take place towards the beginning and middle portions of the consideration/choice questions. We also conducted similar comparisons under varying levels of error instances and product dimensions. We find that the general results hold qualitatively as long as the error instance is not excessive (if the respondents incur too many errors, neither method can effectively recover the true part-worths).</p><p>in the proposed method may only be beneficial when consumers exhibit similar product preferences and practical concerns preclude longer surveys.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>In this paper, we propose an adaptive decompositional framework to elicit consumers' preferences for complex products. Our research suggests that the proposed method could provide the following new capabilities to complement existing preference elicitation methods. First, compared to extant methods, the proposed algorithm is particularly suitable for high dimensional problems. Our empirical and synthetic studies demonstrate that the proposed framework can rapidly and effectively elicit individual-level preference estimates for product categories equipped with 70-100 attribute levels. This is typically considered prohibitive for decompositional preference elicitation methods. Second, we demonstrate that the fuzzy SVM active learning method provides a natural remedy for a long-standing challenge in adaptive question design by gauging the possibility of response errors on the fly and incorporating it into the survey design. Through synthetic data experiments we show that the proposed algorithm is particularly effective when response errors take place towards the beginning or middle portions of adaptive questions. Last, while most adaptive question selection methods only use information from the focal respondent, our research explores in a live setting how previous respondent data may be used to assist active learning of the focal respondent's product preferences. Overall, our research suggests that the proposed approach is a promising new method that can be used to complement extant preference elicitation methods, particularly in the context of complex products.</p><p>Our research is also subject to limitations and suggests promising avenues for future research. First, while we use part-worths models to characterize consumers' responses to consideration and choice questions, our algorithm does not explicitly uncover decision heuristics used by consumers. Future research may adapt the proposed algorithm to directly capture such heuristics. In such cases, the SVM classification would be performed at the product feature level, rather than at the product level as in the proposed method. Separate utility functions may also be used in the consideration and choice stages if the underlying decision rules for the consideration phase versus the choice phase are known to be different.</p><p>Second, while the current research is among the first efforts to explore the use of previous respondents' data in complex product preference elicitation in a live setting, we only observe incremental benefits of collaborative filtering at the outset of the adaptive question survey. Future research may consider alternative approaches to take better advantage of this technique. For example, richer covariates such as demographic, socioeconomic, and product use information may be incorporated into collaborative filtering. Furthermore, advantages from using other respondents' data might become more salient if researchers were to incorporate collaborative filtering into the entire course of adaptive question design rather than only in the selection of initial questions.</p><p>Last, while the proposed algorithm is flexible enough to accommodate nonlinear utility functions, the specifications of such nonlinear utility functions are ad hoc by nature. Managerial insights or pretests (or both) are needed to determine the exact form of the kernel function. If an inappropriate kernel is used, response errors may be indistinguishable from the incorrectly specified utility form. Therefore, before the adaptive question design, managerial consultation or pretests (or both) should be used to carefully specify the exact utility model to be estimated.</p><p>With regard to extensions, future research may further explore the use of semi-supervised active learning in marketing context, particularly in the area of adaptive question design. For example, a common challenge faced by adaptive question design is the lack of labeled data points, particularly at the beginning of the survey. The basic idea of semi-supervised active learning is to iteratively identify unlabeled data points that are similar to labeled data, and to assign pseudo labels to such points so that the training data set can be enlarged. Recent research has shown that such efforts can effectively alleviate the problem of small-sized training data (e.g., <ref type="bibr" target="#b50">Wu and Yap 2006</ref><ref type="bibr" target="#b24">, Hoi et al. 2009</ref><ref type="bibr" target="#b29">, Leng et al. 2013</ref>). Future research may further explore how to use such methods to improve extant adaptive question design, or in any marketing context where individual-level consumer data are relatively sparse. Additionally, if consumer responses are classified in multiple categories (e.g., not preferred, neutral, preferred, etc.), researchers can leverage recent methods that use support vector machine classifiers for active learning of multiclass classification (e.g., <ref type="bibr" target="#b36">Patra and Bruzzone 2012)</ref>. Such endeavors are fruitful areas for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental Material</head><p>Supplemental material to this paper is available at http://dx .doi.org/10.1287/mksc.2015.0946.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>446</head><label></label><figDesc>Marketing Science 35(3), pp.445-464, © 2016 INFORMS    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>is selected as the next choice set shown to the consumer. Similar to §3.4.2, conditional on satisfying the smallest Marketing Science 35(3), pp. 445-464, © 2016 INFORMS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Comparison of Predictive Validity: Digital Camera Study</figDesc><table><row><cell>Hit rate</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc>Comparison of Predictive Validity: Computer Tablet Study</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>KL divergence</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Initial validation</cell><cell></cell><cell></cell><cell cols="2">Delayed validation</cell><cell>Pooled</cell><cell></cell><cell cols="2">Hit rate (pooled)</cell></row><row><cell>Method</cell><cell>N</cell><cell>Avg.</cell><cell>SE</cell><cell>N</cell><cell>Ave.</cell><cell>SE</cell><cell>Ave.</cell><cell>SE</cell><cell>Ave.</cell><cell>SE</cell></row><row><cell>Condition 1: Proposed method</cell><cell>35</cell><cell>0 288 a b</cell><cell>0.062</cell><cell>26</cell><cell>0 260 a b</cell><cell>0.073</cell><cell>0 471 a b</cell><cell>0.054</cell><cell>0 671 a</cell><cell>0.041</cell></row><row><cell>Condition 2: Fuzzy SVM without</cell><cell>36</cell><cell>0 426</cell><cell>0.066</cell><cell>26</cell><cell>0 407</cell><cell>0.077</cell><cell>0 577</cell><cell>0.052</cell><cell>0 565</cell><cell>0.049</cell></row><row><cell>consideration questions</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Condition 3: Self-explicated</cell><cell>39</cell><cell>0 443</cell><cell>0.058</cell><cell>27</cell><cell>0 479</cell><cell>0.080</cell><cell>0 662</cell><cell>0.043</cell><cell>0 585</cell><cell>0.031</cell></row><row><cell>Condition 4: ACBC</cell><cell>41</cell><cell>0 472</cell><cell>0.059</cell><cell>30</cell><cell>0 531</cell><cell>0.062</cell><cell>0 652</cell><cell>0.048</cell><cell>0 520</cell><cell>0.033</cell></row><row><cell cols="6">a Best in column or not significantly different from best in column at the 0.05 level.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">b Marginally better than the fuzzy SVM without consideration questions condition (p &lt; 0 1).</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc>Predictive Validity by Number of Questions Asked: Computer Tablet Study No. of questions (q) KL-divergence (smaller is better) Hit rate (larger is better)</figDesc><table><row><cell>1</cell><cell>0.557</cell><cell>0.538</cell><cell>← Self-configurator</cell></row><row><cell>3</cell><cell>0.600</cell><cell>0.586</cell><cell></cell></row><row><cell>5</cell><cell>0.602</cell><cell>0.619</cell><cell></cell></row><row><cell>7</cell><cell>0.611</cell><cell>0.648</cell><cell></cell></row><row><cell>9</cell><cell>0.522</cell><cell>0.614</cell><cell></cell></row><row><cell>11</cell><cell>0.529</cell><cell>0.638</cell><cell></cell></row><row><cell>13</cell><cell>0.504</cell><cell>0.648</cell><cell></cell></row><row><cell>15</cell><cell>0.484</cell><cell>0.638</cell><cell></cell></row><row><cell>17</cell><cell>0.494</cell><cell>0.671</cell><cell></cell></row><row><cell>19</cell><cell>0.552</cell><cell>0.657</cell><cell></cell></row><row><cell>21</cell><cell>0.498</cell><cell>0.667</cell><cell></cell></row><row><cell>23</cell><cell>0.496</cell><cell>0.676</cell><cell></cell></row><row><cell>25</cell><cell>0.500</cell><cell>0.667</cell><cell></cell></row><row><cell>27</cell><cell>0.502</cell><cell>0.662</cell><cell></cell></row><row><cell>29</cell><cell>0.502</cell><cell>0.676</cell><cell></cell></row><row><cell>31</cell><cell>0.480</cell><cell>0.681</cell><cell></cell></row><row><cell>33</cell><cell>0.480</cell><cell>0.652</cell><cell></cell></row><row><cell>34</cell><cell>0.471</cell><cell>0.671</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4</head><label>4</label><figDesc>Using Proposed vs. Conjunctive Question Selection When the True Consideration Decisions Are Conjunctive: Synthetic Data Experiments</figDesc><table><row><cell></cell><cell></cell><cell cols="3">(a) Parameter recovery and predictive validity comparisons</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Question selection method</cell><cell cols="2">Question selection method</cell></row><row><cell></cell><cell></cell><cell>Proposed method</cell><cell>Dzyabura and Hauser (2011)</cell><cell>Proposed method</cell><cell>Dzyabura and Hauser (2011)</cell></row><row><cell>Product dimension</cell><cell>Performance measure</cell><cell cols="2">Conjunctive estimation</cell><cell cols="2">Fuzzy SVM estimation</cell></row><row><cell>3 × 15</cell><cell>Hit rate</cell><cell>0.986</cell><cell>1 000 a</cell><cell>0 966 a</cell><cell>0.919</cell></row><row><cell></cell><cell>KL divergence</cell><cell>0.072</cell><cell>0 000 a</cell><cell>0 091 a</cell><cell>0.264</cell></row><row><cell></cell><cell>U 2</cell><cell>0.928</cell><cell>1 000 a</cell><cell>0 728 a</cell><cell>0.515</cell></row><row><cell>3 × 25</cell><cell>Hit rate</cell><cell>0.948</cell><cell>0 992 a</cell><cell>0 948 a</cell><cell>0.910</cell></row><row><cell></cell><cell>KL divergence</cell><cell>0.252</cell><cell>0 013 a</cell><cell>0 117 a</cell><cell>0.246</cell></row><row><cell></cell><cell>U 2</cell><cell>0.818</cell><cell>0 850</cell><cell>0 693 a</cell><cell>0.588</cell></row><row><cell>3 × 35</cell><cell>Hit rate</cell><cell>0.945</cell><cell>0 994 a</cell><cell>0 936 a</cell><cell>0.892</cell></row><row><cell></cell><cell>KL divergence</cell><cell>0.232</cell><cell>0 018 a</cell><cell>0 131 a</cell><cell>0.267</cell></row><row><cell></cell><cell>U 2</cell><cell>0.685</cell><cell>0 743 a</cell><cell>0 614 a</cell><cell>0.577</cell></row><row><cell></cell><cell cols="4">(b) Average time to generate next question comparisons (in seconds)</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="2">Question selection method</cell><cell></cell></row><row><cell>Product dimension</cell><cell></cell><cell cols="2">Proposed method</cell><cell></cell><cell>Dzyabura and Hauser (2011)</cell></row><row><cell>3 × 15</cell><cell></cell><cell></cell><cell>0 218 a</cell><cell></cell><cell>2 856</cell></row><row><cell>3 × 25</cell><cell></cell><cell></cell><cell>0 214 a</cell><cell></cell><cell>6 920</cell></row><row><cell>3 × 35</cell><cell></cell><cell></cell><cell>0 215 a</cell><cell></cell><cell>11 861</cell></row></table><note>a Significantly better than the alternative method at the 0.05 level.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Note that, in practice, some consumers may not use the same utility function for consideration and choice decisions. For example, an individual might emphasize different sets of attributes in the consideration phase versus in choice phase. In §5.1, we discuss how our algorithm can be used in conjunction with the algorithm by<ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> to accommodate a consider-then-choice framework wherein conjunctive rules are used to examine answers to consideration questions and conjoint part-worths are used to capture product preferences reflected in choice questions. In such cases, different utility functions may also be used to model consideration and choice decisions separately.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Note that one potential caveat of this approach is that the inclusions of "must-have" and "unacceptable" features might prime the respondent into conjunctive-style decision making. An alternative would be to use the uncertainty sampling method used by<ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> to construct the candidate pool of product profiles, with the trade-off that it might be challenging to accurately identify the most uncertain profiles during the first few queries.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Synthetic data experiments reveal that, as long as the total number of candidate profiles (i.e., N j = N 1 j + N 2 j is sufficiently large, we can recover a part-worths estimate that is close to the true part-worths under our active learning method. In the empirical applications, we set N j to be 20,000. Our synthetic studies suggest that this is sufficiently large to recover the true part-worths while keeping the question selection at less than 0.25 second between questions at the consideration stage. Similar approaches are used to determine the number of profiles to be considered in the choice stage.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Following the approaches described in<ref type="bibr" target="#b13">Evgeniou et al. (2005)</ref> and<ref type="bibr" target="#b44">Toubia et al. (2007b)</ref>, we use a cross-validation method based on pretest data from the same population as the main study to determine the values of C in our two empirical applications.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Marketing Science 35(3), pp.445-464, © 2016 INFORMS   </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">Note that the values of the KL measure depend on the number of the validation tasks<ref type="bibr" target="#b20">(Hauser et al. 2014)</ref>. Therefore, the pooled KL measures differ in magnitude from those based on initial or delayed validation tasks only.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank seminar participants at MIT, Columbia University, the University of Texas at Austin, the University of British Columbia, Georgetown University, the INFORMS Marketing Science Conference, and the AMA Advanced Research Techniques (ART) Forum for their constructive comments. This study also benefited from a grant of Don Murray to the USC Marshall Center for Global Innovation. </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>we normalize the estimated part-worths to the scale of the true part-worths in each problem instance.</p><p>Our comparison results are shown in Table <ref type="table">5</ref>. When the true consideration and choice decisions are based on a part-worths model, the proposed question selection method outperforms the two benchmark methods in parameter recovery and predictive validity (Table <ref type="table">5(a)</ref>). Not surprisingly, the question selection algorithm by <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> does not work as well in this setting, as the algorithm is specifically developed to uncover consideration heuristics when the true consideration decisions follow a set of conjunctive rules, rather than a part-worths model. Meanwhile, the lack of performance from the question selection algorithm by <ref type="bibr" target="#b0">Abernethy et al. (2008)</ref>, particularly in high dimensional problems, is likely related to the discrete transformation required by its gradient-based algorithm when used for a large number of discrete attributes in our setting. 10 10 While we obtain significantly better performance from the proposed method, the hit rate differences between the proposed method and <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> are rather small in the case of 35 attributes with three levels each (0.901 versus 0.893 as in Table <ref type="table">5</ref>(a)). We further examine the percentages of times that the estimated part-worths from the two methods could correctly predict the most preferred attribute level in each attribute. We do not find We also report the average time it takes to generate the next question under each question selection method in Table <ref type="table">5(</ref> <ref type="bibr">b)</ref>. Because the algorithm by <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> is used for consideration questions only and that by <ref type="bibr" target="#b0">Abernethy et al. (2008)</ref> is used for choice questions only, the corresponding average time is reported in this table. For consideration questions, the algorithm by <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> takes approximately three or more seconds on average to generate the next question (again, the computing speed may improve considerably if the code were optimized or written in a more computationally efficient language). Regarding choice questions, the algorithm by <ref type="bibr" target="#b0">Abernethy et al. (2008)</ref> is very fast computationally because the solution used to generate the next question significant differences between the two methods in this case (both can correctly predict the most preferred attribute levels about 86% of the time). We also compare the mean absolute percentage error (MAPE) between the predicted and actual part-worths from the two methods. Consistent with findings from the MAE and RMSE measures in Table <ref type="table">5</ref>, the proposed method provides more accurate part-worths estimates than <ref type="bibr" target="#b12">Dzyabura and Hauser (2011)</ref> in all cases. Managerially, if the primary focus of the firm is to identify the most preferred attribute level in each attribute, we think that such differences in hit rates do not produce additional insights. Nevertheless, if the firm's central goal is to obtain a precise forecast of market share or product profit, we believe that the improved accuracy in our part-worths estimates would be beneficial. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Tests of Improvements Over Noninformative</head><p>Initial Part-Worths In the synthetic experiments above, we use only the focal respondent's information in the design of adaptive questions. In this section, we examine the use of collaborative-filtered initial part-worths versus that of noninformative initial part-worths in parameter recovery and predictive validity. Because the initial individual-specific part-worths in our proposed framework is obtained via collaborative filtering between the focal and previous respondents' self-configured product profiles, we also investigate whether the degree of heterogeneity in synthetic respondents' configurators plays a role in the usefulness of incorporating data from other respondents. Intuitively, if all respondents have the same product preferences and self-configure the same profile, past respondents' data should be quite informative in determining the focal respondent's initial part-worths. By contrast, when respondents differ greatly in their most favorite product profiles, collaborative filtering may not be very helpful.</p><p>We consider the following two scenarios of homogenous versus heterogeneous configurators accordingly. In the homogenous case, we simulate 300 synthetic respondents with identical part-worths (hence identical self-configured profile). In the heterogeneous case, we consider 300 synthetic respondents with different selfconfigurators. By excluding perfect overlap in the focal and previous respondents' self-configured profiles, the average cosine similarity (s j j in Equation ( <ref type="formula">1</ref>)) in the heterogeneous case is 0.331.</p><p>In each case described above, we consider a baseline model where noninformative initial part-worths are used at the outset of the adaptive question design. Instead of using information from the focal and previous respondents' configurators as in the two collaborative filtering conditions, the noninformative initial part-worths  are obtained by randomly querying one profile that the synthetic respondent would consider and one profile the respondent would not consider from the training data. We then compare improvements obtained from collaborative-filtered initial part-worths over noninformative initial part-worths in the respective cases of homogenous versus heterogeneous configurators. In both comparisons, we examine the scenario wherein the focal product category consists of 35 attributes with three levels each. The adaptive question design is based on 40 consideration questions and 25 choice questions as in §5.2. We follow the same procedure described in §5.2 to construct the 3,000 validation questions for each synthetic respondent.</p><p>Table <ref type="table">7</ref> provides comparison results from these two cases as a function of the number of questions queried. Consistent with our conjecture, at the outset of the adaptive question design, incremental benefits from the collaborative-filtered versus the noninformative initial part-worths are considerably more salient in the homogenous configurator case. This finding is rather intuitive because previous respondents' estimated partworths are information rich if all respondents have the same product preferences. Interestingly, Table <ref type="table">7</ref> also reveals that, in both cases, the advantages from collaborative-filtered initial part-worths diminish during the course of the adaptive question survey. Indeed, after the respondents answer about 40 consideration questions, the benefits from the collaborative-filtered initial part-worths become more or less negligible. This finding implies that, analogous to the role of priors in the Bayesian literature, benefits from informative initial part-worths can lessen considerably as more data becomes available. Similar results hold when we use an alternative baseline model wherein the initial partworths vector is calculated based on the focal respondent's configurator alone. These synthetic experiments suggest that collaborative-filtered initial part-worths</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Eliciting consumer preferences using robust adaptive choice questionnaires</title>
		<author>
			<persName><forename type="first">J</forename><surname>Abernethy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Vert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowledge Data Engrg</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="155" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">An Information Processing Theory of Consumer Choice</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bettman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
			<publisher>Addison-Wesley</publisher>
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Empirical analysis of predictive algorithms for collaborative filtering</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Breese</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Kadie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 14th Conf. Uncertainty Artificial Intelligence</title>
				<meeting>14th Conf. Uncertainty Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="43" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Bayesian experimental design: A review</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaloner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Verdinelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statist. Sci</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="304" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Support-vector networks</title>
		<author>
			<persName><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Vapnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learn</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="297" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Prediction in marketing using the support vector machine</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Curry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="595" to="615" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">An incentive-aligned mechanism for conjoint analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="214" to="223" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Incentive-aligned conjoint analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Grewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Liechty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="82" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Barter markets for conjoint analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1003" to="1017" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unstructured direct elicitation of decision rules</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dzyabura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Gaskin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="127" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Fast SVM training algorithm with decomposition on very large data sets</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">X</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Krzyzak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">Y</forename><surname>Suen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="603" to="618" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A simple mechanism to incentivealign conjoint experiments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Res. Marketing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="25" to="32" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Active machine learning for consideration heuristics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dzyabura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="801" to="819" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Generalized robust conjoint estimation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Boussios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zacharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="415" to="429" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A convex optimization approach to modeling consumer heterogeneity in conjoint estimation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pontil</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="805" to="818" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Conjoint analysis in marketing: New developments with implications for research and practice</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="3" to="19" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">The no-choice alternative in conjoint choice experiments</title>
		<author>
			<persName><forename type="first">R</forename><surname>Haaijer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Kamakura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Market Res</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="93" to="106" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Testing the accuracy, usefulness, and significance of probabilistic choice models: An information-theoretic approach</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="406" to="421" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Conjoint analysis, related modeling, and applications</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Marketing Research and Modeling: Progress and Prospects</title>
				<editor>
			<persName><forename type="first">Y</forename><surname>Wind</surname></persName>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Green</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="141" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The impact of utility balance and endogeneity in conjoint analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="498" to="507" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Self-reflection and articulated consumer preferences</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Product Innovation Management</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="32" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Disjunctions of conjunctions, cognitive simplicity, and consideration sets</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Befurt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dzyabura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="485" to="496" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Fuzzy SVM for noisy data: A robust membership calculation method</title>
		<author>
			<persName><forename type="first">G</forename><surname>Heo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Gader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fuzzy Systems Conf. Proc</title>
				<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="431" to="436" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Bayes point machines</title>
		<author>
			<persName><forename type="first">R</forename><surname>Herbrich</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Graepel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Machine Learn. Res</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="245" to="279" />
			<date type="published" when="2001-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Semisupervised SVM batch mode active learning with applications to image retrieval</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">C</forename><surname>Hoi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jin</forename><forename type="middle">R</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Lyu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inform. Systems</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">16</biblScope>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Testing the impact of dimensional complexity and affective differences in adaptive conjoint analysis</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hansen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="159" to="163" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The effectiveness of alternative preference elicitation procedures in predicting choice</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Wittink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Fiedler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="105" to="114" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">K</forename><surname>Orme</surname></persName>
		</author>
		<title level="m">A new approach to adaptive CBC. Sawtooth Software Research Paper</title>
				<meeting><address><addrLine>Sequim, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">On information and sufficiency</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Leibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Statist</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Combining active learning and semisupervised learning to construct SVM classifier</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Leng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Qi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge-Based Systems</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="121" to="131" />
			<date type="published" when="2013-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Fuzzy support vector machines</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Neural Networks</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="464" to="471" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Training algorithms for fuzzy support vector machines with noisy data</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">D</forename><surname>Wang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pattern Recognition Lett</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1647" to="1656" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Adaptive self-explication of multiattribute preferences</title>
		<author>
			<persName><forename type="first">O</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="140" to="156" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Three ways to treat overall price in conjoint analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Orme</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Sawtooth Software Research Paper</title>
				<meeting><address><addrLine>Sequim, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Getting Started with Conjoint Analysis Strategies for Product Design and Pricing Research</title>
		<author>
			<persName><forename type="first">B</forename><surname>Orme</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Research Publishers LLC</publisher>
			<pubPlace>Madison, WI</pubPlace>
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Eliciting preference for complex products: A web-based upgrading method</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="562" to="574" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A batch-mode active learning technique based on multiple uncertainty for SVM classifier</title>
		<author>
			<persName><forename type="first">S</forename><surname>Patra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Bruzzone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Geoscience Remote Sensing Lett</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="497" to="501" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Introduction to Modern Information Retrieval</title>
		<author>
			<persName><forename type="first">G</forename><surname>Salton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Mcgill</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A comparison of conjoint measurement with self-explicated approaches</title>
		<author>
			<persName><forename type="first">H</forename><surname>Sattler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Hensel-Börner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conjoint Measurement Methods and Applications</title>
				<editor>
			<persName><forename type="first">A</forename><surname>Gustafsson</surname></persName>
			<persName><forename type="first">F</forename><surname>Huber</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="147" to="159" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Measuring consumer preferences for complex products: A compositional approach based on paired comparisons</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Scholz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Meissner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Decker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="685" to="698" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Iterative fuzzy support vector machine classification</title>
		<author>
			<persName><forename type="first">A</forename><surname>Shilton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">T</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Fuzzy Systems Conf. Proc</title>
				<imprint>
			<date type="published" when="2007" />
			<biblScope unit="page" from="1391" to="1396" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">A conjunctive-compensatory approach to the self-explication of multiattributed preferences</title>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">S</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Sci</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="295" to="305" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Support vector machine active learning with applications to text classification</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Machine Learn. Res</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="45" to="66" />
			<date type="published" when="2001-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Optimization-based and machine-learning methods for conjoint analysis: Estimation and question design</title>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conjoint Measurement: Methods and Applications</title>
				<editor>
			<persName><forename type="first">A</forename><surname>Gustafsson</surname></persName>
			<persName><forename type="first">A</forename><surname>Herrmann</surname></persName>
		</editor>
		<meeting><address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="231" to="258" />
		</imprint>
	</monogr>
	<note>4th ed.</note>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Probabilistic polyhedral methods for adaptive choice-based conjoint analysis: Theory and application</title>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Garcia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="596" to="610" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Polyhedral methods for adaptive choice-based conjoint analysis</title>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Simester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="131" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Dynamic experiments for estimating preferences: An adaptive method of eliciting time and risk parameters</title>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Johnson</forename><forename type="middle">E</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Delquié</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="613" to="640" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Fast polyhedral adaptive conjoint estimation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Simester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="303" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">N</forename><surname>Vapnik</surname></persName>
		</author>
		<title level="m">Statistical Learning Theory</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A fuzzy support vector machine to evaluate credit risk</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">K</forename><surname>Lai</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Fuzzy Sys</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="820" to="831" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Fuzzy SVM for content-based image retrieval</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">H</forename><surname>Yap</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Comput. Intelligence Magazine</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="10" to="16" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
