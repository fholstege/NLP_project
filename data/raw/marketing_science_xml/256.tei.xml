<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Experimental Designs and Estimation for Online Display Advertising Attribution in Marketplaces</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Joel</forename><surname>Barajas</surname></persName>
							<email>jbarajas@soe.ucsc.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>95064</postCode>
									<settlement>Santa Cruz</settlement>
									<region>California</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">School of Information</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ram</forename><surname>Akella</surname></persName>
							<email>akella@ischool.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>95064</postCode>
									<settlement>Santa Cruz</settlement>
									<region>California</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">University of California</orgName>
								<address>
									<addrLine>Santa Cruz</addrLine>
									<postCode>95064</postCode>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Marius</forename><surname>Holtan</surname></persName>
							<email>marius.holtan@teamaol.com</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>95064</postCode>
									<settlement>Santa Cruz</settlement>
									<region>California</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">AOL Research</orgName>
								<address>
									<postCode>94306</postCode>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Aaron</forename><surname>Flores</surname></persName>
							<email>aaron.flores@teamaol.com</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>95064</postCode>
									<settlement>Santa Cruz</settlement>
									<region>California</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">AOL Research</orgName>
								<address>
									<postCode>94306</postCode>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Experimental Designs and Estimation for Online Display Advertising Attribution in Marketplaces</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
					</monogr>
					<idno type="DOI">10.1287/mksc.2016.0982</idno>
					<note type="submission">Received: December 31, 2013; accepted: October 28, 2015; Pradeep Chintagunta, Dominique Hanssens, and John Hauser served as the special issue editors and Carl Mela served as associate editor for this article.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>online advertising</term>
					<term>experimental design</term>
					<term>user targeting</term>
					<term>field experiments</term>
					<term>Bayesian estimation</term>
					<term>econometrics History:</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please scroll down for article-it is on subsequent pages</head><p>With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning opportunities for individual professionals, and organizations of all types and sizes, to better understand and use O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction and Problem Context</head><p>According to the Interactive Advertising Bureau (IAB) and PricewaterhouseCoopers (PWC), Internet display related advertising revenues in the United States totaled $6.5 billion during the first six months of 2014. This revenue represents 28% of the total online advertising ($23.1 billion) and constitutes an increase of 6% over the $6.1 billion reported over the same period in 2013. Because of the proliferation of the online user activity tracking, performance-based, or Cost-Per-Action (CPA), campaigns accounted for 65% of the campaigns run for the same period. On the other hand, 34% of campaigns were run under the more traditional Cost-Per-Impression (CPM) business model. <ref type="bibr">1</ref> In this context, determining the effectiveness of an online campaign in achieving increased user commercial actions is usually used to give credit to CPA campaigns. This process is termed campaign attribution.</p><p>1 IAB internet advertising revenue report. 2014 first six months' results. http://www.iab.com/wp-content/uploads/2015/05/IAB _Internet_Advertising_Revenue_Report_HY_2014_PDF.pdf.</p><p>The advertising industry has developed methods for online conversion attribution such as Last-Touch Attribution. In this framework, the full conversion credit is given to the last campaign that a converting user is exposed to (i.e., the touch point). Another method is the Multi-Touch Attribution (MTA), where the conversion credit is heuristically split across the touch points in the path to conversion (Atlas Institute 2008). Data-driven MTA approaches have been proposed to model interacting channel effects <ref type="bibr" target="#b23">(Shao and</ref><ref type="bibr" target="#b23">Li 2011, Li and</ref><ref type="bibr" target="#b18">Kannan 2014)</ref>. However, these methods assign attribution credit to every exposed and converting user while ignoring the counterfactual response without ad exposures. Also, these approaches incentivize selection for ad exposure of baseline users <ref type="bibr" target="#b2">(Berman 2015)</ref>, those who convert regardless of the touch point (always-buy users).</p><p>Running randomized experiments (or field experiments) is becoming the standard approach to measuring the marginal effectiveness of online campaigns <ref type="bibr" target="#b6">(Chittilappilly 2012</ref><ref type="bibr" target="#b17">, Lewis et al. 2011</ref><ref type="bibr" target="#b25">, Yildiz and Narayanan 2013</ref><ref type="bibr" target="#b14">, Johnson et al. 2016</ref>. In this practice, the ad is assumed to be the treatment to evaluate, and users are randomly separated into study and control groups. Hence, when a targeting engine selects a visiting user for exposure, the campaign ad is displayed to users in the study group, or a placebo ad is displayed to users in the control group <ref type="bibr" target="#b25">(Yildiz and</ref><ref type="bibr">Narayanan 2013, Lewis et al. 2011)</ref>. Full deployment of this framework is limited by the cost of displaying placebo ads, and the potential revenue loss resulting from yielding the opportunity to advertise to control users. As a consequence, current industry practice is to run a low-budget CPM campaign and measure its effectiveness, which is also assumed to hold (external validity) for a larger budget CPA campaign <ref type="bibr" target="#b25">(Yildiz and</ref><ref type="bibr">Narayanan 2013, Chittilappilly 2012)</ref>.</p><p>Today, ad exchange platforms facilitate marketplaces where advertising spaces on websites are bought and sold. A survey of 49 media buyers indicates that 87.8% intended to purchase digital advertising via real-time bidding (RTB) by 2011 <ref type="bibr" target="#b7">(Digiday and Google 2011)</ref>. Similarly, outside RTB exchanges, ad networks run internal auctions <ref type="bibr" target="#b4">(Broder and Josifovski 2011)</ref>. Because media buying is done endogenously in a competitive market, the user selection for ad exposure complicates the evaluation using placebo ads. Moreover, to display a placebo ad, the opportunity to advertise must be consumed and the campaign must exist in the marketplace (i.e., campaign presence effect). <ref type="bibr" target="#b14">Johnson et al. (2016)</ref> acknowledge the bias induced by endogenous user selection when running a placebo campaign. Similar to propensity-score based corrections, their proposed solution predicts ad exposures of users in the control group based on their features, which are often noisy and fragmented. Also, their approach relies on auction simulations assumed to be stationary. Most important, the effect of the campaign presence in the marketplace 2 (i.e., strategic effect) is ignored by current practices and literature.</p><p>User targeting is one of the most important decisions in running a campaign. A survey of 100 marketers, agencies, and media planners indicates that user targeting and campaign optimization capabilities are perceived as the main differentiators among ad networks <ref type="bibr" target="#b19">(Morrison and Coolbirth 2008)</ref>. In campaign attribution, ad exposures are often considered a consequence of user activity <ref type="bibr" target="#b17">(Lewis et al. 2011</ref>), or even a potential "coincidence" <ref type="bibr" target="#b25">(Yildiz and Narayanan 2013)</ref>. In reality, deployment of CPA campaigns has produced increasingly sophisticated targeting engines that aim to display ads to converting users (i.e., selection effect) <ref type="bibr" target="#b20">(Pandey et al. 2011</ref><ref type="bibr" target="#b0">, Aly et al. 2012</ref>. As a result, the external validity of nonoptimized CPM campaign effects to CPA campaigns, assumed by current industry evaluation practice, is prone to inaccuracies.</p><p>In a recent economic literature review, <ref type="bibr" target="#b11">Goldfarb (2014)</ref> surveys the online advertising literature based on the decreasing cost of user targeting. However, most of the literature on ad effectiveness based on field experiments evaluates focused and specific targeting practices <ref type="bibr" target="#b15">(Lambrecht and Tucker 2013</ref><ref type="bibr" target="#b12">, Goldfarb and Tucker 2011</ref><ref type="bibr" target="#b16">, Lewis and Reiley 2014</ref>. To our knowledge, comparing the selection policy performance of CPA and CPM campaigns, and the implications for current practices have not been adequately addressed by previous literature.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Our Contribution</head><p>We focus on the marginal causal attribution of singleproduct online conversions to online display campaigns (i.e., single channel) run on hundreds of publisher websites, given all other advertising channel exposures or prior branding effect. We find that current industry practice often confounds three campaign effects, i.e., the ad effect on exposed users, the strategic impact of the campaign presence in a competitive market, and the selection effect of the media buyer. We summarize the elements of our contribution below in this context.</p><p>Expand the scope of attribution in marketplaces to the overall campaign. We propose to perform continuing evaluation and estimate the campaign attribution for the current running conditions instead of isolating the ad effect. In this new perspective, the entire campaign, including the campaign presence in the marketplace and the ad, is now the treatment to evaluate. Consequently, we propose a new randomized design that considers all of the visiting users and does not display placebo ads to users of the control group. We argue that this control group represents the right campaign counterfactual in a marketplace. This design cost, which is minimal as to revenue loss, enables us to perform continuing evaluation and attempts to close the feedback loop for causal campaign optimization displayed by Figure <ref type="figure" target="#fig_1">1</ref>. The proposed design is simple to implement and does not suffer from endogenous user selection.</p><p>Capture the effect of the campaign presence in the marketplace. We propose a second randomized design that separates the ad effect from the impact of the campaign presence in the marketplace. Without relying on noisy user features, we develop a method to estimate the user conversion probability of the statistically equivalent users in the control group to those exposed to the ad in the study group. We show the risks of inducing a selection effect in the standard evaluation practice of using placebo ads in a marketplace. Contrary to paid search marketplaces <ref type="bibr" target="#b3">(Blake et al. 2015)</ref>, we report evidence of a campaign presence effect. This effect is  largely ignored in the literature and can significantly change the campaign attribution.</p><p>Characterize the user selection based on user influenceable classes. We present a method to characterize the user selection of influenceable user classes using a Potential Outcomes causal model and Principal Stratification <ref type="bibr" target="#b8">(Frangakis and Rubin 2002)</ref>. By comparing the probability of selecting always-buy users, we report evidence supporting the hypothesis that CPA campaigns incentivize the selection of these users when compared with CPM campaigns <ref type="bibr" target="#b2">(Berman 2015)</ref>. Based on user demographics, we test different user selection policies for mid-flight campaign optimization in the context of the control loop in Figure <ref type="figure" target="#fig_1">1</ref>. Our results suggest that optimizing user selection for ad exposure has a significant impact on campaign effects. These findings raise questions about the external validity of ad effects estimated by a CPM experiment to the CPA campaigns (current practice).</p><p>We approach the problem in two phases: (1) the randomized design, and (2) the causal estimation given this design. Hence, in §2, we analyze the targeted display advertising process in a marketplace and describe the proposed design. We present the methodology to </p><formula xml:id="formula_0">Z ∈ C P S Random treatment assignment Y ∈ 0 1 Converting user indicator B ∈ No Yes Decision to bid indicator A ∈ Lose Win Auction output indicator D ∈ 0 1 Selected for ad exposure indicator W ∈ 0 1 Ad exposure indicator i ∈</formula><p>Variable index for the ith user X ∈ p User feature vector </p><formula xml:id="formula_1">dz ∈ 0 1 Probability of Y = 1 given D = d, Z = z p sel ∈ 0 1 Probability of D = 1 s 0z p s sel z ∈</formula><formula xml:id="formula_2">0 1C 1S sel F targ X i F sig X i F AT E sign X i , w sig</formula><p>Exposure selection optimizing functions (Algorithm 3) characterize the users based on the potential causal effects on them, and the user selection effect in §3. In §4, we cover the estimation model validation, attribution results for two CPA campaigns, the market presence effect for one CPM campaign, and the user selection characterization for these campaigns. We show the value of continuing evaluation in §5 by optimizing user selection for ad exposure assuming short-term ex-ante external validity of the effects. Finally, in §6, we discuss the main findings and their managerial implications. Tables <ref type="table" target="#tab_1">1 and 2</ref> define the notation used in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Experimental Design for Attribution in Marketplaces</head><p>2.1. Targeted Display Advertising in Marketplaces: Overview In Targeted Display Advertising, marketing campaigns are often run by advertisers working closely with a given ad network. The mechanism for displaying an ad is depicted by the decision tree shown in Figure <ref type="figure">2</ref>  Notes. Lifts ∈ −1</p><formula xml:id="formula_3">, P D = 1 U ∈ 0 1 . Other metrics ∈ −1 1 .</formula><p>every visiting user who is provided by a supply-side platform (SSP) or publisher websites. To target users, advertisers develop user profiles of the target market segment based on demographics and other features. However, in practice, the ad network uses a highly sophisticated algorithm, illustrated by the decision node B of Figure <ref type="figure">2</ref>(a), to determine if a user should be targeted. In CPA campaigns, this decision is based on user behavior and history, and how likely the user is to convert, among other features <ref type="bibr" target="#b20">(Pandey et al. 2011</ref><ref type="bibr" target="#b0">, Aly et al. 2012</ref>. If the campaign decides to bid through a demand-side platform (DSP) in the ad exchange (B = Yes), it submits the bid through RTB <ref type="bibr" target="#b24">(Spencer et al. 2011)</ref>. The chance (endogenous) node A of Figure <ref type="figure">2</ref>(a) represents this auction output. If the campaign wins the advertising slot (A = Win), the campaign ad is displayed to the user. Otherwise, another advertiser shows an ad. For CPM campaigns, the decision to bid is set to B = Yes. Moreover, the bidding strategy is determined by guaranteed delivery contracts or by the spot market <ref type="bibr" target="#b10">(Ghosh et al. 2009</ref>). Outside of ad exchanges, these targeting and auction processes are routinely run by large ad networks <ref type="bibr" target="#b4">(Broder and Josifovski 2011)</ref>. For the effects of the current paper, we consider the aggregate targeting engine output (chance node D of Figure <ref type="figure">2</ref>(b)) to refer to users selected for ad exposure, where D = 1 if the user is selected, i.e., if B = Yes and A = Win, and D = 0 otherwise. Referring to selected ad-exposed users as targeted users is typical in the targeted advertising literature. However, we note the case where the user is targeted B = Yes but not exposed to the ad if A = Lose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Campaign Evaluation Using Placebos:</head><p>The Standard Practice The standard approach to evaluating online marketing campaigns is to use randomized experiments assuming the ad design is the treatment to evaluate. <ref type="bibr" target="#b17">Lewis et al. (2011)</ref> propose randomly assigning visiting users at serving time to see the focal ad (study) or the placebo ad assumed to be unrelated to the brand (control). Figure <ref type="figure">3</ref>(a) illustrates this process. In this model, none of the components of standard Targeted Display Advertising in a marketplace are considered. Moreover, randomizing user visits limits this design power; a given user might be assigned to both treatment arms during different visits.</p><p>Current industry practice is to randomize the visiting users once and keep them in the same arm throughout the experiment, as depicted in Figure <ref type="figure">3</ref>(b) <ref type="bibr" target="#b25">(Yildiz and Narayanan 2013)</ref>. Because media buying is endogenously performed in a competitive market, user selection for ad exposure indicator D becomes a post-treatment variable. Conditioning the analysis on its realization might introduce a post-treatment bias. <ref type="bibr">3</ref> Moreover, the targeting engine routinely incorporates user activity feedback, such as user clicks and visits, to improve user selection for ad exposure <ref type="bibr" target="#b0">(Aly et al. 2012)</ref>, which would not be the case for the placebo ad.</p><p>These practices focus on the ad evaluation, without considering the effect of the campaign presence in the marketplace. Also, the ad is often evaluated with a low-budget CPM campaign; the effects are assumed to hold for larger-budget CPA campaigns (Chittilappilly 2012 describes a general industry practice). However, the external validity of CPM campaign effects to CPA campaigns is prone to inaccuracies due to different user selection incentives (Berman 2015), and market interactions <ref type="bibr" target="#b19">(Morrison and Coolbirth 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Proposed Randomized Design</head><p>We propose evaluating the overall campaign, including the ad and the campaign presence in the marketplace. This new perspective implies that the campaign is now the treatment to evaluate. We randomize the visiting users before any decision has been made in the decision tree shown in Figure <ref type="figure">3</ref>(c), and keep them in the same group for the campaign duration. As a result, users in the control group are not exposed to placebo ads. This design aggregates the ad and campaign presence in the marketplace effects analyzed in detail below. Our goal for this randomized design is not to predict or generalize campaign performance for future long-term exposures, which is the objective of randomized experiments. Our goal is to evaluate campaign performance under the current conditions to attribute credit to its overall performance, which is the key attribution problem of interest to online To disaggregate the proposed design in Figure <ref type="figure">3</ref>(c), we consider the design of Figure <ref type="figure">3(d)</ref>, where Z ∈ Control Placebo Study = C P S . To avoid a selection effect, two assumptions of the observed selection in the study and placebo arms need to be tested: Assumption 1. Statistically equivalent user selection; the marginal probability of user selection for ad exposure is the same for both treatment arms.</p><p>Assumption 2. Statistically equivalent selected populations; the marginal conversion probability of the nonselected users for ad exposure is the same for both treatment arms.</p><p>Testing Assumption 1 indicates whether the selection policy (aggregated over user segments) is the same for placebo and study arms. Testing Assumption 2 indicates whether the user selection process (aggregated over user segments) provides statistically equivalent populations based on conversion probabilities. If the nonselected populations are equivalent, in terms of conversion probability, then the complementary populations are statistically equivalent as a consequence of user randomization. Although rejecting Assumption 1 suggests nonequivalent user selection, testing Assumption 2 determines the presence of a selection effect (bias) on the observed conversion data. <ref type="bibr">5</ref> Let Y i Z i be the ith user conversion indicator under the treatment Z i , and assume Assumption 2 holds. Similarly, assume P Y i C D i = 1 Z i = C is known for the control group, in which the user selection indicator D i is not observed; we address this estimation in §3. Thus, the ad average treatment effect ATE Ad i , and the average treatment effect of the campaign presence in the marketplace ATE Market i are defined as follows:</p><formula xml:id="formula_4">ATE Ad i = E Y i S D i = 1 Z i = S − E Y i P D i = 1 Z i = P (1) ATE Market i = E Y i P D i = 1 Z i = P − E Y i C D i = 1 Z i = C</formula><p>The proposed randomized design in Figure <ref type="figure">3</ref>(c) takes the entire campaign as treatment and estimates the campaign average treatment effect (ATE Camp i ) as follows:</p><formula xml:id="formula_5">ATE Camp i = E Y i S Z i = S − E Y i C Z i = C = d∈ 0 1 P D i = d × E Y i S D i = d Z i = S − E Y i C D i = d Z i = C (2)</formula><p>Given that Y i is affected only for the users to whom the ad is displayed, i.e., D i = 1 , all other terms of Equation (2) cancel out. Thus, by substituting for ATE Ad i and ATE Market i from Equation (1), and defining ATE D=1 Camp i to be the campaign local effect given D i = 1 we have</p><formula xml:id="formula_6">ATE Camp i = P D i = 1 × E Y i S D i = 1 Z i = S − E Y i C D i = 1 Z i = C = P D i = 1 × ATE Ad i + ATE Market i = P D i = 1 × ATE D=1 Camp i (3)</formula><p>Therefore, the campaign effect of the proposed design in Figure <ref type="figure">3</ref>(c) provides the aggregated ad and campaign presence effect, ATE D=1</p><p>Camp i . The weighting term, P D i = 1 , is a consequence of a larger user population considered by the campaign (i.e., all visiting users), rather than the subpopulation of exposed users to whom the ad is displayed.  </p><formula xml:id="formula_7">Z = S, D = 1 Z = S, D = 1 Z = S, D = 1 Z = S, D = 0 Z = S, D = 1 Z = P, D = 1 Z = C, D = * No campaign Control Z = C, D = * D Z ∈ {P, S }, D = 0 Z ∈ {P, S}, D = 0 Selected user? Chance Decision End D</formula><p>The standard evaluation using placebo ads identifies ATE Ad i as the "campaign" effect. However, the estimation of the economic value (campaign attribution) based on ATE Ad i alone does not incorporate ATE Market i , which is a consequence of displaying the ad. Therefore, the summation of these two effects, ATE D=1</p><p>Camp i , must be considered. We analyze values of ATE Market i for different scenarios in Appendix A. In Appendix B we show that the proposed design has the lowest potential revenue loss when compared with the standard practice, and is the most suitable for continuing evaluation. Remark 2. To estimate ATE Market (Equation ( <ref type="formula" target="#formula_20">1</ref>)), the expected conversion probability of control users who would be exposed to the ad if they were in the study</p><formula xml:id="formula_8">group, E Y i C D i = 1 Z i = C , has to be inferred (missing D i if Z i = C).</formula><p>In §3, we address this estimation.</p><p>Remark 3. One might believe that the three-arm design described in Figure <ref type="figure">3</ref>(d) is easily analyzed. We can perceive this model as an extension of the standard randomized experiment of Figure <ref type="figure">3</ref>(b), which includes a placebo arm. We reiterate that the error in that logic, and the reason for a different counterfactual and estimation method, is that the publisher slot must be captured and assigned to the campaign or placebo ad.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Estimation Methodology</head><p>Given the randomized design shown in Figure <ref type="figure">3</ref>(c), the estimation of the campaign attribution is straightforward (Equation ( <ref type="formula">6</ref>)). However, by Remark 2, the conversion probability of the users of the control group who would be selected for ad exposure must be inferred. We calculate the local campaign effect on this subpopulation and characterize them based on their response. We develop this methodology in the Potential Outcomes causal model via the Principal Stratification framework. 6</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Causal Modeling: Campaign Effect on the</head><p>Users Exposed to the Ad The Potential Outcomes Causal Model analyzes the individual potential outcomes for each of the treatments <ref type="bibr" target="#b21">(Rubin 2005)</ref>. For two treatment arms, this framework implies that half of the data is missing because we never observe a unit response in both arms. If the treatment assignment is independent of the treatment effect (i.e., random assignment), then the causal estimates are unbiased. The Stable Unit Treatment Value Assumption (SUTVA) is necessary for this causal model; it implies that the treatment status of any unit does not affect the potential outcomes of the other units (i.e., no user interference). Also, the user indicator events are modeled to be random and conditionally independent among users given a predetermined probability.</p><p>Principal Stratification modeling provides a framework to estimate treatment effects conditional on posttreatment (nonignorable) variables, which might be affected by the treatment <ref type="bibr" target="#b8">(Frangakis and Rubin 2002)</ref>.</p><p>The key element in this context is identification of user classes, or strata, with equal treatment effects and probability of treatment assignment. Given the proposed randomized design in Figure <ref type="figure">3</ref>(c), where Z i ∈ Control Study = C S , user exposure to the ad is a post-treatment variable. Here, the exposure selection process is performed in the study group and not performed in the control group. <ref type="bibr">7</ref> Let W i Z i indicate if the ad is shown to the user (W i = 1) or not (W i = 0) under treatment Z i . To define the principal strata, we model the potential outcomes for W i Z i Z i ∈ C S . Because the ad is never shown to the users of the control group W i C = 0 , we define the user principal strata, W P i , as follows:</p><formula xml:id="formula_9">W P i = W i C ∈ 0 W i S ∈ 0 1 = 0 0 0 1 D i = 0 if W P i = 0 0 1 if W P i = 0 1 (4)</formula><p>Table <ref type="table" target="#tab_6">3</ref> shows the observed and missed data in the potential outcomes notation. This definition guarantees </p><formula xml:id="formula_10">W i C Y i C W i S Y i S assignment Z i W i C W i S D i N 0 0 1 C 0 0 * * C (0 * ) * N 1 0 1 C 0 1 * * C (0 * ) * N 0 0S 0 * 0 0 S (0 0) 0 N 1 0S 0 * 0 1 S (0 0) 0 N 0 1S 0 * 1 0 S (0 1) 1 N 1 1S 0 * 1 1 S (0 1) 1</formula><p>Notes. N y dz , where that the selection effect in the control group is the same as that of the study group (Assumption 1). In the definition of Equation ( <ref type="formula">4</ref>), D i indicates whether the user is exposed to the ad had the user been assigned to the study group (exposed-if-assigned, D i = 1), or not (never-exposed, D i = 0). Consequently, we do not observe D i in the control group (Figure <ref type="figure">4</ref>(a)).</p><formula xml:id="formula_11">D i = d, Z i = z, Y i = y ,</formula><p>We define the probability of D i to be Bernoulli distributed with parameter p sel , and the probability of user conversion Y i to be Bernoulli distributed with parameters dz for the four combinations</p><formula xml:id="formula_12">D i = d, Z i = z, and Y = Y i , Z = Z i , D = D i .</formula><p>Let the user selection for ad exposure indicator for those assigned to the control arm be D C i and for those assigned to the study arm be D S i . Therefore, assuming = dz p sel d ∈ 0 1 z ∈ C S are random variables, we have</p><formula xml:id="formula_13">P Y Z D = P Z i=1 P D i = d p sel • P Y i Z i D i = d Z i = z dz P Z i = z (5)</formula><p>One concern with the model described by Equation ( <ref type="formula">5</ref>) is that distribution parameters 0C 1C are not identifiable. That is, for given values of 0C and 1C , the same likelihood value (P Y Z D ) is produced if we switch these parameter values. Thus, we require a constraint based on identifiable parameters 0S 1S to guarantee a unique solution. By Assumption 2, the treatment assignment is independent of the potential outcomes of never-selected users Y i ⊥ Z i D i = 0 . Therefore, we do not consider any campaign effect on this subpopulation as depicted in Figure <ref type="figure">4</ref>(b) leading to:</p><formula xml:id="formula_14">0S = 0C = 0 ⇒ = 0 1C 1S p sel .</formula><p>Note also that, in a sequential setting, the targeting engine uses user conversion probability estimates to determine the selection probability of the next visiting user. However, based on SUTVA and conditionally independent user conversions of each other given a predetermined probability, the user selection for ad exposure indicators D i ; for all i are conditionally </p><formula xml:id="formula_15">Z i = C Study: Z i = S Selected D i = 1 (a) (b) Nonselected D i = 0 Control: Z i = C Study: Z i = S D i S = 1, Z i = S D i C = 1, Z i = C D i S = 1, Z i = S D i S = 0, Z i = S Z i = C D i C ∈ {0, 1} D i {C, S} = 0, Z i ∈ {C, S}</formula><p>Notes. (a) Observed segments. (b) Idealized segments to estimate the campaign effects on the selected users for ad exposure.</p><p>independent from each other, given p sel . As a result, p sel represents the aggregate selection probability during the time of the analysis.</p><p>Algorithm 1 (Gibbs sampling algorithm based on the joint distribution of Equation ( <ref type="formula">5</ref>)) 1: Input:</p><formula xml:id="formula_16">N obs = N y dS N y 0 1 C d ∈ 0 1 y ∈ 0 1 from Table 3 2: Define N samp = N y dC d ∈ 0 1 y ∈ 0 1 3: Set a 0 = 0 5, b 0 = 0 5 4: Initial guess 0 = 1z 0 p sel 0 , z ∈ C S 5: for i ← 1 to N burnin + N s do 6: Set P D Cy i = 1 N obs = p sel 1C y 1 − 1C 1−y p sel 1C y 1 − 1C 1−y + 1 − p sel 0 y 1 − 0 1−y , y ∈ 0 1 7: Draw N y 1C N obs ∼ Binomial N y 0 1 C , P D Cy i = 1 N obs , y ∈ 0 1 8: Set N y 0C = N y 0 1 C − N y 1C , y ∈ 0 1 9: Draw i 1z − 1z N samp N obs ∼ Beta a 0 + N 1 1z , b 0 + N 0 1z ), z ∈ C S 10: Draw i 0 − 0 N samp N obs ∼ Beta a 0 + N 1 0C + N 1 0S , b 0 + N 0 0C + N 0 0S , 11: Draw p i sel −p sel N samp N obs ∼ Beta a 0 + z∈ C S y∈ 0 1 N y 1z b 0 + z∈ C S y∈ 0 1 N y 0z 12: end for 13: return N burnin +1 N burnin +N s</formula><p>The inference objective of the joint distribution of Equation ( <ref type="formula">5</ref>) is to estimate the posterior distribution of the parameters given the observed data from Table <ref type="table" target="#tab_6">3</ref>. Estimating this posterior distribution in closed form is intractable because D C must be observed. Thus, we implement a Markov Chain Monte Carlo (MCMC)based approach using Gibbs sampling depicted by Algorithm 1. We denote the set of observed counts as N obs (step 1). Given an initial guess for 0 (step 4), we sample D C and estimate the counts</p><formula xml:id="formula_17">N y dC ; d ∈ 0 1 , y ∈ 0 1 based on the probability of D Cy i (steps 6-8).</formula><p>We denote these sampled counts as N samp = N y dC d ∈ 0 1 y ∈ 0 1 (step 2). Given the augmented user counts, N obs N samp , we sample each parameter of conditional on − , which is the set without (steps 9-11). The sampling distributions of the parameters 0 1C 1S p sel , are Beta(a 0 b 0 ) distributions with Jeffreys conjugate prior parameters, a 0 = 0 5 b 0 = 0 5 (step 3). We test other prior parameters in Appendix C. This sampling process is repeated for N burnin + N s times (steps 5-12). After discarding a set of burn-in samples, N burnin , a set of samples of the posterior distribution is obtained, 1 N samples . These samples are used to estimate the variability of the effects and the analysis of § §3.2 and 3.3.</p><p>Remark 4. We use the randomization power to estimate the conversion probability of the statistically equivalent users in the control group to those exposed to the ad in the study group. We leverage the fact that there is no campaign effect on the nonselected users. Also, the proportion of users statistically equivalent to those selected in the study group must be the same in both treatment groups. Therefore, the proposed model guarantees that the conversion probabilities are balanced for control and study arms. 8</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Campaign Effect Estimation</head><p>We estimate the average treatment effect by the campaign (ATE Camp ) on the overall visiting users and the lift (lift Camp ) as follows:</p><formula xml:id="formula_18">ATE Camp = E Y i S Z i = S − E Y i C Z i = C lift Camp = ATE Camp E Y i C Z i = C (6)</formula><p>Assuming a Jeffreys conjugate prior distribution, a 0 = 0 5 b 0 = 0 5 , the posterior distribution becomes Beta(a 0 + N 1 z b 0 + N 0 z ) where N 1 z N 0 z are the number of converting and nonconverting users of the z group. We sample from these posterior distributions to provide credible intervals for both ATE Camp and lift Camp .</p><p>The campaign average treatment effect on the users selected for ad exposure (ATE D=1</p><p>Camp ), and the lift (lift D=1 Camp ) are estimated from the posterior distribution of as follows: </p><formula xml:id="formula_19">ATE D=1 Camp = E Y i S D i = 1 Z i = S − E Y i C D i = 1 Z i = C ATE D=1 Camp = 1S − 1C lift D=1 Camp = 1S − 1C / 1C<label>(</label></formula><p>Camp )</p><formula xml:id="formula_21">ATRB Camp = ATE Camp × d∈ 0 1 y∈ 0 1 N y dS N 1 0S + N 1 1S (<label>8</label></formula><formula xml:id="formula_22">)</formula><formula xml:id="formula_23">ATRB D=1 Camp = ATE D=1 Camp × N 0 1S + N 1 1S N 1 0S + N 1 1S</formula><p>Given that only the users exposed to the ad are impacted by the campaign, these metrics must match. They represent the campaign value (causally generated conversions) and the output of the measurement block shown in Figure <ref type="figure" target="#fig_1">1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">User Selection Characterization</head><p>To characterize user selection for ad exposure of converting users performed by the targeting engine, we estimate the user selection effect (SelEff) and the lift (lift sel ) as follows:</p><formula xml:id="formula_24">SelEff = E Y i C D i = 1 Z i = C − E Y i C D i = 0 Z i = C SelEff = 1C − 0 lift sel = 1C − 0 / 0 (9)</formula><p>Note that selecting converting users, whose performance is measured by SelEff, is a common objective of the targeting engine <ref type="bibr" target="#b20">(Pandey et al. 2011</ref>) because of the industry business model for CPA campaigns, i.e., last-touch and multitouch attribution (Atlas Institute 2008). Thus, being part of a converting user path is enough to attribute credit to the campaign.</p><p>To characterize the causal user selection process, we partition the users into four influenceable categories <ref type="bibr" target="#b5">(Chickering and Heckerman 2000)</ref>, U i as follows: Per + , positively influenced user, persuadable; Per − , negatively influenced user, anti-persuadable; AB, converting user with no effect, always-buy; NB, nonconverting user with no effect, never-buy. Given the selection for ad exposure indicator D i , the probability of a category U i is defined as</p><formula xml:id="formula_25">P U i = Per + D i ∝ P Y i S = 1 D i Z i = S •P Y i C = 0 D i Z i = C P U i = Per − D i ∝ P Y i S = 0 D i Z i = S •P Y i C = 1 D i Z i = C P U i = AB D i ∝ P Y i S = 1 D i Z i = S •P Y i C = 1 D i Z i = C P U i = NB D i ∝ P Y i S = 0 D i Z i = S •P Y i C = 0 D i Z i = C (10)</formula><p>We estimate the probability of selecting a user given U i by Bayes theorem as follows: 9</p><formula xml:id="formula_26">P D i = 1 U i = P D i = 1 P U i D i = 1 d∈ 0 1 P D i = d P U i D i = d P Y i Z i = y Z i D i = y dz 1 − dz 1−y P D i = d = p d sel 1 − p sel 1−d (11)</formula><p>Remark 5. We estimate the probabilities of persuadable, anti-persuadable, always-buy, and never-buy user categories, despite not using user features because we observe the counterfactual user response in both control and study treatment groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results</head><p>In this section, we discuss data collection and processing. We also validate the model assumptions based on user randomization. Then, we present the analysis of two CPA campaigns (Figure <ref type="figure">3</ref>(c) design), 10 and one CPM campaign where placebo ads were displayed (Figure <ref type="figure">3</ref>(d) design). Finally, we analyze the selection for ad exposure policy for these campaigns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Data Collection and Description</head><p>We ran two large scale randomized (or field) experiments (Figure <ref type="figure">3</ref>(c) design) collaboratively with two European advertisers in the mobile communications and the public transportation service sectors. The user selection for ad exposure was optimized in real time by a sophisticated targeting engine that valued the user and managed the bidding process for both CPA campaigns. User conversions were economically equivalent for both campaigns. For privacy reasons, we are not allowed to disclose the ad content or the identity of the advertiser. <ref type="bibr">9</ref> The campaign effect is not considered for the nonselected users, thus P U i =Per +</p><formula xml:id="formula_27">i D i = 0 =P U i = Per − i D i = 0 .</formula><p>10 We present a power analysis of the campaign effect estimation in Appendix D, which illustrates the difficulty in measuring this effect in Targeted Advertising even when tens of millions of users are part of the experiment.   We randomly assigned the visiting users using the last two digits of the time their cookies were created. This rule separated the users and kept them in their assigned group while the campaign was active. To avoid user contamination and guarantee that we do not miss user tracking due to cookie deletion, we only consider users whose cookies were born before the campaign started and remained active in the ad network. <ref type="bibr">11</ref> Given a user timeline of events, we focus on those events recorded after the first visit to any publisher website where the ad was potentially displayed. We mark the user as selected and exposed in the study group (Z i = S W i = 1 D i = 1) if at least one ad exposure was recorded (otherwise W i = 0 D i = 0). If one conversion was recorded after at least one ad exposure and before the campaign ended, the user is considered to be selected and a converter (</p><formula xml:id="formula_28">Count N 0 0 1 C N 1 0 1 C N 0 0S N 1 0S N 0 1S N 1 1S Campaign 1 1,</formula><formula xml:id="formula_29">W i = 1 D i = 1 Y i = 1).</formula><p>No ad exposure was performed for the users in the control group (Z i = C W i = 0). Thus, the user selection indicator is missing in this group (D i = * ). User counts based on the notation in Table <ref type="table" target="#tab_6">3</ref> are displayed in Table <ref type="table" target="#tab_10">4</ref>; Table <ref type="table" target="#tab_12">5</ref> shows user activity statistics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Estimation Model Validation</head><p>The estimation approach in §3.1 relies on equal probabilities of selection for both treatment groups, and the condition of no campaign effects on the nonselected users for ad exposure (Figure <ref type="figure">4</ref>(b)). To test these conditions, we randomly partition the users of the study group of the CPA campaigns (Table <ref type="table" target="#tab_10">4</ref>) into simulated control (Z i = C) and study (Z i = S) groups, where D C i and D S i are observed. We define p sel z to be the selection for ad exposure probability, p sel , for the z random group. We perform this partition 3,000 times, obtain the method-of-moments (MM) estimate for p s sel z s 0z independently of our proposed model, and calculate the empirical distribution of:</p><formula xml:id="formula_30">s psel = p s sel S − p s sel C s 0 = s 0S − s 0C .</formula><p>Zero values for psel and 0 verify the conditions of the model (Assumptions 1 and 2). Table <ref type="table" target="#tab_14">6</ref> reports the credible intervals for these statistics and shows that they are centered at 0 for both campaigns. Therefore, we conclude that p sel is the same for both treatment arms, and that no campaign effect is present in the nonselected users. 12</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Campaign Effect Results</head><p>Figure <ref type="figure">5</ref> depicts the estimation results for the CPA campaigns shown in Table <ref type="table" target="#tab_10">4</ref>. Here, we use N burnin = 2 000 burn-in iterations and N s = 10 000 samples for the Gibbs sampling framework of Algorithm 1. As illustrated, the posterior distribution for lift <ref type="bibr">D=1</ref> Camp is skewed because lift D=1</p><p>Camp is a ratio of random variables. The posterior distributions for 0 1C 1S are illustrated by the box plots in Figures <ref type="figure">5(a</ref>) and 5(b). A significant difference is evident between the conversion rates for the selected for ad exposure 1C 1S and the nonselected ( 0 ) groups, which is measured by SelEff and lift sel of Equation ( <ref type="formula">9</ref>). As indicated by Table <ref type="table" target="#tab_16">7</ref>, we obtain a median lift sel = 89% 444% for Campaign 1 and 2, respectively.</p><p>For comparison, we estimate the campaign effect on the selected users by assuming that we do not observe the control group response, ATE <ref type="table" target="#tab_4">I2C</ref> Camp . This naïve estimation is used by last-touch (I2C: impression-toconversion) or multitouch attribution when only the focal campaign is run (i.e., single channel). Similarly, we estimate the campaign effect without correcting for post-treatment bias, ATE post Camp . These effects are defined as follows:</p><formula xml:id="formula_31">ATE I2C Camp = E Y i W i S = 1 Z i = S − E Y i W i S = 0 Z i = S ATE post Camp = E Y i W i S = 1 Z i = S − E Y i W i C = 0 Z i = C (12)</formula><p>Table <ref type="table" target="#tab_16">7</ref> shows the campaign effects on the overall user population, ATE Camp , and on the selected for ad exposure population, ATE D=1</p><p>Camp . Here, the zero effect is not included in the 90% credible intervals for Campaign 1. Campaign 2 leans toward positive values but with a small negative range in the credible interval. In addition, we observe variations of less than 0.2% between median ATRB D=1</p><p>Camp and ATRB Camp : 9 05% 8 90% for Campaign 1 and 5 05% 4 91% for Campaign 2, respectively. This result shows consistency between ATE D=1</p><p>Camp and ATE Camp , and confirms the campaign effect analysis of §2.3. Note the severe overestimation by last-touch attribution, and by the effect without correcting for post-treatment bias compared with the causal lift (lift I2C</p><p>Camp and lift post Camp versus lift D=1 Camp );  Notes. Mean and standard deviation (St dev) are displayed. Visits/user is the number of visits per user. Convs Y i = 1 is the number of conversions per converting user. Imps/user is the number of ad exposures per selected user (D i = 1). that is, for Campaign 1: 129% and 77.54% versus 21.04%; for Campaign 2: 511% and 296% versus 12.36%. 13</p><formula xml:id="formula_32">Z i = C Z i = S Z i = S, D i = 1 Z i = C Z i = S Z i = S, D i = 1</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Comparison with Campaign Evaluation Using Placebo Ads</head><p>To illustrate the effect of campaign presence in the marketplace and the risk of conditioning the ad effect on post-treatment (endogenous) variables, we ran a large scale experiment considering three treatment groups, Z i ∈ Control Placebo Study = C P S (Figure <ref type="figure">3</ref>(d) design), collaboratively with an advertiser in the financial information services sector. We implemented the standard practice to evaluate online campaigns and ran a low-budget CPM campaign, where user conversions are economically equivalent, without optimizing the ad delivery process. Consequently, the decision to bid was always affirmative (Figure <ref type="figure">2</ref>(a): B i = Yes), and the auction was run for all visiting users to satisfy the budget contractual schedule. This auction took place inside the ad network where simultaneous campaigns of the same brand were run to market other products, among other competing campaigns. Table <ref type="table" target="#tab_17">8</ref> shows the aggregated data (Campaign 3) based on the notation in Table <ref type="table" target="#tab_6">3</ref>, and Table <ref type="table" target="#tab_19">9</ref> shows user activity statistics. To verify that there was no selection effect, we now test Assumptions 1 and 2.</p><p>Define the selection indicator D i under the treatments, Z i = P S , to be D P i D S i . To estimate the ad effect conditional on the observed D z i , we define select i and convert i  <ref type="table" target="#tab_1">Campaign 1: 1 73 1 99 2 24 , Campaign 2: 7 39 7 76 8 13</ref> </p><formula xml:id="formula_33">as select i = P D S i = 1 Z i = S − P D P i = 1 Z i = P</formula><formula xml:id="formula_34">. convert i = P Y i S = 1 D S i = 0 Z i = S (13) − P Y i P = 1 D P i = 0 Z i = P</formula><p>Then, we define the hypotheses:</p><formula xml:id="formula_35">H select 0 select i = 0, H convert 0 convert i = 0.</formula><p>We test these hypotheses, and estimate their lifts ( select i Lift, convert i Lift) by sampling the Beta distribution as in the case of the lift Camp estimation in §3.2. <ref type="bibr">14</ref> The testing results in Table <ref type="table" target="#tab_1">10</ref> suggest rejecting</p><formula xml:id="formula_36">H select 0 ( select i Lift = −2 84% −2 75% −2 65% ), and not rejecting H convert 0 ( convert i Lift = −2 80% 4 12% 11 41% ).</formula><p>As a result, the change of user selection probability is not enough to reject the assumption that the sampled placebo and campaign populations are equivalent in conversion rates. <ref type="bibr">15</ref> We estimate the lift effect of the ad ACL Ad , based on ATE Ad from Equation (1), which is the standard "campaign" attributed effect. We obtain a positively leaning effect (ACL Ad = −2 78% 6 74% 17 97% ). We analyze §3.1 to calculate</p><formula xml:id="formula_37">E Y i C D i = 1 Z i = C =</formula><p>1C , and estimate ATE Market lift, ACL Market , based on Equation (1). We estimate a negative effect of the campaign presence in the marketplace and discard the zero effect of the 90% credible interval (ACL Market = −24 02% −15 06% −3 70% ). We know that the focal campaign competed in the marketplace against campaigns run to advertise other products of the same brand. We also know that the product being promoted is a free trial of one of the other products. As a result, we expect significant spillover effects from other brand campaigns. In this  Note. Low Med High are the 0 05 0 5 0 95 quantiles.    Notes. Mean and standard deviation (St dev) are displayed. Visits/user is the number of visits per user. Convs Y i = 1 is the number of conversions per converting user. Imps/user is the number of ad exposures per selected user (D i = 1). scenario, other campaigns generate the user visit (lead) to the advertiser website, where the users are more likely to sign up for a free trial product than for the promoted paid service. Therefore, the mere presence of the focal campaign prevented the other ads of the same brand from being displayed. This strategic effect significantly moves the net campaign effect (lift D=1 Camp = −18 88% −9 15% 2 62% ). Similar spillovers across product campaigns have been detected before by <ref type="bibr" target="#b22">Sahni et al. (2015)</ref> in the context of email coupon promotions. Note that the user selection effect of this CPM campaign significantly contributes to the negative presence effect. However, this user selection can be improved to identify the positively influenceable population.</p><formula xml:id="formula_38">Count N 0 0 1 C N 1 0 1 C N 0 0P N 1 0P N 0 1P N 1 1P N 0 0S N 1 0S N 0 1S N 1 1S</formula><formula xml:id="formula_39">Z i = C Z i = P Z i = S Z i = P D i = 1 Z i = S D i =</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">User Selection Characterization Results</head><p>Table <ref type="table" target="#tab_1">11</ref> shows the user selection characterization results, based on the analysis of §3.3, for CPA Campaigns 1 and 2 in Table <ref type="table" target="#tab_10">4</ref>, and for CPM Campaign 3 in Table <ref type="table" target="#tab_17">8</ref>. The probability of never-buy users is large in the selected population (P U i = NB D i = 1 &gt; 0 99 for all campaigns); this is a consequence of low conversion rates. Using Bayes theorem as in Equation ( <ref type="formula">11</ref>), we observe that the probability of selecting a never-buy user is the lowest as there is no incentive to display the ad to this user category (P D i = 1 U i = NB = 0 32 0 12 0 27 for Campaign 1 2 3 , respectively). Similarly, the probability of selecting a persuadable user is significantly lower for CPM Campaign 3 than for CPA Campaigns 1 and 2 by as much as 37% (0 52 − 0 33 = 0 19 with respect to 0 52, where P D i = 1 U i = Per + = 0 52 0 46 0 33 for campaigns 1 2 3 , respectively), showing the positive effect of optimized user selection of ad exposure.</p><p>As discussed in §3.3, lift sel provides the conversion probability change in the selected population (i.e., selection effect). The CPA last-touch business model suggests that increasing this difference is beneficial for the overall campaign effect. We find that Campaign 2 performance (lift sel = 444%) is superior to Campaign 1 (lift sel = 89%) under the CPA policy of selecting converting users. However, we estimate a significantly larger probability of selecting an always-buy user for Campaign 2 than for Campaign 1 (P D i = 1 U i = AB = 0 82 0 67 for campaigns 1 2 , respectively). Therefore, although Campaign 2 is more useful in optimizing user conversions than Campaign 1 by a factor of five (444% vs. 89%), Campaign 2 is 22% (0 82 − 0 67 = 0 15 with respect to 0.67) and more likely to select alwaysbuy users. This analysis shows that the well accepted policy of selecting users with the highest conversion probability does not necessarily improve the campaign value to the advertiser. Moreover, we find that this probability of selecting always-buy users is as much as 96% larger for CPA Campaign 2 when compared to CPM Campaign 3 (0 82 − 0 418 = 0 402 with respect to 0 418). This evidence shows that CPA campaigns incentivize the selection for ad exposure of always-buy users when compared with CPM campaigns <ref type="bibr" target="#b2">(Berman 2015)</ref>. Also, the generalization of the ad effect estimated for a CPM campaign to a CPA campaign, assumed under the standard evaluation practice, is highly prone to inaccuracies.</p><p>By analyzing the marginal probabilities P U i , we note that the population size of always-buy users is three to four orders of magnitude smaller than the size of the persuadable and anti-persuadable user segments. As a result, the impact of a large P D i = 1 U i = AB is attenuated by the visiting population size of always-buy users.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Campaign Mid-Flight Optimization:</head><p>Leveraging User Features</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Methodology</head><p>We illustrate the value of continuing evaluation in the context of Figure <ref type="figure" target="#fig_1">1</ref> by leveraging user features (X i ) in the effect estimation. We develop user selection rules to achieve mid-flight campaign optimization. Here, we replace the Bernoulli distributions in Equation ( <ref type="formula">5</ref>) with probit regressions conditional on X i . Thus, we estimate the campaign effects conditional on X i to guide the targeting engine. Let x be the standard Normal cumulative density function, X = X i , and</p><formula xml:id="formula_40">X = 0 1C 1S sel , then P Y Z D X X = P X Z i=1 P D i = d sel X i • P Y i Z i D i = d Z i = z dz X i P Z i = z P D i sel X i = i i = X i sel P Y i D i Z i dz X i = dz i dz i = X i dz (14)</formula><p>This model exploits the power of randomization and balances the treatment groups in the inference of the indicator D C i X i based on the propensity of being selected. <ref type="bibr">16</ref> We find the user counts of Control and Study treatment arms (Table <ref type="table" target="#tab_6">3</ref>) for all user feature combination segments, which are assumed to be finite and countable</p><formula xml:id="formula_41">N obs Camp = N y dS X i N y 0 1 S X i d ∈ 0 1 y ∈ 0 1 X i ∈ X (15)</formula><p>whose cardinality becomes # N obs Camp = 6 × # X . To estimate the model described by Equation ( <ref type="formula">14</ref>  </p><formula xml:id="formula_42">P U i = Per + D i = 1 4 55e−4 1 04e−3 1 68e−4 P U i = Per + 2 81e−4 2 75e−4 1 37e−4 P U i = Per − D i = 1 3 76e−4 9 24e−4 1 85e−4 P U i = Per − 2 56e−4 2 62e−4 1 41e−4 P U i = AB D i = 1</formula><p>1 71e−7 9 59e−7 3 11e−8 P U i = AB 8 19e−8 1 42e−7 1 98e−8 P U i = NB D i = 1 0 9992 0 9980 0 9996 P U i = NB 0 9995 0 9995 0 9997</p><formula xml:id="formula_43">P D i = 1 U i = Per + 0 5211 0 4583 0 3276 P D i = 1 U i = AB 0 6728 0 8217 0 4180 P D i = 1 U i = Per − 0 4732 0 4296 0 3497 P D i = 1 U i = NB 0 3221 0 1215 0 2669</formula><p>Note. Campaigns 1 and 2 are CPA (optimized selection for ad exposure), and Campaign 3 is CPM (nonoptimized selection for ad exposure).</p><p>propose a variant of the Gibbs sampling of Algorithm 1, depicted by Algorithm 2 and detailed in Appendix E. We calculate posterior credible intervals of the effect estimates based on the set of Gibbs samples returned by Algorithm 2, 1 N s X .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">User Selection Optimization Results</head><p>We leverage demographic user features to optimize user selection for ad exposure mid-flight, i.e., in the middle of the campaign. For visiting users of CPM Campaign 3, we know the gender, age, and income. These features are segmented by ranges to make them finite and countable (e.g., Male, 35-44 years old, 50,000-75,000 income). We partition the campaign data in duration by half and train the model in Equation ( <ref type="formula">14</ref>) using Algorithm 2 for the first half. During the second half of the campaign, we test different user selection policies based on user response categories from Equation (10) for each user segment X i .</p><p>To simulate a given selection policy, we execute Algorithm 3, which requires: (1) a selection function F sel X i ; (2) a non-zero effect indicator function F sig X i , and (3) ATE D=1</p><p>Camp sign function F ATE sign X i . We discuss this simulation in detail in Appendix F. Given the posterior samples (</p><formula xml:id="formula_44">N burnin +1 N burnin +N s X</formula><p>), we estimate the median probability of influenceable user categories (P U i D i = 1 X i ) in the ad-exposured population. We avoid classifying the users into these categories because this approach requires a set of fine-tuned thresholds. We choose F sel X i as the ratio of probabilities of desirable over nondesirable classes as indicated in Table <ref type="table" target="#tab_1">12</ref>. We define F sig X i as the inclusion (F sig X i = true) or noninclusion (F sig X i = false) of the zero ATE D=1 Camp X i effect in the 90% credible intervals. Similarly, we set F ATE sign X i as the sign of ATE D=1 Camp X i . The intuition behind these functions is to incorporate the degree of uncertainty of the estimated average campaign effects for each user segment. We fix w sig = w − w ± w + to be a set of certainty weights. These weights are chosen based on whether median ATE D=1</p><p>Camp X i is positive or negative and whether a zero effect lies outside or inside the credible interval. This process generates the count set in Table <ref type="table" target="#tab_6">3</ref>, which we use to run Algorithm 1 to estimate lift D=1 Ad (Equation ( <ref type="formula">7</ref>)).</p><p>Table <ref type="table" target="#tab_1">12</ref> shows the results of testing four selection policies. Our benchmark is the optimization of conversion probability ((d) Y = 1 vs. Y = 0, w sig = 1 1 1 ). This selection policy is the standard industry practice given observational data. Results show that this practice is reasonably effective compared with other policies <ref type="bibr">((d) 11.72% versus (b)</ref> 11.93% or (a) 9.86% average lift D=1 Camp ). <ref type="bibr">17</ref> However, the highest performance is achieved when we optimize (c) Per + versus ¬Per + given w sig = 1 1 1 (14.28% lift D=1</p><p>Camp ). Note that user selection of the current CPM campaign is exploratory; consequently the selection effect is significantly smaller than the one for CPA campaigns. Hence, the performance of the standard practice (d) is likely to be inferior to the one we report when CPA campaign data is used to fit the prediction model. We test three weighting frameworks based on the 90% credible intervals of ATE D=1</p><p>Camp X i . Intuition suggests that eliminating segments with negative-only intervals and boosting segments with positive-only intervals would dramatically increase the performance. However, we find that a modest decrease of negative-only and an increase of positive-only segment intervals are more effective. We find that w sig = 0 8 1 1 1 shows the highest performance of the weighting frameworks we test ((c) 14.89% average lift D=1 Camp ). Optimizing w sig represents a line for further research.</p><p>The current analysis demonstrates the value of the experimental design and the effect estimation to optimize the user selection in Figure <ref type="figure" target="#fig_1">1</ref>. Limitations of this study include: the quality of the cookie-based user features, the percentage of users with missing features estimated to be at 75%, and the assumptions of the selection policy simulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion and Managerial Implications</head><p>We have shown that evaluating an online advertising campaign involves more than evaluating just the ad.</p><p>17 Credible intervals are in the range of ±20% for all selection functions evaluated. The short evaluation time, seven days, and the observed budget, which is kept constant in the simulation, are among the reasons. w sig = 1 1 1 w sig = 0 6 1 1 1 w sig = 0 8 1 1 2 w sig = 0 8 1 1 1 (a) </p><formula xml:id="formula_45">P U i = Per + D i = 1 X i P U i = Per − D i = 1 X i 9</formula><formula xml:id="formula_46">P U i = Per + D i = 1 X i P U i = Per − ∪ AB D i = 1 X i 11 93</formula><p>10 80 12 52 12 63 (c)</p><formula xml:id="formula_47">P U i = Per + D i = 1 X i 1 − P U i = Per + D i = 1 X i 14 28</formula><p>13 40 14 74 14 89 Marketplace interactions imply that the final decision to display the campaign/placebo ad is not entirely controllable (i.e., endogenous) in the randomized experiment. We have discussed ( §2.3) and demonstrated this endogeneity with the evaluation of a campaign using placebo ads in §4.4. We do not expect that an ad tested in a controlled environment, as assumed by the exploratory evaluation of CPM campaigns, will yield the same performance in a real marketplace. As demonstrated in §2.3 and supported with the results in §4.4, the effects of being in the marketplace are ineluctable if the ad is to be displayed. Consequently, the right placebo is the complete absence of the campaign. Given the difficulty of predicting the ad effect in marketplaces, the most suitable approach is to assign credit to the overall campaign for the time it is run and rely on short-term effect predictions. Therefore, the randomized experiment and the effect estimation together become a measuring tool. Further research involves determining the optimal time span of these effect predictions. We have illustrated how the strategic campaign presence effect reveals other competing campaigns effects on the focal brand sales. We have analyzed a particular instance where the standing brand campaigns are more beneficial than the new focal campaign. These potentially significant spillover effects provide evidence to determine the right strategic settings to run the campaign. These settings include moderating campaign interactions, adjusting the user reach of the focal campaign, and defining the user selection policy. Explicitly accounting for competitors ad exposures is a further line of research.</p><formula xml:id="formula_48">(d) P Y i = 1 D i = 1 Z i = S X i P Y i = 0 D i = 1 Z i = S X</formula><p>By characterizing the user population selected for ad exposure in the CPM and CPA campaigns in §4.5, we have demonstrated that the purported external validity of ad effects tested under CPM selection policy to CPA selection may be invalid. In CPA campaigns, the decision to select users for ad exposure is often driven by the user propensity to convert. As a result, we have found evidence that CPA campaigns incentivize the selection of users who would buy in any case. Selecting these noninfluenceable users does not add any value to the advertiser. We note that ad networks obtain revenue based on user conversions, as in the case of Last-Touch or Multitouch Attribution. On the other hand, purely nonoptimized CPM campaigns are less effective than CPA campaigns in selecting users with positive effect. The current results provide a potential opportunity for advertisers to act on and improve the user selection policy to improve causal estimates.</p><p>We have demonstrated the value of characterizing the user selection for ad exposure, and the leverage of user features to improve this selection. In a measurementoptimization cycle, the proposed randomized design may enable the transfer of learning from attribution to user targeting and ex-ante optimization. However, the dynamic campaign effects must be analyzed and understood to achieve an effective fast in-flight campaign optimization. Overall, this assessment takes us a step closer to a commercially valuable use of the experimental data in the user targeting and bidding processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental Material</head><p>Supplemental material to this paper is available at http://dx .doi.org/10.1287/mksc.2016.0982.</p><p>Given the Bayesian method from §3, we analyze the effect of different Beta prior parameters and compare them with a method of moments that is derived now. Since D i is observed for the study group, the estimation of p sel and 1S in the study group is straightforward based on the method of moments. Similarly, 0 is approximated using the observed conversions of the nonselected users for ad exposure in the study group. As the observed conversion probability of the control group is a mixture of 0 and 1C weighted by 1 − p sel and p sel , respectively, and 0 p sel are shared by both arms (approximation), the estimation of 1C becomeŝ</p><formula xml:id="formula_49">p sel = N 1 1S + N 0 1S N 1 1S + N 0 1S + N 1 0S + N 0 0S ˆ 1S = N 1 1S N 1 1S + N 0 1S ˆ 0 = N 1 0S N 1 0S + N 0 0S ˆ 1C = 1 p sel N 1 0 1 C N 1 0 1 C + N 0 0 1 C −ˆ 0 1 −p sel (C1)</formula><p>This approach does not account for the data sample size and requires several approximations. Despite these limitations, we provide a robustness check based on this estimator. Table <ref type="table">C</ref>.1 compares this point estimator with the Bayesian method from §3 for different prior rates: a 0 / a 0 + b 0 ; assuming a prior sample size: a 0 + b 0 = 1. Results show that more intuitive prior rate choices for low conversion rates 0 01 0 001 do not affect results more than 0.9% in median lift D=1 Camp and its credible interval. We use the Jeffreys prior a 0 = 0 5 b 0 = 0 5 because increasingly skewed prior distributions are more likely to be numerically unstable in the Gibbs sampling. The method of moments of Equation (C1) shows discrepancies of less than 1% lift D=1</p><p>Camp when compared with this prior choice. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix D. Estimation Power Analysis</head><p>We have observed in major firms that the proportion of users used as a control group is intuitively determined based on the belief that large user populations are readily available. However, in the targeted advertising framework we study in this paper, poorly designed experiments lead to wide credible intervals containing the zero effect. Given the parameter values in Figure D.1, we estimate lift D=1</p><p>Camp as a function of the total user population, the user selection probability p sel , and a set of true lift D=1</p><p>Camp values. We generate the counts in Table <ref type="table" target="#tab_6">3</ref> assuming that the point estimate from Equation (C1) is perfect. Given these count sets, we fit the model using the Bayesian approach from §3. Figure D.1(a) shows that even when the user population is 40 million, the credible interval includes zero for all of the randomized designs analyzed, P Z i = S = 0 95 0 92 0 89 0 86 . If we naïvely set 5% of Algorithm 2 (Gibbs sampling algorithm based on the joint distribution of Equation ( <ref type="formula">14</ref>)) 1: Input:</p><formula xml:id="formula_50">N obs X i = N y dS X i N y 0 1 S X i d ∈ 0 1 y ∈ 0 1 from Table 3, X i ∈ X 2: Define N samp X i = N y dC X i d ∈ 0 1 y ∈ 0 1 X i ∈ X 3: Initial guess 0 X = 0 1z sel 0 , z ∈ C S 4: for i ← 1 to N burnin + N s do 5: Set P D i = d sel X i = i d 1 − i 1−d , i = X i sel , X i ∈ X 6: Set P Y i Z i = y D z i = d Z i = z dz X i = dz i y 1 − dz i 1−y , dz i = X i dz , X i ∈ X 7: Set P D Cy i = 1 X D s Y Z X i = P D i = 1 sel X i P Y i C = y D i = 1 Z i = C dz X i d∈ 0 1 P D i = d sel X i P Y i C = y D i = d Z i = C dz X i , X i ∈ X 8: Draw N y 1C X N obs X i ∼ Binomial N y 0 1 C X i P D Cy i = 1 N obs X i , y ∈ 0 1 , X i ∈ X 9: Set N y 0C X i = N y 0 1 C X i − N y 1C X i , y ∈ 0 1 , X i ∈ X 10: Set ˆ 1z ˆ 1z = glmfit N 1 1z X i N 0 1z X i X i ∈ X , z ∈ C S 11: Set ˆ 0 ˆ 0 = glmfit N 1 0C + N 1 0S X i N 0 1C + N 0 0S X i X i ∈ X 12: Set ˆ sel ˆ sel = glmfit z∈ C S y∈ 0 1 N y 1z X i z∈ C S y∈ 0 1 N y 0z Xi X i ∈ X 13: Draw i 1z X − 1z N samp N obs X ∼ MVN ˆ 1z ˆ 1z , z ∈ C S 14: Draw i 0 X − 0 N samp N obs X ∼ MVN ˆ 0 ˆ 0 15: Draw i sel X − sel N samp N obs X ∼ MVN ˆ sel ˆ sel 16: end for 17: return N burnin +1 N s X</formula><p>the users as the control group (P Z i = S = 0 95), a typical industry practice, the experiment will be useless. When the user selection probability is p sel = 0 4, we observe that the zero effect is discarded of the 90% credible interval when 11% (P Z i = S = 0 89) or higher user population is used as the control group, which is depicted by  Camp values as low as 6% are detected when 14% (P Z i = S = 0 86) of users are assigned to the control group. This analysis indicates the need to perform a similar analysis at the time of designing the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix E. Model Fitting Based on User Features</head><p>To estimate the model of Equation ( <ref type="formula">14</ref>), we provide a variant of the Gibbs sampling of Algorithm 1 depicted by Algorithm 2. We obtain the user counts in Table <ref type="table" target="#tab_6">3</ref> for all user feature combination segments, assumed to be finite and countable Marketing Science 35(3), pp. 465-483, © 2016 INFORMS (step 1: N obs X i X i ∈ X ; whose cardinality # N obs X i X i ∈ X = 6 × # X ). We sample the missing selection indicator, D C i X i X i ∈ X , following a similar logic to that of Algorithm 1 (steps: 5-9). We fit binomial probit regression functions based on these counts using a standard fitting function. We calculate the maximum-likelihood estimate (MLE) of the regression coefficients and its covariance matrix (steps 10-12: ˆ ˆ = glmfit N 1 X i N 0 X i X i ∈ X ). This fitting strategy avoids the fitting of probit regressions with millions of data points. Based on these estimates, the regression parameters are sampled from multivariate normal distributions (steps 13-15: MVN(ˆ ˆ )) by Laplace approximation <ref type="bibr" target="#b9">(Geisser et al. 1990</ref>). We use 1 N s X samples to generate credible intervals for the effect estimates conditional on user features X i .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix F. User Selection Response Simulation</head><p>Algorithm 3 (User selection response simulator for campaign effectiveness optimization) 1: Input: Selection function F sel X i , Non-zero Effect Indicator function F sig X i , ATE D=1 Camp Sign function F AT E sign X i , Sign Certainty weights w sig = w − w ± w + , User Counts N obs Camp as defined by Equation ( <ref type="formula">15</ref>). 2: // Set segment weighting function D sel w X i , based on inputs:</p><formula xml:id="formula_51">F sel X i , F sig X i , F AT E sign X i , w sig 3: Define D sel w X i =     </formula><p>w ± × F sel X i if F sig X i = false w + × F sel X i if F sig X i = true and F AT E sign X i = + w − × F sel X i if F sig X i = true and F AT E sign X i = − 4: Set N new S agg to the output of Algorithm 4 with inputs: </p><formula xml:id="formula_52">F sel X i = D sel w X i , N obs z = N obs S X i X i ∈ X //</formula><formula xml:id="formula_53">d ∈ 0 1 y ∈ 0 1 3: Set ˆ 0z ˆ 1z = glmfit N 1 0z X i N 0 0z X i X i ∈ X , glmfit N 1 1z X i N 0 1z X i X i ∈ X ] // Probit Approximation 4: Set ˆ 0z ˆ 1z X i = X iˆ 0z X iˆ 1z X i ∈ X // Observed Conversion Propensity 5: Set N Visit z X i = N 1 1z + N 0 1z + N 1 0z + N 0 0z X i X i ∈ X // Audience per Segment X i 6: Set N budget 1z = X i ∈ X N 1 1z + N 0 1z X i // Observed Budget 7: Set N 1 new 1z X i = N 0 new 1z X i = 0 X i ∈ X // Set Counts 8: Set N budget remain = N budget 1z</formula><p>// Initialize Remaining Budget 9: while N budget remain &gt; 0 do 10:</p><p>Set P X i = N Visit remain X i / X i ∈ X N Visit remain X i X i ∈ X 11: Set = N budget remain / X i ∈ X N budget remain × F sel X i × P X i X i // Budget Multiplier 12:</p><p>Set </p><formula xml:id="formula_54">N 1 new 1z N 0 new 1z X i = N 1 new 1z N 0 new 1z X i + min × F sel X i × N budget remain × P X i N Visit remain X i × ˆ 1z 1 −ˆ 1z X i X i ∈ X //</formula><formula xml:id="formula_55">X i = N Visit remain × ˆ 0z 1 −ˆ 0z X i , X i ∈ X // Nonselected User Counts 17: Set N new z agg = X i ∈ X N y new dz X i d ∈ 0 1 y ∈ 0 1 // Aggregate User Counts</formula><p>To simulate a given selection function, we execute Algorithm 3, which aggregates the user counts of the study group (Z i = S) given: (1) a selection function F sel X i ; (2) a non-zero effect indicator function F sig X i ; (3) ATE D=1</p><p>Camp sign function F AT E sign X i ; and (4) a sign certainty weighting set w sig = w − w ± w + . These functions are combined into a segment weighting D sel w X i (steps: 1-3). We use D sel w X i as compound selection function (step: 4). We simulate this user selection for the users of the study group, N obs S X i X i ∈ X , by executing Algorithm 4. We aggregate the user counts of the control group over X i , N obs C X i , and concatenate them to the aggregated study user counts after selection, N new S agg (step: 5).</p><p>We model the user response of the selected and nonselected populations for a given treatment arm, ( 0z X i 1z X i X i ∈ X ), using a probit transformation as illustrated by steps 3-4 of Algorithm 4. We consider the audience-by-segment constraint N Visit z X i , and the observed ad-exposed users as a fixed campaign budget N budget 1z (steps: 5-6). We define a budget multiplier to guarantee that all this budget is consumed by the user selection, which includes the probability of user segments P X i (steps: 10-11). The min function enforces the visiting population segment constraints (N Visit remain X i ). The while loop of steps 9-15 redistributes the remaining budget in case N Visit remain X i is exhausted for any segment. We aggregate the user counts over X i to generate the four counts given Z i = z: N new z agg = N y new dz d ∈ 0 1 y ∈ 0 1 (steps: 16-17).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Barajas et al.: Experimental Designs and Estimation: Attribution in Marketplaces 466 Marketing Science 35(3), pp. 465-483, © 2016 INFORMS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 (</head><label>1</label><figDesc>Figure 1 (Color online) Online Advertising Optimization Loop</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure2(Color online) Online Targeted Display Advertising Flow for a Given User Visit</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Marketing</head><label></label><figDesc>Figure 3 (Color online) (a) User Randomization Framework Proposed by Lewis et al. (2011) Without User Targeting-Engine Selection; (b) Standard Industry Randomization Practice with Placebo Ads; (c) Proposed Randomization Design for Campaign Attribution; (d) Randomization Framework with Disaggregated Campaign Effects</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Remark 1 .</head><label>1</label><figDesc>The design in Figure 3(c) identifies the right counterfactual to calculate ATE Camp (Equation (2)) when the objective is to estimate the campaign attribution. The design in Figure 3(d) disaggregates ATE Camp into two effects: ATE Ad and ATE Market (Equation (3)).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>are user counts for the given values of Y Z D. Missing values are presented as * .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Figure 5 (Color online) Model Fitting Results for (a) Campaign 1 and (b) Campaign 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Selection policies: (a) Per + vs. Per − , (b) Per + vs. {Per − ∪ AB}, (c) Per + vs. ¬Per + , (d) Y = 1 vs. Y = 0. Second half campaign duration, 7 days.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure D. 1 (</head><label>1</label><figDesc>Figure D.1 (Color online) Estimation Power as a Function of (a) Total User Population in Millions, (b) User Selection Probability, (c) Campaign Lift on the Users Selected for Ad Exposure (%) 25</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Figure D.1(b).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head></head><label></label><figDesc>Figure D.1(c) shows that true lift D=1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>The focus of this paper is the measurement (i.e., attribution) box.</figDesc><table><row><cell>Goal: Optimize causally generated conversions</cell><cell>SSP Targeting</cell><cell>User selection value estimation</cell><cell>DSP User audience:</cell><cell>User conversions</cell></row><row><cell>Update user</cell><cell>engine</cell><cell></cell><cell>Advertising traffic</cell><cell></cell></row><row><cell>targeting</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">Causally generated conversions</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">(Campaign attribution)</cell><cell>Attribution</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">measurement</cell><cell></cell></row><row><cell>Note.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>Description of the Variables Used in This Paper</figDesc><table><row><cell>Term</cell><cell>Description</cell><cell>Term</cell><cell>Description</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc>Performance Metrics Used in This Paper</figDesc><table><row><cell>Metric</cell><cell>Lift</cell><cell>Description</cell></row><row><cell>ATE Camp</cell><cell>lift Camp</cell><cell>Overall campaign average effect on all visiting</cell></row><row><cell></cell><cell></cell><cell>users</cell></row><row><cell>ATE Ad</cell><cell>ACL Ad</cell><cell>Average effect of the ad on selected users for ad</cell></row><row><cell></cell><cell></cell><cell>exposure</cell></row><row><cell>ATE Market</cell><cell cols="2">ACL Market Average campaign presence in the marketplace</cell></row><row><cell></cell><cell></cell><cell>effect on exposure-selected users</cell></row><row><cell>ATE D=1 Camp</cell><cell>lift D=1 Camp</cell><cell>Average treatment effect of the campaign on</cell></row><row><cell></cell><cell></cell><cell>selected users</cell></row><row><cell>SelEff</cell><cell>lift sel</cell><cell>User selection effect introduced by the targeting</cell></row><row><cell></cell><cell></cell><cell>engine</cell></row><row><cell>P D = 1 U</cell><cell cols="2">Probability of selecting user influenceable category U for</cell></row><row><cell></cell><cell cols="2">ad exposure</cell></row><row><cell>ATRB D=1 Camp</cell><cell cols="2">Campaign attributed converting users, with</cell></row><row><cell></cell><cell cols="2">respect to N 1 0S + N 1 1S , estimated based on ATE D=1 Camp</cell></row><row><cell>ATRB Camp</cell><cell cols="2">Campaign attributed converting users, with</cell></row><row><cell></cell><cell cols="2">respect to N 1 0S + N 1 1S , estimated based on ATE Camp</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3</head><label>3</label><figDesc>Observed User Counts Based on the User Potential Outcomes</figDesc><table><row><cell></cell><cell cols="2">Potential outcomes</cell><cell></cell><cell></cell></row><row><cell>User counts</cell><cell>Control</cell><cell>Study</cell><cell>Treatment</cell><cell>Principal stratum</cell></row><row><cell>N y dz</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>User Segments Based on Control/Study Z i and Nonselected/Selected D i Groups Control:</figDesc><table><row><cell></cell><cell>Marketing Science 35(3), pp. 465-483, © 2016 INFORMS</cell></row><row><cell>Figure 4</cell><cell>(Color online)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>We estimate the proportion of converting users attributed to the campaign with respect to those in the study group based on ATE Camp and ATE D=1 Camp (ATRB Camp , ATRB</figDesc><table><row><cell>7)</cell></row><row><cell>Based on the samples 1 N s obtained by the Gibbs</cell></row><row><cell>sampling procedure in  §3.1, credible intervals are estimated from the set ATE D=1 Camp lift D=1 Camp 1 N s .</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 4</head><label>4</label><figDesc>Campaign Data Based on Notation of Table3</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 5</head><label>5</label><figDesc>User Activity Statistics for the Campaigns of Table4</figDesc><table><row><cell>Campaign 1</cell><cell>Campaign 2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 6</head><label>6</label><figDesc></figDesc><table><row><cell></cell><cell cols="5">Validation of Model Conditions Expressed by Figure 4(b)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Campaign 1</cell><cell></cell><cell></cell><cell>Campaign 2</cell><cell></cell><cell></cell><cell></cell><cell>Campaign 1</cell><cell></cell><cell></cell><cell>Campaign 2</cell><cell></cell></row><row><cell></cell><cell>Low</cell><cell>Med</cell><cell>High</cell><cell>Low</cell><cell>Med</cell><cell>High</cell><cell></cell><cell>Low</cell><cell>Med</cell><cell>High</cell><cell>Low</cell><cell>Med</cell><cell>High</cell></row><row><cell>psel (1e−3)</cell><cell>−2 65</cell><cell>0.02</cell><cell>2.71</cell><cell>−0 89</cell><cell>0.01</cell><cell>0.91</cell><cell>0 (1e−5)</cell><cell>−1 71</cell><cell>0.03</cell><cell>1.70</cell><cell>−1 22</cell><cell>0.02</cell><cell>1.23</cell></row></table><note>Notes. The testing procedure is detailed in §4.2. 90% credible intervals are reported. Low Med High are the 0 05 0 5 0 95 quantiles.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>Lifts are the average point estimates. Thus, ATE I2C</figDesc><table><row><cell>Camp (1e−4), Campaign 1: [2.40, 2.56, 2.73], Campaign 2: [8.34, 8.68, 9.01]; ATE post Camp (1e−4),</cell></row></table><note>13  Intervals of ATE I2CCamp ATE post Camp are estimated using their t-statistics.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 7</head><label>7</label><figDesc></figDesc><table><row><cell></cell><cell cols="5">Attribution Results Using 90% Credible Intervals</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Campaign 1</cell><cell></cell><cell></cell><cell>Campaign 2</cell><cell></cell><cell></cell><cell></cell><cell>Campaign 1</cell><cell></cell><cell></cell><cell>Campaign 2</cell><cell></cell></row><row><cell></cell><cell>Low</cell><cell>Med</cell><cell>High</cell><cell>Low</cell><cell>Med</cell><cell>High</cell><cell></cell><cell>Low</cell><cell>Med</cell><cell>High</cell><cell>Low</cell><cell>Med</cell><cell>High</cell></row><row><cell>lift I2C Camp (%)</cell><cell>-</cell><cell>129</cell><cell>-</cell><cell>-</cell><cell>511</cell><cell>-</cell><cell>lift post Camp (%)</cell><cell>-</cell><cell>77 54</cell><cell>-</cell><cell>-</cell><cell>296</cell><cell>-</cell></row><row><cell>lift Camp (%) lift D=1 Camp (%) lift sel (%)</cell><cell>0.84 1.89 55</cell><cell>9 71 21 04 89</cell><cell>19 61 46 33 126</cell><cell>−1 35 −3 00 359</cell><cell>5 15 12 36 444</cell><cell>12 19 32 43 534</cell><cell>ATRB Camp (%) ATRB D=1 Camp (%)</cell><cell>0.85 0.96</cell><cell>8 90 9 05</cell><cell>16 51 16 59</cell><cell>−1 36 −1 42</cell><cell>4.91 5.05</cell><cell>10 96 11 26</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 8</head><label>8</label><figDesc></figDesc><table><row><cell>Campaign 3 Data (Design of Figure 3(d), Z</cell></row></table><note>i ∈ C P S ), Based on Notation of Table 3</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 9 User</head><label>9</label><figDesc></figDesc><table /><note>Activity Statistics for Campaign 3 of Table 8</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 10 Campaign</head><label>10</label><figDesc>Disaggregated Results, and Validation of the Placebo Campaign Based on 90% Credible Intervals</figDesc><table><row><cell></cell><cell>select Lift (%)</cell><cell></cell><cell></cell><cell cols="2">conver t Lift (%)</cell><cell></cell><cell>ACL Ad (%)</cell><cell></cell><cell></cell><cell>ACL Market (%)</cell><cell></cell><cell></cell><cell>lift D=1 Camp (%)</cell><cell></cell></row><row><cell>Low</cell><cell>Med</cell><cell>High</cell><cell>Low</cell><cell>Med</cell><cell>High</cell><cell>Low</cell><cell>Med</cell><cell>High</cell><cell>Low</cell><cell>Med</cell><cell>High</cell><cell>Low</cell><cell>Med</cell><cell>High</cell></row><row><cell>−2 84</cell><cell>−2 75</cell><cell>−2 65</cell><cell>−2 80</cell><cell>4.12</cell><cell>11 41</cell><cell>−2 78</cell><cell>6.74</cell><cell>17 97</cell><cell>−24 02</cell><cell>−15 06</cell><cell>−3 70</cell><cell>−18 88</cell><cell>−9 15</cell><cell>2.62</cell></row><row><cell cols="6">Note. Low Med High are the 0 05 0 5 0 95 quantiles.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 11 User</head><label>11</label><figDesc>Selection Median Probabilities Based on Equations (10)-(11)</figDesc><table><row><cell>Campaign 1</cell><cell>Campaign 2</cell><cell>Campaign 3</cell><cell>Campaign 1</cell><cell>Campaign 2</cell><cell>Campaign 3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 12</head><label>12</label><figDesc>Averaged Campaign Effect Results, lift D =1 Camp (%), for Different Selection Functions Based on Algorithm 3 Using the First Half of Campaign 3 as Training and Testing in the Second Half Selection function, F sel X i</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head></head><label></label><figDesc>User Selection for ad exposure</figDesc><table><row><cell>13:</cell><cell cols="2">Set N Visit remain X i = N Visit z</cell><cell>− N 1 new 1z</cell><cell cols="2">+ N 0 new 1z</cell><cell>X i</cell></row><row><cell>14:</cell><cell cols="4">X i ∈ X // Remaining Audience Set N budget remain = N budget 1z − X i ∈ X N 1 new 1z</cell><cell>+ N 0 new 1z</cell><cell>X i</cell></row><row><cell></cell><cell cols="3">// Remaining Budget</cell><cell></cell></row><row><cell cols="2">15: end while</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="2">16: Set N 1 new 0z</cell><cell>N 0 new 0z</cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2"><ref type="bibr" target="#b2">Blake and Coey (2014)</ref> identify test-control interference in marketplaces where users bid on scarce products. In the marketplace we address, advertisers bid on ad slots assuming there is enough inventory to satisfy the demand.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Marketing Science 35(3), pp.465-483, © 2016 INFORMS   </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">A post-treatment variable is a random variable whose realization is available after performing the randomized assignment. As a result, the treatment could affect this realization<ref type="bibr" target="#b8">(Frangakis and Rubin 2002</ref>).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">External validity of effects is implicitly assumed by most evaluation practices in literature<ref type="bibr" target="#b17">(Lewis et al. 2011</ref><ref type="bibr" target="#b25">, Yildiz and Narayanan 2013</ref><ref type="bibr" target="#b14">, Johnson et al. 2016</ref>. Given evolving user tastes, marketplace dynamics, and the sequential learning of targeting algorithms, even medium-term effect generalizations could be highly inaccurate.5  A typical belief is that user pre-treatment feature based balancing is the only way to show that control and study populations are statistically equivalent<ref type="bibr" target="#b14">(Johnson et al. 2016</ref>). However, Assumptions 1 and 2 do not require these features as long as the user assignment is independent of the effect, i.e., random.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">The campaign effect estimation of Equation (6), which is similar to the Intention-to-Treat (ITT) estimation, might be perceived as a noisy estimation. Note that the campaign budget, a crucial decision, is captured in the campaign attribution by this estimator. Also, we emphasize that only the visiting users to a given set of publisher websites are potentially selected for ad exposure, and not all of the online users as stated by<ref type="bibr" target="#b14">Johnson et al. (2016)</ref>. Although other causal frameworks have been developed, mainly the Structural Equation framework<ref type="bibr" target="#b13">(Heckman 2008)</ref>, we use Potential Outcomes to model post-treatment variables with experimental data.7  The current analysis holds for the randomized design in Figure3(d) if only the control and study arms are analyzed.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">By focusing on average effect estimates, we obviate the need to predict individual selection for ad exposure indicators, as performed by<ref type="bibr" target="#b14">Johnson et al. (2016)</ref>, with associated prediction errors.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">We assume that the cookie deletion event is independent of the campaign effect (ignorable or exogenous). Thus, no bias is introduced by focusing on users with stable cookies.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12">User principal strata are defined based on the observed selection indicator of the study group. Thus, our testing procedure focuses on this group. Generating actual control groups with one less bidder might produce spillover effects among bidders. We assume these (unlikely) effects to be negligible on average. Also, the larger the user population, the more likely this assumption holds.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14">We estimate a t-statistic for these conversion probability differences and the results are equivalent. However, estimation of the lifts requires further approximations.15  We expect larger effects for CPA campaigns where delivery of placebo ads must be equally optimized.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16"><ref type="bibr" target="#b14">Johnson et al. (2016)</ref> balance the user features in the prediction of the selection indicator first, and then compare this prediction with the selected users in the study group. In our approach, we model user randomization and user feature balancing jointly, which is more powerful than stepwise model fittings.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank the anonymous reviewers and the associate editor for their constructive comments and the patience to improve this paper. The authors also thank Jaimie Kwon, Victor Andrei, Professor Philip B. Stark, and James G. Shanahan for their contribution to this paper. This work is partially funded by CONACYT UC-MEXUS [Grant 194880], CITRIS, NSF IIP-0934364 [Subaward 0000015277], and AOL Faculty Award.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Effect of the Campaign Presence in the Marketplace Analysis</head><p>Based on the three-arm design in Figure <ref type="figure">3</ref>(d), Z i ∈ Control Placebo Study = C P S , we define i Z i as the competitors' selection for ad exposure policy. Let 0 i denote the competitors policy if the focal campaign does not exist i C = 0 i . Let 1 i be the alternative policy competitors execute with probability as a consequence of the campaign presence in the marketplace. If competitors are not interested in user i with probability 1 − , they will not compete to select this user and i Z i = 0 i Z i ∈ P S . Let represent the probability that competitors would win the opportunity to advertise in the control group but lose against the focal or placebo campaigns, and their ads have an effect on Y i . These definitions lead to the distributions</p><p>The parameter ∈ 0 1 is related to ∈ 0 1 through a competitors policy change function, = f ∈ 0 1 . Similarly, the effect ATE Market i is related to based on a competitors effect function, ATE Market i = f AT E ∈ −1 1 . Some individual cases include (proof of these cases is trivial based on Equation (A1)):</p><p>• = 0 ⇒ = f 0 = 0 ⇒ ATE Market i = 0: average competitors policy is not affected by the campaign.</p><p>• &gt; 0 ∧ = f = 0 ⇒ ATE Market i = 0: competitors advertising will not have any effect on Y i .</p><p>• = f &gt; 0 ⇒ &gt; 0: A competitors effect greater than zero is likely only if the focal campaign is likely to affect their average ad delivery policy.</p><p>• = f &gt; 0 ⇔ ATE Market i = 0: An average campaign presence effect implies a non-zero probability of competitors effect on Y i and vice versa.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. The Cost of the Randomized Design</head><p>We analyze the cost of the proposed design of Figure <ref type="figure">3(c</ref>) where no placebo ad is displayed, and Z i ∈ Control Study = C S . Let N D=1 be the number of users for whom the opportunity to advertise is won. For the control group, there is a potential revenue loss, proportional to the campaign effect value on this subpopulation (Val ATE D=1 Camp i ), if these users were exposed to the ad. Because no ad impression is displayed to these users, a campaign budget surplus remains from not displaying these ads (Cost AdDisplay ). Thus, the design cost (Cost Design ) becomes</p><p>Note that P Z i = C × N D=1 × Cost AdDisplay represents a budget surplus for not showing the campaign ad to the users of the control group. If this budget surplus is used to display campaign ads to a larger population in the study group, we have ATE D=1 Camp i as the average campaign effects on these additional exposed users. As a result, the design cost (Cost Design ) results in</p><p>Given an optimal user selection policy, where the users with highest potential causal impact are most likely to be selected, then &gt; 0 and ATE D=1 Camp i . Therefore, the cost of experimentation is reduced to a function of a small number: . Note that the larger P Z i = C , the larger the effect difference .</p><p>Appendix C. The Prior Probability and a Method of Moments: Robustness Checks</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Web-scale user modeling for targeting</title>
		<author>
			<persName><forename type="first">M</forename><surname>Aly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hatch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Josifovski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">K</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21st Internat. Conf. World Wide Web</title>
				<meeting>21st Internat. Conf. World Wide Web<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="3" to="12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title level="m" type="main">Engagement mapping: A new measurement standard is emerging for advertisers</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
		<respStmt>
			<orgName>Atlas Institute</orgName>
		</respStmt>
	</monogr>
	<note>White paper</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Beyond the last touch: Attribution in online advertising. Working paper, University of Pennsylvania</title>
		<author>
			<persName><surname>Berman R ; Philadelphia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Coey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 15th ACM Conf. Econom. Computation</title>
				<meeting>15th ACM Conf. Econom. Computation<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2014" />
			<biblScope unit="page" from="567" to="582" />
		</imprint>
	</monogr>
	<note>Why marketplace experimentation is harder than it seems: The role of test-control interference</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Consumer heterogeneity and paid search effectiveness: A large scale field experiment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nosko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tadelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="155" to="174" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><surname>Broder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Josifovski</surname></persName>
		</author>
		<title level="m">Introduction to Computational Advertising</title>
				<meeting><address><addrLine>Redwood City, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Stanford University Press</publisher>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A decision theoretic approach to targeted advertising</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Chickering</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Heckerman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 16th Uncertainty Artificial Intelligence</title>
				<editor>
			<persName><forename type="first">C</forename><surname>Boutilier</surname></persName>
			<persName><forename type="first">M</forename><surname>Goldszmidt</surname></persName>
		</editor>
		<meeting>16th Uncertainty Artificial Intelligence<address><addrLine>Stanford, CA</addrLine></address></meeting>
		<imprint>
			<publisher>Morgan Kaufmann</publisher>
			<date type="published" when="2000" />
			<biblScope unit="page" from="82" to="88" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Using experiment design to build confidence in your attribution model</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chittilappilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Online Metrics Insider</title>
		<imprint>
			<date type="published" when="2012-07-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Real-time display advertising state of the industry</title>
		<author>
			<persName><forename type="first">Google</forename><surname>Digiday</surname></persName>
		</author>
		<ptr target="http://doubleclickadvertisers.blogspot.com/2011/02/real-time-display-advertising-state-of.html" />
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Principal stratification in causal inference</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Frangakis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrics</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="21" to="29" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The validity of posterior expansions based on Laplace&apos;s method</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geisser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Press</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Zeuner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Bayesian Likelihood Methods Statist. Econometrics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="473" to="488" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Bidding for representative allocations for display advertising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Mcafee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Papineni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vassilvitskii</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Internet Network Econom.: 5th Internat</title>
		<title level="s">Lecture Notes Comput. Sci.</title>
		<editor>
			<persName><forename type="first">S</forename><surname>Leonardi</surname></persName>
		</editor>
		<meeting>Internet Network Econom.: 5th Internat<address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">5929</biblScope>
			<biblScope unit="page" from="208" to="219" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">What is different about online advertising?</title>
		<author>
			<persName><forename type="first">A</forename><surname>Goldfarb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Indust. Organ</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="115" to="129" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Online display advertising: Targeting and obtrusiveness</title>
		<author>
			<persName><forename type="first">A</forename><surname>Goldfarb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="389" to="404" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Heckman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometric causality. Internat. Statist. Rev</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Ghost ads: A revolution in measuring ad effectiveness. Working paper</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Nubbemeyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<pubPlace>Rochester, NY</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Rochester</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">When does retargeting work? Information specificity in online advertising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lambrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="561" to="576" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Online ads and offline sales: Measuring the effects of retail advertising via a controlled experiment on Yahoo!</title>
		<author>
			<persName><forename type="first">R</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Reiley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quant. Marketing Econom</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="235" to="266" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Here, there, and everywhere: Correlated online behaviors can lead to overestimates of the effects of advertising</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Reiley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 20th Internat. Conf. World Wide Web</title>
				<meeting>20th Internat. Conf. World Wide Web<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="157" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Attributing conversions in a multichannel online marketing environment: An empirical model and a field experiment</title>
		<author>
			<persName><forename type="first">H</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Kannan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="56" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">IAB marketplace: Networks and xchanges</title>
		<author>
			<persName><forename type="first">W</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Coolbirth</surname></persName>
		</author>
		<ptr target="http://www.slideshare.net/tinhanhvy/iab-marketplace-networks-and-xchanges-2008" />
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning to target: What works for behavioral targeting</title>
		<author>
			<persName><forename type="first">S</forename><surname>Pandey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Aly</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Bagherjeiran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Hatch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Ciccolo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ratnaparkhi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zinkevich</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 20th Internat. Conf. Inform. Knowledge Management</title>
				<meeting>20th Internat. Conf. Inform. Knowledge Management<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1805" to="1814" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Causal inference using potential outcomes</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">469</biblScope>
			<biblScope unit="page" from="322" to="331" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Do targeted discount offers serve as advertising? Evidence from 70 field experiments</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sahni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Zou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Chintagunta</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>Palo Alto, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Stanford University Graduate School of Business</orgName>
		</respStmt>
	</monogr>
	<note>Research Paper</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Data-driven multi-touch attribution models</title>
		<author>
			<persName><forename type="first">X</forename><surname>Shao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 17th ACM SIGKDD Internat. Conf. Knowledge Discovery Data Mining</title>
				<meeting>17th ACM SIGKDD Internat. Conf. Knowledge Discovery Data Mining<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="258" to="264" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">The arrival of real-time bidding</title>
		<author>
			<persName><forename type="first">S</forename><surname>Spencer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>O'connell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M ;</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName><surname>Iab</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Forrester</forename><surname>Google</surname></persName>
		</author>
		<ptr target="http://www.slideshare.net/IABmembership/the-arrival-of-realtime-bidding-hosted-by-iab-google-forrester" />
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Star digital: Assessing the effectiveness of display advertising. Case Study</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yildiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narayanan</surname></persName>
		</author>
		<ptr target="https://hbr.org/product/star-digital-assessing-the-effectivness-of-display-advertising/M347-HCB-ENG" />
	</analytic>
	<monogr>
		<title level="j">Harvard Business Review</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
