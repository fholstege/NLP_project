<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Test &amp; Roll: Profit-Maximizing A/B Tests</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-11-14">November 14, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Elea</forename><forename type="middle">Mcdonnell</forename><surname>Feit</surname></persName>
							<email>eleafeit@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">LeBow College of Business</orgName>
								<orgName type="institution" key="instit2">Drexel University</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Ron</forename><surname>Berman</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">The Wharton School</orgName>
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Test &amp; Roll: Profit-Maximizing A/B Tests</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
						<imprint>
							<date type="published" when="2019-11-14">November 14, 2019</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.2019.1194</idno>
					<note type="submission">Received: October 29, 2018 Revised: May 21, 2019 Accepted: May 24, 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>A/B testing</term>
					<term>randomized controlled trial</term>
					<term>marketing experiments</term>
					<term>Bayesian decision theory</term>
					<term>sample size</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please scroll down for article-it is on subsequent pages</head><p>With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning opportunities for individual professionals, and organizations of all types and sizes, to better understand and use O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Experimentation is an important tool for marketers in a wide range of settings including direct mail, email, display advertising, social media marketing, website optimization, and app design. In tactical marketing settings, which we call "test &amp; roll" experiments, data on customer response are first collected in a test stage where a subset of customers are randomly assigned to a treatment. In the roll stage that follows, marketers deploy one treatment to all remaining customers based on the test results.</p><p>Figure <ref type="figure" target="#fig_0">1</ref> shows an example test &amp; roll setup screen. Emails with two different subject lines will each be sent to 8,910 customers at random from a total list of 59,404 email addresses. Once the test outcomes are measured, the platform sends the better-performing email to the remainder of the list.</p><p>Traditionally, such randomized controlled trials are analyzed with a significance test, where the null hypothesis of equal mean response of two treatments is rejected if</p><formula xml:id="formula_0">y 1 − y 2 ≥ z 1−α/2 ̅̅̅̅̅̅̅̅̅̅ s 2 1 n 1 + s 2 2 n 2 √ ,<label>(1)</label></formula><p>where y 1 and y 2 are the mean response for each test group, s 1 and s 2 are the standard deviation of the response, n 1 and n 2 are the sample sizes, and the significance level α is the desired Type I error rate that determines the critical value z. 1 When using hypothesis testing, the sample size is fixed prior to data collection, and n 1 and n 2 are set to detect an effect of at least d with probability 1 − β. When s 1 s 2 s, the recommended sample size is</p><formula xml:id="formula_1">n HT n 1 n 2 ≈ z 1−α/2 + z β ( ) 2 2s 2 d 2 ( ) . (<label>2</label></formula><formula xml:id="formula_2">)</formula><p>The recommendation is to set n 1 n 2 because this maximizes the statistical power of the experiment when s 1 s 2 .</p><p>We develop an alternative approach to planning and analyzing A/B tests with finite populations. Although null hypothesis testing is the "gold standard" in scientific and medical research and is often recommended for marketing tests (e.g., <ref type="bibr" target="#b18">Pekelis et al. 2015)</ref>, the statistical significance threshold in (1) is a poor decision rule for test &amp; roll experiments aimed at maximizing profits, for four reasons.</p><p>First, hypothesis tests at typical significance levels (e.g., α 0.05) are designed to avoid concluding that two treatments perform differently when they do not. Yet these Type I errors have little consequence for profit, assuming no deployment costs. If the null cannot be rejected and both treatments yield identical effects, the same profit will be earned regardless of which treatment is deployed. Because of the profit trade-off between test-stage learning and roll-stage earning, conservative sample sizes based on null hypothesis testing lower overall expected profit, by exposing too many people to the less effective treatment in the test.</p><p>Second, the population available for testing and deploying is often limited, but the recommended sample size in (2) does not take this constraint into account. In online advertising experiments where effects are often small (but profitable), the recommended sample size may be larger than the size of the population itself <ref type="bibr">(Lewis and Rao 2015)</ref>. <ref type="bibr">2</ref> Yet, as we show, when the population is limited, smaller tests that will never reach statistical significance can still have substantial benefit in improving expected profit.</p><p>Third, the typical null hypothesis test in (1) provides no guidance on which treatment to deploy when the results are not significant. Many A/B testers advocate deploying the incumbent treatment (if there is one) in the interest of being "conservative," choosing randomly <ref type="bibr" target="#b13">(Gershoff 2017)</ref>, or continuing the test until it reaches significance (e.g., <ref type="bibr">Berman et al. 2018)</ref>.</p><p>Fourth, practitioners often design tests with unequal sample sizes for each treatment (e.g., <ref type="bibr" target="#b15">Lewis and</ref><ref type="bibr">Rao 2015, Zantedeschi et al. 2016)</ref>. Our framework allows unequal sample sizes to arise naturally from prior beliefs, whereas this cannot be rationalized under classical hypothesis testing when response variance is equal (s 2 1 s 2 2 ). We reframe the test &amp; roll decision problem in Section 2, focusing on profit and making an explicit trade-off between the opportunity cost of the test (where some customers receive the suboptimal treatment) and the losses associated with deploying the suboptimal treatment to the remainder of the finite population. In effect, the problem we define can be seen as a constrained version of a multi-armed bandit, where there are only two allocation decisions instead of many. Note. Screenshots were obtained from the email marketing tool Campaign Monitor, as described on the Zapier.com blog.</p><p>Feit and Berman: Test &amp; Roll: Profit-Maximizing A/B Tests <ref type="bibr">Marketing Science, 2019</ref><ref type="bibr">, vol. 38, no. 6, pp. 1038</ref><ref type="bibr">-1059</ref><ref type="bibr" target="#b23">, © 2019</ref> We derive a new closed-form expression for the profit-maximizing sample size in Section 3, assuming that the average revenue per customer is normally distributed with Normal priors. Test sample sizes under this framework are often substantially smaller than those recommended by (2). Unlike sample sizes for a hypothesis test that increase linearly with the variance of the response in (2), profit-maximizing sample sizes increase sublinearly with the standard deviation of the response, leading to substantially smaller test sizes when the response is noisy. Profitmaximizing samples are also proportional to the square root of the total size of the population available, and so they naturally scale to both large and small settings.</p><p>Improved performance is achieved because profitmaximizing tests identify the best-performing treatment with high probability when treatment effects are large; the lost profit (regret) from errors in treatment selection is small when treatment effects are small. We also show that a test &amp; roll with the profitmaximizing sample size achieves nearly the same level of regret as the popular Thompson sampling solution to the multi-armed bandit problem <ref type="bibr" target="#b20">(Scott 2010</ref><ref type="bibr" target="#b19">, Schwartz et al. 2017</ref>; both have regret of O( ̅̅̅ N √</p><p>). Although suboptimal relative to a multi-armed bandit, the profit-maximizing test &amp; roll provides a transparent decision point and reduced operational complexity without significant loss of profit.</p><p>Section 4 extends the analysis to situations with different priors on treatments, and it provides an efficient numeric approach to computing optimal sample sizes. This allows us to rationalize the common practice of using unequally sized treatment groups when the two treatments are believed a priori to produce different responses (e.g., a test comparing media exposure to no exposure or a test comparing two different prices).</p><p>To illustrate how test &amp; roll experiments should be designed in practice, Section 5 provides three empirical applications: website design, online display advertising, and catalog marketing. For each application, we estimate priors based on previous similar experiments. These applications show the wide range of test designs that result from different priors and show that the "one-size-fits-all" approach favored by null hypothesis testing does not maximize profit. We conclude in Section 6 with a discussion of potential extensions of the test &amp; roll framework and implications for A/B testers. Full statements of propositions and proofs appear in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Test &amp; Roll Decision Problem</head><p>A test &amp; roll with a population of N customers has two stages: a test stage and a roll stage. In the test stage, a random sample of n 1 customers are exposed to treatment 1, and a random nonoverlapping sample of n 2 customers are exposed to treatment 2, with n 1 + n 2 &lt; N. In the roll stage, all remaining N − n 1 − n 2 customers receive either treatment 1 or treatment 2 based on a decision rule that incorporates the data observed in the test stage. The marketer's goal is to maximize the cumulative profit earned in both stages.</p><p>Assuming the profit for each customer receiving treatment j is an independent random variable Y j that follows a distribution with parameters θ j , the expected profit earned during the test phase is</p><formula xml:id="formula_3">E Y 1 ,Y 2 Π T |θ 1 , θ 2 [ ] n 1 E Y 1 |θ 1 [ ]+ n 2 E Y 2 |θ 2 [ ], (3)</formula><p>where Y j is the profit net of any costs related to the treatments (e.g., media costs or discounts). In website and email tests, for example, the cost of both treatments is the same and can be ignored. Denote the vector of observed profit from customers exposed to treatment j in the test as y j y j,1 , . . . , y j,n j . Once y 1 and y 2 are observed, the analyst chooses a treatment to deploy with the remaining N − n 1 − n 2 customers. Let δ(y 1 , y 2 ) be the decision rule, which takes the value 1 for the decision to deploy treatment 1 and 0 for treatment 2. The optimal decision rule is to select the treatment with the highest posterior predictive mean E[Y j |y j ] (DeGroot 1970).</p><p>Depending on the decision rule, the expected profit in the roll stage is</p><formula xml:id="formula_4">E Y 1 ,Y 2 Π D |θ 1 , θ 2 [ ] N − n 1 − n 2 ( ) E Y 1 ,Y 2 δ y 1 , y 2 ( ) Y 1 [ + 1 − δ y 1 , y 2 ( ) ( ) Y 2 |θ 1 , θ 2 ] .<label>(4)</label></formula><p>Increasing n 1 and n 2 provides more observations about the profitability of each treatment and thus has the potential to yield more correct decisions in the roll stage. Simultaneously, increasing n 1 and n 2 decreases the population remaining in the roll stage and increases the test population, some of which is exposed to the lesser-performing treatment. Thus, the test &amp; roll framework sets up an explicit trade-off between learning during the test phase and earning during the roll phase. This trade-off is important when the total population size N is limited. <ref type="bibr">3</ref> Well-defined, limited populations are common in marketing: in direct marketing N is the size of the customer list <ref type="bibr" target="#b7">(Bitran and</ref><ref type="bibr">Mondschein 1996, Bonfrer and</ref><ref type="bibr" target="#b8">Drèze 2009)</ref>; in paid media, N is often determined by a finite budget; and in website or app tests, N reflects the expected traffic for some period after the test.</p><p>The parameters θ 1 and θ 2 are unknown prior to the test (hence the need for the test). By assuming a prior distribution over these parameters, we obtain the a priori expected profit of the A/B test: Designing the test entails selecting the sample sizes n 1 and n 2 that maximize the total expected profit:</p><formula xml:id="formula_5">E θ 1 ,θ 2 E Y 1 ,Y 2 Π T |θ 1 , θ 2 [ ]+ E Y 1 ,Y 2 Π D |θ 1 , θ 2 [ ] [ ] .<label>(5</label></formula><formula xml:id="formula_6">n * 1 , n * 2 ( ) argmax n 1 ,n 2 E θ 1 ,θ 2 E Y 1 ,Y 2 Π T |θ 1 , θ 2 [ ] [ + E Y 1 ,Y 2 Π D |θ 1 , θ 2 [ ] ] .<label>(6)</label></formula><p>Thus a profit-maximizing test &amp; roll runs a test with the sample size in (6) and deploys one treatment based on the decision rule δ.</p><p>Both our approach and the hypothesis testing approach described in Equations ( <ref type="formula" target="#formula_0">1</ref>) and ( <ref type="formula" target="#formula_1">2</ref>) are decisiontheoretic but differ in three aspects: (1) We define the decision as whether to deploy treatment 1 or treatment 2, instead of deciding whether to reject the null hypothesis.</p><p>(2) The objective in hypothesis testing is to maximize statistical power while controlling Type I error, whereas we focus on maximizing profits. (3) Hypothesis testing uses a 0/1 loss function, and so every incorrect decision has the same cost, while our approach uses the actual opportunity cost as the loss, including the cost of the test.</p><p>Similar two-stage decision problems have appeared in the literature. <ref type="bibr" target="#b11">Chick and Inoue (2001)</ref> analyze a two-stage decision problem where the cost of the test is a fixed multiple of the sample sizes, rather than actual opportunity cost as we have here. In studying multi-armed bandits, <ref type="bibr" target="#b19">Schwartz et al. (2017)</ref> and <ref type="bibr" target="#b17">Misra et al. (2019)</ref> use a test &amp; roll as a benchmark, but they do not optimize the sample size. The closest work comes from the clinical trials literature, where <ref type="bibr" target="#b9">Cheng et al. (2003)</ref> define the same test &amp; roll problem with a finite "patient horizon" and approximate the optimal sample size for Bernoulli responses with beta priors. <ref type="bibr" target="#b22">Stallard et al. (2017)</ref> extend <ref type="bibr" target="#b9">Cheng et al. (2003)</ref> to exponential family responses with conjugate exponential family priors. As a result, they also need to use approximations to compute the optimal sample size. In this paper, we focus on Normal response distributions with Normal priors, which allows us to provide an exact closed form for the optimal sample size as well as exact expected profit and regret, which we show next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Test &amp; Roll with Symmetric Normal Priors</head><p>To derive a profit-maximizing sample size formula, we assume Y 1 ∼ 1(m 1 , s 2 ) and Y 2 ∼ 1(m 2 , s 2 ) with identical priors m 1 , m 2 ∼ 1(μ, σ 2 ). The variance of the response, s 2 , is known; in practice, it can be estimated from previously observed responses. <ref type="bibr">4</ref> The hyperparameters μ and σ represent expectations for how the two treatments may perform, which can be informed by previous similar marketing campaigns (as illustrated in Section 5).</p><p>The symmetric priors imply that neither treatment is a priori likely to perform better, but they do not imply that m 1 m 2 . The implied prior on the treatment effect m 1 − m 2 is 1(0, 2σ 2 ), and the absolute difference between treatments</p><formula xml:id="formula_7">|m 1 − m 2 | is distributed half-normal with mean ̅̅ 2 √ σ/ ̅̅ ̅ π √</formula><p>. Thus σ is related to the a priori expectation about the potential difference in treatment effects (as well as the uncertainty).</p><p>The expected profit in the test stage for this model is</p><formula xml:id="formula_8">E[Π T ] (n 1 + n 2 )μ. (<label>7</label></formula><formula xml:id="formula_9">)</formula><p>The expected profit in the roll stage depends on the decision rule δ(y 1 , y 2 ). The profit-maximizing decision rule is to choose the treatment with the greater expected posterior mean response:</p><formula xml:id="formula_10">δ(y 1 , y 2 ) I 1 σ 2 + n 1 s 2 ( ) −1 μ σ 2 + n 1 y 1 s 2 ( ) ( &gt; 1 σ 2 + n 2 s 2 ( ) −1 μ σ 2 + n 2 y 2 s 2 ( ) ) ,<label>(8)</label></formula><p>where y j is the average response observed for treatment j and I(•) is the indicator function. Because the priors are symmetric, this reduces to δ(y 1 , y 2 ) I(y 1 &gt; y 2 ) if n 1 n 2 (i.e., the highly intuitive "pick the winner" in the test). Proposition A.1 shows that the decision rule in (8) yields an expected roll-stage profit of</p><formula xml:id="formula_11">E[Π D ] (N − n 1 − n 2 ) μ + ̅̅ 2 √ σ 2 ̅̅ ̅ π √ ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ 2σ 2 + n 1 +n 2 n 1 n 2 s 2 √ ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦ . (9)</formula><p>The second addend in the square brackets is the expected incremental profit per customer earned by (usually) deploying the better treatment relative to choosing randomly with expected profit of μ. Unsurprisingly, the incremental gain per customer from the test is increasing in the sample sizes n 1 and n 2 . However, as (n 1 + n 2 ) increases, the number of customers for whom this higher profit is earned is smaller.</p><p>The incremental gain decreases with the noise in the data, s, as expected. The a priori range of effect sizes is defined by σ. Higher a priori uncertainty about the mean response increases the option value from the experiment, and so the incremental gain increases with σ.</p><p>To find the optimal sample size, the sum of the test profit in (7) and the deployment profit in (9) can be maximized over n 1 and n 2 , resulting in optimal sample sizes (Proposition A.2): </p><formula xml:id="formula_12">n * n * 1 n * 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ ̅ N 4 s σ ( ) 2 + 3 4 s σ ( ) 2 ( ) 2 √ − 3 4 s σ ( ) 2 . (<label>10</label></formula><formula xml:id="formula_13">)</formula><formula xml:id="formula_14">Because N 4 ( s σ ) 2 + ( 3 4 ( s σ ) 2 ) 2 ≤ ( ̅̅̅ N √ s 2σ + 3 4 ( s σ ) 2 ) 2 , (10) implies that n * 1 n * 2 ≤ ̅̅̅ N √ s 2σ .</formula><p>The profit-maximizing sample size is always less than the population size N and grows sublinearly with the standard deviation of the response s. By contrast, the recommended sample size for a hypothesis test in (2) grows linearly with the variance s 2 without regard to N. This explains why, for noisy responses, hypothesis tests frequently require sample sizes that are larger than the available population (Lewis and Rao 2015). <ref type="bibr">5</ref> Note that the profit-maximizing sample size decreases with σ. A large σ implies (1) a larger expected difference between treatments and (2) a lower error rate for a given sample size (see ( <ref type="formula" target="#formula_16">12</ref>)), whereas (3) the opportunity cost remains the same.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Error Rate</head><p>Test &amp; roll does not require the planner to specify an acceptable level of error; the error rate follows from optimally trading off the opportunity cost of the test against the expected loss in profit as a result of deployment errors. However, practitioners may want to know the expected error rate. Conditional on m 1 and m 2 , the likelihood of deploying treatment 1 when treatment 2 has a better mean response is</p><formula xml:id="formula_15">Pr δ(y 1 , y 2 ) 1|m 1 , m 2 ( ) 1 − Φ m 2 − m 1 s ̅̅̅̅̅̅̅̅ 1 n 1 + 1 n 2 √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ .<label>(11)</label></formula><p>From (11), we see that when the difference in treatments m 2 − m 1 is positive and large, the error rate is lower; that is, the better treatment will be deployed. When m 2 − m 1 is smaller, it is more likely that the wrong treatment will be deployed, but this is less consequential for profit. Integrating (11) over the priors on m 1 and m 2 , the expected error rate is (Corollary A.3)</p><formula xml:id="formula_16">E Pr δ(y 1 , y 2 ) 1|m 1 &lt; m 2 ( ) [ ] E[Pr(δ(y 1 , y 2 ) 0|m 1 &gt; m 2 )] 1 4 − 1 2π arctan ̅̅ 2 √ σ s ̅̅̅̅̅̅̅̅̅̅ n 1 n 2 n 1 + n 2 √ ( ) .<label>(12)</label></formula><p>As expected, the error rate decreases with the test sizes n 1 and n 2 , increases with s, and decreases with σ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Regret</head><p>To provide an upper bound on the total expected profit, we compute the expected profit with perfect information (PI). If an omniscient marketer were able to deploy the treatment with higher expected profit to all N customers without testing, the expected profit would be (Proposition A.4, part 1)</p><formula xml:id="formula_17">E[Π|PI] μ + σ ̅̅ ̅ π √ ( ) N.<label>(13)</label></formula><p>The expected profit of any algorithm for choosing which treatment to deploy to each customer will be between the expected value of choosing randomly, which is μN, and the expected value of perfect information in <ref type="bibr">(13)</ref>. The expected profit with perfect information scales with the variance of the prior σ; the more potential difference there is between treatments, the more opportunity there is to improve profits by choosing the better treatment.</p><p>The expected regret of the profit-maximizing test &amp; roll experiment is (Proposition A.4, part (2))</p><formula xml:id="formula_18">E[Π|PI] − E[Π * D + Π * T ] N σ ̅̅ ̅ π √ 1 − σ ̅̅̅̅̅̅̅̅̅ σ 2 + s 2 n * √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ + 2n * σ 2 ̅̅ ̅ π √ ̅̅̅̅̅̅̅̅̅ σ 2 + s 2 n * √ ≤ 3s ̅̅̅ N √ ̅̅ ̅ π √ O( ̅̅̅ N √ ). (<label>14</label></formula><formula xml:id="formula_19">)</formula><p>When populations are larger, the regret per customer decreases; hence marketers with larger populations have a greater opportunity to improve profits on a per-customer basis with a profit-maximizing test. We also see that the regret has an upper bound that does not depend on σ, implying that the potential regret is limited. Marketers can use the new closed-form formulas in ( <ref type="formula" target="#formula_16">12</ref>) and ( <ref type="formula" target="#formula_18">14</ref>) to easily assess the potential value of running a test &amp; roll.</p><p>To gain further insight into these results, we look at the expected relative regret of the profit-maximizing test &amp; roll with respect to the expected profit from perfect information:</p><formula xml:id="formula_20">E[Π|PI] − E Π * D + Π * T [ ] E[Π|PI] .<label>(15)</label></formula><p>As Corollary A.5 proves, the relative regret reaches a maximum for an intermediate finite value of σ. When σ is very small, there is not much to gain from having perfect information, and hence the relative regret will be small, whereas when σ is large, the test stage will pick the best-performing treatment with a very high probability, also yielding low regret. Only when σ is intermediate is there some chance of substantial loss from using a simple method such as test &amp; roll, but even in this case, the potential loss is limited. By contrast, using the suboptimal sample size recommended for a hypothesis test produces substantially greater regret. Assuming that the better-performing treatment will be deployed after the test regardless of significance, 6 we can substitute the value of n HT from (2) for n * in (14). The regret from using the larger sample size is (Proposition A.4, part (3)) ) as N becomes large. <ref type="bibr">7</ref> Proposition A.4 also shows that this bound holds when a finite-population correction is included in the sample size formula.</p><formula xml:id="formula_21">E[Π|PI] − E[Π D + Π T |HT] ≥ N σ ̅̅ ̅ π √ d 2 4(z (1−α)/2 + z β ) 2 σ 2 + 2d 2 ) Ω(N),<label>(16)</label></formula><p>We can also compare a test &amp; roll with profitmaximizing sample size to a multi-armed bandit where allocation to treatments is determined probabilistically for each customer based on previous responses. <ref type="bibr" target="#b0">Agrawal and Goyal (2013)</ref> show that the expected regret of a multi-armed bandit with Thompson sampling <ref type="bibr" target="#b24">(Thompson 1933)</ref>  The Normal model developed in this section can also be used in situations where the response is Bernoulli (e.g., clicks, purchase incidence) using the standard approximation s μ(1 − μ) and has a convenient closed-form solution. Alternatively, Appendix B develops a beta-binomial version where sample size must be computed numerically. Figure B.1 compares exact sample sizes from the beta-binomial with the Normal approximation and shows that the Normal approximation provides accurate sample sizes when μ is between 0.05 and 0.95; for smaller or larger μ, the sample size computed using the Normal approximation is too small, and we suggest using the betabinomial formulation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Test &amp; Roll with Asymmetric Normal Priors</head><p>The analysis thus far has focused on cases with a common prior for both treatments. However, there are many situations where the priors might be different (e.g., comparing a marketing communication against a holdout control).</p><p>Relaxing the assumptions from the previous section, assume</p><formula xml:id="formula_22">Y 1 ∼ 1(m 1 , s 2 1 ) and Y 2 ∼ 1(m 2 , s 2 2 ) with priors m 1 ∼ 1(μ 1 , σ 2 1 ) and m 2 ∼ 1(μ 2 , σ<label>2</label></formula><p>2 ) that represent the information about the treatments available prior to the test.</p><p>Under these priors, the a priori expected profit in the test stage is</p><formula xml:id="formula_23">E Π T [ ] μ 1 n 1 + μ 2 n 2 . (<label>17</label></formula><formula xml:id="formula_24">)</formula><p>Decision rule ( <ref type="formula" target="#formula_10">8</ref>) is still optimal in this case but does not imply selecting the treatment that performs better in the test anymore; the prior information now also affects the decision. Using the decision rule in ( <ref type="formula" target="#formula_10">8</ref>), the a priori expected profit in the roll stage is (Proposition A.1)</p><formula xml:id="formula_25">E Π D [ ] N − n 1 − n 2 ( )μ 1 + eΦ e v ( ) + vφ e v ( ) [ ] ,</formula><p>where e μ 2 − μ 1 ( ) and v</p><formula xml:id="formula_26">̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ σ 4 1 σ 2 1 + s 2 1 /n 1 + σ 4 2 σ 2 2 + s 2 2 /n 2 √ . (<label>18</label></formula><formula xml:id="formula_27">)</formula><p>The expected total profit</p><formula xml:id="formula_28">E[Π] E[Π T ] + E[Π D ]</formula><p>can be maximized over n 1 and n 2 to find the optimal sample size. The optimal sample sizes cannot be solved for analytically, but the function can be easily optimized numerically. 9</p><p>4.1. Incumbent/Challenger Tests One example of an asymmetric test &amp; roll experiment arises when the experimenter has more past experience with treatment 1 versus treatment 2, implying that σ 1 &lt; σ 2 . We dub this an "incumbent/challenger" test. For example, an incumbent can be an ad copy or page design that follows the traditional firm branding strategy, whereas a challenger uses a new creative approach. When σ 1 &lt; σ 2 , the optimal sample size will be larger for the challenger treatment, to gain more information about the challenger in the test. A proof of this alongside sample size formulas can be found in Appendix C.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Pricing Tests</head><p>A second common case for asymmetric test plans is pricing experiments. Because companies face uncertainty about which prices are optimal, they often experiment with multiple prices. Different prices, however, influence two important factors. First is the number of people who will purchase the product; higher prices will elicit fewer purchases. Second is the profit per person; higher prices yield higher profits conditional on purchase. Thus, setting different prices effectively changes the priors on the mean profit per customer, which implies different optimal sample sizes for the two price levels. An example application that fits our framework is as follows. Suppose the firm would like to pick between two known prices, p 1 and p 2 , and that demand from customer i presented with price j is d ij a − m • p j + ε ij . In this model, demand is linear in price, a is the willingness to pay for the product, m is the uncertain price sensitivity with a prior distribution 1(μ, σ 2 ), and ε ij ∼ 1(0, s 2 ). The profit from a customer i presented with price j will be y ij p j d ij . This model translates directly to a Normal-Normal model with asymmetric priors, where we denote μ j p j (a − μp j ), σ j p 2 j σ, and s j p j s. Consequently, the profit and optimal sample size formulas derived for the asymmetric case can be applied directly to pricing experiments and will recommend different sample sizes depending on the levels of prices being tested. A marketer could further optimize the test prices p 1 and p 2 . More distant prices help to identify m but increase the opportunity cost of the test.</p><p>A more comprehensive approach to this problem is taken by <ref type="bibr" target="#b17">Misra et al. (2019)</ref>, where their goal was not to test specific prices but rather to learn the demand curve while maximizing profits. The test &amp; roll setup can be adapted to solve a similar problem, but the solution will require a numerical approach for calculating sample sizes and optimal prices.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Applications</head><p>Designing a profit-maximizing test &amp; roll requires priors on the distribution of the mean response (profit) of the treatments. This section illustrates how to estimate these priors using data on past marketing interventions. <ref type="bibr">10</ref> We then use the estimated priors to provide optimal test plans for three different marketing contexts and compare them to hypothesis testing and multi-armed bandits using Thompson sampling, based on expected profit and regret. The first two applications use symmetric priors, whereas the third presents a situation where asymmetric priors are appropriate.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Website Testing</head><p>To set priors based on past data, we analyze 2,101 website tests from <ref type="bibr">Berman et al. (2018)</ref> that were conducted across a wide variety of websites. For each treatment arm in each experiment, we observe the click rateȳ and sample size n. 11 Fitting a hierarchical model to these data, we estimate that the mean responses (click rates) are distributed 1(0.68, 0.03) across treatment arms. (Appendix Section E.1 details the data and estimation.)</p><p>To plan a new test, we assume that this as a symmetric prior on mean response (m 1 and m 2 ). Assuming symmetric priors is reasonable as there is typically no prior information that one version of a web page will perform better than the other. The implied prior on the treatment effect is shown in Figure <ref type="figure" target="#fig_1">2</ref> and has mean</p><formula xml:id="formula_29">E[|m 1 − m 2 |] 0.023.</formula><p>We compute the sample size based on (10), using ̅̅̅̅̅̅̅̅̅̅̅ μ(1 −μ) √ to approximate s. The population size N is set based on the expected number of people who will visit the website over the deployment period. As an example, with N 100, 000, the optimal test size is n * 1 n * 2 2, 284 in each test group. The expected number of clicks is 3,106 in the test and 66,430 more when the better-performing treatment is deployed, for a total of 69,536 conversions. Following (12), this test will deploy the worse-performing web page 10.0% of the time, and this represents the optimal tradeoff with the opportunity cost of the test. The profitmaximizing test &amp; roll has expected regret of 0.22% relative to expected profit with perfect information 12 and achieves 90.7% of the potential gains over choosing randomly.</p><p>Figure <ref type="figure" target="#fig_2">3</ref> shows the overall expected conversion rate (in the test and roll phases combined) as a function of the test size. Because small tests rapidly improve the deployment decision and increase profits, practitioners should be encouraged to run small tests and act on them. Tests that are larger than optimal decrease the error rate marginally (Figure <ref type="figure" target="#fig_2">3(b)</ref>) but erode overall expected profit (Figure <ref type="figure" target="#fig_2">3</ref>(a)). Notice that the slope of expected profit falls more swiftly when sample sizes are suboptimal; a test is that is too large is preferable to one that is too small by the same amount.</p><p>Computing the profit-maximizing test size formula in (10) requires the user to specify a full prior distribution on the mean response for each arm, which requires the test designer to think about how the treatments will perform and can be informed by past data. By contrast, finding the recommended sample size for a hypothesis test following (2) requires selecting the minimum effect size to detect (d) and acceptable levels of Type I and Type II errors (α and β, respectively). This can be challenging; many test planners have difficulty defining Type I and Type II error, let alone estimating the costs of those two errors to set desired levels of α and β. There are numerous blog posts devoted to explaining how to apply hypothesis testing to A/B tests <ref type="bibr" target="#b13">(Gershoff 2017</ref><ref type="bibr" target="#b25">, Wortham 2018</ref>. In most applications, standard values of α 0.05 and To estimate a typical recommended sample size for a hypothesis test for this example, we use standard values for α and β and set d 0.68 × 0.02 0.0136 (i.e., a 2% lift). This value for d is the 25.1st percentile of the prior distribution of treatment effects implied by μ and σ. The resulting recommended sample size for a hypothesis test is 18,468 in each group (or 13,487 with a finite population correction), an order of magnitude larger than the profit-maximizing test size. This larger sample size is set to control Type I and Type II error tightly irrespective of the opportunity cost of the test, resulting in much larger sample sizes than are necessary to maximize expected profit. In this application, the oversized test reduces the remaining population that can receive the better treatment and results in 476 fewer expected conversions (see Figure <ref type="figure" target="#fig_2">3</ref> and Table <ref type="table" target="#tab_5">1</ref>).</p><p>Figures <ref type="figure" target="#fig_3">4(a</ref>)-(c) show the sensitivity of the profitmaximizing sample size to N, σ, and s. Panel (a) shows how the sample size scales with the population N, allowing marketers with lower-traffic websites or pages to appropriately size website A/B tests. Panel (b) shows how sample size grows linearly with the response noise s, unlike the recommended sample size for a null hypothesis test, which increases with s 2 . Panel (c) shows that when σ is larger, smaller test sizes are sufficient to detect treatments that, on average, perform substantially better than the alternative. <ref type="bibr">13</ref> To compare test &amp; roll to a multi-armed bandit, Table <ref type="table" target="#tab_5">1</ref> shows the expected conversions and relative regret for multi-armed bandit with Thompson sampling where units are allocated to treatments sequentially based on the posterior predictive probabilities that each treatment is best <ref type="bibr" target="#b24">(Thompson 1933)</ref>. See Appendix D for implementation details. The dynamic Thompson sampling algorithm produces 136 more conversions (in expectation) than a test &amp; roll with the optimal sample size. Both methods use a decision rule based on the same posterior, but the multi-armed bandit has more flexibility to recover from early observations that favor the wrong treatment. However, the difference is small: Thompson sampling achieves an expected relative regret of 0.03%, whereas test &amp; roll achieves 0.22%. For this example,  To provide guidance as to when a test &amp; roll and Thompson sampling are most comparable, we compute relative regret for both algorithms under a variety of conditions. For each condition, we simulated R 10, 000 sets of potential outcomes on which to compare algorithms. The resulting densities of relative regret are plotted in Figure <ref type="figure" target="#fig_4">5</ref>. In general, an optimized test &amp; roll has a wider distribution of regret with a longer right tail as a result of occasional deployment errors. Thompson sampling can recover from these errors and so achieves a tighter distribution of regret. The difference between algorithms is more pronounced when there are a greater number of treatment arms, where dynamic allocation provides a stronger advantage. As discussed in Section 3, the difference is also more pronounced when there is a moderate expected difference between treatments (governed by σ), which leads to a greater risk of deployment error for test &amp; roll. When σ is small, there is little to be gained by selecting the right treatment. When σ is large, the difference between treatments is large, and both algorithms will detect the better treatment. Thompson sampling performs remarkably well over a wide range of conditions, usually producing relative regret less than 1%. However, even in the worst conditions we test, the test &amp; roll has expected relative regret that is close to Thompson sampling, making it a reasonable alternative when there are high costs of implementing a dynamic algorithm or </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Display Advertising Testing</head><p>As a second example of a profit-maximizing test &amp; roll, we base priors on online display ad experiments reported by <ref type="bibr">Lewis and Rao (2015)</ref>. We focus on five experiments reported for "advertiser 1." Lewis and Rao (2015) report the mean and standard deviation of the sales response (in dollars) in the control group for each experiment (m 1 and s s 1 s 2 in our notation). Applying a hierarchical model to the reported summaries, we estimate m 1 ∼ 1(10.36, 4.40), and the standard deviation of response s is 103.77. See Appendix E for details.</p><p>Ideally, we would estimate a similar distribution for the treated group, creating asymmetric priors, but <ref type="bibr">Lewis and Rao (2015)</ref> do not report the treatment effects for these experiments. Instead, we assume the Notes. Parameters not varied are fixed at the website example N 100, 000, K 2, μ 0.63, s 0.466, and σ 0.03. Density plots are computed from R 10, 000 draws of potential outcomes. For K &gt; 2 treatments, we computed the test &amp; roll profit numerically for all possible sample sizes to find the optimum. Sometimes, the algorithm achieves profit higher than the ex ante expected value of perfect information, resulting in negative relative regret. profit per customer m 2 has the same prior distribution as m 1 . That is, on average the ads produce a lift that precisely covers the cost.</p><p>Assuming a total population size of N 1, 000, 000, the profit-maximizing sample size is n 1 n 2 11, 391. Even with this small test, the decision of whether to advertise to the remainder of the population is incorrect only 6.9% of the time. By contrast, these tests would require a sample size of 4,782,433 in each group for a standard hypothesis test to detect a difference of d 0.19 at α 0.05 and β 0.20. <ref type="bibr">14</ref> As Lewis and Rao (2015) point out, tests of this size are infeasible within the budget of most advertisers and the population available on most ad platforms. Even with a finite population correction, the sample size for a hypothesis test is 452,673, which results in substantially higher regret. A risk-neutral firm can reliably determine whether advertising is more profitable than not and maximize expected profits with far smaller tests. As can be seen by comparing (2) with (10), the difference in sample size is larger when s is large, as it is for the display advertising tests. Even if we cut the prior variance σ in half and increase the population to N 10, 000, 000, the profit-maximizing sample size only increases to n 1 n 2 234, 361, still half that required for a hypothesis test with finite population correction. Test sizes, profits, and error rates are summarized in Table <ref type="table" target="#tab_7">2</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Catalog Holdout Testing</head><p>Finally, we illustrate how asymmetric priors described in Section 4 lead to unequal test group sizes. We estimate priors based on 30 catalog holdout tests conducted by a specialty retailer. For each customer in each test, we observe all-channel sales (in dollars) in the month after the catalog is sent. Appendix E details how the data are used to estimate the distribution of mean catalog responses for the treated and holdout groups. Figure <ref type="figure">6</ref> shows the fitted priors for mean revenue per customer, which are 1(30.06, 13.48) for the treated groups and 1(19.39, 20.97) for the holdout groups. That is, we expect the customers who receive the catalog to purchase more. The standard deviation in response within a group is estimated at s 1 87.69 and s 2 179.36. After accounting for the cost of the media (approximately $0.80), 23.2% of catalog campaigns are expected to decrease profit based on the priors in Figure <ref type="figure">6</ref>. A test &amp; roll experiment can be used with future campaigns to prevent mailing to the entire list when it is unprofitable. Assuming a population size of N 100, 000, the profit-maximizing sample sizes are n * 1 588 (control) and n * 2 1, 884 (treated). An experiment with these sample sizes achieves expected total sales of $3,463,250. The recommended sample size for a hypothesis test to detect a 25% sales lift is 7,822 in the control group and 15,996 in the treated, <ref type="bibr">15</ref> resulting in a much larger test that achieves a lower expected profit of $3,287,412. Correcting for finite sampling reduces sample sizes to 6,317 (control) and 12,921 (treated) and improves overall profit slightly. These test plans are summarized in Table <ref type="table" target="#tab_8">3</ref>.</p><p>The profit-maximizing test and the null hypothesis test both allocate a larger sample to the treatment group, but for different reasons. The hypothesis test does so because the treatment group has a noisier response (s 1 &lt; s 2 ). The profit-maximizing test additionally considers that we a priori expect greater profits from customers who receive the catalog (m 1 &lt; m 2 ). Even if we fix s 1 s 2 and reestimate the hierarchical model (see Appendix E), the resulting test &amp; roll sample size is n 1 771 and n 2 1, 949, because of the remaining differences in the priors.</p><p>Figure <ref type="figure">7</ref> shows the sensitivity of the sample sizes to the expected catalog lift. We analyzed this sensitivity by varying µ 2 , leaving all other parameters of the priors fixed. As the plot shows, when the expected lift is very high, a small holdout group is optimal. Thus, the common practice of using small holdout tests can be rationalized by a prior expectation that the treatment increases sales (or other desired behavior) more than the cost of marketing. The test &amp; roll framework provides a principled way to set the size of the holdout group by making these priors explicit.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>We present a new approach to planning sample sizes for A/B tests. Unlike the classic hypothesis test that emphasizes high confidence and power, our approach optimally balances the trade-off between not deploying the best treatment in the roll stage and the cost of identifying this treatment in the test stage. The practical result is far smaller recommended test sizes that scale to the size of the available population. Most important, by focusing on profit, we show that marketers should not be discouraged from running smaller tests and acting on the findings; although imperfect, such smaller tests increase profit. Profit-maximizing tests may split the test sample unequally between the treatments, allowing us to rationalize this common practice in marketing experiments.</p><p>The profit-maximizing sample size is optimized for marketing campaigns, which typically have a limited target population. Direct marketing campaigns are conducted with finite mailing lists. Media campaigns have a fixed budget. Web pages have limited traffic. With finite populations, the firm should identify which treatment to deploy to the majority of the population without "wasting" too many exposures on suboptimal treatments in the test.  <ref type="bibr" target="#b6">(Bertsimas and Mersereau 2007</ref><ref type="bibr" target="#b10">, Chick and Frazier 2012</ref><ref type="bibr" target="#b19">, Schwartz et al. 2017</ref>) that vary allocation continuously, our method fits within the typical A/B testing framework and requires no changes in testing software other than the recommended sample size. Operational complexity is reduced by providing a definitive end to the test phase, limiting the number of alternative treatments that must be maintained and providing transparency about what treatment is being selected, what evidence led to the selection of this treatment, and what the expected benefit (or regret) is. Managers can interject if they wish before "rolling." These features make the profit-maximizing test &amp; roll attractive to marketers.</p><p>One limitation of our method is that the best treatment will not always be selected. Although the error rate may be higher than the one guaranteed by typical null hypothesis testing, the profit-maximizing test size sets the error rate optimally, based on the potential differences between treatments and resulting opportunity costs. In contexts where the decision maker is risk averse or the cost of deploying a subpar treatment is very high, as in clinical trials <ref type="bibr" target="#b5">(Berry et al. 1994</ref><ref type="bibr" target="#b9">, Cheng et al. 2003</ref>, then other approaches are warranted.</p><p>Further extensions of the test &amp; roll framework presented in Section 2 would be useful. As data from sets of experiments become available <ref type="bibr" target="#b3">(Bart et al. 2014</ref><ref type="bibr" target="#b15">, Johnson et al. 2017</ref>, there is opportunity to develop a catalog of priors for different test settings. Other forms of prior distributions could be considered. For example, <ref type="bibr" target="#b22">Stallard et al. (2017)</ref> extend the test &amp; roll framework to response distributions from the exponential family using approximations. <ref type="bibr" target="#b2">Azevedo et al. (2019)</ref> focus on priors with fat tails.</p><p>The test &amp; roll method is easily extended to more than two treatments, potentially allowing for correlated priors (e.g., for a holdout group versus several alternative marketing treatments). The cost of switching between treatments, which can be substantial for offline marketing treatments, could also be incorporated into the decision problem. If it is possible to deploy different treatments to subpopulations, then the potential to identify heterogeneous treatment effects <ref type="bibr" target="#b14">(Hitsch and</ref><ref type="bibr">Misra 2018, Simester et al. 2019</ref>) can be considered in the test design. Similarly, time dependency in response could be considered (e.g., day-ofweek or "novelty" effects). These extensions all fit naturally within the test &amp; roll framework.</p><p>Proposition A.1 (Expected Roll Stage Profit). When the mean profit y j is distributed y j ∼ 1(m j , s 2 j /n j ) with prior m j ∼ 1(μ j , σ 2 j ), and when the decision rule picks the arm with the highest posterior mean, the expected profit in the roll stage is</p><formula xml:id="formula_30">E[Π D ] N − n 1 − n 2 ( ) × ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ σ 4 1 σ 2 1 + s 2 1 /n 1 + σ 4 2 σ 2 2 + s 2 2 /n 2 √ φ μ 1 − μ 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ σ 4 1 σ 2 1 +s 2 1 /n1 + σ 4 2 σ 2 2 +s 2 2 /n2 √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ + (μ 1 − μ 2 )Φ μ 1 − μ 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ σ 4 1 σ 2 1 +s 2 1 /n1 + σ 4 2 σ 2 2 +s 2 2 /n2 √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦ . (A.1) Proof. Denote the decision rule δ(y 1 , y 2 ) as I(a 1 + b 1 y 1 &gt; a 2 + b 2 y 2 ).</formula><p>The linear decision rule includes the optimal one that uses the posterior predictive distribution with a j s 2 j /njμj σ 2 j +s 2 j /nj and b j σ 2 j σ 2 j +s 2 j /nj . Denote the pdf of y j as f j and its cdf as F j . Denote the pdf of m j as g j and its cdf as G j .</p><p>The expected value from the roll stage is</p><formula xml:id="formula_31">E Π D [ ] ∫ m1 ∫ m2 ∫ y1 ∫ y2 N − n 1 − n 2 ( ) × δ y 1 , y 2 ( ) m 1 + 1 − δ y 1 , y 2 ( ) ( ) m 2 ( ) f 2 y 2 ( ) f 1 y 1 ( ) × g 2 m 2 ( )g 1 m 1 ( )dy 2 dy 1 dm 2 dm 1 . (A.2)</formula><p>In the derivation, we will make multiple uses of the following identities:</p><formula xml:id="formula_32">∫ ∞ −∞ yΦ y + b a ( ) φ y ( ) dy 1 ̅̅̅̅̅̅̅̅ a 2 + 1 √ φ b ̅̅̅̅̅̅̅̅ a 2 + 1 √ ( ) (A.3) and ∫ ∞ −∞ Φ y + b a ( ) φ y ( ) dy Φ b ̅̅̅̅̅̅̅̅ a 2 + 1 √ ( ) . (A.4)</formula><p>The expression (N − n 1 − n 2 ) can be taken out of the integrand. Continuing with the first additive in the integral (the second will be symmetric),</p><formula xml:id="formula_33">∫ y1 ∫ y2 δ y 1 , y 2 ( ) m 1 f 2 y 2 ( ) f 1 y 1 ( ) dy 1 dy 2 (A.5) ∫ y1 ∫ a 1 −a 2 +b 1 y 1 b 2 −∞ m 1 f 2 y 2 ( ) f 1 y 1 ( ) dy 1 dy 2 (A.6) m 1 ∫ y1 F 2 a 1 − a 2 + b 1 y 1 b 2 ( ) f 1 y 1 ( ) dy 1 (A.7) m 1 ∫ y1 Φ a1−a2+b1y1 b2 − m 2 s 2 / ̅̅̅ n 2 √ ( ) 1 s 1 / ̅̅̅ n 1 √ φ y 1 − m 1 s 1 / ̅̅̅ n 1 √ ( ) dy 1 (A.8) m 1 ∫ y Φ y + a1−a2+b1m1−b2m2 b1s1/ ̅̅ ̅ n1 √ b2s2/ ̅̅ ̅ n2 √ b1s1/ ̅̅ ̅ n1 √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ φ y ( ) dy. (A.9)</formula><p>The last equation uses y y1−m1 s1/ ̅̅ ̅ n1 √ as a change of variables. Using identity (A.4), the final integral equals</p><formula xml:id="formula_34">m 1 ∫ y Φ y + a1−a2+b1m1−b2m2 b1s1/ ̅̅ ̅ n1 √ b2s2/ ̅̅ ̅ n2 √ b1s1/ ̅̅ ̅ n1 √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ φ y ( ) dy (A.10) m 1 Φ a 1 − a 2 + b 1 m 1 − b 2 m 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ b 2 1 s 2 1 /n 1 + b 2 2 s 2 2 /n 2 √ ( ) . (A.11)</formula><p>Plugging back into the expected value in (A.2), the expected value of the roll stage equals</p><formula xml:id="formula_35">N − n 1 − n 2 ( ) ∫ m1 ∫ m2 m 1 Φ a 1 − a 2 + b 1 m 1 − b 2 m 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ b 2 1 s 2 1 /n 1 + b 2 2 s 2 2 /n 2 √ ( ) ( × g 2 m 2 ( )g 1 m 1 ( )dm 1 dm 2 + ∫ m2 ∫ m1 m 2 Φ a 2 − a 1 + b 2 m 2 − b 1 m 1 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ b 2 1 s 2 1 /n 1 + b 2 2 s 2 2 /n 2 √ ( ) × g 1 m 1 ( )g 2 m 2 ( )dm 1 dm 2 ) .</formula><p>(A.12)</p><p>Using identity (A.4) again, the first additive equals</p><formula xml:id="formula_36">∫ m1 ∫ m2 m 1 Φ a 1 − a 2 + b 1 m 1 − b 2 m 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ b 2 1 s 2 1 /n 1 + b 2 2 s 2 2 /n 2 √ ( ) g 2 m 2 ( )g 1 m 1 ( )dm 1 dm 2 (A.13) ∫ m1 m 1 ∫ m 1 − Φ m + a2−a1−b1m1+b2μ2 b2σ2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ ̅ b 2 1 s 2 1 /n1+b 2 2 s 2 2 /n2 √ b2σ2 ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ φ m ( )dmg 1 m 1 ( )dm 1 (A.14) ∫ m1 m 1 Φ a 1 − a 2 + b 1 m 1 − b 2 μ 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ b 2 1 s 2 1 /n 1 + b 2 2 s 2 2 /n 2 + b 2 2 σ 2 2 √ ( ) 1 σ 1 φ m 1 − μ 1 σ 1 ( ) dm 1 (A.15) ∫ m mσ 1 + μ 1 ( ) Φ m + a1−a2+b1μ1−b2μ2 b1σ1 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ b 2 1 s 2 1 /n1+b 2 2 s 2 2 /n2+b 2 2 σ 2 2 b 2 1 σ 2 1 √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ φ m ( )dm, (A.16)</formula><p>where the last equation uses the change of variables m m1−μ1 σ1 . Using identities (A.3) and (A.4), we receive</p><formula xml:id="formula_37">∫ m mσ 1 + μ 1 ( ) Φ m + a1−a2+b1μ1−b2μ2 b1σ1 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ b 2 1 s 2 1 /n1+b 2 2 s 2 2 /n2+b 2 2 σ 2 2 b 2 1 σ 2 1 √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ φ m ( )dm (A.17) b 1 σ 2 1 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ b 2 1 s 2 1 /n 1 + b 2 2 s 2 2 /n 2 + b 2 1 σ 2 1 + b 2 2 σ 2 2 √ × φ a 1 − a 2 + b 1 μ 1 − b 2 μ 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ b 2 1 s 2 1 /n 1 + b 2 2 s 2 2 /n 2 + b 2 1 σ 2 1 + b 2 2 σ 2 2 √ ( ) + μ 1 Φ a 1 − a 2 + b 1 μ 1 − b 2 μ 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ b 2 1 s 2 1 /n 1 + b 2 2 s 2 2 /n 2 + b 2 1 σ 2 1 + b 2 2 σ 2 2 √ ( ) . (A.18)</formula><p>Using symmetry, the a priori expected value of the roll stage is</p><formula xml:id="formula_38">E Π D [ ] N − n 1 − n 2 ( ) b 1 σ 2 1 + b 2 σ 2 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ b 2 1 s 2 1 /n 1 + b 2 2 s 2 2 /n 2 + b 2 1 σ 2 1 + b 2 2 σ 2 2 √ [ × φ a 1 − a 2 + b 1 μ 1 − b 2 μ 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ b 2 1 s 2 1 /n 1 + b 2 2 s 2 2 /n 2 + b 2 1 σ 2 1 + b 2 2 σ 2 2 √ ( ) + (μ 1 − μ 2 )Φ a 1 − a 2 + b 1 μ 1 − b 2 μ 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ b 2 1 s 2 1 /n 1 + b 2 2 s 2 2 /n 2 + b 2 1 σ 2 1 + b 2 2 σ 2 2 √ ( ) ] . (A.19)</formula><p>Plugging in the posterior mean parameters for a j and b j (as they are optimal), the roll stage expected value in the fully asymmetric model is</p><formula xml:id="formula_39">E[Π D ] (N − n 1 − n 2 ) × ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ σ 4 1 σ 2 1 + s 2 1 /n 1 + σ 4 2 σ 2 2 + s 2 2 /n 2 √ φ μ 1 − μ 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ σ 4 1 σ 2 1 +s 2 1 /n1 + σ 4 2 σ 2 2 +s 2 2 /n2 √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ + (μ 1 − μ 2 )Φ μ 1 − μ 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ σ 4 1 σ 2 1 +s 2 1 /n1 + σ 4 2 σ 2 2 +s 2 2 /n2 √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦ , (A.20)</formula><p>where in the text we set e μ 1 − μ 2 and</p><formula xml:id="formula_40">v ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ σ 4 1 σ 2 1 + s 2 1 /n 1 + σ 4 2 σ 2 2 + s 2 2 /n 2 √</formula><p>in Equation ( <ref type="formula" target="#formula_26">18</ref>). Thus we have completed the proof for the asymmetric case.</p><p>To get the expression in (9), we plug in μ 1 μ 2 μ, σ 1 σ 2 σ and s 1 s 2 s into the above expression. □ Proposition A.2 (Profit-Maximizing Sample Size). When the mean profits y j are distributed y j ∼ 1(m j , s 2 /n j ) with prior m j ∼ 1(μ, σ 2 ), the profit-maximizing sample size is</p><formula xml:id="formula_41">n * 1 n * 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ ̅ N 4 s σ ( ) 2 + 3 4 s σ ( ) 2 ( ) 2 √ − 3 4 s σ ( ) 2 .</formula><p>Proof. Because the priors are symmetric, the optimal sample sizes will be equal. Denote them as n n 1 n 2 .</p><p>The expected profit of the experiment with symmetric priors is</p><formula xml:id="formula_42">E[Π T ] + E[Π D ] Nμ + (N − 2n) ̅̅ 2 √ σ 2 ̅̅ ̅ π √ ̅̅̅̅̅̅̅̅̅̅̅̅̅ ̅ 2σ 2 + 2 n s 2 √ ⎡ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎢ ⎣ ⎤ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎥ ⎦ . (A.21)</formula><p>The first-order condition with respect to n is</p><formula xml:id="formula_43">σ 2 ̅̅̅̅̅̅̅̅ ̅ s 2 n + σ 2 √ 4n 2 σ 2 + 6ns 2 − Ns 2 ( ) 2 ̅̅ ̅ π √ nσ 2 + s 2 ( ) 2 0,<label>(40)</label></formula><p>which is equivalent to solving 4n 2 σ 2 + 6ns 2 − Ns 2 0, yielding the optimal sample size formula. □ </p><formula xml:id="formula_44">E[Pr(δ(y 1 , y 2 ) 1|m 1 &lt; m 2 )] and E[Pr(δ(y 1 , y 2 ) 0|m 1 &gt; m 2 )], both equal 1 4 − 1 2π arctan ̅̅ 2 √ σ s ̅̅̅̅̅̅̅̅̅̅ n 1 n 2 n 1 + n 2 √ ( ) .</formula><p>Proof. Using the fact that y j ∼ 1(m j , s 2 /n j ), and because in the symmetric case the decision rule is to pick the treatment with the highest mean,</p><formula xml:id="formula_45">Pr δ y 1 , y 2 ( ) 1|m 1 , m 2 ( ) Pr y 1 − y 2 &gt; 0|m 1 , m 2 ( ) Φ m 1 − m 2 s ̅̅̅̅̅̅̅̅ 1 n1 + 1 n2 √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ . (A.22)</formula><p>If we let m m 1 − m 2 , then m has a prior 1(0, 2σ 2 ). The expected error rate is therefore</p><formula xml:id="formula_46">E δ y 1 , y 2 ( ) 1|m 1 &gt; m 2 [ ] ∫ 0 −∞ Pr y 1 − y 2 &gt; 0|m ( ) Pr m ( )dm ∫ 0 −∞ Φ m s ̅̅̅̅̅̅̅̅ 1 n1 + 1 n2 √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ 1 ̅̅ 2 √ σ φ m ̅̅ 2 √ σ ( ) dm. (A.23) Using the identity ∫ 0 −∞ φ(ax)Φ(bx)dx 1 2π|a| π 2 − arctan b |a| ( ) ( ) ,</formula><p>we get the following expression:</p><formula xml:id="formula_47">E[δ y 1 , y 2 ( ) 1|m 1 &gt; m 2 ] E[δ y 1 , y 2 ( ) 0|m 1 &lt; m 2 ] 1 4 − 1 2π arctan ̅̅ 2 √ σ s ̅̅̅̅̅̅̅̅̅̅ n 1 n 2 n 1 + n 2 √ ( )</formula><p>. □ Proposition A.4 (Regret). In the symmetric Normal-Normal model with a population size N, we have the following:</p><formula xml:id="formula_48">(1) The expected value of perfect information is E[Π|PI] N(μ + σ ̅̅ π √ ). (2) The regret of the profit-maximizing design is O( ̅̅̅ N √</formula><p>).</p><p>(3) The regret from using a classic hypothesis test is Ω(N).</p><p>Proof. Perfect information allows the marketer to pick the treatment with the highest mean m j without testing, yielding an expected profit of N • E[max(m 1 , m 2 )]. Because both treatments come from the same prior 1(μ, σ 2 ), the mean of the maximum of two independent and identically distributed Normal variables is μ + σ ̅̅ π √ , proving the first item. To prove the second item, we calculate the regret from using the profit-maximizing design:</p><formula xml:id="formula_49">E[Π|PI] -E Π * D + Π * T [ ] N σ ̅̅ ̅ π √ 1 − σ ̅̅̅̅̅̅̅̅̅ σ 2 + s 2 n * √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ + 2n * σ 2 ̅̅ ̅ π √ ̅̅̅̅̅̅̅̅̅ σ 2 + s 2 n * √ . (A.24)</formula><p>Applying the inequality</p><formula xml:id="formula_50">̅̅̅̅̅̅̅ x + 1 √ − ̅̅ x √ &lt; 1 2 ̅ ̅ x √ for x &gt; 0, to n * σ 2 /s 2 , the first additive results in N σ ̅̅ ̅ π √ 1 − σ ̅̅̅̅̅̅̅̅̅ σ 2 + s 2 n * √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ (A.25) ≤ N σ ̅̅ ̅ π √ 1 2 ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ σ 2 n * /s 2 + 1 √ ̅̅̅̅̅̅̅̅̅̅ σ 2 n * /s 2 √ (A.26) ≤ N σ ̅̅ ̅ π √ 1 2n * σ 2 /s 2 . (A.27) Plugging in n * ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ N 4 ( s σ ) 2 + ( 3 4 ( s σ ) 2 ) 2 √ − 3 4 ( s σ ) 2 , the denominator 2n * σ 2 /s 2 is larger than 1 2 σ s ̅̅̅ N √ when N &gt; 4 s 2 σ 2 .</formula><p>Hence, we can bound the first additive in the regret (A.24) from above by</p><formula xml:id="formula_51">N σ ̅̅ ̅ π √ 1 − σ ̅̅̅̅̅̅̅̅̅ σ 2 + s 2 n * √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ ≤ 2s ̅̅̅ N √ ̅̅ ̅ π √ . (A.28)</formula><p>To bound the second additive,</p><formula xml:id="formula_52">2n * σ 2 ̅̅ ̅ π √ ̅̅̅̅̅̅̅̅̅ σ 2 + s 2 n * √ ≤ 2n * σ 2 ̅̅ ̅ π √ ̅̅̅ σ 2 √ 2n * σ ̅̅ ̅ π √ &lt; s ̅̅̅ N √ ̅̅ ̅ π √ . (A.29)</formula><p>The first inequality uses the fact that s 2 n * is positive, whereas the second uses the fact that n * &lt; ̅̅̅ N √ s 2σ , as shown in Section 3. Summing the two additives shows that the regret of the profit-maximizing design is smaller than 3s</p><formula xml:id="formula_53">̅̅ N √ ̅̅ π √ , proving the second item, that the regret is O( ̅̅̅ N √</formula><p>). To prove the third item, we plug in the sample size from (2) for n in the regret formula:</p><formula xml:id="formula_54">E Π|PI [ ]− E Π D + Π T [ ] N σ ̅̅ ̅ π √ 1 − σ ̅̅̅̅̅̅̅̅ ̅ σ 2 + s 2 n √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ + 2nσ 2 ̅̅ ̅ π √ ̅̅̅̅̅̅̅̅ ̅ σ 2 + s 2 n √ (A.30) &gt; N σ ̅̅ ̅ π √ 1 − σ ̅̅̅̅̅̅̅̅ ̅ σ 2 + s 2 n √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ N σ ̅̅ ̅ π √ 1 − σ ̅̅̅̅̅̅̅̅̅̅ σ 2 + δ 2 2z 2 √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ (A.31) &gt; N σ ̅̅ ̅ π √ 1 2 2z 2 σ 2 δ 2 + 1 ( ) Ω N ( ), (A.32)</formula><p>where the equality in (A.31) follows from plugging in the null hypothesis significance testing (NHST) sample size denoting z z (1−α)/2 + z β , and the last inequality follows from</p><formula xml:id="formula_55">̅̅̅̅̅̅̅ x + 1 √ − ̅̅ x √ &gt; 1 2 ̅̅̅̅ x+1 √ when x ≥ 0, with x nσ 2 /s 2 .</formula><p>When using the sample size for the NHST with finite population correction, we can use the same approach where in Equation (A.31) we plug in n </p><formula xml:id="formula_56">(z 1−α/2 +zβ) 2 2s 2 N (N−1)d 2 +4s 2 (z 1−α/2 +zβ) 2 .</formula><formula xml:id="formula_57">E Π|PI [ ]− E Π D + Π T [ ] N σ ̅̅ ̅ π √ 1 − σ ̅̅̅̅̅̅̅̅ ̅ σ 2 + s 2 n √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ + 2nσ 2 ̅̅ ̅ π √ ̅̅̅̅̅̅̅̅ ̅ σ 2 + s 2 n √ (A.33) &gt; N σ ̅̅ ̅ π √ 1 − σ ̅̅̅̅̅̅̅̅ ̅ σ 2 + s 2 n √ ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ &gt; N σ ̅̅ ̅ π √ 1 2 nσ 2 s 2 + 1 ( ) (A.34) N σ ̅̅ ̅ π √ 1 2 2Nz 2 σ 2 N − 1 ( )d 2 + 4z 2 s 2 + 1 ( ) &gt; N σ ̅̅ ̅ π √ 1 2 2Nz 2 σ 2 N − 1 ( )d 2 + 1 ( ) (A.35) &gt; N σ ̅̅ ̅ π √ 1 2 2Nz 2 σ 2 1/2Nd 2 + 1 ( ) N σ ̅̅ ̅ π √ 1 2 4z 2 σ 2 d 2 + 1 ( ) Ω N ( ). (A.36) □</formula><p>The last inequality follows from the fact that 1/2N ≤ N − 1 for N ≥ 2, which completes the proof.</p><p>Corollary A.5 (Maximum Relative Regret). There is an intermediate value of σ for which the profit-maximizing test &amp; roll achieves the maximum relative regret.</p><p>Proof. The relative regret at the optimal sample size equals ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅</p><formula xml:id="formula_58">4Nσ 2 + 9s 2 √ − 3s ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ ̅ 4Nσ 2 + 9s 2 + s √ √ s ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ 4Nσ 2 + 9s 2 √ −<label>3s</label></formula><formula xml:id="formula_59">( ) ( + 2σ ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ N s ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ 4Nσ 2 + 9s 2 √ +<label>3s</label></formula><formula xml:id="formula_60">( ) + Nσ 2 ( ) √ − Nσ ( ) ) 2Nσ ̅̅ ̅ π √ μ + σ ( ) .</formula><p>Using L'Hôpital's rule, the limit as σ → 0 is 0. Similarly, the limit as σ → ∞ is 0. The relative regret is always positive. Consequently, the relative regret achieves a maximum for a value of σ, which is not 0 or infinity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. Derivations for Beta-Binomial Model</head><p>Let the profit y ij from customer i exposed to treatment arm j be v j with probability p j and 0 with probability 1 − p j , and let y j ∑n j i 1 yij nj be the average conversion rate with treatment j, when n j is the number of individuals assigned to treatment j. We put a Beta(α, β) prior distribution on p j and denote its pdf as f (•). Proposition B.1 (Beta-Binomial Expected Profit). If profit y ij from customer i exposed to treatment j is v j with probability p j and 0 otherwise, with priors p j ∼ Beta(α, β),</p><p>(1) the expected profit in the test stage is</p><formula xml:id="formula_61">(n 1 v 1 + n 2 v 2 ) α α+β ; (2) the expected profit in the roll stage is N − n 1 − n 2 ( ) ∑ n2 y2 1 n 2 y 2 ( ) Γ y 2 + α ( ) Γ n 2 − y 2 + β ( ) B α, β ( ) Γ n 2 + α + β ( ) × ∑ n1 y1 ỹ 1 n 1 y 1 ( ) Γ y 1 + α ( ) Γ n 1 − y 1 + β ( ) B α, β ( ) Γ n 1 + α + β ( ) v 1 α + y 1 α + β + n 1 ( + ∑ y1−1 y1 0 n 1 y 1 ( ) Γ y 1 + α ( ) Γ n 1 − y 1 + β ( ) B α, β ( ) Γ n 1 + α + β ( ) v 2 α + y 2 α + β + n 2 ) , (B.1) withỹ 1 α v 2 v 1 α + β + n 1 α + β + n 2 − 1 ( ) + y 2 v 2 v 1 α + β + n 1 α + β + n 2 ( ) .</formula><p>Proof. To prove the first item, the expected profit in the test stage is</p><formula xml:id="formula_62">E π T [ ] ∫ p1 ∑ n1 y1 0 v 1 y 1 Pr y 1 |p 1 ( ) f p 1 ( ) dp 1 + ∫ p2 ∑ n2 y2 0 v 2 y 2 Pr y 2 |p 2 ( ) f p 2 ( ) dp 2 . (B.2)</formula><p>Because ∑n j yj 0 y j Pr(y j |p j ) n j p j , then</p><formula xml:id="formula_63">∫ p1 ∑ n1 y1 0 y 1 Pr(y 1 |p 1 ) • f (p 1 )dp 1 n j α</formula><p>α+β , and plugging this in yields the expression in the proposition.</p><p>The prove the second item, the a priori expected profit in the roll stage is</p><formula xml:id="formula_64">N − n 1 − n 2 ( ) ∫ p2 ∫ p1 ∑ n1 y1 1 ∑ n2 y2 1 δ y 1 , y 2 ( ) p 1 v 1 + 1 − δ y 1 , y 2 ( ) ( ) p 2 v 2 [ ] × Pr y 2 |p 2 ( ) Pr y 1 |p 1 ( ) f p 1 ( ) f p 2 ( ) dp 1 dp 2 . (B.3)</formula><p>Focusing on the first additive (the second will be symmetric because of the symmetric prior), it can be written as</p><formula xml:id="formula_65">N − n 1 − n 2 ( ) v 1 ∫ p2 ∫ p1 ∑ n1 y1 1 ∑ n2 y2 1 δ y 1 , y 2 ( ) Pr y 2 |p 2 ( ) × Pr y 1 |p 1 ( ) p 1 f p 1 ( ) f p 2 ( ) dp 1 dp 2 . (B.4)</formula><p>The optimal decision rule δ(y 1 , y 2 ) is to pick the treatment with the highest expected posterior profit v j E[p j |y j ] v j α+yj α+β+nj , resulting from the fact that the profits are binomially distributed with a Beta prior. Hence, by lettingỹ 1 α( v2</p><formula xml:id="formula_66">v1 α+β+n1 α+β+n2 − 1) + y 2 ( v2 v1 α+β+n1 α+β+n2</formula><p>), and by applying Fubini's theorem, we can rewrite (B.4) as</p><formula xml:id="formula_67">N − n 1 − n 2 ( ) v 1 ∑ n2 y2 1 ∑ n1 y1 ỹ 1 ∫ p2 Pr y 2 |p 2 ( ) f p 2 ( ) dp 2 × ∫ p1 p 1 f p 1 ( ) Pr y 1 |p 1 ( ) dp 1 . (B.5)</formula><p>The derivation above assumes that if the expected posterior profit of both treatments is equal, then treatment 1 is chosen as a tiebreaking rule. We will show that this tiebreaking rule does not change the result if we opt for another rule (e.g., pick treatment 2 if tied, or pick one randomly).</p><p>Using Bayes rule, Pr(y j |p j )f (p j ) Pr(y j )f (p j |y j ). This implies that</p><formula xml:id="formula_68">∫ p2 Pr y 2 |p 2 ( ) f p 2 ( ) dp 2 Pr y 2 ( ) , (B.6) ∫ p1 p 1 f p 1 ( ) Pr y 1 |p 1 ( ) dp 1 Pr y 1 ( ) α + y 1 α + β + n 1 . (B.7)</formula><p>The second equation stems from the fact that f (p 1 |y 1 ) is the pdf of a Beta(α + y 1 , β + n 1 − y 1 ) distribution. </p><formula xml:id="formula_69">( ) ∫ 1 pj 0 Pr y j |p j ( ) f p j ( ) dp j n j y j ( ) Γ y j + α ( ) Γ n j − y j + β ( ) B α, β ( ) Γ n j + α + β ( ) .</formula><p>(B.8)</p><p>Plugging into (B.5), the total roll stage profit is</p><formula xml:id="formula_70">N − n 1 − n 2 ( ) ∑ n2 y2 1 n 2 y 2 ( ) Γ y 2 + α ( ) Γ n 2 − y 2 + β ( ) B α, β ( ) Γ n 2 + α + β ( ) × ∑ n1 y1 ỹ 1 n 1 y 1 ( ) Γ y 1 + α ( ) Γ n 1 − y 1 + β ( ) B α, β ( ) Γ n 1 + α + β ( ) v 1 α + y 1 α + β + n 1 ( + ∑ y1−1 y1 0 n 1 y 1 ( ) Γ y 1 + α ( ) Γ n 1 − y 1 + β ( ) B α, β ( ) Γ n 1 + α + β ( ) v 2 α + y 2 α + β + n 2 ) . (B.9)</formula><p>If there is a tie such that v 1 α+y1 α+β+n1 v 2 α+y2 α+β+n2 , it does not matter if we take the left or the right additive within the parentheses. Hence, any tiebreaking rule will yield an equivalent profit. □ To design a test for binomial experiment, the expected profit from Proposition B.1 can be numerically optimized, using a discrete optimization heuristic. However, because the Normal-Normal model is more computationally convenient, it can be used to approximate the beta-binomial using the usual binomial approximation:</p><formula xml:id="formula_71">μ α α+β , s ̅̅̅̅̅̅̅̅̅̅̅ μ(1 − μ) √ ,<label>and</label></formula><formula xml:id="formula_72">σ ̅̅̅̅̅̅̅̅̅̅̅̅̅̅ ̅ αβ (α+β) 2 (α+β+1) √ . Figure B</formula><p>.1 shows that this approximation results in nearly the same sample size except when the response rate μ is close to 0 (or equivalently, close to 1) and the prior is relatively informative (prior precision = α + β &gt; 100) .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C. Asymmetric Tests</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>C.1. Incumbent Challenger Test</head><p>In an incumbent/challenger test, more is known about one treatment than the other. Denote σ 2 cσ 1 with c &gt; 1. To analyze this scenario in closed form, we will assume that μ 1 μ 2 and that s 1 s 2 s, although the solution can be found numerically for any set of values. Because the uncertainty is larger for treatment 2, it is always the case that n * 2 &gt; n * 1 in an incumbent/challenger test. When the population size is small enough, it is too wasteful to experiment with treatment 1, and the test will only include exposures to treatment 2. After this test phase, comparisons will be made to the prior on treatment 1 to select which treatment to deploy. This is shown formally in Proposition C.1.</p><p>Proposition C.1 (Incumbent/Challenger Sample Sizes). In an asymmetric test when treatment 1 is an incumbent and treatment 2 is a challenger such that μ 1 μ 2 , s 1 s 2 s, and σ 2 c • σ 1 , with c &gt; 1, (1) the optimal sample sizes are</p><formula xml:id="formula_73">n * 1 s ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ 2c 2 c 2 + 1 ( )Nσ 2 1 + 2c 4 + 5c 2 + 2 ( ) s 2 √ ( − cs(1 + 2c 2 ) ) 2 c 3 + c ( )σ 2 1 , (C.1) n * 2 s c ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ 2c 2 c 2 + 1 ( )Nσ 2 1 + 2c 4 + 5c 2 + 2 ( ) s 2 √ ( − c 2 + 2 ( ) s ) 2c 2 c 2 + 1 ( )σ 2 1 ; (C.2)</formula><p>(2) n * 2 &gt; n * 1 for any value of N, s, c &gt; 1, and σ; and (3) n * 2 &gt; 0 for any value of N, s, c &gt; 1, and σ, and</p><formula xml:id="formula_74">n * 1 &gt; 0 ⇐⇒ N &gt; 2c 4 −c 2 −1 ( ) s 2 c 2 σ 2 1 .</formula><p>Proof. Plugging μ 1 μ 2 μ, s 1 s 2 s, and σ 2 cσ 1 into the expected profit derived in Proposition A.1, the expected profit in an incumbent/challenger experiment is</p><formula xml:id="formula_75">Nμ + (N − n 1 − n 2 ) v ̅̅̅̅ 2π √ , with v ̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅̅ σ 4 1 σ 2 1 + s 2 /n 1 + c 4 σ 4 1 c 2 σ 2 1 + s 2 /n 2 √ .</formula><p>After simplifying and rearranging, the first-order conditions for finding the optimal n 1 and n 2 are</p><formula xml:id="formula_76">− s 2 (−N + n 1 + n 2 ) n 1 σ 2 1 + s 2 ( ) 2 2 c 4 n 2 c 2 n 2 σ 2 1 + s 2 + n 1 n 1 σ 2 1 + s 2 ( ) , (C.3) c 4 s 2 (N − n 1 − n 2 ) c 2 n 2 σ 2 1 + s 2 ( ) 2 2 c 4 n 2 c 2 n 2 σ 2 1 + s 2 + n 1 n 1 σ 2 1 + s 2 ( ) .</formula><p>(C.4) Dividing the two equations and solving for n 1 , the only possible solution such that n * 1 &gt; 0 for some values is n *</p><formula xml:id="formula_77">1 c 2 n2σ 2 1 −c 2 s 2 +s 2 c 2 σ 2 1</formula><p>. Plugging this into Equation (C.4) yields the expression in the proposition, proving the first item.</p><p>To prove the second item, the inequality n * 2 − n * 1 &gt; 0 can be written as</p><formula xml:id="formula_78">n * 2 − n * 1 ( )2σ 2 1 c 2 1 + c 2 ( ) s 2 c 4 − 1 ( ) s &gt; 0, (C.5)</formula><p>which always holds because c &gt; 1.</p><p>To prove the third item, we solve for n * 2 &gt; 0, which holds for the described parameter values, and n * 1 &gt; 0, which holds if and only if N &gt; Thompson sampling <ref type="bibr" target="#b24">(Thompson 1933)</ref> has recently become the prominent heuristic for solving multi-armed bandit problems, because of its superior performance and ease of implementation <ref type="bibr" target="#b20">(Scott 2010</ref><ref type="bibr" target="#b19">, Schwartz et al. 2017</ref>. Here, we describe the Thompson sampling algorithm we use, which is the standard implementation applied to the Normal symmetric model. Opportunities to apply the treatment are assumed to come in one at a time for each i 1, . . . , N. Under the symmetric Normal model, treatment j generates outcomes y ji drawn from 1(m j , s 2 ).</p><p>The algorithm is initialized with priors m j ∼ 1(μ j (0), σ 2 j (0)). For each i, the algorithm makes a dynamic decision whether to deploy treatment 1 or treatment 2 as follows:</p><p>1. Draw a mean m 1 (i) from 1(μ 1 (i − 1), σ 2 1 (i − 1)) and m 2 (i) from 1(μ 2 (i − 1), σ 2 2 (i − 1)). 2. If m 1 (i) &gt; m 2 (i), treatment 1 is deployed. Otherwise, treatment 2 is deployed.</p><p>3. Either y 1i or y 2i is observed based on the decision. In simulation, y ji is drawn from its true distribution 1(m j , s 2 ).</p><p>4. The hyperparameters μ j (i) and σ 2 j (i) are updated given the new data. If treatment j was not deployed, the hyperparameters at time i equal those at time i − 1. If the treatment was deployed, the hyperparameters are calculated as the posterior of the Normal distribution, with the observed outcome used as data and the hyperparameters from period i − 1 used for the prior.</p><p>Thus, treatments are probabilistically sampled according to the current probability that each treatment is best; that is, treatment 1 is sampled at the rate of Pr(μ 1 (i) &gt; μ 2 (i)). This rule favors treatments with higher expected response, and as a result, the algorithm will quickly converge to the bestperforming treatment as data accumulate. However, it also is also more likely to sample treatments with higher uncertainty, because of the high potential upside for those treatments, which helps to avoid converging to the wrong treatment.</p><p>The explicit explore versus exploit trade-off in a multiarmed bandit is similar to the trade-off between the size of the test sample and the remaining population in a test &amp; roll, albeit more dynamic. The dynamic approach works better when opportunities to apply the treatment are spread out over time and the desired response is immediately available (e.g., website tests where the response is a click), but it can be difficult to execute when the response is not immediately observable (e.g., sales) or when the treatments are sent out in batches (e.g., direct mail). <ref type="bibr" target="#b0">Agrawal and Goyal (2013)</ref> have shown that the regret from Thompson sampling with Normal outcomes and Normal priors is O( ̅̅̅ N √ ). This has been shown before to be the best achievable regret for any dynamic multi-armed bandit approach when compared with having perfect information, and hence Thompson sampling is an ideal benchmark for comparison.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix E. Application Details</head><p>If a firm has data on response to prior marketing treatments that are similar to those that will be tested, these data can be used to estimate the distribution of mean response needed to compute the test &amp; roll sample size. For example, if the firm has past data on response y ij for each customer i in each of the j 1, . . . , J previous marketing campaigns, then we can fit a hierarchical model:</p><formula xml:id="formula_79">y ij ∼ 1 m j , s ( ) for observations i 1, . . . , N j in campaigns j 1, . . . , J, (E.1) m j ∼ 1 μ, σ ( ) in campaigns j 1, . . . , J. (E.2)</formula><p>Estimates of μ and σ can be plugged into (10) to compute the test &amp; roll sample size. For binary responses with small samples, we could estimate a similar beta-binomial model. The campaigns j can be defined by a particular period of time when a marketing treatment was in place and the response was stable, such as response rates to direct marketing campaigns or customers visiting a website in a particular month. The key assumption is that these prior campaigns represent the range of likely mean responses for the treatments in the test that is being planned. We provide more details for specific applications in Sections E.1, E.2, and E.3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.1. Website Testing Example</head><p>The data on website tests are adopted from <ref type="bibr">Berman et al. (2018)</ref> and contain the results for 2,101 A/B tests. These tests were conducted across a wide variety of pages and websites. For each test we observe the number of times the page was served with each of the two variations and the total number of times a user clicked on the page for each variation. Our goal is to use these data to estimate the range of lifts in click rates that one might expect from a website test and then use this to size a test &amp; roll experiment.</p><p>Figure E.1 displays the distribution of observed lift values between −0.6 and 0.6. This range contains 2,084 values, or 99.15% of the experiments. The distribution is long tailed with a small number of experiments having higher lifts than 0.6. The interquantile [1%, 99%] lift range is [−0.213, 0.327], with a mean of 0.112 and a median of 0.0015. For treatment effects, the range is [−0.10, 0.16], with a mean of 0.005 and a median of 0.001. The sample sizes range from 100 to 17.4 million, with an interquantile [1%, 99%] range of <ref type="bibr">[116,</ref><ref type="bibr">903,</ref><ref type="bibr">850]</ref>, a mean of 574,474, and a median of 3,864 users per treatment.</p><p>Because these tests were conducted across many websites with a wide range of click rates, there tends to be correlation in the click rate between the two arms in the same experiment. To account for this, we assume that each experiment k has its own mean click rate t k and assume that the means for the treatment arms within the experiment are distributed Normal around the click rate for the experiment as follows: In the empirical model, ω captures the variation in mean response across experiments, whereas σ captures the variation between arms within an experiment. In sizing a test &amp; roll experiment following (10), we are interested in the potential differences between arms within a single experiment, so we use the estimate of σ and ignore ω. In addition, we assume s μ(1 − μ), but if the experimenter has other information about the likely click rate for these particular web pages, then s can be appropriately adjusted or conservatively set at 0.25 while still using σ as an estimate of the range of mean responses expected for treatments within an experiment.</p><formula xml:id="formula_80">y ijk ∼ 1 m jk , s ( ) , (E.3) m jk ∼ 1 t k , σ<label>(</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.2. Display Ad Testing Example</head><p>We illustrate how "advertiser 1" in <ref type="bibr">Lewis and Rao (2015)</ref> might obtain the parameters μ and σ in order to find the profitmaximizing sample size for a new test &amp; roll with treatments that are expected to perform similarly to experiments 1.1, 1.2, 1.3, 1.5, and 1.6 reported in Table <ref type="table" target="#tab_14">E</ref>.2. We eliminated experiment 1.4 because it had a substantially different media cost and response rate for the control group versus the other experiments and appears to be targeting customers with higher baseline purchase propensity.</p><p>Using the data in Table <ref type="table" target="#tab_14">E</ref>.2, we estimate the following hierarchical model for the mean response in the control group reported for each experiment j:   Note that s is estimated as the average of s j across the five experiments, which is 103.77. Because we are estimating the variance in mean response σ from just five experiments, the posterior of σ is relatively wide. As can be seen from ( <ref type="formula" target="#formula_12">10</ref>), the profit-maximizing sample size will be largest when σ is smallest. Taking a conservative approach one might use the posterior 2.5th percentile for σ instead of the posterior mean. This results in a profitmaximizing sample size of 18,486, still far smaller than that recommended for a hypothesis test.</p><formula xml:id="formula_81">y j ∼ 1 m j ,ŝ̅̅ n √ ( ) , (E.6) m j ∼ 1 μ, σ<label>(</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>E.3. Catalog Holdout Testing Example</head><p>The catalog holdout data describe 30 catalog holdout tests conducted in October 2013 through March 2014. In each month, six tests were conducted using the same print catalog and different targeted populations. These data are provided by the same retailer as in <ref type="bibr" target="#b26">Zantedeschi et al. (2016)</ref> but use a different sample of tests. For each customer i in each test k, we observe the all-channel sales y ijk for one month after the catalog is delivered. The sample sizes and holdout rates for these tests vary with a [10%, 90%] interquartile range for the sample size of <ref type="bibr">[346.7, 1,395.5]</ref>, with a mean of 658.3 and a median of 437.0. The holdout rates also varied widely with a range of [1.1%, 95.1%], a median of 5.4%, and a mean of 21.0%.</p><p>The distribution of the estimated treatment effects are shown in Figure E.2. The interquartile range for the point estimates of the treatment effects is <ref type="bibr">[−10.77, 39.15]</ref>, with a median of 6.23 and a mean of 11.34 (all in U.S. dollars). Lifts cannot be computed for seven of the tests because no purchases were made in the control group, but the median lift is 1.48, and the 10th percentile is −0.549. The one-month purchase amounts for individual customers have a median of 0, a mean of 43.64, and a 90th percentile of 113.00.</p><p>Individually, the catalog holdout tests have very imprecise estimates for response because of small sample size and high noise in the data. The hierarchical model is particularly valuable in pooling information across the tests and propagating uncertainty due to small sample sizes. We fit a model similar to that used for the website tests, except that we allow for μ 1 μ 2 and σ 1 σ 2 , because, unlike for the website tests, there is a clear distinction between the treated and holdout conditions. The model we fit is By modeling the overall response rate for the experiment t k , we allow for the different targeted populations to have different response rates and account for the correlation in response within experiments. In planning a new test, we focus on the variation in response rates within the experiment, as estimated by σ 1 and σ 2 . Samples from the posterior are obtained using the HMC algorithm implemented in Stan with uniform priors on the  We also estimated a version of the model where s 1 was constrained to be the same as s 2 and used these estimates to show that unequal group sizes can arise from the priors (unlike in null hypothesis testing). The resulting estimates are reported in Table E.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Endnotes</head><p>1 We focus on a z-test for simplicity. The test of proportions is similar.</p><p>2 The seldom-used finite population correction (FPC) will recommend sample sizes smaller than the population; however, this correction does not account for the opportunity cost of the test and does not maximize profit. The FPC adjusts the standard error to correct for the inaccuracy of the central limit theorem when sampling from a finite population of size N without replacement resulting in a recommended sample size of n FPC 2N(z1−α/2+zβ) 2 s 2 (N−1)d 2 +4s 2 (z1−α/2+zβ) 2 . We thank an anonymous reviewer for suggesting this as a benchmark.</p><p>3 Treatments may be defined as a single exposure (e.g., an email) or a series of exposures (e.g., a digital media campaign). <ref type="bibr">4</ref> The assumption that s 1 and s 2 are known could easily be relaxed by putting priors on them, but this is not necessary for deriving key insights. <ref type="bibr">5</ref> An online sample size calculator is available at http://testandroll.com. <ref type="bibr">6</ref> As noted in the introduction, it is not clear what should be done if the null hypothesis cannot be rejected. <ref type="bibr">7</ref> The symbol Ω denotes a lower asymptotic bound, whereas O denotes an upper asymptotic bound. <ref type="bibr">8</ref> Thompson sampling uses a decision rule based on the posterior similar to (8), but it continuously updates the posterior and makes a probabilistic decision for each customer proportional to the probability that each treatment is best. 9 R functions for finding optimal sample sizes for asymmetric Normal priors or beta-binomial priors are available at http://testandroll.com. 10 This is similar to using a pretest to inform priors for conjoint design <ref type="bibr" target="#b1">(Arora and Huber 2001)</ref>. <ref type="bibr">11</ref> Although it would be ideal to observe sales and revenue for each visitor, this is not always possible. As a proxy, we assume for this example that profit is proportional to the number of clicks. 12 To facilitate comparisons across applications, we report the regret relative to the expected value of perfect information as in (15). <ref type="bibr">13</ref> The values of n HT and n FPC shown in panel (c) assume d is set at the 25th percentile of the prior of the absolute treatment effect. <ref type="bibr">14</ref> The difference of 0.19 is approximately the difference between the return on investment being equal to −100% and 0%, assuming the ads cost 0.094 per user (the average reported cost across experiments) and the margin on retail sales is 0.5. This sample size is similar to those calculated by <ref type="bibr">Lewis and Rao (2015)</ref> in table III. 15 When s 1 s 2 , then the sample sizes n 1 (z (1−α)/2 + z β ) 2 ( s 2 1 +s1s2</p><p>δ 2 ) and n 2 (z (1−α)/2 + z β ) 2 ( s1s2+s 2 2 δ 2 ) minimize n 1 + n 2 while achieving the desired confidence and power. See <ref type="bibr" target="#b16">Luh and Guo (2007)</ref>.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. (Color online) Typical Test &amp; Roll Setup</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Implied Prior on Treatment Effect for Website Example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. (Color online) Total Expected Conversions (a) and Error Rate (b) as a Function of Test Size for Website Test Example</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. (Color online) Optimal Sample Size (n * ) for Website Test Example as a Function of (a) Population Size N, (b) Standard Deviation of Response s, and (c) σ Compared with the Sample Size for a Hypothesis Test (n HT ) and a Hypothesis Test with Finite Population Correction (n FPC )</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. (Color online) The a Priori Relative Regret of Thompson Sampling (Dark) and Profit-Maximizing Test &amp; Roll (Light) Are Remarkably Similar Under a Wide Range of Conditions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Feit and Berman :</head><label>Berman</label><figDesc>Test &amp; Roll: Profit-Maximizing A/B Tests</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure B. 1 .</head><label>1</label><figDesc>Figure B.1. (Color online) Comparison of Optimal Sample Sizes Computed Exactly Using the Beta-Binomial Model vs. the Normal-Normal Approximation for Various Values of Mean Response Rate (μ α α+β ) and Prior Precision (α + β)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure E. 1 .</head><label>1</label><figDesc>Figure E.1. Distribution of Lift Values for Experiments</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Feit and Berman: Test &amp; Roll: Profit-Maximizing A/B TestsMarketing Science, 2019, vol. 38, no. 6, pp. 1038-1059<ref type="bibr" target="#b23">, © 2019</ref> </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 1 .</head><label>1</label><figDesc>Comparison of Test Plans for Website Test ExampleNote. Here, N 100, 000, μ 0.68, σ 0.03, and s 0.466.Marketing Science, 2019, vol. 38, no. 6, pp. 1038-1059, © 2019 INFORMS profit-maximizing test &amp; roll becomes an attractive option once the operational complexity of integrating a dynamic algorithm into the website is considered.</figDesc><table><row><cell cols="2">Feit and Berman: Test &amp; Roll: Profit-Maximizing A/B Tests</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Expected conversions</cell><cell></cell><cell></cell></row><row><cell>Test plan</cell><cell>n 1</cell><cell>n 2</cell><cell>Test</cell><cell cols="2">Roll Overall</cell><cell cols="2">Exp. regret (%) Roll error (%)</cell></row><row><cell>No test (random)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>68,000</cell><cell>2.43</cell><cell>50.0</cell></row><row><cell>Standard hypothesis</cell><cell cols="5">18,468 18,468 25,116 43,944 69,060</cell><cell>0.91</cell><cell>3.6</cell></row><row><cell>test</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="6">Hypothesis test with FPC a 13,487 13,487 18,342 50,883 69,225</cell><cell>0.67</cell><cell>4.2</cell></row><row><cell>Test &amp; roll</cell><cell cols="5">2,284 2,284 3,106 66,430 69,536</cell><cell>0.22</cell><cell>10.0</cell></row><row><cell>Thompson sampling</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>69,672</cell><cell>0.03</cell><cell>-</cell></row><row><cell>Perfect information</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>69,693</cell><cell>0</cell><cell>-</cell></row></table><note>a  The hypothesis test with finite population correction as defined in Endnote 2.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Feit and Berman: Test &amp; Roll: Profit-Maximizing A/B TestsMarketing Science, 2019, vol. 38, no. 6, pp. 1038-1059<ref type="bibr" target="#b23">, © 2019</ref> </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2 .</head><label>2</label><figDesc>Comparison of Test Plans for Online Display ExampleNote. Here, N 1, 000, 000, μ 10.36, σ 4.40, and s 103.77.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="3">Expected sales ($000)</cell><cell></cell><cell></cell></row><row><cell>Test plan</cell><cell>n 1</cell><cell>n 2</cell><cell cols="3">Test Roll Overall</cell><cell cols="2">Regret (%) Roll error (%)</cell></row><row><cell>No test (random)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>10,360</cell><cell>19.32</cell><cell>50.0</cell></row><row><cell cols="4">Standard hypothesis test a 4,782,433 a 4,782,433 a n/a</cell><cell>n/a</cell><cell>n/a</cell><cell>n/a</cell><cell>n/a</cell></row><row><cell>Hypothesis test with FPC b</cell><cell>452,673</cell><cell cols="4">452,673 9,380 1,125 10,595</cell><cell>17.5</cell><cell>1.1</cell></row><row><cell>Test &amp; roll</cell><cell>11,391</cell><cell cols="4">11,391 236 12,491 12,727</cell><cell>0.89</cell><cell>6.9</cell></row><row><cell>Thompson sampling</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>12,803</cell><cell>0.29</cell><cell>-</cell></row><row><cell>Perfect information</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>12,840</cell><cell>0</cell><cell>-</cell></row></table><note>a The recommended test size is larger than assumed population. b The hypothesis test with finite population correction as defined in endnote 2.Figure 6. Fitted Distributions for Mean Response Estimated from Previous Catalog Mailings for a Specialty Retailer (Left) and the Implied Prior on Treatment Effects (Right) Feit and Berman: Test &amp; Roll: Profit-Maximizing A/B Tests</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3 .</head><label>3</label><figDesc>Comparison of Test Plans for Catalog Holdout Example Here, N 100, 000, μ 1 30.06, σ 1 13.48, s 1 87.69, μ 2 19.39, σ 2 20.97, and s 2 179.36).</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="3">Expected sales ($000)</cell><cell></cell><cell></cell></row><row><cell>Test plan</cell><cell>n 1</cell><cell>n 2</cell><cell>Test</cell><cell>Roll</cell><cell>Overall</cell><cell cols="2">Regret (%) Roll error (%)</cell></row><row><cell>No test (random)</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>2,433</cell><cell>30.75</cell><cell>50.0</cell></row><row><cell>Standard hypothesis test</cell><cell cols="2">7,822 15,999</cell><cell>620</cell><cell>2,668</cell><cell>3,287</cell><cell>7.85</cell><cell>1.9</cell></row><row><cell cols="3">Hypothesis test with FPC 6,317 12,921</cell><cell>501</cell><cell>2,828</cell><cell>3,328</cell><cell>5.23</cell><cell>2.2</cell></row><row><cell>Test &amp; roll</cell><cell>588</cell><cell>1,884</cell><cell>67</cell><cell>3,409</cell><cell>3,476</cell><cell>1.68</cell><cell>6.4</cell></row><row><cell>Thompson sampling</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>3,504</cell><cell>0.57</cell><cell>-</cell></row><row><cell>Perfect information</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>3,512</cell><cell>0</cell><cell>-</cell></row><row><cell>Note.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>(Expected Error Rate). Under symmetric priors, the expected rates of making the incorrect choice in the roll stage,</figDesc><table><row><cell>Feit and Berman: Test &amp; Roll: Profit-Maximizing A/B Tests</cell></row><row><cell>Marketing Science, 2019, vol. 38, no. 6, pp. 1038-1059, © 2019 INFORMS</cell></row><row><cell>Corollary A.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>Table E.1. Model Estimates for Meta-Analysis of Website Tests Provide an Estimate of the Distribution of Mean Response to Be Used in Planning Future Tests with Similar Treatments and Targeted Populations</figDesc><table><row><cell>Parameter</cell><cell>Mean</cell><cell>sd</cell><cell>2.5th %ile</cell><cell>97.5th %ile</cell></row><row><cell>μ</cell><cell>0.676</cell><cell>0.004</cell><cell>0.667</cell><cell>0.685</cell></row><row><cell>σ</cell><cell>0.030</cell><cell>0.001</cell><cell>0.029</cell><cell>0.031</cell></row><row><cell>ω</cell><cell>0.199</cell><cell>0.003</cell><cell>0.193</cell><cell>0.206</cell></row></table><note>Note. %ile, percentile.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table E</head><label>E</label><figDesc>Note. These are used to estimate mean and variance for display advertising response for the typical campaign of advertiser 1. Tests where the sampling distribution for y ijk in (E.4) has been replaced withȳ j , because we do not have access to the userlevel data. The estimates of μ and σ reported in TableE.3 are used in designing a new test &amp; roll for advertiser 1.</figDesc><table><row><cell></cell><cell cols="3">Feit and Berman: Test &amp; Roll: Profit-Maximizing A/B</cell></row><row><cell></cell><cell cols="3">.2. Reported Mean and Standard Deviation for the</cell></row><row><cell cols="4">Control Group in Display Advertising Tests from Table 1 of</cell></row><row><cell cols="2">Lewis and Rao (2015)</cell><cell></cell><cell></cell></row><row><cell>Test</cell><cell>Mean (ȳ j )</cell><cell>Pooled sd (ŝ)</cell><cell>Group size (n)</cell></row><row><cell>1.1</cell><cell>9.49</cell><cell>94.28</cell><cell>300,000</cell></row><row><cell>1.2</cell><cell>10.50</cell><cell>111.15</cell><cell>300,000</cell></row><row><cell>1.3</cell><cell>4.86</cell><cell>69.98</cell><cell>300,000</cell></row><row><cell>1.5</cell><cell>11.47</cell><cell>111.37</cell><cell>300,000</cell></row><row><cell>1.6</cell><cell>17.62</cell><cell>132.15</cell><cell>300,000</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>Table E.3. Model Estimates for Meta-Analysis of Display Advertising Tests Provide an Estimate of the Distribution of Mean Response to Be Used in Planning Future Tests with Similar Treatments and Targeted Populations Note. %ile, percentile. Figure E.2. Distribution of Catalog Holdout Test Treatment Effects (y 2 − y 1 ) Table E.4. Model Estimates for Meta-Analysis of Catalog Holdout Tests Provide an Estimate of the Distribution of Mean Response to Be Used in Planning Future Tests</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Parameter</cell><cell>Mean</cell><cell>sd</cell><cell>2.5th %ile</cell><cell>97.5th %ile</cell></row><row><cell>Parameter</cell><cell>Mean</cell><cell>sd</cell><cell>2.5th %ile</cell><cell>97.5th %ile</cell><cell>s 1</cell><cell>87.69</cell><cell>1.21</cell><cell>85.41</cell><cell>90.06</cell></row><row><cell>μ</cell><cell>10.36</cell><cell>1.99</cell><cell>6.16</cell><cell>14.17</cell><cell>s 2</cell><cell>179.36</cell><cell>0.97</cell><cell>177.46</cell><cell>181.24</cell></row><row><cell>σ</cell><cell>4.40</cell><cell>1.17</cell><cell>2.63</cell><cell>7.17</cell><cell>μ 1</cell><cell>19.39</cell><cell>7.13</cell><cell>5.32</cell><cell>33.17</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Δ</cell><cell>10.67</cell><cell>6.19</cell><cell>−1.30</cell><cell>22.77</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>σ 1</cell><cell>20.97</cell><cell>5.85</cell><cell>8.81</cell><cell>32.25</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>σ 2</cell><cell>13.48</cell><cell>5.88</cell><cell>4.01</cell><cell>26.78</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>ω</cell><cell>27.25</cell><cell>5.18</cell><cell>18.27</cell><cell>38.57</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Note. %ile, percentile.</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head></head><label></label><figDesc>Table E.5. Model Estimates for Catalog Holdout Tests Assuming s 1 s 2 s Note. %ile, percentile. Feit and Berman: Test &amp; Roll: Profit-Maximizing A/B Tests Marketing Science, 2019, vol. 38, no. 6, pp. 1038-1059, © 2019 INFORMS hyperparameters. The posterior means for μ 1 , Δ = μ 2 − μ 1 , σ 1 , and σ 2 reported in Table E.4 are used as point estimate to compute the asymmetric test &amp; roll sample size.</figDesc><table><row><cell>Parameter</cell><cell>Mean</cell><cell>sd</cell><cell>2.5th %ile</cell><cell>97.5th %ile</cell></row><row><cell>s</cell><cell>170.17</cell><cell>0.86</cell><cell>168.48</cell><cell>171.91</cell></row><row><cell>μ 1</cell><cell>23.32</cell><cell>8.38</cell><cell>6.64</cell><cell>40.06</cell></row><row><cell>Δ</cell><cell>6.39</cell><cell>7.48</cell><cell>−7.78</cell><cell>21.93</cell></row><row><cell>σ 1</cell><cell>18.54</cell><cell>7.08</cell><cell>5.55</cell><cell>33.62</cell></row><row><cell>σ 2</cell><cell>9.79</cell><cell>5.98</cell><cell>2.37</cell><cell>23.73</cell></row><row><cell>ω</cell><cell>28.75</cell><cell>4.87</cell><cell>20.20</cell><cell>39.15</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">MarketingScience, 2019, vol. 38, no. 6, pp. 1038-1059<ref type="bibr" target="#b23">, © 2019</ref> </note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank Julie Albers, Eduardo Azevedo, Eric Bradlow, Raghu Iyengar, Pete Fader, Bruce McCullough, and Christophe Van den Bulte for helpful discussions and suggestions.</p><p>Feit and Berman: Test &amp; Roll: Profit-Maximizing A/B Tests Marketing Science, 2019, vol. 38, no. 6, pp. 1038-1059<ref type="bibr" target="#b23">, © 2019</ref> </p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr">Feit and Ron Berman (Marketing Science, vol. 38, no. 6, pp. 1038</ref><ref type="bibr">-1058</ref><ref type="bibr">, DOI: 10.1287</ref><ref type="bibr">/mksc.2019</ref><ref type="bibr">.1194</ref><p>, equation ( <ref type="formula">8</ref>) on page 1041 has been corrected to remove an error in the expression for the posterier mean in the decision rule. The other formulas in the body of the paper, including the expected deploy-stage profits in equations ( <ref type="formula">9</ref>) and ( <ref type="formula">18</ref>), are correct. The expression for the decision rule used in the Appendix where the deploy-stage profit is derived (Proposition A.1) is correct, but uses slightly different notation. In Proposition A.1, y j is used to denote the average response for treatment group j (instead of y j as in the body of the paper).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Further optimal regret bounds for Thompson sampling</title>
		<author>
			<persName><forename type="first">S</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Goyal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 16th International Conference on Artificial Intelligence and Statistics (AISTATS) (PMLR)</title>
				<editor>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Carvalho</surname></persName>
			<persName><forename type="first">P</forename><surname>Ravikumar</surname></persName>
		</editor>
		<meeting>the 16th International Conference on Artificial Intelligence and Statistics (AISTATS) (PMLR)</meeting>
		<imprint>
			<date type="published" when="2013" />
			<biblScope unit="page" from="99" to="107" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Improving parameter estimates and model prediction by aggregate customization in choice experiments</title>
		<author>
			<persName><forename type="first">N</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Huber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="273" to="283" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">A/B testing with fat tails. Working paper</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Azevedo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Alex</forename><forename type="middle">D</forename></persName>
		</author>
		<author>
			<persName><forename type="first">Montiel</forename><surname>Olea</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Weyl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">G</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<pubPlace>Wharton School; Philadelphia</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Which products are best suited to mobile advertising? A field study of mobile display advertising effects on consumer attitudes and intentions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sarvary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="270" to="285" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Van den Bulte C (2018) p-Hacking and false discovery in A/B testing. Working paper</title>
		<author>
			<persName><forename type="first">R</forename><surname>Berman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Pekelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Scott</surname></persName>
		</author>
		<imprint>
			<pubPlace>Wharton School, University of Pennsylvania, Philadelphia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Decision making during a phase III randomized controlled trial</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Wolff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Sack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Controlled Clinical Trials</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="360" to="378" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A learning approach for interactive marketing to a customer segment</title>
		<author>
			<persName><forename type="first">D</forename><surname>Bertsimas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Mersereau</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1120" to="1135" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Mailing decisions in the catalog sales industry</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">R</forename><surname>Bitran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Mondschein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1364" to="1381" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Real-time evaluation of email campaign performance</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bonfrer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Drèze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="251" to="263" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Choosing sample size for a clinical trial using decision analysis</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Cheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Berry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="923" to="936" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Sequential sampling with economics of selection procedures</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Chick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frazier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="550" to="569" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">New two-stage and sequential procedures for selecting the best simulated system</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Chick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Inoue</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="732" to="743" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Degroot</surname></persName>
		</author>
		<title level="m">Optimal Statistical Decisions</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Do no harm A/B testing without P-values</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gershoff</surname></persName>
		</author>
		<ptr target="https://conductrics.com/do-no-harm-or-ab-testing-without-p-values/" />
	</analytic>
	<monogr>
		<title level="m">Conductrics Blog</title>
				<imprint>
			<date type="published" when="2017-03-30" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Heterogeneous treatment effects and optimal targeting policy evaluation. Working paper</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Hitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Misra</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>University of Chicago, Chicago</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The online display ad effectiveness funnel &amp; carryover: A meta-study of ghost ad experiments. Working paper</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Nubbemeyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econom</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1941" to="1973" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
	<note>The unfavorable economics of measuring the returns to advertising. Quart</note>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Approximate sample size formulas for the two-sample trimmed mean test with unequal variances</title>
		<author>
			<persName><forename type="first">W-M</forename><surname>Luh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-H</forename><surname>Guo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">British J. Math. Statist. Psych</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="137" to="146" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Dynamic online pricing with incomplete information using multiarmed bandit experiments</title>
		<author>
			<persName><forename type="first">K</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Abernethy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="225" to="252" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">The new Stats Engine</title>
		<author>
			<persName><forename type="first">L</forename><surname>Pekelis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Walsh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Johari</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>Optimizely, San Francisco</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Customer acquisition via display advertising using multi-armed bandit experiments</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="500" to="522" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">A modern Bayesian look at the multi-armed bandit</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">L</forename><surname>Scott</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Stochastic Models Bus. Indust</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="639" to="658" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Efficiently evaluating targeting policies: Improving upon champion vs. challenger experiments</title>
		<author>
			<persName><forename type="first">D</forename><surname>Simester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Timoshenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">I</forename><surname>Zoumpoulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci. Forthcoming</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Determination of the optimal sample size for a clinical trial accounting for the population size</title>
		<author>
			<persName><forename type="first">N</forename><surname>Stallard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">W</forename><surname>Hee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zohar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Posch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrical J</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="609" to="625" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">RStan: The R interface to Stan</title>
		<author>
			<persName><forename type="first">Stan</forename><surname>Development Team</surname></persName>
		</author>
		<ptr target="http://mc-stan.org" />
		<imprint>
			<date type="published" when="2018-05-01" />
		</imprint>
	</monogr>
	<note>R package version 2.17.3.</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On the likelihood that one unknown probability exceeds another in view of the evidence of two samples</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3/4</biblScope>
			<biblScope unit="page" from="285" to="294" />
			<date type="published" when="1933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Sample size calculation-Myth buster edition</title>
		<author>
			<persName><forename type="first">K</forename><surname>Wortham</surname></persName>
		</author>
		<ptr target="https://www.searchdiscovery.com/blog/sample-size-calculation-myth-buster-edition" />
	</analytic>
	<monogr>
		<title level="m">Search Discovery (blog)</title>
				<imprint>
			<date type="published" when="2018-05-20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Measuring multichannel advertising response</title>
		<author>
			<persName><forename type="first">D</forename><surname>Zantedeschi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Feit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="2706" to="2728" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<author>
			<persName><forename type="first">Berman</forename><surname>Feit</surname></persName>
		</author>
		<title level="m">Test &amp; Roll: Profit-Maximizing A/B Tests</title>
				<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
