<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Nonparametric Approach to Identifying Latent Relationships in Hierarchical Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Thomas</forename><forename type="middle">S</forename><surname>Shively</surname></persName>
							<email>shively@mail.utexas.edu</email>
						</author>
						<author>
							<persName><forename type="first">Greg</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>Kohn</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Max</forename><forename type="middle">M</forename><surname>Fisher</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Management Science and Information Systems</orgName>
								<orgName type="institution">The University of Texas at Austin</orgName>
								<address>
									<postCode>78712</postCode>
									<settlement>Austin</settlement>
									<region>Texas</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">College of Business</orgName>
								<orgName type="department" key="dep2">Australian Graduate School of Management</orgName>
								<orgName type="institution">Ohio State University</orgName>
								<address>
									<postCode>43210</postCode>
									<settlement>Columbus</settlement>
									<region>Ohio</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">University of New South Wales</orgName>
								<address>
									<postCode>2052</postCode>
									<settlement>Sydney</settlement>
									<region>New South Wales</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">A Nonparametric Approach to Identifying Latent Relationships in Hierarchical Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.19.2.149.11807</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>This paper provides a method for nonparametrically modeling the relationship between consumer preference for product features, such as reliability or durability, and covariates that describe consumers and how they use the product. This relationship is of interest to firms designing and delivering products to a market because the extent to which consumers are sensitive to particular features determines the potential profitability of product offerings, and affects decisions relating to appropriate distribution outlets and advertising strategies. The successful identification of these relationships also aids in efficiently targeting marketing activities to specific segments of the consumer population.</p><p>The relationship between consumer preference for product features and observable covariates is important but is typically unknown. In addition, these relationships are often deeply embedded in a model hierarchy and are not observed directly. For example, in models of household choice, the observed outcomes are multinomial with probabilities driven by latent utilities or values that consumers place on the choice alternatives. These utilities are in turn a function of characteristics, such as price and product features, which are differentially valued. Of primary interest is the relationship between consumer sensitivity to product characteristics and readily observed covariates such as household demographics or aspects of product usage. Because the relationships of interest are not directly observed, it is difficult to draw inferences about them without formal statistical models.</p><p>This paper presents a three-level hierarchical Bayes model for modeling binary consumer preferences as a function of observable covariates. The hierarchical model nonparametrically estimates the relationships between consumer preferences for product features and the covariates without assuming a specific functional form. A nonparametric model is particularly useful in the exploratory analysis of consumer data in which the primary purpose of the analysis is to generate further questions rather than provide specific answers to well-posed questions. This type of analysis is frequently encountered in marketing where a series of studies are commissioned to better understand the nature of demand. The first level of the hierarchy in the Bayesian model relates the binary consumer choice to the sensitivities of the consumer to product attributes such as brand name, price, reliability,</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>and durability. The second level of the hierarchy models the heterogeneity across consumers using functions that relate attribute sensitivities to observable covariates. This level of the hierarchy also allows each respondent to have unique demand coefficients by introducing random effect components. The third level of the hierarchy specifies a smoothness prior for each of the unknown functions used in the second level. The approach is flexible and works well both when the unknown function can be closely approximated by a linear function and when it cannot be. A Bayesian model selection technique is used to determine which functions can be modeled using a linear function and which ones should be modeled nonparametrically to provide the necessary flexibility to estimate the function accurately.</p><p>The proposed methodology is illustrated using data from a survey of consumer preferences for features of marine outboard engines that was collected as part of a consulting project. Our analysis focuses on measuring consumer preferences for engine features and their relationships to two variables related to boat length and engine size. Consumer preferences for engine features were obtained through a national survey conducted over the telephone. Preferences were elicited by means of a pairwise evaluation in which respondents chose between two engines that were identical in every respect except for two engine features. The methodology can be modified to allow for more complex comparisons such as conjoint data collected in full profiles.</p><p>The application of a Bayesian model selection procedure indicates that 4 of the 28 covariate relationships in the model are nonlinear, while the other 24 are linear. The preferences associated with these four functions are involved in 56% of the pairwise comparisons in the study. Therefore, in practice, if the nonlinear functions are not properly estimated there is the potential to draw misleading inferences regarding 56% of the pairwise choices. Firms can use the estimates of the functions relating preferences to covariates in a number of ways. First, they can use the covariates to determine the total number of consumers who have high demand for a particular product feature, and then they can target communication efforts to those individuals. Alternatively, the empirical results can be used as a basis of subsequent analysis to obtain a more complete characterization of a market segment. <ref type="bibr">(Consumer Preferences; Cubic Smoothing Spline; Hierarchical Bayes Model; Markov Chain Monte Carlo; Randan Effects)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>What is the relationship between consumer preference for product features, such as reliability or durability, and covariates that describe consumers and how they use the product? There is no universally correct answer to this question because the relationship depends on the product and the benefits it offers. Yet this relationship is of interest to firms designing and delivering products to a market. The extent to which consumers are sensitive to particular features determines the potential profitability of product offerings, and affects decisions relating to appropriate distribution outlets and advertising strategies. In addition, the successful identification of these relationships aids in efficiently targeting marketing activities to specific segments of the consumer population. The relationship between consumer preference for product features and observable covariates is important but is typically unknown.</p><p>Further complicating the identification of relationships between determinants of demand and observable covariates is the fact that consumer preferences and sensitivities are often deeply embedded in a model hierarchy and are not observed directly. For example, in models of household choice, the observed outcomes are multinomial with probabilities driven by latent utilities or values that consumers place on the choice alternatives. These utilities are in turn a function of characteristics, such as price and product features, which are differentially valued. Of primary interest is the relationship between consumer sensitivity to product characteristics and readily observed covariates such as household demographics or aspects of product usage. Because the relationships of interest are not directly observed, it is difficult to draw inferences about them without formal statistical models.</p><p>In addition, these inferences are often based on very limited amounts of information. For example, household purchases recorded in scanner panel data sets typically contain less than a dozen or so entries in most product categories (see <ref type="bibr" target="#b1">Allenby and</ref><ref type="bibr" target="#b1">Lenk 1994, 1995)</ref>. Data obtained through consumer surveys are similarly limited because the quality of responses starts to deteriorate after about 20 minutes of interviewing. This data limitation precludes the precise estimation of many model parameters of interest to firms. As a result, it is often not possible to analyze latent relationships by first obtaining point estimates of parameters and then relating them to other variables because large standard errors mask the true latent relationship.</p><p>This paper presents a hierarchical Bayesian approach for modeling binary consumer preferences as a function of observable covariates. The model estimates the effects of the covariates nonparametrically, that is, without assuming a particular functional form for the regression functions. The estimates of the regression functions are cubic smoothing splines. A number of authors aim to achieve such flexibility by using loworder polynomials, for example quadratics or cubics, but such low-order polynomials cannot capture the shape of all plausible functional forms. Our approach is more flexible and works well both when the unknown function can be closely approximated by a loworder polynomial and when it cannot be. A model selection technique is used to determine which functions can be modeled using a low-order polynomial and which ones require a smoothing spline to provide the necessary flexibility to model the relationship. The model also allows each respondent to have unique demand coefficients by introducing random effects components.</p><p>The proposed methodology is particularly useful in the exploratory analysis of consumer data in which the primary purpose of the analysis is to generate further questions rather than to provide specific answers to well-posed questions. This type of analysis is frequently encountered in marketing where a series of studies are commissioned to better understand the nature of demand. For example, variation in consumer demand for automobile features occurs mainly because consumers use automobiles to solve very different problems. Families with small children are motivated by a very different set of needs than those of a teenager. It is often not possible to specify exactly how these needs translate into demand for product features, and whether there exist observable covariates that could be used to identify groups of consumers (i.e., segments) with particularly high demand. Instead, marketers often work in reverse by first measuring demand for features and then attempting to understand how variation in demand is related to observed covariates, and, hopefully, to a set of underlying needs. Hence, results from earlier studies are used to refine the collection of data in later studies, with the goal of eventually identifying and understanding why specific groups of consumers demand the products they do.</p><p>The paper is organized as follows. Section 2 introduces the empirical application that is a field study of consumer preferences for a product. Section 3 presents the statistical model and the priors. This section includes setting priors for the unknown regression functions. Section 4 discusses model estimation as well as the variable selection technique used to determine which functions should be estimated nonparametrically. Section 5 presents and interprets the estimation results when the model is applied to the data on consumer preferences. Section 6 contains some concluding remarks. The appendix provides the Markov chain Monte Carlo sampling schemes used to implement the estimation and variable selection techniques.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Empirical Example</head><p>The proposed methodology is illustrated using data from a survey of consumer preferences for features of marine outboard engines that was collected as part of a consulting project. Outboard engines are used in a variety of activities, including fishing, water skiing, and leisure boating. Our analysis focuses on measuring consumer preferences for engine features (for example, brand name, price, reliability, and durability) and their relationships to two variables related to boat length and engine size. We use boat length and engine size as the covariates in the model because they represent aspects of product usage that are expected to be related to demand for product attributes. Marketing studies typically find that covariates representing previous product usage contain more explanatory power than, for instance, demographic variables. There are 10 engine features used in our analysis, and they are presented in Table <ref type="table" target="#tab_0">1</ref>.</p><p>Consumer preferences for engine features were obtained through a national survey conducted over the telephone. Respondents were randomly chosen from boat registration lists. Preferences were elicited by means of a pairwise evaluation in which respondents chose between two engines that were identical in every respect except:</p><p>The first engine was high on feature A and low on feature B; and</p><p>The second engine was low on feature A and high on feature B where "low" and "high" represent levels of performance on the feature. The specific wording used in the evaluation is provided in Table <ref type="table" target="#tab_0">1</ref>. Note that "high" always represents better, so "high" on price means a lower price. Using this convention makes the empirical results in §5 easier to interpret. For proprietary reasons, values of the performance levels cannot be revealed and are referred to as low and high. Specific performance levels and brand names were used in the actual survey. Pairwise evaluations were used in the study because the survey was administered over the telephone, which limited the complexity of the questions that could be asked. The methodology can be modified to allow for more complex comparisons (e.g., conjoint data collected in full profiles) and for covariates other than boat length and engine size (e.g., demographic variables such as age or income level).</p><p>Our analysis involves 682 respondents for whom boat length and engine size are available and who used outboard engines on freshwater lakes and streams. Each respondent reported their preferences for 13 to 15 pairwise evaluations involving a subset of the product attributes in Table <ref type="table" target="#tab_0">1</ref>, resulting in a total of 9,421 observations. A randomized design was used in which respondents were randomly assigned to one of five groups, and each group performed a different subset of evaluations. For example, respondents providing preferences about price and fuel economy did not provide information about emissions. As discussed below, inferences for these respondents about sensitivity to emissions were obtained through the random effects distribution for these respondents and estimated covariate relationships. Each respondent answered questions involving either five or six attributes. The validity of using fractionated designs to draw inferences about individual effects is discussed in detail by <ref type="bibr" target="#b9">Lenk et al. (1996)</ref>.</p><p>The goal of our analysis is to determine how sensitive a consumer is to various engine features and to determine whether boat length and engine size are related to these sensitivities. This information can be used to identify current owners who have high demand for a particular product feature and can also be used to identify usage situations that require higher or lower levels of engine performance. The relationship of interest is embedded in the middle of a model hierarchy, and standard diagnostic tests such as residual analysis are not available. Therefore, it is often useful to employ exploratory techniques to uncover patterns in the data, and to then examine these patterns more rigorously in a subsequent study by narrowing the focus of the study to a specific activity for which the brand is relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Statistical Model</head><p>A three-level hierarchical Bayes model was used to estimate the sensitivity of the respondents to the engine features in Table <ref type="table" target="#tab_0">1</ref> and to estimate the relationships of these sensitivities to boat length and engine size. The model also includes a random component that captures the extent of unobservable heterogeneity in the population. The relationships between attribute sensitivities and the covariates are estimated using a nonparametric estimation technique, so no restrictive assumptions are placed on the functional forms of these relationships.</p><p>The observed binary choices w are defined as follows:</p><p>1 if the first engine is preferred, w ‫ס‬ ij Ά 0 if the second engine is preferred, where i indexes the choices for the jth respondent. The probability that w ij ‫ס‬ 1 is modeled as</p><formula xml:id="formula_0">p(w ‫ס‬ 1|x , x , b ) ‫ס‬ U((x ‫מ‬ x )Јb ), (1) ij ij1 ij2 j i j 1 ij2 j</formula><p>where U is the standard normal cumulative distribution function so that a probit link function is used. For each index pair (i, j), the vectors x ij1 and x ij2 correspond to a comparison of the first and second engines. Each element of these two vectors is either zero or one. For example, suppose that a respondent's preference for brand A is compared to that for brand B, with the price of brand A lower (better) than that for brand B. Then x ij1 has a one for the first (brand A) and sixth (price) elements and zeros elsewhere, while x ij2 has a one for the second (brand B) element and zeros elsewhere. If a respondent's preference for speed and durability was being determined, then x ij1 has a one for the twelfth (speed) element, and zeros elsewhere; while x ij2 has a one for the ninth (durability) element, and zeros elsewhere. Only five of the six brands are included in the x ij1 and x ij2 to avoid multicollinearity. The vector b j ‫ס‬ (b 1j , . . . , b 14j )Ј is a 14 ‫ן‬ 1 vector, and its lth element is the sensitivity of the jth respondent to the lth engine feature. We note that for a given combination of i and j the vector x ij1 ‫מ‬ x ij2 has at most three nonzero values corresponding to the features of the two engines.</p><p>The second level of the hierarchy models the heterogeneity across respondents using the following: (1) functions that relate sensitivities (b lj ) to the covariates; these functions are assumed common to all respondents; (2) respondent-specific random effects. Let z j ‫ס‬ (z 1j , z 2j )Ј be the vector of covariates for the jth respondent, where z 1j represents boat length in feet and z 2j represents engine size measured in horsepower. The lth element of b j is modeled as</p><formula xml:id="formula_1">b ‫ס‬ f (z ) ‫ם‬ f (z ) ‫ם‬ f ,<label>(2)</label></formula><p>l j l 1 l j l 2 2j 1j l ‫ס‬ 1, . . . , 14, and j ‫ס‬ 1, . . . , 682. The model allows for a different function for each product feature and each covariate. Each function is modeled by the smoothness prior described below. The vector f j ‫ס‬ (f 1j , . . . , f 14j )Ј is a respondent specific random effect that captures the effects of variables other than boat length and engine size. We model the f j as independent multivariate N(0,D) random variables. The diagonal elements of D indicate the amount of unexplained heterogeneity in the respondent preferences. The offdiagonal elements with positive entries indicate pairs of features which tend to be jointly preferred, while negative entries indicate pairs for which either one or the other tend to be preferred, but not both. The prior distribution for the matrix D is inverse Wishart IW(I, 15). The third level of the hierarchy specifies the prior on each of the functions f lk . It will be convenient to express each function as</p><formula xml:id="formula_2">f (z ) ‫ס‬ l ‫ם‬ c z ‫ם‬ g (z ),<label>(3)</label></formula><p>lk kj lk lk kj lk kj with g lk (0) ‫ס‬ (0) ‫ס‬ 0, where (0) is the first de-</p><formula xml:id="formula_3">(1) (1) g g l k l k</formula><p>rivative of g lk evaluated at zero. Thus, g lk is the nonlinear part of f lk and has zero intercept. Only l l1 is estimated, with l l2 set to zero because the individual l lk are not identified unless they have informative priors. That is, only the first function f l1 has a nonzero intercept with the remainder having zero intercept. For conciseness, we write l l1 as l l . Diffuse priors are placed on l l , l ‫ס‬ 1, . . . , 14, and c lk , l ‫ס‬ 1, . . . , 14, and k ‫ס‬ 1, 2. We assume that the g lk are independent a priori and that they all have the same prior. It is thus sufficient to discuss the prior for a typical function g ‫ס‬ g lk . Without loss of generality we assume that the argument z of g is nonnegative. The prior distribution on the function g is defined by the integral equation</p><formula xml:id="formula_4">z g(z) ‫ס‬ s (z ‫מ‬ s)W(ds), (<label>4</label></formula><formula xml:id="formula_5">)</formula><formula xml:id="formula_6">Ύ 0</formula><p>where W(s) is a Wiener process with W(0) ‫ס‬ 0 and Var{W(s)} ‫ס‬ s. This prior is discussed by <ref type="bibr" target="#b12">Wahba (1978)</ref> for cubic spline smoothing and more generally by <ref type="bibr" target="#b6">Hastie and Tibshirani (1990)</ref> and <ref type="bibr" target="#b5">Green and Silverman (1994)</ref> for penalized likelihood estimation. Kalyanam and Shively (1998) use this prior to fit flexible functional forms to data in a nonhierarchical model. Unlike most of Bayesian analysis, where a prior is placed on a discrete number of parameters, Equation ( <ref type="formula" target="#formula_4">4</ref>) is a prior on a curve and has the following properties: (1) The function g is smooth and has a continuous first deriv-</p><formula xml:id="formula_7">ative because g (1) (z) ‫ס‬ dg(z)/dz ‫ס‬ W(z); (2) for s Ͼ 0, the increment g (1) (z ‫ם‬ s) ‫מ‬ g (1) (z) in the first derivative is not predictable from g(u), u Յ z, because g (1) (z ‫ם‬ s) ‫מ‬ g (1) (z) ‫ס‬ W(z ‫ם‬ s) ‫מ‬ W(z) is independent of g(u);</formula><p>(3) the second derivative of g is diffuse because d 2 g(z)/ dz 2 ‫ס‬ dW(z)/dz and Var{dW(z)/dz} ‫ס‬ ϱ; (4) if s 2 ‫ס‬ 0, then g is identically zero and the corresponding function f is linear in z; (5) the posterior mean of g is a cubic smoothing spline.</p><p>To complete the specification of the priors on the functions g lk we assume that the scale factors cor-2 s lk responding to the functions g lk are a priori independent and have flat priors. These priors are used to allow the data to determine the "smoothness" of the function estimates. Simulation results in <ref type="bibr" target="#b14">Wood and Kohn (1998)</ref> indicate that the use of these priors provides good function estimates in binary regression for a wide range of functional forms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Estimation and Variable Selection</head><p>This section provides a brief discussion of the method used to estimate the parameters and function values in the hierarchical model. It also outlines the variable selection procedure used to determine whether each function should be estimated as a linear function or estimated nonparametrically. To successfully implement the estimation and variable selection procedures it is important to take advantage of the structure of the model to reduce the computational time required to run the estimation and variable selection sampling schemes. Details of the sampling schemes used to implement these procedures are given in the appendix. The smoothing parameters , the function values 2 s lk f lk (z kj ), the random effects vectors f j , and the elements of the covariance matrix D are estimated by their posterior means. A Markov chain Monte Carlo sampling scheme is used to estimate the parameters and function values because it is computationally intractable to obtain analytically the posterior moments of interest. The</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1</head><p>Histograms for Engine Size and Boat Length for All Respondents practical problem that arises in the estimation is the large amount of computation required to estimate the 28 functions using 9,421 observations. There are two insights that reduce the computational burden. First, we exploit the fact that there are only 16 distinct values for boat length and 43 distinct values for engine size.</p><p>Figure <ref type="figure">1</ref> provides histograms that summarize the data regarding the number of respondents having boats and engines of various sizes. As we show in the appendix, by averaging across observations with the same covariate values we can reduce the problem of generating 682 function values (i.e., one for each respondent) for each of the 28 functions to one of generating function values for only the distinct covariate values. These distinct values can then be used to construct the entire f lk vector. Second, we exploit the structure of the design vector (x ij1 ‫מ‬ x ij2 )Ј because, as noted in §3, at least 11 of the 14 elements of (x ij1 ‫מ‬ x ij2 )Ј take on a value of zero. This type of structure is common in pairwise evaluations and is frequently employed in marketing studies. It allows us to construct a sampling scheme that substantially reduces the number of observations that must be cycled through each iteration by using only those observations that contain information about a specific function value. Details are given in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variable Selection</head><p>A variable selection method is used to determine which functions in Equation ( <ref type="formula" target="#formula_1">2</ref>) should be estimated as linear functions and which functions should be estimated nonparametrically. Each function f lk can be written as </p><formula xml:id="formula_8">z kj f (z ) ‫ס‬ l ‫ם‬ c z ‫ם‬ s (z ‫מ‬ s)W (</formula><formula xml:id="formula_9">s lk 1 2 ‫2/1מ‬ 2 p(s ) ‫ס‬ (2p) (<label>cr</label></formula><formula xml:id="formula_10">)</formula><formula xml:id="formula_11">lk s lk 2 s lk ‫1מ‬ 2 2 • exp (log(s ) ‫מ‬ l ) , lk s lk 2 2(cr ) s lk</formula><p>where c is an appropriate multiple of . The rationale 2 r s lk for using these priors as well as how to choose c is given by <ref type="bibr" target="#b11">Shively et al. (1999)</ref>. The variable selection algorithm therefore requires two sampling schemes. The first sampling scheme is used to compute and for each function f lk , and 2 lr s s l k l k therefore provides the data generated priors for . The 2 s lk second sampling scheme then uses these priors to compute the posterior probabilities pr(M lk ‫ס‬ 0 | w) and pr(M lk ‫ס‬ 1 | w). The two sampling schemes are given in the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results for Empirical Example</head><p>The application of the variable selection procedure described in § 4 to the model in Equations ( <ref type="formula">1</ref>)-( <ref type="formula" target="#formula_2">3</ref>) indicates that four of the 28 covariate relationships are nonlinear, with posterior probabilities greater than 0.50 that a nonlinear function is required to model the relationship (i.e., posterior odds greater than one). The four nonlinear functions relate engine size to preferences for brand E, reliability, durability, and emissions (the corresponding posterior probabilities that the functions are nonlinear are 1.0, 0.814, 0.919, and 0.745, respectively). The functions relating engine size to the preferences for the other 10 product attributes are linear, and the functions relating all the preferences to boat length are also linear.</p><p>The model was re-estimated with the four nonlinear functions estimated nonparametrically and the other 24 functions estimated as linear functions. The estimates of the nonlinear functions are plotted in Figures <ref type="figure">2 through 5</ref>. The intercepts and slope coefficients for the linear functions for the other 24 functions are reported in Table <ref type="table" target="#tab_1">2</ref>. A model in which all 28 functions are restricted to be linear was also estimated for comparison purposes. The estimates of the four linear functions relating preferences to brand E, reliability, durability, and emissions are plotted as the dashed lines in Figures <ref type="figure">2 through 5</ref>.</p><p>A Bayesian procedure that imposes a penalty for extra parameters can be used to compare the fit of the nonparametric model with four nonlinear functions to the fully linear model. More specifically, the posterior probabilities for the two models are used to determine which model provides a better fit to the data. The calculation of the posterior probability for a specific model imposes a penalty for each parameter in the model because the parameters are integrated out. The  posterior probabilities are 1.0 for the nonparametric model and 0.0 for the fully linear model, so there is very strong evidence that the nonparametric model provides a substantially better fit to the data even after penalizing for its extra complexity.</p><p>Figures 2 through 5 indicate how preferences for various engine features are related to the size of the outboard engine currently owned by the respondent. The solid curves representing the nonlinear function estimates indicate substantial variation in preferences for each of the four features, with respondents differing in their estimated preferences for product features by a half unit or more. Because a probit link function was used, a difference of a half unit in the function estimates can translate to differences up to 0.19 in the choice probability, while a difference of one unit in the function estimates can translate to differences up to 0.38. This is discussed in more detail below.</p><p>The linear function estimates in Figures 2 through 5 do not show as much variation in preferences as the nonlinear function estimates, particularly in Figures <ref type="figure">3  and 4</ref>, and therefore provide a different interpretation of the preferences for each attribute among respondents. For example, in Figure <ref type="figure">3</ref> the nonlinear function estimate varies by a half unit, while the linear function estimate varies by less than 0.1 unit.</p><p>The nonlinear function estimate in Figure <ref type="figure">2</ref> indicates that brand E is most preferred by respondents with engines between 50 and 100 horsepower and is not valued as highly by those boat owners with engines larger than 100 horsepower. Figure <ref type="figure">3</ref> indicates that engine reliability (engine starts quickly) is a feature that is preferred most by respondents with moderately sized engines. Figure <ref type="figure">4</ref> displays a highly nonlinear relationship between durability and engine size, in which a group of respondents with engines between 100 and 140 horsepower have higher demand for this feature while those with both slightly smaller and slightly larger engines have less extreme preference. Finally, Figure <ref type="figure">5</ref> indicates that engine emissions (smoke) are of much greater concern to respondents with small engines than to those with medium or large engines.</p><p>By allowing for a flexible functional form between preferences and the covariates, the spline allows for more abrupt changes in the relationship than can be represented by a low-order polynomial. For example,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 6</head><p>Estimated Choice Share as a Function of Engine Size (in Horsepower) from Linear and Nonparametric Models for Engine 1 in a Pairwise Comparison. Note: Engine 1 has 10% lower emissions than Engine 2, and Engine 2 has 10% better durability than Engine 1. (The solid line is the estimate from the linear model, the long-dashed line is the estimate from the nonparametric model, and the two short-dashed lines are 95% confidence bands from the linear model.) a cubic polynomial is insufficient to capture the relationship between durability (l ‫ס‬ 9) and engine size (k ‫ס‬ 2) in Figure <ref type="figure">4</ref>. This is confirmed when we compute posterior probabilities that the spline term g lk ‫ס‬ g 92 in Equation ( <ref type="formula" target="#formula_2">3</ref>) is still required when quadratic and cubic terms are included in the model for b 9j . The posterior probability that is greater than zero is 0.78, which 2 s 92 indicates that a cubic polynomial is not flexible enough to model the relationship between durability and engine size. The advantage of the spline methodology is that it allows a user to determine if a low-order polynomial is sufficient to model each relationship. If it is not, the nonparametric spline model allows the data to specify the appropriate functional form. This model provides a more flexible method of uncovering groups of respondents with similar covariate values who have heightened demand for particular product features. These groups are often referred to as segments in the marketing literature (see <ref type="bibr" target="#b8">Kotler 1997)</ref>.</p><p>Figure <ref type="figure">6</ref> shows how the choice share for an engine involved in a specific pairwise comparison varies as engine size varies. This figure summarizes the results for a pairwise trade-off involving the attributes of emissions and durability. The first engine in the pairwise comparison has 10% lower emissions (attribute 13) than the second engine, while the second engine has 10% better durability (attribute 9) than the first. We set boat length to 17 feet (because this is the most common boat length and in the middle of the boat length range) and the random effects vector f to (0, 0, . . . , 0)Ј to represent a typical respondent.</p><p>The solid line in Figure <ref type="figure">6</ref> is the estimate of the probability of choosing the first engine obtained using the linear model (i.e., all 28 functions are estimated linearly). The long dashed line is the estimated probability obtained when 24 functions are estimated linearly and the remaining four are estimated nonparametrically. The short dashed lines are the 95% confidence bands obtained from the model with all 28 functions estimated linearly. Figure <ref type="figure">6</ref> shows that the estimated choice share function from the nonparametric model falls outside the 95% confidence bands at each of the peaks and valleys in the function. Many of the probability functions for pairwise trade-offs involving durability show similar behavior with the nonparametric estimates falling outside the 95% confidence bands from the linear model.</p><p>Figure <ref type="figure">6</ref> also shows a practical difference between the probabilities given by the linear model and those given by the nonparametric model. For example, for an engine size of 110 horsepower, the difference in the probabilities between the linear and nonlinear estimates of the probabilities is approximately 0.15; while for an engine size of 170 horsepower, the difference is approximately 0.20.</p><p>To provide evidence that the variability in the function estimates are not a result of idiosyncratic noise, we reran the estimation procedure four times, with a different quarter of the data omitted each time, and compared the estimated choice share functions. For example, there are 682 respondents in the sample, so for the first run the model is estimated with the first 25% of the data omitted. For the second run, the second 25% of the data are omitted, and so on. Figure <ref type="figure">7</ref> provides the four estimates of the choice share function for the pairwise comparison involving emissions and durability. The results for this pairwise comparison are provided because the function relating the sensitivity of durability to engine size is the most nonlinear and is therefore most susceptible to having been affected by idiosyncrasies in the data. The four function estimates all show the same general shape with bumps for engine size values of approximately 70 and 160 horsepower. The dashed lines are the 95% confidence bands obtained when the choice share function is estimated with the first 25% of the data omitted. Plots of the estimated choice share functions for other pairwise comparisons involving brand E, reliability, durability, and emissions (i.e., the four nonlinear functions in the model) also show similar shapes for each of the four data sets.</p><p>The high posterior probabilities that the functions in Figures 2 through 5 are nonlinear, along with the results discussed above relating to Figure <ref type="figure">7</ref>, indicate it is unlikely that the nonlinearity in the functions in Figures 2 through 5 is a result of random fluctuations in the data. This possibility can never be ruled out entirely, but the evidence in the data suggests it is unlikely. Some of the nonmonotonicity is difficult to explain (e.g., the function in Figure <ref type="figure">4</ref> that relates respondent preference for durability to engine size). It is possible that omitted covariates are driving the nonlinearity. However, this indicates one of the strengths of the nonparametric modeling procedure as an exploratory data analysis technique, because it suggests avenues for further exploration of the data (as discussed below).</p><p>An out-of-sample validation procedure was used to validate the model, with the first 75% of the observations used for estimation and the remaining 25% used for out-of-sample validation. There was little difference between the validation results for the parametric and nonparametric models, even though the variable selection and graphical results show strong evidence of nonlinearity in four of the functions. We believe the reason is the following: Detecting differences between the linear and nonlinear models using model validation is difficult because the differences, while real, are large for only a limited range of Engine Size values. For example, in Figure <ref type="figure">6</ref> where the pairwise comparison is between emissions and durability, only a small number of respondents in the validation sample fall in the regions where the differences between the linear and nonparametric choice share functions differ by more than 0.10. This means it will be difficult to detect differences between the two models because the inherent random variability in the dependent variable will likely overwhelm the differences because of the small number of pairwise comparisons that will have substantial differences in the choice probabilities. However, the population of boat owners is very large, and in particular, the number of boat owners that have substantial differences between the choice probabilities implied by the two models is large. This implies the differences in the probabilities will translate into large and practically significant differences in the number of boat owners in the population actually interested in an attribute such as durability. The covariance matrix (D) of the random effects distribution is available from the authors on request. The diagonal elements of the covariance matrix are large (ranging from 1.4 to 3.4), indicating a substantial amount of unexplained heterogeneity in respondent preferences. Many of the off-diagonal elements are nonzero, particularly for the engine features not associated with the name of the manufacturer. For example, the covariance between reliability and durability is 1.63, which corresponds to a correlation of 0.83. Positive covariances indicate pairs of features which tend to be evaluated similarly after accounting for the variability explained by the covariates, with either both features important to a particular respondent or neither being important. Many of the posterior means of the covariance terms are more than two posterior standard deviations from zero, indicating the importance of including a random effects distribution in the model specification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>Firms can use the estimates of the functions relating preferences to covariates in a number of ways. First, they can use the covariates to determine the total number of consumers who have high demand for a particular product feature, and then target communication efforts to those individuals. For example, consider the respondents in Figure <ref type="figure">4</ref> whose engine size is between 100 and 140 horsepower and who prefer high durability. A manufacturer considering improvements in the durability of their outboard engine would be critically interested in the number of boat owners with engines in the 100-140 horsepower range, and whether it is possible to identify them through sources such as state licensing agencies.</p><p>Alternatively, the empirical results can be used as a basis of subsequent analysis to obtain a more complete characterization of a market segment. Further analysis of our questionnaire reveals that 29 percent of the respondents with 100-140 horsepower engines report using their boats primarily for nonfishing activities (e.g., recreational boating, water skiing, and camping). In contrast, respondents with engines in the 35-100 horsepower range and the 140-170 horsepower range report this type of primary usage only 19 and 13 percent of the time, respectively. A cross-tabulation of these three segments (35-100 horsepower, 100-140 horsepower, and 140-170 horsepower) against primary boat usage indicates a statistically significant relationship with a p-value of 0.02. The 100-140 horsepower segment also tends to have a higher proportion of first-time boat owners (23%) than the other two groups (18% and 12%, p-value ‫ס‬ 0.06) and tend to own multi-purpose (62%) rather than single-purpose boats (32% and 42%, p-value ‫ס‬ 0.00).</p><p>Subsequent analysis would attempt to understand why these differences exist. Why, for example, do owners of engines in the 100-140 horsepower range have a heightened sensitivity to durability, and in what way is this related to nonfishing activities? Do these boaters come in contact with submerged objects, or use their engines for long periods of time? Do they use their boats in remote locations or in extreme climatic environments? Durability does not have a precise meaning and may translate into different engineering specifications depending on the context and environment of engine use. Furthermore, it is possible that consumers within a specific context may express a variety of concerns and interests about the engines. Some water skiers, for example, may want to build their endurance and need to maintain high speeds for extended periods of time without engine overheating. Other skiers may be more sensitive to acceleration and require engines that stand up to the strain of frequent starts and stops. Insights into the questions raised by our exploratory analysis can be obtained from additional analyses that focus on a more limited scope of boating activities.</p><p>The value of using the smoothness prior in Equation ( <ref type="formula" target="#formula_4">4</ref>) is that it results in a functional specification that flexibly summarizes relationships that are embedded in the middle of a model hierarchy. These relationships are of critical interest to firms attempting to relate covariates to model-based estimates of preferences and sensitivities. These relationships are difficult to specify a priori because of the lack of any guiding theory that would help specify an appropriate functional form. The smoothness prior, therefore, offers a useful approach to identifying these latent relationships without imposing any functional form assumptions that obscure the true latent relationship. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Sampling Schemes for Estimation and Variable Selection</head><p>This appendix provides the sampling schemes used to estimate the unknown parameters and functions of the model and to do variable selection. It also provides a detailed description of how the sampling scheme for estimation is implemented to make the estimation technique computationally feasible in a large scale problem such as the one in this paper.</p><p>A Gibbs sampler is used to estimate all parameters of interest 1</p><p>The authors thank the area editor and two reviewers for their helpful comments and suggestions. They improved the paper considerably. Tom Shively's work was partially supported by a Faculty Research Committee grant from the Graduate School of Business at the University of Texas at Austin. Robert Kohn's work was partially supported by an Australian Research Council grant.</p><p>because it is computationally intractable to obtain analytically the posterior moments of interest. For very readable introductory accounts of the Gibbs sampler, see <ref type="bibr" target="#b4">Gelfand and Smith (1990)</ref> and <ref type="bibr" target="#b3">Casella and George (1992)</ref>. To implement the Gibbs sampler we follow <ref type="bibr" target="#b0">Albert and Chib (1993)</ref> and <ref type="bibr" target="#b10">McCulloch and Rossi (1994)</ref> and introduce the additional latent variables y ij such that</p><formula xml:id="formula_12">y ‫ס‬ (x ‫מ‬ x )Јb ‫ם‬ ⑀ , ij ij1 ij2 j i j</formula><p>where the e ij are N(0,1) random variables and independent for all i and j, and are also independent of b j . Let w ij ‫ס‬ 1 if y ij Ͼ 0, and let w ij ‫ס‬ 0 otherwise. It is readily checked that w ij satisfies Equation (1). To describe the sampling scheme it is necessary to introduce some extra notation. Let I j be the number of questions asked of respondent j (I j is either 13, 14, or 15 for each j), J ‫ס‬ 682 be the number of respondents, K ‫ס‬ 2 be the number of covariates, and L ‫ס‬ 14 be the number of product features. Let w ‫ס‬ {w ij : i ‫ס‬ 1, . . . , I j ; j ‫ס‬ 1, . . . , J}, y ‫ס‬ {y ij : i ‫ס‬ 1, . . . , I j ; j ‫ס‬ 1, . . . , J}, c ‫ס‬ {c lk : l ‫ס‬ 1, . . . , L; k ‫ס‬ 1, . . . , K}, z k ‫ס‬ {z kj : j ‫ס‬ 1, . . . , J}, g lk ‫ס‬ {g lk (z kj ): j ‫ס‬ 1, . . . , J}, g ‫ס‬ {g lk : l ‫ס‬ 1, . . . , L; k ‫ס‬ 1, . . . , K}, l ‫ס‬ {l l , . . . , l L }, f ‫ס‬ {f l , . . . , f J }, and s 2 ‫ס‬ { : l ‫ס‬ 1, . . . , L; k ‫ס‬ 1, . . . , K}. For conciseness we use 2 s lk the notation g lk in two senses. First, g lk is a function with argument z kj . Second, for the purposes of the sampling scheme, we use g lk to denote the set of function values {g lk (z kj ): j ‫ס‬ 1, . . . , J}.</p><p>Sampling Scheme 1 (A) Choose initial values c <ref type="bibr">[0]</ref> , g <ref type="bibr">[0]</ref> , l <ref type="bibr">[0]</ref> , f <ref type="bibr">[0]</ref> , (s 2 ) <ref type="bibr">[0]</ref> and D <ref type="bibr">[0]</ref> . These values are either fixed or generated from some distribution.</p><p>Let A ‫ס‬ {w, y, c, g, l, f, s 2 , D}. (B) Generate from the following conditional distributions: If f lk is restricted to be a linear function, then set ‫ס‬ 0 in step B(ii).</p><p>2 s lk Steps B(i)-B(iii) are similar to those given in the algorithm by <ref type="bibr" target="#b14">Wood and Kohn (1998)</ref>, with two exceptions. First, in Step B(ii), we exploit the specific structure of the design vector (x ij1 ‫מ‬ x ij2 )Ј and the numerous repeated values in the covariates to improve the speed of the algorithm. Second, in Step B(ii) we use an eigenvalue decomposition that speeds up the algorithm as a result of the structure of the model. The implementation of Step B(ii) in the sampling scheme is outlined below. Steps B(iv) and (v) are taken from an algorithm given in <ref type="bibr" target="#b1">Allenby and Ginter (1995)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Implementation of Step B(ii)</head><p>We exploit the structure of the design vector x ij1 ‫מ‬ x ij2 , and the multiple repeated values in z 1 and z 2 to generate the random variates in this step in a computationally efficient manner. The repeated values in z 1 (a similar argument holds for z 2 ) allow observations with the same z 1 values to be averaged. This reduces the problem of generating J ‫ס‬ 682 function values for g l1 to one of generating function values for only the distinct z 1 values and then using these values to construct the entire g l1 vector. We will outline how to generate (l l , c l1 , g l1 ) |A ‫מ‬ {l l , c l1 , g l1 }.</p><p>To construct an algorithm for generating these random variates, we express b lj as b ‫ס‬ f (z ) ‫ם‬ f (z ) </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>(</head><label></label><figDesc>If k ‫ס‬ 2, then l l is set to 0.) Note that if ‫ס‬ 0, then 2 s lk f lk is a linear function, while if Ͼ 0, then f lk should 2 s lk be estimated nonparametrically. Therefore, we compute the posterior probability pr( Ͼ 0 | w) where w 2 s lk is a 9421 ‫ן‬ 1 vector containing the w ij s. The higher the probability, the stronger the evidence that a linear function is inadequate to model f lk .To compute pr( ‫ס‬ 0 | w) and pr( Ͼ 0 | w), lk ‫ס‬ 0, and if Ͼ 0, then M lk ‫ס‬ 1. We use the fol-2 s lk lowing priors for M lk and in our variable selection 2 s lk technique. First, the prior for each M lk is pr(M lk ‫ס‬ 0) ‫ס‬ pr(M lk ‫ס‬ 1) ‫ס‬ 1/2. The prior distributions for the are the following: If M lk ‫ס‬ 0, then ‫ס‬ 0 with probone (i.e., a point mass at 0). If M lk ‫ס‬ 1, then a data generated prior is used for . To obtain this prior, 2 s lk the full model is estimated (i.e., all functions for boat length and engine size are estimated nonparametrically) and estimates of the posterior mean and variance of log( ) | w,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2Nonlinear and Linear Relationships Between Respondent Preference for Brand E and Engine Size (in Horsepower)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 5Nonlinear and Linear Relationship Between Respondent Preference for Emissions and Engine Size (in Horsepower)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 7Estimated Choice Share from the Nonparametric Model as a Function of Engine Size (in Horsepower) for Four Data Sets Where a Different 25% of the Full Data Set Is Removed Each Time Note: Engine 1 in the Pairwise Comparison has 10% lower emissions than Engine 2, and Engine 2 has 10% better durability than Engine 1. (Dashed lines are 95% confidence bands.)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>(i) p(y ij |A ‫מ‬ {y ij }), for I ‫ס‬ 1, . . . , I j and j ‫ס‬ 1, . . . , J; (ii) p(l l , c lk , g lk | A ‫מ‬ {l l , c lk , g lk }) for l ‫ס‬ 1, . . . , L and k ‫ס‬ 1; p(c lk , g lk |A ‫מ‬ {c lk , g lk }) for l ‫ס‬ 1, . . . , L and k ‫ס‬ 2, . . . , K; (iii) p( | A ‫מ‬ { }) for l ‫ס‬ 1, . . . , L and k ‫ס‬ 1, . . . , K; p(f j | A ‫מ‬ {f j }) for j ‫ס‬ 1, . . . , J; (v) p(D | A ‫מ‬ {D}).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>‫ס‬ [l ‫ם‬ c z ‫ם‬ g (z )] ‫ם‬ [c z ‫ם‬ g (z )].x ij (l) be the lth element of x ij1 ‫מ‬ x ij2 , andỹ ‫ס‬ y ‫מ‬ [x (1)b ‫ם‬ • • • ‫ם‬ x (l ‫מ‬ 1‫מ‬ x (l)[c z ‫ם‬ g (z )] ‫ם‬ f .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 Description of the Data</head><label>1</label><figDesc></figDesc><table><row><cell>Sample Size:</cell></row><row><cell>682 Respondents</cell></row><row><cell>9,421 Observations</cell></row><row><cell>Attributes:</cell></row><row><cell>1. Brand Name</cell></row><row><cell>6 brands of outboard engines were studied, denoted by: A, B, C, D,</cell></row><row><cell>E, F</cell></row><row><cell>2. Price</cell></row><row><cell>x% less (more) expensive</cell></row><row><cell>3. Fuel Economy</cell></row><row><cell>x% more (less) fuel efficient</cell></row><row><cell>4. Reliability</cell></row><row><cell>Starts quickly every (x% of the) time</cell></row><row><cell>5. Durability</cell></row><row><cell>x% decreased (increased) risk of mechanical failure</cell></row><row><cell>6. Vibration and Noise</cell></row><row><cell>x% less (more) vibration and noise</cell></row><row><cell>7. Acceleration</cell></row><row><cell>Gets on "plane" x% faster (slower)</cell></row><row><cell>8. Speed</cell></row><row><cell>x% faster (slower) for the same horsepower</cell></row><row><cell>9. Emissions</cell></row><row><cell>x% less (more) smoke</cell></row><row><cell>10. Technology</cell></row><row><cell>Cutting-edge (standard) technology</cell></row><row><cell>Covariates:</cell></row><row><cell>Boat Length (feet)</cell></row><row><cell>Engine Size (horsepower)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 Posterior</head><label>2</label><figDesc>Posterior standard deviations are reported in parentheses</figDesc><table><row><cell>Product Feature</cell><cell>Intercept</cell><cell>Boat Length (z 1 )</cell><cell>Engine Size (z 2 )</cell></row><row><cell>Brand A</cell><cell>1.674</cell><cell>‫130.0מ‬</cell><cell>‫3600.0מ‬</cell></row><row><cell></cell><cell>(0.868)</cell><cell>(0.054)</cell><cell>(0.0035)</cell></row><row><cell>Brand B</cell><cell>2.958</cell><cell>‫021.0מ‬</cell><cell>‫7300.0מ‬</cell></row><row><cell></cell><cell>(1.104)</cell><cell>(0.067)</cell><cell>(0.0041)</cell></row><row><cell>Brand C</cell><cell>1.259</cell><cell>‫741.0מ‬</cell><cell>0.0040</cell></row><row><cell></cell><cell>(1.361)</cell><cell>(0.084)</cell><cell>(0.0055)</cell></row><row><cell>Brand D</cell><cell>0.057</cell><cell>‫730.0מ‬</cell><cell>‫1610.0מ‬</cell></row><row><cell></cell><cell>(1.818)</cell><cell>(0.113)</cell><cell>(0.0075)</cell></row><row><cell>Brand E</cell><cell>1.251</cell><cell>‫782.0מ‬</cell><cell>Spline</cell></row><row><cell></cell><cell>(2.261)</cell><cell>(0.117)</cell><cell>Function</cell></row><row><cell>Price</cell><cell>‫261.0מ‬</cell><cell>0.023</cell><cell>0.0008</cell></row><row><cell></cell><cell>(0.882)</cell><cell>(0.056)</cell><cell>(0.0030)</cell></row><row><cell>Fuel Economy</cell><cell>‫882.0מ‬</cell><cell>0.093</cell><cell>0.0005</cell></row><row><cell></cell><cell>(0.902)</cell><cell>(0.056)</cell><cell>(0.0032)</cell></row><row><cell>Reliability</cell><cell>0.211</cell><cell>0.042</cell><cell>Spline</cell></row><row><cell></cell><cell>(0.799)</cell><cell>(0.049)</cell><cell>Function</cell></row><row><cell>Durability</cell><cell>1.098</cell><cell>0.077</cell><cell>Spline</cell></row><row><cell></cell><cell>(0.887)</cell><cell>(0.055)</cell><cell>Function</cell></row><row><cell>Vibration</cell><cell>0.185</cell><cell>0.092</cell><cell>‫4100.0מ‬</cell></row><row><cell></cell><cell>(0.819)</cell><cell>(0.051)</cell><cell>(0.0029)</cell></row><row><cell>Acceleration</cell><cell>‫800.0מ‬</cell><cell>0.065</cell><cell>‫1000.0מ‬</cell></row><row><cell></cell><cell>(0.862)</cell><cell>(0.054)</cell><cell>(0.0029)</cell></row><row><cell>Speed</cell><cell>‫201.0מ‬</cell><cell>0.052</cell><cell>0.0033</cell></row><row><cell></cell><cell>(0.795)</cell><cell>(0.049)</cell><cell>(0.0028)</cell></row><row><cell>Emissions</cell><cell>0.250</cell><cell>0.127</cell><cell>Spline</cell></row><row><cell></cell><cell>(0.900)</cell><cell>(0.054)</cell><cell>Function</cell></row><row><cell>Technology</cell><cell>‫898.2מ‬</cell><cell>0.197</cell><cell>0.0005</cell></row><row><cell></cell><cell>(0.931)</cell><cell>(0.058)</cell><cell>(0.0031)</cell></row></table><note>Means of the Coefficients for the 14 ProductAttributes for the Linear (Nonspline) Functions Note:</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Marketing Science/Vol. 19, No. 2, Spring 2000</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Then</head><p>Therefore, generating (l l , c l1 , g l1 ) | A ‫מ‬ {l l , c l1 , g l1 } is equivalent to generating (l l , c l1 , g l1 )|ỹ, where ỹ ‫ס‬ {ỹ ij ; i ‫ס‬ 1, . . . , I j , j ‫ס‬ 1, . . . , J}. If x ij (l) is zero, then the ijth observation contains no information regarding c l1 and g l1 , and can be omitted when these quantities are generated. Further, there are only 16 distinct values for z 1j . (There are 43 distinct values for z 2j .) The remaining x ij (l) are all 1 or ‫1מ‬ so [x ij (l)] 2 ‫ס‬ 1. Multiplying the left and right sides of (A.1) by x ij (l) gives</p><p>where ‫ס‬ x ij (l)e ij are independent N(0, 1) random variables. Ob-e* ij servations with x ij (l) ‫ס‬ 0 are not included in (A.2).</p><p>For the jth respondent, z 1j (i.e., the length of the boat currently owned by the respondent) is the same for each question i ‫ס‬ 1, . . . , I j asked of the respondent so the observations within a respondent can be averaged without losing any information regarding l l , c l1 , and g l1 . In addition, many respondents will have the same z 1 value so the observations can also be averaged across respondents with the same z 1 . This gives the same value, and ϳ N(0,1/n s ) where n s is the number of obser-e s vations in (A.2) for which z 1j takes on the sth distinct value. Note that S l1 will be different for each l because different x ij (l) elements will be zero for each l. The observations in (A.3) can be arbitrarily ordered, so we will assume that the observations are ordered in ascending order with respect to z 1s .</p><p>(A.3) can be rewritten in matrix notation as</p><p>where ȳ ‫ס‬ (ȳ 1 , . . . , )Ј, Z is an S l1 ‫ן‬ 2 matrix whose sth row is (1, y S l1 z 1s ), and ‫ס‬ . . . ,</p><p>defined S l1 ‫ן‬ S l1 symmetric matrix with stth value given by</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SHIVELY, ALLENBY, AND KOHN Identifying Latent Relationships in Hierarchical Models</head><p>Marketing Science/Vol. <ref type="table">19, No. 2, Spring 2000</ref> 161</p><p>for z 1s Ͻ z 1t . Note that the original 9,421 observations have been reduced to S l1 observations, where S l1 is the number of distinct values the regressor z 1 takes on in (A.2). We note here that for boat length, S l1 takes on values ranging from 13 to 16 for the 14 attributes. For engine size, S l2 takes on values ranging from 33 to 43. This makes the sampling scheme we employ feasible to implement in practice.</p><p>To generate (l l , c l1 , ḡ l1 ) | ȳ, an eigenvalue method is used rather than the state space approach used by Wood and Kohn (1998) because for a small number of distinct knots it is computationally faster to use eigenvalues. First, let G ‫2/1מ‬ ‫ס‬ diag( , . . . ,</p><p>) and mul-</p><p>tiply both sides of (A.4) by G ‫2/1מ‬ to give</p><p>where</p><p>where P is an S l1 ‫ן‬ S l1 matrix whose columns contain the eigenvectors of G ‫2/1מ‬ VG ‫2/1מ‬ , and R is a diagonal matrix whose diagonal elements are the eigenvalues of G ‫2/1מ‬ VG ‫2/1מ‬ . Note that the eigenvalues and eigenvectors need to be computed only once, before the sampling scheme starts; they do not need to be computed each iteration. Multiplying both sides of (A.5) by PЈ gives</p><p>where ŷ ‫ס‬ PЈG ‫2/1מ‬ ȳ, Ẑ ‫ס‬ PЈG ‫2/1מ‬ Z , ĝ l1 ‫ס‬ PЈG ‫2/1מ‬ ḡ l1 , and ‫ס‬ e PЈG ‫2/1מ‬ Note that ĝ l1 ϳ N(0, R) and ϳ N(0, I). </p><p>Standard Bayesian calculations can be used to show that (l l , c l1 ) | ŷ is normally distributed with mean and variance given by</p><p>To generate ĝ l1 | ŷ, (l l , c l1 ), standard multivariate normal calculations can be used to show that ĝ l1 |ŷ,(l l , c l1 ) is normally distributed with mean and variance given by</p><p>Finally, to generate g l1 | ỹ, (l l , c l1 ), transform ĝ l1 to ḡ l1 using ḡ l1 ‫ס‬ P ĝ l1 , and then expand ḡ l1 appropriately to give g l1 . We point out here that the computational efficiency described above where we exploit the specific structure of the design vector (x ij1 ‫מ‬ x ij2 )Ј is available only for conjoint models and does not apply to more standard nonparametric regression models. The output of the sampling scheme can now be used to estimate the posterior moments of the parameters of interest in the usual way. The results reported in § 5 are based on 20,000 iterations of the sampling scheme chain in which the first 10,000 iterations are discarded. Parameter point estimates and other summary statistics are based on the last 10,000 iterations. Time series plots indicate that the draws converge in distribution well within the initial 10,000 iterations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sampling Scheme for Variable Selection</head><p>The variable selection algorithm requires two sampling schemes. The first is Sampling Scheme 1, given above. It is used to compute and for each function f lk , and therefore provides the data To describe the second sampling scheme, define M ‫ס‬ {M lk : l ‫ס‬ 1, . . . , L; k ‫ס‬ 1, . . . , K}.</p><p>Sampling Scheme 2 (A) Choose initial values c <ref type="bibr">[0]</ref> , g <ref type="bibr">[0]</ref> , l <ref type="bibr">[0]</ref> , f <ref type="bibr">[0]</ref> , M <ref type="bibr">[0]</ref> , (s 2 ) <ref type="bibr">[0]</ref> and D <ref type="bibr">[0]</ref> . These values are either fixed or generated from some distribution.</p><p>Let A* ‫ס‬ {w, y, c, g, l, f, M, s 2 , D}. (B) Generate from the following conditional distributions: Step (a) requires a numerical integration while, Step (b) uses a Metropolis-Hastings algorithm. The computational details of generating these terms are given in <ref type="bibr" target="#b11">Shively et al. (1999)</ref>. Steps (c) and (d) are generated the same way as Step B(ii) of Sampling Scheme #1.</p><p>If the number of distinct values for the covariates are very large, then the software used to implement the estimation and variable selection techniques may take a long time to run. Because the CPU time is highly dependent on the type of computer used, it is difficult to specify in general when the number of distinct values becomes too large for practical purposes.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Bayesian analysis of binary and polychotomous response data</title>
		<author>
			<persName><forename type="first">J</forename><surname>Albert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Chib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="669" to="679" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Reassessing brand loyalty, price sensitivity, and merchandising effects on consumer brand choice</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L J</forename><surname>Ginter ; P</surname></persName>
		</author>
		<author>
			<persName><surname>Lenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="281" to="290" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
	<note>J. Bus. Econom. Statist.</note>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Sales Promotion: Concepts, Methods and Strategies</title>
		<author>
			<persName><forename type="first">R</forename><surname>Blattberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Neslin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>Prentice Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Explaining the Gibbs sampler</title>
		<author>
			<persName><forename type="first">G</forename><surname>Casella</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>George</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. Statistician</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="167" to="174" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sampling-based approaches to calculating marginal densities</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Gelfand</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">F M</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="398" to="409" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Nonparametric Regression and Generalized Linear Models: A Roughness Penalty Approach</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">W</forename><surname>Silverman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Chapman and Hall</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Generalized Additive Models. Chapman and Hall</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Tibshirani</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Estimating irregular pricing effects: a stochastic spline approach</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kalyanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Shively</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="16" to="29" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName><forename type="first">Philip</forename><surname>Kotler</surname></persName>
		</author>
		<title level="m">Marketing Management</title>
				<meeting><address><addrLine>Englewood Cliffs, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Prentice Hall</publisher>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
	<note>9th edition</note>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Hierarchical Bayes conjoint analysis: recovery of part-worth heterogeneity from incomplete designs in conjoint analysis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Desarbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="173" to="191" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An exact likelihood approach to analysis of the MNP model</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mcculloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="207" to="240" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Variable selection and function estimation in additive nonparametric regression using a data-based prior (with discussion)</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Shively</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kohn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="page" from="777" to="806" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Improper priors, spline smoothing and the problem of guarding against model errors in regression</title>
		<author>
			<persName><forename type="first">G</forename><surname>Wahba</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Statist. Soc</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="364" to="372" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The signal extraction approach to nonparametric regression and spline smoothing</title>
		<author>
			<persName><forename type="first">W</forename><surname>Wecker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Ansley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="page" from="81" to="89" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">A Bayesian approach to robust nonparametric binary regression</title>
		<author>
			<persName><forename type="first">S</forename><surname>Wood</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="203" to="213" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">This paper was received November 30, 1998, and was with the authors 6 months for 2 revisions</title>
		<editor>Dick Wittink</editor>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
