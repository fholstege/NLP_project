<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">When Less Is More: Data and Power in Advertising Experiments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-07-26">July 26, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Garrett</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
							<email>garrett.johnson@simon.rochester.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Simon Business School</orgName>
								<orgName type="institution">University of Rochester</orgName>
								<address>
									<postCode>14627</postCode>
									<settlement>Rochester</settlement>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Randall</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
							<affiliation key="aff1">
								<address>
									<postCode>95032</postCode>
									<settlement>Netflix, Los Gatos</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">David</forename><forename type="middle">H</forename><surname>Reiley</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Pandora Media</orgName>
								<address>
									<postCode>94612</postCode>
									<settlement>Oakland</settlement>
									<region>California</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">University of California at Berkeley</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">When Less Is More: Data and Power in Advertising Experiments</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
						<imprint>
							<date type="published" when="2016-07-26">July 26, 2016</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.2016.0998</idno>
					<note type="submission">Received: March 5, 2015 Accepted: January 13, 2016</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Yahoo! Research partnered with a nationwide retailer to study the effects of online display advertising on both online and in-store purchases. We use a randomized field experiment on 3 million Yahoo! users who are also past customers of the retailer. We find statistically significant evidence that the retailer ads increase sales 3.6% relative to the control group. We show that control ads boost measurement precision by identifying and removing the half of in-campaign sales data that are unaffected by the ads. Less data give us 31% more precision in our estimates-equivalent to increasing our sample to 5.3 million users. By contrast, we only improve precision by 5% when we include additional covariate data to reduce the residual variance in our experimental regression. The covariate-adjustment strategy disappoints despite exceptional consumer-level data including demographics, ad exposure levels, and two years' worth of past purchase history.</p><p>History: Russell Winer served as the senior editor and Jean-Pierre Dub√© served as associate editor for this article.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>From 2007 to 2011, Yahoo! Research conducted a number of large-scale controlled experiments to measure the effects of online display advertising on retail sales. The experiment reported in this paper represents the best of these, incorporating wisdom accumulated during other experiments and breaking new ground on scale. We examine two consecutive weeklong ad campaigns that target three million of an apparel retailer's existing customers, matching subsequent in-store and online retail purchases with advertising exposure at the individual level. These retail image ads show attractive photos of featured items, but no prices, detailed product information, or calls to action. Our experimental estimates suggest the retailer ads increased sales by 3.6% and that the campaigns were profitable.</p><p>The Yahoo! Research experiments demonstrate that even large ad experiments have low statistical power. <ref type="bibr" target="#b20">Lewis and Rao (2015)</ref> critically examine these Yahoo! Research advertising experiments. They point out a "signal-to-noise" problem: the plausible mean impact of advertising is typically a small fraction of the variance in sales across consumers for occasionally purchased products. Such ad experiments have low statistical power and may require millions of observations-across consumers, campaigns, or time-to detect a profitable impact. With this bleak reality in mind, we saw two opportunities to reduce the variance in the outcome variable and thus alleviate the power problem. First, we add rich covariates to our data set, including a two-year history of purchases prior to the experiment, to reduce residual variance and, hence, standard errors. Second, we improve on the precision of intent-to-treat estimates by using control ads in the control group to exclude the noise from purchases by users who are not exposed to an ad.</p><p>In this paper, we employ both approaches by adding covariates to our estimator of the treatment effect and subtracting irrelevant observations via the use of control ads. We find that the control-ad approach is more effective: it improves the precision of our ad lift estimates by 31%, whereas the covariates approach only improves precision by 5%. When combined, the two approaches produce a 34% improvement in precision, equivalent to increasing our sample size by 80% to 5.6 million users. Conditioning on covariates underwhelms despite over 200 user-level covariates, including ad exposure intensity, user demographics, retailer customer categories, and two years of past sales history. Covariates struggle to predict sales in the campaign because purchases at the retailer are occasional, unpredictable, and highly variable in size. The controlad approach requires that the ad platform delivers the retailer ads in the treatment group symmetrically to the control ads in the control group, which we verify in the experiment. One quarter of the control-ad improvement results from a related methodological innovation: we discard sales that occur in the campaign prior to a user's first impression.</p><p>Retailers account for a large share of online display ads (8% of total impressions, according to com-Score 2013), but multichannel retailers face challenges in measuring the in-store sales impact of their online advertising. To help solve this problem, Yahoo! Research partnered with five retailers and with thirdparty data-matching services to link consumer data on Yahoo! ad views with a retailer's in-store and offline sales data. This proved to be a nontrivial task: a number of the experiments encountered technical problems, rendering data unusable or statistically underpowered. Such database-match campaigns allow advertisers to target past customers; this capability is available on major ad platforms like Facebook and Twitter as well as Yahoo!.</p><p>Among the Yahoo! Research experiments attempted, the experiment reported in this paper stands out for its large size and spending as well as its superior experimental design and execution. Three design improvements distinguish this experiment from our previous best experiment with the same retailer, described in <ref type="bibr" target="#b21">Lewis and Reiley (2014)</ref>. First, our experiment includes three million eligible users-double the size of its predecessor-and balances the treatment/control group split. Second, our experiment includes control ads, which boost the precision of our estimates. Third, the experiment features exceptional data on consumers, which also boost precision. With these advantages, our experiment delivers significant evidence that the ad campaigns increased sales. By contrast, <ref type="bibr" target="#b21">Lewis and Reiley (2014)</ref> do not obtain statistically significant experimental estimates without making a difference-in-differences assumption that is difficult to test.</p><p>We designed our experiment to examine the impact of ad exposure frequency. The experiment includes a "Full" treatment group that is exposed to the retailer's ads and a "Control" group that is exposed to unrelated control ads. We also included a "Half" treatment group that sees a retailer or control ad with equal probability at each ad viewing opportunity. Our experimental estimates suggest an average sales lift of $0.477 on the Full treatment group and $0.221 on the Half treatment group, which represent a 3.6% and a 1.7% increase over the Control group's sales.</p><p>The rest of this paper is organized as follows. The next section reviews the experimental ad effectiveness literature. Section 3 describes our experimental design, while the fourth section provides descriptive statistics and validates the experiment. The fifth section presents our measurements of the causal effects of the advertising. The final section concludes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Literature Review</head><p>Yahoo! Research emphasized the use of controlled experiments to avoid endogeneity between advertising and consumer behavior, having documented serious bias from methods commonly used in the advertising industry to analyze observational data. Na√Øve observational estimates that compare endogenously exposed versus unexposed users may overstate ad effectiveness by orders of magnitude <ref type="bibr" target="#b22">(Lewis et al. 2011)</ref>, largely not overlap <ref type="bibr" target="#b11">(Hoban and Bucklin 2015)</ref>, or even have the wrong sign relative to experimental estimates <ref type="bibr" target="#b21">(Lewis and Reiley 2014)</ref>. Advertisers' advertising choices can induce bias, for instance, by targeting customers who are more likely to purchase or by targeting times like Christmas when customers purchase more. <ref type="bibr">Lewis et al. (2011, p. 157)</ref> show that online consumer choices can also induce bias (what they term "activity bias") because consumers' activity is correlated across websites without that correlation necessarily being causal.</p><p>Controlled experiments remain rare in the advertising industry. This dearth of experiments seems surprising given the dollars at stake: advertising represents between 1% and 2% of global gross domestic product <ref type="bibr" target="#b3">(Bughin and Spittaels 2012)</ref>, and U.S. online display advertising revenues alone reached $7.9 billion in 2013, excluding mobile <ref type="bibr" target="#b13">(IAB 2014)</ref>. We believe that the potential pitfalls of endogeneity and selection bias in observational studies are not well appreciated by industry analysts, despite a report commissioned by the Interactive Advertising Bureau <ref type="bibr" target="#b17">(Lavrakas 2010)</ref> affirming experiments as the gold standard for measurement. To be sure, observational studies can provide value by exploiting natural sources of exogenous variation in advertising (see, e.g., <ref type="bibr" target="#b10">Hartmann and Klapper 2016</ref><ref type="bibr" target="#b30">, Shapiro 2016</ref><ref type="bibr">, Sinkinson and Starc 2016</ref><ref type="bibr" target="#b33">, Stephens-Davidowitz et al. 2015</ref>. The cited studies rely on a combination of high ad spend and a type of natural experiment specific to television advertising. Most of them also rely on aggregation of multiple campaigns to get statistically significant results, combining many experiments instead of measuring the effects of a single campaign as in this paper. We find experiments particularly valuable in the digital setting, where randomization can be conducted at the level of the individual consumer. <ref type="bibr" target="#b20">Lewis and Rao (2015)</ref> describe the severe statistical power problem in ad experiments that past studies resolve in different ways. One solution is to examine the effect of ads on less sparse or noisy outcome variables than sales. For instance, multiple online ad studies use survey outcomes like purchase intent and brand recall (e.g., <ref type="bibr" target="#b8">Goldfarb and</ref><ref type="bibr">Tucker 2011, Bart et al. 2014)</ref>. Other online ad studies use indicator outcomes like clicks <ref type="bibr" target="#b18">(Lewis 2010</ref><ref type="bibr" target="#b0">, Bakshy et al. 2012</ref>, site visits, sales leads <ref type="bibr" target="#b27">(Sahni 2016)</ref>, transactions <ref type="bibr" target="#b16">(Lambrecht and Tucker 2013)</ref>, or some combination of these purchase funnel indicators <ref type="bibr" target="#b11">(Hoban and Bucklin 2015)</ref>. We are interested in measuring the effect on online and in-store sales, although this is a harder estimation problem, because this allows us to evaluate the short-run return on investment for the campaign. Another solution to the power problem is to study settings with large ad effects, like in online search, where users are often seeking out competing advertisers with an intent to purchase <ref type="bibr" target="#b15">(Kalyanam et al. 2015</ref><ref type="bibr" target="#b27">, Sahni 2016</ref>, though not if the users already have an advertiser in mind <ref type="bibr" target="#b2">(Blake et al. 2015)</ref>. Instead, we are interested in the effects of image ads on users who receive ads while browsing unrelated content; our efforts to increase power are therefore crucial.</p><p>Studies that examine purchase outcomes are rare and often gain power by combining studies. <ref type="bibr" target="#b23">Lodish et al. (1995)</ref> pioneered split-cable television experiments with a panel of 3,000 households with advertising treatment matched to household-level purchases of consumer packaged goods. With merely thousands of consumers per experiment, these 600 experiments individually lack statistical power-the majority were statistically insignificant-but collectively demonstrate a significant ad effect in a metastudy <ref type="bibr" target="#b23">(Lodish et al. 1995</ref><ref type="bibr" target="#b12">, Hu et al. 2007</ref>). <ref type="bibr" target="#b15">Kalyanam et al. (2015)</ref> demonstrate that product-category search advertising increases offline retail sales using a metastudy of 15 experiments and 13 retailers. <ref type="bibr" target="#b15">Kalyanam et al. (2015)</ref> vary advertising at the city level then compare sales at treated stores to similar counterparts. Again, these studies are collectively significant though only half are individually significant. <ref type="bibr" target="#b31">Simester et al. (2009)</ref> is an exception-their single experiment finds statistically significant results in the catalog setting, where customer-level advertising is readily linked to customer-level sales.</p><p>Control ads have previously been used in ad experiments to improve measurement precision or to identify a set of holdout users. Control ads take the form of charity ads (see, e.g., <ref type="bibr" target="#b34">Yildiz and</ref><ref type="bibr">Narayanan 2013, Hoban and</ref><ref type="bibr" target="#b11">Bucklin 2015)</ref>, ads from unrelated companies (see, e.g., <ref type="bibr" target="#b18">Lewis 2010, Lewis and</ref><ref type="bibr" target="#b19">Nguyen 2015)</ref>, house ads promoting the platform (see, e.g., present study and Sahni 2016), or blank ads (see, e.g., <ref type="bibr" target="#b8">Goldfarb and</ref><ref type="bibr">Tucker 2011, Bart et al. 2014</ref>).</p><p>Though ours is not the first to employ control ads, the present study stands out for its rich individual-level covariates including user demographics, ad exposure, retailer categories of recency, frequency, and monetary value (RFM), and two years of historical sales separately by online and offline channels. Online ad experiments typically only have covariates for ad exposure and browsing behavior during the experiment or a few weeks before <ref type="bibr" target="#b11">(Hoban and Bucklin 2015</ref><ref type="bibr" target="#b16">, Lambrecht and Tucker 2013</ref><ref type="bibr" target="#b26">, Sahni 2015</ref> or self-reported survey covariates <ref type="bibr" target="#b8">(Goldfarb and</ref><ref type="bibr">Tucker 2011, Bart et al. 2014</ref>). Other online ad experiments do not include past behavior or demographics as covariates-preferring to present simple experimental difference results <ref type="bibr" target="#b18">(Lewis and</ref><ref type="bibr">Reiley 2014, Sahni 2016)</ref>. Many market-level ad experiments normalize outcomes with past sales in order to reduce small-sample bias that can result from unlucky random assignment of the few largest markets to the same treatment group <ref type="bibr" target="#b6">(Eastlack and Rao 1989</ref><ref type="bibr" target="#b23">, Lodish et al. 1995</ref><ref type="bibr" target="#b12">, Hu et al. 2007</ref><ref type="bibr" target="#b15">, Kalyanam et al. 2015</ref>. <ref type="bibr" target="#b31">Simester et al. (2009)</ref> stand out for including RFM variables from 15 years of sales history as well as the proximity to stores as covariates in their catalog experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experimental Design</head><p>The experiment measures Yahoo! advertising effectiveness for a national apparel retailer. The experiment took place during two consecutive weeks in spring 2010. In each week, the advertisements featured a different line of branded clothing. The experimental subjects were randomly assigned to treatment groups that remained constant for both weeks. A confidentiality agreement prevents us from naming either the retailer or the featured product lines.</p><p>To investigate the effects of exposure frequency, our experiment uses three treatment groups that vary the treatment intensity. The Full treatment group is exposed to the retailer's ads while the Control group is exposed to unrelated control ads. A third, Half treatment group is, on average, exposed to half of the retailer and control ads of the other two groups. We implement this design by booking 20 million retailer ads for the Full group, 20 million control ads for the Control group, and both 10 million retailer ads and 10 million control ads for the Half group. 1 Each experimental ad exposure in the Half group therefore has a 50% chance of being a retailer ad and a 50% chance of being a control ad. This experimental design enables us to investigate the impact of doubling the number of impressions in a campaign. Doubling the size of the campaign increases ad delivery on two margins:</p><p>(1) showing more ads to the same consumers (the intensive margin) and (2) increasing the number of consumers reached, here by 8% (the extensive margin). The average ad frequency in the Half group is comparable to a typical campaign for this retailer on Yahoo!.</p><p>The retailer ads are primarily image advertising and are co-branded with apparel firms. The ads display the store brand, the brand of the featured product line, and photographs of the advertised clothing line worn by attractive models. The ads do not include any price or promotion information. Figure <ref type="figure">1</ref> presents an illustrative example with the retailer Target and the designer Missoni-neither of which is involved in the experiment. The creative content of each ad impression is dynamic, with slideshow-style transitions between still photographs and text. Campaign 1 includes three different ads in an equal-probability rotation: men's apparel, women's apparel, and women's shoes. Campaign 2 advertises a product line from a different manufacturer and features women's apparel. The control ads advertise Yahoo! Search and are depicted in Figure <ref type="figure" target="#fig_0">2</ref>.</p><p>The experiment implements a "database-match" campaign in which the subjects are existing customers of both Yahoo! and the retailer. Prior to the experiment, a third-party data-collection firm matched the customer databases of Yahoo! and the retailer using the customer's name and either terrestrial or email address. Leveraging additional customer records, the third party doubled the number of matched customers  <ref type="bibr" target="#b21">Lewis and Reiley (2014)</ref> to 3.1 million in the present experiment. After the experiment ended, the third-party firm combined the retailer's sales data and the Yahoo! advertising data and removed identifying information to protect customer privacy. The retailer believes that its sales data correctly record the individual customer for more than 90% of all purchases. Matching customers sales and ad exposure data frequently results in a multiple-identifiers matching problem. Our original data source also suffered from such a problem: the data contain more retailer than Yahoo! identifiers. For simplicity, we focus our analysis on the 3.1 million users who were uniquely matched (see Online Appendix A.1 for details). The experiment thus measures the causal effects of advertising on this particular intersection of Yahoo!'s users and the retailer's customers.</p><p>Database-match campaigns like the one in our experiment are used by advertisers to target existing customers or to prospect for new customers. This service is available on major platforms like Yahoo!, Twitter <ref type="bibr" target="#b24">(Lynn 2014)</ref>, Google <ref type="bibr" target="#b25">(Ramaswamy 2015)</ref>, and Facebook, which even allows targeting for buyers of automobiles and consumer packaged goods <ref type="bibr" target="#b5">(Datalogix 2014)</ref>. Though the experiment's campaign targets existing customers, only 41% of users in the sample have transacted with the retailer in the past eight weeks, and 3.6% have not transacted in the previous two years. Thus, database-match campaigns reach both active and inactive customers, whereas retargeting campaigns (see, e.g., Lambrecht and Tucker 2013) reach only consumers who visited the retailer's website recently. Unlike retargeting, database-match campaigns can target users based on their offline sales and less recent sales. Moreover, database-match campaigns target logged-in users who are linked to their offline identities. The fact that we deliver ads only to loggedin users represents a great advantage relative to most online-advertising measurement efforts, which suffer from problems like impersistent cookie identifiers and the difficulty of linking user activity across multiple browsers and devices. Users in the campaign receive ads as they browse mostly unrelated content on Yahoo!. As such, the ads are much closer to traditional print and television ads than to online search ads, since users express intent through their queries in the latter case.</p><p>Many users in the experiment do not see an ad because they either do not visit Yahoo! at all or do not browse enough pages on Yahoo! during the campaigns. The experiment employs control ads to identify the counterfactual treated users in the control group who would have received the retailer's ads. The control ads also tell us the number of counterfactual ad exposures that a consumer would see if they had been assigned to the Full group. The experiment's retailer and control ad campaigns join all other competing ad campaigns in Yahoo's ad server, which selects each ad on each pageview on Yahoo! subject to ad supply and demand constraints, campaign-targeting criteria, and revenue-optimization goals. The experiment's ads ran on about 8% of the targeted customers' pageviews on Yahoo!, appearing on all Yahoo! properties including Mail, News, and Autos. The ads have four rectangular formats. The campaigns were identically configured for all three treatment groups, except for the ad creatives featuring Yahoo! versus the retailer.  <ref type="bibr">b</ref> The click-through rate is the quotient of total ad clicks and views. <ref type="bibr">c</ref> The clicker rate is the proportion of users exposed to the ad who click on it. d Here we include pageviews in the two weeks prior to the experiment in the regression to reduce the impact of outliers.</p><p>To demonstrate the limits of our experiment, we calculate that our experiment has the statistical power to reject the null hypothesis that advertising has no impact on sales 79% of the time in the Full group and 34% of the time in the Half group. In this calculation, we consider the alternative hypothesis that the advertiser receives a 50% return on its advertising investment. The alternative hypothesis implies an average treatment effect on the treated of $0.51 in the Full treatment group, given the $0.17 cost of display ads and assuming a 50% contribution margin for the retailer. The standard deviation of sales is $125 for the twoweek campaign and the sample size is 570,000 in each of the Full and Control treatment groups. In Section 5, we present methods that reduce the standard deviation of sales to $111, without which our power would be much lower (49% instead of 79%). A comparable calculation for <ref type="bibr" target="#b21">Lewis and Reiley (2014)</ref> reveals that its study had only 47% power. If we seek to detect longer-run ad effects, this compounds the statistical power problem. In particular, if the hypothesized $0.51 lift occurs against the background noise of more than just the two weeks of sales during the campaign, our statistical power will be reduced.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Data and Experimental Validation</head><p>This section describes our data and demonstrates the validity of our experimental randomization. In particular, we demonstrate that the distribution of user characteristics, pretreatment outcomes, and experimental ad exposures are equivalent across treatment groups  in accordance with experimental best practices (see <ref type="bibr">Gerber and Green 2012, Chapter 4)</ref>. In other experiments not reported here, our randomization checks have often helped us to uncover execution errors such as incorrect matching of sales to advertising data, failure to create identical targeting between treatment and control ads, or unexpected selection bias generated by an advertising auction. Our randomization checks here validate that the treatment and control groups are equivalent but for the exposure to retailer advertising. Online Appendix A.1 details the source of our data and some key variables. We verify the randomization by testing the distribution of user characteristics and pretreatment outcomes. Table <ref type="table" target="#tab_2">1</ref> provides summary statistics for the experiment. In Table <ref type="table" target="#tab_2">1</ref>'s right-most column, F-tests of equality of means of the variables by treatment group are not rejected, which is consistent with a valid experimental randomization. Over three million customers were evenly assigned to one of our three treatment groups: Full, Half, or Control. In each treatment group 68.5% of customers are female, the average age is 43.6 years, and customers viewed an average of 245 Web pages on Yahoo! during the campaign. Customers spent an average of $19.23 at the retailer during the two weeks prior to the experiment and $857.53 in the two years beforehand. Figure <ref type="figure" target="#fig_1">3</ref> shows that the distribution of average weekly sales over the two years prior to the experiment are essentially identical across all three treatment groups.</p><p>Ad distribution tests are critical in ad experiments with control ads to demonstrate that the total number of experimental ads (treatment plus control) are delivered symmetrically across treatment and control groups. Ad platforms are complex and may fail such tests for many reasons including the use of click-or action-optimized campaigns. In such cases, the ad platform will optimize ad delivery such that the retailer-ad exposed users look different from control-ad exposed users. Our experiment uses a simple reach-based campaign and avoids such problems. In Table <ref type="table" target="#tab_2">1</ref>, we see that the experiment delivers advertisements evenly across treatment groups. Ad exposure depends on a user's browsing activity during the two weeks of the campaign; 55% of users were exposed to an experimental ad. Figure <ref type="figure" target="#fig_2">4</ref> shows that the distribution of total ad views (both retailer and control) across the three treatments is identical and the F-test of equality reveals no significant differences in average impressions in Table <ref type="table" target="#tab_2">1</ref>. The distribution of ad views is highly skewed right, so that the mean is 33 while the median is 15 among exposed users. As expected, the Half treatment group sees an even split of retailer and control ads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>In this section, we show the experimental estimates for the sales lift during the two weeks of the ad campaign. We present methods that improve the statistical precision of our estimates in this low-powered setting. Our preferred experimental estimates suggest that consumers who were exposed to the retailer's ad saw their average sales increase by $0.477 (3.6%) in the Full treatment group and $0.221 (1.7%) in the Half treatment group. In Online Appendix A.2, we separate the effect of advertising by campaign, sales channel, and shopping trips. We find that the majority of the total treatment effect is attributable to the in-store rather than online sales channel and estimate a 1.8% increase in shopping trips in the Full group. Online Appendix A.2 also shows that including sales after the campaign increases the estimates of the overall causal effects, which allays the concern that the in-campaign  <ref type="bibr">d</ref> The retailer customer category covariates include categorical variables for recency of last purchase, customer loyalty, and lifetime customer spending.</p><p>e Two-year sales of pretreatment-both online and in-store sales amounts-at the weekly level except for aggregate sales for weeks 9-44 and 61-104 (54 variables in total).</p><p>For models that use sales after the first ad exposure as the outcome variable, we also include a covariate defined as sales from the beginning of the campaign up to that first exposure.</p><p>f The exposure intensity covariates include fixed effects for the day of the first ad exposure and the number of total exposures (retailer or control) for 1 to 30 separately and a single indicator for &gt;30.</p><p>* p &lt; 0.1; * * p &lt; 0.05; * * * p &lt; 0.01.</p><p>estimates might merely reflect intertemporal substitution of purchases from future to present. Table <ref type="table" target="#tab_4">2</ref> presents regression estimates of the average effect of treatment on the treated (TOT) for the impact of advertising on consumer purchases during the two-week experiment. In particular, we contrast two approaches for increasing the precision of the estimates without inducing bias: the control-ad and the covariates approaches. The control-ad approach works by pruning components of the outcome data that cannot be influenced by advertising. The covariates approach introduces covariates into the experimental linear regression to reduce the residual variance of the outcome variable. In all, we improve the precision of our estimates-or shrink the standard errors-by 34% on average.</p><p>As a baseline, we begin with the intent-to-treat (ITT) estimates from which we derive the indirect TOT estimate. The indirect TOT estimator takes the treatmentcontrol difference for the entire sample of 3.1 million consumers (ITT estimate) and divides by the treatment probability (the 55.4% exposed subsample). <ref type="bibr">2</ref> The indirect TOT estimator relies on the fact that outcomes among untreated subjects have an expected experimental difference of zero. However, variance in outcomes among untreated subjects adds noise (but no signal) to the estimator. As column (1) of Table <ref type="table" target="#tab_4">2</ref> indicates, the indirect TOT estimator yields a $0.67 average sales lift (s.e. $0.32) in the Full treatment group and an average lift of $0.03 (s.e. $0.31) in the Half group. Whereas <ref type="bibr" target="#b21">Lewis and Reiley (2014)</ref> estimate the TOT indirectly out of necessity, this experiment uses control ads to isolate the counterfactual treated sample in the Control group.</p><p>Our control ads identify the users in the control group who would have received the retailer's ad had they been in the treatment group. Table <ref type="table" target="#tab_4">2</ref>'s column (2) presents the direct TOT regression estimate on the treated sample. The treated sample are those users who see any of the experiment's retailer or control ads during the two weeks of the campaign. The direct TOT estimator increases precision by pruning the untreated subsample that contributes only noise to the estimator. By using the control ads to filter out the unexposed users, we improve the precision of the experimental estimates-or decrease the standard errors-by 25% on average.</p><p>We propose a second use for control ads that further improves precision: we omit purchases that occur prior to a consumer's first experimental ad exposure, because ads cannot influence sales until the user receives the ad. The key to achieving this result Marketing Science 36(1), pp. 43-53, ¬© 2017 INFORMS was obtaining daily data on individual consumer purchases during the campaign. Because the control ads identify the counterfactual pretreatment sales in the Control group, we can exclude purchases on days before the first ad impression is seen by a given consumer. This method requires that the ad platform delivers the experimental ads symmetrically across treatment groups, which we verified in Section 4. Table <ref type="table" target="#tab_4">2</ref>'s column (3) uses both the control ads and daily sales data to further prune the data and boost precision by another 8%. In all, by trimming sales of unexposed users and pretreatment sales, we remove 52.4% of total purchases during the campaign, which in turn shrinks our confidence intervals by 31%. As our title suggests, less data means more precise estimates.</p><p>Next, we apply our covariates approach to increase the precision of our estimates. Adding covariates to the TOT regression improves precision by reducing the unexplained variance in the dependent variable. 3 Specifically, these covariates include: demographics, retailer-defined customer segments, consumer sales history, and ad-exposure intensity. The demographic covariates include indicator variables for gender, age, and state of residence as well as a scalar variable for the time since the consumer signed up with Yahoo!. The retailer-defined RFM customer segments include Recency of last purchase, Frequency of past purchases, and Monetary value (total lifetime spending at the retailer). We include 54 variables capturing past purchases amounts over the two years before the campaign as well as purchases prior to the first exposure during the campaign. The ad-exposure-intensity covariates are a set of indicator variables for the total number of experimental ads delivered and for the day of the consumer's first ad exposure. To the extent that shopping behavior is correlated with current online browsing activity, the exposure intensity fixed effects will improve efficiency. In columns ( <ref type="formula">4</ref>)-( <ref type="formula">7</ref>), we gradually add these different covariate types. The historical sales and customer category covariates account for nearly all of the 5% improvement in precision. The demographic and exposure-intensity covariates provide almost no precision improvement. In total, the full regression model in column (7) includes 236 covariates in addition to the Full and Half treatment dummy variables but only achieves a R 2 of 0.09.</p><p>Note that these results apply to a retailer of occasionally purchased goods; past purchase covariates may prove more useful for frequently purchased goods. Apparel retailer sales are difficult to predict because-unlike consumer packaged goods like milk-transactions are infrequent and highly variable conditional on purchase. A total of 7.7% of control group users transacted during the campaign after their first ad exposure, and the standard deviation in sales conditional on transacting is $385. In Online Appendix A.2.3, Table <ref type="table">5</ref> column (2) reveals that even the transaction indicator outcome is difficult to predict, as the R 2 there is only 0.15. In an unpublished study with another apparel retailer, we find comparable R 2 for sales regressions that include past sales covariates: the R 2 varies between 0.017 and 0.073 across seven campaigns.</p><p>Including covariates improves precision by 5% (columns 3-7) across Full and Half groups, while pruning irrelevant data improves precision by 31% (columns 1-3) on average. Put another way, the experiment would have to be 10% larger without covariates or 71% larger without control ads to maintain the same measurement precision. Collectively, covariates and control ads boost precision by 34%, which would otherwise require an 80% larger sample of 5.6 million users as well as 80% larger ad spend. Though we find covariates to be less effective at improving precision, covariates may be inexpensive to include and serve to validate the experimental randomization. Control ads are expensive, since one has to pay for additional advertising inventory <ref type="bibr" target="#b14">(Johnson et al. 2016</ref> suggest a low-cost alternative), but they facilitate data pruning and thereby improve precision five times more than covariates. This is an example where less is more: subtracting data proves more valuable than adding data.</p><p>Our preferred experimental estimator-in column (7) of Table <ref type="table" target="#tab_4">2</ref>-measures a $0.477 (s.e. $0.204) increase in average sales from the ads in the Full group and a $0.221 (s.e. $0.209) increase in the Half group. Though all of the estimates in Table <ref type="table" target="#tab_4">2</ref> are unbiased, we prefer the estimates in column (7) as they are the most precise. These point estimates with covariates are more conservative, as they are smaller than those in column (3). The point estimates in column (7) likely fall because they account for differences like the slightly lower sales in the Control group in the two weeks before treatment (see Table <ref type="table" target="#tab_2">1</ref>). The preferred Full treatment effect is statistically significant at the 5% level (p-value 0.020) and represents a 3.6% sales lift over the Control group. The Half treatment effect is not significantly different from zero (p-value 0.289), and the joint F-test is marginally significant (p-value 0.065). The point estimates indicate that doubling the advertising approximately doubles the effect on purchases, but the precision of these estimates is too low for us to have great confidence in the result. Recall from our power calculations in Section 3 that this is the most likely outcome: under our proposed alternative hypothesis of a 50.</p><p>Our estimates imply a relatively high elasticity of sales with respect to advertising of about 0.19. Elasticity is the derivative of sales with respect to advertising, multiplied by the advertising-to-sales ratio. For the derivative of revenue with respect to advertising, we divide the incremental effect of ads in the Full group by the cost of the advertising ($4.60 per thousand impressions (CPM), with 33.4 ads delivered per person): (dR/dA) $0.477/(33.4 √ó $0.0046) 3.10. Elasticity depends crucially on the interpretation of the advertising-to-sales ratio, which we interpret as the retailer's total advertising across channels. Since we were not given the advertising-to-sales ratio of the retailer, we impute this ratio to be 6% from the financial filings of a competitor. Our short-run elasticity of 3.1√ó6% 0.19 exceeds the average elasticity of 0.12 and a median of 0.05 given in the metastudy by <ref type="bibr" target="#b28">Sethuraman et al. (2011)</ref>, though we note that they exclude all experimental estimates. The TV ad experiment metastudy by <ref type="bibr" target="#b12">Hu et al. (2007)</ref> calculates the elasticity of online display ads to be 0.11 using another approach: they use the campaign's ad weight over the during-campaign sales as the ads-to-sales ratio. By this method, our elasticity estimate is much lower at about 0.017. <ref type="bibr">4</ref> To make decisions about advertising, managers want not only to establish a revenue lift but also calculate return on investment. The profitability of advertising depends not only on the elasticity of advertising but also on the retailer's gross profit margin and the cost of the ads. Given 570,000 exposed users in each of the three treatment groups, our point estimates indicate that the Full campaign increased retail purchases by a dollar value of $273,000 ¬± 229,000, while the Half campaign increased purchases by $126,000 ¬± 234,000, using 95% confidence intervals. Compared with costs of about $88,000 for the Full campaign and $44,000 for the Half campaign, these point estimates indicate incremental revenues of around three times the cost. We assume a contribution margin of 50% for the retailer's sales. <ref type="bibr">5</ref> Our point estimates indicate a rate of return of 51% on the advertising dollars spent, but with a 95% confidence interval of [ ‚àí 101%, 204%].</p><p>Our short-run sales effect and corresponding rate-ofreturn estimates are likely conservative, as several factors attenuate the measurement. These factors include (1) incomplete attribution of sales to a given consumer, (2) mismatching of consumer retail accounts to Yahoo! accounts, (3) logged-in exposures viewed by other household members, and (4) observing purchases for a time period that fails to cover all longrun effects of the advertising. Though short-run effects could outpace the long-run effects because of intertemporal substitution as in <ref type="bibr" target="#b31">Simester et al. (2009)</ref>, our estimates in Online Appendix A.2.1, which include sales for the two weeks post-treatment, suggest a positive long-run effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>This paper provides a helpful case study of an ad experiment for both academics and practitioners, one that may be useful in the classroom. We examine the managerial question, How do I measure the total effect of my online display advertising if most of my sales are offline? A field experiment yields an elegant solution to this problem when combined with individual-level sales data. With the results from our large experiment, the retailer has confidence that their ads increased online and in-store sales. Despite the significant sales results and high ad elasticity measure, the confidence region for the profitability of the campaign includes zero. However, the point estimates indicate that the campaign was likely profitable in the short run, and we believe our estimates understate the true sales lift because of several measurement issues that attenuate the result and because our postcampaign estimates indicate that the campaign's benefits might carry over past the end of the measurement period.</p><p>This experiment highlights three nuances of online display ad field experiments. First, this study highlights the limits to what can be learned from large ad experiments and thus the challenge of optimizing advertising. As <ref type="bibr" target="#b20">Lewis and Rao (2015)</ref> elaborate, hundreds of millions of subjects may be required to experimentally evaluate a hypothesis positing a 10% profit on ad spending. By their nature, online display ad effect estimates are imprecise and managers should take point estimates with a grain of salt so as not to overreact to either good or bad news.</p><p>Second, covariate data serve two important roles in ad field experiments. Covariates improve the precision problem by decreasing the residual variance of the outcome variable. While covariates improved precision here by only 5%, this approach may perform better in settings with frequently purchased goods or in other ad media. In addition, covariates allow the experimentalist to validate the randomization as we do in Section 4, a best practice that is especially important in complex online ad systems.</p><p>Third, control ads increase precision-in our case, considerably more than do covariates. By trimming both unexposed users and outcomes prior to exposure, control ads increase the precision of our estimates by 31%-equivalent to increasing the number of subjects by 71%. Nonetheless, control ads are seldom used because they are expensive and incompatible with cost-per-click and cost-per-action optimized campaigns. We note that the ghost ad methodology developed by <ref type="bibr" target="#b14">Johnson et al. (2016)</ref> resolves these problems and still delivers the precision gains of control ads.</p><p>Unbiased field experiments measuring the effectiveness of advertising can contribute both to the science of consumer choice and to the advertising decisions of managers. We look forward to future research including studies that leverage either ghost-ad and intentto-treat (see, e.g., <ref type="bibr" target="#b9">Gordon et al. 2016</ref>) experimentation platforms and illuminates how advertising influences consumer choice.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Control Ad: Promoting Yahoo! Search</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Histogram of Average Weekly Purchases During the Two Years Before the Experiment</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Histogram of Total Ad Exposures (Both Retailer and Control Ads)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Johnson, Lewis, and Reiley:</head><label></label><figDesc>When Less is More 44 Marketing Science 36(1), pp. 43-53, ¬© 2017 INFORMS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Co-Branded Retailer-Designer Example (Experiment Uses Neither Target Nor Missoni)    </figDesc><table><row><cell>Marketing Science 36(1), pp. 43-53, ¬© 2017 INFORMS</cell></row><row><cell>Figure 1. Source. Target (2011).</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Summary Statistics and Experimental Validation</figDesc><table><row><cell></cell><cell>Treatment group</cell><cell></cell><cell></cell></row><row><cell>Full</cell><cell>Half</cell><cell>Control</cell><cell>p-value</cell></row></table><note>Note. Sample includes only those customers who are uniquely matched to a single Yahoo! user identifier.a Webpage views on Yahoo! properties during the two weeks of the campaign.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 .</head><label>2</label><figDesc>Effect of Advertising on Sales: Refinements in Precision Average effect of Treatment on the Treated estimates. Dependent variable is sales during the two weeks of the experiment. Robust standard errors are in parentheses.</figDesc><table><row><cell></cell><cell>(1)</cell><cell>(2)</cell><cell>(3)</cell><cell>(4)</cell><cell>(5)</cell><cell>(6)</cell><cell>(7)</cell></row><row><cell>Subset of users a</cell><cell>Everyone</cell><cell>Treated</cell><cell>Treated</cell><cell>Treated</cell><cell>Treated</cell><cell>Treated</cell><cell>Treated</cell></row><row><cell>Sales after first ad exposure b</cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell></row><row><cell>Full treatment ($)</cell><cell>0.673  *  *</cell><cell>0.525  *  *</cell><cell>0.559  *  *</cell><cell>0.553  *  *</cell><cell>0.535  *  *</cell><cell>0.486  *  *</cell><cell>0.477  *  *</cell></row><row><cell></cell><cell>(0.317)</cell><cell>(0.237)</cell><cell>(0.217)</cell><cell>(0.217)</cell><cell>(0.213)</cell><cell>(0.204)</cell><cell>(0.204)</cell></row><row><cell>Half treatment ($)</cell><cell>0.0248</cell><cell>0.189</cell><cell>0.307</cell><cell>0.307</cell><cell>0.239</cell><cell>0.241</cell><cell>0.221</cell></row><row><cell></cell><cell>(0.311)</cell><cell>(0.235)</cell><cell>(0.217)</cell><cell>(0.217)</cell><cell>(0.212)</cell><cell>(0.209)</cell><cell>(0.209)</cell></row><row><cell>Constant ($)</cell><cell>15.52  *  *  *</cell><cell>15.53  *  *  *</cell><cell>13.17  *  *  *</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>(0.122)</cell><cell>(0.166)</cell><cell>(0.154)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Covariates</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Demographics (126 variables) c</cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell></row><row><cell>Customer categories (13 variables) d</cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell>x</cell><cell></cell></row><row><cell>Past sales, two years (54 variables) e</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell>x</cell><cell></cell></row><row><cell>Exposure intensity (43 variables) f</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>x</cell><cell></cell></row><row><cell>Observations</cell><cell>3,096,577</cell><cell>1,714,704</cell><cell>1,714,704</cell><cell>1,714,704</cell><cell>1,714,704</cell><cell>1,714,704</cell><cell>1,714,704</cell></row><row><cell>R 2</cell><cell>0.000</cell><cell>0.000</cell><cell>0.000</cell><cell>0.001</cell><cell>0.042</cell><cell>0.090</cell><cell>0.091</cell></row><row><cell>Notes.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>a Treated users are those who are exposed to either the retailer or the control ad. b Sales after the first ad exposure modifies the outcome measure to exclude all sales prior to a user's first exposure to either the retailer or the control ad.c Demographic covariates include individual gender, age, and state dummies as well as the user's tenure as a Yahoo! customer.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Johnson, Lewis, and Reiley: When Less is More Marketing Science 36(1), pp. 43-53, ¬© 2017 INFORMS</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors would like to thank Valter Sciarillo, Jennifer Grosser Carroll, Taylor Schreiner, Eddie Babcock, Iwan Sakran, and many others at Yahoo! and at the client retailer who made this research possible. The authors thank Eric Anderson, Susan Athey, Mitch Lovett, Ben Jones, Preston McAfee, Rob Porter, Justin Rao, Elie Tamer, and Florian Zettelmeyer for helpful discussions, and Mary Kraus for proofreading. The authors performed this research while employed at Yahoo! Research. The authors acknowledge Yahoo! both for its financial support and for its support of unbiased scientific research through its ex ante decision to allow publication of the results of the experiment no matter how they turned out.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Endnotes <ref type="bibr">1</ref> These campaigns were purchased on an cost-per-impression, not a cost-per-click, basis. This avoids distortions induced by ad servers optimizing delivery patterns in the treatment and control groups because of the retailer and control ads having different clickthrough rates. Such distortions can render the control ads unsuitable for tagging counterfactual exposures in the control group. See <ref type="bibr" target="#b14">Johnson et al. (2016)</ref> for a discussion and a control-ad alternative that is robust to an ad server's campaign optimization.</p><p>2 This is numerically equivalent to computing a local average treatment effect by using the random assignment as an instrument for treatment. The unscaled, intent-to-treat estimates are $0.37 for the Full group and $0.01 for the Half group. 3 A regression model with a given R 2 reduces the standard errors of our treatment effect estimates by ‚âà 1 ‚àí ‚àö 1 ‚àí R 2 . 4 We calculate the "local" elasticity measure at the Half group ad intensity level since this level of intensity is normal for the retailer. We use the increase in incremental sales from the Half to the Full group as our derivative ($0.477 ‚àí $0.221)/(33.42 √ó $0.0046 ‚àí 16.69 √ó $0.0046), using this ad campaign's cost of $4.60 CPM. Since sales in a Half group among those exposed to 17 ads (¬±2 ads) is $15.20, we use $15.20/(16.7 √ó $0.0046) as the "local" ads-to-sales ratio. <ref type="bibr">5</ref> We base this on conversations with retail experts, supplemented with references to similar retailers' financial statements.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Social influence in social advertising: Evidence from field experiments</title>
		<author>
			<persName><forename type="first">E</forename><surname>Bakshy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Eckles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Yan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rosenn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th ACM Conf. Electronic Commerce</title>
				<meeting>13th ACM Conf. Electronic Commerce<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2012" />
			<biblScope unit="page" from="146" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Which products are best suited to mobile advertising? A field study of mobile display advertising effects on consumer attitudes and intentions</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Bart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sarvary</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="270" to="285" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Consumer heterogeneity and paid search effectiveness: A large-scale field experiment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Blake</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Nosko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tadelis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="155" to="174" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Advertising as an economic-growth engine</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bughin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Spittaels</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>McKinsey &amp; Company</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">U.S. digital future in focus</title>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>comScore, Reston, VA</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Datalogix announces Facebook partner categories for CPG, retail and automotive brands</title>
		<author>
			<persName><surname>Datalogix</surname></persName>
		</author>
		<ptr target="http://www.datalogix.com/2013/04/datalogix-announces-facebook-partner-categories-for-cpg-retail-and-automotive-brands/" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Advertising experiments at the Campbell Soup company</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Eastlack</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="57" to="71" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Gerber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">P</forename><surname>Green</surname></persName>
		</author>
		<title level="m">Field Experiments: Design, Analysis, and Interpretation</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>W.W. Norton</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Online display advertising: Targeting and obtrusiveness</title>
		<author>
			<persName><forename type="first">A</forename><surname>Goldfarb</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="389" to="404" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">A comparison of approaches to advertising measurement: Evidence from big field experiments at Facebook. Working paper</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zettelmeyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Bhargava</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chapsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<pubPlace>Evanston, IL</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Northwestern University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Do Super Bowl ads affect brand share? Working paper</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">R</forename><surname>Hartmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Klapper</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<pubPlace>Palo Alto, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Stanford University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Effects of Internet display advertising in the purchase funnel: Model-based insights from a randomized field experiment</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">R</forename><surname>Hoban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bucklin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="375" to="393" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">An analysis of real world TV advertising tests: A 15-year update</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Lodish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Krieger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising Res</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="341" to="353" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><surname>Iab</surname></persName>
		</author>
		<ptr target="http://www.iab.net/AdRevenueReport" />
		<title level="m">IAB Internet advertising revenue report 2013</title>
				<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Ghost ads: Improving the economics of measuring ad effectiveness. Working paper</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>Nubbemeyer</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<pubPlace>University of Rochester, Rochester, NY</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Cross channel effects of search engine advertising on brick and mortar retail sales: Insights from multiple large scale field experiments on Google</title>
		<author>
			<persName><forename type="first">K</forename><surname>Kalyanam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Mcateer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Marek</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hodges</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>Santa Clara, CA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Santa Clara University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">When does retargeting work? Information specificity in online advertising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Lambrecht</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Tucker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="561" to="576" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">An evaluation of methods used to assess the effectiveness of advertising on the Internet</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lavrakas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
	<note>Interactive Advertising Bureau</note>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Where&apos;s the &quot;Wear-Out?&quot;: Online display ads and the impact of frequency</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<pubPlace>Cambridge</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Department of Economics, Massachusetts Institute of Technology</orgName>
		</respStmt>
	</monogr>
	<note>Unpublished doctoral thesis</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Display advertising&apos;s competitive spillovers to consumer search</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Nguyen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quant. Marketing Econom</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="93" to="115" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The unfavorable economics of measuring the returns to advertising. Quart</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econom</title>
		<imprint>
			<biblScope unit="volume">130</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1941" to="1973" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Online ads and offline sales: Measuring the effect of retail advertising via a controlled experiment on</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Reiley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Yahoo! Quant. Marketing Econom</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="235" to="266" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Here, there, and everywhere: correlated online behaviors can lead to overestimates of the effects of advertising</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Lewis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Reiley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 20th Internat. Conf. World Wide Web</title>
				<meeting>20th Internat. Conf. World Wide Web<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="157" to="166" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">How TV advertising works: A meta-analysis of 389 real world split cable TV advertising experiments</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Lodish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kalmenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Livelsberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lubetkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="139" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Twitter blog: New ways to create and use tailored audiences</title>
		<author>
			<persName><forename type="first">K</forename><surname>Lynn</surname></persName>
		</author>
		<ptr target="https://blog.twitter.com/2014/new-ways-to-create-and-use-tailored-audiences" />
		<imprint>
			<date type="published" when="2014-01-14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Ramaswamy</surname></persName>
		</author>
		<ptr target="http://adwords.blogspot.com/2015/09/Google-brings-you-closer-to-your-customers.html" />
		<title level="m">Google AdWords blog: Google brings you closer to your customers in the moments that matter. (September 27</title>
				<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Effect of temporal spacing between advertising exposures: Evidence from an online field experiment</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sahni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quant. Marketing Econom</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="203" to="247" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Advertising spillovers: Field experimental evidence and implications for returns from advertising</title>
		<author>
			<persName><forename type="first">N</forename><surname>Sahni</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res. Forthcoming</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">How well does advertising work? Generalizations from meta-analysis of brand advertising elasticities</title>
		<author>
			<persName><forename type="first">R</forename><surname>Sethuraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Tellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Briesch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="457" to="471" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">Lewis</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Reiley</forename></persName>
		</author>
		<idno>INFORMS 53</idno>
	</analytic>
	<monogr>
		<title level="j">When Less is More Marketing Science</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="43" to="53" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Positive spillovers and free riding in advertising of prescription pharmaceuticals: The case of antidepressants</title>
		<author>
			<persName><forename type="first">B</forename><surname>Shapiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Political Econom. Forthcoming</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dynamics of retail advertising: Evidence from a field experiment</title>
		<author>
			<persName><forename type="first">D</forename><surname>Simester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econom. Inquiry</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="482" to="499" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Ask your doctor? Direct-to-consumer advertising of pharmaceuticals. Working paper</title>
		<author>
			<persName><forename type="first">M</forename><surname>Sinkinson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Starc</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>Philadelphia</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Pennsylvania</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Super returns to Super Bowl ads? Working paper</title>
		<author>
			<persName><forename type="first">S</forename><surname>Stephens-Davidowitz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Varian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="https://corporate.target.com/article/2011/09/missoni-for-target-margherita-maccapani-missoni-on" />
	</analytic>
	<monogr>
		<title level="m">Missoni for Target-Margherita Maccapani Missoni on Missoni history</title>
				<imprint>
			<date type="published" when="2011-09-06" />
		</imprint>
		<respStmt>
			<orgName>University of California, Berkeley. Target</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Star digital: Assessing the effectiveness of display advertising</title>
		<author>
			<persName><forename type="first">T</forename><surname>Yildiz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Narayanan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard Bus. Rev.: Case Study</title>
		<imprint>
			<date type="published" when="2013-03-06" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
