<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Disentangling Preferences and Learning in Brand Choice Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Sangwoo</forename><surname>Shin</surname></persName>
							<email>shin58@purdue.edu</email>
						</author>
						<author>
							<persName><forename type="first">Sanjog</forename><surname>Misra</surname></persName>
							<email>misra@simon.rochester.edu</email>
						</author>
						<author>
							<persName><forename type="first">Dan</forename><surname>Horsky</surname></persName>
							<email>dan.horsky@simon.rochester.edu</email>
						</author>
						<author>
							<persName><forename type="first">Monte</forename><surname>Carlo</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Krannert School of Management</orgName>
								<orgName type="institution">Purdue University</orgName>
								<address>
									<postCode>47907</postCode>
									<settlement>West Lafayette</settlement>
									<region>Indiana</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Simon School of Business</orgName>
								<orgName type="institution">University of Rochester</orgName>
								<address>
									<postCode>14627</postCode>
									<settlement>Rochester</settlement>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Disentangling Preferences and Learning in Brand Choice Models</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
					</monogr>
					<idno type="DOI">10.1287/mksc.1110.0680</idno>
					<note type="submission">Received: November 14, 2007; accepted: January 4, 2011; Eric Bradlow served as the</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayesian learning</term>
					<term>brand choice</term>
					<term>preferences</term>
					<term>state dependence</term>
					<term>Markov chain</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please scroll down for article-it is on subsequent pages</head><p>With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning opportunities for individual professionals, and organizations of all types and sizes, to better understand and use O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Consumers choose between brands based on their individual preferences, past experiences, and the brands' marketing mix elements. The marketing and economics literatures are replete with examples of studies that investigate the relative impact each of these factors has on the brand choice decision. Although this literature is quite heterogeneous in its findings, what has emerged as a consensus is that the separate identification of these effects is nontrivial. It is now well documented (see, e.g., Heckman 1991) that the effect individual preferences (heterogeneity) and past experiences (state dependence) have on brand choices can be confounded. That is, we know that a failure to adequately account for heterogeneity in preferences may lead to a bias in the effect of state dependence. This in turn may also lead to a bias in the estimates pertaining to marketing mix effects such as price.</p><p>In recent years there has been a growing stream of literature in marketing and economics that aims to structurally model the beliefs that consumers have about each brand and the role such beliefs play in choice decisions. In particular, this literature treats consumers as Bayesian learners and allows them to update their beliefs via signals obtained at each purchase occasion. For implementation purposes, the Bayesian learning framework is embedded within a discrete choice setting that is then calibrated on consumer choice data (see, e.g., <ref type="bibr" target="#b7">Erdem and Keane 1996</ref><ref type="bibr" target="#b0">, Ackerberg 2003</ref><ref type="bibr" target="#b19">, Mehta et al. 2003</ref>. This approach specifies a structural model of the brand choice process and allows researchers to delve into the underpinnings of brand choice behavior.</p><p>Said differently, the Bayesian learning model can be thought of as a framework that allows for higherorder state dependence, albeit in a fairly parsimonious manner. As such, the discrete choice model with Bayesian learning is data intensive and makes disentangling preference heterogeneity and state dependence even more difficult. The key problem, simply stated, is that consumer learning is not fully identified from revealed choice data. This identification problem has been recognized <ref type="bibr" target="#b7">(Erdem and Keane 1996)</ref>, and the typical solution is to assume a common prior <ref type="bibr">Shin, Misra, and</ref>  across consumers or to somehow use past data to calibrate priors. The crux of the issue is that without data on initial conditions, there is no way of identifying the rate and amount of learning for a given consumer. Note that this problem persists even if data were available from the first choice onward because there remains an informational insufficiency, because prior beliefs at the initial point are still unavailable and remain heterogeneous across consumers. Ignoring this missing information and the implicit heterogeneity induces biases in our understanding of consumer learning and will almost surely misrepresent other constructs of heterogeneity. We note that the problem cannot simply be resolved with long panels because such data are not informative about the consumers' initial priors.</p><p>What additional information, then, can researchers collect that would help resolve these issues? The answer is simply to augment revealed preference data with information on consumer preferences. Ideally, if a consumer's true preferences for the relevant brands were available at each purchase occasion, the researcher could pin down the precise underlying behavior that drives observed choices. Such preference information, however, is tedious and expensive to collect. A second-best alternative is to gather data on preferences at some point prior to choices being observed. Such information substantially reduces the researcher's burden about inferring initial priors by substituting data in place of assumptions. As a result, one is better able to resolve the confounding between learning and preference heterogeneity by allowing this augmented preference information to offer a competing explanation for the observed choice sequence.</p><p>For instance, if a consumer's preference data reveal a strong idiosyncratic preference for a particular brand of toothpaste (such as Crest) as well as a high degree of familiarity with the brand, the researcher should be able to rule out a learning-based explanation. Sensitivity to marketing mix variables is also better assessed in the presence of such preference information. Continuing the earlier example, perhaps a price discount on the last shopping trip seems to have induced the consumer to switch from her preferred brand (Crest) to a potentially less preferred one (Colgate). Clearly, the availability of preference information now offers insights into the degree of substitutability between the two brands and would directly inform the degree to which the consumer is price sensitive. If data reveal that Colgate and Crest are equally preferred, it would imply that she is less price sensitive than if the consumer strongly preferred Crest to Colgate. Consequently, the price differential required to induce a brand switch from Crest to Colgate should be smaller in the former case than in the latter, and this has direct implications on the estimates of price elasticity. By a similar argument, the effect of other marketing mix elements would also be more cleanly estimated.</p><p>In general, there is widespread agreement that stated preferences are based on the true underlying preferences of the consumer. Conjoint studies routinely use multiattribute utility models to construct estimates of consumers' utility functions and use them to predict choices. The previous literature has also paid some attention to the importance of combining revealed preference data with such stated preference data. Early studies such as Ben-Akiva and <ref type="bibr" target="#b1">Morikawa (1990)</ref>, <ref type="bibr" target="#b12">Hensher and Bradley (1993)</ref>, and <ref type="bibr" target="#b13">Horsky and Nelson (1992)</ref> investigated the behavioral and cognitive process through which stated preference data are generated, and they explained why such data are predictive of actual market behavior. Using cross-sectional health-care plan choice and survey data, <ref type="bibr" target="#b10">Harris and Keane (1999)</ref> showed that incorporation of the attitudinal data leads to a substantial improvement in choice model fit and more precise estimates of all choice model parameters. <ref type="bibr" target="#b15">Horsky et al. (2006)</ref> reported similar findings in the context of scanner panel data analysis. The above-cited studies are primarily concerned with choice environments in which decision makers act on full information. There has been, however, a growing trend in recent years to model choice processes in which decision makers act with partial information. <ref type="bibr" target="#b17">Manski (2004)</ref> recently discussed identification of such decision processes and concluded that choice data alone do not suffice to infer about the underlying behavior. In the spirit of <ref type="bibr" target="#b17">Manski (2004)</ref>, we attempt to empirically show how misleading inferences about the consumer's learning process can be, particularly when this process is calibrated using only scanner panel data.</p><p>In the current study we estimate a logit-based Bayesian learning model in which learning parameters are allowed to be fully heterogeneous via the augmentation of survey information on consumer preferences and familiarities. By comparing it with the Bayesian learning model calibrated on standard scanner panel data alone, we make a number of substantive contributions to the literature. Our findings enhance the current knowledge about the consumer brand choice process. First, we demonstrate how the inclusion of preference and familiarity information substantially alters our understanding of the brand choice process. In particular, the absence of this information significantly overestimates the amount of aggregate-level learning. Correspondingly, the role of preference heterogeneity is much more pronounced in the presence of survey information. Second, our analysis allows us to take a deeper look at the individuallevel choice process and to consequently document the effect that preference heterogeneity and learning have on explaining individual-level purchase patterns. Finally, we find that the inclusion of preference 117 information uncovers statistically and managerially significant biases in parameter estimates, such as price sensitivity, and the degree of parameter heterogeneity. Although our results are an initial foray into the topic and are based on a single data set and one particular model specification, they do offer the marketing scientist new insights into disentangling the impact of preferences and learning in consumer's brand choice.</p><p>The rest of this paper is organized as follows: In the next section, we lay out the Bayesian learning process and illustrate how to embed it in a discrete choice framework. In §3 we describe our unique data set, which combines stated preferences (survey) and actual purchase data (scanner panel) for the same group of consumers in the toothpaste market. We specify how the survey information on preferences and familiarity of the brands is incorporated into the Bayesian learning model. In particular, our specification of the learning process uses additional parameters that allow the consumer to update fully heterogeneous initial preferences. At the same time, we discuss the identification issues associated with estimation of the Bayesian learning model using scanner panel data. We then describe our estimation methodology and follow this with a discussion of our empirical findings. The parameter estimates of the Bayesian learning model that relate to preference heterogeneity, learning, and marketing mix variables are provided. We follow with discussing managerial and research implications of our study. We conclude with a summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Bayesian Learning Model</head><p>The seminal work of <ref type="bibr" target="#b7">Erdem and Keane (1996)</ref> has generated a stream of papers in marketing and economics that incorporate the Bayesian learning process into a discrete choice framework. <ref type="bibr">1</ref> These models have been used to model choices in various application areas, from consumer's brand choice decisions (e.g., <ref type="bibr" target="#b7">Erdem and Keane 1996</ref><ref type="bibr" target="#b0">, Ackerberg 2003</ref><ref type="bibr" target="#b19">, Mehta et al. 2003</ref> to physicians' prescription decisions (e.g., <ref type="bibr" target="#b3">Crawford and</ref><ref type="bibr">Shum 2005, Narayanan and</ref><ref type="bibr" target="#b21">Manchanda 2009)</ref>. In keeping with this literature, we will assume that beliefs are updated via a Bayesian learning mechanism with normal priors and signals.</p><p>In addition, we will also assume that consumers are risk neutral and myopic.</p><p>In the rest of this section, we lay out the model specification and main assumptions underlying the Bayesian learning model. Our exposition in the sequel focuses mainly on the Bayesian learning model in the context of its estimation using scanner panel data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">The Bayesian Quality Learning Process</head><p>In the framework described below, consumers learn about brand quality by updating their beliefs over successive purchase occasions. More specifically, consumers receive a quality signal after each purchase, combine the information contained in this signal with their prior beliefs, and construct a posterior belief in accordance with Bayes's rule. In this context, "learning" is conceptualized as having two distinct effects: bias reduction and uncertainty reduction. The first effect stems from the stochastic convergence of a consumer's quality perception to the true mean quality (bias reduction), whereas the second effect reflects the deterministic convergence of uncertainty to zero (uncertainty reduction). This two-dimensional nature of the Bayesian learning process yields a parsimonious yet flexible learning mechanism.</p><p>Let Q S ij t denote a signal about brand j's quality that consumer i receives after purchasing brand j at time t. We assume that quality signals are generated from the following normal distribution: 2</p><formula xml:id="formula_0">Q S ij t ∼ N Q ij 2 Q ij (1)</formula><p>where Q ij is consumer i's true mean quality assessment (or match value) of brand j, and 2 Q ij is the signal variance of brand j faced by consumer i. Given that 2 Q ij &gt; 0, quality signals only contain partial information about the unknown true mean quality. Again, the quality signal is assumed to be realized only after consumer i purchases and consumes brand j at time t.</p><p>Consumer i is assumed to have an initial quality belief about the unknown true mean quality of brand j, as given below:</p><formula xml:id="formula_1">Q ij 0 = N Q ij 0 2 Q ij 0 (2)</formula><p>In the above equation, Q ij 0 and 2 Q ij 0 are initial beliefs about the mean and variance of brand j's quality at time 0, respectively. We note here that in the Bayesian paradigm, prior beliefs at any time t are simply the posterior beliefs at time t − 1 In other words, successively combining prior beliefs with the consumption signals allows us to construct the posterior belief at any time t &gt; 0 This time-specific posterior belief also follows a normal distribution and is denoted bỹ</p><formula xml:id="formula_2">Q ij t = N Q ij t 2 Q ij t (3)</formula><p>Because quality beliefs at any time t ≥ 0 are normally distributed, they are completely characterized by their mean and variance parameters. In other Marketing Science 31(1), pp. 115-137, © 2012 INFORMS words, the laws of motion for the posterior mean and variance are sufficient to characterize the evolution of a consumer's quality beliefs. If consumer i updates posterior beliefs at time t − 1 (or prior belief at time t) through the realization of quality signals in a Bayesian fashion, the posterior mean and variance at time t can be updated in the following recursive manner:</p><formula xml:id="formula_3">Q ij t = 2 Q ij t 2 Q ij t−1 Q ij t−1 + y ij t 2 Q ij t 2 Q ij Q S ij t</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>and</head><p>(4)</p><formula xml:id="formula_4">1 2 Q ij t = 1 2 Q ij t−1 + y ij t 1 2 Q ij (5)</formula><p>where y ij t is an indicator variable such that y ij t = 1 if consumer i purchases brand j at time t and y ij t = 0 otherwise. Successive substitutions of Equations ( <ref type="formula">4</ref>) and ( <ref type="formula">5</ref>) result in alternative expressions for Q ij t and 2 Q ij t as given by</p><formula xml:id="formula_5">Q ij t = 2 Q ij t 2 Q ij 0 Q ij 0 + 2 Q ij t 2 Q ij t =1 y ij Q S ij and (6) 1 2 Q ij t = 1 2 Q ij 0 + t =1 y ij 2 Q ij<label>(7)</label></formula><p>From an estimation standpoint, it is useful to construct an alternative expression of the Bayesian learning process using a change of variables. To do this we define two new variables, Q ij t = Q ij t − Q ij and S ij t = Q S ij t −Q ij . These new variables, Q ij t and S ij t , are referred to as perception bias and signal noise, respectively. The former measures how much consumer i's mean quality perception deviates from the true mean quality, whereas the latter represents a noise component of the quality signal. Using these transformations and combining Equation ( <ref type="formula" target="#formula_5">7</ref>) with (6) lead to the final expression for the mean quality perception, given by</p><formula xml:id="formula_6">Q ij t = Q ij + Q ij t = Q ij + 2 Q ij / 2 Q ij 0 Q ij 0 + t =1 y ij S ij 2 Q ij / 2 Q ij 0 + t =1 y ij<label>(8)</label></formula><p>The mean quality perception starts with Q ij + Q ij 0 at the initial period (t = 0), evolves over time as suggested in Equation (8) (for t ≥ 1), and converges to Q ij at steady state (t = t * , where Q ij t * = 0 and 2 Q ij / 2 Q ij t * = ). The above equation represents the crux of the Bayesian learning process. It highlights the fact that the mean quality perception Q ij t can be decomposed into two components: a time-invariant Q ij and a time-varying Q ij t . The existence of the timevarying component differentiates the Bayesian learning process from the zero-order process. If Q ij 0 = 0 and 2 Q ij 0 = 0 (therefore, Q ij t = 0 ∀ t), the Bayesian learning process collapses to the zero-order process (i.e., Q ij t = Q ij ). This case describes a consumer who is no longer learning (about brands) because his or her quality perception already converged to the true mean quality, and no uncertainty about his or her quality perception remains. The unique specification of the time-varying component also differentiates the Bayesian learning process from the alternative approaches of modeling time-varying preferences such as the popular inertia/purchase reinforcement process (i.e., Q ij t = Q ij + i y ij t−1 ). There are two noticeable differences between the inertia and Bayesian learning processes. First, the extent of state dependence is different. The inertia process has only a first-order effect (i.e., only the brand choice lagged by one time period affects the current brand choice decision), whereas the Bayesian learning process is a higher-than-first-order process (which is often referred to as an infinite-order process, in which the entire choice history affects the current brand choice decision). More importantly, the nature of state dependence is different. The effect of inertia is usually modeled as not varying across brands or over time, whereas that of learning is heterogeneous across brands and is diminishing over time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Utility Specification</head><p>Given the specification of a consumer learning process, we now move to describing the consumers' utility and choice framework. As is typical in discrete choice models, we specify consumer i's utility from purchasing brand j at time t as the following linear form:</p><formula xml:id="formula_7">U ij t =Q ij t−1 + X ij t i + U ij t<label>(9)</label></formula><p>whereQ ij t−1 is consumer i's beliefs about brand j s quality at time t, X ij t stands for the vector of marketing mix variables of brand j observed by consumer i at time t, i is the corresponding vector of response coefficients, and U ij t stands for utility components unobserved to researchers. Note that when consumer i makes a purchase decision at time t, the brand quality signal is not yet realized and hence is not considered an observable. In other words, quality beliefs in our notation are lagged by one time period to represent the fact that the quality beliefs updated after purchase occasion at time t − 1 are relevant to purchase decision at time t. SinceQ ij t−1 is a random variable, consumer i bases decisions on the expected value of utility with respect to quality beliefs. This expected utility can be computed as Using the alternative parametrization introduced earlier in Equation ( <ref type="formula" target="#formula_6">8</ref>), we can also express the above equation as</p><formula xml:id="formula_8">U E ij t = E U ij t = E Q ij t−1 + X ij t i + U ij t = Q ij t−1 + X ij t i + U ij t<label>(</label></formula><formula xml:id="formula_9">U E ij t = Q ij + Q ij t−1 + X ij t i + U ij t (11)</formula><p>The assumption that U ij t is independent and identically distributed (iid) Type I extreme value distributed completes the model specification and leads to the random coefficient multinomial logit model where brand-specific intercepts are composed of true mean qualities (Q ij ) and perception biases ( Q ij t−1 ). Notice that the model specification presented here is simpler than are other variants of the Bayesian learning model available in the literature. There are several ways to extend the current specification if the researcher so desires. First, the assumption that U ij t is multivariate normal distributed leads to the random coefficient multinomial probit model with a full covariance matrix <ref type="bibr" target="#b21">(Narayanan and Manchanda 2009)</ref>. Second, risk aversion can be incorporated via the Constant Absolute Risk Aversion subutility function <ref type="bibr" target="#b7">(Erdem and Keane 1996</ref><ref type="bibr" target="#b3">, Crawford and Shum 2005</ref><ref type="bibr" target="#b21">, Narayanan and Manchanda 2009</ref>. Third, forgetting can be embedded in the learning model by allowing for the possibility of imperfect recall <ref type="bibr" target="#b20">(Mehta et al. 2004)</ref>. Finally, forward looking can be modeled together with learning <ref type="bibr" target="#b7">(Erdem and Keane 1996</ref><ref type="bibr" target="#b0">, Ackerberg 2003</ref><ref type="bibr" target="#b3">, Crawford and Shum 2005</ref>. In this study, we keep the model specification as simple as possible to focus on our main research questions by avoiding methodological and interpretational complications. 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Identification Issues</head><p>In what follows, we informally discuss the identification of the parameters in Bayesian learning models. Identification of the model parameters depends on the specification of the model as well as the data available. The Bayesian learning model presented <ref type="bibr">3</ref> The inclusion of forward-looking behavior substantially increases the computational burden because it requires solving a dynamic programming problem in the course of estimation. As a consequence, forward-looking behavior is often introduced at the expense of heterogeneity in the Bayesian learning model. Furthermore, the incorporation of forward-looking behavior is usually undertaken to allow for experimentation, which in the context of a mature product category with experienced buyers seems less important. We also ignore risk aversion in our application. Given that the focus of this study is to discuss the role of survey information augmented to scanner panel data in improving identification of the Bayesian learning model, we conjecture that the findings reported in this study would be robust to the change of model specification. Finally, our results are based on a multinomial logit (MNL) specification. A more general framework, such as the multinomial probit, will be able to capture correlations across brands at each purchase occasion and, consequently, might offer richer and cleaner insights into learning.</p><p>in the earlier section is not identifiable in its current form. Some parameters are by design unidentifiable, whereas others are challenging to identify with typical scanner panel data. One therefore needs to impose a number of additional restrictions to achieve identification.</p><p>The set of parameters that characterize the Bayesian learning process is Q ij</p><formula xml:id="formula_10">2 Q ij Q ij 0 2 Q ij 0</formula><p>∀ i and j. From Equations ( <ref type="formula" target="#formula_5">7</ref>) and ( <ref type="formula" target="#formula_6">8</ref>) it is obvious that the initial perception variance 2 Q ij 0 and the quality signal variance 2 Q ij are not separately identified, but only their ratio, 2 Q ij / 2 Q ij 0 is identifiable. To resolve this, one usually sets 2 Q ij = 1 ∀ i and j. The literature adopts various rules in dealing with these identification issues. Whereas <ref type="bibr" target="#b19">Mehta et al. (2003)</ref> impose the same restriction to identify this ratio, <ref type="bibr" target="#b21">Narayanan and Manchanda (2009)</ref> use a different strategy in the sense that (i) their initial perception variance is only brand specific (i.e., 2 Q j 0 ) and is drawn from a common prior distribution, and (ii) the quality signal variance is only individual specific (i.e., 2 Q i ) and is estimated from data.</p><p>Under our specification, the interpretation of estimated 2 Q ij 0 is deemed relative to 2 Q ij = 1 (e.g.,ˆ 2</p><formula xml:id="formula_11">Q ij 0 = 1/2 implies that 2 Q ij 0 is one-half of 2 Q ij ).</formula><p>The true mean qualities, Q ij , can be thought of as steady-state individual-level intercept terms. As is typical, not all of these brand-specific Q ij s are identified, and we need to specify a reference brand (e.g., say, Q iJ = 0 .</p><p>A remaining question is how one identifies Q ij 0 and 2 Q ij 0 separately from Q ij . These prior quantities represent heterogeneous initial conditions that cannot simply be identified from revealed choice data without strong untestable assumptions. The identification problems arise because typical standard scanner panel data are usually left-truncated (initial conditions) and/or are often relatively short. In addition, typical patterns of choices in frequently purchased product categories make this identification task harder to conduct. First, the market share of brands covaries with changes in brands' marketing mix investments that could mask the systematic evolution of the market share, which is essential to separating the prior bias and uncertainty constructs from the steady-state intercepts. This problem is exacerbated because of the maturity of typical product categories for which scanner panel data are available. <ref type="bibr">4</ref> Second, consumers often purchase a brand from a small subset of the brands available in the product category. That is, y ij t = 0 for some j during the entire purchase history of consumer i. This implies that consumer i's quality beliefs about the unchosen brands do not evolve over time; consequently, for such a consumer, we cannot cleanly distinguish the prior means and variances from the steady-state qualities for these brands. Given these limitations of scanner panel data, researchers have no choice but to impose some homogeneity restrictions on Q ij 0 and 2 Q ij 0 to achieve identification. Typically, researchers make assumptions such as setting Q ij 0 =v j and 2 Q ij 0 =¯ 2 Q 0 Furthermore, one assumes that the panel data are sufficiently long so as to allow one to identify Q ij from the individual-level choice share near the end of the sample and¯ j from the difference of choice share between the early and late periods of the sample. Finally, one argues for the identification¯ 2 Q 0 by relying on the evolution patterns of choice shares over the sample period.</p><p>These identification problems are well recognized, and various authors have attempted to mitigate them by making innovative use of available data coupled with adjustments to model structure. Our identification strategy, which is detailed in the next section, is to use individual-level survey data to calibrate the prior constructs, which then will help identify both cross-sectional heterogeneity and the scope and nature of individual learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Data</head><p>In this section we describe the data used in our application. The data consist of typical scanner panel data augmented by a matched survey of the panelists' preferences toward the brands. After presenting the data, we discuss how the survey information is integrated into the model and, along with other assumptions, how it helps identify key constructs pertaining to the Bayesian learning process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Data Description</head><p>The empirical analysis in this study uses a unique data set on toothpaste choices and preferences obtained from IRI. The scanner panel data contain individual-level choice data over time, along with price and promotion information for the brands within the toothpaste category. Two marketing mix variables, price and in-store display, are available in this data set. Price is measured as the shelf price, inclusive of any temporary price discount. In-store display is measured as a scale index ranging from zero to one, which represents the intensity of display activity for a particular brand and time in the relevant store.</p><p>A unique feature of the data is that survey information pertaining to liking (i.e., how much each respondent likes each brand) and familiarity (i.e., how familiar each respondent is with each brand) is available in addition to the standard scanner panel data.</p><p>Both liking and familiarity are rated on a scale from 1 (low) to 7 (high). This stated preference information is pertinent to our identification of individual learning because it was collected from the same individuals we have scanner data on and just before the start of the observation period. It is this additional survey information that will allows us to tease out crosssectional variation and better initialize time-varying components in the learning process.</p><p>The data set comprises a random sample of 673 households dispersed across the United States. Brand choices among seven national brands in the toothpaste category-Aim, Arm &amp; Hammer, Aquafresh, Colgate, Crest, Mentadent, and Pepsodent-were tracked for one year. These seven brands totaled 86% of U.S. category sales at the time. From 673 households, we use only those who made at least four purchases over the study period. This yields a sample of 354 households, making a total of 2,501 purchases in the category.</p><p>Table <ref type="table" target="#tab_2">1</ref> presents basic descriptive statistics related to both survey and scanner data. The two large market share brands, Colgate and Crest, are not the highest-priced brands but, on average, rated high in both liking and familiarity. When compared with Colgate, Crest is priced lower, and displayed less frequently, but rated higher in both liking and familiarity. Furthermore, these two market leaders are repeatedly purchased more often than other brands except Mentadent. The two small market share brands, Aim and Pepsodent, are among the lowest-priced brands and, on average, rated low in both liking and familiarity. The medium market share brands-Aquafresh, Mentadent, and Arm &amp; Hammer-generally rank in the middle in terms of price, display, and survey ratings. There are a couple of noticeable exceptions. Arm &amp; Hammer is the least frequently displayed brand, whereas Mentadent is the highest-priced brand and among the most repeatedly purchased brands. Table <ref type="table" target="#tab_2">1</ref> also presents demographic information of the sample pertaining to family size and household income. The average family size is about three, and the average household income belongs to the bracket between $45,000 and $55,000. These numbers closely match with figures from the 2000 U.S. Census. 5</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The Information Content of Survey Data</head><p>To begin with, we seek to address the issue of whether liking and familiarity are indeed separate constructs. Figure <ref type="figure">1</ref> provides jittered scatterplots of the two constructs for each brand along with their marginal histograms. The correlation between the liking and Notes. Family size is the number of individuals in the household. Income is measured using categories (1 = less than $10K, 2 = $10-$12K, 3</p><formula xml:id="formula_12">= $12-$15K, 4 = $15-$25K, 5 = $25-$35K, 6 = $25-$35K, 7 = $35-$45K, 8 = $45-$55K, 9 = $55-$65K, 10 = $65-$75K, 11 = $75-$100K, 12 = greater than $100K).</formula><p>familiarity ratings hover around the 45%-50% range, and the proportion of consumers providing identical ratings for familiarity and liking range from 25% (Pepsodent) to 61% (Crest). The spread in the data reveals that consumers are clearly heterogeneous across the measures and also that the covariance between the two is not perfect. Finally, in the reduced-form models of brand choice we discuss next, the effects of the two constructs were separately identified and significant. These tests lead us to conclude that the two measures are indeed separate. The incorporation of survey data into the model is valuable to the extent it helps explain individual choices. We investigate this further by running a number of reduced-form models that use only the survey data to explain brand choices. <ref type="bibr">6</ref> First, we run a simple multinomial logit that seeks to model choices as a function of the survey data measures. The estimated within-sample hit rate was approximately 53.5%, suggesting that cross-sectional heterogeneity across consumers can explain a large proportion of brand choices even without the inclusion of temporal covariates or learning. This model uses both the familiarity and liking scores to predict choices. Excluding the familiarity construct lowered the hit rate to 51%, whereas excluding liking reduces the hit rate to 38%. Our informal examination of the survey data underlines its potential role in identifying key effects in choice models and, in particular, structural models incorporating state dependence and learning. In what follows we now examine patterns in the data that might (or might not) support the presence of learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Where Is the Learning? Model-Free</head><p>(Lack of) Evidence Before we embark on a fully structural approach to the problem, we undertake an extensive model-free investigation of the presence of learning in our data set. Given the availability of survey data, we should be able to discern whether consumers are learning without recourse to a full model. To do so we focus our attention on three empirical indicators of learning.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Temporal Effects of Survey Data.</head><p>Learning, on the part of the consumers, implies that preferences for the brands are temporally varying, and such variation can be tested for. In particular, if consumers are actively learning, choices documented in "early" observations should be significantly affected by liking and familiarity measures, whereas "later" observations should not. <ref type="bibr">7</ref> To investigate this we ran separate simple MNL choice models (with and without unobserved heterogeneity) based on two distinct samples created for early and late observations. To ensure robustness we defined early (and late) in various ways, including first and last observations for each household, and extended this to first and last "few" observations (two to three observations). In both cases, we found that liking and familiarity are significant predictors of choice. Furthermore, the differences in the effect of these measures were not different from zero in a statistically significant way. This leads us to conclude that preferences are stable and that aggregate patterns in the data do not support a learning hypothesis.</p><p>3.3.2. Aggregate Patterns in Market Share. Shifts in market share and changes in variability of market share are often cited as evidence of learning. We ran a number of tests to ascertain whether there were shifts in market share over the sample period conditional on the familiarity levels of the brands. In particular, we examined the movement in market share among those households that indicated low familiarity with brands. If there was indeed learning at play, we should see market shares of these brands changing over time. Although we found no evidence of shifts in market share of the major brands (Crest, Colgate, and Aquafresh), we did find some evidence that market shares were moving over the sample period for niche brands (Arm &amp; Hammer and Mentadent). We note that these shifts could also be explained by movements in prices or promotions. These alternative explanations will be examined when we implement the full model in what follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.3.">Higher-Order State Dependence.</head><p>Learning can be thought of as higher (than first)-order state dependence. Clearly, an infinite-order state dependence model cannot be empirically distinguished from learning. To test whether the data exhibit such higher-order patterns, we ran simple choice models with increasing lagged choice indicators. We found that lagged indicators up to the fourth order were significant predictors of current choice. This leads us to conclude that a model with a Bayesian learning component would obtain traction (if higher-order state dependence were ignored, as it usually is in the literature). To check whether this was indeed learning, we included our survey measures into the model with higher-order state dependence. We find that most lagged choice indicators (except of the first order) are insignificant in the presence of the survey data. This again leads us to suspect that any learning in these data may be spurious.</p><p>Overall, the results from our model-free analyses suggest that the survey data have significant relevance as a measure of cross-sectional heterogeneity, as a proxy for consumers' beliefs, and in the data's ability to disentangle learning from preferences. In the next section, we discuss our empirical implementation and provide details about how the survey data are used to calibrate the levels and uncertainty in consumers' prior beliefs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Empirical Implementation</head><p>To estimate the parameters of our model, we construct a Markov chain Monte Carlo (MCMC) scheme that provides us draws from the stationary joint posterior density of the parameters. In what follows we describe the procedure in brief and relegate details to the appendix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Basic Specification</head><p>Recall that our basic specification relies on consumers maximizing expected utility of the form</p><formula xml:id="formula_13">U E ij t = Q ij + Q ij t−1 + X ij t i + U ij t (<label>12</label></formula><formula xml:id="formula_14">)</formula><p>with the perception bias at time t being denoted by</p><formula xml:id="formula_15">Q ij t−1 = 2 Q ij 2 Q ij 0 + t−1 =1 y ij −1 2 Q ij 2 Q ij 0 Q ij 0 + t−1 =1 y ij S ij</formula><p>(13) In our specification, the vector X ij t consists of prices and display levels for each brand. Finally, as mentioned before, the U ij t are assumed to be distributed iid extreme value Type I.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Identification Using Survey Information</head><p>As we mentioned earlier, the identification of learning models is a nontrivial matter. In the traditional, homogeneous learning model, identification restrictions are imposed to achieve identification (see, e.g., <ref type="bibr" target="#b7">Erdem and Keane 1996)</ref>. More recently, <ref type="bibr" target="#b21">Narayanan and Manchanda (2009)</ref> exploit the variation in the patterns of evolution in prescriptions across multiple drugs to identify heterogeneous learning. In both cases, parametric identification assumptions are required on the agent's prior beliefs to say something about identification. In this paper, we have access to survey data that allows us to inform the model about heterogeneity in prior beliefs without resorting to a purely distributional assumption.</p><p>The survey component in our data provides additional information such as liking and familiarity for each brand. Define S ij = LIK ij FAM ij , where S ij is consumer i's survey data for brand j, LIK ij is consumer i's 1-to-7-point liking measure for brand j, and FAM ij is consumer i's 1-to-7-point familiarity measure for brand j. 8 In both constructs, 1 implies less and <ref type="bibr">8</ref> The results in the sequel are based on using the survey data as is. We also experimented with alternative standardizations of the data and found similar results. The key identification in our framework stems from the variation in the survey responses across individual households, and therefore our results are fairly robust to the way this information is used. Also note that because the impact that liking has on quality is heterogeneous, any scaling distortions will be subsumed into the relevant parameter. Again, this results in our basic findings being robust to the manner in which the survey data are coded. 7 implies more. For example, a 7 on familiarity would imply that the consumer is very familiar with that particular brand.</p><p>Because this survey information is collected prior to the choices being observed, liking and familiarity are likely to contain relevant information about the mean and variance of quality perception at the initial period. We exploit this analogy by making the consumers' prior constructs a function of the survey data as follows:</p><formula xml:id="formula_16">Q ij 0 =¯ j + i LIK ij − 1 N N i=1</formula><p>LIK ij and ( <ref type="formula">14</ref>)</p><formula xml:id="formula_17">1 2 Q ij 0 = exp ¯ + i FAM ij (<label>15</label></formula><formula xml:id="formula_18">)</formula><p>where the bar notation over the parameters indicates that they are common across consumers. The liking and familiarity measures pin down a given consumer's quality beliefs and uncertainty at the time the survey was conducted. Because our data pertain only to choices made after the survey data are collected, we are in essence "initializing" our prior constructs at this point. The variation in liking allows us to identify heterogeneity in the perception bias, whereas familiarity helps identify variation across consumers in prior uncertainty. Together, they allow us to identify a model that allows for heterogeneous priors and, consequently, heterogeneous learning. When survey information is not available (or is ignored, as in some models we estimate) we set i = 0 and i = 0. Consequently, Q ij 0 =¯ j and 1/ 2 Q ij 0 = exp ¯ . In this case, the initial perception bias is pooled across consumers, and the initial perception variance is pooled across both consumers and brands. These are standard identification restrictions that are needed in the context of Bayesian learning models applied to scanner panel data (see, e.g., <ref type="bibr" target="#b7">Erdem and</ref><ref type="bibr">Keane 1996, Mehta et al. 2003)</ref>. <ref type="bibr">9</ref> Note that, in general, homogeneity restrictions on Q ij 0 and 2 Q ij 0 do not necessarily imply homogeneous learning. As is evident from Equation (8), the mean quality perceptions are still heterogeneous on account of heterogeneous (yet time-invariant) true mean qualities and the observed sequence of individual-level brand choices. The initial market shares of the toothpaste brands help identify the initial perception bias pooled across consumers. On the other hand, the initial perception variance pooled across both consumers and brands is identified from the evolution patterns of consumer choice behavior for all brands in the market and its relationship with quality signals from consumption experience. Finally, not all brand-specific¯ j s are identified, and therefore one of them needs to be locationally fixed (say,¯ K = 0). 10 This is the last condition to render the parameters in our Bayesian learning model identified.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">MCMC Estimation Scheme</head><p>Complete details of the MCMC procedure are in the appendix. The basic algorithm is similar to those used in the literature and involves iteratively sampling parameter blocks from their conditional posterior densities. <ref type="bibr">11</ref> We ran 25,000 iterations after 25,000 burn-in iterations, and we thinned the chain by retaining every fifth draw to reduce autocorrelation, leaving us with 5,000 draws that were then used for inference. Figure <ref type="figure">2</ref> presents trace plots for the learning parameters with and without survey data. Visual inspection suggests that the above burn-in period is adequate and that the chains converge. Other parameters exhibit similar patters and are omitted for the sake of brevity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results and Empirical Findings</head><p>In this section we report our results and discuss empirical findings. These include estimates from the Bayesian learning model with and without the individual-level survey information on familiarity and preferences of the brands. We focus on four areas of interest that pertain to our earlier discussion: (i) model fit, (ii) parameter estimates, (iii) magnitude of learning, and (iv) individual-level insights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Model Fit</head><p>Table <ref type="table" target="#tab_4">2</ref> provides the fit statistics for the Bayesian learning model and other competing models. The model fit statistics presented are log-marginal likelihoods computed using the harmonic mean approach of <ref type="bibr" target="#b22">Newton and Raftery (1994)</ref>, and in all cases the significance of the fit improvement is interpreted based on the criteria proposed by <ref type="bibr" target="#b16">Kass and Raftery (1995)</ref>.</p><p>The results presented in Table <ref type="table" target="#tab_4">2</ref> show that either with or without the survey data, the Bayesian learning model provides a better fit than do any of its competing models (in which state dependence is either not allowed or specified with a different functional form). The differences between the Bayesian learning model log-marginal density and its best-fitting 10 This K need not be the same as the J that sets Q iJ = 0. Also note that in cases where households only buy a single brand in the sample, identification of learning is partially parameteric and relies on the survey data (for initial conditions) and on Bayesian shrinkage for the true mean qualities of other brands. <ref type="bibr">11</ref> We checked the performance of our estimation procedure with simulated data. The simulation results show that the proposed MCMC sampler converges after several thousand iterations and all parameter estimates recover the true values within sampling error. Full details of the simulation results are available from the authors upon request. ,000 2,000 3,000 4,000 5,000 -5.5 -5.0 -4.5 -4.0 0 1,000 2,000 3,000 4,000 5,000 -4 -3 0 1,000 2,000 3,000 4,000 5,000 0 1,000 2,000 3,000 4,000 5,000 0 1,000 2,000 3,000 4,000 5,000 0 1,000 2,000 3,000 4,000 5,000 0 1,000 2,000 3,000 4,000 5,000 0 1,000 2,000 3,000 4,000 5,000 0 1,000 2,000 3,000 4,000 5,000 0 1,000 2,000 3,000 4,000 5,000 0 1,000 2,000 3,000 4,000 5,000 0 1,000 2,000 3,000 4,000 5,000 0 1,000 2,000 3,000 4,000 5,000 0 1,000 2,000 3,000 4,000 5,000 0 1,000 2,000 3,000 4,000 5,000 0 1,000 2,000 3,000 4,000 5,000 competing model can be classified as "very strong." 12 Taken at face value, these results make a strong case for the inclusion of the Bayesian learning process in traditional brand choice models. However, we note that the better fit stems directly from the additional <ref type="bibr">12</ref>  <ref type="bibr" target="#b16">Kass and Raftery (1995)</ref> suggest that 2ln(BayesFactor) be larger than 10 for the evidence to be very strong in favor of the numerator model. The ln(BayesFactor) in the above is the difference of the logmarginal densities.</p><p>flexibility afforded by the learning framework. In particular, learning-based models permit the incorporation of higher-order feedback effects into the model that mechanically increase performance. The extent to which learning is relevant in our application will be discussed in the sections that follow.  considered. In particular, the fit of the Bayesian learning model improves from −1 983 to −1 820 when the survey information is incorporated. This fit improvement offers very strong evidence in favor of incorporating the survey data. Equally striking is the fact  that the fit of the survey augmented random coefficient logit model without state dependence (i.e., zeroorder behavior), in which the individual-level preference measures serve only to "shift" the brand-specific constants, has a better fit than does the Bayesian learning model, which allows a high-order effect of state dependence but does not include the survey information (−1 863 versus −1 983). This implies that stated preferences play a larger and more significant role in explaining choices than does the flexibility afforded by learning models. The inclusion of the stated preference information has a twofold impact on the brand-specific constants, which are interpreted as the true mean qualities in the context of the Bayesian learning model. Pairwise comparisons of these constants (in Table <ref type="table" target="#tab_6">3</ref>) reveal that both the mean values and variances are smaller when stated preferences are included. The reduction in the means and in particular in the heterogeneity of the brand-specific constants indicate that stated preferences provide valuable information on the variation in the true mean qualities. In Figure <ref type="figure">3</ref> we plot the estimated individualspecific posterior means of the quality perceptions evaluated at the initial period. This quantity reflects the beliefs of the consumers at the beginning of the sample. The estimated initial mean quality perceptions with survey information are significantly more dispersed for every brand, whereas there is no discernible systematic pattern to the differences when it comes to the location of the density. This suggests that a large proportion of the individual-level variation across consumers is not captured by the brand-specific constants without the aid of the stated preference information. In the absence of the survey information, some of that variation is carried over to other constructs in the model, such as the heterogeneity in marketing mix effects. We discuss this next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Parameter Estimates</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">Sensitivity to Marketing Mix Variables.</head><p>The mean effect and heterogeneity in the sensitivity of marketing mix variables, reported in Table <ref type="table" target="#tab_6">3</ref>, are different when the stated preference information is accounted for. Without survey information consumers are (on average) thought to be more price sensitive and more dispersed in their response to price changes than they actually are. This happens partly because the absence of preference information forces price to account for more than its true effect. It seems that when consumer preferences are "known," the substitution patterns in choices are well explained, thereby mitigating the need for brand switches to be rationalized by differences in prices. Of course, the full effect of price changes on choices (elasticity) depends not only on the price coefficients but also on the brandspecific constants and true mean qualities. Because for any brand the latter vary across the estimated models, the price elasticities will do so, too. Taken together, the increased heterogeneity in quality beliefs and price sensitivity implies that consumer responsiveness to prices is a lot more varied than traditional models would have us believe. Finally, we note that although aggregate price effects are dampened with the inclusion of stated preferences, there may be individual cases where the effects move in the opposite direction (larger effects with survey data). We will return to these issues in later sections dealing with individual-level insights. Figure <ref type="figure">4</ref> depicts the individual-specific posterior means of price and display. Display effects, on average, have a larger mean but, similar to price, exhibit somewhat lower variances when survey data are included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Magnitude of Learning</head><p>The distribution of individual-level posterior means of the initial perception biases is depicted in Figure <ref type="figure">5</ref>. Without survey information, initial perception biases for the brands are more negative and less heterogeneous, indicating a larger amount of learning. The extent of learning is determined not only by the initial perception biases but also by variances. Figure <ref type="figure">6</ref> presents initial precision, which is defined as inverse of variance of quality perception. Note that in the absence of the survey-based measures, initial perception biases are homogeneous across consumers and initial precision is homogeneous across consumers and brands. These are represented by solid vertical lines in the graphs.</p><p>Figure <ref type="figure">7</ref> depicts the joint impact of these parameters on aggregate-level learning. There are two significant differences between the two data scenarios. First, the estimated average learning during the sample period is "lower" when preference information is accounted for. Said differently, the posterior perceived quality levels are much smaller. Second, the rate of learning is also very different. The inclusion of survey information results in consumers updating beliefs at a much "slower" rate. These two effects suggest that the estimated learning patterns without preference information are exaggerated. Note that this pattern of exaggerated learning is true for all brands in the data; however, it is more pronounced for the large-share brands such as Colgate and Crest. In fact, for Colgate and Mentadent, the learning patterns with survey data are not significantly different from a flat line (no learning), whereas for Crest and Aim, the patterns are only weakly different from a no-learning pattern.</p><p>Taken together, the utility (constants/marketing mix effects) and learning parameters indicate that without the incorporation of stated preferences, the learning process is forced to proxy for differences across consumers. This reflects the classic confound between state dependence and heterogeneity. By capturing the initial beliefs of individual consumers, we are better able to frame the heterogeneity, which in turn mitigates the need for the learning component to try to rationalize the unexplained variation. This confound becomes even more stark when we examine individual cases in what follows.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Individual-Level Insights</head><p>Although the patterns discussed in Figure <ref type="figure">7</ref> suggest that there is little learning (for most brands) in the data, the aggregate nature of the plots masks the heterogeneous nature of learning. To investigate heterogeneity in learning further, we examine individual-level patterns for the extreme case of Colgate, where the aggregate pattern suggests no learning at all. Figure <ref type="figure">8</ref> depicts the learning patterns for each household in our sample for Colgate. There are three important points about this plot: First, including survey data captures heterogeneity in learning. This is depicted in the spread of the curves around the mean curve. Second, in the absence of survey data, the patterns of learning are very similar, whereas with survey data, the nature of learning is varied.</p><p>In particular, with survey data, households can lower their perceptions about Colgate's quality. Finally, even though the aggregate pattern suggests little learning for Colgate (with survey data), there are households that exhibit significant learning. These insights were echoed for the other brands in our analysis as well.</p><p>To further examine heterogeneous learning, we investigate a sample of households at a deeper level. Table <ref type="table" target="#tab_9">4</ref> depicts four households with different choice patterns facing varied marketing mix environments. For each household, the table also presents liking and preferences. Figure <ref type="figure">9</ref> presents the estimated learning patterns for them.</p><p>Household #3. This consumer makes five brand choices over the sample period. She chooses Crest four consecutive times and then switches to Colgate on her last shopping trip. The top pair of graphs in Figure <ref type="figure">9</ref> pertains to this household and suggests that she has actively engaged in learning about Crest during the sample period. Her mean quality perception has noticeably increased, and her variance of quality perception has remarkably decreased over successive Crest choices. This preference reinforcement, coupled with uncertainty reduction, indicates active learning about Crest. However, a cursory examination of her stated preferences reveals strong preferences for Crest. Incorporating these data lessens the estimated degree of learning for Crest. This is a clear case where without data, the researcher's learning about consumer preferences is misconstrued as the consumer learning about the brand. As discussed earlier, the survey data also play a role in the consumers' estimated price sensitivity. Because Colgate is also rated favorably, the switch to Colgate on the last purchase occasion does not have to be explained by price differences. Conse-quently, the estimated price coefficient is −4 13 without survey and −3 50 with survey.</p><p>Household #297. This household buys Aquafresh repeatedly and continues to do so even when the price creeps above the mean price. It is only when the price of Aquafresh is significantly above the mean level that she switches over to Arm &amp; Hammer. Her brand choices are unique in that there is no other consumer in the sample who bought Aquafresh six times out of seven. The sample market share of Aquafresh is only 15%. The large disparity between her and the "average" Aquafresh consumer's behavior leads her to be classified as an active learner. A quick examination of the survey data information on liking and familiarity tells a very different story. Aquafresh is not only her most preferred brand but also the one she is most familiar with. Given this information, it is obvious that the consumer buys Aquafresh not because of state dependence or learning but simply because she likes the brand. In other words, she is a zero-order type consumer who exhibits no learning whatsoever. Because preferences explain a large proportion of the choice patterns, they also explain why her price coefficient with the survey data is now less negative. The estimated price coefficient is −3 78 without survey and −3 51 with survey.</p><p>Households #334 and #55. In contrast to the previously discussed households, no brand switching is observed during the sample period for these two households. One only buys Colgate and the other buys Aquafresh. A quick glance at Table <ref type="table" target="#tab_9">4</ref>, however, reveals that these households differ significantly in their stated preferences and level of brand familiarity. In a model without the survey information, household #334 appears to be actively learning, but once again the survey data reveal that the Colgate choice can be explained by preferences alone. In contrast, household #55 is identified as learning about Aquafresh even after survey data are included. This happens because the survey data reveal the mean liking of Aquafresh to be 4 and familiarity with Aquafresh to be 3, which are both on the low side of the rating scale. Consequently, the purchase string suggests learning.</p><p>Our individual-level analysis uncovered many more examples that offer insights similar to those presented in these examples. For the sake of brevity, we  have limited ourselves to these cases. We would like to point out that we did attempt to explain the differences in learning across households using demographic covariates. Unfortunately, we had little success in this endeavor, suggesting that differences in learning stem from idiosyncratic differences across households.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Implications and Directions</head><p>To be clear, our results are based on a single data set and one particular model specification. Although we conjecture that our results are robust to changes in model specification, we also caution the reader that forming generalizations based on our results is not without risk. That said, our results do raise a red flag about the use of learning models in frequently purchased, mature product categories. Although there will be numerous contexts and applications where learning remains an important aspect of consumer behavior, the onus falls on the researcher to document and provide evidence in support of the phenomena.</p><p>This paper raises questions about the identification of learning models because different households may have different (and unobservable) initial conditions. Without a strategy for dealing with the heterogeneity in initial conditions, identification of learning is difficult, to say the least. In our application the availability of survey data helps address the problem; however, such data are not universally available. As such, it would seem that there is no recourse left to researchers wishing to use Bayesian learning models. We do not share this fatalistic attitude. On the contrary, we believe that our results should spur interest in merging varied data sources to learn about consumer preferences. There is already movement in this direction in the marketing and economics disciplines. For example, recent work by <ref type="bibr" target="#b4">Dubé et al. (2009)</ref> aims at using a conjoint setting to measure discount factors. This moves us away from the traditional approach to dynamic discrete choice models, which are often identified only from parametric and functional form assumptions. Like them, this paper shows that using data to construct consumer beliefs offers new and exciting avenues for research aimed at understanding consumer behavior. Our findings question the blind substitution of structure in place of data and underline the pitfalls of taking identification restrictions for granted. We hope this paper will encourage interest in constructing well-thought-out models where identification is driven more by variation in data than by assumptions.</p><p>We recognize that there will be instances where additional data will be unavailable and researchers will need to make strong assumptions to facilitate identification. In such cases, we suggest that they provide evidence as to the robustness of their estimates by perturbing these identification restrictions. In addition, picking categories where learning is easy to justify (diapers, pet food, new products), employing a rich and flexible specification of heterogeneity, and using smart prior initialization and creative identification arguments will all help in convincing the reader that the results obtained are relevant.</p><p>On the substantive front, our results highlight a number of interesting issues. We show that a misspecification of the model results in biased estimates for marketing mix effects and for the heterogeneity in them. These clearly have implications for managerial decision making. Our findings also reveal that consumers are heterogeneous not only in the way they react to marketing stimuli but also in terms of the order of their decision process. Although such "process heterogeneity" has been well documented in the literature (see, e.g., <ref type="bibr" target="#b9">Givon and Horsky 1979)</ref>, there may be reason to allow for such heterogeneity when estimating models such as learning. For example, in the absence of survey data, it might be worthwhile to allow consumers to be endogenously bucketed as "zero-order" or "Bayesian learners" as part of the estimation algorithm. We are currently working on implementing methods in this direction.</p><p>Finally, we note that the model implemented in this paper makes a number of assumptions. For example, we assume that consumers are myopic and risk averse. A natural extension would be to relax these assumptions and investigate the degree of experimentation that emerges with and without the inclusion of survey data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Summary and Conclusion</head><p>Consumers in choosing brands within a product category act intelligently. They use their existing preferences and update those based on their own consumption experiences. A key problem in the identification of learning models (or state dependence models in general) is that initial conditions are difficult to pin down. Without these initial conditions being known, a clear identification of the degree of learning is all but impossible. In this study we capture consumers' initial beliefs as a function of stated preferences and investigate the impact these data have on the scope, degree, and nature of learning in the sample. Our findings reveal that including stated preferences and familiarity information allows for a better characterization of heterogeneity and reduces the extent of learning. Our results have implications for both practitioners and scholars. For managers, the findings suggest that consumers' preferences of brands in established categories might be much stronger than extant models would have you believe. This in turn has implications for the effectiveness of pricing and promotional decisions (see, e.g., <ref type="bibr">Dubé et al. 2008, Freimer and</ref><ref type="bibr" target="#b8">Horsky 2008)</ref>. For scholars our findings reveal new insights into the way learning models are identified and offers avenues for future research in this area. The paper has also benefitted from comments by seminar participants at the University of Chicago, Stanford University, Purdue University, and the University of Rochester, as well as the Marketing Science Conference in Pittsburgh.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix. MCMC Implementation Details</head><p>A.1. Overview The full parameter set of the Bayesian learning model is defined as follows:</p><p>= ∪ i i ×¯ , where i = Q i1 Q iJ −1 i i i S ij for =1</p><p>T i −1 represents a set of the individual-level parameters, and¯ = ¯ 1 ¯ J −1 ¯ stands for a set of the aggregate-level parameters. The expected utility specification is now represented by</p><formula xml:id="formula_19">U E ij t = Q ij + exp ¯ + i FAM ij ¯ j + i LIK ij − 1 N N i=1 LIK ij + t−1 =1 y ij S ij • exp ¯ + i FAM ij + t−1 =1 y ij −1 + i X ij t + U ij t</formula><p>Given that U ij t is iid Type I extreme value distributed, the resulting likelihood function is of multinomial logit form, as given by</p><formula xml:id="formula_20">i y i X i S i i ¯ = y i X i S i i ¯ = T i t=1 J j=1 exp Ū E ij t J q=1 exp Ū E iq t y ij t</formula><p>where S i is individual i's survey information,Ū E ij t stands for the deterministic part of expected utility, and the bracket notation • • is hereafter used for a generic expression of conditional probability distributions.</p><p>To construct an MCMC sampler for the Bayesian learning model presented here, we complete our hierarchical setup by specifying prior distributions for the parameters. For notational simplicity, we further decompose i into i = Q i1 Q iJ −1 i and i = i i such that i = i ∪ i . The former ( i ) represents a set of the individual-level parameters pertaining to the standard multinomial logit model, whereas the latter ( i ) stands for a set of the individual-level parameters unique to the Bayesian learning model. The prior distributions of the model parameters are specified as follows.</p><p>1. Individual-level parameters in the standard multinomial logit model, i = Q i1 Q iJ −1 i : = 0 and 2 = 1 Hyperparameters p, P , r, R, h, H , g, G, q¯ , and Q¯ are appropriately chosen to make the corresponding prior distributions diffuse. These prior distributions, coupled with the likelihood function, specify the target posterior distribution from which we need to sample. Our sampling procedure starts with an initialization of the MCMC sampler. We draw the starting values of¯ V¯ , V¯ ,¯ , and S ij t−1 =1 from their prior distributions and those of i and i from MVN ¯ V¯ and MVN ¯ V¯ , respectively. Our sampler then cycles through the following steps, each one performed conditional on current values of all other parameters in the model.</p><p>Step 1. Update i by a Metropolis-Hastings (hereafter, M-H) sampler.</p><p>Step 2. Update¯ and V¯ by a Gibbs sampler.</p><p>Step 3. Update i by an M-H sampler.</p><p>Step 4. Update¯ and V¯ by a Gibbs sampler.</p><p>Step 5. Update¯ by an M-H sampler.</p><p>Step 6. Update S ij t−1</p><p>=1 by an M-H sampler. Sampling procedures in Steps 1 and 2 are now well established in the literature because they are the same as those for a standard random coefficient logit. The subsequent steps involve updating the parameters specific to the Bayesian learning processes. <ref type="bibr" target="#b21">Narayanan and Manchanda (2009)</ref> propose an MCMC sampling scheme for a heterogeneous version of the probit-based Bayesian learning model. We adapt their methodology to our logit-based framework by appropriate substitutions of the M-H steps where needed. A noticeable adaptation in our sampling procedure outlined above is that the series of signal noises are sampled independently and updated simultaneously in Step 6, thereby making the chain easier to construct and faster to sample. Full details on the MCMC sampling scheme are presented below. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2. Details</head><p>Given the prior specifications and the likelihood function of the Bayesian learning model, the joint posterior distribution of all the parameters conditional on the data is proportional to</p><formula xml:id="formula_21">I i=1 y i X i S i i i ¯ S ij T i −1 =1 i ¯ V¯ i ¯ V¯ • T i −1 =1 S ij 2 × ¯ p P ¯ h H ¯ q¯ Q¯</formula><p>We here illustrate the MCMC sampling procedure outlined in the estimation section. Following are the details of each of six steps employed to estimate the proposed model in this study.</p><p>Step 1. Update i = Q i1 Q iJ −1 i by an M-H sampler.</p><p>The full conditional distribution of i is</p><formula xml:id="formula_22">i rest ∝ y i X i S i i i ¯ S ij T i −1 =1 i ¯ V¯</formula><p>and we generate a vector of proposal values i using a symmetric random-walk M-H algorithm. The acceptance probability of i is min 1 i rest / i rest . This step is conducted on an individual basis.</p><p>Step 2. Update¯ and V¯ by a Gibbs sampler. Because of the conjugate prior specification for¯ and V¯ , their full conditional distributions are</p><formula xml:id="formula_23">¯ rest = MVN V −1 I i=1 i + P −1 p V −1 I + P −1</formula><p>V −1 I + P −1 −1 and V¯ rest = InvW r + I R +</p><formula xml:id="formula_24">I i=1 i −¯ i −¯ −1</formula><p>from which it is straightforward to sample.</p><p>Step 3. Update i = i i by an M-H sampler. The full conditional distribution of i is</p><formula xml:id="formula_25">i rest ∝ y i X i S i i i ¯ S ij T i −1 =1 i ¯ V¯</formula><p>and we generate a vector of proposal values i using a symmetric random-walk M-H algorithm. The acceptance probability of i is min 1 i rest / i rest . This step is conducted on an individual basis.</p><p>Step 4. Update¯ and V¯ by a Gibbs sampler. Because of the conjugate prior specification for¯ and V¯ , their full conditional distributions are</p><formula xml:id="formula_26">¯ rest = MVN V −1 I i=1 i +H −1 h V −1 I +H −1 V −1 I +H −1 −1 and V¯ rest = InvW g +I G+ I i=1 i −¯ i −¯ −1</formula><p>from which it is straightforward to sample.</p><p>Step 5. Update¯ by an M-H sampler.</p><p>The full conditional distribution of¯ is</p><formula xml:id="formula_27">¯ rest ∝ I i=1 y i X i S i i i ¯ S ij T i −1 =1</formula><p>¯ q¯ Q¯ and we generate a vector of proposal values¯ using a symmetric random-walk M-H algorithm. The acceptance probability of¯ is min 1 ¯ rest / ¯ rest . Notice that this step is conducted for the full sample.</p><p>Step 6. Update S ij T i −1 =1 by an M-H sampler. The full conditional distribution of</p><formula xml:id="formula_28">S ij T i −1 =1 is S ij T i −1 =1 rest ∝ X i S i i i ¯ S ij T i −1 =1 • T i −1 =1</formula><p>S ij 2 and we generate proposal values S ij T i −1 =1 using an independent M-H algorithm. Their prior density is used to generate independent proposal values. The acceptance probability of</p><formula xml:id="formula_29">S ij T i −1 =1 is min 1 X i S i i i ¯ S ij T i −1 =1 X i S i i i ¯ S ij T i −1 =1</formula><p>This step is conducted on an individual basis.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1Scatterplots of Liking and Familiarity with Marginal Histograms</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2 MCMC Trace Plots for Learning Parameters</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Numbers in parentheses indicate a 90% credible set. a Unobserved heterogeneity is measured by the posterior mean of the square root of the diagonal element of V¯<ref type="bibr" target="#b24">(Rossi et al. 1996</ref>). b Precision = 1/Variance of quality perception.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 3Individual-Specific Posterior Means of Initial Mean Quality Perception</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figure 4Individual-Specific Posterior Means of Marketing Mix Variables</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Figure 5 Estimated Posterior Means of Initial Perception BiasArm &amp; Hammer</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Figure 6 Estimated Posterior Means of Inital PrecisionArm &amp; Hammer</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Figure 7Estimated Aggregate-Level LearningArm &amp; Hammer</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>Figure 8Estimated Individual-Level Learning for Colgate</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Horsky: Disentangling Preferences and Learning in Brand Choice Models 116 Marketing Science 31(1), pp. 115-137, © 2012 INFORMS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Descriptive Statistics for Toothpaste Data</figDesc><table><row><cell>Brand</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Shin, Misra, and Horsky: Disentangling Preferences and Learning in Brand Choice Models    </figDesc><table><row><cell>124</cell><cell>Marketing Science 31(1), pp. 115-137, © 2012 INFORMS</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>also showcases the importance of includ-</cell></row><row><cell>ing survey data. Incorporating survey information</cell></row><row><cell>always improves fit, irrespective of the model being</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2</head><label>2</label><figDesc>Log-Marginal Densities of the Estimated Models</figDesc><table><row><cell></cell><cell>Data</cell><cell></cell></row><row><cell>Model</cell><cell>Standard scanner data</cell><cell>Survey augmented data</cell></row><row><cell>Model 1</cell><cell>−2 086</cell><cell>−1 863</cell></row><row><cell>Model 2</cell><cell>−2 066</cell><cell>−1 850</cell></row><row><cell>Model 3</cell><cell>−1 983</cell><cell>−1 820</cell></row><row><cell cols="3">Notes. Model 1: Random coefficient logit without state dependence. Model 2:</cell></row><row><cell cols="3">Random coefficient logit with a loyalty variable (last purchase dummy).</cell></row><row><cell cols="3">Model 3: Random coefficient logit with the Bayesian learning process.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3</head><label>3</label><figDesc>Parameter Estimates of the Bayesian Learning Model</figDesc><table><row><cell></cell><cell cols="2">Standard scanner data</cell><cell cols="2">Survey augmented data</cell></row><row><cell></cell><cell cols="2">(Choice + Marketing mix)</cell><cell cols="2">(Choice + Marketing mix + Survey)</cell></row><row><cell>Parameter</cell><cell>Posterior mean</cell><cell>Heterogeneity a</cell><cell>Posterior mean</cell><cell>Heterogeneity a</cell></row><row><cell>True mean quality</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Arm &amp; Hammer</cell><cell>10.0911</cell><cell>0.4879</cell><cell>7.8784</cell><cell>0.3618</cell></row><row><cell></cell><cell>9 9696 10 2133</cell><cell>0 3685 0 6254</cell><cell>7 6361 8 1190</cell><cell>0 2671 0 4423</cell></row><row><cell>Aim</cell><cell>2.7086</cell><cell>0.6405</cell><cell>1.5366</cell><cell>0.4610</cell></row><row><cell></cell><cell>2 5554 2 8663</cell><cell>0 4786 0 7661</cell><cell>1 4073 1 6578</cell><cell>0 2722 0 6266</cell></row><row><cell>Aquafresh</cell><cell>7.8559</cell><cell>0.7972</cell><cell>7.2396</cell><cell>0.5932</cell></row><row><cell></cell><cell>7 6133 8 1253</cell><cell>0 5203 0 9752</cell><cell>7 0269 7 4144</cell><cell>0 3634 0 8072</cell></row><row><cell>Colgate</cell><cell>9.3644</cell><cell>0.6492</cell><cell>8.2139</cell><cell>0.4282</cell></row><row><cell></cell><cell>9 2256 9 5545</cell><cell>0 3789 0 9261</cell><cell>7 9863 8 3593</cell><cell>0 2560 0 6234</cell></row><row><cell>Crest</cell><cell>8.8023</cell><cell>0.7165</cell><cell>8.3815</cell><cell>0.6038</cell></row><row><cell></cell><cell>8 6587 8 9273</cell><cell>0 5484 1 0392</cell><cell>8 1817 8 6328</cell><cell>0 3794 0 8074</cell></row><row><cell>Mentadent</cell><cell>11.9406</cell><cell>0.7473</cell><cell>10.8523</cell><cell>0.5628</cell></row><row><cell></cell><cell>11 6708 12</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 3</head><label>3</label><figDesc>Disentangling Preferences and Learning in Brand Choice Models</figDesc><table><row><cell>provides the parameter estimates of the</cell></row><row><cell>Bayesian learning model (with and without sur-</cell></row><row><cell>vey data).</cell></row></table><note>Shin, Misra, and Horsky:  </note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Shin, Misra, and Horsky: Disentangling Preferences and Learning in Brand Choice Models    </figDesc><table><row><cell>132</cell><cell>Marketing Science 31(1), pp. 115-137, © 2012 INFORMS</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4</head><label>4</label><figDesc>Examples of Individual-Level Scanner and Survey Data</figDesc><table><row><cell>Purchase</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Price</cell><cell></cell><cell></cell><cell></cell></row><row><cell>occasion</cell><cell>Choice</cell><cell>AH</cell><cell>AM</cell><cell>AF</cell><cell>CG</cell><cell>CR</cell><cell>MT</cell><cell>PS</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Household #3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>CR</cell><cell>2 202</cell><cell>1 242</cell><cell>2 631</cell><cell>2 663</cell><cell>0 790</cell><cell>3 023</cell><cell>332</cell></row><row><cell>2</cell><cell>CR</cell><cell>3 239</cell><cell>1 380</cell><cell>2 466</cell><cell>2 588</cell><cell>1 500</cell><cell>4 480</cell><cell>033</cell></row><row><cell>3</cell><cell>CR</cell><cell>3 174</cell><cell>1 776</cell><cell>2 229</cell><cell>2 560</cell><cell>1 440</cell><cell>3 503</cell><cell>874</cell></row><row><cell>4</cell><cell>CR</cell><cell>3 410</cell><cell>1 114</cell><cell>2 629</cell><cell>2 863</cell><cell>1 800</cell><cell>4 064</cell><cell>116</cell></row><row><cell>5</cell><cell>CG</cell><cell>2 837</cell><cell>1 756</cell><cell>2 033</cell><cell>0 860</cell><cell>2 877</cell><cell>3 449</cell><cell>190</cell></row><row><cell>Liking</cell><cell></cell><cell>2</cell><cell>4</cell><cell>4</cell><cell>7</cell><cell>7</cell><cell>4</cell><cell></cell></row><row><cell>Familiarity</cell><cell></cell><cell>4</cell><cell>4</cell><cell>5</cell><cell>7</cell><cell>7</cell><cell>3</cell><cell></cell></row><row><cell>Mean price</cell><cell></cell><cell>2 765</cell><cell>1 425</cell><cell>2 368</cell><cell>2 534</cell><cell>2 438</cell><cell>3 552</cell><cell>327</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Household #297</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>AF</cell><cell>2 478</cell><cell>1 210</cell><cell>1 680</cell><cell>2 542</cell><cell>2 741</cell><cell>3 230</cell><cell>443</cell></row><row><cell>2</cell><cell>AF</cell><cell>2 737</cell><cell>1 419</cell><cell>1 680</cell><cell>2 616</cell><cell>2 535</cell><cell>4 074</cell><cell>097</cell></row><row><cell>3</cell><cell>AF</cell><cell>2 833</cell><cell>1 237</cell><cell>2 434</cell><cell>2 696</cell><cell>2 476</cell><cell>4 263</cell><cell>108</cell></row><row><cell>4</cell><cell>AF</cell><cell>3 239</cell><cell>1 380</cell><cell>2 466</cell><cell>2 588</cell><cell>2 558</cell><cell>4 480</cell><cell>033</cell></row><row><cell>5</cell><cell>AF</cell><cell>2 905</cell><cell>1 452</cell><cell>2 060</cell><cell>2 596</cell><cell>2 488</cell><cell>3 679</cell><cell>546</cell></row><row><cell>6</cell><cell>AF</cell><cell>4 120</cell><cell>1 035</cell><cell>1 680</cell><cell>2 457</cell><cell>2 624</cell><cell>3 284</cell><cell>032</cell></row><row><cell>7</cell><cell>AH</cell><cell>2 490</cell><cell>1 715</cell><cell>2 737</cell><cell>2 584</cell><cell>2 507</cell><cell>3 341</cell><cell>748</cell></row><row><cell>Liking</cell><cell></cell><cell>4</cell><cell>4</cell><cell>7</cell><cell>4</cell><cell>4</cell><cell>1</cell><cell></cell></row><row><cell>Familiarity</cell><cell></cell><cell>4</cell><cell>4</cell><cell>7</cell><cell>5</cell><cell>5</cell><cell>2</cell><cell></cell></row><row><cell>Mean price</cell><cell></cell><cell>2 765</cell><cell>1 425</cell><cell>2 368</cell><cell>2 534</cell><cell>2 438</cell><cell>3 552</cell><cell>327</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Household #334</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>CG</cell><cell>2 478</cell><cell>1 210</cell><cell>2 422</cell><cell>2 542</cell><cell>2 741</cell><cell>3 230</cell><cell>442</cell></row><row><cell>2</cell><cell>CG</cell><cell>2 478</cell><cell>1 210</cell><cell>2 422</cell><cell>2 320</cell><cell>2 741</cell><cell>3 320</cell><cell>442</cell></row><row><cell>3</cell><cell>CG</cell><cell>2 231</cell><cell>1 355</cell><cell>3 404</cell><cell>2 512</cell><cell>2 707</cell><cell>3 225</cell><cell>190</cell></row><row><cell>4</cell><cell>CG</cell><cell>3 957</cell><cell>1 474</cell><cell>3 072</cell><cell>1 720</cell><cell>2 577</cell><cell>3 797</cell><cell>095</cell></row><row><cell>5</cell><cell>CG</cell><cell>2 860</cell><cell>1 442</cell><cell>2 434</cell><cell>2 240</cell><cell>2 549</cell><cell>3 844</cell><cell>485</cell></row><row><cell>6</cell><cell>CG</cell><cell>2 444</cell><cell>0 853</cell><cell>2 434</cell><cell>2 673</cell><cell>2 463</cell><cell>3 546</cell><cell>180</cell></row><row><cell>7</cell><cell>CG</cell><cell>2 614</cell><cell>1 755</cell><cell>2 166</cell><cell>2 731</cell><cell>2 490</cell><cell>3 465</cell><cell>260</cell></row><row><cell>8</cell><cell>CG</cell><cell>2 230</cell><cell>2 030</cell><cell>2 275</cell><cell>2 050</cell><cell>2 610</cell><cell>3 823</cell><cell>045</cell></row><row><cell>9</cell><cell>CG</cell><cell>3 319</cell><cell>1 270</cell><cell>2 325</cell><cell>2 020</cell><cell>2 917</cell><cell>3 563</cell><cell>352</cell></row><row><cell>10</cell><cell>CG</cell><cell>2 897</cell><cell>1 425</cell><cell>2 533</cell><cell>2 489</cell><cell>2 812</cell><cell>3 988</cell><cell>213</cell></row><row><cell>Liking</cell><cell></cell><cell>1</cell><cell>3</cell><cell>3</cell><cell>7</cell><cell>5</cell><cell>6</cell><cell></cell></row><row><cell>Familiarity</cell><cell></cell><cell>4</cell><cell>5</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell>7</cell><cell></cell></row><row><cell>Mean price</cell><cell></cell><cell>2 765</cell><cell>1 425</cell><cell>2 368</cell><cell>2 534</cell><cell>2 438</cell><cell>3 552</cell><cell>327</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>Household #55</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1</cell><cell>AF</cell><cell>2 582</cell><cell>1 275</cell><cell>2 060</cell><cell>3 156</cell><cell>2 890</cell><cell>3 501</cell><cell>290</cell></row><row><cell>2</cell><cell>AF</cell><cell>2 231</cell><cell>1 355</cell><cell>1 860</cell><cell>2 512</cell><cell>2 707</cell><cell>3 225</cell><cell>190</cell></row><row><cell>3</cell><cell>AF</cell><cell>2 475</cell><cell>1 007</cell><cell>2 070</cell><cell>2 371</cell><cell>2 319</cell><cell>3 668</cell><cell>375</cell></row><row><cell>4</cell><cell>AF</cell><cell>2 857</cell><cell>1 044</cell><cell>1 720</cell><cell>2 763</cell><cell>2 486</cell><cell>3 215</cell><cell>243</cell></row><row><cell>Liking</cell><cell></cell><cell>2</cell><cell>1</cell><cell>4</cell><cell>2</cell><cell>5</cell><cell>6</cell><cell></cell></row><row><cell>Familiarity</cell><cell></cell><cell>3</cell><cell>1</cell><cell>3</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell></cell></row><row><cell>Mean price</cell><cell></cell><cell>2 765</cell><cell>1 425</cell><cell>2 368</cell><cell>2 534</cell><cell>2 438</cell><cell>3 552</cell><cell>327</cell></row><row><cell cols="8">Note. AH, Arm &amp; Hammer; AM, Aim; AF, Aquafresh; CG, Colgate; CR, Crest; MT, Mentadent; PS, Pepsodent.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head></head><label></label><figDesc>Shin, Misra, and Horsky: Disentangling Preferences and Learning in Brand Choice Models    </figDesc><table><row><cell cols="7">Marketing Science 31(1), pp. 115-137, © 2012 INFORMS</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Marketing Science 31(1), pp. 115-137, © 2012 INFORMS 135</cell></row><row><cell>Figure 9</cell><cell cols="5">Examples of Individual-Level Learning</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Household #3</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>9.00</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.00</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Mean quality perception (Crest)</cell><cell>8.00 8.25 8.50 8.75 7.25 7.50 7.75</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Variance of quality perception</cell><cell>(Crest)</cell><cell>0.50 0.75 0.25</cell><cell></cell><cell></cell><cell></cell><cell>Without survey With survey</cell></row><row><cell></cell><cell></cell><cell>7.00</cell><cell>1</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>40</cell><cell>50</cell><cell></cell><cell></cell><cell>0</cell><cell>1</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>40</cell><cell>50</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Week</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Week</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Household #297</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Mean quality perception (Aquafresh)</cell><cell>7.0 7.5 8.0 8.5 5.5 6.0 6.5</cell><cell>1</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>40</cell><cell>50</cell><cell>Variance of quality perception</cell><cell>(Aquafresh)</cell><cell>0.50 0.75 1.00 0 0.25</cell><cell>1</cell><cell>10</cell><cell>20</cell><cell>Without survey With survey 30 40 50</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Week</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Week</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Household #334</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Meean quality perception (Colgate)</cell><cell>8.5 9.0 9.5 7.0 7.5 8.0</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Variance of quality perception</cell><cell>(Colgate)</cell><cell>0.50 0.75 1.00 0 0.25</cell><cell></cell><cell></cell><cell></cell><cell>Without survey With survey</cell></row><row><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell></cell><cell>50</cell><cell></cell><cell></cell><cell></cell><cell>1</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>40</cell><cell>50</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Week</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Week</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Household #55</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Mean quality perception (Aquafresh)</cell><cell>7.0 7.5 8.0 8.5 5.5 6.0 6.5</cell><cell>1</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell>40</cell><cell>50</cell><cell>Variance of quality perception</cell><cell>(Aquafresh)</cell><cell>0.60 0.85 1.00 0.10 0.35</cell><cell>1</cell><cell>10</cell><cell>20</cell><cell>Without survey With survey 30 40 50</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Week</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Week</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head></head><label></label><figDesc>V¯ = MVN ¯ V¯ ¯ p P = MVN p P and V¯ r R = InvW r R2. Individual-level learning parameters, i = i i :</figDesc><table><row><cell cols="3">¯ h H = MVN h H</cell><cell>and V¯ g G = InvW g G</cell></row><row><cell cols="3">3. Aggregate-level</cell><cell>learning</cell><cell>parameters,¯ =</cell></row><row><cell>¯ 1</cell><cell>¯ J −1 ¯ :</cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">¯ q¯ Q¯ = MVN q¯ Q¯</cell></row><row><cell cols="4">4. Signal noises S ij ing model are by design drawn from a standard normal for =1 T i −1 in the Bayesian learn-</cell></row><row><cell cols="3">distribution. That is,</cell></row><row><cell>S ij</cell><cell>2</cell><cell>= N</cell></row></table><note>i ¯ i ¯ V¯ = MVN ¯ V¯ 2 where</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head></head><label></label><figDesc>Shin, Misra, and Horsky: Disentangling Preferences and Learning in Brand Choice Models 136 Marketing Science 31(1), pp. 115-137, © 2012 INFORMS</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Earlier work in this vein includes<ref type="bibr" target="#b23">Roberts and Urban (1988)</ref>,<ref type="bibr" target="#b6">Eckstein et al. (1988)</ref>, and<ref type="bibr" target="#b14">Horsky and Raban (1988)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We are assuming that non-purchases are uninformative from a quality learning point of view. An alternative specification could include a reinforcement learning component wherein non-purchases also have a role to play, in the spirit of<ref type="bibr" target="#b2">Camerer et al. (2002)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">This problem is mitigated by relying on specific product categories, such as diapers, food, cat or dog food, where new customers exhibit learning or by choosing product categories with new brand introductions.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Marketing Science 31(1), pp.115-137, © 2012 INFORMS   </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">According to the 2000 U.S. Census, the average family size is 3.14, and the average household income is $51,855.Shin, Misra, and Horsky: Disentangling Preferences and Learning in Brand Choice Models Marketing Science 31(1), pp. 115-137, © 2012 INFORMS</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">For brevity we have not included the actual results from all reduced-form models we ran but are providing a short qualitative description of the results obtained. Detailed results are available from the authors upon request.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">We thank an anonymous reviewer for suggesting this test and other model-free tests.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9"><ref type="bibr" target="#b19">Mehta et al. (2003)</ref> use an initialization sample to minimize the negative impact of these homogeneity assumptions.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank the editor, associate editor, and two anonymous reviewers for their comments and suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Advertising, learning, and consumer choice in experienced goods markets: An empirical examination. Internat</title>
		<author>
			<persName><forename type="first">D</forename><surname>Ackerberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econom. Rev</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="1007" to="1040" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Estimation of switching models from revealed preferences and stated intentions</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ben-Akiva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Morikawa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Res. Part A</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="485" to="495" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Sophisticated EWA learning and strategic teaching in repeated games</title>
		<author>
			<persName><forename type="first">C</forename><surname>Camerer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econom. Theory</title>
		<imprint>
			<biblScope unit="volume">104</biblScope>
			<biblScope unit="page" from="137" to="188" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Uncertainty and learning in pharmaceutical demand</title>
		<author>
			<persName><forename type="first">G</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="page" from="1137" to="1174" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Estimating durable goods adoption decisions from stated preference data. Working paper</title>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Dubé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Jindal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<pubPlace>Chicago</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Chicago</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Category pricing with state-dependent utility</title>
		<author>
			<persName><forename type="first">J.-P</forename><surname>Dubé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Hitsch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Vittorino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="417" to="429" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">An empirical dynamic model of optimal brand choice. Working paper</title>
		<author>
			<persName><forename type="first">Z</forename><surname>Eckstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Horsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Raban</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<pubPlace>Tel Aviv, Israel</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Tel Aviv University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Decision-making under uncertainty: Capturing dynamic brand choice processes in turbulent consumer goods markets</title>
		<author>
			<persName><forename type="first">T</forename><surname>Erdem</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Try it, you will like it-Does consumer learning lead to competitive price promotions? Marketing Sci</title>
		<author>
			<persName><forename type="first">M</forename><surname>Freimer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Horsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="796" to="810" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Application of a composite stochastic model of brand choice</title>
		<author>
			<persName><forename type="first">M</forename><surname>Givon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Horsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="258" to="267" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A model of health plan choice: Inferring preferences and perceptions from a combination of revealed preference and attitudinal data</title>
		<author>
			<persName><forename type="first">K</forename><surname>Harris</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Keane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="page" from="131" to="157" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Identifying the hand of the past: Distinguishing state dependence from heterogeneity</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Heckman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. Econom. Rev</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="75" to="79" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Using stated response choice data to enrich revealed preference discrete choice models. Marketing Lett</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hensher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bradley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="139" to="151" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">New brand positioning and pricing in an oligopolistic market</title>
		<author>
			<persName><forename type="first">D</forename><surname>Horsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="133" to="153" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A Bayesian updating model of dynamic brand choice behavior. Working paper</title>
		<author>
			<persName><forename type="first">D</forename><surname>Horsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Raban</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<pubPlace>Rochester, NY</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Rochester</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Observed and unobserved heterogeneity in brand-choice models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Horsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="322" to="335" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Bayes factors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kass</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="773" to="795" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Measuring expectations</title>
		<author>
			<persName><forename type="first">C</forename><surname>Manski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="1329" to="1376" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Disentangling Preferences and Learning in Brand</title>
		<author>
			<persName><forename type="first">Misra</forename><surname>Shin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Horsky</forename></persName>
		</author>
		<idno>© 2012 INFORMS 137</idno>
	</analytic>
	<monogr>
		<title level="j">Choice Models Marketing Science</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="115" to="137" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Price uncertainty and consumer search: A structural model of consideration set formation</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajiv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="58" to="84" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Role of forgetting in memory-based choice decisions: A structural model</title>
		<author>
			<persName><forename type="first">N</forename><surname>Mehta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Rajiv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quant. Marketing Econom</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="107" to="140" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Heterogeneous learning and the targeting of marketing communications for new products</title>
		<author>
			<persName><forename type="first">S</forename><surname>Narayanan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Manchanda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="424" to="441" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Approximate Bayesian inference with the weighted likelihood bootstrap</title>
		<author>
			<persName><forename type="first">M</forename><surname>Newton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Statist. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="3" to="48" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Modeling multiattribute utility, risk, and belief dynamics for new consumer durable brand choice</title>
		<author>
			<persName><forename type="first">J</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="167" to="185" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The value of purchase history data in target marketing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Mcculloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="321" to="340" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
