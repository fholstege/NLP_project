<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Research Note-Competitive Brand Salience</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005-09-13">September 13, 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Ralf</forename><surname>Van Der Lans</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Rik</forename><surname>Pieters</surname></persName>
							<email>pieters@uvt.nl</email>
						</author>
						<author>
							<persName><forename type="first">Michel</forename><surname>Wedel</surname></persName>
							<email>mwedel@rhsmith.umd.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Rotterdam School of Management</orgName>
								<orgName type="institution">Erasmus University</orgName>
								<address>
									<settlement>Rotterdam</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Tilburg University</orgName>
								<address>
									<settlement>Tilburg</settlement>
									<country key="NL">The Netherlands</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Robert H. Smith School of Business</orgName>
								<orgName type="institution">University of Maryland</orgName>
								<address>
									<postCode>20742</postCode>
									<settlement>College Park, Maryland</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Research Note-Competitive Brand Salience</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 e 1526-548X 08 2705 0922</idno>
						<imprint>
							<date type="published" when="2005-09-13">September 13, 2005</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.1070.0327</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:25+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>search goals</term>
					<term>eye movements</term>
					<term>Hidden Markov</term>
					<term>brand salience</term>
					<term>visual attention</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please scroll down for article-it is on subsequent pages</head><p>With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning opportunities for individual professionals, and organizations of all types and sizes, to better understand and use O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Competitive clutter at the point of purchase is intense, due to stock-keeping unit (SKU) proliferation, brand extensions, me-too products, private labels, and copycats. As a consequence, searching brands on supermarket shelves is a daily challenge for consumers. Clutter causes consumers to accidentally pick up the wrong brands or not find their favorite brand at all. Therefore, manufacturers and retailers try to make the SKUs of their brands visually salient among competitors through improved package design and advertising. They seek an optimal level of differentiation of their brands and SKUs by balancing the visual salience of each SKU relative to competitors with a unique identity of the entire line of SKUs. At the same time, they need to obey established codes about the visual appearance of the category. To support this management task, the visual salience of SKUs and brands needs to be assessed, but how to accomplish this is far from obvious: there is no academic literature addressing this problem, but related literatures exist on variety perceptions of assortments <ref type="bibr" target="#b1">(Broniarczyk et al. 1998</ref><ref type="bibr" target="#b9">, Herpen and Pieters 2002</ref><ref type="bibr" target="#b10">, Hoch et al. 1999</ref> and on the overlap within product portfolios <ref type="bibr">(Aribarg and Arora 2007)</ref>.</p><p>We intend to fill this gap and afford a detailed analysis of visual competition between brands based on the few seconds that consumers search for them on the shelf. Using eye-movement data collected in a brand search experiment, we develop a model of brand search and, based on this, a methodology to assess the competitive salience of brands, establish its effects on search performance, and show how to improve it through marketing. We begin with a description of the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Brand Search Experiment</head><p>During a computer-mediated brand search task for laundry detergents, eye movements were collected for a random sample of 109 regular consumers in the Netherlands (47 males and 62 females, between 16 and 55 years of age). Participants were individually seated behind 21-inch LCD computer screens (1 024 × 1 280) on which a shelf with six brands of laundry detergent was shown-four brands with three SKUs each and two brands with two SKUs each (16 SKUs in total). Multiple replications (facings) of SKUs were van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience Marketing Science 27(5), pp. <ref type="bibr">922-931, © 2008 INFORMS 923</ref> present to mimic regular shelves at the point of purchase. Participants were randomly assigned to one of five conditions of a one-factorial between-subjects design in which they searched for one out of five different brands, respectively, Witte Reus Tablets, Omo Tablets, Persil Tablets, Sunil Tablets, and Dixan Tablets. In all cases, the search goal was directed at a specific SKU of a brand (the tablet SKU). The sixth brand, Ariel, is the market leader and serves as a baseline. Placement of the brands in the display was rotated across conditions and consumers to eliminate possible location effects, with the same number of facings in all conditions. Participants had a maximum of 10 seconds to find the target brand, and indicated having found the target brand by touching it on the touch-sensitive LCD screen, after which the brand search task ended. Eye movements, and latency and accuracy of search were recorded. For the details about eye tracking, we refer to <ref type="bibr" target="#b28">Wedel and Pieters (2000)</ref>. Figure <ref type="figure">A1</ref> in the appendix provides an example of a scan-path across the shelf for one participant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Brand Search: Theory and Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Brand Search Theory</head><p>In brand search, consumers try to find a target brand among distracters in a visual display, which is guided by eye movements. During eye fixations, information is extracted from small regions in the display, and during eye saccades attention is redirected rapidly to other potentially informative regions <ref type="bibr" target="#b7">(Findlay 2005)</ref>. Bottom-up effects-visual characteristics of the shelf-and top-down effects-the consumers' search goals-influence brand search. Basic perceptual features affect search bottom-up: color, luminance, and edges <ref type="bibr" target="#b29">(Wolfe and Horowitz 2004)</ref>. Brand search is easy when the target brand is dissimilar from all distracters on a single feature and when all distracters are similar on that feature <ref type="bibr" target="#b6">(Duncan and Humphreys 1992)</ref>. In that case, the target brand pops out and is found almost instantly, as when searching for the Heinz green ketchup among its uniformly red competitors. Brand search on retail shelves is difficult when targets share features with distracters and the distracters are heterogeneous among themselves, which is common. This creates spatial uncertainty: i.e., where in the display candidates are located, and identity uncertainty, i.e., what the identity of a located candidate is: target brand or distracter. During search, the visual brain likely alternates between a fast but less accurate "where" (localization) state to reduce spatial uncertainty and a slower but more accurate what (identification) state to reduce identity uncertainty <ref type="bibr" target="#b20">(Niebur and Koch 1998)</ref>.</p><p>A salience map guides eye movements during the where state. It is a topographic map, represented physically in the visual brain, that captures the visual importance (salience) of all locations in the display <ref type="bibr" target="#b20">(Niebur and</ref><ref type="bibr">Koch 1998, Thompson 2005)</ref>. A location that contrasts with its surroundings on a perceptual feature is visually salient. The salience map is thought to be a weighted combination of the perceptual features at each location in the display. It enables individuals to search efficiently by shifting their focus of attention successively to display locations of decreasing salience, until the candidate is found.</p><p>The salience map is also influenced top down by the search goal. This occurs because the search goal selectively enhances presumably diagnostic and suppresses presumably nondiagnostic features of the target brand <ref type="bibr" target="#b15">(Lee and Mumford 2003)</ref>. For example, in a search for ketchup, the color red will be enhanced and candidate brands with this color will become more salient. Such enhancement and suppression due to search goals is effortful and may be limited to one or two features only, mostly colors <ref type="bibr">Horowitz 2004, Wolfe et al. 1990</ref>). The total salience that guides eye movements during search is the sum of bottomup salience due to the brand's perceptual features, and top-down salience due to the goal-based selective enhancement and suppression of these features <ref type="bibr" target="#b31">(Yantis and Egeth 1999)</ref>. Because bottom-up salience is determined by perceptual features of the visual display, it is independent of the search goal. A brand with large bottom-up salience, such as the Heinz green ketchup, will attract attention no matter what an individual's search goal is.</p><p>Eye movements in the where state are also guided by systematic search strategies <ref type="bibr" target="#b18">(Monk 1984</ref><ref type="bibr" target="#b23">, Ponsoda et al. 1995</ref>. These strategies are based on the layout of the display, in particular the horizontal organization of product shelves in supermarkets. Horizontal eyemovement patterns (left-right and right-left) appear to prevail in target search <ref type="bibr" target="#b8">(Gilchrist and Harvey 2006)</ref>. Whereas eye movements guided by the salience map are mostly disorderly when salient display regions are nonadjacent, eye movements guided by systematic search strategies are orderly. The where state is characterized by longer saccades between brands.</p><p>Once a candidate brand is fixated, the brain switches to the what state to reduce uncertainty about the candidate's identity. This typically requires repeated fixations on the candidate, with small saccades between consecutive fixations. Search terminates when the consumer has sufficient evidence that the candidate is the target brand.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Operationalization of Variables</head><p>We define the independent variables used in the model indexed by k = 1 K, for consumers c = 1 C, and eye fixations i = 1 I c for each consumer c. These variables are derived from the image of the display and defined for each pixel u v <ref type="bibr">van</ref>  in it, where u = 1 1 024 and v = 1 1 280. These variables correspond to the basic features processed by the visual brain.</p><p>The first set of independent variables s cik u v indexed by k ∈ K M covers the constant and the perceptual features, i.e., colors, luminance, and edges, contributing to the salience map. Colors were derived from the RGB values of each pixel (the values range from 0 to 255), using standard imaging software, with luminance derived as S luminance = 0 299R + 0 587G + 0 114B <ref type="bibr" target="#b25">(Shapiro and Stockman 2001)</ref>. Because colors are collinear with luminance, we coded red, green, and blue as dummy values (0/1) for each pixel. Edges are extracted from the image using standard imaging procedures that compute edges as the gradients of luminance <ref type="bibr" target="#b17">(Marr 1982)</ref>. Whereas edges at various levels of detail are available, we retained the edges that determine for each pixel to which brand (multiple SKUs) and to which SKU it belonged. We define a dummy variable (0/1) for each pixel u v indicating whether it belongs to a specific brand, and a dummy variable indicating whether the pixel belongs to a specific SKU. The region from which the eye extracts information is larger than the exact pixel on which it fixates and can be approximated by a bivariate normal distribution <ref type="bibr" target="#b19">(Motter and</ref><ref type="bibr">Holsapple 2001, Pomplun et al. 2000)</ref>. We therefore spatially smooth the image data for each of the perceptual features by a two-dimensional Normal kernel, using a bandwidth of 2 degrees, which is the visual angle covered by the fovea <ref type="bibr" target="#b7">(Findlay 2005)</ref>. We use the smoothed values of these dummy variables at each pixel location u v .</p><p>The second set of independent variables s cik i−1 u v , indexed by k ∈ K S , contains two dummy variables reflecting left-right and right-left zigzag systematic search strategies, respectively. For example, the left-right strategy is specified through dummy s cik i−1 u * v * = 1 for all new locations u * v * to the right of the previous fixation point i − 1 u v and 0 for all others.</p><p>The third set of independent variables s cik i−1 u v , indexed by k ∈ K T , contains two dummies reflecting refixation strategies on the same, SKU and SKUs of the same brand, respectively, which variables characterize the identification state. For example, a refixation on the same SKU is specified through a dummy variable s cik i−1 u * v * = 1 for all locations u * v * that pertain to the same SKU as the SKU in location u v on fixation i − 1.</p><p>Thus, the data that are used as input for the model consist of C c=1 I c rows, where each row i c specifies the location of fixation i for consumer c, along with the values of the K = 9 independent variables for all 1,310,720 (1 024 × 1 280) pixels of the display. The first set of independent variables that defines the constant term, colors, luminance, and edges is constant across fixa-tions of a consumer, but differs between consumers because of the randomization of the shelf positions. The variables in the second and third sets, defining the systematic and refixation strategies, vary between consumers and fixations. Next to the fixation locations, for each consumer search accuracy (0/1) and latency (seconds) are used as dependent variables.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">The Brand Search Model</head><p>We develop a brand search model that extends the Hidden Markov Models (HMM) by <ref type="bibr" target="#b16">Liechty et al. (2003)</ref> and <ref type="bibr">van der Lans et al. (2007)</ref>. <ref type="bibr" target="#b16">Liechty et al. (2003)</ref> used an HMM to describe eye movements during free viewing of print ads. The present model goes beyond that study by including (a) the effects of image features, (b) systematic search strategies on eye movements, and (c) the use of the exact fixation locations on pixels rather than on a coarse spatial grid. We extend van der Lans et al. ( <ref type="formula">2007</ref>) by (a) separating topdown from bottom-up salience, which is enabled by our combination of experimental design with a hierarchical Bayes formulation, and (b) integrating search accuracy and latency in the HMM model. Together, this makes it possible to comprehensively assess competitive brand salience and its effects on search performance, for which neither of these two previous approaches allows. In the appendix the scan path of one participant is used to illustrate how the model explains eye movements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.1.">Eye Movements. The model describes, for consumer c = 1</head><p>C, the location of a fixation as a choice among all pixels D 1 × D 2 = 1 024 × 1 280 of the display. Thus, the location of every fixation i is a choice of one out of all pixels. Each fixation is either generated in the localization state (j = 1) or in the identification state (j = 2). Switching between these two attention states is represented by an HMM, with probabilities j j <ref type="bibr" target="#b16">(Liechty et al. 2003)</ref>. We let j u v • be the probability that the next fixation is in location u v ∈ D 1 D 2 , given that this fixation is generated in attention state j. In the localization state (j = 1), j=1 u v • is based on the salience map and systematic search strategies. In the identification state (j = 2), j=2 u v • represents the probability of refixating on the previously fixated SKU or brand. We thus have S = 2 systematic strategies (left-right and right-left zigzag) and T = 2 (SKU surface and brand surface) refixation strategies. The dimensions of the s cik = s cik u v and</p><formula xml:id="formula_0">s cik i−1 = s cik i−1 u v are D 1 × D 2 .</formula><p>The fixation probabilities j u v jc s ci are a function of these variables with consumer and statespecific weights, ci , with s ci = s cik K k=1 a collection of K D 1 × D 2 matrices. These weights are assumed to have a normal distribution to account for heterogeneity, jc ∼ N j j , with a diagonal covariance van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience Marketing Science 27(5), pp. 922-931, © 2008 INFORMS 925 matrix j . A square-root link function is used for j • . This ensures that j • ≥ 0, which is appealing because it describes probabilities on a two-dimensional surface, and makes the computation of fixation probabilities feasible <ref type="bibr">(van der Lans et al. 2007</ref>):</p><formula xml:id="formula_1">u v jc s ci =                                  Salience map k∈K M s cik u v jck + Systematic strategy k∈K S s cik i−1 u v jck 2 R jci j = 1 k∈K T s cik i−1 u v jck Repeated fixation 2 R jci j= 2 (1)</formula><p>where</p><formula xml:id="formula_2">R j=1 c i = u∈D 1 v∈D 2 k∈K M ∪K S s cik i−1 u v jck 2 , and R j=2 c i = u∈D 1 v∈D 2 k∈K T s cik i−1 u v jck 2 .</formula><p>To ensure that the expression in ( <ref type="formula">1</ref>) is a probability across all pixels, we normalize by R jci for all states j, consumers c, and fixations i. Because of this, one parameter in each attention state is not identified and we restrict the constant in the localization state, and the SKU refixation strategy in the identification state to be equal to 1. <ref type="bibr">1</ref> The probability of a sequence of fixations of a consumer c, y</p><formula xml:id="formula_3">eye c = y eye ci</formula><p>, with y ci the location of the ith fixation in pixel coordinates, is written as an HMM:</p><formula xml:id="formula_4">P y eye c c s c = 2 j 2 =1 • • • 2 j n c =1 n c i=2 j i−1 j i j i y eye ci j i c s ci u v (2)</formula><p>where s c = s ci n c i=1 . For identification purposes, the first fixation is assumed to be in the localization state, i.e., j 1 = 1. Furthermore, Equation (2) does not include the probability of the first fixation (i = 1). At or before this fixation the visual brain is believed to rapidly segment the search display and extract perceptual features from it to build the salience map <ref type="bibr" target="#b12">(Itti and</ref><ref type="bibr" target="#b12">Koch 2001, Koch and</ref><ref type="bibr" target="#b14">Ullman 1985)</ref>. Therefore, the first fixation is used to initialize the transition probabilities of the refixation and systematic strategies, and is not affected by them.</p><p>In the experiment, there are g = 1 G groups of consumers, each with a different search goal. Each of the G = 5 goals affects the salience map differently, which makes it possible to assess the competitive salience of brands and SKUs. Search goals are thought to impose a hierarchical prior on the weights of the individual perceptual features in the salience map <ref type="bibr" target="#b15">(Lee and Mumford 2003)</ref>. For example, if searching for a brand that is remembered to be mostly blue, the color blue will receive higher top-down weight. To capture this, we specify a normal prior distribution c1 ∼ N + g j for the salience weights, c1k , k ∈ K M . We specify G g=1 g = 0, so that the mean for group g equals + g , and consists of an overall effect , and an effect of the specific search goal g . Our interpretation of these parameters is based on the assumption that the effect of each feature that is common across the five search goals is the (mean) bottom-up effect of the display. That is, the effect that the color red, for example, has on the eye-movement pattern under each of the search goals is what we designate as its bottom-up effect. Differences in salience weights between the five search goals are interpreted as their (mean) top-down effects. That is, if red receives a different weight when searching for brand A than it does when searching for brand B, then we believe this to be induced by the search goals for these two brands. The diagonal covariance matrix j captures heterogeneity in the salience weights across individuals. Thus, individuals have different weights for the basic features, and have different salience maps, and these maps are influenced hierarchically by the (mean) bottom-up and top-down g effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Search Performance.</head><p>As an integral component of the model, we allow search performance to be influenced by three aspects of the eye-movement model: f r c , r = 1 3. These are not fixed independent variables, but are functions of the eyemovement model parameters:</p><formula xml:id="formula_5">1 f 1 1c = target k∈K M s cik u v 1ck 2 du dv Display k∈K M s cik u v 1ck 2 du dv</formula><p>captures the relative salience of the target brand in the localization state (higher salience indicates lower spatial uncertainty), where the integral is approximated as a sum over all pixels u v in the target brand. 2. f 2 cj ∝ i∈BT c I z c i = 2 is the total time in the identification state when attending to the target brand (attending longer to the target in the identification state should lead to more accurate decisions), where z ci ∈ 1 2 is a latent variable (computed in the Gibbs sampler) that indicates the state from which fixation i of consumer c is generated, and BT c are the fixations on the target.</p><p>3. f 3 cj ∝ i∈BD c I z c i = 2 is the relative time in the identification state when attending to distracter brands (shorter duration indicates lower identity uncertainty), where BD c are the fixations on all nontarget brands. </p><formula xml:id="formula_6">∼ N         time 0 + r time r f r c acc 0 + r acc r f r c     perf     (3)</formula><p>where time r and acc r represent the coefficients for log search time and accuracy, respectively, and perf is a full covariance matrix.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Estimation and Inference</head><p>The model is estimated with an Markov chain Monte Carlo (MCMC) algorithm 2 with auxiliary variables <ref type="bibr" target="#b5">(Damien et al. 1999</ref>) to estimate c . We follow <ref type="bibr" target="#b24">Robert et al. (1993)</ref> to estimate the HMM, and a Metropolis Hastings step <ref type="bibr" target="#b4">(Chib and Hamilton 2000)</ref> to estimate perf , using 25,000 draws, thinned 1 in 10, with a burn-in of 25,000 iterations. In synthetic data analyses the parameters are recovered well. We compare several alternative models based on the log marginal density, computed using <ref type="bibr" target="#b3">Chib (1995)</ref>. We compute the hold-out Mean Absolute Deviation (MAD) and hitrate for search latency and accuracy, for a random sample of one-third of the participants, by considering y acc c and y time c missing for these participants and sampling them from their predictive distributions within the MCMC algorithm. We compare models with and without systematic search, identification, and effects of search goals.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Findings</head><p>The data contain 1,762 fixations on the display during the search task. Average brand search time was 3.82 seconds (SD = 2 02), and did not vary much across the tasks. Of the 109 consumers, 88% correctly located the target brand. Most failures (9%) were due to incorrectly locating brands.  <ref type="table" target="#tab_3">20 722</ref>). These model comparisons support the full two-state model with goal effects on salience, and strategic search; it explains search performance very well and better than the five competing models. The hold-out MAD of predicted search time and the Hit Rate (HR) for search accuracy are 1.79 sec and 81%, respectively, for the full model. Models without search goals (MAD: 1.82 sec, and HR: 80%), and especially without the identification state (MAD: 1.97 sec, HR: 81%) predict search performance significantly worse, and our model improves over the other three benchmark models, as well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Parameter Estimates</head><p>Table <ref type="table" target="#tab_1">1</ref> shows the posterior means of the parameters. Reducing identity uncertainty is somewhat more important than reducing location uncertainty: the limiting probabilities of the Hidden Markov Chain reveal that consumers spent 32% of the time in the localization state and 68% of the time in the identification state. Consumers are highly likely to refixate the last fixated brand in the latter state; 90% of the consumers terminated search in that state, presumably after having identified the target brand. Saccade lengths are on average 3.4 times larger in the localization state (posterior median 332.0 pixels) than in the identification state (97.2 pixels), which provides evidence of the qualitatively different attention processes that guide eye movements in these two states <ref type="bibr" target="#b2">(Bullier et al. 1996</ref><ref type="bibr" target="#b26">, Thompson 2005</ref>.</p><p>Table <ref type="table" target="#tab_1">1</ref> shows that salience guides attention in the localization state. All individuals have positive posterior median salience weights for blue, and there is substantial heterogeneity. The positive weight of luminance indicates that attention is directed to the brighter locations in the display. Systematic search strategies guided attention strongly as well, independent of salience. In fact, there is a stronger tendency to use the left-right zigzag strategy (posterior median: 0.446) than the right-left zigzag strategy (posterior median: 0.359); consumer heterogeneity in these effects is fairly small. These results are obtained across rotated search displays, and thus are not due to specific positions of brands and SKUs. More salient brands are indeed found faster (posterior median: −0 090) and more accurately (posterior  median: 2.705). Furthermore, consumers who direct more identification fixations to the target are more accurate at the expense of longer search times. The correlation between search time and accuracy is positive but low and positive, which reflects an accuracyeffort trade-off.</p><p>Figure <ref type="figure">1</ref> shows the mean bottom-up and top-down salience maps for two brands (C and E). Note that the maps are derived from the localization state, and that systematic search patterns in the localization state and repeated fixations on the target brand in the identification state do not play a role in their construction. The maps are computed as BU</p><formula xml:id="formula_7">u v = k∈K M s cik • u v k 2 , and TD u v = k∈K M s cik u v k + gk 2 − k∈K M s cik u v k 2</formula><p>, for the bottom-up and topdown components, respectively, and are evaluated at the posterior medians of the parameters in question. The figure reveals the dramatic effects of search goal effects on the salience maps.</p><p>Figure <ref type="figure">2</ref> presents for each of the five target brands the salience per pixel and the proportion of this due to the display, u v ∈ target BU u v , and the search goal, u v ∈ target TD u v . The search targets are highly salient, as revealed in comparison to the average salience per pixel across the image (normalized to equal 1), shown as a horizontal line on the graph. There are important differences in brand salience. For instance, whereas brand B (Omo) and brand D (Sunil) are equally salient, the salience of brand B is more due to its visual image (73%) than is the case for brand D (56%). Search goals account for about onethird of salience. This suggests roughly a 1 to 2 ratio in the effectiveness of strategies to influence salience through out-of-store versus in-store marketing activities, respectively.</p><p>Figure <ref type="figure">2</ref> suggests avenues for building salience through in-store visual marketing. For example, Brand A (Witte Reus) is relatively salient when it is the search target, but its low bottom-up salience suggests that, when it is not on the consumers' shopping list, the visual features of this brand are insufficient to have the brand make eye contact. The estimated bottom-up weights of perceptual features suggest how to improve this, however. The brand may, for example, increase the amount of blue in its package, because that color is already present in its package and blue contributes most to its salience.</p><p>Figure <ref type="figure">2</ref> also provides input for out-of-store activities such as advertising. For example, brand C (Persil) has a relatively small lift of its salience when it is the target of search. Its diagnostic color is green and there is much heterogeneity in the salience weight of that color. Apparently, its green packaging does not facilitate pop-out on the shelf, which is perhaps van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience due to confusion with the green packaging of the market leader, Ariel. But, even worse, consumers do not appear to have strong memory for the visual image of brand C. Advertising should strengthen the association between the brand and its green color to make the brand easier to find when it is on consumers' shopping lists.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Analysis of Competitive Brand Salience</head><p>The estimation of salience and its decomposition into top-down and bottom-up components makes it possible to analyze the competitive salience of brands. Such an analysis reveals visual strengths and weaknesses of brands and their SKUs at the point of purchase. On a continuum of completely similar to completely dissimilar, both brands and their SKUs need to attain an optimum visual differentiation level. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>929</head><p>When brand differentiation is optimal, a brand becomes more salient to consumers that search for it, while at the same time the salience of all competing brands is suppressed. All five brands in our experiment became more salient when they were the search target. Although none of the brands suppressed salience of all competing brands as would be desirable, brand differentiation was closest to optimal for brand D (Sunil). When this brand was the target, the salience of three competing brands was reduced significantly. Brand C (Persil), on the other hand, appears to be underdifferentiated. When it was the search target, the three SKUs of the market leader (Ariel) became more salient as well, and even more so than brand C itself (see Table <ref type="table" target="#tab_3">2</ref>). To improve its visual competitiveness, this brand's visual image needs to become more strongly differentiated from the market leader. Some visual features are shared by all brands in a product category, such as the color red for tomato ketchup. A brand that is overdifferentiated on such category codes could experience adverse effects. This did not occur in the current empirical analysis, but would manifest itself when all or many competing brands gain more in salience than the target brand, which becomes hard to find.</p><p>When SKU differentiation is optimal, a SKU that is searched for and the other SKUs of the same brand become more salient, but the latter less strongly so. Two of the five brands exhibited a close-to-optimal pattern, namely, brands B (Omo) and D (Sunil). However, some of the SKUs of brands A (Witte Reus) and E (Dixan) appear to be overdifferentiated. Specifically, two SKUs of brand A (Color Reus and Witte  Reus Vloeibaar) do not become more salient when the Tablets-SKU of that brand is the search target. The same holds for the SKU of brand E (Dixan Gel). To achieve an optimal level of differentiation, the SKUs of these brands need to increase the similarity of their visual features. When SKUs are underdifferentiated the salience of the other SKUs of the brand in question are increased at least as much as the salience of the target SKU, and the SKUs may be too hard to distinguish. Brand C (Persil) exhibits this pattern: the salience of the Gel-SKU is enhanced equally as that of the target Tablets-SKU. To achieve an optimal differentiation level, this brand needs to differentiate the visual features of its SKUs better.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>Competition on the shelves of supermarkets is intense, and most of that competition is visual. Retailers and manufacturers aim to make their brands stand out to enable consumers to find them quickly, or to pick them up serendipitously on impulse. However, how to make brands salient at the point of purchase is not obvious, and that is an issue with which brand managers and retailers grapple. They seek to make their brands and SKUs more salient than those of their competitors, while obeying established norms about the visual appearance of the category. Both in-store (packaging) and out-of store (advertising) marketing efforts are applied to that end.</p><p>Our study reveals that about one-third of salience on the shelf is due to out-of-store and two-thirds due to in-store marketing. This underlines that the integration of advertising with packaging strategies should be a key concern <ref type="bibr" target="#b13">(Keller and Lehmann 2006)</ref>. The relatively small top-down influences on salience that we found for some brands in our study may well be attributable to a lack of integration of packaging and advertising strategies for some brands.</p><p>We have shown that the salience of brands has a pervasive effect on search performance, but it appears that consumers use only one or two basic features simultaneously when trying to find a brand rapidly and accurately. This has important implications for package design, and for advertising that aims to increase brand salience on the shelf. Such advertising would need to establish strong associations in memory with a limited number of unique features.</p><p>We have proposed a methodology for competitive brand salience analysis and a framework to guide thinking about competitive salience by exposing the optimal visual differentiation level, of a brand versus competitors, and of each SKU versus the other SKUs of the same brand. Our model of the visual search process, captured through eye tracking, helps to identify current levels of visual differentiation of brands and SKUs at the point of purchase and enables diagnostic analysis of competitive salience. Naturally, underdifferentiation of brands leads to brand confusion and reduces market share. But overdifferentiating brand packaging from the category comes with risks as well, because brands that differ too much from the category codes may not be found easily. Visual differentiation of SKUs should play a role in managing product line length and in decisions of product line extensions. Visual underdifferentiation may affect consumers' preference for the brand <ref type="bibr" target="#b11">(Hui 2004</ref>) and lead to cannibalization. Overdifferentiation of SKUs may diminish unique brand associations and erode brand equity.</p><p>Future research could investigate how such factors as the number, facings, and arrangements of brands and SKUs on the shelf affect salience and search. Extending the present analysis to other visual marketing stimuli, including brand logos and ads and to dynamic contexts, including web pages and TV commercials, are other avenues for future research. i = 1: 0 -180 ms. j = 1 i = 2: 180-380 ms. j = 1 i = 3: 380-600 ms. j = 2 i = 4: 600-900 ms. j = 2 i = 5: 900 -1,120 ms. j = 1 i = 6: 1,120-1,340 ms. j = 1 i = 7: 1,340-1,580 ms. j = 2 i = 8: 1,580 -1,740 ms. j = 1 i = 9: 1,740 -2,460 ms. j = 2 i = 10: 2,460-2,540 ms. j = 2 i = 11: 2,540-2,720 ms. j = 2 i = 12: 2,720-2,920 ms. j = 2 5.2% 0.0% 0.0% 1.7% 80.0% 9.3% 1.3% 0.0% 0.0% 0.0% 0.1% 0.0% 0.0% 0.0% 0.0% 0.0% 0.0% Note. An observed eye-movement pattern consisting of 12 eye fixations of a consumer searching for Dixan Tablets (4th SKU at the top shelf), starting at the top-left panel (i = 1 − symbol ), and ending at the bottom-right panel (i = 12 − symbol ). Predicted posterior probabilities of fixation per SKU are shown.</p><p>path is of Participant 3 searching for brand E (Dixan Tablets; fourth SKU at the top shelf). It consists of 12 fixations, each next fixation shown in a separate panel of the figure, starting at the top-left and ending at the bottom-right panel. The (estimated median) attention state is shown for each fixation (j = 1: location, j = 2: identification). Also shown are for each SKU, the fixation probabilities given the attention state. These probabilities are obtained by integrating the pixel-by-pixel fixation probabilities, j u v • as computed from the individual-specific parameter estimates of the model, over the area of the SKU on the shelf (note that these probabilities do not need to sum to one across SKUs, since fixations may fall outside of any of the brand facings on the shelf). Figure <ref type="figure">A1</ref> shows that switching between localization and identification causes the predicted probabilities of the location of a next fixation to change continuously at every fixation. At the first fixation (Panel 1, top left), the consumer is in the localization state (j = 1). Eye movements at this first fixation are entirely driven by the salience map. The target (SKU4) has a probability of 0.145 of being fixated, which is caused by Participant 3's large salience weights for blue and red. The first fixation lands on SKU3. This individual has a strong tendency to use a left-right zigzag strategy, which makes subsequent fixations to the right of SKU3 more likely. This causes the probability that the second fixation is the target to jump to 0.328. Nevertheless, due to the stochasticity in the process, the second fixation (Panel 2) in fact falls on SKU7. At the third and fourth fixations (Panels 3-4) the participant is in the identification state (j = 2). The probability to refixate on the same SKU7 then jumps to 0.778, but the probability to fixate on the target (SKU4) drops to 0. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>931</head><p>Apparently, the identification process does not result in a match, and search continues.</p><p>At Fixation 5 the probability of fixating the target is 0.080, but the probability of fixating SKU13 increases to 0.276, because, similar to the target, that brand has much blue and red. The fifth fixation thus lands on SKU13. At Fixations 5 and 6 (Panels 5 and 6), the individual's use of the left-right zigzag strategy is apparent as the eyes move along the shelf to the right. At Fixation 7 (Panel 7), the individual is again in the identification state and examines the other SKU of the previously inspected brand Omo. Fixation 8 (Panel 8) lands on the target brand, but on SKU5 rather than on target SKU4. The consumer is in the identification state (j = 2) for the next four fixations. Fixations 10 to 12 are on the target SKU4, which has a fixation probability of 0.800. This results in accurate target identification, in 2,920 milliseconds.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Marketing</head><label></label><figDesc>Science 27(5), pp. 922-931, © 2008 INFORMS For each consumer c, search accuracy y acc c and the log of search time y time c indicate search performance. For search accuracy we use a probit formulation, and define the continuous latent normal variable acc</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Six different models are compared using the logmarginal density (LMD): a single-state model with salience only, a single-state model with salience and systematic search, and a two-state model with salience, systematic search in the localization state, and an identification state, each with and without effects of search goals. Model fit improves when systematic search is added (LMD = −22 223) to the one-state salience-only model (LMD = −22 290). Adding the identification state improves fit substantially (LMD = −20 782). Whereas adding the effects of search goals to the one-state salience-only model decreases fit (LMD = −22 443), adding effects of search goals results in an improvement in fit once systematic search (LMD = −22 066) and the identification state are accounted for (LMD = −</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>90% posterior confidence interval does not contain 0, * * 95% posterior confidence interval does not contain 0. a We included a constant and brand dummies to control for brand specific search performance effects; salience multiplied by 100. b Number of identification fixations on SKUs of target brand. c Proportion of fixation frequency on SKUs of competitive brands in identification state. d Variance of search accuracy set to one for identification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 1Illustration of Display (Bottom-Up) and Search Goal (Top-Down) Effects on the Salience Map</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>2 06 −0 11 −0 18 Note. Median parameter estimates (multiplied by 100) are presented. Estimates in bold are from 0.025-0.975 credible intervals not covering 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience Attention Guidance During Target Search and Its Effects on Search Performance Medians of the Posterior Distributions of Parameters</figDesc><table><row><cell>Marketing Science 27(5), pp. 922-931, © 2008 INFORMS</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="3">Analysis of Competitive Brand Salience</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="3">Target brands during search</cell><cell></cell></row><row><cell>Competitive</cell><cell>A 1</cell><cell>B 1</cell><cell>C 1</cell><cell>D 1</cell><cell>E 1</cell></row><row><cell>salience effects</cell><cell cols="5">Witte Reus Omo Persil Sunil Dixan</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience    </figDesc><table><row><cell>Marketing Science 27(5), pp. 922-931, © 2008 INFORMS</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We normalized for each consumer c, the perceptual features, and surfaces, such that the sum of their squared values across all display locations equals 1, so that the estimates of are comparable across variables.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience   </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">A Technical Appendix presenting the details of the MCMC algorithm can be downloaded from the Marketing Science website at http://mktsci.pubs.informs.org.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank the editor, area editor, and the reviewers for their helpful comments. The authors also thank Dominique Claessens of Verify International for the eyetracking database.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>We use the scan path of one participant in Figure <ref type="figure">A1</ref> to illustrate how the model explains the eye movements. This scan  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Inter-brand variant overlap: Impact on brand preference and portfolio profit</title>
		<author>
			<persName><forename type="first">A</forename><surname>Aribarg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Arora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Consumers&apos; perceptions of the assortment offered in a grocery category: The impact of item reduction</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Broniarczyk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">D</forename><surname>Hoyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Mcalister</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="166" to="176" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Functional streams in Occipito-Frontal connections in the monkey</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bullier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Schall</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Morel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behav. Brain Res</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="89" to="97" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Marginal likelihood from the Gibbs output</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chib</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">432</biblScope>
			<biblScope unit="page" from="1313" to="1321" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Bayesian analysis of cross-section and clustered data treatment models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">H</forename><surname>Hamilton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">97</biblScope>
			<biblScope unit="page" from="25" to="50" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Gibbs sampling for Bayesian non-conjugate and hierarchical models by using auxiliary variables</title>
		<author>
			<persName><forename type="first">P</forename><surname>Damien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wakefield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Walker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Statist. Soc.: Ser. B</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="331" to="344" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Beyond the search surface: Visual search and attentional engagement</title>
		<author>
			<persName><forename type="first">J</forename><surname>Duncan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">W</forename><surname>Humphreys</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Experiment. Psych.: Human Perception Performance</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="578" to="588" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Covert attention and saccadic eye movements</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Findlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neurobiology of Attention</title>
				<editor>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
			<persName><forename type="first">G</forename><surname>Rees</surname></persName>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Tsotsos</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier Academic Press</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="114" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Evidence for a systematic component within scan paths in visual search</title>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">D</forename><surname>Gilchrist</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Harvey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Visual Cognition</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4-8</biblScope>
			<biblScope unit="page" from="704" to="715" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The variety of an assortment: An extension to the attribute-based approach</title>
		<author>
			<persName><forename type="first">E</forename><surname>Herpen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Van</surname></persName>
		</author>
		<author>
			<persName><surname>Pieters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="331" to="341" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The variety of an assortment</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hoch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wansink</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="527" to="546" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Product variety under brand influence: An empirical investigation of personal computer demand</title>
		<author>
			<persName><forename type="first">K.-L</forename><surname>Hui</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="686" to="700" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Computational modelling of visual attention</title>
		<author>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Rev. Neuroscience</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="194" to="203" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Brands and branding: Research findings and future priorities</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Keller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="740" to="759" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Shifts in selective visual attention: Towards the underlying neural circuitry</title>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ullman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Neurobiology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="219" to="227" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Hierarchical Bayesian inference in the visual cortex</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mumford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Optical Soc. America</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1434" to="1448" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Global and local covert visual attention: Evidence from a Bayesian Hidden Markov model</title>
		<author>
			<persName><forename type="first">J</forename><surname>Liechty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pieters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="519" to="541" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Vision: A Computation Investigation into the Human Representation and Processing of Visual Information</title>
		<author>
			<persName><forename type="first">D</forename><surname>Marr</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1982" />
			<publisher>W. H. Freeman and Company</publisher>
			<pubPlace>San Francisco</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Sustained Attention in Human Performance</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">H</forename><surname>Monk</surname></persName>
			<affiliation>
				<orgName type="collaboration">. Search. J. S. Warm</orgName>
			</affiliation>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>Wiley</publisher>
			<biblScope unit="page" from="293" to="321" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Separating attention from chance in active visual search</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">C</forename><surname>Motter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Holsapple</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Visual Attention and Cortical Circuits</title>
				<editor>
			<persName><forename type="first">J</forename><surname>Braun</surname></persName>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Davis</surname></persName>
		</editor>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
			<date type="published" when="2001" />
			<biblScope unit="page" from="159" to="175" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Computational architectures for attention. R. Parasuraman, ed. The Attentive Brain</title>
		<author>
			<persName><forename type="first">E</forename><surname>Niebur</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Koch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press</publisher>
			<biblScope unit="page" from="163" to="186" />
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">The area activation model of saccadic selectivity in visual search</title>
		<author>
			<persName><forename type="first">M</forename><surname>Pomplun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">E</forename><surname>Williams</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">R</forename><surname>Gleitman</surname></persName>
		</author>
		<title level="m">Proc. Twenty Second Annual Conference Cognitive Science Society</title>
				<editor>
			<persName><forename type="first">A</forename><forename type="middle">K</forename><surname>Joshi</surname></persName>
		</editor>
		<meeting>Twenty Second Annual Conference Cognitive Science Society<address><addrLine>Philadelphia</addrLine></address></meeting>
		<imprint>
			<biblScope unit="page" from="543" to="548" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A probability vector and transition matrix analysis of eye movements during visual search</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ponsoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Scott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Findlay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="page" from="167" to="185" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bayesian estimation of Hidden Markov chains: A stochastic implementation</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Celeux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Diebolt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statist. Probab. Lett</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="77" to="83" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Computer Vision</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">G</forename><surname>Shapiro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">C</forename><surname>Stockman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Prentice Hall</publisher>
			<pubPlace>Upper Saddle River, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Dissociation of selection from saccade programming</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Thompson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neurobiology of Attention</title>
				<editor>
			<persName><forename type="first">L</forename><surname>Itti</surname></persName>
			<persName><forename type="first">G</forename><surname>Rees</surname></persName>
			<persName><forename type="first">J</forename><forename type="middle">K</forename><surname>Tsotsos</surname></persName>
		</editor>
		<meeting><address><addrLine>San Diego</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="124" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Eye-movement analysis of search effectiveness</title>
		<author>
			<persName><forename type="first">R</forename><surname>Van Der Lans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pieters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc. Forthcoming</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Eye fixations on advertisements and memory for brands: A model and findings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wedel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Pieters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="297" to="312" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">What attributes guide the deployment of visual attention and how do they do it?</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Horowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Rev. Neuroscience</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2004-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Limitations on the parallel guidance of visual search: Color × color and orientation × orientation conjunctions</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">D</forename><surname>Shorter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Friedman-Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Cave</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Experiment. Psych.: Human Perception Performance</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="879" to="892" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">On the distinction between visual salience and stimulus-driven attentional capture</title>
		<author>
			<persName><forename type="first">S</forename><surname>Yantis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Egeth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Experiment. Psych.: Human Perception Performance</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="661" to="676" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
