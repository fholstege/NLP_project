<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Ticking Away the Moments: Timing Regularity Helps to Better Predict Customer Activity</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Michael</forename><surname>Platzer</surname></persName>
							<email>michael.platzer@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Marketing</orgName>
								<orgName type="institution">WU Vienna University of Economics and Business</orgName>
								<address>
									<postCode>A-1020</postCode>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Reutterer</surname></persName>
							<email>thomas.reutterer@wu.ac.at</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Marketing</orgName>
								<orgName type="institution">WU Vienna University of Economics and Business</orgName>
								<address>
									<postCode>A-1020</postCode>
									<settlement>Vienna</settlement>
									<country key="AT">Austria</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Ticking Away the Moments: Timing Regularity Helps to Better Predict Customer Activity</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
					</monogr>
					<idno type="DOI">10.1287/mksc.2015.0963</idno>
					<note type="submission">Received: August 12, 2013; accepted: August 17, 2015; Preyas Desai served as the editor-in-chief and Peter Fader served as associate editor for this article.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>customer-base analysis</term>
					<term>customer lifetime value</term>
					<term>purchase regularity</term>
					<term>stochastic prediction models</term>
					<term>noncontractual settings</term>
					<term>Pareto/NBD</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>A ccurate predictions of a customer's activity status and future purchase propensities are crucial for managing customer relationships. This article extends the recency-frequency paradigm of customer-base analysis by integrating regularity in interpurchase timing in a modeling framework. By definition, regularity implies less variation in timing patterns and thus better predictability. Whereas most stochastic customer behavior models assume a Poisson process of "random" purchase occurrence, allowing for regularity in the purchase timings is beneficial in noncontractual settings because it improves inferences about customers' latent activity status. This especially applies to those valuable customers who were previously very frequently active but have recently exhibited a longer purchase hiatus. A newly developed generalization of the well-known Pareto/NBD model accounts for varying degrees of regularity across customers by replacing the NBD component with a mixture of gamma distributions (labeled Pareto/GGG). The authors demonstrate the impact of incorporating regularity on forecasting accuracy using an extensive simulation study and a range of empirical applications. Even for mildly regular timing patterns, it is possible to improve customer-level predictions; the stronger the regularity, the greater the gain. Furthermore, the cost in terms of data requirements is marginal because only one additional summary statistic, in addition to recency and frequency, is needed that captures historical transaction timing.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The song "Time" by world-famous rock band Pink Floyd is about how a lifetime can rush by and that many people do not realize this until it is too late. This anecdotal evidence by Pink Floyd's songwriter Roger Waters also mirrors some facets of enduring, but noncontractual, customer-firm relationships. In such settings, managers are often left with an uncomfortable degree of ambiguity concerning how to react to the moments that are ticking away with customers who were previously active but have recently grown "silent" in interacting with the focal firm. This paper proposes to consider past timing patterns when interpreting a customer's most recent activity hiatus. By introducing a new probabilistic model for customer-base analysis, the Pareto/GGG, we will show that regularity in interevent timings helps to better predict customer activity.</p><p>In recent years, customer-base analysis has become increasingly popular among marketing analysts and data scientists <ref type="bibr">(Winer 2001, Fader and</ref><ref type="bibr" target="#b16">Hardie 2009)</ref>. Triggered by the availability of vast amounts of customer-level transaction data, combined with the facilitated access to and greater usability of sophisticated models, this popularity is also paralleled by the growing managerial interest in residual customer lifetime value (CLV) and its subcomponents as key metrics for managing customer-centric organizations <ref type="bibr" target="#b46">(Shah et al. 2006</ref><ref type="bibr" target="#b49">, Tirenni et al. 2007</ref><ref type="bibr" target="#b27">, Kumar 2008</ref><ref type="bibr" target="#b13">, Fader 2013</ref>. One of the main challenges in such analyses is accurately predicting future purchase behavior when customer-firm relationships are of a noncontractual nature <ref type="bibr" target="#b37">(Reinartz and</ref><ref type="bibr">Kumar 2000, Gupta et al. 2006)</ref>. First, in such a setting, a customer's current status at time T is not directly observable by the organization, but must be inferred indirectly from past activity. Second, the available historical purchase data is right censored at time T , such that the full lifetime of a customer cohort has yet to be observed. Third, the amount of customer-level data tends to vary significantly. In general, despite the richness of the data in the aggregate, only a few transactions are observed for most customers, and hence to extract the most information from the available data, marketing analysts need to adaptively pool information across customers.</p><p>Figure <ref type="figure" target="#fig_10">1</ref> illustrates the transaction records of two hypothetical customers in a noncontractual setting; the solid black dots indicate the first purchases, and the circles represent repeat purchases. Both cases exhibit identical values of the two widely used statistics to  summarize observed transaction histories, namely, recency (R, indicating the date of the last transaction; here, t 6 = 38) and frequency (F, or the total number of transactions; here, x = 6). The key question for managers is to determine which customer is more valuable to the company at the current time T = 52 and thereafter.</p><p>Applying a purely recency-based heuristic, such as the "hiatus heuristic" used by <ref type="bibr" target="#b54">Wübben and von Wangenheim (2008)</ref>, would leave managers undecided. The same applies to simple RF-based customer scoring models <ref type="bibr" target="#b30">(Malthouse 2001, Malthouse and</ref><ref type="bibr" target="#b32">Blattberg 2005)</ref>, which were originally imported from direct marketing and remain popular among many practitioners for valuing their customers. A series of increasingly sophisticated probabilistic models link simple RF summary statistics with a theoretically well-grounded behavioral story of customers' repurchase behavior and explicitly integrate latent customer attrition into the modeling framework <ref type="bibr" target="#b16">(Fader and Hardie 2009)</ref>. These so-called "buy-till-you-die" (BTYD) models represent the wellestablished standard approach used by data scientists and analysts to predict crucial CLV components (such as the expected number of future purchases) and have been applied in a wide variety of industries <ref type="bibr" target="#b54">(Wübben and von Wangenheim 2008)</ref>. <ref type="bibr">1</ref> In a standard BTYD model, however, customers A and B would also be evaluated equally (same R and F), which is a direct consequence of the model's assumptions regarding the purchase process of active customers. For example, the most widely recognized benchmark BTYD model, the Pareto/NBD <ref type="bibr" target="#b41">(Schmittlein et al. 1987)</ref>, assumes a Poisson purchase process and an exponentially distributed lifetime. The two corresponding customer-level parameters can vary across customers, following independent gamma distributions. Because the gamma-exponential mixture results in a Pareto distribution, whereas the gamma-Poisson mixture leads to a negative binomial distribution, the model is referred to as Pareto/NBD. Among the many variations and extensions of the Pareto/NBD model <ref type="bibr" target="#b16">(Fader and Hardie 2009)</ref>, most retain a Poisson purchase <ref type="bibr">1</ref> The popularity of BTYD models also has benefited greatly from Excel-based implementations <ref type="bibr" target="#b18">(Fader et al. 2005a</ref>) and the more recent availability of open-source implementations in more sophisticated programming environments, such as the R package BTYD <ref type="bibr" target="#b11">(Dziurzynski et al. 2014)</ref>. process, in which the time between two purchases is exponentially distributed. This implies that the most likely time for a repurchase is immediately after a purchase (mode zero). Furthermore, because of the memoryless property of the exponential distribution, the time elapsed since the last purchase does not influence the timing of the next purchase <ref type="bibr" target="#b7">(Chatfield and Goodhardt 1973)</ref>.</p><p>Because of these properties, NBD-based models interpret the purchase hiatus at the end of the observation period equally for both customers in Figure <ref type="figure" target="#fig_10">1</ref>. However, their observed intertransaction timing patterns tell a different story: Customer B shows a regular repurchase pattern, with narrowly distributed intertransaction times (ITTs). The long waiting time since the last transaction thus differs from that customer's individual norm, suggesting that customer B may have actually defected. By contrast, the recent purchase hiatus exhibited by customer A is observed before (t 3 − t 2 ), and hence it does not provide a similarly clear indication of whether this person will be active in the future. A model that adequately accounts for these differences in timing patterns would thus assign a significantly lower probability of future activities to the regular but "overdue" customer relative to the customer purchasing more irregularly. Therefore, these two customers also deserve to be treated differently in terms of allocating marketing resources and tailoring marketing campaigns to them. Efforts need to be undertaken to win back customer B, whereas customer A could be targeted with up-and cross-selling opportunities, because the next purchase event is anticipated to take place soon.</p><p>Recently, in a similar vein, but with opposite signs, <ref type="bibr" target="#b56">Zhang et al. (2015)</ref> introduced the concept of clumpiness in the marketing literature and proposed extending the R, F, monetary value (RFM)-based framework for CLV predictions by including a metric-based approach that captures variations in timing patterns across customers. By definition, their proposed clumpiness metric C takes its minimum value with equally spaced events; hence, clumpiness can be understood as the opposite of regularity. Such non-Poisson-like, "clumpy" patterns of rapidly occurring events separated by longer periods of inactivity can occur, for example, in digital media consumption and website visits (e.g., YouTube, Amazon, eBay, Hulu), where many consumers tend to "binge." <ref type="bibr" target="#b2">Barabasi (2005)</ref> lists further examples of certain human activities that exhibit such "bursts" of activity, followed by longer periods of inactivity, and shows that such patterns can arise as a consequence of a priority-driven decision process. However, there is also evidence that more regular timing patterns are prevalent in other contexts <ref type="bibr" target="#b7">(Chatfield and Goodhardt 1973</ref><ref type="bibr" target="#b22">, Gupta 1991</ref><ref type="bibr" target="#b53">, Wu and Chen 2000</ref><ref type="bibr" target="#b3">, Bardhan et al. 2015</ref>, such as purchases of packaged consumer goods that are frequently consumed (e.g., food, beverages, detergents, toiletries). The consumption patterns for these products are often regular per se and thus trigger regular purchases. Furthermore, if many acts of consumption are required to initiate the need for repurchase (e.g., breakfast cereals, ground coffee, toothpaste, toilet paper), then even if consumption timing is random, purchase timing still will appear regular. Intuitively, this regularity results when variations in interconsumption times cancel one another out when summed together. <ref type="bibr">2</ref> In this paper, we respond to the call by <ref type="bibr" target="#b56">Zhang et al. (2015)</ref> to develop a model-based approach that accommodates intertransaction timing patterns in predicting future purchase activities. Our proposed model builds on a probabilistic BTYD framework and leverages information on timing patterns to make improved inferences regarding customers' activity status. We develop a Pareto/NBD variant that replaces the NBD repeat-buying component with a mixture of gamma distributions (Pareto/GGG) to allow for a varying degree of regularity across customers. We thereby abandon the historical focus on the count process, but fully emphasize accurately capturing the timing process. Although the model captures a wide variety of timing patterns, it does not induce any substantial additional costs in terms of data requirements. Other than the usual RF statistics, it requires only a single summary statistic for the historical ITTs, which can be provided easily while updating the RF variables.</p><p>Before we present the formal properties of the model in §3, we review prior contributions that suggest relaxing the restrictive intertransaction timing assumptions underlying conventional BTYD models and thereby draw conclusions for developing our model variant. We show that the proposed model generalizes the Pareto/NBD by accommodating regular timing patterns, but also nests cases of random (i.e., exponentially distributed) and clumpy patterns. In §4, we explore the improved predictive performance of the Pareto/GGG using a like-for-like comparison with the Pareto/NBD across a broad range of simulated parameter settings, then investigate for which customer segments we should expect the greatest improvement in holdout predictions. Next, we empirically validate the forecasting performance of our model using multiple data sets. By accounting for regularity, our model outperforms both the Pareto/NBD and the heuristic benchmark suggested by <ref type="bibr" target="#b54">Wübben and von Wangenheim (2008)</ref> in terms of out-of-sample, individual-level forecasting accuracy for future customer-level transactions. This is already the case for relatively mild intertransaction timing regularities, whereas the models perform on par for data sets without regularities. When ITTs feature regularity, the greatest improvements accrue in the important, high-frequency, low-recency customer segment. In such a situation, a standard NBD-type model results in overly optimistic predictions and erroneous recommendations with respect to customer prioritization. In §5, we contrast the properties of our model-based approach with the clumpiness metric C developed by <ref type="bibr" target="#b56">Zhang et al. (2015)</ref> in greater detail. Finally, we discuss the merits and limitations of the proposed model for researchers and practitioners and outline some suggestions for further research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Random, Regular, and Clumpy</head><p>Interpurchase Timing</p><p>Since its introduction, the Pareto/NBD model has been extended in various ways, mostly by modifying the dropout process. A particularly noteworthy variation resulted in the betageometric/NBD model (BG/NBD) by <ref type="bibr" target="#b18">Fader et al. (2005a)</ref>, which adjusts the dropout story by restricting defection to repurchase incidents. The BG/NBD approach offers data-fitting capabilities similar to those of the Pareto/NBD model, but it is mathematically and computationally less demanding, which has helped disseminate this model class in real-world settings. In turn, <ref type="bibr" target="#b4">Batislam et al. (2007)</ref> and <ref type="bibr" target="#b25">Hoppe and Wagner (2007)</ref> each modified this variant by allowing for an additional dropout opportunity immediately after the initial purchase (MBG/NBD and CBG/NBD, respectively). In the model developed by <ref type="bibr" target="#b26">Jerath et al. (2011)</ref>, periodic death opportunities serve to decouple the discrete dropout opportunities from the purchase process. <ref type="bibr" target="#b5">Bemmaor and Glady (2012)</ref> reintroduces the assumption of a continuously distributed dropout process, but allows for a nonconstant hazard rate (gamma/Gompertz/NBD). Furthermore, other Pareto/NBD variants have succeeded in incorporating time-invariant covariates <ref type="bibr" target="#b13">(Fader and</ref><ref type="bibr">Hardie 2007, Abe 2009</ref>). However, all of these models retain the assumptions of a Poisson purchase process (i.e., NBD).</p><p>Considering that the dropout process is latent, whereas the purchase process is directly observable and offers more customer-level information, it seems appropriate to focus on the purchase process and model a more flexible distribution to adapt to a wider range of real-world timing patterns. This adaptation appears particularly necessary against the backdrop of our research motivation, namely, to gain a better understanding of the purchase process and thereby to also improve inferences concerning the nonobservable activity status. The idea of accounting for deviations from Poissonlike purchasing in repeat-buying models is not new in the marketing literature. <ref type="bibr" target="#b24">Herniter (1971)</ref> was among the first to propose modeling ITTs using the Erlang-k family of distributions, which allows for various degrees of regularity in timing patterns (i.e., higher k, stronger regularity), but also contains the exponential distribution as a special case (k = 1). In addition, <ref type="bibr" target="#b7">Chatfield and Goodhardt (1973)</ref> combined the Erlang-k with a gamma distribution to reflect the variation in the purchase rate across customers and termed the resulting model a condensed negative binomial distribution (CNBD). Both contributions also offered empirical support for regular purchase patterns of k = 2 for products such as aluminum foil, detergents, razor blades, and soaps. However, in their concluding remarks, <ref type="bibr">Chatfield and Goodhardt (1973, p. 834</ref>) worried that "the CNBD formulas are so much more complex that it is doubtful if the small improvements in fit that seem possible justify the extra effort." Furthermore, these authors focused on stationary settings in a repeat-buying context, whereas we attempt to leverage a better understanding of the timing process to improve inferences concerning the latent activity status. Further research on the characteristics of the CNBD appear in the papers by <ref type="bibr" target="#b39">Schmittlein and Morrison (1983)</ref> and <ref type="bibr" target="#b33">Morrison and Schmittlein (1988)</ref>. <ref type="bibr" target="#b22">Gupta (1991)</ref> presents a framework capable of incorporating time-dependent covariates for estimating NBD as well as CNBD models; the empirical evidence in that article also suggests regular purchase patterns for the coffee category. Within this framework, <ref type="bibr" target="#b17">Fader et al. (2004)</ref> build a dynamic changepoint model, in which changes in purchase frequency predict new product sales along the product cycle. In addition, <ref type="bibr" target="#b43">Schweidel and Fader (2009)</ref> allow for a transition from an exponentially distributed to a more regular Erlang-2 timing pattern over a customer's life cycle. Finally, <ref type="bibr" target="#b53">Wu and Chen (2000)</ref> combine the CNBD model with a nonstationary repeat-buying process and observe strong regularities in the tea category, with an estimate of k = 5.</p><p>It is possible to achieve greater flexibility for modeling intertransaction timing regularity by moving from Erlang-k to a gamma distribution, which contains the former as a special case, although its shape parameter is no longer restricted to integer values. The shape parameter can be estimated at the customer level by calculating the coefficient of variation (CV) or maximum likelihood and is then aggregated across customers <ref type="bibr" target="#b24">(Herniter 1971</ref><ref type="bibr" target="#b10">, Dunn et al. 1983</ref><ref type="bibr" target="#b53">, Wu and Chen 2000</ref>. However, this approach requires sufficient transactions made by a customer (usually 10 or more) and thus suffers in settings marked by low frequency. <ref type="bibr" target="#b50">Wheat and Morrison (1990)</ref> propose an alternative estimation method that requires only two observed ITTs ( t 1 t 2 ) per customer by assuming a common shape parameter k across all customers. The estimate for this shape parameter is given bŷ</p><formula xml:id="formula_0">k wheat = 1 − 4 • var M 8 • var M with M = t 1 t 1 + t 2 (1)</formula><p>which serves as an easy-to-compute data-set-level summary statistic and can be used as a quick diagnostic check for regularity within a customer base before running a more complex modeling approach, such as the Pareto/GGG presented in the next section.</p><p>In addition to the above work, <ref type="bibr" target="#b1">Allenby et al. (1999)</ref> present an even more flexible model that assumes that the intertransaction timing patterns follow a generalized gamma distribution, which contains the gamma, Weibull, lognormal, Erlang, and exponential distributions as special cases, and hence it accommodates a wide variety of timing patterns, including regular purchases. However, both shape parameters remain constant across customers in their model; thus, they only allow for a homogeneous regularity parameter in the customer base.</p><p>More recently, <ref type="bibr" target="#b55">Zhang et al. (2013)</ref> introduce an entire class of C measures to calculate the degree of "clumpiness" at an individual level in time-discrete settings. The design of these measures has been guided by four requirements concerning their behavior. Among others, they are expected to take their maxima when events are tightly clustered and their minima in the case of constant ITTs. Thus, they effectively capture the level of nonrandomness in event timings and also measure regularity, just with opposite signs. Nevertheless, as we will show in §5, to become reliable, these metrics also require a high number of observations at the individual level and therefore need to be used with care in low-frequency or high-churn scenarios. The generalization of the Pareto/NBD presented in the next section, the Pareto/GGG, is able to address both situations well, because it adaptively pools available information across customers and explicitly allows for churn to take place.</p><p>Before introducing this approach, we depict the range of timing patterns induced by assuming gammadistributed ITTs. Figure <ref type="figure" target="#fig_1">2</ref> displays the probability density and multiple sampled timing patterns for three different values of the shape parameter (k ∈ 0 3 1 8 ). To facilitate direct comparisons across settings, we also use k as a rate parameter, such that all result in the same expected ITT of one time unit. Obviously, for higher values of k, the density exhibits a narrower shape, resulting in less variance in ITTs and thus more regular patterns. For smaller values of k, we instead detect tight clusters of transactions along the timeline. As this brief illustration shows, the gamma distribution </p><formula xml:id="formula_1">k &gt; 1 k = 1 k &lt; 1 Regular Random Clumpy 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4 0 1 2 3 4</formula><p>can capture regular (k &gt; 1), random (k = 1), and clumpy (k &lt; 1) patterns; it generalizes the exponential and Erlang-k family of distributions and thus represents a good candidate for a flexible model of timing patterns in noncontractual settings with continuous timing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Model Development</head><p>Because the Pareto/NBD model remains the workhorse among BTYD models operating in continuous time <ref type="bibr" target="#b54">(Wübben and von Wangenheim 2008)</ref>, we selected it as the base for developing a more general model that can account for various timing patterns. Specifically, we replace the exponential with a gamma distribution to model a customer's ITTs and let the shape parameter of that gamma distribution vary across customers. In so doing, we not only allow for heterogeneity in frequency and dropout but also in terms of regularity. Note that other NBD-based models could be generalized in a similar way. Using a hierarchical Bayes setup, the model adaptively pools (the commonly sparse) individuallevel information, and the degree of pooling is driven by the data <ref type="bibr" target="#b38">(Rossi and Allenby 2003)</ref>. Thus, a prior belief about a customer's regularity gets updated in a Bayesian manner, according to the available customerlevel information about variance in ITTs. The more transactions that are available for a customer, the better we can draw inferences on that customer's regularity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Model Assumptions</head><p>3.1.1. Transaction Process. While the customer remains alive, her ITTs, t j = t j − t j−1 , follow a gamma distribution, with shape parameter k and rate parameter k :</p><formula xml:id="formula_2">t j ∼ Gamma k k (2)</formula><p>The mean of the gamma distribution is shape/rate, and the CV is 1/ shape. The chosen parameterization therefore results in the same mean ITT as the Pareto/NBD, 1/ , which allows for a direct comparison of the parameter estimates of between the two models. Here, determines the frequency, and the shape parameter k determines the regularity of the transaction timings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.2.">Dropout Process. A customer remains alive for an exponentially distributed lifetime</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>∼ Exponential</head><p>(3) 3.1.3. Heterogeneity Across Customers. The individual-level parameters k follow gamma distributions across customers independently</p><formula xml:id="formula_3">k ∼ Gamma t (4) ∼ Gamma r (5) ∼ Gamma s (6)</formula><p>Considering these adapted assumptions for the transaction process, we call this new model variant as the Pareto/GGG (gamma-gamma-gamma) model of repeat purchase behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Parameter Estimation</head><p>To achieve the parameter estimation for the Pareto/ GGG, we formulate a full hierarchical Bayesian model with hyperpriors for the heterogeneity parameters, then generate draws of the marginal posterior distributions using a Markov Chain Monte Carlo (MCMC) sampling scheme. This comes with additional computational costs and implementation complexity, compared with the maximum likelihood method available for Marketing Science 35(5), pp. 779-799, © 2016 INFORMS Pareto/NBD, but we simultaneously gain the benefits of (1) estimated marginal posterior distributions rather than point estimates, (2) individual-level parameter estimates, and thus (3) straightforward simulations of customer-level metrics that are of managerial interest. <ref type="bibr" target="#b38">Rossi and Allenby (2003)</ref> provided a blueprint for applying a full Bayes approach (in contrast to an empirical Bayes approach) to hierarchical models such as Pareto/NBD. Then <ref type="bibr" target="#b29">Ma and Liu (2007)</ref> published a specific MCMC scheme, comprised of Gibbs sampling with slice sampling to draw from the conditional distributions. Later Abe ( <ref type="formula">2009</ref>) provided a significantly faster sampling scheme for the Pareto/NBD model by using data augmentation <ref type="bibr" target="#b48">(Tanner and Wong 1987)</ref>, thus expanding the parameter space with two latent variables: unobserved lifetime and activity status z. This approach effectively decouples the sampling of the transaction process from the dropout process and therefore is able to take advantage of simple Bayesian updating rules for the conjugate priors. <ref type="bibr">3</ref> However, for Pareto/GGG, the transaction process priors are no longer conjugate priors, so we must sample the conditional posteriors for the individuallevel transaction parameters k and using MCMC sampling for each Gibbs iteration and for each customer. The continued increases in computational power make even such brute-force simulation methods feasible and enable greater flexibility in model assumptions, as was also demonstrated by <ref type="bibr" target="#b0">Abe's (2009)</ref> Pareto/NBD variant.</p><p>As we show subsequently, the Pareto/GGG requires only one additional, easily maintained summary statistic of historic transaction timings: the sum over the logarithmic ITTs. 4 Therefore, the data requirements imposed by modeling gamma-distributed ITTs are not, in practice, any higher than those for Pareto/NBD, which requires (1) the number of past transactions x, (2) the timing of the most recent transaction t x , and (3) the total observation time T since the customer was acquired. Computing these three statistics requires processing the customer's full transaction history or their continuous updating whenever a new transaction is recorded. In either case, adding the sum of the logarithmic ITTs as an additional measure is straightforward to implement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Key Expressions</head><p>Following, we present expressions for quantities of interest to users of the Pareto/GGG model. In doing so, we use f to denote the density and F to indicate the cumulative distribution function of the gamma distribution.</p><p>P alive The probability that a customer is still alive at time T is derived in Appendix A and results in the following equation:</p><formula xml:id="formula_4">P &gt; T k t 1 t x T = 1 + T t x 1 − F y − t x k k e − y dy 1 − F T − t x k k e − T −1<label>(7)</label></formula><p>Individual-level likelihood. The likelihood of observing x intertransaction times t j and then having no further transaction occur until time T (or in case of churn, until time , i.e., t x+1 &gt; min T − t x ) can be expressed as follows:</p><formula xml:id="formula_5">L k t 1 t x T = x j=1 f t j k k 1 − F min T − t x k k = k kx k x e −k t x x j=1 t j k−1 • 1 − F min T − t x k k (8)</formula><p>Conditional log-posterior for k It follows from Equations ( <ref type="formula">8</ref>) and ( <ref type="formula">4</ref>) that log k t 1 t x T t</p><formula xml:id="formula_6">∝ log likelihood + log prior ∝ kx log k − x log k − k t x + k − 1 x j=1 log t j + log 1 − F min T − t x k k + t − 1 log k − k (9)</formula><p>Note that the conditional log-posterior for the regularity parameter k requires the sum over the logarithmic ITTs as an additional summary statistic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conditional log-posterior for</head><p>It follows from Equations ( <ref type="formula">8</ref>) and (5) that log</p><formula xml:id="formula_7">t 1 t x T k r ∝ loglikelihood+logprior ∝ kxlog −k t x +log 1−F min T −t x k k + r −1 log − (10)</formula><p>Probability distribution of in case of churn. For sampling the lifetime of a customer who churns before T , we must consider the likelihood that no further transactions occur in t x , such that the next ITT will be greater than − t x . The probability distribution of − t x thus can be specified up to a normalizing constant as follows:</p><formula xml:id="formula_8">f − t x k ∝ e − −t x 1 − F − t x k k (11)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">MCMC Procedure</head><p>The sampling scheme to generate draws from the joint posterior distribution is a combination of <ref type="bibr" target="#b29">Ma and Liu's (2007)</ref> Gibbs sampler with slice sampling <ref type="bibr" target="#b34">(Neal 2003</ref>) and <ref type="bibr" target="#b0">Abe's (2009)</ref> augmented parameter space. 1. Use separate gamma distributions as hyperpriors for t, , r, , s, and , and set the according shape and rate hyperparameters t 1 t 2 , 1 2 , r 1 r 2 , 1 2 , s 1 s 2 , and 1 2 to capture the prior belief on the heterogeneity parameters. 2. Set initial values for t, , r, , s, and , such as by using maximum likelihood estimates of Pareto/NBD.</p><p>3. Set initial values for k i i i z i i for all customers.</p><p>4. For each customer i, (a) Draw k i by slice sampling the conditional posterior in Equation ( <ref type="formula">9</ref>);</p><p>(b) Draw i by slice sampling the conditional posterior in Equation ( <ref type="formula">10</ref>);</p><p>(c) Draw i ∼ Gamma s + 1 + i , with the recognition that the gamma distribution is the conjugate prior of the exponential distribution;</p><p>(d) Draw z i ∼ Bernoulli P alive with P alive calculated according to Equation ( <ref type="formula" target="#formula_4">7</ref>);</p><p>(e) Draw i conditional on status z i : (i) If the customer is alive (z i = 1), then draw i ∼ Exponential i , left truncated to T i ; (ii) If the customer has already churned before time T i (z i = 0), then draw i − t x i by slice-sampling the probability density in Equation ( <ref type="formula">11</ref>), truncated to 0 T i − t x i .</p><p>5. Draw the heterogeneity parameters, treating the individual-level parameter draws as data and the specified gamma hyperpriors as priors. <ref type="bibr" target="#b29">Ma and Liu (2007)</ref> propose updating the rate and shape heterogeneity parameters separately, whereas we suggest using component-wise slice-sampling to draw them simultaneously, which reduces the strong auto-correlation of the MCMC chain. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Performance Evaluation and Empirical Analysis</head><p>We benchmark the performance of the Pareto/GGG against the Pareto/NBD using the following evaluation strategy: First, we conduct an extensive simulation study to systematically investigate the role of ITT regularity in holdout-forecasting tasks across variations of our model's assumptions. Second, we assess the empirical performance of the model using six real-world data sets on the purchasing of various product categories at e-commerce websites, an online grocery retailer, and the donation records of a nonprofit organization.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Simulation Study</head><p>Our simulation study sought a better understanding of the benefits of incorporating regularity in a wide variety of purchase settings. For this purpose, we built on the simulation design suggested by <ref type="bibr" target="#b18">Fader et al. (2005a)</ref>, who use three levels for each of the four Pareto/NBD heterogeneity parameters for creating synthetic cohorts.</p><p>To ensure a reasonable size for the total number of simulated "worlds," we chose only the two extreme values for each parameter, but combined these 2 4 = 16 settings with five distributions of regularity and two cohort sizes, resulting in a total full-factorial design of 16 × 5 × 2 = 160 Pareto/GGG scenarios. The chosen parameter values are as follows: N ∈ 1,000 4,000 , r ∈ 0 25 0 75 , ∈ 5 15 , s ∈ 0 25 0 75 , ∈ 5 15 , and t ∈ 1 6 0 4 5 2 5 6 4 8 8 17 20 . The resulting distributions for the regularity parameter k are displayed in Figure <ref type="figure">3</ref>; they include a mix of customers with clumpy, random, and regular transaction timing. Based on these assumptions, we then generated transaction records for a calibration period and a holdout period of 52 weeks each. Similar to the simulation environment created by <ref type="bibr" target="#b18">Fader et al. (2005a)</ref>, the spanned parameter space covers a wide range of settings. The share of customers with no repeat transactions during the calibration period (x = 0) ranges from 22% to 91%; the share of frequent customers with x ≥ 10 spans 0% to 22%; and the share of customers who are active during the holdout period ranges from 4% to 58%.</p><p>For each scenario, we performed parameter estimations using the MCMC sampler, with weakly informative hyperpriors. To ensure like-for-like comparisons between the Pareto/GGG and Pareto/NBD, we also performed parameter estimations for the latter using MCMC sampling. An efficient implementation of the Pareto/GGG and Pareto/NBD MCMC sampler is made available as part of the BTYDplus R package (R Core Team 2014, <ref type="bibr" target="#b12">Eddelbuettel and François 2011)</ref> under an open-source license. <ref type="bibr">5</ref> Further details on runtime and convergence diagnostics are reported in Appendix B.</p><p>To illustrate parameter recovery, Table <ref type="table" target="#tab_1">1</ref> shows the results for five selected scenarios. Apparently, the Pareto/GGG MCMC sampler can recover the underlying data-generating parameters quite well, and it does so more effectively for the purchase process (t r ) than for the unobservable lifetime process (s ). A further analysis of all 160 scenarios confirms that Pareto/NBD tends to overestimate lifetime and ITTs in the presence of regularity. This error likely results because the Pareto/NBD model interprets a long transaction hiatus observed for a regular customer rather as an exceptionally long ITT, because it allows for greater variance in waiting times than would be the case when taking regularity into account.</p><p>Next, we assess the impact of incorporating regularity into the model by examining the lift in predictive accuracy for all 160 simulated scenarios when we move from Pareto/NBD to Pareto/GGG. Forecasting accuracy is compared in terms of the customer-level mean absolute error (MAE) of the predicted number of transactions during the holdout period; 6 we define a relative lift as 1 − MAE PGGG /MAE PNBD and an absolute lift as MAE PNBD − MAE PGGG . Thus, the higher the lift measure, the higher the (relative) gain in predictive accuracy. In general, the Pareto/GGG performs well in these forecasting tasks. In cases with predominantly random or clumpy ITT patterns, the models generally perform on par. However, for scenarios with mildly regular timing patterns, the Pareto/GGG already consistently improves forecasting accuracy across the board, with larger improvements for greater degrees of regularity (up to +20% relative lift). As expected, the stronger the regularity within a cohort, the stronger the lift, and this result holds across all other parameter configurations. A complete summary of the results of the simulation study for all 160 synthetic scenarios is included in Appendix B.</p><p>To obtain a more thorough understanding of the particular customer groups within a cohort for which the largest gains in predictive accuracy can be achieved when accounting for regularity, we combined the forecasts for all 400,000 customers from the 160 simulated worlds and then divided them into distinct segments according to their recency, frequency, and (true underlying) regularity. In terms of frequency, we distinguish groups of customers with four or more transactions (high), one to three transactions (low), and no repeat transactions (zero). For recency, the distinction indicates whether a customer conducted the latest transaction less than eight weeks ago, t x &gt; 42 (high), or more than eight weeks ago (low). Table <ref type="table" target="#tab_2">2</ref> reports the relative and absolute lift in MAE both for Pareto/NBD and Pareto/GGG, along with the average number of transactions during the holdout period for that segment. We also rank our 400,000 synthetic customers according to their regularity, divide them into 10 equally sized groups, and plot their corresponding relative lift in MAE against their mean regularity in Figure <ref type="figure">4</ref>. Several important findings emerge from inspecting Table <ref type="table" target="#tab_2">2</ref> and Figure <ref type="figure">4:</ref> • The stronger the regularity, the greater the lift in the predictive accuracy of the Pareto/GGG compared with the Pareto/NBD forecasts.</p><p>• For customers with random (k ≈ 1) or even clumpy (k &lt; 1) purchase patterns, the Pareto/GGG offers predictions that are generally on par with those of the Pareto/NBD.</p><p>• The lift for customers purchasing at high frequencies is greater than for customers with lower purchase frequencies, likely because Pareto/GGG detects an individual's degree of regularity more easily when more transactions are observed in the past. However, we find a lift even for customers with few or zero repurchase transactions. In such cases, the model leverages the estimated heterogeneity of regularity to form a prior belief about each person's regularity.</p><p>• The lift for customers with a longer purchase hiatus since the last observed purchase (i.e., the low recency group) is greater than that for those who were  active recently. It seems (and we will subsequently confirm this) that the presence of regularity particularly facilitates distinguishing between active and inactive customers, if their next transaction is overdue. While this finding makes intuitive sense, traditional NBD-type models fail to take advantage of it. If the timing patterns are fairly erratic, this becomes relatively inconsequential. However, in a world with increasingly regular purchase timing, the Pareto/NBD no longer provides good predictions and is clearly outperformed by the much more flexible Pareto/GGG.</p><p>• The greatest lift emerges for the group of customers who formerly purchased very frequently in the past but have not been active more recently. Although usually a relatively small segment, it deserves particular attention by managers because these valuable customers are currently at risk of being lost. Accounting for regularity helps to remove some of the ambiguity regarding their future behavior.</p><p>• Finally, note that for the high-frequency, lowrecency segment, the mean number of transactions during the holdout period x * is significantly lower for regular than for random customers (2.31 vs. 3.49; see Table <ref type="table" target="#tab_2">2</ref>). A purely RF-based model would not be able to capture such a pattern.</p><p>These findings suggest refining the observation of <ref type="bibr">Zhang et al. (2015, p. 206</ref>) that "a buy-till-you-die story performs well for nonclumpy customers, but  not for clumpy ones." Although the clumpiness phenomenon might indeed be better accommodated in a modeling framework that allows for a more complex nonstationary repeat-buying behavior, we advocate replacing the dichotomy of clumpy versus nonclumpy with the understanding that timing patterns range along a continuum between clumpy and regular (with improved predictions for the latter when adopting the Pareto/GGG).</p><p>In noncontractual settings, the expected number of future transactions depends largely on the assessment of a customer's latent status. The BTYD model class assumes that a customer who has defected is "lost for good" and will not make any further transactions in the future. To better understand the previous discussion on the varying impact of regularity for predicting future transactions (Table <ref type="table" target="#tab_2">2</ref>), a closer examination of the functional shape of P alive (see §3.3) and its interplay with recency, frequency, and regularity is helpful. Figure <ref type="figure">5</ref> displays the dependence of P alive on observed recency for two levels of frequency ( ∈ 1/6 1/26 ), for various degrees of ITT regularity (k ∈ 0 5 1 2 4 8</p><p>), and for a hypothetical customer with a mean lifetime of 52 weeks ( = 1/52). The thick solid curve (k = 1) displays the corresponding functional shape of a Poisson purchase process, paired with an exponentially distributed lifetime (i.e., Pareto/NBD). The thin solid line (k = ) instead shows the extreme case of equally spaced transaction timings. The dotted line represents a clumpy customer, and the three dashed lines represent various degrees of regularity. A closer inspection of Figure <ref type="figure">5</ref> reveals that the deviation from Pareto/NBD depends largely on whether the latest transaction hiatus T − t x is greater or smaller than the expected ITT. If the transaction is overdue (i.e., T − t x &gt; mean ITT ), P alive declines for regular customers, and the magnitude of this shift depends on the strength of the regularity.</p><p>Our motivating example in Figure <ref type="figure" target="#fig_10">1</ref> reflects this finding: It indicates the timing patterns of customers A and B with the same recency and frequency but different degrees of regularity. Figure <ref type="figure">5</ref>(a) also indicates their approximate positions on the corresponding P alive curves. Their observed purchase hiatus of 14 weeks yields a 44% probability of being alive for customer A with random purchase occurrences; it is close to 0% for regular customer B. For the border case with deterministic timing patterns, P alive) falls to zero immediately after the (constant) ITT has elapsed without activity. In the case of clumpy patterns, with strongly varying ITTs, the effect moves in the other direction, resulting in greater uncertainty regarding the latent activity state of the customer. This is exactly reflected by the findings of <ref type="bibr" target="#b56">Zhang et al. (2015)</ref> of larger prediction errors for clumpy customers using a BTYD model (in their case, the BG/BB by <ref type="bibr" target="#b20">Fader et al. 2010)</ref>. For customers who were recently active (again, in relation to their expected ITT), as depicted to the right of the curves' inflection points, we find only marginal differences. Comparing Figures <ref type="figure">5(a</ref>) and 5(b) further supports our previous finding from the simulation study that the largest gain in predictive accuracy should be expected for customers with high frequency and low recency because, for these segments, regularity allows us to remove some of the ambiguity concerning the customer's status.</p><p>In sum, our simulation study shows that the presence of regularity allows for better predictability. Thus, replacing the NBD with the more flexible GGG-type transaction model is particularly advisable for data sets exhibiting regular timing patterns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Empirical Application of the Pareto/GGG</head><p>Model We now empirically examine the importance of incorporating ITT regularity into stochastic models, using six data sets that represent various settings.</p><p>• CDNOW: This data set includes 2,357 customers of an online CD store (CDNOW) who were acquired in the first quarter of 1997 and then observed over 1.5 years. This canonical data set has been studied and benchmarked extensively in the marketing literature <ref type="bibr" target="#b14">(Fader and Hardie 2001;</ref><ref type="bibr">Fader et al. 2005a, b;</ref><ref type="bibr" target="#b4">Batislam et al. 2007;</ref><ref type="bibr" target="#b54">Wübben and von Wangenheim 2008;</ref><ref type="bibr" target="#b0">Abe 2009;</ref><ref type="bibr" target="#b26">Jerath et al. 2011;</ref><ref type="bibr" target="#b5">Bemmaor and Glady 2012;</ref><ref type="bibr" target="#b56">Zhang et al. 2015)</ref>.</p><p>• Apparel and accessories: This data set includes 831 customers of an online apparel and accessories retailer (www.m18.com) who were acquired in April 2009 and observed over the course of one year. This data set came from <ref type="bibr" target="#b56">Zhang et al. (2015)</ref>, who kindly provided us with access to their data.</p><p>• Donations: This data set includes 21,166 donors to a nonprofit organization who were acquired in the first half of 2002 and observed over 4.5 years. The data set was provided by the Direct Marketing Educational Foundation (see also <ref type="bibr" target="#b31">Malthouse 2009</ref><ref type="bibr" target="#b5">, Bemmaor and Glady 2012</ref><ref type="bibr" target="#b44">, Schweidel and Knox 2013</ref>.</p><p>• Groceries: These data came from an online retailer offering a broad range of grocery categories. The total observation period spans four years. Because customers' acquisition date was not part of this data set, we constructed a quasi cohort by limiting the analysis to the 1,525 customers who purchased in the first quarter of 2006 but not at all in the preceding two years. 7 These purchase data are available at the product category level, which allows us to study purchase patterns by category.</p><p>• Dietary supplements and office supplies: Two additional data sets come from an anonymous e-commerce service provider, each consisting of 35 weeks of purchase records for 1,000 randomly sampled customers.</p><p>All data sets contain the complete transaction records, including exact dates. Repeated transactions by a customer on a given day are treated as a single transaction. Without loss of generality, the chosen unit of time for our analysis is one week, and hence we provide the reported lifetime and ITT estimates in weeks. <ref type="bibr">8</ref> Figure <ref type="figure">6</ref> provides an overview of all six data sets by displaying the timing patterns of 40 randomly sampled customers, plus the histogram of transaction counts divided by calibration and holdout period. The displayed timing patterns reveal the sparseness of the available customer-level information, which requires us to pool data across customers. Furthermore, we can visually detect the varying degrees of regularity across not only the data sets but also the frequent customers in the databases. We seek to quantify this regularity and its heterogeneity by fitting the Pareto/GGG model.</p><p>For each data set, we fit both the Pareto/GGG and Pareto/NBD models using MCMC sampling, with the same settings as in the simulation study: four chains with 8,000 samples, of which the initial 2,000 are the burn-in sample. For the donations data set, we increased the samples to 30,000 because of the high autocorrelation in the draws for the lifetime parameters s and .</p><p>A summary overview of the resulting posterior distributions for the model parameters is given in Table <ref type="table" target="#tab_5">3</ref>; the ranges of the respective posterior estimates for regularity are depicted in Figure <ref type="figure">7</ref>. For the CDNOW data set, the regularity parameter k varies narrowly around 1, which confirms the validity of assuming a Poisson purchase process for this specific customer base. The estimates for the remaining Pareto/GGG parameters closely match those for Pareto/NBD, and both models result in similar fit and predictions. For the apparel and accessories retailer, the estimates for k also exhibit little variation, although the timing patterns appear rather irregular (k q50 = 0 85). For the remaining four data sets, we detected varying degrees of regularity, with a median k ranging from 1.78 for dietary supplements to 3.47 for the grocery retailer (see Table <ref type="table" target="#tab_5">3</ref>). However, as can also be seen from Figure <ref type="figure">7</ref>, the individual-level estimates of the regularity parameter k vary significantly within these customer bases. In the grocery data set, for example, close to 10% of customers are estimated to purchase with timing patterns that are   more irregular than random (k &lt; 1), and another 10% exhibit strong regular patterns with k larger than 9.24 (see the corresponding quantiles for k q10 and k q90 in Table <ref type="table" target="#tab_5">3</ref>).</p><p>We also investigated how many of the individuallevel marginal posterior densities for which we have 90% confidence that the timing patterns are more regular than random (i.e., P k &gt; 1 &gt; 0 9 . Whereas for the CDNOW and the apparel and accessories data sets there were no such customers, the share of customers who satisfy this condition is 95% for donations, 72% for groceries, 58% for dietary supplements, and 80% for the office supply data set. This suggests that regularity is a widely prevalent phenomenon at least for some of the empirical data we explored and for substantial fractions of customers within these data sets. Our observation is perfectly consistent with those from the related literature reviewed by §2 and with the findings by <ref type="bibr" target="#b56">Zhang et al. (2015)</ref>, who report the presence of clumpy timing patterns to be particularly present in online visitations and to a far lesser extent for repeated purchases. It is an interesting research subject to study whether these findings also hold for a broader set of empirical settings. Furthermore, Table <ref type="table" target="#tab_5">3</ref> shows that for data sets with mainly regular patterns, the Pareto/NBD results in significantly higher estimates for lifetime , and thus P alive , compared to Pareto/GGG. This finding accords with those from the simulation study, which diagnosed a systematic bias for the Pareto/NBD in the presence of regularity.</p><p>Corresponding to the simulation study, we also assess forecasting accuracy using the MAE of the predicted number of transactions during the holdout period and the comparative lift when we incorporate regularity. In addition, we provide the MAE for a simple heuristic forecast following a method suggested by <ref type="bibr" target="#b54">Wübben and von Wangenheim (2008)</ref>. Table <ref type="table" target="#tab_7">4</ref> reports the results for all six empirical data sets, which conform to those of the simulation study: the stronger the ITT regularity, the greater the lift in predictive accuracy, whereas for cases with predominantly random purchase occurrence, the models perform equally well. Note  that by taking regularity into account, the probabilistic model outperforms the heuristic in all six cases. Next to the median of the posterior for the Pareto/GGG regularity parameter k, Table <ref type="table" target="#tab_7">4</ref> also reports <ref type="bibr" target="#b50">Wheat and Morrison's (1990)</ref> summary statistic calculated according to Equation (1). Except for the grocery data set, which is characterized by a considerable degree of heterogeneity,k wheat approximates the regularity estimated by the Pareto/GGG fairly well. Given our empirical findings and the diagnostic power of the <ref type="bibr" target="#b50">Wheat and Morrison (1990)</ref> summary statistic, we expect that customer-base analysts would benefit from the improved performance of the Pareto/GGG relative to the Pareto/NBD whenk wheat is estimated to be approximately 1.5 or higher. Note, however, that this is a data-set-level statistic and ignores any potential heterogeneity across individual customers.</p><p>To illustrate the changes in the individual-level estimates when we account for regularity, we inspect three selected customers from the grocery data set in detail. Figure <ref type="figure">8</ref> displays the timing patterns during the calibration and holdout periods, together with their corresponding Pareto/GGG and Pareto/NBD parameter estimates. Customer (a) engaged in four rather regularly spaced transactions during the calibration period, but was not active in the last months of 2006 (the end of the calibration period). The Pareto/GGG estimates a strong degree of regularity (k q50 = 6 1) for this customer and assigns a probability of only 56% that this customer will purchase again, compared with the significantly higher probability of 77% according to the Pareto/NBD model. Note that the posterior probability density for the next transaction arrival shows a steep decline, implying that the next purchase event is overdue. To marketing managers, these are clear signals that the customer (rightly) is at risk of being lost and that appropriate marketing actions are called for. The Pareto/GGG performs substantially better at identifying this than does the Pareto/NBD, for which the long transaction hiatus is not as strong an indicator of defection. Customer (b) exhibits similarly strong regularity, but has remained active recently. Because of the recent transaction, P alive is (correctly) assessed equally high by the two models. However, the posterior probability density estimated by the Pareto/GGG points to an expected short inactivity period, after which transactions are expected to fall in a rather narrow bandwidth. Customer (c) undertook five rather irregularly spaced transactions in 2006, resulting in an estimate of k q50 = 0 9, which further demonstrates the variety of timing patterns that can appear in one and the same customer cohort. Because of the clumpy ITT pattern, P alive is also slightly elevated when it is taken into consideration. In sum, these findings reinforce the previously discussed model behavior, as depicted in Figure <ref type="figure">5</ref>. Apparently, the clumpy case is difficult to predict for both models, and the Pareto/NBD assumptions appear to be not particularly costly relative to the Pareto/GGG.</p><p>To conclude our empirical application, we exploit the shopping basket data at the product category level in the grocery data set to provide some further insights into which categories exhibit stronger regularities than others. For each of the 143 product categories, we construct quasi cohorts of customers who did not purchase in that category in 2004 and 2005 but did so in the first half of 2006. Using these cohorts, we then fit a Pareto/GGG model using all of 2006 as a calibration period, obtaining estimated distributions for k in each category. Among the most regularly bought categories, we find perishable food categories such as salad (k q50 = 7 7) and fresh cheese (k q50 = 6 0), as well as packaged, regularly consumed goods, such as washing detergents (k q50 = 6 0), fabric conditioners (k q50 = 5 0), aluminum foil (k q50 = 4 7), ground coffee (k q50 = 4 2), and toilet paper (k q50 = 3 4). The less regular categories still exhibit median k values greater than 1.5, as exemplified by categories such as pantyhose (k q50 = 1 5), spices (k q50 = 1 9), and flour (k q50 = 2 0). A benchmark of the Pareto/GGG against the Pareto/NBD further showed that for 140 of the 143 available categories, we increased predictive accuracy by accounting for observed regularity (the detailed results are available on request). As our findings suggest, ITT regularity generally translates into lower prediction errors. Thus, even for customers exhibiting considerable uncertainty in their future purchase behavior at the firm-level,</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Relationship Between the Regularity</head><p>Parameter k and the Clumpiness Metric C <ref type="bibr" target="#b55">Zhang et al. (2013)</ref> introduce a class of measures to capture clumpiness in incidence data. A subsequent contribution by <ref type="bibr" target="#b56">Zhang et al. (2015)</ref> demonstrates the application of these measures to customer-base analysis using a specific C metric (i.e., the H p variant) for a variety of purchase (purchase C) and online visit (visit C) patterns. The main empirical findings related to our research are that (1) clumpiness is a prevalent phenomenon, but mainly in the context of online visits and digital media consumption; (2) the inclusion of the C metric improves the data-fitting capability of RFMbased regression models of customers' future (i.e., outof-sample) activity; and (3) clumpy customers tend to be more active than regular ones in future periods. <ref type="bibr">9</ref> Our presented research supports these findings, provides a link to the theoretical framework underlying the wellestablished class of BTYD models and thus contributes to improving our understanding of them, and develops a predictive model capable of extrapolating beyond the calibration period.</p><p>To establish the relationship between the Zhang et al. ( <ref type="formula">2015</ref>) C metric and the shape parameter k of the gamma-timing model of the Pareto/GGG, we conducted another simulation study. For various values of k, we generated 10,000 Gamma k k timing patterns with n = 6 and n = 12 events each and calculated their H p metric accordingly. The parameter is chosen sufficiently small to avoid zero-length ITTs when converting to discrete time units. The solid black curves in Figure <ref type="figure">9</ref> visualize the median over the H p samples and reveal a strictly monotonous relationship between C and k: the higher k is, and thus the less variation we have in the ITTs, the lower the C-measure will be. Thus, despite being designed by the authors to measure clumpiness, the metric C also captures the degree of regularity.</p><p>Figure <ref type="figure">9</ref> further shows, for increments of k, the variation in the measure C as vertical lines, with the sampled 5% and 95% quantiles indicated by whiskers. Comparing Figure <ref type="figure">9</ref>(a) with Figure <ref type="figure">9</ref>(b) also demonstrates that the more transactions we observe per customer, the more confident we can be regarding the degree of clumpiness or regularity, respectively. In both graphs, there is significant overlap between the sampled C values across different timing patterns, but this is particularly pronounced for a smaller number of transactions. Furthermore, we extend the whiskers horizontally for the case of a simulated Poisson process (i.e., k = 1) by dotted lines, as these boundaries serve as the rejection regions for detecting clumpiness as described in <ref type="bibr" target="#b55">Zhang et al. (2013)</ref>. We find that only in cases of very strong clumpiness or strong regularity (marked by the whiskers in bold), the C measure is able to correctly reject the null hypothesis of randomly distributed events for more than half of the customers. Therefore, in settings characterized by customers with a small number of events (e.g., n &lt; 10) during the observation period, analysts should be cautious when calculating the C measure, because it bears a significant Another potential shortcoming of the C measure is its insensitivity in distinguishing between clumpy interevent timing and latent defection or churn. Any defected customer with a prolonged phase of inactivity at the end of the observation period will be biased toward clumpiness. This can also be seen from the evolution of the C measure for the third sample customer in Figure <ref type="figure" target="#fig_1">2</ref> of <ref type="bibr" target="#b55">Zhang et al. (2013)</ref>. When simulating an entire customer base following the Pareto/NBD assumptions, whereas parameters r, , s, and are set to match the CDNOW parameter estimates <ref type="bibr" target="#b18">(Fader et al. 2005a</ref>), 10% of the customer base will be incorrectly classified as clumpy, despite the rejection rate of the test being set to 5%. In these cases, the events might mistakenly appear to be "clustered" due to a long period of inactivity after a customer has dropped out. For churn settings with higher frequency (r = 0 75, = 5, s = 0 75, = 5, T = 52), the type I error can be as high as 35%. However, we need to concede here that <ref type="bibr" target="#b56">Zhang et al. (2015)</ref> primarily focus on visit C, and in digital settings such as those studied by the authors, infrequent visits and churn might not be a substantial issue. Thus, in such (or similar) settings, the C metric actually might be a useful tool for scanning a data set before any formal model fitting. However, in the case of purchase histories with significant shares of customers who purchase less frequently (n &lt; 10) and/or where customer defection is prevalent, the Pareto/GGG offers a descriptive and predictive alternative that is capable of avoiding both of the above-described shortcomings of the C measure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">General Discussion and Future Research</head><p>Many companies exploit the continuous influx of transaction data to make inferences about the future activity of their customers and related metrics, such as CLV and its subcomponents <ref type="bibr" target="#b18">(Fader et al. 2005a</ref>). Yet, despite the considerable scale of data available at the overall level, little information is typically available at the individual level because a significant share of customers engages in few (if any) repeat transactions. Thus, it is common practice to pool information across customers, and probabilistic purchase models based on RF data remain the primary means for doing so <ref type="bibr" target="#b42">(Schwartz et al. 2014</ref>). However, by condensing historic transaction records to RF summary statistics alone, these models discard any additional customer-level information that is contained in the past timing patterns but equally easily available to the analyst. Recently, <ref type="bibr" target="#b56">Zhang et al. (2015)</ref> questioned whether recency and frequency are sufficient statistics to fully summarize a customer history and posit that adding an individual-level statistic reflecting a customer's interevent timing patterns helps to better understand CLV and its subcomponents. The authors propose a metric-based approach to extend the widely adopted RF framework, with a measure to capture clumpiness in timing patterns, and they also demonstrate its usefulness for predicting customer value. Whereas <ref type="bibr" target="#b56">Zhang et al. (2015)</ref> are very clear in positioning their work as a "measurement paper," our contribution is a "modeling paper." We complement their timely and important research by introducing a model-based approach, which accommodates a wide range of timing patterns (regular, random, and irregular) but adaptively pools the information across customers to attain reliable, individual-level estimates. A probabilistic modeling approach to capture regularity is not new to marketing <ref type="bibr" target="#b7">(Chatfield and</ref><ref type="bibr">Goodhardt 1973, Morrison and</ref><ref type="bibr" target="#b33">Schmittlein 1988)</ref>, but this research and the proposed Pareto/GGG model make two novel contributions. First, we propose adaptively pooling the sparse, individual-level information on timing patterns across customers and then leveraging heterogeneity in regularity to predict future behavior. Second, we build intuition and consistently demonstrate using an extensive simulation study and empirical applications that, particularly in a BTYD setting, accounting for regularity is highly beneficial because it facilitates making inferences regarding the customer's latent status. In such settings, we gain the most in terms of predictive accuracy for the managerially important segment of highly frequent but recently inactive customers. All of these benefits entail only marginal additional costs in terms of data requirements, which involve simple and sufficient summary statistics of historical transaction records.</p><p>Beyond developing the Pareto/GGG model and comparing it to the Pareto/NBD model, our research in turn offers several important managerial implications. First, better predictions of important CLV components are of value to customer relationship managers per se because such improved estimates help them to prioritize customers more effectively. Second, the model results in sound customer-level estimates of the regularity parameter k and thus provide a valuable customer metric (as illustrated by Figure <ref type="figure">8</ref>). For example, marketing managers can use this diagnostic information as a basis for segmenting customers (e.g., into irregular, random, and regular segments), as well as to score them according to their attractiveness and predictability. The corresponding Rand F -related metrics could define further subsegments. Third, managers might apply this segmentation effectively in their customer targeting and resource allocation decisions. For example, regular customer types could be targeted with cross-or upselling options prior to their next projected visit; "overdue" regular customers should be gently reminded to return or solicited to provide customer feedback. Finally, companies operating in multiple categories could also learn from categoryspecific purchase timings to draw inferences concerning the (overall) activity status of their customers. For example, even customers showing random (or clumpy) ITT patterns at the firm level could reveal some aspects of regularity at the category level when examining their shopping baskets in greater detail, i.e., categories they purchase on a more regular basis. Indeed, our empirical study using online grocery data showed that there is considerable variation across categories. Model builders could leverage this information by extending our approach in an integrated multicategory purchase timing model. Managers could then benefit from the potential insights from such an approach by deriving customized marketing efforts across categories.</p><p>In this paper, our main focus has been on the accurate individual-level prediction of the expected number of future transactions, which could easily be converted into a discounted quantity to yield a net present value as suggested by <ref type="bibr" target="#b19">Fader et al. (2005b)</ref>. Although (discounted) expected transactions are an important aspect of customer valuation, extending the Pareto/GGG toward a full CLV model would require a submodel for the purchase amount per transaction. The flexibility of our hierarchical Bayesian model approach permits the incorporation of such an extension, for example, by assuming a standard normal <ref type="bibr" target="#b40">(Schmittlein and Peterson 1994)</ref>, a log-normal <ref type="bibr" target="#b6">(Borle et al. 2008)</ref>, or a gamma-gamma <ref type="bibr" target="#b8">(Colombo and Jiang 1999)</ref> submodel for purchase amounts. With such an extension toward a fully faceted model to predict residual CLV for a customer base, relationship managers could benefit further from the insights we have gained from applying the Pareto/GGG in our empirical studies.</p><p>To our knowledge, this research represents the first systematic study demonstrating that the presence of ITT regularities improves the predictability of future purchase behavior. Regarding further research, we anticipate similar gains from our proposed gammadistributed timing model for inferring customers' latent activity states not only in BTYD settings but also for the broader class of hidden Markov models <ref type="bibr" target="#b42">(Schwartz et al. 2014</ref>), 10 with the promise of detecting changes between high-frequency and low-frequency purchase phases (or vice versa) more quickly. This also includes models in which customers are allowed to make back-and-forth transitions between an active and an inactive state (e.g., an "on and off" purchasing model; see <ref type="bibr" target="#b42">Schwartz et al. 2014)</ref>. We conjecture that modeling approaches accounting for such nonstationary repurchase behavior might be good candidates for capturing clumpy ITT patterns (interpreted as "episodes" with higher purchase propensities followed by a period with lower or even no activity) and to translate this capability into better predictions of future transactions. However, such models typically come at some additional costs because they require complete purchase histories and not merely summary statistics.</p><p>Certainly, we also have to acknowledge that, similar to any other BTYD model, the Pareto/GGG implicitly assumes stationary marketing activities in both the calibration and forecasting periods. It thus can serve as a baseline for benchmarking the impact of changes in target marketing actions <ref type="bibr" target="#b18">(Fader et al. 2005a)</ref>. It is beyond the scope of this paper but would be important yet challenging to build a model that incorporates marketing covariates, in addition to accounting for ITT regularities. The hidden Markov model-based approaches presented by <ref type="bibr" target="#b35">Netzer et al. (2008)</ref> and <ref type="bibr" target="#b45">Schweidel et al. (2011)</ref> offer promising starting points for endeavors to model the interplay between ITT regularity and marketing actions.</p><p>Finally, several other extensions of our research would be welcome. In particular, we call for studies that translate the general idea underlying the Pareto/GGG Marketing Science 35(5), pp. 779-799, © 2016 INFORMS into a discrete-time setting. The BG/BB introduced by <ref type="bibr" target="#b20">Fader et al. (2010)</ref> could serve as a modeling framework, although researchers would need to relax the memoryless binomial assumption for purchase occurrences. In addition, the modeling flexibility gained by an MCMC sampling scheme might facilitate links between individual-level parameters ( , , but also k) and customer-specific covariates, as well as allow for correlations between them, as demonstrated by <ref type="bibr" target="#b0">Abe (2009)</ref>. With a link between the purchase and dropout processes, the effect of ITT regularities on customers' activity states could be studied even more thoroughly than we have done in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental Material</head><p>Supplemental material to this paper is available at http://dx .doi.org/10.1287/mksc.2016.0963.    </p><formula xml:id="formula_9">0 0 0 0 −2 0 −2 −1 mean(k) − 1 75 5 +6 −6 +14 0 +5 0 +11 +3 +4 25 15 −1 0 0 −2 −2 0 −2 −2 −1 75 15 0 0 +9 −3 0 0 +2 0 0 t = 17/y = 20 25 5 0 −1 0 −2 −1 −2 −2 −2 −1 mean(k) = 0.85 75 5 +1 0 +7 +2 −2 −3 +4 0 +1 25 15 −1 −3 −2 −4 −1 −2 −3 −2 −2 75 15 −3 −1 +1 −4 −1 −2 +1 −3 −2 Mean +4 +3 +7 +6 +3 +3 +7 +4</formula></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1Same Recency, Same Frequency, yet Customer A Is More Likely to Be Alive than Customer B 0 5 7 2 3 3 03 2 3 8 5 2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2Distribution and Sampled Timing Patterns for Gamma k k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Steps 4 and 5 until convergence is reached and sufficient samples have been drawn.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 3Interquartile Ranges for Simulated Distributions of Regularity Parameter k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>, Pareto/NBD; PGGG, Pareto/GGG.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figure 4Relative Lift in MAE vs. Regularity k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Figure 5Interplay of Recency, Frequency, Regularity, and P (alive)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>, Pareto/NBD; PGGG, Pareto/GGG. Values in bold describe the relative lift in MAE for the Pareto/GGG against the Pareto/NBD.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Figure 7Interquartile Ranges for Posterior Distributions of Regularity Parameter k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Marketing</head><label></label><figDesc>Figure 9 (Color online) Calculations of Metric C for the Range of Gamma k k Distributed Events (a) 6 transactions</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure B. 1 (</head><label>1</label><figDesc>Figure B.1 (Color online) MCMC Chains for the Simulated Scenario with t = 5 = 2 5 r = 0 25 = 5 s = 0 25 = 5, and N = 1 000</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>Recoverability of True Parameters for Five Selected Scenarios with N = 4 000</figDesc><table><row><cell>t q50</cell><cell>q50</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Impact of Incorporating Regularity by Customer Segment</figDesc><table><row><cell>Customer segment</cell></row></table><note>Notes. PNBD, Pareto/NBD; PGGG, Pareto/GGG. Values in bold describe the relative lift in MAE for the Pareto/GGG against the Pareto/NBD.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc>Selected Quantiles of the Posterior Distributions for Pareto/GGG and Pareto/NBD Parameters</figDesc><table><row><cell></cell><cell></cell><cell>t q50</cell><cell>q50</cell><cell>r q50</cell><cell>q50</cell><cell>s q50</cell><cell>q50</cell><cell>k q10</cell><cell>k q50</cell><cell>k q90</cell><cell>IT T q50</cell><cell>q50</cell><cell>P (alive) (%)</cell></row><row><cell>CDNOW</cell><cell>PGGG</cell><cell>40 4</cell><cell>38 9</cell><cell>0 5</cell><cell>10 3</cell><cell>0 6</cell><cell>11 5</cell><cell>0 86</cell><cell>1 04</cell><cell>1 29</cell><cell>26 2</cell><cell>24 1</cell><cell>44</cell></row><row><cell></cell><cell>PNBD</cell><cell></cell><cell></cell><cell>0 6</cell><cell>10 6</cell><cell>0 5</cell><cell>8 3</cell><cell></cell><cell></cell><cell></cell><cell>25 8</cell><cell>25 2</cell><cell>45</cell></row><row><cell>Apparel and accessories</cell><cell>PGGG</cell><cell>43 9</cell><cell>51 0</cell><cell>0 5</cell><cell>7 5</cell><cell>0 6</cell><cell>19 1</cell><cell>0 69</cell><cell>0 85</cell><cell>1 03</cell><cell>18 0</cell><cell>42 1</cell><cell>53</cell></row><row><cell></cell><cell>PNBD</cell><cell></cell><cell></cell><cell>0 6</cell><cell>7 4</cell><cell>0 6</cell><cell>15 0</cell><cell></cell><cell></cell><cell></cell><cell>16 1</cell><cell>32 6</cell><cell>47</cell></row><row><cell>Donations</cell><cell>PGGG</cell><cell>4 2</cell><cell>1 4</cell><cell>1 0</cell><cell>77 0</cell><cell>8 2</cell><cell>1,565</cell><cell>1 33</cell><cell>2 70</cell><cell>4 88</cell><cell>96 4</cell><cell>136 4</cell><cell>42</cell></row><row><cell></cell><cell>PNBD</cell><cell></cell><cell></cell><cell>0 6</cell><cell>77 4</cell><cell>2 0</cell><cell>1,432</cell><cell></cell><cell></cell><cell></cell><cell>158 3</cell><cell>628 7</cell><cell>81</cell></row><row><cell>Groceries</cell><cell>PGGG</cell><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 4</head><label>4</label><figDesc>Impact of Incorporating Regularity by Data Set Notes. PNBD, Pareto/NBD; PGGG, Pareto/GGG. Values in bold describe the relative lift in MAE for the Pareto/GGG against the Pareto/NBD.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>Lift</cell><cell></cell><cell></cell><cell>Mean absolute error</cell><cell></cell><cell>Holdout</cell></row><row><cell></cell><cell>k wheat</cell><cell>k q50</cell><cell>Relative (%)</cell><cell>Absolute</cell><cell>PGGG</cell><cell>PNBD</cell><cell>Heuristic</cell><cell>mean x  *</cell></row><row><cell>CDNOW</cell><cell>1 0</cell><cell>1 0</cell><cell>+2</cell><cell>+0 02</cell><cell>0 76</cell><cell>0 77</cell><cell>1 02</cell><cell>0 80</cell></row><row><cell>Apparel and accessories</cell><cell>0 6</cell><cell>0 8</cell><cell>−2</cell><cell>−0 01</cell><cell>0 44</cell><cell>0 43</cell><cell>0 56</cell><cell>0 38</cell></row><row><cell>Donations</cell><cell>2 2</cell><cell>2 7</cell><cell>+16</cell><cell>+0 06</cell><cell>0 29</cell><cell>0 35</cell><cell>0 34</cell><cell>0 28</cell></row><row><cell>Groceries</cell><cell>2 5</cell><cell>3 4</cell><cell>+8</cell><cell>+0 13</cell><cell>1 39</cell><cell>1 52</cell><cell>2 57</cell><cell>2 22</cell></row><row><cell>Dietary supplements</cell><cell>2 0</cell><cell>1 8</cell><cell>+5</cell><cell>+0 01</cell><cell>0 15</cell><cell>0 16</cell><cell>0 15</cell><cell>0 09</cell></row><row><cell>Office supply</cell><cell>1 8</cell><cell>2 1</cell><cell>+4</cell><cell>+0 01</cell><cell>0 28</cell><cell>0 30</cell><cell>0 30</cell><cell>0 32</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table B</head><label>B</label><figDesc></figDesc><table><row><cell>.1</cell><cell cols="5">Relative Lift in Customer-Level MAE for Holdout Period</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">N = 1,000 (%)</cell><cell></cell><cell></cell><cell cols="2">N = 4,000 (%)</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>r</cell><cell>0.25</cell><cell>0.75</cell><cell>0.25</cell><cell>0.75</cell><cell>0.25</cell><cell>0.75</cell><cell>0.25</cell><cell>0.75</cell></row><row><cell></cell><cell></cell><cell>s</cell><cell>\</cell><cell>5</cell><cell>5</cell><cell>15</cell><cell>15</cell><cell>5</cell><cell>5</cell><cell>15</cell><cell>15</cell><cell>Mean (%)</cell></row><row><cell cols="2">t = 1 6/y = 0 4</cell><cell>25</cell><cell>5</cell><cell>+8</cell><cell>+6</cell><cell>+5</cell><cell>+12</cell><cell>+8</cell><cell>+11</cell><cell>+4</cell><cell>+11</cell><cell>+8</cell></row><row><cell>mean(k) = 4</cell><cell></cell><cell>75</cell><cell>5</cell><cell>+11</cell><cell>+10</cell><cell>+11</cell><cell>+19</cell><cell>+11</cell><cell>+10</cell><cell>+22</cell><cell>+13</cell><cell>+14</cell></row><row><cell></cell><cell></cell><cell>25</cell><cell>15</cell><cell>+10</cell><cell>+10</cell><cell>+12</cell><cell>+12</cell><cell>+6</cell><cell>+8</cell><cell>+8</cell><cell>+10</cell><cell>+10</cell></row><row><cell></cell><cell></cell><cell>75</cell><cell>15</cell><cell>+16</cell><cell>+10</cell><cell>+20</cell><cell>+17</cell><cell>+11</cell><cell>+11</cell><cell>+12</cell><cell>+16</cell><cell>+14</cell></row><row><cell>t = 5/y = 2 5</cell><cell></cell><cell>25</cell><cell>5</cell><cell>+5</cell><cell>+5</cell><cell>+6</cell><cell>+9</cell><cell>+5</cell><cell>+6</cell><cell>+6</cell><cell>+8</cell><cell>+6</cell></row><row><cell>mean(k) = 2</cell><cell></cell><cell>75</cell><cell>5</cell><cell>+4</cell><cell>+4</cell><cell>+17</cell><cell>+12</cell><cell>+7</cell><cell>+7</cell><cell>+19</cell><cell>+10</cell><cell>+10</cell></row><row><cell></cell><cell></cell><cell>25</cell><cell>15</cell><cell>+4</cell><cell>+7</cell><cell>+5</cell><cell>+11</cell><cell>+4</cell><cell>+5</cell><cell>+7</cell><cell>+7</cell><cell>+6</cell></row><row><cell></cell><cell></cell><cell>75</cell><cell>15</cell><cell>+7</cell><cell>+4</cell><cell>+14</cell><cell>+11</cell><cell>+7</cell><cell>+6</cell><cell>+14</cell><cell>+9</cell><cell>+9</cell></row><row><cell>t = 6/y = 4</cell><cell></cell><cell>25</cell><cell>5</cell><cell>+3</cell><cell>+4</cell><cell>0</cell><cell>+3</cell><cell>+3</cell><cell>+2</cell><cell>+4</cell><cell>+2</cell><cell>+3</cell></row><row><cell>mean(k) = 1.5</cell><cell></cell><cell>75</cell><cell>5</cell><cell>+7</cell><cell>+5</cell><cell>+13</cell><cell>+7</cell><cell>+3</cell><cell>+3</cell><cell>+10</cell><cell>+5</cell><cell>+7</cell></row><row><cell></cell><cell></cell><cell>25</cell><cell>15</cell><cell>+4</cell><cell>+4</cell><cell>+4</cell><cell>+5</cell><cell>+2</cell><cell>+2</cell><cell>+3</cell><cell>+3</cell><cell>+3</cell></row><row><cell></cell><cell></cell><cell>75</cell><cell>15</cell><cell>+6</cell><cell>0</cell><cell>+7</cell><cell>+9</cell><cell>+5</cell><cell>+3</cell><cell>+10</cell><cell>+5</cell><cell>+5</cell></row><row><cell>t = 8/y = 8</cell><cell></cell><cell>25</cell><cell>5</cell><cell>−4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table B</head><label>B</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">Marketing Science 35(5), pp. 779-799, © 2016 INFORMS</cell></row><row><cell>.2</cell><cell cols="6">Absolute Lift in Customer-Level MAE for Holdout Period</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">N = 1,000</cell><cell></cell><cell></cell><cell cols="2">N = 4,000</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>r</cell><cell>0.25</cell><cell>0.75</cell><cell>0.25</cell><cell>0.75</cell><cell>0.25</cell><cell>0.75</cell><cell>0.25</cell><cell>0.75</cell></row><row><cell></cell><cell></cell><cell>s</cell><cell>\</cell><cell>5</cell><cell>5</cell><cell>15</cell><cell>15</cell><cell>5</cell><cell>5</cell><cell>15</cell><cell>15</cell><cell>Mean</cell></row><row><cell cols="2">t = 1 6/y = 0 4</cell><cell>0</cell><cell>5</cell><cell>+0 05</cell><cell>+0 09</cell><cell>+0 02</cell><cell>+0 11</cell><cell>+0 06</cell><cell>+0 18</cell><cell>+0 02</cell><cell>+0 10</cell><cell>+0 08</cell></row><row><cell>mean(k) = 4</cell><cell></cell><cell>0</cell><cell>5</cell><cell>+0 03</cell><cell>+0 06</cell><cell>+0 01</cell><cell>+0 06</cell><cell>+0 03</cell><cell>+0 07</cell><cell>+0 03</cell><cell>+0 04</cell><cell>+0 04</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>15</cell><cell>+0 08</cell><cell>+0 19</cell><cell>+0 05</cell><cell>+0 12</cell><cell>+0 05</cell><cell>+0 16</cell><cell>+0 04</cell><cell>+0 10</cell><cell>+0 10</cell></row><row><cell></cell><cell></cell><cell>0</cell><cell>15</cell><cell>+0 08</cell><cell>+0 13</cell><cell>+0 05</cell><cell>+0 11</cell><cell>+0 06</cell><cell>+0 14</cell><cell>+0 03</cell><cell>+0 10</cell><cell>+0 09</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table B</head><label>B</label><figDesc></figDesc><table><row><cell>.2</cell><cell>(Continued)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">N = 1,000</cell><cell></cell><cell></cell><cell cols="2">N = 4,000</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>r</cell><cell>0.25</cell><cell>0.75</cell><cell>0.25</cell><cell>0.75</cell><cell>0.25</cell><cell>0.75</cell><cell>0.25</cell><cell>0.75</cell><cell></cell></row><row><cell></cell><cell>s</cell><cell>\</cell><cell>5</cell><cell>5</cell><cell>15</cell><cell>15</cell><cell>5</cell><cell>5</cell><cell>15</cell><cell>15</cell><cell>Mean</cell></row><row><cell>t = 5/v = 2</cell><cell>0 25</cell><cell>5</cell><cell>+0 04</cell><cell>+0 08</cell><cell>+0 02</cell><cell>+0 08</cell><cell>+0 04</cell><cell>+0 10</cell><cell>+0 02</cell><cell>+0 08</cell><cell>+0 06</cell></row><row><cell>mean(k) = 2</cell><cell>0 75</cell><cell>5</cell><cell>+0 01</cell><cell>+0 02</cell><cell>+0 03</cell><cell>+0 04</cell><cell>+0</cell><cell>+0 05</cell><cell>+0 02</cell><cell>+0 03</cell><cell>+0 03</cell></row><row><cell></cell><cell>0 25</cell><cell>15</cell><cell>+0 03</cell><cell>+0 13</cell><cell>+0 02</cell><cell>+0 12</cell><cell>+0 04</cell><cell>+0 10</cell><cell>+0 03</cell><cell>+0 08</cell><cell>+0 07</cell></row><row><cell></cell><cell>0</cell><cell>15</cell><cell>+0 03</cell><cell>+0 05</cell><cell>+0 04</cell><cell>+0 07</cell><cell>+0 03</cell><cell>+0 07</cell><cell>+0 04</cell><cell>+0 06</cell><cell>+0 05</cell></row><row><cell>t = 6/y = 4</cell><cell>0 25</cell><cell>5</cell><cell>+0 02</cell><cell>+0 06</cell><cell>+0 00</cell><cell>+0 03</cell><cell>+0 02</cell><cell>+0 04</cell><cell>+0</cell><cell>+0 02</cell><cell>+0 03</cell></row><row><cell>mean(k) = 1.5</cell><cell>0 75</cell><cell>5</cell><cell>+0 02</cell><cell>+0 03</cell><cell>+0 02</cell><cell>+0 02</cell><cell>+0 01</cell><cell>+0 02</cell><cell>+0 01</cell><cell>+0 02</cell><cell>+0 02</cell></row><row><cell></cell><cell>0 25</cell><cell>15</cell><cell>+0 03</cell><cell>+0 08</cell><cell>+0 02</cell><cell>+0 05</cell><cell>+0 02</cell><cell>+0 05</cell><cell>+0 02</cell><cell>+0 04</cell><cell>+0 04</cell></row><row><cell></cell><cell>0 75</cell><cell>15</cell><cell>+0 03</cell><cell>+0 00</cell><cell>+0 02</cell><cell>+0 06</cell><cell>+0 03</cell><cell>+0 04</cell><cell>+0 03</cell><cell>+0 03</cell><cell>+0 03</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Specifically, the sum of k independent exponential variables follows an Erlang-k distribution, and its coefficient of variation decreases with increasing k: CV = 1/ √ k.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Other studies using hierarchical Bayesian approaches using MCMC sampling to estimate the Pareto/NBD model or variations thereof include the contributions by<ref type="bibr" target="#b47">Singh et al. (2009)</ref>, Conoor (2010), or, more recently,<ref type="bibr" target="#b36">Quintana and Marshall (2015)</ref> in a noncontractual setting, and the paper by<ref type="bibr" target="#b6">Borle et al. (2008)</ref> in a contractual context.4  Note that one of the four clumpiness measures introduced by<ref type="bibr" target="#b55">Zhang et al. (2013)</ref> relies on the same summary statistic, which again shows that the same underlying concept is being captured, just with opposite signs.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">The authors wish to express their gratitude to Sandeep Conoor, who provided them with a working Fortran implementation of his MCMC sampler for estimating the Pareto/NBD. The work by<ref type="bibr" target="#b9">Conoor (2010)</ref> proved to be very helpful for writing our own performance-tuned MCMC sampler in R.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">The MAE measure is frequently used for time-series data. In the context of customer-base analysis, see the recent contribution by<ref type="bibr" target="#b42">Schwartz et al. (2014)</ref> for a justification of choosing MAE as a model selection criterion.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7"><ref type="bibr" target="#b4">Batislam et al. (2007)</ref> use this approach by left filtering a grocery retail customer base with the requirement that it provides 11 months of initial inactivity.8  Note that the chosen unit of time is an arbitrary definition for continuous-time BTYD models. It is only reflected in the scale parameters of the purchase and dropout models, but does not impact the predictions themselves.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">Note the positive sign of the regression coefficient of purchase C in Table4reported by<ref type="bibr" target="#b56">Zhang et al. (2015)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Markov models, with two states, one of which is an absorbing, inactive state.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank the editor-in-chief, the associate editor, and the anonymous reviewers for their helpful suggestions and valuable guidance throughout the review process. This research also benefited from comments and input by Sandeep Conoor, Peter Fader, Nicolas Glady, Bruce Hardie, Daniel McCarthy, Udo Wagner, and the audience at the Marketing Science Conference 2014. The authors also thank Eric Bradlow and Yao Zhang for sharing their data sets.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>ITT q50 = 7 weeks q50 = 22 weeks multicategory firms such as the grocery retailer in the above example could greatly benefit from leveraging information on category-level regularities in their overall assessment of customer activities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A. Derivation of P(alive)</head><p>We provide the derivation of the probability of a customer still being alive at time T here <ref type="bibr">(Schmittlein et al. 1987, Appendix 1)</ref>.</p><p>Let denote the individual-level parameters k , let indicate the observed data t 1 t x T , and let T −t x refer to the event of no transaction occurring in t x T . Then,</p><p>The assumption of exponentially distributed lifetimes gives us P &gt; T = e − T (A2)</p><p>The likelihood functions f 1 and f 2 can be further split into independent components</p><p>• f 4 t x T −t x &gt; T and (A3)</p><p>Conditional on the time of the last transaction t x , the exact timing of the earlier transactions t 1 t x−1 is independent of the subsequent timing of the dropout. Therefore, f 3 = f 5 , and the according terms cancel out in Equation (A1).</p><p>Conditional on the dropout &gt; T , the timing of the last transaction t x and an observed waiting time of T − t x are independent events that can be derived separately. Because the sum of x independent and identically distributed variables t j ∼ Gamma k k is a gamma-distributed random variable with an updated shape parameter kx, it follows that</p><p>Similarly, f 6 can be expressed by integrating f 4 over t x &lt; ≤ T , such that is exponentially distributed</p><p>Putting it all together, we obtain</p><p>For the degenerate case of k = 1, this expression can be simplified to the Pareto/NBD result published by Schmittlein et al. ( <ref type="formula">1987</ref>)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix B. Further Details on Simulation Study</head><p>In total, 160 data sets based on a variety of parameter settings for N , r, , s, , t, and have been generated and used for assessing the predictive accuracy of the Pareto/GGG and Pareto/NBD models. For each setting, we ran four separate MCMC chains with 8,000 iterations each, then retained only every 200th iteration after an initial burn-in of 2,000 iterations.</p><p>To check for convergence, we used the Gelman diagnostic <ref type="bibr" target="#b21">(Gelman and Rubin 1992</ref>  </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Counting your customers one by one: A hierarchical Bayes extension to the Pareto/NBD model</title>
		<author>
			<persName><forename type="first">M</forename><surname>Abe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="541" to="553" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A dynamic model of purchase timing with application to direct marketing</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Leone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jen</forename><forename type="middle">L</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">94</biblScope>
			<biblScope unit="issue">446</biblScope>
			<biblScope unit="page" from="365" to="374" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The origin of bursts and heavy tails in human dynamics</title>
		<author>
			<persName><forename type="first">A-L</forename><surname>Barabasi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">435</biblScope>
			<biblScope unit="page" from="207" to="211" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Predictive analytics for readmission of patients with congestive heart failure</title>
		<author>
			<persName><forename type="first">I</forename><surname>Bardhan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Jh(c)</forename><surname>Oh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z(e)</forename><surname>Zheng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Kirksey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Systems Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="19" to="39" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Empirical validation and comparison of models for customer base analysis</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">P</forename><surname>Batislam</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Denizel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Filiztekin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Res. Marketing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="201" to="209" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Modeling purchasing behavior with sudden death: A flexible customer lifetime model</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">C</forename><surname>Bemmaor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Glady</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1012" to="1021" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Customer lifetime value measurement</title>
		<author>
			<persName><forename type="first">S</forename><surname>Borle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="100" to="112" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A consumer purchasing model with Erlang inter-purchase time</title>
		<author>
			<persName><forename type="first">C</forename><surname>Chatfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Goodhardt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">344</biblScope>
			<biblScope unit="page" from="828" to="835" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">A stochastic RFM model</title>
		<author>
			<persName><forename type="first">R</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Jiang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Interactive Marketing</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="2" to="12" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Customer-base analysis in noncontractual settings</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Conoor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<pubPlace>Evanston, IL</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Northwestern University</orgName>
		</respStmt>
	</monogr>
	<note>Unpublished doctoral thesis</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">An investigation of the assumptions of the NBD model as applied to purchasing at individual stores</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dunn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Reader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Wrigley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Statist</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="249" to="259" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">BTYD: Implementing buy &apos;til you die models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Dziurzynski</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Wadsworth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mccarthy</surname></persName>
		</author>
		<ptr target="http://CRAN.R-project.org/package=BTYD" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Rcpp: Seamless R and C++ integration</title>
		<author>
			<persName><forename type="first">D</forename><surname>Eddelbuettel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>François</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Statist. Software</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Customer Centricity: Focus on the Right Customers for Strategic Advantage</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>Wharton Executive Essentials, Philadelphia</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Forecasting repeat sales at CDNOW: A case study</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bgs</forename><surname>Hardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Interfaces</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="S94" to="S107" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>suppl</note>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Incorporating time-invariant covariates into the Pareto/NBD and BG/NBD models</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bgs</forename><surname>Hardie</surname></persName>
		</author>
		<ptr target="http://www.brucehardie.com/notes/019" />
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Probability models for customer-base analysis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bgs</forename><surname>Hardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Interactive Marketing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="69" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A dynamic changepoint model for new product sales forecasting</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bgs</forename><surname>Hardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chun-Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="50" to="65" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Counting your customers&quot; the easy way: An alternative to the Pareto/NBD model</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bgs</forename><surname>Hardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="275" to="284" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">RFM and CLV: Using ISO-value curves for customer base analysis</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bgs</forename><surname>Hardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="415" to="430" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Customer-base analysis in a discrete-time noncontractual setting</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bgs</forename><surname>Hardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Shang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1086" to="1108" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Inference from iterative simulation using multiple sequences</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statist. Sci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="457" to="472" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Stochastic models of interpurchase time with timedependent covariates</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="15" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Modeling customer lifetime value</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Hanssens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bgs</forename><surname>Hardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Ravishanker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sriram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Service Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="139" to="155" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">A probabilistic market model of purchase timing and brand selection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Herniter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="102" to="112" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Customer base analysis: The case for a central variant of the Betageometric/NBD model</title>
		<author>
			<persName><forename type="first">D</forename><surname>Hoppe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing ZFP-J. Res. Management</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="75" to="90" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">New perspectives on customer &quot;death&quot; using a generalization of the Pareto/NBD model</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jerath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Bgs</forename><surname>Hardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="866" to="880" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Customer Lifetime Value: The Path to Profitability</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
			<publisher>Now Publishers</publisher>
			<pubPlace>Hanover, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">The power of CLV: Managing customer lifetime value at IBM</title>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Venkatesan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bohling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Beckmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="585" to="599" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The MCMC approach for solving the Pareto/NBD model and possible extensions</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Ma</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Third Internat. Conf. Natural Comput</title>
				<meeting>Third Internat. Conf. Natural Comput<address><addrLine>Los Alamitos, CA</addrLine></address></meeting>
		<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2007" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="505" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Assessing the performance of direct marketing scoring models</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Malthouse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Interactive Marketing</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="49" to="62" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The results from the lifetime value and customer equity modeling competition</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Malthouse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Interactive Marketing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="272" to="275" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Can we predict customer lifetime value?</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">C</forename><surname>Malthouse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Blattberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Interactive Marketing</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="2" to="16" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Generalizing the NBD model for customer purchases: What are the implications and is it worth the effort?</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Schmittlein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Bus. Econom. Statist</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="159" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Slice sampling</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Neal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="705" to="741" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">A hidden Markov model of customer relationship dynamics</title>
		<author>
			<persName><forename type="first">O</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Lattin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="185" to="204" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A Bayesian non-parametric Pareto/NBD model: Individual and cluster analysis</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">A</forename><surname>Quintana</surname></persName>
			<affiliation>
				<orgName type="collaboration">R Core Team</orgName>
			</affiliation>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Marshall</surname></persName>
			<affiliation>
				<orgName type="collaboration">R Core Team</orgName>
			</affiliation>
		</author>
	</analytic>
	<monogr>
		<title level="m">R: A Language and Environment for Statistical Computing (R Foundation for Statistical Computing</title>
				<meeting><address><addrLine>Santiago, Chile; Vienna</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
		<respStmt>
			<orgName>Pontificia Universidad Católica de Chile</orgName>
		</respStmt>
	</monogr>
	<note>Working paper</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">On the profitability of long-life customers in a noncontractual setting: An empirical investigation and implications for marketing</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">J</forename><surname>Reinartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="17" to="35" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Bayesian statistics and marketing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="304" to="328" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Prediction of future random events with the condensed negative binomial distribution</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Schmittlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Morrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">382</biblScope>
			<biblScope unit="page" from="449" to="456" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Customer base analysis: An industrial purchase process application</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Schmittlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Peterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="41" to="67" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Counting your customers: Who are they and what will they do next?</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Schmittlein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Colombo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Model selection using database characteristics: Developing a classification tree for longitudinal incidence data</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="188" to="205" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Dynamic changepoints revisited: An evolving process model of new product sales</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Schweidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Res. Marketing</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="119" to="124" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Incorporating direct marketing activity into latent attrition models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Schweidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Knox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="471" to="487" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Portfolio dynamics for customers of a multiservice provider</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">A</forename><surname>Schweidel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="471" to="486" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The path to customer centricity</title>
		<author>
			<persName><forename type="first">D</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Parasuraman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Staelin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">S</forename><surname>Day</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Service Res</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="113" to="124" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A generalized framework for estimating customer lifetime value when customer lifetimes are not observed</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">S</forename><surname>Singh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Borle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Jain</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quant. Marketing Econom</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="181" to="205" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">The calculation of posterior distributions by data augmentation</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Tanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="issue">398</biblScope>
			<biblScope unit="page" from="528" to="540" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Customer equity and lifetime management (CELM) Finnair case study</title>
		<author>
			<persName><forename type="first">G</forename><surname>Tirenni</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Labbi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Berrospi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Elisseeff</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Bhose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Pauro</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Pöyhönen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="553" to="565" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Estimating purchase regularity with two interpurchase times</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Wheat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Morrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="87" to="93" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">GPU accelerated MCMC for modeling terrorist activity</title>
		<author>
			<persName><forename type="first">G</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Porter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Statist. Data Anal</title>
		<imprint>
			<biblScope unit="volume">71</biblScope>
			<biblScope unit="page" from="643" to="651" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A framework for customer relationship management</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Winer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">California Management Rev</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="89" to="105" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">A consumer purchasing model with learning and departure behaviour</title>
		<author>
			<persName><forename type="first">C</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H-L</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Oper. Res. Soc</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="583" to="591" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Instant customer base analysis: Managerial heuristics often &quot;get it right</title>
		<author>
			<persName><forename type="first">M</forename><surname>Wübben</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Von Wangenheim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="82" to="93" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">New measures of clumpiness for incidence data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Small</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Appl. Statist</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2533" to="2548" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Predicting customer value using clumpiness: From RFM to RFMC</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Small</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="195" to="208" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
