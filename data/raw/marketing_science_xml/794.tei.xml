<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Investigating Endogeneity Bias in Marketing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2006-01-31">January 31, 2006</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Qing</forename><surname>Liu</surname></persName>
							<email>qliu@bus.wisc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Marketing</orgName>
								<orgName type="institution">University of Wisconsin-Madison</orgName>
								<address>
									<postCode>53706</postCode>
									<settlement>Madison</settlement>
									<region>Wisconsin</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Thomas</forename><surname>Otter</surname></persName>
							<email>otter@marketing.uni-frankfurt.de</email>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Business and Economics</orgName>
								<orgName type="institution">Johann Wolfgang Goethe University</orgName>
								<address>
									<settlement>Frankfurt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Greg</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
							<email>allenby.1@osu.edu</email>
							<affiliation key="aff2">
								<orgName type="department">Fisher College of Business</orgName>
								<orgName type="institution">Ohio State University</orgName>
								<address>
									<addrLine>2100 Neil Avenue</addrLine>
									<postCode>43210</postCode>
									<settlement>Columbus</settlement>
									<region>Ohio</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Investigating Endogeneity Bias in Marketing</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 e 1526-548X 07 2605 0642</idno>
						<imprint>
							<date type="published" when="2006-01-31">January 31, 2006</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.1060.0256</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>likelihood principle</term>
					<term>adaptive design</term>
					<term>Bayes theorem</term>
					<term>directed acyclic graphs History: This paper was received</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>T he use of adaptive designs in conjoint analysis has been shown to lead to an endogeneity bias in partworth estimates using sampling experiments. In this paper, we re-examine the endogeneity issue in light of the likelihood principle. The likelihood principle asserts that all relevant information in the data about model parameters is contained in the likelihood function. We show that, once the data are collected, adhering to the likelihood principle leads to analysis where endogeneity becomes ignorable for estimation. The likelihood principle is implicit to Bayesian analysis, and discussion is offered for detecting and dealing with endogeneity bias in marketing.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The recent paper by <ref type="bibr" target="#b5">Hauser and Toubia (2005)</ref>, "The Impact of Utility Balance and Endogeneity in Conjoint Analysis," raises an interesting set of issues related to a wide class of marketing models. In their paper, they present evidence that adaptive designs, where answers to early questions in a conjoint interview are used to select later questions, induce biases in the estimated part-worths. While their paper focuses on analysis associated with Sawtooth Software's popular ACA (Adaptive Conjoint Analysis) software, the implications of their analysis reach beyond conjoint analysis, sequential analysis, and utility balance, touching on important philosophical issues at the core of statistical inference.</p><p>In this paper, we reexamine the endogeneity bias identified by <ref type="bibr">Hauser and Toubia (HT)</ref> and explain its presence using traditional econometric methods. Bias is an aspect of statistical inference that relies on the notion of a sampling experiment, where hypothetical data sets are used to characterize the performance of an estimator. We argue that sampling experiments are useful to study properties of estimators and other procedures when real data are not available. However, when data are available, analysis should proceed according to the likelihood principle as originally proposed by <ref type="bibr" target="#b3">Fisher (1922)</ref>.</p><p>The likelihood principle asserts that the likelihood contains all the information about model parameters (e.g., conjoint part-worths) in the data. We show that, according to the likelihood principle, the endogeneity created by adaptive questioning is not of concern for estimation, i.e., does not alter the likelihood function of the observed data. Our discussion of the likelihood principle raises a number of philosophical issues at the core of statistical inference that highlight the difference between classical (i.e., frequentist) and Bayesian philosophies.</p><p>Our analysis of endogeneity bias in conjoint models uses HT as a springboard for discussion and is not meant to criticize their findings. In fact, our analysis covers some of the same ground as their analysis, restating their findings in terms more familiar to the statistics literature. Our examples are sometimes similar to those examined by HT and sometimes depart from theirs to provide additional insight and analysis. We applaud their interest in analyzing the issue of endogeneity created by adaptive designs because of its importance to both practitioners and academic researchers.</p><p>The remainder of the paper is organized as follows. We begin with a review of endogeneity bias in regression models caused by adaptive designs, restating many of the points made by HT. We then introduce the likelihood principle and examine its implication for data analysis. Our analysis shows that, conditional on the dependent variable y , the way the design is adaptively created is not informative Liu, Otter, and Allenby: Investigating Endogeneity Bias in Marketing Marketing Science 26(5), pp. 642-650, © 2007 INFORMS 643 about model parameters. The mechanism employed to pick the design points, and the resulting endogeneity, are "ignorable" for the purpose of likelihood-based inference <ref type="bibr">(Gelman et al. 2004, p. 203;</ref><ref type="bibr" target="#b10">Rubin 1976</ref>). 1 Thus, we believe the potential harm from endogeneity created by adaptive designs should be considered when selecting among experimental procedures (e.g., adaptive versus fixed designs), not in estimation. Discussion is provided about the importance of bias in the evaluation of procedures, and tools are offered for detecting when endogeneity created by adaptive questioning and other forms of sample selection will impact conditional inference-i.e., when it alters the likelihood function. Concluding comments are then offered, in which we advocate a Bayesian orientation to conducting analysis in marketing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Endogeneity Bias</head><p>Endogeneity bias arises in regression analysis y = X + when the regressors, X, are not independent of the errors, . When a specific realization of the regressors, x t , is selected based on the outcome of previous choices, y &lt;t , as is the case for sequential design data, then x t is determined from within the system of study and is not independently determined. In this case, the traditional ordinary least-squares estimator is biased because the vector space of the regressors is dependent on the error realizations. Regression coefficient bias is defined as the difference between the true value of the parameter and the expected value of the estimate over hypothetical sets of data (D):</p><formula xml:id="formula_0">E D = E D X X −1 X y = E D X X −1 X X + = + E D X X −1 X (1)</formula><p>The presence of endogenous responses biases the regression estimate because the second term in Equation (1) is not equal to zero. To see this, consider a simple example where there is just one regressor without an intercept (y = x + ), and just two observations. The OLS estimator is given by</p><formula xml:id="formula_1">= x 1 y 1 + x 2 y 2 x 2 1 + x 2 2 (2)</formula><p>Then, if x 2 is determined by the value of y 1 , i.e., x 2 = f y 1 = f x 1 + 1 , we have</p><formula xml:id="formula_2">E D = + E D x 1 1 x 2 1 + x 2 2 + x 2 2 x 2 1 + x 2 2</formula><p>(3) <ref type="bibr">1</ref> We would like to thank the associate editor for pointing out that the result can be viewed as an extension/application of <ref type="bibr" target="#b10">Rubin's (1976)</ref> framework for classifying missing data mechanisms.</p><p>The expectation of the first term in the brackets is not equal to zero because y 1 , and hence 1 , is used to determine x 2 . Because 1 and x 2 are not independently determined, E f x 2 1 = E f x 2 E 1 = 0, specifically</p><formula xml:id="formula_3">E D x 1 1 x 2 1 + x 2 2 = E D x 1 x 2 1 + x 2 2 E D 1 = 0 (4)</formula><p>Thus, for regression estimates to be unbiased it must be the case that all errors are independent of all the regressors (X). The lack of independence between regressors and errors occurs in many models. Models with a lagged dependent variable (e.g., Koyck lag models, autoregressive models) violate the assumption that the regressors are independent of the error terms. In these models, the lagged regressors are themselves functions of the lagged error terms, and the assumption of independent regressors and errors is not valid. Endogeneity bias also occurs in models with sequential design, in which design points are selected based on previous responses. While the specific algorithm used to select design points (e.g., utility balance in ACA) may exacerbate the extent of endogeneity bias documented by frequentist analyses of small-sample situations with relatively large error variance, the bias is present whenever the vector of residuals, , is not independent of all the regressors.</p><p>Figure <ref type="figure">1</ref> illustrates the biasing effect of endogeneity, using a simple problem similar to that studied by HT. The analysis involves 1,000 replicates of samples, each consisting of 1,000 homogeneous respondents. Each respondent supplies three observations, where the regressor for the third observation is determined as a function of the first two observations. The model is y t = 1 x 1t + 2 x 2t + t , t = 1 2 3 and t ∼ Normal 0 25 . The value of x for the first observation is x 1 = x 11 x 21 = 1 0 , the value of x for the second observation is x 2 = 0 1 , and</p><formula xml:id="formula_4">x 3 =    1 −1 if y 1 y 2 &gt; 0 1 1 if y 1 y 2 ≤ 0 (5)</formula><p>The design rule in Equation ( <ref type="formula">5</ref>) is meant to mimic the "utility balance" criterion used by the ACA software. The true values of the regression coefficients are 1 = 1 and 2 = 2. The figure shows that the OLS estimates exhibit positive bias, with E 1 = 1 198 and E 2 = 2 406. Each triangle character in the figure represents the mean of individual-level OLS estimates computed from one sample of j = 1 1 000 homogeneous respondents (i.e., 1000 j=1 j /1 000, where j is estimated with three observations y jt , x jt , t = 1 2 3).</p><p>Econometricians recognize the bias present in regression models when functions of lagged dependent variables are included in the model specification, and as a result, the finite sampling properties of these models are generally unknown (see <ref type="bibr">Judge et al. 1988, p. 575)</ref>. This has led to the use of asymptotics to characterize the sampling properties of estimators in such situations. In particular, the probability limit, or "plim" is used to describe the behavior of estimators as the sample size increases. The probability limit is a formal expression for the consistency of an estimator. An estimator is said to be consistent if the probability limit of obtaining an estimate arbitrarily close to the true parameter value equals one in infinite samples; i.e., the probability that an estimate from a sample of size T falls within the interval − + goes to one as the sample size increases, no matter how small : lim</p><formula xml:id="formula_5">T → P T − &lt; = 1 (6)</formula><p>A result known as Slutsky's theorem can be used to show that the OLS estimator is asymptotically consistent as defined above. Slutsky's theorem states that if g is a continuous function and z T is some random variable that depends on T , then</p><formula xml:id="formula_6">plim g z T = g plim z T (7)</formula><p>Thus, from Equation ( <ref type="formula">1</ref>) we can derive the plim of the regression estimate as the sample size increases:</p><formula xml:id="formula_7">plim = + plim X X −1 X = + plim X X /T −1 plim X /T = (8)</formula><p>where the last equality holds if plim X X /T −1 converges to a finite-valued matrix (i.e., −1 XX , and plim X /T converges to zero. The latter condition holds as long as E D x t t = 0 for all t. Consistency only requires independence between regressor values x t and their corresponding error term t , and not the entire vector of errors. Thus, the requirements for asymptotic consistency are easier to obtain than the requirements of unbiasedness.</p><p>To illustrate the consistency of the OLS estimator in the simulation study, we obtained pooled OLS estimates for each of the replicated data sets, i.e., estimated regression coefficients using all 3,000 observations (1,000 respondents each supplying three observations) contained in each data set. The pooled estimates are plotted in Figure <ref type="figure">1</ref> as black diamonds. Clearly, the pooled estimates are not affected by the bias; their mean is = 1 005 2 000 which is close to the true value of = 1 2 . While the simulation study of HT does exhibit an endogeneity bias in small samples, the estimates are asymptotically consistent. Thus, endogenously determined covariates need not lead to inconsistent inferences, as is often assumed. As we show below, inconsistency arises from model misspecification, i.e., employing the wrong likelihood function for the data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Likelihood Principle</head><p>The study by HT touches on an important philosophical point about the role of sampling experiments in statistical analysis and managerial decision making. Bias is obviously a concern in conjoint analysis, where part-worth estimates are used to set prices and guide product formulation. Moreover, managers are often confronted with choosing the best way to collect and analyze data. Bayesians and frequentists disagree, however, on how to quantify knowledge given data and on how to study properties of statistical procedures and characterize their performance.</p><p>A principle of statistical inference first introduced by <ref type="bibr" target="#b3">Fisher (1922)</ref>, and adhered to in Bayesian analysis, is that the likelihood function contains all the information in the data about the model parameters. The likelihood principle implies that if two likelihoods for a parameter are proportional, then we should make the same inference for regardless of which likelihood we use. This principle has a number of significant and far-reaching implications. <ref type="bibr" target="#b1">Berger and Wolpert (1984)</ref> provide an excellent review of this topic and provide many interesting examples. When considering implications of the likelihood principle, it is important to remember that the likelihood is always meant to represent the true data-generating mechanism, whose parameters have substantive meaning that guide decision making. Moreover, statistical inference involves the quantification of knowledge about these parameters.</p><p>An example of the application of the likelihood principle involves sequential sampling. Suppose we observe the number of successes Z in n independent Bernoulli trials with success probability . The likelihood for the data is</p><formula xml:id="formula_8">1 Z = z = n z z 1 − n−z (9)</formula><p>Now, suppose that instead of holding fixed the number of trials, we were to decide to sample until we obtained z successes and then observed the realization of N , the number of trials to the zth success. In this scenario, N has a negative binomial distribution, so the model is</p><formula xml:id="formula_9">2 N = n = n − 1 z − 1 z 1 − n−z (<label>10</label></formula><formula xml:id="formula_10">)</formula><p>and we have that, conditional on any pair z n ,</p><formula xml:id="formula_11">1 Z = z n ∝ 2 N = n z .</formula><p>Despite the fact that the sampling scheme and the dependent variable are different, the likelihood principle states that we should ignore this and make the same inference about in both cases. A Bayesian analysis of these data would be equivalent because the likelihood principle implies that the stopping rule associated with a data collection is irrelevant. In contrast, a frequentist analysis of these data would incorporate the effects of the stopping rule in computing standard errors of point estimates and constructing confidence intervals. Frequentist confidence intervals are based on the idea of multiple realizations of the data, across which the number of trials n will vary in Equation ( <ref type="formula" target="#formula_9">10</ref>) but not in Equation ( <ref type="formula">9</ref>).</p><p>Analysis in marketing contains many instances where adherence to the likelihood principle will lead to different inference. Analysis in direct marketing, for example, involves initial testing of offer formats using many lists, and subsequent mailings of the best offers using lists with the highest response rates. Ignoring the uncertainty present in the initial test phase does not matter as long as the goal of the analysis is to simply identify the best list for a specific offer. However, if the goal is more general, involving learning about offer formats and list characteristics associated with high yields using both sets of data, then whether one conditions on the observed data or not will matter. By considering multiple hypothetical realizations of the initial test data, frequentist inference must admit the possibility of alternative best offers mailed out in the second round. Frequentist confidence intervals are misrepresented unless alternative hypothetical second-round offers are included in the analysis. In contrast, the Bayesian approach is more straightforward because it adheres to the likelihood principle and simply conditions on the observed data in both samples.</p><p>Another example involves the use of screening questions by Internet merchants, where answers are used to determine offers that are likely to be of value to the customer. Frequentist analysis of the observed purchases of the offers needs to account for possibly different answers to the screening questions, leading to offers different from those that were observed, to properly quantify the information in the data. In contrast, adherence to the likelihood principle implies that one should simply condition on the observed responses to the screening questions in the analysis. However, as discussed in greater detail later, simply conditioning on the particular offerings presented, and ignoring the responses to the screening questions, results in a misspecified likelihood. Consider again the stylized example above, similar to the problem studied by HT. The likelihood function should acknowledge that x 3 , the third design point, is determined from within the system of study and is therefore endogenous:</p><formula xml:id="formula_12">y 1 y 2 x 3 y 3 2 = 1 y 1 y 2 2 × 2 x 3 y 1 y 2 2 × 3 y 3 x 3 2 (11)</formula><p>where the conditioning variables x 1 and x 2 are not written to improve readability. The first factor on the right side of Equation ( <ref type="formula">11</ref>) corresponds to the first two observations where the design points x 1 and x 2 are determined beforehand. The likelihood for these observations corresponds to that found in a standard regression analysis:</p><formula xml:id="formula_13">1 y 1 y 2 2 = 1 2 2 exp −1 2 2 y 1 − x 1 2 + y 2 − x 2 2 (12)</formula><p>Similarly, the third factor, which conditions on the realized design point x 3 , is the same as found in standard analysis:</p><formula xml:id="formula_14">3 y 3 x 3 2 = 1 √ 2 2 exp −1 2 2 y 3 −x 3 2 (13)</formula><p>The effect of endogeneity is therefore isolated in the second factor, 2 . The likelihood for x 3 is determined by Equation ( <ref type="formula">5</ref>), where a positive product of y 1 and y 2 leads to the selection of x 3 = 1 −1 , and a negative product yields x 3 = 1 1 . Given y 1 and y 2 , the selection of x 3 is deterministic, or</p><formula xml:id="formula_15">2 x 3 y 1 y 2 2 = 2 x 3 y 1 y 2 = 1 (14)</formula><p>Thus, while the likelihood for design point x 3 is unconditionally dependent on the model parameters and 2 , the likelihood is independent of these parameters given y 1 and y 2 . 2 This makes intuitive sense Marketing Science 26(5), pp. 642-650, © 2007 INFORMS because we learn about and 2 from the respondent, not the mechanism used to select the design point. Following the likelihood principle implies that, given the data, selection mechanisms such as ACA's utility balance are ignorable; i.e., the likelihood of model parameters is unchanged if 2 is included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heterogeneity and Selection Bias</head><p>In §6 of their paper, HT suggest that the presence of heterogeneity might compound the biasing effects of utility balance by also biasing the hyperparameters of the model that describe the mean part-worths (i.e., the mean of the random-effects distribution). <ref type="bibr">3</ref> The likelihood principle again implies that, conditional on all the data, adaptive utility balance, or any other criterion to adaptively choose design points, is irrelevant to the analysis. In the presence of consumer heterogeneity, a respondent's contribution to the likelihood is</p><formula xml:id="formula_16">l i = D i i (<label>15</label></formula><formula xml:id="formula_17">)</formula><p>and, by conditional independence, the sample likelihood is</p><formula xml:id="formula_18">l i N i=1 = i D i i (16)</formula><p>Equation ( <ref type="formula">14</ref>) demonstrates that adaptive questioning does not change the likelihood for any of the "i" respondents. The total sample likelihood is therefore not affected. In the setting of a Bayesian hierarchical model with heterogeneity, a random-effects distribution for i is introduced along with a prior distribution for the hyperparameters, :</p><formula xml:id="formula_19">i N i=1 D i N i=1 ∝ i D i i × i × (17)</formula><p>This corresponds to a data-generating process where the i vectors are modeled as draws from the randomeffects distribution i , and the data is generated from the likelihood D i i . Because adaptive questioning does not change the likelihood, it is not relevant to the analysis, whether heterogeneity is present or absent. Moreover, posterior estimates of the hyperparameters will converge to the true data-generating values as the sample size increases, even if each consumer provides a limited amount of information and the individual-level parameters, i , experience shrinkage toward the hyperparameter . This result is due to exchangeability of consumers implied by the random-effects distribution-adaptive questioning does not affect the exchangeability of the response vectors obtained from each consumer.</p><p>As a result, estimates of hyperparameters are based on relatively large samples where data are pooled across respondents and will be close to their true values. Estimates of individual-level parameters, i , are biased because their posterior distributions are based on an individual's own data D i , all other data D j as shared through the mixing distribution i , and the prior distribution . The mixing distribution and prior distribution have a nonnegligible effect on the individual-level estimates. We comment further on sampling properties of Bayesian estimators below.</p><p>We investigate the impact of endogenous covariates in a hierarchical Bayes model by adding heterogeneity to our earlier example. That is, instead of 1,000 identical respondents, we assume that the part-worths for the respondents follow a random-effects distribution: <ref type="formula">18</ref>)</p><formula xml:id="formula_20">i ∼ Normal = 2 1 V = 1 0 0 1 i = 1 1 000 (</formula><p>where i indexes the respondents. Diffuse prior distributions, centered on the true values, are assumed for the hyperparameters: V = IW 0 V 0 with 0 = 10 and V 0 = 10I (20)</p><p>Figure <ref type="figure">2</ref> compares Bayesian analysis of for exogenous versus endogenous covariates. Time-series plots of the draws of for these two sets of data show little difference. The posterior mean for the plot with exogenous x 3 is = 2 00 0 96 , with a posterior standard deviation of (0.12, 0.11). For x 3 endogenous, the posterior mean is = 2 01 0 96 , with a posterior standard deviation of (0.12, 0.12). These results agree with the implications of the likelihood principleanalysis that conditions on all of the observed data is not affected by endogenously determined covariates. Analysis with fewer respondents (e.g., 100) yields similar results, although the precision of the parameter estimates is decreased. Managerial decisions based on the analysis of the data are also unaffected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Discussion</head><p>Our analysis shows that the presence of endogenously determined covariates leads to small-sample bias in conjoint part-worths, which diminishes as the sample size increases. The likelihood principle, on the other hand, asserts that one should ignore the fact that the covariates are endogenously determined in estimation. We note that, in general, likelihoodbased estimates are biased whenever model parameters are nonlinearly related to the observed data (e.g., variance estimates, logit coefficient estimates), including endogenously determined covariates. In this section we discuss the use of bias for evaluating the performance of estimators, and offer a method for determining when endogenously generated variables will create problems in analysis and decision making-i.e., are not ignorable. Prior to data collection, managers might be concerned about the manner in which the data will be collected and the anticipated method used to analyze these data. While data collection (i.e., question selection, experimental design) and data analysis (i.e., parameter estimation) are related tasks, and decisions regarding them are often made jointly in light of commercially available software and user knowledge, they are not necessarily related. As discussed by HT and others, utility balance can be pursued for reasons that are difficult to quantify within a statistical model. Forcing respondents to select from among alternatives with nearly equal value might avoid scaling problems that occur when one alternative dominates the rest and might encourage respondents to more carefully evaluate the alternatives. These aspects are not reflected in the standard linear models used in traditional conjoint analysis and therefore do not enter into traditional analysis. Moreover, once the data are collected, one of a number of methods of estimation can be used in analysis (e.g., Bayesian, method of moments, maximum likelihood). It is therefore useful to think of data collection and data analysis separately.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sampling Properties</head><p>Bias is one measure of the performance of an estimator, and while managers should be concerned about bias prior to data collection, bias should not be used as a litmus test for selecting an estimator or, as such, a scheme to generate design points adaptively. Bias is an aspect of statistical risk, defined as the expected loss from incorrectly estimating a respondent's true part-worths ( ). For squared-error loss we have</p><formula xml:id="formula_21">Risk = E D − 2 = E D − E D + E D − 2 = E D − E D 2 + E D − 2 + 2 − E D E D − = Var + Bias 2 (21)</formula><p>where the cross-product (third) term is zero because the expectation of its first factor in parentheses is zero. Bias can be traded off against variance to obtain lower risk, as it is in ridge regression, and is not usually pursued as a goal in and of itself. Many biased estimators have excellent sampling-theory properties.</p><p>Marketing Science 26(5), pp. 642-650, © 2007 INFORMS Bayesian estimators (˜ ), for example, minimize expected loss with respect to the posterior distribution (see <ref type="bibr">Rossi et al. 2005, pp. 17-18)</ref>:</p><formula xml:id="formula_22">= arg min E D L = L D d (<label>22</label></formula><formula xml:id="formula_23">)</formula><p>where L is the loss (e.g., squared-error loss) associated with using to estimate . Sampling properties of˜ can be studied across multiple realizations of the data:</p><formula xml:id="formula_24">E D E D L ˜ = L ˜ D D d dD = L ˜ D dD d = E E D L ˜ = E Risk˜ (23)</formula><p>The last equality shows that Bayes estimators have the property of minimizing expected risk, where the expectation is taken with respect to the prior distribution. Moreover, while Bayesian estimators are biased by the presence of the prior distribution, , they often outperform other estimators by successfully trading off increased bias for lower variance. Theoretically, bias (i.e., E D ˜ − ) is of diminished relevance to Bayesians because its computation requires knowledge of the unobserved true value of .</p><p>An interesting issue is why one would want to engage in an adaptive design in the first place. After all, orthogonal designs are known to be optimal for linear models, and the use of procedures like utility balance will likely lead to a nonorthogonal design. As discussed by <ref type="bibr" target="#b2">Chaloner and Verdinelli (1995)</ref>, orthogonal designs are optimal only within the context of fixed designs in the absence of prior knowledgei.e., designs where the questions are all selected prior to the collection of any data. Orthogonality is not necessarily optimal in the space of designs, D, that include design points that are selected sequentially. As pointed out by HT, utility balance as a criterion for adaptive design is unlikely to increase efficiency within the confines of the linear model. To the extent that the linear model is at best a local approximation, however, utility balance could help the design stay in the range of values that can be sensibly fitted by the local approximation. This is an empirical issue, the investigation of which is beyond the scope of this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Determining When Endogeneity Will Matter in Estimation</head><p>Directed acyclic graphs (DAGs) are useful tools for determining when conditioning on endogenously determined covariates results in a misspecified likelihood function. An introduction to DAGs for Bayesian analysis can be found in <ref type="bibr">Rossi et al. (2005, p. 67)</ref>. The DAG for the utility-balance example discussed earlier is</p><formula xml:id="formula_25">x 1 , x 2 y 1 , y 2 x 3 y 3 β, σ 2</formula><p>The graph is read from left to right, with the model parameters ( <ref type="formula">2</ref>and two design points x 1 x 2 used to generate responses y 1 and y 2 . The third design point, x 3 , is determined from the responses as per Equation ( <ref type="formula">5</ref>), and used to generate the third response, y 3 . The likelihood comprises all arrows connected to the model parameters ( 2 . Here we see that the third design point, x 3 , is determined entirely from y 1 and y 2 , and is not directly connected to the parameters. This implies that the mechanism for selecting x 3 can be ignored-i.e., is not relevant for inferences about ( 2 -so long as y 1 and y 2 are included.</p><p>The direct-marketing example discussed earlier involved a pilot study (x 1 ) from which initial results (y 1 are obtained and used to design a subsequent study (x 2 whose results (y 2 are used to draw inferences about model parameters ( ). The DAG for this example is similar to the utility-balance example:</p><formula xml:id="formula_26">x 1 θ y 1 x 2 y 2</formula><p>The arrow from y 1 to x 2 in the DAG above can represent a simple calculation as in Equation ( <ref type="formula">5</ref>) above, or more complicated calculations involving the data, including the derivation and use of the posterior distribution y 1 x 1 ∝ y 1 x 1 for choosing x 2 . The posterior conditions on x 1 y 1 and thus insulates x 2 from -i.e., if x 2 is chosen based on y 1 x 1 , x 2 cannot convey information about that is not already contained in y 1 x 1 . If, however, y 1 (e.g., self-explicated data, results of the pilot study, answers to screening questions) are not included in the analysis, or prior knowledge in the form of y 1 x 1 used to select x 2 is discarded, the DAG becomes </p><formula xml:id="formula_27">x 1 θ x 2 y 2 Liu,</formula><formula xml:id="formula_28">x 2 y 2 = y 1 y 2 x 2 x 1 d y 1 = 1 x 2 x 1 × 2 y 2 x 2 (24)</formula><p>The likelihood contribution of x 2 is no longer ignorable. Nonignorable likelihoods occur whenever the data selection/creation mechanism for x is directly related to a parameter ( ) that is also related to the dependent variable y. In addition to the examples described above, marketing researchers often struggle with the issue of sample-selection bias, and various corrections have been proposed (e.g., <ref type="bibr" target="#b6">Heckman 1976</ref>) to obtain consistent estimates. All the corrections are based on the presence of a common parameter (e.g., a correlation coefficient) related to variables x and y. Equation ( <ref type="formula">24</ref>) indicates that, in principle, one should deal with an endogenously selected sample by including the likelihood for x as part of the model specification-i.e., to use the correct likelihood for all the data x y (for marketing examples, see <ref type="bibr">Manchanda et al. 2004, Zanutto and</ref><ref type="bibr" target="#b12">Bradlow 2006)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effects of Omitting Self-Explicated Data in Conjoint Analysis</head><p>Consider what would happen if enough data were initially collected to make precise inferences about a respondent's part-worths. The utility balance algorithm would then generate candidate design points with responses close to zero for all choices. The likelihood 3 in Equation ( <ref type="formula">11</ref>) would then have multiple modes-one at zero, one at the true parameter value, and at all parameters values that are proportional to the true values. The mode at zero corresponds to one solution to fitting responses that are all equal to zero. The mode at the true parameter value is present as in any analysis, and the other values proportional to the true value will also yield zero responses for utility balance. Without access to the earlier data, or the original designer's knowledge to be used as a prior, inferences about the part-worths would not be identified by the data anywhere along the true parameter vector. The likelihood for stimulus selection (e.g., 1 in Equation ( <ref type="formula">24</ref>)) needs to be included in these analyses to avoid model misspecification. If past observations (in the sense that they are no longer available) were used to learn about model parameters, and design points were picked based on the acquired knowledge, then any analysis that proceeds without incorporating this fact is incomplete and the likelihood function misspecified. Expanding on our earlier example, which mimics ACA, consider a model that has three regressors instead of two: y t = 1 x 1t + 2 x 2t + 3 x 3t + t and t ∼ Normal 0 1 . Assume we have three self-explicated observations y SE i = I i + i and that we do not ask respondents questions about the attribute corresponding to the response y t with the smallest (absolute) value. That is, the response data will be uninformative about one of the coefficients. ACA uses a similar procedure to avoiding asking questions about attributes that are unimportant to the respondent. Assume further that each respondent then provides answers to six pairwise comparisons corresponding to product profiles of the remaining attributes and that the distribution of heterogeneity is multivariate normal with mean = 6 3 1 and covariance matrix V = I 4 . Finally, we assume that the self-explicated data are not used in the analysis.</p><p>The resulting posterior means of based on 1,000 respondents are equal to (6 23 3 59 1 67), with posterior standard deviations equal to (0 06 0 07 0 14). Thus, the relative importances of the attributes are distorted. Moreover, the presence of nonzero heterogeneity covariance can be shown to increase the frequency of rank-order reversals of individual-level estimates by two to three times. It should be noted that the magnitude of these inconsistencies are functions of the unobserved parameters. Thus, there is no way to correct for the inconsistencies without knowing the desired parameter values beforehand. When the self-explicated data are included in the analysis (i.e., by including the likelihood for these data), posterior means are equal to (6.05, 2.93, 0.88) with posterior standard deviation equal to (0 06 0 07 0 07). These results indicate that violating the likelihood principle by ignoring the self-explicated data can easily result in economic harm to managers using conjoint analysis to inform product policy. Thus, ACA's "pairs only" option, which discards the self-explicated data when making inferences, should be avoided whenever the design in the pairs section is based on self-explicated data.</p><p>ACA offers several options for analysis. Empirically, "pairs only with constraints," where the constraints are derived from the self-explicated data, seems to perform best <ref type="bibr">(Sawtooth Software 2003)</ref>. This method, and the analysis option "pairs plus selfexplicated" (ACA/Hierarchical Bayes v2.0), where the self-explicated data and the pairs data are analyzed jointly, can be shown to render ACA's adaptive design mechanism ignorable. For "pairs only with constraints," the self-explicated data are assumed to provide ordinal-level information without error that leads to ordinal constraints in the analysis of the pairs data (see <ref type="bibr" target="#b0">Allenby et al. 1995)</ref>. The "pairs plus selfexplicated" analysis assumes that the data are generated from the same underlying model. Both analysis options condition on the self-explicated data, and the manner in which ACA adaptively generates questions is ignorable. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Concluding Comments</head><p>The likelihood principle is implicit to the Bayesian approach to statistics, where the posterior distribution is derived from the prior distribution and the likelihood. Bayesian analysis conditions on the data to draw inferences about unobservable parameters in the analysis. In a conjoint analysis, it provides an answer to the question "Given the data at hand, what do I know about the part-worths?"</p><p>Sampling experiments are useful for understanding statistical properties such as bias when data have not yet been collected. They are not generally useful, however, once data are available for analysis. We demonstrate that the endogeneity identified by HT is irrelevant for analysis once data have been collected. A manager at a user firm who wants to make inferences about part-worths based on a specific data set should not worry about endogeneity created by adaptive questioning so long as the mechanism of choosing design points is ignorable. This will be the case if inference proceeds conditional on the data used to pick design points. Prior to data collection, however, we believe that adaptive design procedures should be evaluated based on risk.</p><p>Whether one should condition on the data and adhere to the likelihood principle, as in Bayesian analysis, or conduct sampling experiments, as in a frequentist analysis, is at the philosophical core of statistical inference. The Bayes-frequentist debate is sometimes dismissed as irrelevant because one can obtain about the same answer in some special cases (e.g., a normal likelihood in combination with diffuse priors). The issue of endogeneity bias raised by HT provides a counterexample to this view, where philosophical principles of inference play an important role in conducting analysis. We believe that analysis should condition on the data that is, strictly speaking, only possible if the mode of inference is Bayesian.</p><p>The advantage of taking on this orientation is that it greatly simplifies analysis while providing a coherent framework for inference.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure2MCMC Draws for Exogenous and Endogenous Covariates 1,000 Respondents</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Otter, and Allenby: Investigating Endogeneity Bias in Marketing</figDesc><table><row><cell>Marketing Science 26(5), pp. 642-650, © 2007 INFORMS</cell><cell>649</cell></row><row><cell>and the likelihood for the endogenously determined</cell><cell></cell></row><row><cell>covariate (x 2 ) becomes a function of :</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Adding a random component to the selection mechanism implying a nondegenerate 2 does not change the basic argument. Conditional on previous data, x 3 is again independent of and 2 .</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The selection bias results of HT (2005) may be based on analysis that excluded the self-explicated data. We comment further on that procedure, which ACA refers to as "pairs only," below.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank John Hauser, Rich Johnson, and Olivier Toubia for helpful comments.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Incorporating prior knowledge into the analysis of conjoint studies</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Ginter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="152" to="162" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">O</forename><surname>Berger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Wolpert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Instititute of Mathematical Statistics</title>
		<imprint>
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Bayesian experimental design: A review</title>
		<author>
			<persName><forename type="first">K</forename><surname>Chaloner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Verdinelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statist. Sci</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="273" to="304" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the mathematical foundations of theoretical statistics</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Fisher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philos. Trans. Roy. Soc. London, Ser. A</title>
		<imprint>
			<biblScope unit="volume">222</biblScope>
			<biblScope unit="page" from="309" to="368" />
			<date type="published" when="1922" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Bayesian Data Analysis</title>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Stern</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2004" />
			<publisher>Chapman &amp; Hall/CRC</publisher>
			<pubPlace>Boca Raton, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The impact of utility balance and endogeneity in conjoint analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="498" to="507" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The common structure of statistical models of truncation, sample selection and limited dependent variables, and a simple estimator for such models</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Heckman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Econom. Soc. Measurement</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="475" to="492" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Introduction to the Theory and Practice of Econometrics</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">G</forename><surname>Judge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">E</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Lutkepohl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T.-C</forename><surname>Lee</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>2nd ed</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Response modeling with nonrandom marketing-mix variables</title>
		<author>
			<persName><forename type="first">P</forename><surname>Manchanda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Chintagunta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="page" from="467" to="478" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Bayesian Statistics and Marketing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mcculloch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Inference and missing data</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Rubin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="581" to="592" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">ACA/Hierarchical Bayes v2</title>
		<ptr target="http://www.sawtoothsoftware.com/technicaldownloads.shtml#acahbtech" />
	</analytic>
	<monogr>
		<title level="m">Sawtooth Software</title>
				<imprint>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note type="report_type">Technical paper</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Data pruning in consumer choice</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">L</forename><surname>Zanutto</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quant. Marketing Econom</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="267" to="287" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
