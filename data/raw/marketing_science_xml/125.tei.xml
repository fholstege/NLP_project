<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Accounting for Discrepancies Between Online and Offline Product Evaluations</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2019-01-30">January 30, 2019</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daria</forename><surname>Dzyabura</surname></persName>
							<email>ddzyabur@stern.nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Stern School of Business</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>10012</postCode>
									<settlement>New York</settlement>
									<region>New York</region>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">New Economic School</orgName>
								<address>
									<postCode>121353</postCode>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Srikanth</forename><surname>Jagabathula</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Stern School of Business</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>10012</postCode>
									<settlement>New York</settlement>
									<region>New York</region>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department">Harvard Business School</orgName>
								<orgName type="institution">Harvard University</orgName>
								<address>
									<postCode>02163</postCode>
									<settlement>Boston</settlement>
									<region>Massachusetts</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Eitan</forename><surname>Muller</surname></persName>
							<email>emuller@stern.nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Stern School of Business</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>10012</postCode>
									<settlement>New York</settlement>
									<region>New York</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">Arison School of Business</orgName>
								<address>
									<addrLine>Interdisciplinary Center (IDC) Herzliya</addrLine>
									<postCode>46101</postCode>
									<settlement>Herzliya</settlement>
									<country key="IL">Israel</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Accounting for Discrepancies Between Online and Offline Product Evaluations</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
						<imprint>
							<date type="published" when="2019-01-30">January 30, 2019</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.2018.1124</idno>
					<note type="submission">Received: March 3, 2016 Revised: November 17, 2016; March 31, 2017; October 10, 2017 Accepted: January 21, 2018</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:29+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>conjoint analysis</term>
					<term>omnichannel</term>
					<term>machine learning</term>
					<term>Bayesian</term>
					<term>consumer choice</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Despite the growth of online retail, the majority of products are still sold offline, and the "touch-and-feel" aspect of physically examining a product before purchase remains important to many consumers. In this paper, we demonstrate that large discrepancies can exist between how consumers evaluate products when examining them "live" versus based on online descriptions, even for a relatively familiar product (messenger bags) and for utilitarian features. Therefore, the use of online evaluations in market research may result in inaccurate predictions and potentially suboptimal decisions by the firm. Because eliciting preferences by conducting large-scale offline market research is costly, we propose fusing data from a large online study with data from a smaller set of participants who complete both an online and an offline study. We demonstrate our approach using conjoint studies on two sets of participants. The group who completed both online and offline studies allows us to calibrate the relationship between online and offline partworths. To obtain reliable parameter estimates, we propose two statistical methods: a hierarchical Bayesian approach and a k-nearest-neighbors approach. We demonstrate that the proposed approach achieves better out-of-sample predictive performance on individual choices (up to 25% improvement), as well as aggregate market shares (up to 33% improvement).</p><p>History: K. Sudhir served as the editor-in-chief and Scott Neslin served as associate editor for this article.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Despite the rapid growth of online retail, the "touchand-feel" experience of physically evaluating a product remains a significant driver of consumer purchase decisions. Physical evaluation drives purchase decisions in offline stores, which remain the predominant sales channel for many industries. In the first two quarters of 2017, online sales accounted for 8.7% of the $2.5 trillion in total U.S. retail sales during this period (U.S. Census <ref type="bibr" target="#b37">Bureau 2017)</ref>. A recent survey of 19K consumers by <ref type="bibr" target="#b30">PricewaterhouseCoopers (2015)</ref> revealed that 73% of U.S. consumers report having browsed products online, then purchased them in store. In the same survey, 61% of respondents cited being able to see and try out the item as the reason for buying in store (other reasons include delivery fees and having the item immediately).</p><p>With the prevalence of offline shopping, firms need to measure and predict consumer decision making in the offline channel. Yet conjoint analysis, widely used by firms to conduct market research, design products, and predict market shares, is nearly always conducted online, asking participants to rate or choose between product descriptions via computer. The implicit assumption is that the attribute partworths carry over from online behavior to offline behavior. However, consumers may weight attributes differently when evaluating a physical product than when reading a list of attributes on the computer. These two formats differ greatly in how they convey information to the consumer. Consumers might obtain more information about certain product attributes by evaluating the physical prototype; they most commonly cite this reason for choosing to shop in physical stores. Additionally, an online description with the features presented in list form may render certain attributes more or less salient than when examining the product "live." Product features that are more salient tend to catch our attention and influence our decisions more so than less salient features. Behavioral factors are also at play that may affect how consumers process the information and integrate it into a decision in these two task formats.</p><p>In a conjoint experiment, we show that large systematic differences can exist between the weight that respondents give to product attributes online versus offline, even for utilitarian features such as a file divider and strap pad when evaluating messenger bags. We find that when the online task is performed first, the difference is larger than when the offline task is performed first, suggesting that much of the discrepancy is due to consumers' inability to obtain all necessary information about the product online and learning more offline.</p><p>This discrepancy poses a problem, as conducting conjoint studies offline is significantly costlier than doing so online. We obtained price quotes from market research firms for a commercial offline conjoint study (to avoid peer effects, only one participant should be in the room examining products at a time). The costs involve payment to participants, the hourly rate of an experimenter (including salary, benefits, and overhead), and recruiting costs. The total comes to $100-$150 per participant, whereas online participants can be obtained for $2-$3 per participant. The firm therefore has access to very costly "accurate" data and much cheaper data that are noisy but correlate with the accurate data. Given the large difference in costs, assuming budget constraint, our proposed solution is to split the budget between the two types of data.</p><p>The rest of this paper is organized as follows: The next section reviews relevant conjoint literature on using physical prototypes and on data fusion. Section 3 then describes Study 1, in which participants complete online and offline conjoint tasks in randomized order. Section 4 demonstrates superior predictive ability of offline choices when a separate group of online respondents' choices are fused with the data from Study 1. Section 5 reports an asymptotic variance analysis that calculates, for various cost-per-participant ratios, the precision with which partworths can be estimated for various sizes of online and offline populations. We conclude with implications and limitations of our work.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Work</head><p>We contribute to the large body of literature on preference elicitation using conjoint analysis, first introduced to marketing by <ref type="bibr" target="#b16">Green and Rao (1971)</ref>. Since then, researchers have improved on the basic methodology of asking respondents to rate, rank, or choose from among sets of products, with the goal of increasing the accuracy of the estimates of relative importance, or "partworths," of various product attributes. <ref type="bibr" target="#b26">Netzer et al. (2008)</ref> provided a comprehensive review of recent developments in preference-measuring techniques, including conjoint analysis. They view preference measurement as comprising three components:</p><p>(1) the problem the study seeks to address, (2) the design of the task and the data collection approach, and (3) the specification and estimation of the model.</p><p>Under this framework, this paper specifically addresses the latter two steps (data collection and estimation). Our proposed methodology for improving estimates of offline partworths consists of two components: (1) a data collection method that measures both online and offline partworths for a set of respondents and (2) a statistical data fusion method that combines the online and offline data to estimate offline parameters. Each of these components builds on existing work, which we review here. We focus our review on two types of papers: those that propose to collect preference data using physical prototypes and those that propose data fusion techniques to combine conjoint data with other data.</p><p>Past research has demonstrated that using physical prototypes as part of the data collection process is feasible in a number of categories and helps improve the validity of the preference elicitation. <ref type="bibr" target="#b34">Srinivasan et al. (1997)</ref> advocated for the use of "customer-ready" prototypes rather than having consumers react to hypothetical product concepts and demonstrated a discrepancy between evaluating descriptions and prototypes in the categories of citrus juicers, bicycle lighting systems, and travel mugs. Our task format is most similar to that of <ref type="bibr" target="#b25">Luo et al. (2008)</ref>, who asked respondents to rate prototypes on the likelihood of purchase and used these ratings to infer attribute partworths, as part of a systematic approach to calibrating subjective product characteristics. More recently, a study by <ref type="bibr" target="#b33">She and MacDonald (2013)</ref> exposed respondents to physical prototypes of toasters that either contained environmentally friendly features or did not. They then measured attitude and choice in a consider-then-choose task. The manipulation of exposing respondents to the "trigger feature" did not induce respondents to either consider or purchase sustainable products more frequently. The key distinction between our work and the above body of literature is that we asked individuals to complete an online task in addition to evaluating physical prototypes offline.</p><p>The second step of our approach was to combine the online and offline data from the small set of respondents with online data of a larger set of respondents. Past research has developed methods for combining (or "fusing") data from a conjoint study with another data source, such as aggregate market shares observed in the real market <ref type="bibr" target="#b3">(Ben-Akiva et al. 1994</ref><ref type="bibr" target="#b35">, Swait and Andrews 2003</ref><ref type="bibr" target="#b27">, Orme and Johnson 2006</ref><ref type="bibr" target="#b14">, Feit et al. 2010</ref>). To combine preference data from two sources, most methods assume that the means of the partworths are similar in both data sets (e.g., <ref type="bibr" target="#b35">Swait and Andrews 2003)</ref>. Then parameters are estimated by combining the data sets using various statistical methods, such as incorporating market share data by introducing a constraint that requires parameter estimates to result in prespecified market shares <ref type="bibr" target="#b15">(Gilbride et al. 2008)</ref>, or using the market shares as the prior in a Bayesian approach <ref type="bibr" target="#b10">(Dzyabura and Hauser 2011)</ref>. The approach proposed by <ref type="bibr" target="#b14">Feit et al. (2010)</ref> provides more flexibility by linking preferences to consumer demographics, which are <ref type="bibr">Muller: Online vs. Offline Product Evaluations Marketing Science, 2019, vol. 38, no. 1, pp. 88-106, © 2019 INFORMS</ref> observed in both revealed (purchase) data and conjoint data. The demographic data allow for the population mean to differ between the two data sets.</p><p>All of the existing methods require the same individual to maintain the same individual parameter values across the two data sets. A key distinction of our work is that, depending on the order in which the respondent rated the products, the same individual may elicit differing resultant partworths in the online and offline data sets. We are able to merge the data sets by collecting both types of data from a set of consumers, which allows us to calibrate the mapping from online to offline preferences. Other work, such as that of <ref type="bibr" target="#b6">Brownstone et al. (2000)</ref> and <ref type="bibr" target="#b5">Bhat and Castelar (2002)</ref>, has combined stated and revealed preference data from a panel of consumers, when all the respondents are observed in both data sets. Our approach allows offline data to be collected for only a subset of individuals, as collecting offline data are significantly costlier per respondent.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Online/Offline Discrepancy</head><p>Our first goal is to establish whether a significant discrepancy exists between the weight that consumers place on various product attributes when evaluating online versus offline. <ref type="bibr">1</ref> To that end, we had a set of participants complete two conjoint tasks-one online and one offline-in randomized order. We found statistically significant differences between online and offline partworths both within and across subjects. The discrepancy is smaller when the offline task is done first than when the online task is done first.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Study 1 Design</head><p>For our studies, we used Timbuk2 messenger bags as the focus product. This product is a good example of our application because (1) these bags are often sold offline (as well as online), and (2) they are a familiar category, yet are infrequently purchased, such that we expected that many participants would not be familiar with some of the attributes and would therefore not have well-formed preferences. In addition, they are fully customizable through the firm's website, which allowed us to purchase bags for the offline study with the aim of creating an efficient experimental design. Timbuk2's website offers a full customization option that includes a number of product features. We selected a subset of attributes that we expected to be relevant to the target population and for which some uncertainty was likely to exist on the part of consumers and respondents. To make the study manageable, we reduced the number of levels of some of the features. We thus have the following six attributes for the study:</p><p>• Exterior design (four options): black, blue, reflective, colorful</p><p>• Size (two options): small (10 × 19 × 14 in), large (12 × 22 × 15 in)</p><p>• Price (four levels): $120, $140, $160, $180 • Strap pad (two options): yes, no • Water bottle pocket (two options): yes, no • Interior compartments (three options): empty bucket with no dividers, divider for files, padded laptop compartment</p><p>We treat price as a continuous variable in the estimation and have a total of 13 discrete attribute levels for the rest of the attributes. We recruited respondents through a university subject pool and paid them $7 for completing both tasks, which together took 25 minutes on average. To ensure incentive compatibility and promote honest responses, the experimenter told participants that they would be entered in a raffle for a free messenger bag. Were they to win, their prize would be a bag configured to their preferences, which the researchers would infer from the responses they provided in the study. This chance of winning a bag provided an incentive to participants to take the task seriously and respond truthfully with respect to their preferences <ref type="bibr" target="#b8">(Ding 2007</ref><ref type="bibr" target="#b17">, Hauser et al. 2010</ref>. We followed the instructions used by <ref type="bibr" target="#b9">Ding et al. (2011)</ref> and told participants that, were they to win, they would receive a messenger bag plus cash, a combined value of $180. The cash component eliminates incentive for participants to provide higher ratings for more expensive items in order to win a more valuable prize.</p><p>Each participant was asked to complete an online conjoint task and an offline conjoint task. We used two conditions: subjects either completed the online task first followed by the offline task (condition 1), or vice versa (condition 2). We next describe the details of both tasks.</p><p>Conjoint Task. We used a ratings-based task in which respondents rated each bag on a five-point scale (definitely not buy, probably not buy, may or may not buy, probably buy, and definitely buy). Using the D-optimal study design criterion <ref type="bibr">(Kuhfeld et al. 1994, Huber and</ref><ref type="bibr" target="#b20">Zwerina 1996)</ref>, we selected a 20-product design that has a D-efficiency of 0.97. The reason a ratings-based task is preferable for offline conjoint is to keep the cost of the study reasonable. The cost of offline conjoint studies is affected not only by respondent time but also by the number of physical prototypes that need to be created, which is not a factor in online conjoint. In our setting, conducting a choice-based conjoint (CBC) offline would require 75 distinct physical prototypes 2 (with each bag costing about $150), instead of the 20 we required for the ratings-based task design. Moreover, the task would require the researcher and the respondent to move between 20 displays of four prototypes each, potentially making the task tedious and the collected data prone to error. We use the ratings-based format in the online task as well, in the interest of keeping the tasks as similar as possible regarding all aspects other than Dzyabura, Jagabathula, and Muller: Online vs. Offline Product Evaluations online/offline. Because CBC is the more prevalent format, and because choices arguably have higher external validity, we demonstrate in Section 4 how results obtained from our data can be fused with an online CBC data set to make predictions about participants' offline choices.</p><p>Online Task. The online task was conducted using Sawtooth software. The first screens walked the participants through the feature descriptions one by one. Next, they were shown a practice rating question and were informed that it was for practice and that their response to it would be discarded. The screens that followed presented a single product configuration, along with the five-point scale, and one additional question that was used for another study. Participants could go back to previous screens if they wished but could not skip a question. Figure <ref type="figure" target="#fig_1">1</ref> shows a sample screenshot of the online task. The online portion took 10 minutes to complete on average.</p><p>Offline Task. To ensure that participants could not see the bags during the online study, we conducted the offline task in a room separate from the computer laboratory in which the online task was conducted. This task was done individually, one respondent at a time in the room, to avoid a contagion effect. The bags were laid out on a conference table, each with a card next to it displaying a corresponding number (indexing the item), and the bags were arranged in order from 1 through 20. The prices were displayed on stickers on Timbuk2 price tags attached to each bag. The experimenter first walked the respondents through all the features, showing each one on a sample bag. Figure <ref type="figure" target="#fig_0">2</ref> shows the conference room display of the offline task. The offline portion took 15 minutes to complete on average.</p><p>We next describe the results of the study and demonstrate the discrepancy between partworths participants use when evaluating products online and offline.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Comparison of Online and Offline Partworths</head><p>We begin with the online-first condition, which consisted of 122 participants. We assume a standard linearin-attributes utility function. The categorical attributes are dummy coded, using one level of each category as a baseline; price is captured as a linear attribute. To capture consumer heterogeneity, we fit a linear mixed effects (LME) model to the ratings data (abstracting away from any scale-usage heterogeneity):</p><formula xml:id="formula_0">u ijt β i0t + K k 1 β ikt x jk + ijt , β ikt µ kt + δ ikt .</formula><p>(1)</p><p>In Equation (1), u ijt is the rating by participant i of product j for task t ∈ {on, off}, with t on denoting the online task and t off denoting the offline task; β ikt is the partworth that participant i assigns to feature k during task t; and β i0t is the intercept. Product j is represented by its (K) attribute levels x jk . The random component ijt is assumed to follow a normal distribution, ijt~1 (0, σ 2 t ); the vector δ i [δ i1 , . . .δ i,K ] follows a normal distribution with mean 0 and covariance matrix Σ t that is diagonal.    As we can see from Table <ref type="table" target="#tab_1">1</ref>, the magnitudes of the online and offline partworth differences are large for many attributes. The sign of the partworth of the size attribute, for example, even flips: participants prefer the large size bag online and the small size bag offline. The strap pad and water bottle pocket attributes carry much less weight offline than they do online.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Statistical Tests to Establish Discrepancy</head><p>To formally compare the two sets of partworths, we use a nested-model likelihood-ratio test (LRT) to perform both within-and across-subject tests.</p><p>Within-Subject Test. We first test whether the online and offline partworths differ at the individual level. To do so, we estimate two models on the pooled online and offline data: one in which the online and offline parameters are constrained to be equal and the other in which they are unconstrained. Specifically, the restricted model assumes that β i,on β i,off for all participants i and fits the following model to the pooled online and offline data, whereas the unrestricted model allows the participants to have differing partworths for each task:</p><formula xml:id="formula_1">Restricted: u ijt β i0 + K k 1 β ik x jk + ijt , t ∈ {on, off}. (2)</formula><p>The unrestricted model allows the participants to have differing partworths for each task:</p><formula xml:id="formula_2">Unrestricted: u ijt β i0t + K k 1 β ikt x jk + ijt , t ∈ {on, off}<label>(3)</label></formula><p>but assumes that participant i samples the partworth vectors according to</p><formula xml:id="formula_3">β i,on β i,off ~1 µ on µ off , Σ , Σ on Σ on,off Σ off,on Σ off ,<label>(4)</label></formula><p>where Σ on , Σ off , and Σ on,off are diagonal. The estimates of the variance-covariance matrix Σ are reported in Appendix A. We constrain the covariance to estimate only the covariance between the online and offline partworths between the same attribute level (e.g., blue online and blue offline). We use the LRT to test the null hypothesis 3 β i,on β i,off for all participants i. The log likelihoods of the restricted and unrestricted models are −6,969 and −6,691, respectively. There are 29 additional degrees of freedom in the unconstrained model, including 10 additional fixed-effects coefficients and 19 additional covariance parameters. We are able to reject the null hypothesis because the LRT is significant ( p &lt; 10 −98 ).</p><p>Across-Subjects Test. One concern with the above within-subjects setup is that it may have led to a demand effect: if participants guessed that the researchers were looking for a difference between online and offline ratings, they may have felt compelled to change their decision rule in the offline task. To rule out this possibility, we used data from participants in condition 2 (N = 40) who completed the offline task first. Comparing this group's offline ratings to the online ratings of the online-first group provides an across-subjects comparison of online and offline partworths, both of which came first for the respective group of participants. We test for significance again using the LRT. Because this study has an across-subjects design, we constrain only the fixed effects (µ k ) to be equal. In other words, we test the null hypothesis µ on µ off . The constrained and unconstrained models' log likelihoods are −4,677 and −4,524, respectively, and the LRT again results in a significant difference, p 5 • 10 −48 , allowing us to reject the null hypothesis. This finding suggests that when comparing the first task done by participants, unpolluted by any prior tasks, participants doing the online task use differing partworths than those doing the offline task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Sources of Online-vs.-Offline Discrepancy</head><p>We have shown within and across subjects that a large, statistically significant discrepancy exists between partworths in online and offline task formats. Although the main focus of our paper is on the discrepancy's consequences, we first discuss a possible theoretical framework that could explain the observed discrepancy. We do note, however, that our conjoint studies are not designed to isolate the underlying causes of the onlineversus-offline discrepancy, and as such, our theoretical framework provides only one possible explanation. Nevertheless, it demonstrates that the observed discrepancy is consistent with previous findings in the behavioral literature. We explore two mechanisms that have been studied in the consumer behavior literature that may be the source of this discrepancy: (1) information obtained from examining the products physically and</p><p>(2) inherent differences in attribute salience across the online versus offline formats.</p><p>Offline Information Gain. The first phenomenon that may be the cause of the discrepancy is the valuable information that consumers obtain about products by visually and physically examining them <ref type="bibr" target="#b28">(Peck and Childers 2003)</ref>. Learning through touch and feel occurs not only for inherently experiential attributes, such as color, size, and texture of the product, but also for utilitarian features. For instance, in the messenger bag study, examining physical products gives consumers information about just how padded the laptop compartment is, how much room it takes up in the bag, how easily accessible the water bottle pocket is, and so on.</p><p>Inherent Attribute Salience Difference. Aside from additional information gained by physically examining products, the online and physical presentations also impart information to participants in differing formats, which may lead to behavioral biases. In the online channel, the attributes are presented in list form, whereas in the offline channel, the user sees the product as a whole. The attribute list representation may render certain attributes more or less salient to the user <ref type="bibr" target="#b19">(Higgins 1996)</ref>. For example, attributes that are physically smaller, such as the water bottle pocket and the strap pad, are easy for the participant to miss when examining the bag physically, whereas the color and size of the bag are very noticeable. The phenomenon of consumers' choices being influenced by the format in which the information is presented to them is consistent with the Bettman et al. (1998) preference construction theory. Note that the attribute salience effect is inherent to each channel and does not persist as the consumer moves from one channel to another. In this regard, the attribute salience effect differs from information gain, as the information obtained in the offline channel persists as the consumer moves to the online channel.</p><p>To assess how our theoretical framework explains the observed discrepancies, we further analyze the partworths in the two conditions to better understand the source of the discrepancy. These analyses are summarized in Figures <ref type="figure" target="#fig_2">3 and 4</ref>. Rather than testing behavioral theories, our goal is simply to demonstrate that the discrepancy between online and offline choice rules is consistent with that in previous work. First, we note that in the online-first condition (condition 1), both offline information gain and attribute salience influence the discrepancy between online and offline tasks for the same group of participants (edge 1), whereas in offline-first condition (condition 2), only attribute salience contributes to the discrepancy (edge 3). This is because in condition 2, any information gained from physically examining the products is obtained prior to completing the online task, and as mentioned above, the information obtained persists as the participant moves from the offline to the online task. The differences in the attribute salience between the channels exists in this condition as well because it is inherent to the format in which information was presented to the consumer.</p><p>We find statistically significant differences in both cases (p &lt; 10 −98 in condition 1 and p = 10 −6 in condition 2). In the offline-first condition, the magnitude of the difference between the partworths is much smaller than in the online-first condition. The online and offline partworths for the offline-first condition are presented in Table <ref type="table" target="#tab_3">2</ref> (with standard errors in parentheses).</p><p>Compared with Table <ref type="table" target="#tab_1">1</ref>, we can see that for some attributes, very little discrepancy remains: for example, the size attribute is now weighted consistently in both conditions, consistent with our theory that the discrepancy we observed in the online-first condition was due to the participants being underinformed about the attribute based on the online description only. Other attributes, such as the water bottle pocket and strap pad, are weighted much higher online than they are offline, in both the online-first and offline-first conditions, suggesting the presence of channel-specific attribute salience effect. Our findings also suggest that  exposing participants to physical prototypes prior to completing an online conjoint task <ref type="bibr" target="#b13">(Feinberg et al. 2012</ref>) produces partworth estimates that are closer to offline partworths yet still leaves some discrepancypossibly because of how the information is presentedsuch as the relative salience of the attributes online versus offline.</p><p>We find additional evidence for information gain by comparing the two online tasks (edge 4). The online task in condition 2, which participants completed after the offline task, resulted in statistically significantly more differing (p = 10 −4 ) partworths than did the online task in condition 1, which participants completed first. The restricted and unrestricted models' log likelihoods are −4,482 and −4,449, respectively. This difference is consistent with participants having obtained information by examining bags physically and then applying this additional information to online product evaluation. Finally, we note that the online task did not appear to influence offline behavior, as we do not find statistically significant differences between the offline tasks between the two conditions (edge 4). The log likelihood of the restricted model is −4,732, and that of the unrestricted model is −4,712. Note that because edge 4 compares two offline tasks, there is no difference in attribute salience, nor is there additional offline information gain. The fact that we did not find statistically significant differences is consistent with our framework.</p><p>Discussion. We have shown that a discrepancy exists both within and across subjects. The discrepancy is reduced when the offline task is conducted first, suggesting that a large portion of the discrepancy is due to consumers being uninformed about some product attributes. Thus, if a firm conducts conjoint analysis online for a product that will be sold offline, the predictions it makes from the resulting partworths estimates are likely to be biased because of the online-versus-offline discrepancy. This estimate bias is a major issue if the aim is to make predictions about purchases made in the offline environment. Note that the information gain aspect of the discrepancy may be reduced by better informing consumers about the features-for example, through more vivid descriptions or images.</p><p>The discrepancy between online and offline partworths has important consequences for a firm's decisions. For instance, <ref type="bibr" target="#b11">Dzyabura and Jagabathula (2018)</ref> showed that if a firm sells products both online and offline, selecting the optimal product assortment requires knowledge of both online and offline partworths. Even when selling offline only, firms base both aggregatelevel predictions, such as market shares, and individual predictions, such as segmentation or targeting decisions, on results of online preference elicitation.</p><p>In these cases, ignoring the discrepancy can result in significant prediction errors. For instance, in the onlinefirst condition, using the model estimated on participants' online ratings to predict their offline ratings results in an average root mean square error (RMSE) of 1.56 (recall that ratings are on a five-point scale). For comparison, the within-sample RMSE of using the offline ratings to predict the same ratings is 0.51. Therefore, it is important that firms correct the estimation bias to improve the accuracy of their decision making.</p><p>We next address the issue of how the estimate bias can be corrected by supplementing an online conjoint study with a sample of respondents who complete both online and offline tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Improving Predictions of Offline Behavior</head><p>A straightforward solution to dealing with the systematic differences between consumers' online and offline preferences is to conduct offline conjoint studies rather than online studies featuring descriptions or images of products. In fact, past research advocates the use of physical prototypes to quantify the impact of subjective characteristics on consumers' purchase decisions <ref type="bibr" target="#b34">(Srinivasan et al. 1997</ref><ref type="bibr" target="#b25">, Luo et al. 2008</ref>. But a large sample of respondents is necessary to obtain reliable parameter estimates, and conducting large-scale offline conjoint studies is logistically challenging and costly.</p><p>Offline studies require the respondent to physically arrive at a location in order to participate, as opposed to the online studies, which can reach a large population of respondents on the web. This need for participants to be physically present increases the marginal cost of the study per respondent, rendering offline studies practically infeasible for all but a "small" number of respondents. We propose a hybrid solution for improving the accuracy of offline preference estimates by supplementing a large online study with a small set of respondents who complete both an online and an offline task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Correction Techniques to Predict Individual-</head><p>Level Offline Partworths from Online Data We now focus on the setting where our objective is to predict individual-level offline partworths. Concretely, we assume that we have asked a set I off of respondents to complete an online conjoint task followed by an offline conjoint task and another set I on of respondents to complete only an online conjoint task. Instead of using the online partworth estimates for all the individuals in I off ∪ I on , or using only the offline estimates for the individuals in I off , we predict the offline partworths for the individuals in I on and use all offline partworth estimates for our decisions. To predict the offline partworth estimates of the individuals in I on , we propose two techniques: a Bayesian technique that we term Bayesian intertask conditional likelihood correction (Bayes ICL correction) and a k-nearest-neighbor (k-NN) technique. Both techniques rely on the observations of individuals in I off , for whom we observe matched online and offline responses, to estimate the relationship between online and offline partworths. From this relationship, we predict the offline partworths using the online data from the individuals in I on . The Bayesian ICL technique takes as input the raw observations of the individuals in I off and I on , and it produces as output the predicted offline partworths for individuals in I on . The Bayesian technique relies on standard distributional assumptions. The k-NN technique is a machine-learning technique that makes no global distributional assumptions but approximates the distribution locally. It takes as input the estimated partworth vectors [β i,on , β i,off ] for all individuals i ∈ I off and β i,on i ∈ I on ; then it outputs the predicted offline partworths for the individuals in I on . The inputs for the k-NN technique can be obtained using any method. For the purposes of our empirical study, we use the estimates obtained from the Bayesian ICL method; see Section 4.2.</p><p>To test both methods on a holdout data set, in addition to the results we obtained from Study 1, we conducted Study 2 with a group of 67 respondents who completed both an online and an offline task. We designed the study to mimic what a firm might do in practice. As in the first study, we asked each respondent to complete an online task, followed by an offline task. We use a choice task in this validation study, as that is the prevalent form of conjoint used in industry, and consumer choice data are more similar to what a firm would want to predict. The online portion was a traditional CBC task, consisting of 20 choice sets of four products each, 4 conducted using Sawtooth. We then presented the respondents with five choice sets of four products each in the offline environment.</p><p>The respondents' choices in the offline environment are the target variable we predict. We demonstrate that both the HB and k-NN corrections outperform the benchmark method of simply using the same respondents' online choice data to make predictions about their offline choices.</p><p>We now describe the two correction techniques we propose.</p><p>Bayesian ICL Correction. For this correction, we consider the following hierarchical Bayesian (HB) model to describe the observations. We begin with the unrestricted linear model described in Equations ( <ref type="formula" target="#formula_2">3</ref>) and (4) in Section 3. A key component of the model is its flexibility that allows the same consumer to assign differing partworths to the same feature when evaluating a product description online versus a physical product offline. To allow for this within-consumer discrepancy, the model associates the respondent's valuation of a given feature with two partworths, β ikt , t ∈ {on, off}, where β ik,on is the utility partworths that respondent i applies to feature k online, and β ik,off is the utility partworth that he or she applies offline. That is, partworths vary by respondent, product feature, and task format (on for online and off for offline). The specification of the utility model in Equation ( <ref type="formula">1</ref>) then becomes</p><formula xml:id="formula_4">u ijt β i0t + K k 1 β ikt x jk + ijt , t ∈ {on, off}. (<label>5</label></formula><formula xml:id="formula_5">)</formula><p>To accommodate a choice framework, we assume that the error terms ijt~i ndependent and identically distributed extreme value, instead of being normally distributed as in the linear model. We also let c t 1, . . .C t i index the choice tasks completed by respondent i in task format t ∈ {on, off}, X i,c t be the matrix containing sets of product attributes offered to respondent i in choice set c t ; and X i,c t ,j correspond to the jth row of matrix X i,c t , containing the attributes of the jth product in choice set c t . The total number of products in respondent i's choice set c t is J i,c t . Note that, because product attributes are categorical variables, online and offline attribute levels are coded as multiple levels of the same attribute. For example, if there are four colors, as in our data, in the online and offline data would be coded as one attribute with eight levels: four corresponding to online colors and four corresponding to offline colors. Finally, let y i,c t be respondent i's chosen product from set c t . According to the utility specification in (5), the likelihood of observing choice y i,c t is given by</p><formula xml:id="formula_6">[ y i,c t |X i,c t , β i,t ] exp(β i,t • X i,c t ,y i,c t ) j 1,. . . J i,c t exp(β i,t • X i,c t ,j ) . (<label>6</label></formula><formula xml:id="formula_7">)</formula><p>As above, we assume that the online and offline partworths are drawn from a joint multivariate normal distribution:</p><formula xml:id="formula_8">β i,on β i,off ~1 µ on µ off , Σ , Σ Σ on Σ on,off Σ off,on Σ off . (7)</formula><p>Assuming that the respondents make choices according to the model specification in ( <ref type="formula" target="#formula_6">6</ref>) and ( <ref type="formula">7</ref>), we propose a Bayesian technique to estimate the parameters. Note that this method differs from the existing data fusion techniques (e.g., <ref type="bibr" target="#b35">Swait and</ref><ref type="bibr">Andrews 2003, Feit et al. 2010</ref>), as we allow the same individual i's β ik,on and β ik,off to differ from each other in both task formats, instead of constraining them to be equal. We estimate the population-level parameters as follows: combining the individual-and population-level models gives us the Dzyabura, Jagabathula, and Muller: Online vs. Offline Product Evaluations likelihood of observing online and offline choices for all respondents:</p><p>[ y|µ on , µ off , Σ, X]</p><formula xml:id="formula_9">∏ i∈I off β i,on β i,off ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ ∏ C on i c on 1 [ y i,c on |X i,c on , β i,on ] • ∏ C off i c off 1 y i,c off |X i,c off , β i,off • β i,on , β i,off |µ on , µ off , Σ ⎞ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎟ ⎠ dβ i,off dβ i,on • ∏ i∈I on β i,on ∏ C on i c on 1 y i,c on |X i,c on , β i,on • β i,on |µ on , Σ on dβ i,on,<label>(8)</label></formula><p>where y {y i,c t } is the set of all observed choices, and</p><formula xml:id="formula_10">[β i,on , β i,off |µ on , µ off , Σ]</formula><p>is the probability of sampling the β's conditioned on the population-level parameters.</p><p>The model is estimated using a Bayesian approach. Because maximizing the likelihood expression in (8) over the population parameters is hard in general, we estimated the population parameters using the Bayesian framework. We used normal priors for µ on and µ off with mean 0 and variance 100, and we followed Sawtooth software guidelines for setting the prior values for Σ off , Σ on . For Σ on,off , we set the prior value for the covariance of the same level of the same attribute in both the online and offline tasks to a positive value. The exact prior covariance is reported in Appendix C. As no closed-form expression for the posterior distributions of the parameters exists, we used a standard Gibbs sampler to generate samples of the unknown parameters (β on , β off , µ on , µ off , Σ) iteratively (see <ref type="bibr" target="#b32">Rossi et al. 2012)</ref>. We then computed the individual-and population-level parameters by taking the average of 10,000 generated samples (after burning in the first 10,000 samples). k-Nearest Neighbors (k-NN) Correction. k-nearest neighbors (k-NN) is a popular data mining (meta-)algorithm, voted one of the top 10 data mining algorithms at the 2006 IEEE International Conference on Data Mining (ICDM) <ref type="bibr" target="#b36">(Wu et al. 2008)</ref>. It is a nonparametric method used for both classification and regression. It relies on the premise that "similar" users behave similarly. In its most general form, the algorithm requires specification of a similarity function that produces a similarity score between pairs of users, a response variable of interest, and the number of nearest neighbors, k. Then, the algorithm predicts the response for a test user by outputting the weighted average of the responses of the k nearest neighbors in the training sample, as determined according to the given similarity metric. The weights may be chosen to be equal, proportional to the similarity scores between the test user and the corresponding neighbor, or optimized for prediction accuracy.</p><p>In our context, we begin with the premise that customers with similar values of online partworths will have similar values of offline partworths. On the basis of this premise, we approach the following prediction task: We are given both the offline partworth vector β i,off and the online partworth vector β i,on for each individual i ∈ I off and the online partworth vector β i,on only for individuals i ∈ I on . Our objective is to predict the offline partworth vector for all of the individuals in the set I on . The given partworth vectors themselves could be estimated using any method. For the purposes of the empirical study presented below, we use the partworth estimates obtained from the HB method described above.</p><p>To predict the offline partworth of a respondent in I on , we select the k nearest respondents in the set I off , where the distance between two respondents is measured as the Euclidean distance between their respective online partworths:</p><formula xml:id="formula_11">d(i, i ′ ) k 1,. . . ,K (β i, k, on − β i ′ , k, on ) 2 . (<label>9</label></formula><formula xml:id="formula_12">)</formula><p>For each respondent i ∈ I on , we let S i denote the set of k nearest neighbors from the set I off . Then, we predict the respondent's offline partworth as</p><formula xml:id="formula_13">β i,off i ′ ∈S i w i,i ′ β i ′ ,off ,<label>(10)</label></formula><p>where the weights w i,i ′ 1/d(i, i ′ ) are chosen to be inverses of the distances between the corresponding individuals. Note that by construction we have S i ⊂ I off , and we are given β i ′ ,off for all individuals i ′ ∈ I off . Therefore, we can compute the expression in (10). The value of k is typically tuned using cross-validation, which is standard practice for model selection <ref type="bibr" target="#b0">(Abu-Mostafa et al. 2012)</ref>. For the purposes of the empirical study, we picked k = 30 through 10-fold cross-validation. Specifically, we split the individuals in the set I off into 10 (roughly) equal parts and then train our model on data from 9 parts and make predictions for the individuals in the 10th part. Letting I off,train denote the individuals in the first 9 parts and I off,validation denote the individuals in the 10th part, we compute the prediction error</p><formula xml:id="formula_14">Error i∈I off,validation k 1,. . . ,K β i, k, off − β i, k, off 2 , (<label>11</label></formula><formula xml:id="formula_15">)</formula><p>where we compute β i,off using Equation (10) but with neighborhood of individual i chosen as the k closest individuals from the set I off,train , where the distance between individuals is measured as in Equation ( <ref type="formula" target="#formula_11">9</ref>). We repeat the above process 10 times (folds) with each of the 10 parts used exactly once as the validation sample I off,validation . We average the error across the 10 folds and use the resulting average error as the proxy for the outof-sample performance. We compute the average error for each value of the number k of neighbors from the set {10, 15, 20, 25, 30, 35, 40, 35}, and we pick the value that resulted in the least average error. We found that k = 30 resulted in the least average error. The k-NN approach is custom-built for making individual-level predictions. It is particularly well suited to settings in which the population distribution is multimodal <ref type="bibr" target="#b36">(Wu et al. 2008)</ref>. In this case, a Bayesian approach with a normal distribution assumption shrinks the all the respondents' individual-level partworths to a single population mean. Instead, the k-NN approach shrinks the partworths of different respondents to means of different subsets of respondents and thereby better captures multiple modes within the data set. Once the partworth vectors for the individuals in I on and I off are given, the k-NN does not make any parametric assumptions in predicting the offline partworths for the individuals in I on . In this sense, it is a nonparametric method that is not designed to incorporate any prior information. Therefore, all else being equal, we expect it to perform better when the modeler has access to a larger training sample of respondents with offline partworths. We implemented the k-NN method using the sklearn.neighbors. KNeighborsRegressor function from Python scikit-learn <ref type="bibr" target="#b29">(Pedregosa et al. 2011</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Performance of the Bayesian ICL and k-NN Corrections</head><p>We now describe the empirical performance both in terms of prediction and decision accuracies of the proposed Bayesian ICL and k-NN corrections. To test the performance, we used data from two studies: first, the data on the respondents in Study 1, condition 1, who did an online followed by an offline conjoint (N = 122), described above in Section 3; and second, the data from a set of respondents who completed an online CBC followed by an offline CBC as part of Study 2 (N = 67), described next.</p><p>Study 2. As in Study 1, we asked each respondent to complete an online task, followed by an offline task. Prior to completing the choice tasks, respondents first viewed a screen with instructions and then viewed each attribute description one by one, followed by a sample choice task that we did not use for estimation. For the offline task, we created five choice sets of four bags each, using the same 20 physical bags as in the first study. For each respondent, bags in the same choice set were placed next to each other, and each choice set was covered with fabric to avoid comparison with previous or subsequent choices, and to ensure that the respondents focused on the products in the present choice set. We also positioned the sets of bags such that two consecutive choice tasks were not next to one another; for example, choice set 1 was not next to choice set 2. We used this approach to help the respondent focus on the single choice set she was presented with and to refrain from comparing the bags to those in the choice sets she had just seen. The experimenter pointed out each of the features on a sample bag and then uncovered one choice set at a time, in order from 1 to 5. Respondents circled their choices on a paper form. Completing this portion took respondents about 15 minutes.</p><p>To avoid idiosyncratic noise in the performance measures, we randomly assigned respondents to one of three groupings of the bags into choice sets. Although all respondents' choice sets were made up of the same 20 bags, the bags were divided differently into five choice sets, resulting in 15 distinct choice sets total.</p><p>Prediction Accuracy: Predicting Offline Choices Using Online Data. We first assess the overall improvements in the accuracy of predicting offline choices of individuals in I on , who completed Study 2. The data used for our computational study are summarized in Table <ref type="table">3</ref>. Our objective is to predict the choices in cell D in Table <ref type="table">3</ref>.</p><p>We let I off denote the set of individuals from Study 1 who completed an online task followed by an offline task (cells A and C in Table <ref type="table">3</ref>), and we let I on denote the set of individuals who were part of Study 2 (corresponding to cells B and D in Table <ref type="table">3</ref>). Because respondents in I off completed a ratings-based task, and the HB method assumes choice data, we first convert these ratings to a choice format. We adapted a procedure similar to the rank-ordered logit model <ref type="bibr" target="#b2">(Beggs et al. 1981, Hausman and</ref><ref type="bibr" target="#b18">Ruud 1987)</ref>, also known as the exploded logit model <ref type="bibr" target="#b31">(Punj and Staelin 1978</ref><ref type="bibr" target="#b7">, Chapman and Staelin 1982</ref><ref type="bibr" target="#b1">, Allison and Christakis 1994</ref> for ranking data. Specifically, let u ij denote the rating provided by participant i for bag j. We converted the ratings data into a ranked list by breaking ties based on the population averages. Letū denote i∈I off u ij |I off | , or the rating that product j received averaged over the entire population. Then, with each individual i, we associated ranked list δ i that encodes the ranking in terms of pairwise comparisons, with δ ijl taking the value 1 if the participants preferred j to l and 0 otherwise. More precisely, δ ijl 1 if j l or u ij &gt; u il or if u ij u il andū j &gt;ū l , and 0 otherwise.</p><p>We then converted the ranked list into "exploded" choice sets as follows: Fix an individual i. Let ( j 1 , j 2 , . . ., j 20 ) be the ordered ranked list corresponding to δ i , with the products ordered in decreasing order of Dzyabura, Jagabathula, and Muller: Online vs. Offline Product Evaluations preference. We "explode" this ranked list into 20 choice sets: C 1 {j 1 , j 2 , . . ., j 20 }, C 2 {j 2 , . . ., j 20 }, . . ., C 20 {j 20 }, where we successively remove the most preferred product from each choice set. The respondent's choice is the most preferred product from each set, so the choice y i,C l is equal to j l for l 1, 2, . . ., 20. We compared three different methods for predicting the offline choices of participants in Study 2: the benchmark method, the Bayesian ICL correction, and the k-NN correction. The online benchmark method ignores all the data from the offline studies. Using the standard Bayesian techniques, the method estimates the expected online partworths β i,on for each individual i and sets β i,off,bench β i,on . The Bayesian and k-NN techniques estimate β i,off,Bayes and β i,off,kNN as described above, using online data from participants in Study 2.</p><p>To assess the quality of the estimates, we compute two metrics on the held-out offline choices: individual log-likelihood and choice-set RMSE, defined as follows.</p><p>Individual log likelihood:</p><formula xml:id="formula_16">1 |I on | i ∈ I on 1 |C off i | c 1,. . . ,C off i log exp β i,off,method • X i,c,y i,c j 1,. . . ,J i,c exp β i,off • X i,c,j ,<label>(12)</label></formula><p>where c indexes the offline choice task of respondent i, and y i,c denotes the product chosen by the respondent in choice task c, j 1, . . .J i,c denote the products offered in choice task c, and method ∈ {bench, Bayes, kNN}. Of course, the higher the value of the likelihood, the better the method.</p><p>To compute the choice set share RMSE, let m j,c denote the observed market share for product j and choice set c, and let m j,c,method denote the predicted market share, given by</p><formula xml:id="formula_17">m j,c |i ∈ I c : y i,c j| |I c | , m j,c,method 1 |I c | i∈I c exp β i,off,method • X i,c,y i,c j ′ 1,. . . J i,c exp β i,off,method • X i,c,j ′ , (<label>13</label></formula><formula xml:id="formula_18">)</formula><p>where I c is the set of respondents presented with choice set c. Then the choice set share RMSE metric is given by 1 |C| c∈C j 1,. . . J c m j, c − m j, c, method 2 , (</p><p>where C denotes the collection of all the choice tasks.</p><p>We report the performance of the methods (Bayesian ICL correction and k-NN correction), and two benchmarks, on both performance metrics in Table <ref type="table" target="#tab_6">4</ref>.</p><p>In addition to the online benchmark mentioned above, we also add an offline benchmark that ignores the data from all the online studies. Because the offline benchmark ignores the data from cell B in Table <ref type="table">3</ref>, it can predict aggregated market shares only, and not individual-level partworths for individuals in I on . Therefore, we report the choice set share RMSE metric only for the offline benchmark. The prediction task for all four models is the offline choice data in study 2 (cell D in Table <ref type="table">3</ref>). The online-only benchmark uses the online data from both sets of participants (i.e., cells A and B). The offline-only benchmark uses the data in cell C. Therefore, we compute only aggregate-level choice set shares for the offlineonly benchmark, as we cannot make individual-level predictions. The two corrections (Bayesian and k-NN) use the online data from both sets of participants and the offline data from the first group of participants, cells A, B, and C of Table <ref type="table">3</ref>. Significance is computed relative to the online-only benchmark using a two-tailed paired sample t-test, over the 67 individuals for the individual log likelihood metric, and 15 choice sets for the choice set share RMSE metric.</p><p>From Table <ref type="table" target="#tab_6">4</ref>, we observe that both proposed methods that use the offline data from the first study to estimate participants' offline partworths outperform the online-only benchmark, which simply uses their online partworths. We also compute aggregate-level predictions from the offline data. Note that the Bayesian method leads to a larger improvement in the aggregate measure, whereas the k-NN method leads to a larger improvement in the individual prediction, while demonstrating no significant improvement in the aggregate prediction. One reason for the difference in aggregate-level performance may be that the Bayesian estimation specifically estimates population-level parameters, as part of the model estimation. The k-NN method, on the other hand, does not have the population mean as an explicit model parameter that is estimated. The difference in individual-level performance is likely due to k-NN being particularly well suited to individual-level predictions when the population distribution is multimodal <ref type="bibr" target="#b36">(Wu et al. 2008)</ref>, as discussed in Section 4.1. Because the two methods are better tailored to different predictive tasks, researchers can choose which method is appropriate depending on whether individual-level or aggregate-level predictions are more important in their particular application.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Robustness and Value of the Offline Information</head><p>In this section, we evaluate the robustness of our findings as well as the value of offline information and in particular, the role of online data in inferring offline parameters, and the relative information gain between offline and online data. We begin with a robustness evaluate our two correction methods-namely, the Bayesian ICL correction and k-NN correction-in terms of their prescriptive implications for optimal product lines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Robustness Test: Comparison of the Revenue-Maximizing Subsets</head><p>We now investigate how products' revenue-maximizing subsets differ under differing methods of estimating utility partworths. The problem of finding revenueor sales-maximizing subsets of products, also called the assortment optimization (AO) problem, has received much attention both in the marketing <ref type="bibr" target="#b21">(Kohli and Sukumar 1990)</ref> and the operations management <ref type="bibr" target="#b22">(Kök et al. 2015)</ref> literatures. It is aimed at helping a firm make the important decision of which products to carry in its stores. As it involves solving a computationally challenging set optimization problem, most existing work has focused on developing tractable techniques for addressing the computational challenge.</p><p>The critical inputs to these techniques are utility partworths, which are often estimated from a conjoint study, as we did here, or using secondary transaction-level data. These partworth estimates' accuracies crucially determine the accuracy of the assortment decision. We now showcase how the particular corrections to partworth estimates that we propose impact a firm's assortment decision. For that, we compute the revenue-maximizing product subsets of size four using the partworth estimates obtained from three different methods: the online-only benchmark, Bayesian ICL correction, and k-NN correction. To compute the revenue-maximizing subset for each method, let β i,method denote the estimated utility partworths for participant i in Study 2. For a subset S of bags, we compute the expected revenue under a particular method as follows:</p><formula xml:id="formula_20">R method (S) 1 |I on | i∈I on j∈S r j exp(β i,method • X j ) j∈S exp(β i,method • X j ) ,<label>(15)</label></formula><p>where r j denotes the price of product j, and I on denotes the set of participants who completed Study 2. We then search over all possible subsets of size four from the 20 bags used in our two studies to obtain the revenuemaximizing subset. Table <ref type="table" target="#tab_7">5</ref> presents the results. We observe from the table that the assortment decisions under the benchmark method and both corrections overlap in only two products-namely, A and C. This marginal overlap suggests that the differences in the partworths can significantly alter the assortment decision and thereby the firm's revenue and profit potential. In addition, we notice that the subsets obtained under both the corrections overlap Note. The subsets obtained under both corrections overlap in three out of four products (A, B, and C), indicating that the assortment decision is reasonably robust to the particular correction used.</p><p>Dzyabura, Jagabathula, and Muller: Online vs. Offline Product Evaluations in three products-namely A, B, and C-out of a possible four. This suggests that the corrections are robust, at least as far as the assortment decision is concerned.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Role of Online Data in Inferring</head><p>Offline Parameters To obtain intuition on how online data helps improve offline estimates, we analytically illustrate the correction under a linear mixed-effects model. Under this model, it can be shown that, conditioned on the online parameters, the offline parameters are distributed as a multivariate normal random variable:</p><formula xml:id="formula_21">β i,off |β i,on~1 (µ i,off|on , Σ i,off|on ), µ i,off|on µ off + Σ on,off Σ −1 on • (β i,on − µ on ), Σ i,off|on Σ off − Σ off,on Σ −1 off Σ on,off .<label>(16)</label></formula><p>We can rewrite the conditional distribution of β i,off |β i,on as the sum of a deterministic component and a mean zero random component: β i,off |β i,on µ i,off|on + ε, where ε~1(0, Σ i,off|on ). Substituting the expression for µ i,off|on from Equation ( <ref type="formula" target="#formula_21">16</ref>), we obtain the following relationship:</p><formula xml:id="formula_22">β i,off |β i,on − µ off Σ on,off Σ −1 on • (β i,on − µ on ) + ε.<label>(17)</label></formula><p>In Appendix B, we show that under some constraints on the structure of the covariance matrix Σ, one can rewrite Equation ( <ref type="formula" target="#formula_22">17</ref>) for individual attribute k as follows:</p><formula xml:id="formula_23">β i,k,off|on − µ k,off ρ k σ k,off σ k,on (β i,k,on − µ k,on ) + ε k , (<label>18</label></formula><formula xml:id="formula_24">)</formula><p>where ρ k is the correlation coefficient between the online and offline partworths β i,k,off and β i,k,on . Here, we can see the extent to which individual-level offline and online partworths for an attribute are directly related: If an individual had a higher than average partworth for a particular feature k online, β i,k,on &gt; µ k,on , she will also have a higher than average partworth for the feature offline, assuming the online and offline partworths are positively correlated (ρ k &gt; 0 in Equation ( <ref type="formula" target="#formula_23">18</ref>)).</p><p>We can see from Equations ( <ref type="formula" target="#formula_22">17</ref>) and ( <ref type="formula" target="#formula_23">18</ref>) that if the correlation is zero (or close to zero), then β i,k,on is not a good predictor of β i,k,off , and our conditional estimate of the individual offline partworth is simply the population mean. On the other hand, the higher the magnitude of the correlation between the online and offline partworths of the same attribute level |ρ k |, the more precisely we can estimate the individual-level β i,k,off from β i,k,on . In particular, if β i,k,off and β i,k,on are perfectly correlated, we obtain an estimate of β i,k,on simply by subtracting the difference between the two population means. For example, note that (from Table <ref type="table" target="#tab_1">1</ref> and Table <ref type="table">A</ref>.1 in Appendix A) the feature "colorful" has online-offline bias, or high µ k,on − µ k,off −1.06 + 0.71 0.35, and also a high value of ρ k σ k,off σ k,on 1. Although a big discrepancy exists between online and offline partworths, given a respondent's online responses, and given good estimates of µ k,on and µ k,off , we can predict the individuallevel β k,off well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Relative Information Gain in Offline and</head><p>Online Data Section 4 shows that our proposed approach, which combines offline and online conjoint results, yields more accurate individual-and aggregate-level purchase predictions than does pure online-only conjoint. As our objective is to obtain accurate predictions of offline purchase behavior, an alternate approach is to forgo the online task altogether, and simply conduct offline conjoint studies. By requiring the respondents to evaluate physical prototypes, these studies are closer to the real-world purchasing context and therefore preferable. The trade-off, of course, is that conducting a conjoint study offline is significantly costlier per participant.</p><p>In this section, using the unrestricted linear mixed model described in Equations ( <ref type="formula" target="#formula_2">3</ref>) and ( <ref type="formula" target="#formula_3">4</ref>), we compare our proposed approach to conducting an offline-only conjoint on the precisions of the offline parameter estimates they obtain. We measure the precision of a parameter estimate in terms of the asymptotic variance of the corresponding maximum-likelihood (ML) estimator, obtained from the inverse of the Fisher information matrix, to be described shortly. Lower variance values indicate higher precisions. To conduct the comparison on equal footings, we focus on settings in which the costs of the two approaches are equalized; of course, without a cost constraint, conducting an offline-only conjoint should yield better performance.</p><p>The key insight from our analysis is that our proposed approach can take advantage of the cost differential between conducting online and offline conjoint studies to obtain more precise estimates than those yielded by an offline-only conjoint. When there is a cost differential, our approach uses a small share of the budget to collect a large sample of "noisy" (online) data as opposed to a small sample of "cleaner" (offline) data. The larger sample size more than makes up for the noise in the data to yield more precise estimates for the values of cost differentials observed in practice.</p><p>Setup. We considered the following setup for our analysis: Suppose the cost to the firm of a single online respondent is c on , and the cost of a single offline respondent is c off , such that c off &gt; c on . Let Q = c off /c on denote the cost multiplier of an offline respondent with respect to an online one. Given cost values to be discussed shortly, we compared two study designs: a combined design and an offline-only design. The combined design collects offline and online data for a set of respondents and online-only data for an additional set of respondents. Thus, all respondents complete the online study, and we let N on represent the size of this set. Offline data are collected for </p><p>In other words, we can collect offline-only data, at the same total cost, for Δ more respondents than in the combined design.</p><p>To obtain a realistic estimate to the multiplier Q, we obtained price quotes from market research firms for a commercial offline conjoint study. The costs involve payment to participants, the hourly rate of an experimenter (including salary, benefits, and overhead), and recruiting costs. The total comes to $100-$150 per participant. Online participants can be obtained for $2-$3 per participant. With these cost values, we set N on = 122 and N off = 61, and we varied the cost multiplier Q to take values from the set {50, 30, 15}. Although the value of Q = 50 is reasonable given the quotes we obtained, we also considered the value Q = 15 as a lower-end estimate, to capture any settings in which conducting an offline conjoint is relatively cheap. Finally, we also considered an intermediate multiplier of 30. With these values of Q, we obtained Δ N on /Q to be approximately 2, 4, and 8 (corresponding to the values of Q = 50, 30, and 15). Thus, although we kept the benchmark case at 61 online and offline, plus 61 online respondents, we compared this benchmark to 63, 65, and 69 offline respondents only. For example, for Q = 50, given the figures of $2 and $100 for online and offline cost per respondent, the total budget remains the same for the two studies: approximately $6,300 (see Equation ( <ref type="formula">19</ref>)).</p><p>Results and Discussion. Table <ref type="table" target="#tab_9">6</ref> shows the asymptotic variances corresponding to the ML estimates of the offline partworths, as the cost multiplier is varied over Q = 50, 30, 15. We obtained these values by taking the inverses of the Fisher information matrices computed for the two designs; the details of the computations are presented in Appendix C.</p><p>We note that when cost multiplier Q = 50 (i.e., conducting an offline conjoint is relatively costly, as market prices indicate), our proposed combined design yields more precise estimates (i.e., with lower asymptotic variances) of the offline partworths than does the offlineonly design for all but "reflective" and "divider" features. The reduction in the variance as a result of the combined design can be significant: as much as 28% for the partworth "colorful." The increase in the variance, on the other hand, is less than 1% for "reflective" and "divider" features. These findings enable us to conclude that when conducting an offline conjoint is significantly more costly than conducting an online one, using some portion of the budget to conduct an online conjoint for a large sample of respondents can provide more precise estimates of the offline partworths. In these settings, the loss in the "quality" of the data per respondent from collecting online instead of offline data is more than made up for by the ability to collect a much larger sample.</p><p>When the cost multiplier Q reduces to 30, the combined design results in lower variances for six features, with a reduction of up to 24% for the feature "colorful" and higher variances for the remaining three features, with a maximum increase of less than 4%. Therefore, even if the cost of conducting an offline conjoint dropped by 40%, the combined design offers better precision overall when compared with the offline-only design. It is only when conducting an offline conjoint becomes significantly cheaper (i.e., when Q = 15) that the offline-only conjoint outperforms the combined design. This analysis shows how the benefits of the combined approach over the offline-only conjoint hinge on the cost differential Q. In most practical settings, we expect Q to be reasonably large, given the ease of finding respondents online through crowdsourcing platforms, such as MTurk. As a result, the comparison corresponding to Q = 50 is more indicative of what we expect to see in practice. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions and Implications</head><p>In this work, we challenged the common implicit assumption in preference elicitation that findings from online studies can accurately predict offline purchase behavior. We compared consumers' product evaluations in an online conjoint study with verbal product descriptions and pictures with those of the same consumers in an offline study with physical products. We found that the majority of partworth parameters changed significantly between online and offline studies. This discrepancy will lead models trained on data from online studies only to have diminished predictive ability for offline behavior. We recognize, however, that conducting online preference elicitation is significantly cheaper than conducting offline preference elicitation. Therefore, we proposed and tested a hybrid solution: supplementing an online conjoint study with a small set of participants who complete both online and offline preference elicitation. We tested two data fusion techniques that use the data from an online study completed by a "large" number of respondents, supplemented by an offline study completed by a "small" subset of the respondents. The techniques predict a respondent's offline preference partworths when given her online partworths. In the empirical application, we demonstrated that our data fusion techniques result in more accurate predictions of respondents' offline choices.</p><p>Our study consisted of two conditions in which participants completed the online and offline conjoint tasks in differing orders, allowing us to gain further insight into the source of the discrepancy. The results suggest that two key factors cause respondents to behave differently when evaluating products online versus offline: (1) information gained by physically and visually examining the product and (2) differing relative attribute salience in the two formats. Note that neither of these factors is related to consumer preferences actually differing between online and offline settings. What the conjoint partworths more precisely represent are decision rules, or the extent to which a product's having a certain feature increases the probability of its being chosen.</p><p>The decision rule may not perfectly capture a consumer's preference. For example, making a certain feature, such as strap pad, more salient, such as by increasing the font size of that feature in the product description, will increase the weight that the strap pad carries in the respondent's decision. Clearly, the larger font does not increase the respondent's actual preference for the feature: he or she does not start to like the strap pad any more or less than before. It does, however, increase the role it plays in the consumer decision, which is what the partworths capture.</p><p>One of the limitations of our approach is that it is applicable to the cases in which a prototype is available for preference-elicitation techniques. It thus does not apply to services but rather to physical goods purchased in brick-and-mortar stores only. Clearly, for a service such as cellular, the packages (usually threetier assortments) do not lend themselves to information gain offline compared with online, and attribute salience should not exist, as both are presented in list form. Neither can our approach be used to forecast demand for radical innovations, for which physical prototypes are not yet available. Note that the discrepancy between online and offline attribute evaluations might be consumer specific, and thus a possible future avenue of research could examine consumer characteristics-and in particular, the level of familiarity with the product category-that might help explain this discrepancy.</p><p>In this paper, we used primary data to carefully control for all factors and to hone in on the online/ offline distinction. But the higher-level problem of predicting a consumer's offline preferences, given the same consumer's online preferences and other consumers' online and offline preferences, has implications beyond online preference elicitation. Typically, the firm has, or can obtain, some data on both online and offline preferences for customers who have a history with both, as is depicted in Figure <ref type="figure" target="#fig_5">5</ref>.</p><p>These preferences could be estimated from secondary sources, such as past purchases, clicks, or returns data. Consider mixed retailers that sell both online and offline, such as Warby Parker, Zappos, or Bonobos, or online-only retailers: both are affected by the discrepancy of online and offline product evaluation because of "showrooming" and the prevalence of flexible return policies. For instance, when consumers purchase from online/mixed retailers, they may decide what to order based on their online evaluation of the available items. However, once they receive their order, consumers determine what they want to keep and what to return based on physical evaluation. Because of the generous return policies offered by many retailers, customers may try on several items before purchasing one. To apply our methods, an online/mixed retailer can use the online and offline preference data obtained from the items that Marketing <ref type="bibr">Science, 2019</ref><ref type="bibr">, vol. 38, no. 1, pp. 88-106, © 2019</ref> a given customer ordered online and the items that he or she decided to return after physical evaluation. Such customers can be considered the training set, as they provide sufficient data to calibrate the discrepancy between online and offline partworths. For a new customer, who has not yet evaluated the firm's products physically, the firm may have data on online preferences only. In this case, the firm can apply an approach similar to ours to predict what the customer will prefer upon physical examination of the products. With this prediction, the firm can better manage returns or may recommend products that the customer is likely to prefer in person. For use of a similar approach, see .</p><p>2 Computed from Sawtooth: 20 choices among four profiles each, so as to obtain standard errors below 0.05. Note that this number could be somewhat reduced by appropriately constraining the choice design while maintaining reasonable design efficiency, although lower than the one chosen here.</p><p>3 An alternative specification of the model would be u ij,online β i0 + Δ i0 + K k 1 β ik x jk + K k 1 Δ ik x jk • x online + ijt , where β ik represents the offline attribute partworths, Δ ik represents the bias as a result of the online format, and x online is a binary variable that takes the value 1 in the online format and 0 in the offline format. In this specification, the null hypothesis can be stated more precisely as the population mean and variance parameters corresponding to Δ are zero. <ref type="bibr">4</ref> We optimized the design of the study using the standard Sawtooth Complete Enumeration module to ensure efficient estimation.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. (Color online) Offline Task Room Setup</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Sample Online Conjoint Screenshot</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Mechanisms Accounting for Discrepancy Between Tasks</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Observed Discrepancy Between Tasks</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Table 3 .</head><label>3</label><figDesc>Data Used for Model Training and Prediction Study 1 (N 122) Study 2 (N 67) Cells A, B, and C are used for training, and cell D is used for prediction.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Schematic Data Available to a Typical Online Retailer</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Dzyabura, Jagabathula, and Muller: Online vs. Offline Product Evaluations</figDesc><table><row><cell>Marketing Science, 2019, vol. 38, no. 1, pp. 88-106, © 2019 INFORMS</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>reports the attribute fixed effects µ k , estimated when the model in (1) is fit separately to the online and offline data sets. Standard errors are reported in parentheses.</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 .</head><label>1</label><figDesc>Mean Population Partworths (µ), Online-First Condition (Standard Errors in Parentheses) Attribute Level Online partworth (µ k,on ) Offline partworth (µ k,off )</figDesc><table><row><cell>Exterior design</cell><cell>Reflective</cell><cell>−0.31 (0.07)</cell><cell>−0.60 (0.09)</cell></row><row><cell></cell><cell>Colorful</cell><cell>−1.06 (0.09)</cell><cell>−0.71 (0.10)</cell></row><row><cell></cell><cell>Blue</cell><cell>−0.22 (0.06)</cell><cell>−0.11 (0.06)</cell></row><row><cell></cell><cell>Black</cell><cell></cell><cell></cell></row><row><cell>Size</cell><cell>Large</cell><cell>0.27 (0.05)</cell><cell>−0.31 (0.06)</cell></row><row><cell></cell><cell>Small</cell><cell></cell><cell></cell></row><row><cell>Price</cell><cell>$120, $140, $160, $180</cell><cell>−0.011 (8E−4)</cell><cell>−0.0075 (8E−4)</cell></row><row><cell>Strap pad</cell><cell>Yes</cell><cell>0.51 (0.05)</cell><cell>0.25 (0.05)</cell></row><row><cell></cell><cell>No</cell><cell></cell><cell></cell></row><row><cell>Water bottle pocket</cell><cell>Yes</cell><cell>0.45 (0.04)</cell><cell>0.17 (0.03)</cell></row><row><cell></cell><cell>No</cell><cell></cell><cell></cell></row><row><cell>Interior</cell><cell>Divider for files</cell><cell>0.41 (0.04)</cell><cell>0.52 (0.04)</cell></row><row><cell>compartments</cell><cell>Crater laptop sleeve</cell><cell>0.62 (0.06)</cell><cell>0.88 (0.06)</cell></row><row><cell></cell><cell>Empty bucket/no dividers</cell><cell></cell><cell></cell></row><row><cell>Intercept</cell><cell></cell><cell>3.72 (0.12)</cell><cell>3.39 (0.13)</cell></row></table><note>Dzyabura, Jagabathula, and Muller: Online vs. Offline Product Evaluations</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Mean Population Partworths (µ), Offline-First Condition</figDesc><table><row><cell>Attribute</cell><cell>Level</cell><cell cols="2">Online partworth (µ k,on ) Offline partworth (µ k,off )</cell></row><row><cell>Exterior design</cell><cell>Reflective</cell><cell>−0.25 (0.14)</cell><cell>−0.26 (0.16)</cell></row><row><cell></cell><cell>Colorful</cell><cell>−0.26 (0.13)</cell><cell>−0.18 (0.14)</cell></row><row><cell></cell><cell>Blue</cell><cell>−0.07 (0.11)</cell><cell>0.03 (0.10)</cell></row><row><cell></cell><cell>Black</cell><cell></cell><cell></cell></row><row><cell>Size</cell><cell>Large</cell><cell>−0.15 (0.03)</cell><cell>−0.17 (0.07)</cell></row><row><cell></cell><cell>Small</cell><cell></cell><cell></cell></row><row><cell>Price</cell><cell>$120, $140, $160, $180</cell><cell>−0.012 (0.002)</cell><cell>−0.008 (0.002)</cell></row><row><cell>Strap pad</cell><cell>Yes</cell><cell>0.50 (0.09)</cell><cell>0.24 (0.08)</cell></row><row><cell></cell><cell>No</cell><cell></cell><cell></cell></row><row><cell>Water-bottle pocket</cell><cell>Yes</cell><cell>0.33 (0.07)</cell><cell>−0.005 (0.06)</cell></row><row><cell></cell><cell>No</cell><cell></cell><cell></cell></row><row><cell>Interior compartments</cell><cell>Divider for files</cell><cell>0.65 (0.07)</cell><cell>0.62 (0.08)</cell></row><row><cell></cell><cell>Crater laptop sleeve</cell><cell>1.01 (0.11)</cell><cell>1.15 (0.10)</cell></row><row><cell></cell><cell>Empty bucket/no dividers</cell><cell></cell><cell></cell></row><row><cell>Intercept</cell><cell></cell><cell>3.38 (0.21)</cell><cell>3.07 (0.25)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc> Muller: Online vs. Offline Product Evaluations   Marketing Science, 2019, vol. 38, no. 1, pp. 88-106, © 2019 INFORMS   </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>Dzyabura, Jagabathula, and Muller: Online vs. Offline Product Evaluations</figDesc><table><row><cell>Marketing Science, 2019, vol. 38, no. 1, pp. 88-106, © 2019 INFORMS</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 .</head><label>4</label><figDesc>Predictive Performance</figDesc><table><row><cell></cell><cell>Individual log</cell><cell>Choice-set share</cell><cell>% change individual log</cell><cell></cell><cell>% change choice-set share</cell><cell></cell></row><row><cell></cell><cell>likelihood</cell><cell>RMSE</cell><cell>likelihood</cell><cell>p-value</cell><cell>RMSE</cell><cell>p-value</cell></row><row><cell>Bayesian</cell><cell>−1.347</cell><cell>0.177</cell><cell>17.9%</cell><cell>0.001</cell><cell>33.6%</cell><cell>0.013</cell></row><row><cell>k-NN</cell><cell>−1.191</cell><cell>0.267</cell><cell>27.3%</cell><cell>0.000</cell><cell>−0.7%</cell><cell>0.95</cell></row><row><cell>Benchmark (offline</cell><cell>NA</cell><cell>0.246</cell><cell>NA</cell><cell></cell><cell>7.5%</cell><cell>0.62</cell></row><row><cell>only)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Benchmark (online</cell><cell>−1.640</cell><cell>0.266</cell><cell>NA</cell><cell></cell><cell>NA</cell><cell></cell></row><row><cell>only)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5 .</head><label>5</label><figDesc>Revenue-Maximizing Subsets of Size 4 Under Different Methods</figDesc><table><row><cell>Method</cell><cell>Color</cell><cell>Size</cell><cell>Strap</cell><cell>Water bottle</cell><cell>Interior</cell><cell>Price</cell><cell>Product ID</cell></row><row><cell>Benchmark</cell><cell>Colorful</cell><cell>Small</cell><cell>Yes</cell><cell>Yes</cell><cell>Laptop</cell><cell>$180</cell><cell>A</cell></row><row><cell>(online only)</cell><cell>Black</cell><cell>Large</cell><cell>Yes</cell><cell>Yes</cell><cell>Laptop</cell><cell>$140</cell><cell>C</cell></row><row><cell></cell><cell>Reflective</cell><cell>Large</cell><cell>No</cell><cell>Yes</cell><cell>Divider</cell><cell>$180</cell><cell>D</cell></row><row><cell></cell><cell>Blue</cell><cell>Large</cell><cell>Yes</cell><cell>No</cell><cell>Empty</cell><cell>$180</cell><cell>E</cell></row><row><cell>Bayesian</cell><cell>Colorful</cell><cell>Small</cell><cell>Yes</cell><cell>Yes</cell><cell>Laptop</cell><cell>$180</cell><cell>A</cell></row><row><cell>correction</cell><cell>Blue</cell><cell>Small</cell><cell>No</cell><cell>Yes</cell><cell>Divider</cell><cell>$160</cell><cell>F</cell></row><row><cell></cell><cell>Black</cell><cell>Small</cell><cell>No</cell><cell>No</cell><cell>Laptop</cell><cell>$180</cell><cell>B</cell></row><row><cell></cell><cell>Black</cell><cell>Large</cell><cell>Yes</cell><cell>Yes</cell><cell>Laptop</cell><cell>$140</cell><cell>C</cell></row><row><cell>k-NN</cell><cell>Blue</cell><cell>Small</cell><cell>Yes</cell><cell>Yes</cell><cell>Divider</cell><cell>$140</cell><cell>G</cell></row><row><cell>correction</cell><cell>Colorful</cell><cell>Small</cell><cell>Yes</cell><cell>Yes</cell><cell>Laptop</cell><cell>$180</cell><cell>A</cell></row><row><cell></cell><cell>Black</cell><cell>Small</cell><cell>No</cell><cell>No</cell><cell>Laptop</cell><cell>$180</cell><cell>B</cell></row><row><cell></cell><cell>Black</cell><cell>Large</cell><cell>Yes</cell><cell>Yes</cell><cell>Laptop</cell><cell>$140</cell><cell>C</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc> Muller: Online vs. Offline Product Evaluations   Marketing Science, 2019, vol. 38, no. 1, pp. 88-106, © 2019  INFORMS N off respondents. The offline-only design collects offline data only for N respondents. To equalize the costs of the two designs, the following relationship should be satisfied: c off N c on N on + c off N off . off + Δ, where Δ N on /Q.</figDesc><table><row><cell>(19)</cell></row><row><cell>This implies that</cell></row><row><cell>N N</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6 .</head><label>6</label><figDesc>Asymptotic Variance Performance</figDesc><table><row><cell></cell><cell>Combined design</cell><cell></cell><cell>Offline-only design</cell><cell></cell></row><row><cell></cell><cell>N on = 122</cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>N off = 61</cell><cell>N = 63 (Q = 50)</cell><cell>N = 65 (Q = 30)</cell><cell>N = 69 (Q = 15)</cell></row><row><cell>Reflective</cell><cell>0.0161</cell><cell>0.0160</cell><cell>0.0155</cell><cell>0.0146</cell></row><row><cell>Colorful</cell><cell>0.0147</cell><cell>0.0203</cell><cell>0.0196</cell><cell>0.0185</cell></row><row><cell>Blue</cell><cell>0.0062</cell><cell>0.0064</cell><cell>0.0062</cell><cell>0.0059</cell></row><row><cell>Size</cell><cell>0.0059</cell><cell>0.0067</cell><cell>0.0065</cell><cell>0.0061</cell></row><row><cell>Price</cell><cell>1.27E−6</cell><cell>1.33E−6</cell><cell>1.29E−6</cell><cell>1.22E−6</cell></row><row><cell>Strap pad</cell><cell>0.0038</cell><cell>0.0042</cell><cell>0.0040</cell><cell>0.0038</cell></row><row><cell>Water bottle</cell><cell>0.00249</cell><cell>0.00254</cell><cell>0.0025</cell><cell>0.0023</cell></row><row><cell>Divider</cell><cell>0.00379</cell><cell>0.00378</cell><cell>0.0037</cell><cell>0.0034</cell></row><row><cell>Laptop</cell><cell>0.0072</cell><cell>0.0076</cell><cell>0.0074</cell><cell>0.0070</cell></row></table><note>Note. Bold indicates values where the offline-only design is worse than combined design.Dzyabura, Jagabathula, and Muller: Online vs. Offline Product Evaluations</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">MarketingScience, 2019, vol. 38, no. 1, pp. 88-106, © 2019 </note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank Tom Meyvis, John Hauser, Russ Winer, Liu Liu, Oded Netzer, and seminar participants at UC San Diego Rady School of Management, London Business School, and the New Economic School for their thoughtful comments.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Covariance Matrix The ICL method computes the expected offline ratings conditioned on all the observed data. We exploit the properties of multivariate normal distributions to compute the conditional expectations in closed form. Specifically, recall that we assume that participant i samples the online and offline partworths, β i,k,on and β i,k,off , of feature k jointly from a bivariate normal distribution:</p><p>, where σ k,on,off is the covariance between the online and offline partworths of feature k. The assumption embedded in the covariance matrix is that there are no correlations among various features; that is, we fix at zero the elements of Σ that correspond to cov(β i,k,t , β i,k ′ ,t ′ ) for k ≠ k ′ and for all t and t ′ .</p><p>We use observed data to determine the maximum likelihood estimates of the population-level parameters µ k,off , µ k,on , σ k,off , σ k,on , and σ k,on,off for each feature k. Note that the data from the group of respondents who completed both the online and offline tasks enables us to estimate the covariance parameters. Given the population-level parameters, we can show that the conditional distribution of β i,k,off given β i,kj,on is a normal one, with mean µ i,k,off|on and variance σ 2 i,k,off|on as given by</p><p>where ρ k is the correlation coefficient between feature k's online and offline partworths. Note that µ i,k,off|on is also the maximum likelihood estimator of β i,k,off conditioned on β i,k,on because of normality. Therefore, under this model, conditioned on β i,k,on , the maximum likelihood estimates of a respondent's offline partworths are given by </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix C. Computation of the Asymptotic Variances</head><p>We now present the details of the computations we carried out to obtain the asymptotic variances corresponding to the maximum likelihood estimates of the offline partworths under the LME model. We compute the variances by inverting the Fisher information (FI) matrix, which we compute following theorem 1 in <ref type="bibr" target="#b24">Lenk et al. (1996)</ref>.</p><p>Our computations were carried out on the data collected as part of the study, described in Section 3. The study was carried out on n 20 products, selected using the D-optimal study design criterion. Product j is described by the length K feature vector x j , obtained by dummy-coding 13 discrete attribute levels into K 9 features. Collecting the feature vectors together, we obtain the following design matrix:</p><p>In our study, each respondent is exposed to the same design X and asked to rate the products in an offline, online, or an online followed by offline conjoint. We assume that the rating assigned by respondent i for product j follows the following model:</p><p>x jk +ε i,j,off , if j was evaluated offline, and</p><p>x jk +ε i,j,on , if j was evaluated online, where β i,0 is the intercept term; δ i is the offline fixed effect; and β i,off [β i, 1, off , . . ., β i, K, off ] u and β i,on [β i, 1, on , . . ., β i, K, on ] u are the offline and online partworth vectors, respectively. We assume that individual i independently samples β i,0 according to 1(µ 0 , σ 2 0 ), δ i according to 1(µ f , σ 2 f ), ε i,j,on and ε i,j,off according to 1(0, σ 2 ) for all j, and where diag(v) denotes the diagonal matrix with v as the diagonal.</p><p>When a respondent evaluates the n products in an offline conjoint and then the same n products in an online conjoint, the relation between the ratings collected and the underlying model parameters can be written more compactly as</p><p>For compactness of notation, we define</p><p>and say that the respondent evaluated the design X full when her or she completes an online followed by an offline conjoint. Similarly, we define</p><p>where X off (respectively, X on ) is obtained by replacing the upper (respectively, lower) block row with all zeros. We say that a respondent evaluated the design X off (respectively, X on ) if he or she completes only an offline (respectively, online) conjoint. Finally, define</p><p>We now invoke theorem 1 from <ref type="bibr" target="#b24">Lenk et al. (1996)</ref> to compute the FI matrix corresponding to the parametersμ [µ 0 , µ f , µ u ] u . Under the combined design, N off respondents complete an online followed by offline conjoint, and N on respondents complete only the online conjoint. It can be shown that the FI under this design is given by</p><p>where I m×m is an m × m identity matrix for any m. The first term in FI full corresponds to the FI from the respondents who complete an online followed by an offline conjoint (equivalently, a conjoint on the design X full ). The second term, on the other hand, corresponds to the FI from the respondents who complete only an online conjoint (equivalently, a conjoint on the design X on ). The counts N off and N on factor out because each of the N off (respectively, N on ) respondents evaluates the same set of profiles X full (respectively, X on ). In a similar manner, the FI under the offline only conjoint can be shown to be given by</p><p>and N is the number of respondents who complete an offline conjoint on the set of profiles X off .</p><p>For computing the above FI matrices, we used design matrix X reported in Section 3 and Σ full reported in Appendix A. Once we compute the FI matrices, we obtained the asymptotic variances under the combined and offline only designs corresponding to the estimate of µ k,off by taking the diagonal element corresponding to µ k,off in FI −1 full and FI −1 off , respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Endnotes</head><p>1 In Section 3.3, we elaborate on the likely sources of this difference between the verbal or pictorial description of the online study versus physical prototype offline presentation.</p><p>Dzyabura, Jagabathula, and Muller: Online vs. Offline Product Evaluations</p><p>Marketing <ref type="bibr">Science, 2019</ref><ref type="bibr">, vol. 38, no. 1, pp. 88-106, © 2019</ref> </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Learning from Data</title>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">S</forename><surname>Abu-Mostafa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Magdon-Ismail</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H-T</forename><surname>Lin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<publisher>AMLBook</publisher>
			<biblScope unit="volume">4</biblScope>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Logit models for sets of ranked items</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">D</forename><surname>Allison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Christakis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociol. Methodology</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="199" to="228" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Assessing the potential demand for electric cars</title>
		<author>
			<persName><forename type="first">S</forename><surname>Beggs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Cardell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hausman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Combining revealed and stated preferences data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ben-Akiva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bradley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Morikawa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Benjamin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Oppewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Lett</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="335" to="349" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Constructive consumer choice processes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Frances</forename><surname>Luce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="187" to="217" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A unified mixed logit framework for modeling revealed and stated preferences: Formulation and application to congestion pricing analysis in the San Francisco Bay area</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">R</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Castelar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Res. Part B: Methodological</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="593" to="616" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Joint mixed logit models of stated and revealed preferences for alternative-fuel vehicles</title>
		<author>
			<persName><forename type="first">D</forename><surname>Brownstone</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Bunch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Train</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Res. Part B: Methodological</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="315" to="338" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Exploiting rank ordered choice set data within the stochastic utility model</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Staelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="288" to="301" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An incentive-aligned mechanism for conjoint analysis</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="214" to="223" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Unstructured direct elicitation of decision rules</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dzyabura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Su</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">P</forename><surname>Gaskin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="127" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Active machine learning for consideration heuristics</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dzyabura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="801" to="819" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Offline assortment optimization in the presence of an online channel</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dzyabura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagabathula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2767" to="2786" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Leveraging the power of images in predicting product return rates. Working paper</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dzyabura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>El Kihal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ibragimov</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<pubPlace>New York University; New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Kinnear</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Taylor</surname></persName>
		</author>
		<title level="m">Modern Marketing Research: Concepts, Methods, and Cases (Cengage Learning</title>
				<meeting><address><addrLine>Mason, OH</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Reality check: Combining choice experiments with market data to estimate the importance of product attributes</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Feit</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Beltramo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Fred</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="785" to="800" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Market share constraints and the loss function in choice-based conjoint analysis</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Gilbride</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Brazell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="995" to="1011" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Conjoint measurement for quantifying judgmental data</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="355" to="363" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Disjunctions of conjunctions, cognitive simplicity, and consideration sets</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Befurt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Dzyabura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="485" to="496" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Specifying and testing econometric models for rank-ordered data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Hausman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">A</forename><surname>Ruud</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="83" to="104" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Knowledge activation: Accessibility, applicability, and salience</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Higgins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Social Psychology: Handbook of Basic Principles</title>
				<editor>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Higgins</surname></persName>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Kruglanski</surname></persName>
			<persName><surname>Eds</surname></persName>
		</editor>
		<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Guilford Press</publisher>
			<date type="published" when="1996" />
			<biblScope unit="page" from="133" to="168" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The importance of utility balance in efficient choice designs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Zwerina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="307" to="317" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Heuristics for product-line design using conjoint analysis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Sukumar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1464" to="1478" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Assortment planning: Review of literature and industry practice. Retail Supply Chain Management</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Kök</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Vaidyanathan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="175" to="236" />
			<pubPlace>Boston</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Efficient experimental design with marketing research applications</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">F</forename><surname>Kuhfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Tobias</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Garratt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="545" to="557" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Hierarchical Bayes conjoint analysis: Recovery of partworth heterogeneity from reduced experimental designs</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Desarbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="191" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Incorporating subjective characteristics in product design and evaluations</title>
		<author>
			<persName><forename type="first">L</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Kannan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">T</forename><surname>Ratchford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="182" to="194" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Beyond conjoint analysis: Advances in preference measurement</title>
		<author>
			<persName><forename type="first">O</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Feit</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Lett</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">3-4</biblScope>
			<biblScope unit="page" from="337" to="354" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">External effect adjustments in conjoint analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Orme</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Sawtooth Software Conf. (Sawtooth Software</title>
				<meeting>Sawtooth Software Conf. (Sawtooth Software<address><addrLine>Sequim, WA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="183" to="210" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">To have and to hold: The influence of haptic information on product judgments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Peck</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">L</forename><surname>Childers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="35" to="48" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Scikit-learn: Machine learning in Python</title>
		<author>
			<persName><forename type="first">F</forename><surname>Pedregosa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Varoquaux</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Michel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Thirion</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Grisel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Blondel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Machine Learn. Res</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="2825" to="2830" />
			<date type="published" when="2011-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Physical store beats online as preferred purchase destination for U.S. shoppers, according to PwC</title>
		<author>
			<persName><surname>Pricewaterhousecoopers</surname></persName>
		</author>
		<ptr target="http://www.prnewswire.com/news-releases/physical-store-beats-online-as-preferred-purchase-destination-for-us-shoppers-according-to-pwc-300032566.html" />
	</analytic>
	<monogr>
		<title level="m">PricewaterhouseCoopers LLP</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
	<note>Press release</note>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The choice process for graduate business schools</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">N</forename><surname>Punj</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Staelin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="588" to="598" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Mcculloch</surname></persName>
		</author>
		<title level="m">Bayesian Statistics and Marketing</title>
				<meeting><address><addrLine>Chichester, UK</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Trigger features on prototypes increase preference for sustainability</title>
		<author>
			<persName><forename type="first">J</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Macdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. Design Engrg. Tech. Conf. Comput. Inform. Engrg. Conf</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="V005T" to="6A" />
			<date type="published" when="2013" />
			<publisher>American Society of Mechanical Engineers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Integrated product design for marketability and manufacturing</title>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Lovejoy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Beach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="154" to="163" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Enriching scanner panel models with choice experiments</title>
		<author>
			<persName><forename type="first">J</forename><surname>Swait</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Andrews</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="442" to="460" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Top 10 algorithms in data mining</title>
		<author>
			<persName><forename type="first">X</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ross</forename><surname>Quinlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ghosh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Motoda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mclachlan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Knowledge Inform. Systems</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="37" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Quarterly retail e-commerce sales, 2nd quarter</title>
		<author>
			<persName><forename type="first">U</forename><forename type="middle">S</forename><surname>Bureau</surname></persName>
		</author>
		<ptr target="https://www.census.gov/retail/mrts/www/data/pdf/ec_current.pdf" />
		<imprint>
			<date type="published" when="2017-08-17" />
			<pubPlace>U.S. Census Bureau News</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<author>
			<persName><forename type="first">Jagabathula</forename><surname>Dzyabura</surname></persName>
		</author>
		<author>
			<persName><surname>Muller</surname></persName>
		</author>
		<title level="m">Online vs. Offline Product Evaluations</title>
				<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
