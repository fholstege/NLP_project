<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Modeling Page Views Across Multiple Websites with an Application to Internet Reach and Frequency Prediction</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName><forename type="first">Peter</forename><forename type="middle">J</forename><surname>Danaher</surname></persName>
							<email>p.danaher@mbs.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Melbourne Business School</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<postCode>3053</postCode>
									<settlement>Carlton</settlement>
									<region>Victoria</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
							<affiliation key="aff0">
								<orgName type="department">Melbourne Business School</orgName>
								<orgName type="institution">The University of Melbourne</orgName>
								<address>
									<postCode>3053</postCode>
									<settlement>Carlton</settlement>
									<region>Victoria</region>
									<country key="AU">Australia</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Modeling Page Views Across Multiple Websites with an Application to Internet Reach and Frequency Prediction</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 e 1526-548X 07 2603 0422</idno>
					</monogr>
					<idno type="DOI">10.1287/mksc.1060.0226</idno>
					<note type="submission">received July 18, 2005, and was with the author 3 months for 2 revisions; processed by Bruce Hardie.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:31+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please scroll down for article-it is on subsequent pages</head><p>With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning opportunities for individual professionals, and organizations of all types and sizes, to better understand and use O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>A key measure of website activity is page views, also known as page impressions or page requests, which are the number of distinct pages served to a Web user over the duration of his or her visit to a domain <ref type="bibr" target="#b1">(Bhat et al. 2002)</ref>. The underlying reason for the increasing importance of page views is that Web pages often carry banner ads or sponsored search links to other websites. Now that annual Internet advertising spending has reached $12.5 billion and is growing consistently and strongly (Internet Advertising Bureau 2006), accurate models for estimating campaign audiences are required <ref type="bibr" target="#b27">(Meskauskas 2003)</ref>. Models that produce well-known advertising audience measures such as reach and frequency are in particular demand to help give online advertising credibility alongside traditional advertising media such as television <ref type="bibr" target="#b40">(Smith 2003)</ref>.</p><p>A necessary starting point for a model of Internet advertising exposure is a probability model for page views. However, an alternative method to a probability model is an empirical distribution based on historical data. For instance, in recent years, Nielsen/Netratings and comScore Media Metrix have enlarged their Web user panels to the point where a probability model is seemingly redundant. In particular, the comScore Media Metrix data set in the United States totals 100,000 panelists, which allows an advertiser to accurately compile an empirical exposure distribution to an Internet ad campaign comprising the entire panel as well as demographic subgroups. Indeed, empirical distributions are the basis of Nielsen's and Telmar's online media planning software. In §5.1, we show that the real challenge for Internet media models is not to estimate the audience for a historical data set since the availability of large panels enables audience measures to be estimated empirically with high accuracy. Instead, the pertinent problem is to predict audiences for a time period in the future based on historical data. For example, none of the probability models considered by <ref type="bibr" target="#b20">Leckenby and Hong (1998)</ref> are adaptable to the predictive environment. Therefore, the purpose of this research is to develop a model that can accurately predict audience exposure measures for Internet advertising campaigns by using a model for page views. In doing so, we address the limitations of previous models by tailoring our model to the Internet environment, but we retain the ability to report media exposure measures that are familiar to traditional media buyers. Internet ad campaigns often run across several websites simultaneously, with sites being similar in purpose such as travel websites, so there is a resulting correlation in page view counts among the sites <ref type="bibr" target="#b24">(Li et al. 2002)</ref>. Such correlations will affect the audience measures for Internet campaigns <ref type="bibr" target="#b20">(Leckenby and Hong 1998)</ref> and thereby present a modeling challenge. Hence, our model of page views is multivariate without assuming independence between pairs of sites, and additionally allows for the possibility of different time periods for ad delivery on each website. Our results show our model to be significantly more accurate than all previous models including those based in empirical distributions from large panels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Modeling Page Views and Internet Advertising</head><p>There is a long history of models being used in traditional media such as television and print <ref type="bibr" target="#b4">(Chandon 1986</ref><ref type="bibr" target="#b10">, Danaher 1992</ref><ref type="bibr" target="#b21">, Leckenby and Kishi 1982</ref><ref type="bibr" target="#b34">, Rust 1986</ref>. Models have been used in these media primarily to estimate reach, the proportion of the target audience exposed to at least one ad; frequency, the average number of exposures among those reached; gross rating points (GRPs), the average number of exposures (with GRPs = reach × frequency); and the exposure distribution (ED), the proportion of the target audience exposed to none, just one, just two, etc., ads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Modeling Issues Specific to Online</head><p>Advertising For online media to be accepted by advertisers and advertising agencies, online publishers must also be able to apply traditional media language, particularly GRPs, to their medium <ref type="bibr" target="#b27">(Meskauskas 2003)</ref>. However, when it comes to online advertising there is a fundamental difference between the way advertising space is bought compared with offline media. <ref type="bibr">1</ref> The primary difference is that online campaigns are often purchased on the basis of "ad impressions." An online ad impression is some form of advertisement (e.g., banner, interstitial, pop up, etc.) that is served to a website's user during the course of a visit. A typical online ad campaign might comprise 50,000 to 200,000 ad impressions (http://computer. howstuffworks.com/banner-ad.htm). While a user is surfing a particular website, he downloads different pages depending on the links he clicks. As each page is assembled, advertisements are added to the page by the site's server. Each page served could have different ads embedded within it. However, the more pages a user requests the more likely it is that he will receive several exposures to the same ad, especially if he visits the site multiple times over several weeks. Hence, the key issue in the online environment is that users determine the rate of page view delivery depending on where and how often they click on items within a session. This contrasts with traditional media, where the broadcaster/publisher controls the delivery of advertisements to its audience.</p><p>Estimating the audience for an Internet advertising campaign is further complicated by issues such as possibly having multiple ads per page, ads on just the homepage, and frequency capping whereby websites limit the number of ads served to a computer by using "cookies." Handling these issues requires data not just from the page server, but also from the ad server. User centric Web browsing data (such as the comScore Media Metrix used in this study) has only page views and no record of ads served. Hence, we model page views/impressions which are conceptually similar to ad impressions, since all ads are served on Web pages. If an advertiser is fortunate enough to additionally have data on the advertising regime, then the "ad view data" simply replaces the page view data.</p><p>A further difference between online and offline media models is the data available for model fitting. Models in traditional media are generally limited to using published figures on single-vehicle reach and pairwise duplications <ref type="bibr" target="#b34">(Rust 1986</ref>). However, online media models usually have large-scale individuallevel panel data available, as detailed in §4.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Previous Page View and Internet</head><p>Advertising Models To the best of our knowledge, only one page view model exists, being a multivariate discretized version of the Tobit model developed by <ref type="bibr" target="#b24">Li et al. (2002)</ref>. Their use of the Tobit model is justified because a large proportion of Web users do not visit particular sites, creating a "spike" at zero page views for each website. In addition, page views are nonnegative integers, so the Tobit must be "discretized." Last, <ref type="bibr" target="#b24">Li et al. (2002)</ref> recognize the need to allow for correlations in page views across different website categories so they generalize the univariate Tobit model to one that has a multivariate normal distribution. They apply their model to page views of comScore Media Metrix data, as we do, but their primary purpose is to uncover patterns in browsing behavior across categories of websites like auction and portal sites and test the effects of user demographics on such browsing. Still, their model can be adapted to predicting Internet audiences, so we compare our model with their multivariate discretized Tobit in §5.4.</p><p>To date, only three nonproprietary models have been developed specifically for online advertising. Of these, the most comprehensive are <ref type="bibr" target="#b20">Leckenby and Hong's (1998)</ref> and <ref type="bibr" target="#b15">Huang and Lin's (2006)</ref> studies, with <ref type="bibr" target="#b41">Wood's (1998)</ref> model essentially a curve-fitting method rather than a formal model. Leckenby and Hong compare some well-known models from offline media such as the betabinomial distribution (BBD)  <ref type="bibr" target="#b28">(Metheringham 1964</ref>) and the Dirichlet-multinomial <ref type="bibr" target="#b22">(Leckenby and Kishi 1984)</ref>. To use these models, <ref type="bibr" target="#b20">Leckenby and Hong (1998)</ref> had to artificially aggregate the panel-based website exposure data in a way that forced it into the same format as that used in offline media. Rather than restricting the number of exposures to coincide with a prespecified time period, as done by <ref type="bibr" target="#b20">Leckenby and Hong (1998)</ref>, our model allows each person's exposure level to range from zero to infinity. This is more appropriate for the Internet, where there is varying exposure opportunity per website visitor. <ref type="bibr" target="#b15">Huang and Lin (2006)</ref> avoid the problems of <ref type="bibr" target="#b20">Leckenby and Hong's (1998)</ref> model by allowing exposures to range upward from zero, but their model requires the duration of advertising on each website to be the same and ignores duplication of exposure between websites. Our model does not have these limitations.</p><p>Proprietary models for reach and frequency prediction include Nielsen/Netratings' "WebRF" and Telmar's "WebPlanner" models. Both use individuallevel panel data to build an empirical exposure distribution. Another proprietary model is one developed by Atlas DMT (www.atlasdmt.com), which combines site-centric ad server information with comScore Media Metrix panel data <ref type="bibr" target="#b40">(Smith 2003)</ref>. No technical details about this model are available except that it is based on a simulation method, although <ref type="bibr" target="#b3">Chandler-Pepelnjak (2004)</ref> reports that the average prediction error for reach for this model is 20%. Later, we demonstrate that this is much higher than the 5% average prediction error for our model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Model Development</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Notation</head><p>A formal statement of the exposure distribution (ED) setup is as follows. Let X i be the number of exposures 2 a person has to media vehicle i,</p><formula xml:id="formula_0">X i = 0 1 2 i = 1 m,</formula><p>where m is the number of different vehicles. The exposure random variable to be modeled is X = m i=1 X i , the total number of exposures to an advertising schedule. Although X is a simple sum of random variables, two nonignorable correlations make modeling it difficult <ref type="bibr" target="#b8">(Danaher 1989)</ref>. One is the intravehicle correlation due to repeat viewing/visits to the same vehicle <ref type="bibr" target="#b8">(Danaher 1989</ref><ref type="bibr" target="#b31">, Morrison 1979</ref>) and the other is intervehicle correlation, where there might be an overlap in exposure to two vehicles.</p><p>In the case of the print media, for example, observed empirical EDs are known to be particularly "lumpy" due to strong intravehicle correlation. As a consequence, <ref type="bibr" target="#b7">Danaher (1988</ref><ref type="bibr" target="#b8">Danaher ( , 1989</ref><ref type="bibr" target="#b9">Danaher ( , 1991</ref> shows that it is necessary to first model the joint multivariate distribution of X 1 X 2 X m , from which the distribution of total exposures X = m i=1 X i can be derived. This is less of a problem with television EDs <ref type="bibr" target="#b34">(Rust 1986)</ref> where loyalty from episode to episode is generally moderate, with intra-exposure duplication factors of the order 0.28 <ref type="bibr" target="#b12">(Ehrenberg and Wakshlag 1987)</ref>. In addition, for the television environment there are more vehicle choices than for the print medium <ref type="bibr" target="#b19">(Krugman and Rust 1993)</ref> and this helps to reduce both intra-and intervehicle correlation. As a result, models for just X rather than the full multivariate X 1 X 2 X m are often adequate for television EDs, which tend to be smooth <ref type="bibr" target="#b35">(Rust and Klompmaker 1981)</ref>. The Internet has many more possible vehicles than even television and so it might be the case that Internet EDs are also relatively smooth. Indeed, <ref type="bibr" target="#b20">Leckenby and Hong (1998)</ref> have already noted that Internet EDs are reasonably well-behaved, that is, they tend to be smooth rather than lumpy. To assess the need for a model of the full joint distribution X 1 X 2 X m , in §3.5 we also develop a direct model for just X, which is an approximation to the model based on X 1 X 2 X m .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">One-Vehicle Model</head><p>In the case of Internet advertising, X i is the number of ad/page impressions a person has to website i, i = 1 m Over the course of a fixed time period, X i can range from 0 to infinity as there is no limit to the number of times a site can be visited and how many pages can be viewed.</p><p>Modeling the number of exposures a person has to website i in a fixed time period (say, a month) is analogous to the well-known problem in marketing of modeling the number of purchases a person has in a product category (say, in a year or month for a frequently purchased product). <ref type="bibr" target="#b14">Goodhardt et al. (1984)</ref> and <ref type="bibr" target="#b11">Ehrenberg (1988)</ref> show that the number of purchases, given a purchase rate i , is modeled accurately by a Poisson distribution with mean i . That is, the number of purchases follows a Poisson process, 3 conditional on a person's purchase rate i . To allow for heterogeneity in i across individuals, we assume i comes from a gamma distribution, as was also proposed by <ref type="bibr" target="#b11">Ehrenberg (1988)</ref> and <ref type="bibr" target="#b32">Morrison and Schmittlein (1988)</ref> to allow for heterogeneity in purchase rates in packaged goods. Compounding the X i i ∼ Poisson i with a gamma distribution results in the well-known negative binomial distribution (NBD) with mass function</p><formula xml:id="formula_1">Pr X i = x i r i i = x i + r i − 1 x i i i + 1 r i 1 i + 1 x i x i = 0 1 2 (1)</formula><p>where r i and i are the usual parameters for the gamma distribution. Hence, a reasonable model for ad exposures to a single website is the NBD (see also <ref type="bibr" target="#b15">Huang and Lin 2006)</ref>. We later show that it fits observed EDs very well.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Two-Vehicle Model</head><p>While the NBD is a natural model for one website and derives easily by making an analogy between website page impressions and category purchases, an extension to two websites is less obvious. Although <ref type="bibr" target="#b5">Chintagunta and Haldar (1998)</ref> have studied purchase timing across two categories, there are no models for the total number of purchases across two product categories. A naïve approach is to assume that page impressions across two websites are statistically independent. The bivariate mass function is then simply the product of the two marginal mass functions.</p><p>Given the vast number of websites, many of which have relatively few visitors, this may seem like a reasonable assumption. However, we obtained the pairwise correlations between the top 45 websites in our data and found many instances of reasonably high correlations. For example, the correlation between the two Web hosting sites angelfire.com and tripod.com is 0.56, while that between msn.com and msnbc.com is 0.22. Correlations of this order make the independence assumption questionable. <ref type="bibr" target="#b33">Park and Fader (2004)</ref> faced a similar issue to ours when examining the visit times between two websites. They use an exponential-gamma model for a single website and initially assume independence between the sites. Like us, they find the independence assumption to be unsupported by their data. Instead, they develop a model in which the marginal distributions are still exponential gamma, but allowance is made for a correlation between the univariate random variables. The bivariate model employed by <ref type="bibr" target="#b33">Park and Fader (2004)</ref> belongs to a general class of bivariate distributions developed by <ref type="bibr" target="#b38">Sarmanov (1966)</ref> and first applied by <ref type="bibr" target="#b23">Lee (1996)</ref> in the statistics literature. <ref type="bibr">4</ref> The general form of the Sarmanov bivariate distribution for X 1 X 2 is</p><formula xml:id="formula_2">f X 1 X 2 = f 1 X 1 f 2 X 2 1 + 1 x 1 2 x 2 (2)</formula><p>where f i X i is the marginal distribution for random variable X i and i x i are called "mixing functions," with the requirement that i t f i t dt = 0 Notice that the general form of this bivariate distribution is the product of the marginal distributions, with a "correction factor" to allow for correlation. This general bivariate distribution clearly has strong appeal in our application, where we would ideally like to have a bivariate model for page impressions that has NBD marginal distributions to retain the modeling accuracy and simplicity of the univariate model. Notice, however, that our bivariate model is different from that of <ref type="bibr" target="#b33">Park and Fader (2004)</ref>, since theirs has exponential-gamma marginals while ours has NBD marginals. Furthermore, they report only the bivariate case whereas we extend the bivariate to a multivariate version of the Sarmanov distribution to Web ad campaigns with up to 15 websites.</p><p>There is often a choice for the mixing functions, but <ref type="bibr" target="#b23">Lee (1996)</ref> recommends the appropriate mixing function for the NBD to be</p><formula xml:id="formula_3">i x i = e −x i − i 1 + i − e −1 r i (3)</formula><p>Now, substituting Equation (3) into Equation ( <ref type="formula">2</ref>) we obtain a model for the bivariate distribution of X 1 X 2 as</p><formula xml:id="formula_4">f X 1 X 2 = f 1 X 1 f 2 X 2 1+ e −x 1 − 1 1+ 1 −e −1 r 1 • e −x 2 − 2 1+ 2 −e −1 r 2 (4)</formula><p>where f i X i , i = 1 2 are NBD distributions with parameters r i and i , as given in Equation (1). Due to the property of the mixing functions, namely t i t f i t = 0, it is easy to verify that the marginal distributions of X 1 X 2 in Equation ( <ref type="formula">4</ref>) are NBD distributions. This bivariate advertising exposure model has the same functional form as one previously developed in the print media by <ref type="bibr" target="#b9">Danaher (1991)</ref>, namely the canonical expansion model. Danaher's developed for just two websites, whereas Internet ad campaigns can have many more than two sites. Our model can be applied to any number of websites, with the empirical results showing good predictive accuracy for as many as 15 websites in a campaign. In addition, they model intervisit times and visit rates, but we require a model for the count of the number of pages viewed at each of several websites. Hence, there is a fundamental difference in the underlying random variables between our application and that of <ref type="bibr" target="#b33">Park and Fader (2004)</ref>.  <ref type="bibr">(1991)</ref> model is a product of univariate marginal distributions with a correction factor to account for correlation in exposure between media vehicles. Another way to construct Equation ( <ref type="formula">4</ref>) is to use Equation ( <ref type="formula">2</ref>) to build a bivariate gamma distribution and then mix it with two conditionally independent Poisson distributions. <ref type="bibr" target="#b23">Lee (1996)</ref> gives a general expression for the correlation between random variables in the Sarmanov distribution. In the case of the bivariate NBD distribution in Equation ( <ref type="formula">4</ref>), the correlation between X 1 and</p><formula xml:id="formula_5">X 2 is corr X 1 X 2 = 1 − e −1 2 r 1 r 2 1 + 1 1 + 2 1 2 • 1 1 + 1 − e −1 r 1 +1 2 1 + 2 − e −1 r 2 +1</formula><p>(5) Therefore, X 1 and X 2 are independent if and only if = 0, so the parameter largely determines the correlation between exposure to two websites.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Model for Three or More Vehicles</head><p>To extend the bivariate model in Equation ( <ref type="formula">4</ref>) to m vehicles, we again draw on the Sarmanov model to allow for correlation in advertising exposures among websites. <ref type="bibr" target="#b23">Lee (1996)</ref> provides a generalization of the bivariate Sarmanov model to m variates, being</p><formula xml:id="formula_6">f X 1 X 2 X m = m i=1 f i X i 1 + j 1 &lt;j 2 j 1 j 2 j 1 x j 1 j 2 x j 2 + • • • + 1 2 m i x i (6)</formula><p>Equation ( <ref type="formula">6</ref>) is a series expansion of bivariate, trivariate, up to m-variate terms. Estimating parameters for such a model would require observed multivariate duplications among the m websites. To reduce the number of terms in the multivariate Sarmanov model, we truncate Equation ( <ref type="formula">6</ref>) after just the trivariate terms. This gives an approximation to the full Sarmanov expansion, with accuracy up to third-order terms. This means that bivariate and trivariate exposure interactions among the websites are modeled, but fourth-and higher-order interactions are not explicitly modeled. Again, this is very similar to the approximation made by <ref type="bibr" target="#b9">Danaher's (1991)</ref> canonical expansion model, but he truncated the full canonical expansion after just the second-order terms. We show later that even after truncating the multivariate Sarmanov model, the resulting website exposure model is still very accurate.</p><p>The multivariate model with truncation after thirdorder terms is</p><formula xml:id="formula_7">f X 1 X 2 X m = m i=1 f i x i r i i • 1 + j 1 &lt;j 2 j 1 j 2 exp −x j 1 − j 1 1 + j 1 − e −1 r j 1 • exp −x j 2 − j 2 1 + j 2 − e −1 r j 2 + j 1 &lt;j 2 &lt;j 3 j 1 j 2 j 3 exp −x j 1 − j 1 1 + j 1 − e −1 r j 1 • exp −x j 2 − j 2 1 + j 2 − e −1 r j 2 • exp −x j 3 − j 3 1 + j 3 − e −1 r j 3 (7)</formula><p>Since this model is a multivariate generalization of the NBD and has NBD marginals, we name it the multivariate negative binomial distribution (MNBD). Our model for X, the total number of exposures, can now be obtained from the multivariate distribution for X 1 X 2 X m by summing over the relevant probabilities as follows:</p><formula xml:id="formula_8">f X x = x 1 x m x 1 +•••+x m =x f X 1 X 2 X m x = 0 1 2 (8)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Model for Very Large Schedules</head><p>For advertising schedules with a very large number of sites (m ≥ 10 , the multivariate NBD model for X given by Equation ( <ref type="formula">8</ref>) takes a lot of computation time, making it impractical. A solution to this difficulty arises from a convenient additive property of the Poisson distribution, as we now explain.</p><p>Recall that we assume the conditional univariate distribution X i i is a Poisson distribution with mean i . In the multivariate case, the corresponding assumption is that X 1 X 2 X m are conditionally independent Poisson distributions, with respective parameters 1 2 m . It is easy to show that conditional on</p><formula xml:id="formula_9">1 2 m , X = m i=1 X i ∼ Poisson m i=1 i .</formula><p>Remembering that X and not X 1 X 2 X m is our ultimate modeling objective, the additive property of the Poisson distribution shows it is possible to get a direct model for the ED without first estimating a model for the full multivariate distribution. The trade-off is a reduction in prediction accuracy, as will be seen later.</p><p>We can think of m i=1 i as simply another parameter, denoted by . Then, as for the univariate NBD model, to allow for individual-level heterogeneity we assume that has a gamma distribution with parameters r * and * resulting in X ∼ NBD r * * . 5 Hence, the mass function for the large-schedule model is</p><formula xml:id="formula_10">f * X x = f * x r * * (9)</formula><p>where f * • denotes the NBD mass function as given by Equation ( <ref type="formula">1</ref>). Since this model is intended to approximate the full multivariate model in Equation ( <ref type="formula">8</ref>), we subsequently refer to it as the approximate NBD (ANBD).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Parameter Estimation-Full Model</head><p>It can be seen from Equation ( <ref type="formula">7</ref>) that only univariate marginals and bi-and trivariate associations are needed to model the joint probability of X 1 X 2 X m . Indeed, the model in Equation ( <ref type="formula">7</ref>) has NBD marginals, each with parameters r i and i , i = 1 m. Hence, a straightforward method for estimating r i and i for each website is to fit a univariate NBD separately to each website's observed univariate ED. As <ref type="bibr" target="#b14">Goodhardt et al. (1984)</ref> show, an efficient method for estimating the parameters of the NBD is the method of means and zeros <ref type="bibr" target="#b0">(Anscombe 1950</ref>). <ref type="bibr">6</ref> Here, the observed sample mean number of exposures to website i is fit to the parametric mean of each NBD, namely r i / i , and the observed nonreach (0th frequency of each univariate ED) is fit to f i 0 r i i = i / 1 + i r i , giving estimatesr i and i . A straightforward iterative Newton-Raphson method is required for this estimation.</p><p>The remaining parameters to be estimated are the second-and third-order measures of association among the websites, j 1 j 2 , 1 ≤ j 1 &lt; j 2 ≤ m and j 1 j 2 j 3 , 1 ≤ j 1 &lt; j 2 &lt; j 3 ≤ m. We start by discussing several possible methods for estimating j 1 j 2 , all of which we tried. The first is to use the observed bivariate exposure distribution and estimate each j 1 j 2 by maximum likelihood. The second is to use a method of moments-type estimator and equate the empirical correlation to the parametric correlation given in Equation (5). As each r i and i have already been estimated, an estimate of j 1 j 2 is obtained by solving for j 1 j 2 in Equation (5). A third possible estimator has its roots in the print media industry <ref type="bibr" target="#b4">(Chandon 1986</ref>) and is based on the unduplicated reach, meaning the proportion of people exposed to either one or both sites (any number of times) within a given time interval. For websites, this is now routinely being reported by ACNielsen's Nielsen/Netratings software, for example. One minus the unduplicated reach is the nonreach, which can be used to estimate the pairwise associations, as we now show.</p><p>Consider for the moment just the bivariate model, as given by Equation (4). The nonreach for two vehicles is</p><formula xml:id="formula_11">f 0 0 = f 1 0 f 2 0 1 + 1 0 2 0 (<label>10</label></formula><formula xml:id="formula_12">)</formula><p>where</p><formula xml:id="formula_13">f i 0 = f i 0 r i i and i 0 = 1 − i 1 + i − e −1 r i i = 1 2</formula><p>Now obtain the observed nonreach of two website vehicles and denote thisf 0 0 . Using ther i and i from the univariate ED estimation stage, from Equation ( <ref type="formula" target="#formula_11">10</ref>) we obtain a consistent estimate of as</p><formula xml:id="formula_14">= f 0 0 f 1 0 f 2 0 − 1 1 1 0 ˆ 2 0 (11)</formula><p>This method of parameter estimation is used for all m m − 1 /2 pairwise combinations of websites to obtain j 1 j 2 . We illustrate the estimation of j 1 j 2 with an example comprised of the websites aol.com, netflix.com, and travelzoo.com as given in To estimate the third-order association parameters, j 1 j 2 j 3 , 1 ≤ j 1 &lt; j 2 &lt; j 3 ≤ m, we use an analogous argument as for the second-order terms. The starting point is the trivariate Sarmanov model at the zero exposure levels for all three websites, which is <ref type="table" target="#tab_2">12 1 0 2 0 + 13 1 0 3 0   + 23 2 0 3 0 + 123 1 0 2 0 3 0  (12)</ref> Substituting the respective second-order estimates from Equation ( <ref type="formula">11</ref>) into Equation ( <ref type="formula">12</ref>) gives a consistent estimate of the third-order association:</p><formula xml:id="formula_15">f 0 0 0 = f 1 0 f 2 0 f 3 0 • 1 +</formula><formula xml:id="formula_16">123 = f 0 0 0 f 1 0 f 2 0 f 3 0 − 1 − 12ˆ 1 0 ˆ 2 0 − 13ˆ 1 0 ˆ 3 0 − 23ˆ 2 0 ˆ 3 0 • 1 1 0 ˆ 2 0 ˆ 3 0 (13)</formula><p>A very appealing feature of the estimators in Equations ( <ref type="formula">11</ref>) and ( <ref type="formula">13</ref>), which is not shared by the first two estimators discussed above, is that they result in very accurate estimates of reach, which is the most important measure of advertising audience size. This is because reach is one minus the nonreach, and the estimators in Equations ( <ref type="formula">11</ref>) and ( <ref type="formula">13</ref>) ensure an exact match between the model estimate and observed values of bivariate and trivariate nonreach. For four or more websites, the match is no longer exact but it is closer than we obtained for the first two estimators described above. Moreover, the estimators in Equations ( <ref type="formula">11</ref>) and ( <ref type="formula">13</ref>) are superior empirically when compared against maximum likelihood and methodof-moments estimators.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.7.">Parameter Estimation-Approximate Model</head><p>To estimate the two parameters of the ANBD model, we follow the common practice in marketing of using the method of means and zeros for the NBD <ref type="bibr" target="#b14">(Goodhardt et al. 1984)</ref>. First, we need a good estimate of the probability of zero exposures, i.e., nonreach. This can be obtained from the estimated nonreach given by the MNBD in Equation ( <ref type="formula">7</ref>). Hence, the MNBD is a crucial component of the ANBD. Second, the observed mean of X is simply the sum of the observed mean exposures for each website. With these estimates of mean exposures and nonexposure, estimates of r * and * can be obtained. 7</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Data</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Estimation Data</head><p>We use comScore Media Metrix data to fit and test our model. comScore employs a user-centric method of measurement, whereby a panel of Internet-enabled homes have all their Web browser activity monitored (see <ref type="bibr" target="#b6">Coffey 2001</ref> for particular details relating to Media Metrix methodology). Panelists install proprietary software on their computers that unobtrusively captures the URL, page impressions, and visit duration for each URL as they proceed through their Internet sessions. The Web activity is tied to a particular machine in the home rather than a particular person, allowing for the possibility of multiple machines within the same home. The data are aggregated to the domain level, enabling reporting of the total number of page impressions within that domain. In addition, if several Internet browsing sessions occur on the same day, data are aggregated across that day. <ref type="bibr">Moe and Fader (2004a, b)</ref> and <ref type="bibr" target="#b33">Park and Fader (2004)</ref> also use comScore data aggregated to the daily level. <ref type="bibr">8</ref> It is important to note that we do not use click stream data and do not have information on the navigation history within a website. Such detailed information is not required in our application, even if it were available.</p><p>Our particular comScore data come from the Wharton Research Data Service (www.wrds.upenn.edu), which stores a six-month sample of comScore panelist records from the United States for the months July through December 2002 and is available by subscription for research purposes. The panel size comprises 100,000 machines located within panelists' homes. <ref type="bibr">9</ref> At recruitment, each household reports a number of demographic variables, including the education level of the most educated person, household size, region, age of oldest member, income, presence of children, race, and the speed of the household's Internet connection. There is a long history of media planners targeting advertising campaigns at particular demographic groups <ref type="bibr" target="#b2">(Cannon 2001</ref><ref type="bibr" target="#b13">, Gal-Or and Gal-Or 2005</ref><ref type="bibr" target="#b17">, Iyer et al. 2005</ref>, which enhances the appeal of user-centric data, like comScore's panel.</p><p>As the data quantity is enormous, comprising over 120 MB each day, we take a representative subset of the full data set, as we now detail. A panel of 100,000 machines is clearly very large and a smaller panel size for a shorter time period could easily suffice without much loss of accuracy. Hence, we take a systematic random sample of every tenth panelist just for the 1 3 5 2 6 9 1 6 2 2 4 5 1 3 4 hotbar.com software 3 7 7 5 3 2 6 7 8 6 3 6 7 7 6 hotmail.com e-mail 7 2 4 1 2 7 1 2 9 4 7 6 3 7 0 iwon.com lottery 6 7 4 8 0 6 7 4 2 6 6 6 4 1 6 kazaa.com music 11 1 1 0 3 1 1 7 1 0 1 1 3 3 1 0 8 looksmart.com search 2 6 4 4 2 8 3 5 2 4 4 3 lycos.com portal 19 0 1 2 9 1 9 5 1 0 7 2 1 3 1 3 5 mamma.com search 5 6 2 8 5 6 2 9 7 1 2 6 mcafee.com software 3 0 1 6 0 3 3 1 7 5 3 0 1 4 6 msn.com portal 51 8 4 5 9 5 2 9 4 6 1 5 2 8 4 4 9 msnbc.com news 10 2 4 7 1 2 1 4 9 9 9 4 5 nascar.com sports 2 0 1 0 7 1 2 1 0 5 2 2 1 2 6 neopets.com entertainment 1 4 9 0 9 1 3 8 3 7 1 9 9 7 5 netflix.com movies 12 1 2 0 1 1 3 2 3 1 2 0 2 2 netscape.com portal 12 1 1 4 2 1 3 3 1 4 7   <ref type="table" target="#tab_4">2</ref> gives the reach for each website for the full subset of 10,000 households and for two demographic subsets, those where the most educated household member has a college degree and for households with children. It can be seen that yahoo.com has the highest reach by some way, even among this group of popular websites. There is not much variation in its reach across the demographic groups, showing its broad appeal. Contrast this with the children's site, neopets.com, which has a reach of 1.4% among all households but its reach is nearly 40% higher, at 1.9%, in households with children. In addition to reach, Table <ref type="table" target="#tab_4">2</ref> gives the average frequency, in other words, the mean number of page impressions for the month of September among those reached by the site. neopets.com is a good example of a website with low reach but high average frequency, meaning its users consume a high number of page impressions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Validation Method and Data</head><p>Previous models used to estimate advertising campaign EDs in traditional or online media have used the estimation data set to also evaluate the fit of the model <ref type="bibr" target="#b4">(Chandon 1986;</ref><ref type="bibr" target="#b9">Danaher 1991</ref><ref type="bibr" target="#b10">Danaher , 1992</ref><ref type="bibr" target="#b22">Leckenby and Kishi 1984;</ref><ref type="bibr" target="#b20">Leckenby and Hong 1998;</ref><ref type="bibr" target="#b34">Rust 1986</ref>). In the past, media model researchers have used part of the data such as first-insertion reach for each vehicle and bivariate reach across all pairs of vehicles to fit their models, then predicted the entire ED from this subset of the data. This is necessitated by media audience suppliers such as SMRB reporting only this limited amount of data in the print industry <ref type="bibr" target="#b34">(Rust 1986</ref>). In our application to online media, we have the entire data set at hand so there is no such limitation. In this situation, it is possible to obtain an empirical estimate of the ED by counting the number of households with none, just one, just two, etc., page impressions to a website or a combination of websites, seemingly making it unnecessary to use a model. However, we show later that our model is able to outperform an empirical estimate of the ED.</p><p>Media planners typically use data from an estimation period to predict the audience size to a campaign for a future time period. In the case of television, the time lag might be as much as six months to a year from the time of prediction to the actual airing of commercials <ref type="bibr" target="#b18">(Katz 2003)</ref>. Internet advertising lead times are much shorter, however. Due to the six-month duration and large size of the available comScore data set, we are able to simulate a more challenging prediction environment than has been possible for traditional media. A rigorous test of ours and other models is to use an estimation data set for model fitting, but then predict the reach and ED for a different group of households in a future time period. As mentioned above, we use a random sample of 10,000 panelists for the month of September 2002 for estimation, then pick a different random sample of 10,000 panelists for November 2002. This is more in keeping with what happens in media planning, where sample data are employed to predict future media audiences for the downstream population. In our case, the September data comprise the estimation sample, while the November validation sample of different people can be viewed as the "population."</p><p>As explained in §2.1, the way that Internet campaigns work is that a buyer purchases a fixed number of page/ad impressions from an online publisher. Visitors to the publisher's site are served up pages (with the embedded ads) in time order until the purchase quota is expended. Since users of the site have different visit behavior, the likelihood is that different visitors "consume" a different number of page/ad impressions over the duration of the campaign. This can create problems for advertisers, who may be trying to achieve a reach target but then find that purchasing a large number of impressions results in a small group of people being served the majority of the ad impressions (Chandler-Pepelnjak 2004), resulting in a shortfall in the actual reach delivered. <ref type="bibr">10</ref> Consider an example from our data set in which the total page impressions for travelzoo.com in September is 1,293 for the 10,000 panelists. In November, the total page impressions increase markedly to 2,129 for the same panel size of 10,000 but different people. The respective observed reach values for these two time periods are 8.7% and 12.4%. To enable us to use the full 30 days of validation data, we assume that an advertiser purchases 2,129 impressions on travelzoo.com. We then obtain the empirically derived reach and ED values for the validation data. Hence, in the case of travelzoo.com we use the estimation data for model fitting, which has only 1,293 page impressions, and somehow extend this to 2,129 page impressions to get an accurate prediction of reach in the validation sample. This is detailed in §5.1. To adjust our model for different page impression totals, it turns out that the NBD has a very convenient mathematical property that allows us to make this extension using just a simple rescaling of one of its parameters, as we now demonstrate. This property is not shared, for example, by the betabinomial distribution, which is a very common media model in everyday practice <ref type="bibr" target="#b21">(Leckenby and Kishi 1982)</ref> and has been previously used by <ref type="bibr" target="#b20">Leckenby and Hong (1998)</ref> for online campaigns.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Parameter Modification for Varying</head><p>Page Impressions We now show how the parameter of the NBD and the mixing functions of the Sarmanov model require only a straightforward modification to allow for different page impressions across the estimation and validation data sets.</p><p>For a single website, let X be the number of page impressions served in the time interval 0 T E for the estimation data set. For this total number of page impressions in the estimation sample, denote the sample mean number of page impressions per panelist as X E . Our NBD model parameterizes this mean number of page impressions per person as , with the NBD model assuming that X ∼ Poi and that ∼ gamma r . In the prediction data set, with time interval 0 T P , the mean number of page impressions per person is likely to change either due to more or less website activity or the fact that the prediction sample are completely different panelists. We parameterize the new mean as , that is, we simply multiply the mean from the estimation data set by , with &gt; 0. Due to the additive property of the Poisson distribution, it is not difficult to prove that for X ∼ Poi and ∼ gamma r , the unconditional distribution of X is NBD r / . Hence, the r parameter is the same across the NBD models applied to each respective data set but changes to / in the prediction data set. <ref type="bibr">Lilien et al. (1992, p. 34)</ref> demonstrate the same property of the NBD when it is applied to different observation periods of unequal duration.</p><p>We denote the sample mean number of page impressions in the prediction period as X P , and then we can equate the respective sample means to their parametric means under the NBD models. This gives r/ = X E and r/ / = X P , which implies that = X P / X E . For example, in our data set the number of page impressions for amazon.com in the November prediction month is about double that of the estimation month of September. Therefore, when applying the NBD to the November data, all that is required is to use the same parameter estimates for September but divide the parameter by two. A similar adjustment is required for the mixing functions 11 in Equation (3), where the parameter is replaced by / .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Test of the Multivariate NBD Model</head><p>In this section, we describe how the estimation data can be used to derive a simple empirical prediction of the ED. This empirical model is then compared with the newly developed models for ad campaigns ranging from 1 to 15 websites. We also show how the NBD model reveals how the reach for a website increases over the duration of a campaign.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Empirical Model for ED Prediction</head><p>The standard method for evaluating estimation accuracy for reach and frequency models is to compare the observed ("true") ED to that estimated by a model <ref type="bibr" target="#b4">(Chandon 1986;</ref><ref type="bibr" target="#b7">Danaher 1988</ref><ref type="bibr" target="#b8">Danaher , 1989</ref><ref type="bibr" target="#b9">Danaher , 1991</ref><ref type="bibr" target="#b10">Danaher , 1992</ref><ref type="bibr" target="#b20">Leckenby and Hong 1998;</ref><ref type="bibr" target="#b22">Leckenby and Kishi 1984;</ref><ref type="bibr" target="#b34">Rust 1986;</ref><ref type="bibr" target="#b36">Rust and Leone 1984)</ref>. Observed EDs are easily obtained from individual-level data by counting the total number of exposures each person has to the vehicles which comprise the campaign and then aggregating over individuals <ref type="bibr" target="#b20">(Leckenby and Hong 1998)</ref>.</p><p>As explained in §4.2, the availability of only partial information in traditional media data sets has required that models be developed to "fill in the gaps" left by the partial data. However, for Internet campaigns, panel data suppliers like comScore and Nielsen/Netratings provide enough data to enable empirical EDs to be developed, seemingly making models redundant. As explained above, a model is required for Internet campaigns to predict the ED for a future time period when the visit behavior of Web users may not be the same as for the estimation period, as we now illustrate.</p><p>Returning to our earlier three-website example, Table <ref type="table" target="#tab_2">1</ref> shows that the total page impressions for each site is higher in November than for September. That is, across two periods of identical duration (30 days), the "consumption" of pages is higher in the second period. Suppose an advertiser purchases 104,970, 5,768, and 2,129 page impressions, respectively, on the sites aol.com, netflix.com, and travelzoo.com. Advertising planning is based on the estimation period in September but the actual campaign goes "live" in the November validation period. Hence, it is more appropriate to predict the ED based on the November total page impressions. Table <ref type="table" target="#tab_8">3</ref> gives two observed distributions, respectively, for the estimation and validation periods. The two distributions are clearly not the same even though they both span 30 days, with the November ED placing greater weight on higher page impressions. One of the reasons the two distributions are not the same is that the page impressions are not equivalent over the two time periods. They are also based on different panelists. To get a comparable estimate of the ED for the two periods, there should be an identical number of page impressions in the estimation and validation data. This is easily achieved by appending October data to the estimation data set for the original 10,000 estimation panelists. For instance, for aol.com, Table <ref type="table" target="#tab_2">1</ref> shows that by the end of September some 97,701 page impressions have been consumed by the estimation panelists. For that same group of panelists, we now run into October, accumulating enough additional page impressions until exactly 104,970 page   <ref type="table" target="#tab_2">1 0 7  8 8  1 0 1  7 8  1 2 4  1 1 7  2  4 4  5 8  5 2  4 4  6 7  4 6  3  2 7  3 6  3 6  3 2  4 4  2 7  4</ref> 1 9 3 1 2 7 2 5 3 1 2 0 5 1 6 2 5 2 1 2 0 2 4 1 6 6 1 4 1 8 1 8 1 7 1 9 1 3 7 1 1 1 5 1 5 1 5 1 5 1 2 8 1 0 1 0 1 3 1 3 1 3 1 0 9 0 9 1 0 1 1 1 2 1 1 0 9 10 0 8 0 8 1 0 1 1 0 9 0 6 11+ 17 8 2 0 2 1 8 0 2 1 7 1 7 8 1 7 9</p><p>Number of parameters --10 12 * 6 0 * * RER, % --3 4 3 4 6 7 9 2 EPOR --12 0 1 4 7 2 0 9 2 7 8 * The ANBD has 2 parameters, as given in Equation ( <ref type="formula">9</ref>), plus 10 further parameters that are used to estimate nonreach, which is obtained from the MNBD. * * The empirical-based exposure distribution has no parameters.</p><p>impressions have been "consumed." In the case of aol.com, we had to append the first two days in October to achieve the required total number of impressions. The same "over run" is done for the other two websites so that they too have the same total page impressions as for the validation period. <ref type="bibr">12</ref> From this augmented September/October estimation data, we are able to obtain an empirical estimate of the future ED. Indeed, this appears to be the method used by Nielsen/Netratings; The description of their reach and frequency planning tool, WebRF, states that "WebRF uses actual respondent-level data acquired by measuring users' online activity, so there's no modeling-just real results" (www.netratings.com). The last column in Table <ref type="table" target="#tab_8">3</ref> shows this empirical distribution for our example campaign. Comparing it with the ED from the validation period shows that it overestimates the zeroth and first exposure levels, meaning it underestimates reach. The "true" reach is 50.1% whereas the empirical method estimates it at 45.5%. Contrast this with the MNBD model, which gives a much closer estimate of reach at 48.4%.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Test Design</head><p>Predicted EDs are obtained as shown earlier for the MNBD (Equation <ref type="formula">8</ref>) and the ANBD (Equation <ref type="formula">9</ref>). We contrast these new models with three other possible methods for predicting EDs. The first is the empirical ED just described and the second is a naïve independent model, where we assume that there is no association in exposures across different websites. This allows us to estimate a multivariate model that is the product of the marginal distributions. Essentially, this is the MNBD with all the bivariate and trivariate parameters set to zero. <ref type="bibr" target="#b33">Park and Fader (2004)</ref> also use a model assuming independence as a benchmark for their bivariate model which allowed for correlation in website visit timing. The third model is <ref type="bibr" target="#b24">Li et al's. (2002)</ref> multivariate discretized Tobit model for page views. Although their model allows for the inclusion of demographic variables, we do not make use of this possibility as none of the other models incorporate demographics. This makes the models consistent in their use of data.</p><p>The empirical model described in §5.1 appears to be the basis of Nielsen's proprietary WebRF model. Another proprietary model has been developed by Atlas DMT for forecasting the reach and frequency for Internet campaigns. However, it requires both usercentric panel data and data on the number of ads served to a visitor using cookies placed on a user's PC. As we do not have the cookie information, we can not reproduce this method, which is based on simulation (Chandler-Pepelnjak 2004). However, we can at least compare the accuracy of our models with that of the Atlas DMT simulation method, as Chandler-Pepelnjak (2004) reports that its average prediction error for reach is 20%. We do not compare our models with those examined by <ref type="bibr" target="#b20">Leckenby and Hong (1998)</ref> since, as noted above, models like the BBD are not adaptable to the predictive setting that is germane to Internet media planning.</p><p>The test schedules in our model comparison range from m = 1 to 15. For the single-vehicle schedules (m = 1), all 45 websites in Table <ref type="table" target="#tab_4">2</ref> are estimated with univariate NBDs as given by Equation (1). For all  <ref type="table" target="#tab_2">10 6  2 8 3  1 2 6  3 5 9  9 8  2 8 3  0 74</ref>  other values of m, we randomly select 200 advertising schedules. We find that when the number of websites exceeds m = 8, models that require estimation of the full joint distribution such as the MNBD and multivariate Tobit become computationally very slow. For this reason, we fit only the ANBD and the empirical methods for schedules with m = 9 through 15.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Definition of Prediction Errors</head><p>Denote f x = f X = x andf x , respectively, as the observed and predicted probabilities of the ED for the validation data of November, x = 0 1 2 The two measures of error employed are the same as used previously by <ref type="bibr" target="#b7">Danaher (1988</ref><ref type="bibr" target="#b8">Danaher ( , 1989</ref><ref type="bibr" target="#b9">Danaher ( , 1991</ref>, <ref type="bibr" target="#b20">Leckenby and Hong (1998)</ref>, and <ref type="bibr" target="#b22">Leckenby and Kishi (1984)</ref>: relative error in reach (RER), where</p><formula xml:id="formula_17">RER = f 0 − f 0 1 − f 0</formula><p>and error in the exposure probabilities over schedule reach (EPOR), where</p><formula xml:id="formula_18">EPOR = 20 x=0 f x − f x 1 − f 0</formula><p>We limited the EPOR range of exposures to 20 as beyond that almost all observed exposure frequencies are zero. An example of these fit statistics is given in Table <ref type="table" target="#tab_8">3</ref>, showing that for the Internet advertising campaign comprised of the three websites given in Table <ref type="table" target="#tab_2">1</ref>, the MNBD model gives the smallest values of RER and EPOR followed, respectively, by the ANBD, independence, and empirical methods.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4.">Results of Model Comparison</head><p>The average prediction errors for the MNBD, ANBD, independent, Tobit, and empirical models are given in Table <ref type="table" target="#tab_9">4</ref>. Results are shown for the entire panel of 10,000 households plus the demographic subgroups of households where the highest education attainment is a college degree and households with children.</p><p>5.4.1. Single-Website Schedules. For single-website schedules, the MNBD and independent models reduce to the NBD so only the NBD is reported. The RER and EPOR error measures are both lower for the NBD than for the Tobit and empirical models. The standard errors for the RER and EPOR measures confirm that the NBD gives a statistically significantly better fit than the next-best model, at the 5% level, for almost all the comparisons. <ref type="bibr">13</ref> As an illustration of the how the NBD predicts accurately, consider the website travelzoo.com in Table <ref type="table" target="#tab_2">1</ref>. Its reach across the <ref type="bibr">Marketing Science 26(3), pp. 422-437, © 2007 INFORMS</ref> 30 days of September is 8.7% for 1,293 page impressions. For the validation period, the number of page impressions increases to 2,129, resulting in a much higher reach of 12.4%. Using the adjustment method described in §4.3, the value of 1.65 gives an adjusted value of 1 053/1 65 = 0 6397. Using Equation ( <ref type="formula">1</ref>), the estimate of reach in the validation period is 1 − 0 6397/ 1 + 0 6397 0 1362 = 12 0%, very close to the actual reach value of 12.4% in the validation data. Contrast this with the empirical model, which gives a much lower reach estimate of only 8.8%. For this example, and in general across all 45 websites, the adjustment of the NBD to different page impression totals is superior to simply using raw data to compile a prediction of the downstream ED.</p><p>5.4.2. Reach Velocity and Acceleration. As described above, since Internet users rather than Web publishers largely determine the delivery of page impressions, online campaigns require an understanding of the rate at which users are exposed to the ads. For example, suppose that two websites both have a cumulative reach of 10% after 30 days but the first site achieves 9.5% reach after just 5 days, while the second site takes 25 days to attain 9.5%. It is apparent that page impressions served after the fifth day on the first website are delivering mostly repeat impressions to visitors previously exposed to the campaign, while the second site is still reaching new visitors after the fifth day.</p><p>Knowledge of the rate at which page impressions are "consumed" by site users is important when planning how to handle responses to an ad campaign. Consider, for instance, a campaign of 100,000 banner ad impressions for a discount travel package where customers must call an 800 number. If most of the impressions are delivered in 3 days, more call center staff are required than if the 100,000 impressions are spread evenly over 15 days.</p><p>To describe the rate at which reach builds over time for Internet ad campaigns, we introduce the concept of reach velocity. Using Equation (1), under the NBD model for a single website, the reach is defined as</p><formula xml:id="formula_19">reach = 1 − Pr X = 0 r = 1 − 1 + r</formula><p>The NBD model is fit using D days of estimation data (D = 30 in §4.1). Recall from §4.3 that the NBD has the flexibility to accommodate different time periods with a straightforward modification of the parameter <ref type="bibr">(Lilien et al. 1992, p. 34)</ref>. All that is required is to replace with / t/D , where t is time measured in days. Denote the reach at time t as R t , which is</p><formula xml:id="formula_20">R t = 1 − D t + D r</formula><p>Reach velocity is just the rate of change of reach, being reach_velocity</p><formula xml:id="formula_21">= dR t dt = r D D t + D r+1</formula><p>Since r &gt; 0 and &gt; 0, reach velocity is always positive and, therefore, reach increases with time as expected. However, because we expect diminishing returns in reach, the rate of increase in velocity, i.e., reach acceleration, should be decreasing. This is confirmed by taking the second derivative of reach to obtain reach_acceleration =</p><formula xml:id="formula_22">dR 2 t dt 2 = − r r + 1 D 2 D t + D r+2</formula><p>which is clearly always negative in sign.</p><p>We illustrate the concepts of reach velocity and acceleration with an example from our data. It happens that the three websites amazon.com, netflix.com, and netscape.com have very similar reach values after 30 days, being 12.8%, 12.1%, and 12.1%, respectively. Despite this similarity, the growth rates in reach for these three sites are very different. We calculate the reach velocity and acceleration curves using the appropriate parameter estimates for each website and show these curves in Figure <ref type="figure">1</ref>. It can be seen that at day one, netscape has the highest reach velocity and netflix has the lowest. netscape's higher velocity over netflix stops at day five, after which netflix's reach velocity always exceeds that of netscape. In fact, netflix's reach velocity is almost linear while the other two sites have more of a hyperbolic curve. This is also evident in the reach acceleration curves, where netflix is close to zero while amazon and netscape begin with large negative acceleration that rapidly converges to zero.</p><p>Figure <ref type="figure">1</ref> illustrates that both amazon and netscape quickly achieve close to their final reach while netflix has more of a linear growth toward its ultimate reach of 12.1%. The average frequency after 30 days for amazon, netflix, and netscape are 5.2, 2.0, and 14.2, respectively, showing that netscape in particular levels out in reach after about 5 days, beyond which subsequent page impressions are delivered primarily to those already reached. This results in a big buildup in frequency for netscape, with possibly excessive frequency delivered for the same reach that can be obtained for amazon and netflix. 5.4.3. Medium-Sized Schedules. For small-to medium-sized schedules (m = 2 to 8), Table <ref type="table" target="#tab_9">4</ref> shows that the MNBD and the ANBD are the most accurate models for estimating reach, with RER values of only 5.9% on average. 14 This is significantly lower Velocity at the 5% level than for the independent, Tobit, and empirical models and is also the case for the other two demographic groups. The same pattern emerges when examining the EPOR measure, which tests prediction accuracy over the entire ED. Again, all differences are significant except among the MNBD, ANBD, and empirical models in the "all households" demographic. Overall, the MNBD is the most accurate, followed by the ANBD, then the empirical, independent, and Tobit models. The finding that the independent model performs poorly underscores the observation by <ref type="bibr" target="#b33">Park and Fader (2004)</ref> that independence among websites (be it for visit times or page impressions) is an unreasonable assumption. While the Tobit model gives reasonable predictions for reach, it predicts very badly for the remaining part of the ED as evidenced by its high EPOR values.</p><p>It is encouraging to see that even though the NBD approximation to the MNBD is not as accurate as the full multivariate model, it still performs as well or better than the empirical method. However, the ANBD can not completely replace the MNBD since it relies on the MNBD for its parameter estimation. 5.4.4. Large Schedules. For large schedules (m = 9 to 15), only the ANBD and empirical models are computationally feasible as they do not require the initial estimation of a full joint distribution. The ANBD again significantly outperforms the empirical model across all demographics. Notice also that the average RER and EPOR values for both models are somewhat lower than for small/medium schedules. This is consistent with <ref type="bibr" target="#b20">Leckenby and Hong's (1998)</ref> observation that observed Internet EDs become smoother for a larger number of websites, much the same as for television which also has many channels <ref type="bibr" target="#b35">(Rust and Klompmaker 1981)</ref>. A smoother observed distribution is easier to model with the ANBD which is itself a smooth distribution, whereas the MNBD can capture the lumpiness in observed EDs which is more prevalent when m = 2 to 6.</p><p>We mentioned in §5.2 that there are two known proprietary models for forecasting Internet EDs. From the description on Nielsen/Netratings's website, the WebRF model appears to be similar to what we have called the empirical model in Table <ref type="table" target="#tab_9">4</ref>. This model is a very robust and challenging benchmark, based on individual-level data that can be filtered to accommodate alternative demographic targets as is commonplace in advertising. Table <ref type="table" target="#tab_9">4</ref> shows that the RER errors for the empirical model are reasonably consistent across the demographic groups for m = 1 to 8, but the EPOR errors are higher for smaller sample sizes. For instance, the smallest demographic group, homes where someone is college educated, has the higher EPOR value across all schedule sizes. Hence, it appears that the empirical model is vulnerable to small sample sizes. In contrast, the MNBD and ANBD models are less vulnerable to smaller sample sizes, particularly for small-to medium-sized schedules.</p><p>The other proprietary model in everyday use is Atlas DMT's simulation method. We are not able to <ref type="bibr">Marketing Science 26(3), pp. 422-437, © 2007 INFORMS</ref> replicate this model but we can compare its reach performance with that of the models in Table <ref type="table" target="#tab_9">4</ref>. <ref type="bibr" target="#b3">Chandler-Pepelnjak (2004)</ref> reports that the average RER value for Atlas DMT's model is 20%. Table <ref type="table" target="#tab_9">4</ref> shows that none of the average RER values for any of the 4 models are higher than 20%, the closest being 16% for the Tobit model in college-educated households. In particular, the MNBD and ANBD models always have RER values much lower than 20%, averaging 5% over all schedule sizes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusion</head><p>The two new models developed for website page views and applied to predicting Internet EDs, the MNBD and its approximation ANBD, appear to have much merit. The MNBD, in particular, is derived from an elegant class of multivariate models introduced by <ref type="bibr" target="#b38">Sarmanov (1966)</ref>, extended by <ref type="bibr" target="#b23">Lee (1996)</ref>, and introduced to the marketing literature by <ref type="bibr" target="#b33">Park and Fader (2004)</ref>. An attractive feature of the Sarmanov model that makes it especially suitable for Internet audience prediction is that it allows each marginal distribution to have a negative binomial distribution while simultaneously accounting for association among websites. Even though there are millions of websites, when popular sites or sites with similar purpose are considered, there is frequently a high overlap that reduces reach but increases frequency. Knowledge of these dynamics is critical when advertising in any media. For instance, a model which assumes independence among websites performed very poorly at predicting Internet reach and the ED.</p><p>Previous efforts to model Internet EDs have adapted models used for traditional media, in particular, the BBD <ref type="bibr" target="#b20">(Leckenby and Hong 1998)</ref>. However, we show that such models do not capture a fundamental difference between exposure to online and offline ads. This makes the NBD, rather than the BBD, an appropriate model for each website because visitors to a site can receive anything from none to several thousand impressions over a time period. An additional feature of the NBD that makes it ideal for Internet EDs is its ability to adjust itself for different page impression totals. This expansion/contraction property is not shared by any of the models used for traditional media.</p><p>Of the two new models, the MNBD gives the best prediction accuracy but becomes computationally slow for a large number of websites. When advertising schedules have eight or fewer websites, the MNBD model is recommended. Beyond that number of websites, the ANBD gives slightly less accuracy but is much faster. Nevertheless, both new models perform better than existing proprietary models. It now remains to test these models on other Internet data sets to ensure their general applicability.</p><p>The validation method we employ has not been used in prior media modeling efforts and sets a more demanding standard for media model testing. In the past, models have used the same data for validation as for parameter estimation. This has been necessitated by a lack of data over a long time period and the use of only partial information from the estimation data set for model fitting, typically limited to univariate and bivariate information. The comScore data used here has no such limitation, however, and has revealed shortcomings in the use of empirical distributions when they are used for prediction. Such practice is commonplace in television, for example, where individual-level peoplemeter records are used to predict ratings some way into the future (three to six months). Empirical EDs are also used by proprietary Internet reach and frequency prediction software. We find that even though the empirically-based predictions are very good, they suffer from what might be termed "empirical overfitting." That is, they are limited to the visit behavior of estimation-period panelists, which ends up being somewhat different from that observed among the "population" in the validation period as little as one month later. Such overfitting is well-documented for econometric models used in forecasting applications. It is encouraging to see that our model does not suffer from overfitting to the same extent as the empirical model and, therefore, the MNBD must be capturing some fundamental website visit processes without being badly affected by the vagaries of particular panelists at particular time periods.</p><p>Such empirical overfitting could also prove problematic in CRM efforts, for example, where a sample of customer data is used to find patterns in purchase behavior that may not be as prevalent in the population of customers or potential customers. Further work is required to better understand what can and can not be reliably inferred from customer databases used for downstream prediction.</p><p>It is worth noting that the multivariate count model developed here can also be applied to situations other than Internet page views. For example, our generalization of the NBD could be used to model purchases across several categories of packaged goods. Finally, although not explicitly addressed here, the MNBD and ANBD models can be used as the basis for optimal media planning in much the same way that the BBD has been used for traditional media (see, for example, <ref type="bibr" target="#b26">Little and</ref><ref type="bibr">Lodish 1969, Rust 1986)</ref>. In this study, we also introduce additional factors to the usual media scheduling optimization problem, namely a variable number of impressions served to each website user and different rates of increase in reach even when the final reach achieved is the same. Incorporating these additional dimensions to media </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Danaher:</head><label></label><figDesc>Modeling Page Views Across Multiple Websites Marketing Science 26(3), pp. 422-437, © 2007 INFORMS 423</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>*</head><label></label><figDesc>Standard error in parentheses.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 1Reach Velocity and Acceleration for Amazon, Netflix, and Netscape</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Danaher:</head><label></label><figDesc>Modeling Page Views Across Multiple Websites Marketing Science 26(3), pp. 422-437, © 2007 INFORMS 437 planning introduces further computational challenges and should be a fertile area for future research.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1</head><label>1</label><figDesc>Data and Parameter Estimates for an Online Advertising Schedule</figDesc><table><row><cell></cell><cell></cell><cell cols="3">Univariate parameter estimates</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Pairwise parameters</cell><cell></cell></row><row><cell></cell><cell cols="3">Estimation period (September)</cell><cell cols="3">Validation Period (November)</cell><cell>Non-reach</cell><cell cols="2">netflix.com</cell><cell cols="2">travelzoo.com</cell></row><row><cell>Website</cell><cell cols="2">Page impressionsr i</cell><cell>i</cell><cell>Page impressions</cell><cell></cell><cell cols="2">ifi 0</cell><cell>f 00</cell><cell></cell><cell>f 00</cell><cell></cell></row><row><cell>aol.com</cell><cell>97 701</cell><cell>0 0922</cell><cell>0 0094</cell><cell>104 970</cell><cell>1.07</cell><cell>0.0088</cell><cell>0.6501</cell><cell>0.586</cell><cell>0.847</cell><cell>0.614</cell><cell>1.736</cell></row><row><cell>netflix.com</cell><cell>2 449</cell><cell>0 1091</cell><cell>0 4453</cell><cell>5 768</cell><cell>2.36</cell><cell>0.1891</cell><cell>0.8795</cell><cell>-</cell><cell>-</cell><cell>0.812</cell><cell>1.886</cell></row><row><cell>travelzoo.com</cell><cell>1 293</cell><cell>0 1362</cell><cell>1 053</cell><cell>2 129</cell><cell>1.65</cell><cell>0.6397</cell><cell>0.9131</cell><cell>-</cell><cell>-</cell><cell>-</cell><cell>-</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1</head><label>1</label><figDesc>(full details on the data are given later in §4.1). The univariate NBD parameters are estimated by the method of means and zeros, while the bivariate j 1 j 2 parameters are estimated with Equation (11).</figDesc><table><row><cell>For example,</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc>Top 45 Websites and Their Reach and Frequency for Various Demographics</figDesc><table><row><cell></cell><cell></cell><cell cols="2">All households,</cell><cell cols="2">College educated,</cell><cell cols="2">Household with</cell></row><row><cell></cell><cell></cell><cell cols="2">n = 10 000</cell><cell cols="2">n = 2 865</cell><cell cols="2">children, n = 4 420</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Average</cell><cell></cell><cell>Average</cell><cell></cell><cell>Average</cell></row><row><cell>Website name</cell><cell>Site type</cell><cell>Reach, %</cell><cell>frequency</cell><cell>Reach, %</cell><cell>frequency</cell><cell>Reach, %</cell><cell>frequency</cell></row><row><cell>about.com</cell><cell>portal</cell><cell>8 8</cell><cell>4 5</cell><cell>1 0 1</cell><cell>4 2</cell><cell>1 0 1</cell><cell>4 6</cell></row><row><cell>aim.com</cell><cell>messaging</cell><cell>4 6</cell><cell>3 5</cell><cell>5 5</cell><cell>3 7</cell><cell>6 1</cell><cell>3 6</cell></row><row><cell>altavista.com</cell><cell>search</cell><cell>4 6</cell><cell>8 1</cell><cell>5 2</cell><cell>1 0 2</cell><cell>5 0</cell><cell>7 2</cell></row><row><cell>amazon.com</cell><cell>retail</cell><cell>12 8</cell><cell>5 2</cell><cell>1 4 3</cell><cell>5 7</cell><cell>1 3 8</cell><cell>5 7</cell></row><row><cell>angelfire.com</cell><cell>hosting</cell><cell>8 6</cell><cell>4 6</cell><cell>9 1</cell><cell>5 5</cell><cell>1 0 8</cell><cell>4 8</cell></row><row><cell>aol.com</cell><cell>portal</cell><cell>35 0</cell><cell>2 7 9</cell><cell>3 6 2</cell><cell>2 8 4</cell><cell>3 8 1</cell><cell>2 9 1</cell></row><row><cell>ask.com</cell><cell>search</cell><cell>5 0</cell><cell>5 6</cell><cell>5 0</cell><cell>5 7</cell><cell>5 8</cell><cell>4 9</cell></row><row><cell>bonzi.com</cell><cell>software</cell><cell>2 6</cell><cell>8 9</cell><cell>2 2</cell><cell>7 8</cell><cell>2 6</cell><cell>7 9</cell></row><row><cell>cnet.com</cell><cell>service</cell><cell>3 6</cell><cell>2 4</cell><cell>4 5</cell><cell>2 7</cell><cell>3 5</cell><cell>2 4</cell></row><row><cell>cnn.com</cell><cell>news</cell><cell>10 3</cell><cell>7 5</cell><cell>1 3 1</cell><cell>9 0</cell><cell>1 0 6</cell><cell>7 7</cell></row><row><cell>ebay.com</cell><cell>auction</cell><cell>21 7</cell><cell>3 3 8</cell><cell>2 1 7</cell><cell>3 3 0</cell><cell>2 3 1</cell><cell>3 3 2</cell></row><row><cell>excite.com</cell><cell>portal</cell><cell>4 6</cell><cell>2 1 5</cell><cell>4 6</cell><cell>2 1 1</cell><cell>4 9</cell><cell>2 3 2</cell></row><row><cell>expedia.com</cell><cell>travel</cell><cell>6 9</cell><cell>6 1</cell><cell>9 1</cell><cell>6 4</cell><cell>6 2</cell><cell>6 0</cell></row><row><cell>ezboard.com</cell><cell>messaging</cell><cell>3 5</cell><cell>1 4 4</cell><cell>3 9</cell><cell>8 4</cell><cell>4 4</cell><cell>1 3 9</cell></row><row><cell>flowgo.com</cell><cell>greetings</cell><cell>5 6</cell><cell>4 3</cell><cell>4 2</cell><cell>2 4</cell><cell>4 8</cell><cell>3 6</cell></row><row><cell>gamespot.com</cell><cell>games</cell><cell>1 9</cell><cell>8 2</cell><cell>2 7</cell><cell>9 7</cell><cell>2 6</cell><cell>7 4</cell></row><row><cell>gator.com</cell><cell>software</cell><cell>25 1</cell><cell>2 4 6</cell><cell>2 4 4</cell><cell>2 6 9</cell><cell>2 6 9</cell><cell>2 3 1</cell></row><row><cell>go.com</cell><cell>portal</cell><cell>14 5</cell><cell>1 4 8</cell><cell>1 7 3</cell><cell>1 5 9</cell><cell>1 6 4</cell><cell>1 4 4</cell></row><row><cell>gohip.com</cell><cell>portal</cell><cell>1 8</cell><cell>2 7 0</cell><cell>1 2</cell><cell>2 3 5</cell><cell>2 2</cell><cell>2 4 0</cell></row><row><cell>google.com</cell><cell>search</cell><cell>22 7</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table</head><label></label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 3</head><label>3</label><figDesc>Comparison of the Observed and Estimated EDs for the Example Online Schedule in Table 1</figDesc><table><row><cell>Page</cell><cell cols="2">Observed distribution, %</cell><cell></cell><cell></cell><cell>Model</cell><cell></cell></row><row><cell>impressions</cell><cell>Estimation</cell><cell>Validation</cell><cell>MNBD</cell><cell>ANBD</cell><cell>Independent</cell><cell>Empirical</cell></row><row><cell>0</cell><cell>5 5 7</cell><cell>4 9 9</cell><cell>5 1 6</cell><cell>5 1 6</cell><cell>4 6 5</cell><cell>5 4 5</cell></row><row><cell>1</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 4</head><label>4</label><figDesc>Average Errors for Alternative Models Across Different Demographic Groups</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Demographic group</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">All households,</cell><cell cols="2">College educated,</cell><cell cols="2">Households with</cell></row><row><cell></cell><cell></cell><cell cols="2">n = 10 000</cell><cell cols="2">n = 2 865</cell><cell cols="2">children, n = 4 420</cell></row><row><cell>Number of websites</cell><cell>Model</cell><cell>RER, %</cell><cell>EPOR, %</cell><cell>RER, %</cell><cell>EPOR, %</cell><cell>RER, %</cell><cell>EPOR, %</cell></row><row><cell>1 (45 schedules)</cell><cell>NBD</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We distinguish between banner ads and a rapidly growing form of online advertising revenue, namely paid search advertising(IAB  2006). Paid search advertising is the primary source of revenue for Google.com, for example. Our model is best suited to the situation where banner ads are placed on a website but can accommodate sponsored links, as they are conveyed by pages served up to Web users who may view the links, then click on them.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">For Internet advertising, by "exposure" we mean an ad impression. As mentioned earlier, since our data do not have explicit information on ad impressions, only page views/impressions, throughout this paper we consider an exposure and a page impression to be synonymous.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Website users can accrue page impressions over a month-long period by having multiple visits to the site and/or spending more time on a site during their visits. In the category purchase situation, this is analogous to multiple store trips and greater quantity purchased at each trip, respectively. While it might be of interest to model the way in which page impressions are accumulated, it is not necessary in this application. A sufficient statistic for reach and frequency estimation is simply the total number of page impressions.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">When modeling page views across multiple websites, we can not simply adapt Park and Fader's (2004) model since theirs is</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">It is not the case that we are assuming that each i has a gamma distribution and that their sum is another gamma distribution. We initially set = i only as a parameter and then later allow for heterogeneity in by permitting it to come from a flexible distribution, being the gamma distribution in this case.6  We also fit the NBD by maximum likelihood and found very little difference in parameter estimates and model fit.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">This parameter estimation method ensures that the reach predictions for the multivariate NBD in Equation (7) will agree identically with those of the approximation given by Equation (9).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8"><ref type="bibr" target="#b33">Park and Fader (2004)</ref>, in particular, report that daily aggregations are not problematic as multiple visits to the same site on the same day are not common for the vast majority of websites.9 Even though a house may have more than one machine, we use the terms machine and household interchangeably.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">A practical solution to this problem is to impose "frequency capping," but this depends on the use of cookies.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">We make no modification of the parameters because they are measures of association and we find it is reasonable to assume they are constant across the September and November time periods.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="12">If it happened that the page impressions for November were less than for September, then we would truncate the September impressions to less than 30 days to get a match with November.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">The only nonsignificant differences are for EPOR in the "all households" group and RER in the "college-educated" group when comparing the NBD and empirical models.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14">Recall that the ANBD always agrees with the MNBD reach estimate because it uses the MNBD reach estimate as input to its parameter estimation by the method of means and zeros.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The author thanks comScore Media Metrix for supplying the data used in this study.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Sampling theory of the negative binomial and logarithmic distributions</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">J</forename><surname>Anscombe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="358" to="382" />
			<date type="published" when="1950" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Measuring users&apos; Web activity to evaluate and enhance advertising effectiveness</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bhat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Bevans</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sengupta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="97" to="106" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Addressing new media with conventional media planning</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Cannon</surname></persName>
		</author>
		<ptr target="http://jiad.org/vol1/no2/cannon/index.html" />
	</analytic>
	<monogr>
		<title level="j">J. Interactive Advertising</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">J</forename><surname>Chandler-Pepelnjak</surname></persName>
		</author>
		<ptr target="www.atlasdmt.com" />
		<title level="m">Forecasting reach, frequency and GRPs on the Internet. Atlas Digital Marketing Technologies</title>
				<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">A Comparative Study of Media Exposure Models</title>
		<author>
			<persName><forename type="first">J.-L</forename><forename type="middle">J</forename><surname>Chandon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<pubPlace>Garland, New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Investigating purchase timing behavior in two related product categories</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Chintagunta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Haldar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="43" to="53" />
			<date type="published" when="1998-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Internet audience measurement: A practitioner&apos;s view</title>
		<author>
			<persName><forename type="first">S</forename><surname>Coffey</surname></persName>
		</author>
		<ptr target="http://jiad.org/vol1/no2/coffey/index.html" />
	</analytic>
	<monogr>
		<title level="j">J. Interactive Advertising</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A log-linear model for predicting magazine audiences</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Danaher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="356" to="362" />
			<date type="published" when="1988-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">An approximate log-linear model for predicting magazine audiences</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Danaher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="473" to="479" />
			<date type="published" when="1989-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A canonical expansion model for multivariate media exposure distributions: A generalization of the duplication of viewing law</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Danaher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="361" to="367" />
			<date type="published" when="1991-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Some statistical modeling problems in the advertising industry: A look at media exposure distributions</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Danaher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. Statistician</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="254" to="260" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S C</forename><surname>Ehrenberg</surname></persName>
		</author>
		<title level="m">Repeat Buying: Facts, Theory and Applications</title>
				<meeting><address><addrLine>London</addrLine></address></meeting>
		<imprint>
			<publisher>Charles Griffin and Company Limited</publisher>
			<date type="published" when="1988" />
		</imprint>
	</monogr>
	<note>2nd ed</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Repeat-viewing with peoplemeters</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S C</forename><surname>Ehrenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wakshlag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising Res</title>
		<imprint>
			<biblScope unit="page" from="9" to="13" />
			<date type="published" when="1987-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Customized advertising via a common media distributor</title>
		<author>
			<persName><forename type="first">E</forename><surname>Gal-Or</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Gal-Or</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="253" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">The Dirichlet: A comprehensive model of buying behavior</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Goodhardt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S C</forename><surname>Ehrenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Chatfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Statist. Soc. A</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="621" to="655" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Modeling the audience&apos;s banner ad exposure for Internet advertising planning</title>
		<author>
			<persName><forename type="first">C.-Y</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C.-S</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="23" to="37" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<ptr target="http://www.iab.net/news/pr_2006_04_20.asp." />
		<title level="m">IAB/PwC release full year 2005 Internet ad revenue figures</title>
				<imprint>
			<date type="published" when="2006-04-20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">The targeting of advertising</title>
		<author>
			<persName><forename type="first">G</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Soberman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="461" to="476" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Villas-Boas</note>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Media Handbook: A Complete Guide to Advertising</title>
		<author>
			<persName><forename type="first">H</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Media Selection, Planning, Research and Buying</title>
				<meeting><address><addrLine>Mahwah, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates, Inc</publisher>
			<date type="published" when="2003" />
		</imprint>
	</monogr>
	<note>2nd ed</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The impact of cable and VCR penetration on network viewing: Assessing the decade</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Krugman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rust</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="67" to="73" />
			<date type="published" when="1993-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Using reach/frequency for Web media planning</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Leckenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising Res</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="7" to="20" />
			<date type="published" when="1998-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">How media directors view reach/frequency estimation</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Leckenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kishi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="64" to="69" />
			<date type="published" when="1982-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The Dirichlet-multinomial distribution as a magazine exposure model</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Leckenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kishi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="100" to="106" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Properties and applications of the Sarmanov family of bivariate distributions</title>
		<author>
			<persName><forename type="first">M.-L</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. Statist.: Theory Methods</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1207" to="1222" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Modeling category viewership of Web users with multivariate count models</title>
		<author>
			<persName><forename type="first">S</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Liechty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Montgomery</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">25</biblScope>
			<pubPlace>Pittsburgh, PA</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon Graduate School of Industrial Administration</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Working Paper</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Marketing Models</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Lilien</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Kotler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">S</forename><surname>Moorthy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>Prentice Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">A media planning calculus</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D C</forename><surname>Little</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Lodish</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="1969" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Reach and frequency-Back in the spotlight. iMedia Connection, www.imediaconnection.com</title>
		<author>
			<persName><forename type="first">J</forename><surname>Meskauskas</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Measuring the net cumulative coverage of a print campaign</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">A</forename><surname>Metheringham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising Res</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="23" to="28" />
			<date type="published" when="1964-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Capturing evolving visit behavior in clickstream data</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Moe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Interactive Marketing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="19" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Dynamic conversion behavior at e-commerce sites</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Moe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="326" to="335" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Purchase intentions and purchasing behavior</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Morrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="65" to="74" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Generalizing the NBD model for customer purchases: What are the implications and is it worth the effort?</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Schmittlein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Bus. Econom. Statist</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="159" />
			<date type="published" when="1988-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Modeling browsing behavior at multiple websites</title>
		<author>
			<persName><forename type="first">Y.-H</forename><surname>Park</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="280" to="303" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Advertising Media Models: A Practical Guide. Lexington Books</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rust</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<pubPlace>Lexington, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Improving the estimation procedure for the beta binomial TV exposure model</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Klompmaker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="442" to="448" />
			<date type="published" when="1981-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The mixed-media Dirichletmultinomial distribution: A model for evaluating televisionmagazine advertising schedules</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">T</forename><surname>Rust</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Leone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="89" to="99" />
			<date type="published" when="1984-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A model of TV show loyalty</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Sabavala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Morrison</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising Res</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="35" to="43" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Generalized normal correlations and twodimensional Frechet classes</title>
		<author>
			<persName><forename type="first">O</forename><forename type="middle">V</forename><surname>Sarmanov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Doklady (Soviet Math.)</title>
		<imprint>
			<biblScope unit="volume">168</biblScope>
			<biblScope unit="page" from="596" to="599" />
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">United States demand for Internet access</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Savage</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Waldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Network Econom</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="228" to="246" />
			<date type="published" when="2004-09" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Online reach and frequency: An update</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">L</forename><surname>Smith</surname></persName>
		</author>
		<ptr target="http://www.mediasmithinc.com/white/msn/msn042003.html." />
		<imprint>
			<date type="published" when="2003-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Internet ad buys-What reach and frequency do they deliver?</title>
		<author>
			<persName><forename type="first">L</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising Res</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="21" to="28" />
			<date type="published" when="1998-01" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
