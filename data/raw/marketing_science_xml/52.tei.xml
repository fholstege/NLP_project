<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Introduction to the Special Issue on Marketing Science and Field Experiments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Leif</forename><surname>Nelson</surname></persName>
							<email>leif_nelson@haas.berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Haas School of Business</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<postCode>94720</postCode>
									<settlement>Berkeley</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Duncan</forename><surname>Simester</surname></persName>
							<email>simester@mit.edu</email>
							<affiliation key="aff1">
								<orgName type="department">Sloan School of Management</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<postCode>02142</postCode>
									<settlement>Cambridge</settlement>
									<region>Massachusetts</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">K</forename><surname>Sudhir</surname></persName>
							<email>k.sudhir@yale.edu</email>
							<affiliation key="aff2">
								<orgName type="institution">Yale School of Management</orgName>
								<address>
									<postCode>06520</postCode>
									<settlement>New Haven, Connecticut</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Introduction to the Special Issue on Marketing Science and Field Experiments</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
					</monogr>
					<idno type="DOI">10.1287/mksc.2020.1266</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please scroll down for article-it is on subsequent pages</head><p>With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning opportunities for individual professionals, and organizations of all types and sizes, to better understand and use O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The marketing literature has recently seen a surge of papers using field experiments. Although this has been partly catalyzed by the relative ease of field experimentation in digital settings, field experiments are increasingly feasible even in some nondigital settings. From a scientific perspective, field experiments offer some advantages over other research methods. When designed well, they can help avoid concerns about endogeneity and selection that often hinder causal inference when using historical data. They can also aid in the validation of theories in real-world settings with fewer modeling assumptions. But, in addition to the potential operational burdens, field experiments also have potential limitations for inference. Notably, it may be difficult to isolate the behavioral mechanisms underlying the findings, and it is generally difficult to answer counterfactuals that are not represented by one of the experimental conditions. In such cases, field experiments can be valuable complements to traditional laboratory experiments or model-based analysis of historical data. The goal of the special issue is to provide further impetus for research using field experiments, especially by diversifying its range of substantive questions and methodological applications.</p><p>This editorial is organized as follows. Section 2 summarizes the characteristics of the submissions and the papers accepted/rejected and provides takeaways for scholars. Section 3 presents additional suggestions on how field experiments can complement research in quantitative, behavioral, and managerial marketing. Section 4 concludes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Special Issue</head><p>We summarize the characteristics of the submissions and accepted papers and our broad takeaways from the process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Characteristics of Submitted and</head><p>Accepted Papers As a source of guidance for future submissions, we compare the characteristics of the accepted manuscripts with those of the rejected manuscripts. We begin by describing the characteristics of the submitted papers. We received a total of 61 submissions for the special issue. As we finalize the special issue, 60 of the submissions have received final decisions with nine papers accepted (15%) and the remaining 51 papers rejected. The 61 manuscripts include a total of 167 unique authors; the accepted papers include 26 unique authors.</p><p>The submissions to the special issue cover an impressive range of topics though there was concentration in certain areas. Advertising and marketing communications are the most common substantive topics (48% of submitted papers), followed by pricing (21%) and sales and service employee incentives (8%). The growth in the use of field experiments to study advertising-related topics reinforces an earlier trend. <ref type="bibr" target="#b18">Simester (2017)</ref> reviews the field experiments published in the major quantitative marketing journals between 1995 and 2014. 1 Prior to 2010, pricing topics dominate with relatively few papers on advertising. However, this pattern is reversed in the papers published after 2010 with many of the more recent papers focused on advertising (particularly digital advertising). Within these broad areas, there are relatively few submissions on the same topics. Some topics for which we had multiple submissions include food choices (seven papers), charitable giving (three), product recommendations (three), multitask incentives (two), retirement savings (two), popularity information (two), and restaurant menus (two).</p><p>Figure <ref type="figure" target="#fig_0">1</ref> summarizes the marketing channels in which the experimental manipulations occurred. Digital channels contribute approximately 50% of the submitted papers. This proportion is similar for both published and submitted papers. In-person and direct mail experiments are also well represented. Telephone and email experiments are rare and are included in the "other" category.</p><p>We also classify the papers according to their disciplinary focus. To do so, we examined the research cited in the literature review and used to motivate the research question. The dominant disciplinary focus is behavioral; 59% of the submitted papers have a behavioral focus and 45% have a quantitative focus (some papers fall into both categories, and one paper is in neither category). Notably, the proportion of papers with a behavioral focus is similar between both the submitted and published papers.</p><p>The accepted papers highlight possible misconceptions about what is required to publish field experiments. In particular, the published papers do not always satisfy criteria that some might believe necessary for publication. For example, randomization is not a requirement. Two of the accepted papers report field experiments that do not rely upon randomization. One paper <ref type="bibr" target="#b15">(Mohan et al. 2020)</ref> rotates treatments between consecutive hours in a cafeteria, and in the other <ref type="bibr" target="#b23">(Wolters et al. 2020)</ref>, the two treatments are implemented in consecutive periods. The proportion of papers that rely upon randomization (75%) is almost identical for accepted and rejected papers.</p><p>Reporting multiple field experiments is also not a requirement for acceptance. Only one of the nine accepted papers reports multiple field experiments, compared with 11 (22%) of the rejected papers. Perhaps surprisingly, three of the accepted papers that focus on substantive issues do not investigate the mechanism behind their results. <ref type="bibr" target="#b9">Hershfield et al. (2020)</ref> study how framing messages to encourage savings affects savings decisions. Although the authors do not investigate the underlying mechanisms, they do discuss how their results compare with previous work on related mechanisms. <ref type="bibr" target="#b23">Wolters et al. (2020)</ref> study the profitability of customer referral reward programs and contrast their findings with previous work that focuses solely on response rates. Goswami and Urminsky (2020) study the framing of appeals in a charitable giving setting. They creatively compare their findings with both theory-and expert-based predictions. Their results illustrate the limitations in both theory and expert opinion.</p><p>There are several characteristics of the accepted papers that distinguished them from the rejected papers. When the accepted papers do investigate the underlying mechanism, they use very robust methods. For example, two of the accepted papers supplement their field experiments with laboratory experiments <ref type="bibr" target="#b13">(Mislavsky et al. 2020</ref><ref type="bibr" target="#b15">, Mohan et al. 2020</ref>, and one of the papers <ref type="bibr" target="#b16">(Munz et al. 2020</ref>) is able to observe intermediate process measures. In addition, two of the papers study the underlying mechanism by measuring conditional average treatment effects (CATEs) and contrasting the treatment effects across different customer segments. Although many of the rejected papers also estimate CATEs, it is notable that both accepted papers that use this approach <ref type="bibr" target="#b10">(Huang et al. 2020</ref><ref type="bibr" target="#b12">, Li et al. 2020</ref>) randomize the covariates that they employ for this segmentation. As a result, they rule out the possibility that variation in the covariates could reflect an unobserved intervening variable. In contrast, when CATEs are used in many of the rejected papers, they rely upon available covariates that are not randomized as part of the experiment.</p><p>The accepted papers are more likely to have preregistered experiments. Four of the nine published papers were preregistered compared with only 2 of the 51 rejected papers.</p><p>The accepted papers are also more likely to make a methodological contribution. Only 5 of the 51 rejected papers (10%) offer a methodological contribution compared with three of the nine accepted papers (33%). The three accepted papers include <ref type="bibr" target="#b13">Mislavsky et al. (2020)</ref>, who investigate when people dislike experiments, and <ref type="bibr" target="#b16">Munz et al. (2020)</ref>, who investigate how to more effectively target charitable donors by matching names. The most econometrically sophisticated of the accepted papers is <ref type="bibr" target="#b22">Tian and Feinberg (2020)</ref>, who propose a method for using experimental data to optimize price menus when a firm wants Nelson, Simester, and Sudhir: Introduction to the Special Issue on Marketing Science and Field Experiments to offer a discount to customers who sign up for a longer subscription. The method has to adjust for selection in order to anticipate how varying prices affect both how many new customers sign up for a subscription and what duration length the new customers choose.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Primary Reasons Papers Were Rejected</head><p>Unfortunately, a review of the rejected papers reveals that a lot of effort is invested into papers that would require a lot of additional work to be accepted. To identify the primary reasons for rejection, we review the area editor (AE) reports for all 51 rejected papers. We group these reasons into five broad categories, and in Figure <ref type="figure" target="#fig_1">2</ref>, summarize the proportion of rejected papers that fall into each category. Many of the papers are rejected for more than one reason, and so a single paper may fall into more than one category.</p><p>The most common reason cited for rejection is a lack of sufficient contribution. In some cases, this can be attributed to opportunism. When a firm presents researchers with an opportunity to implement a field experiment or provides data from a past experiment, it is tempting to pursue this offer. Although some opportunities lead to substantial contributions, merely documenting a field experiment itself alone is not a sufficient contribution. Publication requires a wellmotivated research question together with an interesting set of findings. Rejection because of a lack of contribution occurs for three primary reasons:</p><p>• Either the experimental variation does not speak to a research question that is of academic interest (16% of rejections) or the research question is already addressed in the literature (37% of rejections).</p><p>• The setting is so specific and obscure that there are concerns about generalizability (29% of rejections).</p><p>• The results are small, inconsistent, unsurprising, and/or have no managerial implications (33% of rejections).</p><p>After contribution, the second most frequent reason cited for rejection, is the failure to convincingly investigate the underlying mechanism. There are often obstacles that hinder investigation of the mechanism when using field experiments. Circumstances generally limit the range and number of experimental treatments, and it is often not possible to run multiple studies to rule out alternative explanations. Collecting process measures is also often infeasible.</p><p>Authors recognize these challenges and employ a wide range of methods to shed light on the mechanism. These include laboratory experiments, reporting heterogeneity in treatment effects, collecting survey data, or using ancillary data as process measures (such as email open rates or website browsing). However, each of these approaches introduces its own challenges. Reviewers question the interpretation of heterogenous treatment effects if the covariates are not randomized and question the value of laboratory data if the experimental context is different in the laboratory than in the field. As a result, reviewers often recommend papers to be rejected because the investigations of the underlying mechanism are not convincing.</p><p>The high number of papers that are rejected (at least in part) because they do not document the underlying mechanism may seem inconsistent with our earlier statement that three of the published papers do not document the mechanisms behind their findings. The acceptance of these three papers makes it clear that explaining the mechanism is not a requirement for publishing field experiments that make a substantive contribution (it is also generally not relevant for methodological papers). However, if the paper does not establish the mechanism, then the reported effects must be of unusual interest. Authors face a trade-off: either establish the mechanism or expect to be held to a higher contribution threshold for your findings.</p><p>Errors in the design, implementation, or analysis of experiments are relatively rare. Although the AE reports often highlight concerns or opportunities to improve the analysis, this is generally not the primary reason a paper is rejected. Perhaps the only issue that is recurring (and, even then, occasional) is selection bias. This is typically introduced in one of two ways: (a) in the study design when there are criteria used to qualify customers for the study or (b) in the study analysis when customers are segmented based upon posttreatment customer behavior. When this occurs, authors are generally aware of the issue and attempt either to control for it or address it through interpretation (generally not successfully).</p><p>Perhaps surprisingly, poor exposition is raised as one of the reasons for rejection in 27% of the Notes. The figure summarizes the primary reasons cited in the area editor reports for rejecting the 51 rejected papers. For example, 73% of the papers were rejected because of concerns about the contribution. A single paper could be rejected for multiple reasons, and so the percentages sum to more than 100%.</p><p>Nelson, Simester, and Sudhir: Introduction to the Special Issue on Marketing Science and Field Experiments Marketing Science, 2020, vol. 39, no. 6, pp. 1033-1038, © 2020 INFORMS rejected papers. The description of the hypotheses, experiments, and/or analysis sometimes lack clarity or are incomplete. Given the effort required to design and implement a field experiment, we might expect that authors would also invest considerable effort into documenting the experiments in their papers. In many cases, it appears that many of these authors do not invest enough effort. However, to fully understand the manipulations and findings for reviewers and readers, extensive discussion of both the context and the implementation is required. Papers that are rejected for expositional reasons typically have too few details, and so the review team is unable to fully evaluate the findings.</p><p>Eight of the papers were rejected for lack of fit with the special issue. These include papers that document findings from a natural experiment. These papers typically lack a control group and instead rely upon a before versus after comparison for identification. There are also some papers rejected because the experiments are essentially laboratory experiments conducted using participants sourced in the field. For these papers, the phenomenon under investigation has essentially no specific connection to the participants sourced for the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Where We Expect Field Experiments</head><p>Can Further Advance the Marketing Literature</p><p>We now consider how field experiments can serve as a bridge to further research in the quantitative, behavioral, and strategy literatures in marketing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Quantitative Research</head><p>We note some areas in which exogenous randomized variation with field experiments can complement existing areas of quantitative work in structural models, training targeting policies, and adaptive experimentation.</p><p>3.1.1. Structural Models. First, it is generally difficult with field experiments to answer counterfactuals that are not represented by one of the experimental conditions. Without some additional modeling, it is hard to predict outcomes in counterfactual situations or optimize the marketing mix in terms of levels for which there is no experimentation. Structural models are particularly ideal for such counterfactual analysis. Typically, exogenous identifying variation and/or instruments in naturally occurring data are necessary to identify and estimate the structural models. However, field experiments with randomization might be an alternative and complementary approach to generate exogenous variation in economic/behavioral levers. There are two benefits to this: First, it helps to estimate structural models that help answer counterfactual questions. Second, such experimental variation coupled with structural models can also test and uncover underlying mechanisms, thus enriching findings from field experiments. For example, <ref type="bibr" target="#b6">Dubé et al. (2017)</ref> use a structural model to show that customer response to price variation, when bundled with a charitable donation, can be attributed to self-signaling. Without a structural model, it is unlikely that standard methods would have been able to provide convincing evidence of this mechanism. Similarly, <ref type="bibr" target="#b11">Kim et al. (2020)</ref> exploit randomization in transfers at a bank (though not a field experiment) to understand the mechanism by which a salesperson's private information affects sales outcomes through changes in acquisition and maintenance behavior. Decomposing the effects of private information on acquisition and maintenance outcomes requires a structural model. Further, they conduct counterfactuals around job design and incentive design given private information. Field experiments can also offer a second role: providing a model-free validation of the trained policy. Conveniently, a single field experiment can be used to evaluate the performance of any trained policy as long as the experiment includes each of the marketing actions that a policy might recommend <ref type="bibr" target="#b20">(Simester et al. 2020)</ref>.</p><p>These two roles of field experiments in targeting are highlighted in <ref type="bibr" target="#b5">Dubé and Misra (2019)</ref>, who study how to personalize prices using two field experiments. They use the first experiment to provide training data for their models and use the second experiment to validate the trained model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.3.">Adaptive Experimentation.</head><p>The ability to perform real-time, automated experimentation in digital settings, especially in the areas of pricing, advertising, and targeting, allows firms to balance the gains from exploration relative to the cost of lost profits from experimentation. <ref type="bibr" target="#b14">Misra et al. (2019)</ref> is an illustration of this type of research. <ref type="bibr" target="#b8">Hansen et al. (2020)</ref> show that Nelson, Simester, and Sudhir: Introduction to the Special Issue on Marketing Science and Field Experiments such adaptive and automated experimentation may lead to collusive outcomes when the effects of competitor pricing are not accounted for.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Behavioral Research</head><p>As noted in <ref type="bibr" target="#b21">Sudhir (2016)</ref>, there is a large missed opportunity at the intersection of behavioral and quantitative marketing, and behavioral field studies can be an excellent means by which such a bridge may be created. <ref type="bibr" target="#b21">Sudhir (2016)</ref> notes several challenges that arise from the way in which behavioral and quantitative scholars evaluate papers, and they make it harder to publish such papers that seek to bridge the divide. It is, therefore, gratifying that four of the papers being published in this special issue are behavioral.</p><p>In an ideal world, a field experiment leverages the simplicity of random assignment to establish the unambiguous identification of a relationship that is empirically sound, theoretically insightful, and practically consequential. As can be seen from the review of the accepted papers, that trifecta of quality is seldom achieved. However, acceptable deviations from the ideal help to highlight how field experiments can appeal to multiple groups of readers. Insufficient attention to the underlying process is frequently a kiss of death for a traditional paper submitted to a classic behavioral journal, but that is, in part, because most studies in behavioral journals are only interested in the extent to which they can identify a new understanding of consumer behavior. A field experiment runs that relationship backward: because the behavior being investigated is intrinsically interesting, there is less of a demand for delivering a perfect explanation. A laboratory experiment showing variation in hypothetical purchase behavior is interesting only if that variation can be explained and such an explanation potentially could be generalized. A field experiment showing variation in actual purchase behavior is interesting because of that variation almost regardless of whether it is readily explainable. Quantitative and behavioral researchers can feel both these trade-offs, and though it is inevitably the case that they have different value functions for different shortcomings, field experiments allow them to think about the same research in some of the same ways.</p><p>The last decade has seen a tremendous evolution in scientific practices in the behavioral sciences, and it is worth thinking about where field experimentation and marketing science both fit in with these changes. The evolution starts with a recognition that the selective reporting of treatments, measures, and analyses can make it easier for researchers to falsely conclude that they have found a new truth even when there is no true relationship to find. That recognition leads to increases in sample sizes and more transparent disclosure of materials and methods in the posting and sharing of data and materials and in the adoption of preregistration. These changes came quickly in traditional experimental psychology but considerably more slowly in consumer research. Field experimentation accelerates that evolution. It is a telling fact that four of the nine published papers in this issue were preregistered, whereas only 2 of the 51 rejected manuscripts were. Preregistration allows a reader to recognize when analyses are confirmatory and when they are exploratory. Just as important, preregistration allows researchers to show off when their results are confirmatory and not just a product of late-stage p-hacking. Because field experiments are often time-consuming to plan, expensive to run, and slow to complete (outside of digital settings), researchers really want to make sure that they generate informative (and publishable) findings. In practice, that means that sample sizes tend to be considerably larger, measures and manipulations are more likely to be shared, and everything is more likely to be preregistered. All behavioral science benefits from open science and preregistration, but those benefits are particularly salient for the consideration of field experimentation.</p><p>Marketing science may not be a traditional outlet for the consumer researcher, but it could be an outlet for the consumer research most committed to replicable findings. Looking forward, it is worth thinking more broadly about the potential value of collaboration between quantitative and behavioral researchers. It is unrealistic to think that everyone will start reading everyone else's journals and even less realistic to think that they will all start asking the same questions or using the same tools to answer them. Nevertheless, it is more plausible to think that researchers from either discipline might start to see how some research problems could benefit from contributions from others. Perhaps that might mean a behavioral researcher recognizing how novel econometrics could allow a closer understanding of complex data. Or, perhaps, it might mean that an economic theorist might see opportunities for seeing ideas tested and refined through behavioral experimentation. Any such possibilities are necessarily speculative, but we see field experiments (both here and elsewhere) as potential vehicles for those collaborations. We would like behavioral and quantitative scholars to view marketing science as a natural outlet in which those collaborations are most likely to find a home.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Marketing Strategy Research</head><p>Much of the field experimental focus in quantitative marketing research tends to be in tactical elements of the marketing mix, such as pricing, advertising, and product design, which are easily manipulated in the context of a field experiment. Marketing levers that have more organizational elements, such as marketing channels and sales force management, are often less amenable to experimentation as they are harder to vary and often require more intraorganizational cooperation and coordination than is typical. Further, questions of how marketing organizations are structured (e.g., siloed, cross-functional, information sharing, decision rights, etc.) to execute chosen marketing strategies are of interest to senior managers. Expanding the focus of field experiments to intraorganizational and cross-functional decisions relevant to senior marketing managers can considerably expand our knowledge as these are also areas in which exogenous variation and establishment of causal relationships are hardest to establish. Even though such field experiments are hard to do, there is a long history <ref type="bibr" target="#b17">(Seashore 1964)</ref>. See <ref type="bibr" target="#b1">Bandiera et al. (2011)</ref> for a recent survey of field experiments in firms.</p><p>Among such levers, the area in which field experiments have shown greatest success is, not surprisingly, in the area of sales incentives because these are relatively easy to modify in the short run (e.g., <ref type="bibr">Narayandas 2017, Chung et al. 2020)</ref>. Managerial training is another area in which field experiments have succeeded (e.g., <ref type="bibr" target="#b2">Bloom et al. 2013</ref><ref type="bibr" target="#b0">, Anderson et al. 2018</ref>. The promise of experimentation in asking often difficult organizational questions, such as about job and incentive design, is seen in <ref type="bibr" target="#b11">Kim et al. (2020)</ref>, who exploit a policy of random job transfers to study how a salesperson's private information interacts with job and incentive design to impact customer acquisition and retention.</p><p>With big data, it becomes easier for researchers to observe various aspects of the internal organization, and firms can easily structure levers, such as incentives and information visibility on dashboards, to sales, service, and marketing employees to motivate, incentivize, and improve performance. Such easily changeable levers are potentially amenable to field experimentation and open up new areas of research within the marketing organization, B2B marketing, and marketing channels.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Conclusion</head><p>This special issue includes a range of papers addressing both behavioral and quantitative marketing questions through multiple marketing channels. We summarize elements of successful submissions in the review process and shed some light on success factors and reasons for failure. We also discussed ways by which field experiment papers can augment research in the areas of quantitative, behavioral, and managerial marketing. We hope these descriptions of success factors and potential contributions to different areas of marketing help researchers choose topics as well as craft successful field experiment-based papers to expand marketing scholarship.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Endnote</head><p>1 Coincidentally, that analysis also included 61 papers.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Marketing Channel</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Primary Reasons Papers Were Rejected</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Nelson,Simester, and Sudhir:  Introduction to the Special Issue on Marketing Science and Field ExperimentsMarketing Science, 2020, vol. 39, no. 6, pp. 1033-1038 </figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">MarketingScience, 2020, vol. 39, no. 6, pp. 1033-1038 </note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Pathways to profits: The impact of marketing vs. finance skills on business performance</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chandy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Zia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="5559" to="5583" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Field experiments with firms</title>
		<author>
			<persName><forename type="first">O</forename><surname>Bandiera</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Barankay</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Rasul</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econom. Perspect</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="63" to="82" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Does management matter? Evidence from India. Quart</title>
		<author>
			<persName><forename type="first">N</forename><surname>Bloom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Eifert</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mahajan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mckenzie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Roberts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econom</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="51" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Incentives vs. reciprocity: Insights from a field experiment</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Narayandas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="511" to="524" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">The effects of quota frequency: Sales performance and product focus</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Narayandas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Chang</surname></persName>
		</author>
		<idno type="DOI">10.1287/mnsc.2020.3648</idno>
		<ptr target="https://doi.org/10.1287/mnsc.2020.3648" />
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<date type="published" when="2020-09-16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Personalized pricing and customer welfare</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Dubé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Misra</surname></persName>
		</author>
		<ptr target="https://ssrn.com/abstract=2992257" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Preprint</note>
	<note>submitted August 3</note>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Self-signaling and prosocial behavior: A cause marketing experiment</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">P</forename><surname>Dubé</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Luo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Fang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="161" to="186" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">No substitute for the real thing: The importance of in-context field experiments in fundraising</title>
		<author>
			<persName><forename type="first">I</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Urminsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1052" to="1070" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Algorithmic collusion: Supracompetitive prices via independent algorithms. Working paper</title>
		<author>
			<persName><forename type="first">K</forename><surname>Hansen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pai</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>San Diego</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of California</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Temporal reframing and participation in a savings program: A field experiment</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Hershfield</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Shu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Benartzi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1039" to="1051" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Social advertising effectiveness across products: A large-scale field experiment</title>
		<author>
			<persName><forename type="first">S</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Aral</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Brynjolfsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1142" to="1165" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">A structural model of a multitasking salesforce: Job task allocation and incentive plan design</title>
		<author>
			<persName><forename type="first">M</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Sudhir</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Uetake</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<pubPlace>New Haven, CT</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Yale University</orgName>
		</respStmt>
	</monogr>
	<note type="report_type">Working Paper</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Examining salesperson effort allocation in teams: A randomized field experiment</title>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1122" to="1141" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Critical condition: People don&apos;t dislike a corporate experiment more than they dislike its worst condition</title>
		<author>
			<persName><forename type="first">R</forename><surname>Mislavsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Dietvorst</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Simonsohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1092" to="1104" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Dynamic online pricing with incomplete information using multiarmed bandit experiments</title>
		<author>
			<persName><forename type="first">K</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Abernethy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="226" to="252" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Lifting the veil: The benefits of cost transparency</title>
		<author>
			<persName><forename type="first">B</forename><surname>Mohan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Buell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>John</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1105" to="1121" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Name similarity encourages generosity: A field experiment in email personalization</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">P</forename><surname>Munz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">L</forename><surname>Alter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1071" to="1091" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Field experiments with formal organizations</title>
		<author>
			<persName><forename type="first">S</forename><surname>Seashore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Human Organ</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="164" to="170" />
			<date type="published" when="1964" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Field experiments in marketing</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Simester</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook of Economic Field Experiments</title>
				<editor>
			<persName><forename type="first">E</forename><surname>Duflo</surname></persName>
			<persName><forename type="first">A</forename><surname>Banerjee</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam</addrLine></address></meeting>
		<imprint>
			<publisher>Elsevier</publisher>
			<date type="published" when="2017" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="465" to="497" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Dynamic catalog mailing policies</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Simester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="683" to="696" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Efficiently evaluating targeting policies: Improving upon champion vs. challenger experiments</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Simester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Timoshenko</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Zoumpoulis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="3412" to="3424" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The exploration-exploitation tradeoff and efficiency in knowledge production</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sudhir</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Optimizing price menus for duration discounts: A subscription selectivity field experiment</title>
		<author>
			<persName><forename type="first">L</forename><surname>Tian</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Feinberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1181" to="1198" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Referral reward size and new customer profitability</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Wolters</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Schulze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gedenk</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1166" to="1180" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
