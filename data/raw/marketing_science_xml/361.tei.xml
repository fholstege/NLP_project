<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Just the Faces: Exploring the Effects of Facial Features in Print Advertising</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2014-02-10">February 10, 2014.</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Li</forename><surname>Xiao</surname></persName>
							<email>lixiao@fudan.edu.cn</email>
						</author>
						<author>
							<persName><forename type="first">Min</forename><surname>Ding</surname></persName>
							<email>minding@psu.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">School of Management</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country>People&apos;s Republic of China</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Smeal College of Business</orgName>
								<orgName type="institution">Pennsylvania State University</orgName>
								<address>
									<postCode>16802</postCode>
									<settlement>University Park</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">School of Management</orgName>
								<orgName type="institution">Fudan University</orgName>
								<address>
									<postCode>200433</postCode>
									<settlement>Shanghai</settlement>
									<country>People&apos;s Republic of China</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Just the Faces: Exploring the Effects of Facial Features in Print Advertising</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
						<imprint>
							<date type="published" when="2014-02-10">February 10, 2014.</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.2013.0837</idno>
					<note type="submission">Received: July 9, 2012; accepted: November 12, 2013; Preyas Desai served as the editor-in-chief and Michel Wedel served as associate editor for this article.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:28+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>face</term>
					<term>facial features</term>
					<term>advertising effectiveness</term>
					<term>eigenface</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please scroll down for article-it is on subsequent pages</head><p>With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning opportunities for individual professionals, and organizations of all types and sizes, to better understand and use O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Print media plays an important role in advertising practice. According to <ref type="bibr" target="#b28">Nielsen's (2013)</ref> report, global print advertising spending reached more than $150 billion in 2012, accounting for more than a quarter of total media advertising spending in the world. In print advertising, it is common practice to have a human endorser present the brand or product and advocate its adoption. We collected more than 600 print ads that appeared in the United States from 2001 to 2012 from the AdForum database 1 and found that over 50% of print ads feature faces. A recent GfK MRI (2011) report indicated that only a small portion (less than 10%) of print ads use celebrity endorsers, a finding consistent with our search of the AdForum database. For many ads that use noncelebrity endorsers, consumers know nothing about these endorsers other than what they can infer from the endorsers' faces.</p><p>Although faces are widely used in print ads, the selection process in practice is ad hoc. We interviewed an advertising agency on how print ads are created for fashion brands. The normal procedures are as follows: (a) the advertising agency receives a request from a client company, (b) it sends a model request to multiple modeling agencies, (c) the modeling agencies send back pictures of recommended models (100+), (d) the advertising agency selects some models (about 10 to 20, based the fashion brand and its request) and photographs them wearing the same clothes, (e) the advertising agency gives the pictures to the client, and (f) the client decides which models to use (often in conjunction with the advertising agency), at which point copy testing may or may not be involved.</p><p>Although there is a large body of literature on the effects of endorsers/spokespersons on advertising effectiveness from various aspects-for example, gender (e.g., <ref type="bibr" target="#b20">Gilly 1988)</ref>, ethnicity (e.g., <ref type="bibr" target="#b40">Wheatley 1971)</ref>, age (e.g., <ref type="bibr" target="#b18">Freiden 1984)</ref>, profession (e.g., <ref type="bibr" target="#b29">Ohanian 1991)</ref>, fame (e.g., <ref type="bibr" target="#b24">Heath et al. 1994)</ref>, and overall attractiveness (e.g., <ref type="bibr" target="#b5">Bower and Landreth 2001)</ref>-few studies deal directly with faces. Therefore, the effect of Xiao and Ding: Exploring the Effects of Facial Features in Print Advertising Marketing Science 33(3), pp. 338-352, © 2014 INFORMS 339 different faces on advertising effectiveness remains largely unknown. In this paper, we focus on faces of noncelebrity endorsers about whom viewers know little but their faces.</p><p>Borrowing face recognition techniques from the field of computer science, we empirically test how different faces affect advertising effectiveness in the print advertising context. Specifically, we aim to address three questions that are important to both researchers and practitioners:</p><p>1. Do faces affect how a viewer reacts to an advertisement (abbreviated as an "ad") on the metrics that advertisers care about? While keeping certain aspects of the spokesperson constant <ref type="bibr">(gender, ethnicity, age, etc.)</ref>, will different faces elicit different responses from viewers? Here, we focus on three key metrics of advertising effectiveness that advertisers care most about, including attitude toward the ad (Aad), attitude toward the brand (Abrand), and purchase intention (PI) <ref type="bibr" target="#b27">(Miniard et al. 1990</ref><ref type="bibr" target="#b21">, Goldsmith et al. 2000</ref>.</p><p>2. If faces do have an effect, is it large enough to warrant a careful selection of faces when constructing a print advertisement? If the effect of face exists but is trivial, clearly advertisers should not spend much time or money on face selection. Only if the effect exists and is substantial should they be careful when selecting the face to appear in an advertisement.</p><p>3. If faces do have an effect and the effect is large, what specific facial features elicit such differential reactions on the metrics, and are such reactions different across individuals and different product categories? This question deals with the heterogeneity of the effect of faces on viewers' responses on key ad metrics. A critical step toward answering this question involves the decomposition of faces. As such, we relied on the eigenface method, which is a widely used approach for face recognition in the computer science field. The eigenface method is "the first really successful demonstration of machine recognition of faces" <ref type="bibr">(Zhao et al. 2003, p. 412)</ref>. Many face recognition algorithms have been derived from this approach. The eigenface method will be explained in further detail in the next section.</p><p>The rest of the paper is organized as follows: We first review the literature on face research. We then describe the empirical study and discuss the data analysis and results. Finally, we present a discussion and conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relevant Literature</head><p>We first provide a review of previous research on the effects of faces and facial features. Then, we introduce the eigenface method and how it works to extract facial features from different faces. Finally, we review literature indicating that substantial heterogeneity exists in the way people make inferences from faces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Existing Literature on Face Research</head><p>The effect of faces on people's perceptions and behavior has been studied in multiple disciplines (see <ref type="bibr" target="#b42">Zebrowitz 2006</ref> for a review). In psychology, <ref type="bibr" target="#b36">Todorov et al. (2005)</ref> showed that inferences of competence based solely on facial appearance could predict the outcomes of U.S. congressional elections to some extent. <ref type="bibr" target="#b15">Dumas and Testé (2006)</ref> found that perceived facial maturity has an influence on juridic judgments. <ref type="bibr" target="#b9">Collins and Zebrowitz (1995)</ref> found that appearance is significantly related to the types of jobs people hold and partly determines job status. <ref type="bibr" target="#b30">Pincott (2010)</ref> found that women use facial masculinity to infer the attractiveness of males and form mating preferences. In marketing, <ref type="bibr" target="#b22">Gorn et al. (2008)</ref> found that during public relations crises, chief executive officers with baby faces are perceived to be more trustworthy and creditable than those with mature faces. <ref type="bibr" target="#b34">Solomon et al. (1992)</ref> showed that congruency between the facial attractiveness of a spokesperson and product image can elicit favorable communication responses. In computer science, <ref type="bibr" target="#b26">Koda and Maes (1996)</ref> showed that faces of virtual agents have an impact on humancomputer interaction. And <ref type="bibr" target="#b6">Brahnam (2002)</ref> focused on techniques to customize virtual agents' faces to match the personalities of users.</p><p>Despite the large body of literature, to our knowledge, the effect of face on the effectiveness of print ads has not been empirically demonstrated. The most relevant literature in this domain is <ref type="bibr" target="#b5">Bower and Landreth's (2001)</ref> study on how the overall physical attractiveness of models (but not specifically their faces) affects product evaluations. More important, the magnitude of a face effect, heterogeneity in reactions to a face, and the practical relevance to practitioners have never been addressed.</p><p>An important stream of face research is to identify what specific facial features drive perceptions or behavior. In psychology, researchers have used a physiognomic approach to extract facial features from different faces. Physiognomic method represents a face with a set of facial distances. For example, <ref type="bibr" target="#b2">Berry and McArthur (1985)</ref> decomposed a male face into 11 facial distances and found that a face with bigger eyes and a wider chin is judged to be more baby-faced and thus more trustworthy. <ref type="bibr" target="#b12">Cunningham et al. (1990)</ref> decomposed a male face into 26 facial distances and found that a male face with bigger eyes and a longer chin is perceived as more attractive in a female's eyes. Other researchers focused on one feature, facial width-to-height ratio, and found a significant effect on perceived propensity for aggression <ref type="bibr" target="#b7">(Carré et al. 2009)</ref> and cooperative behavior in a trust game <ref type="bibr" target="#b35">(Stirrat and Perrett 2010)</ref>.</p><p>As the above studies illustrate, the choice of physiognomic measurement is somewhat arbitrary and Marketing Science 33(3), pp. <ref type="bibr">338-352, © 2014 INFORMS</ref> only captures a subset of information from face. For example, <ref type="bibr" target="#b2">Berry and McArthur (1985)</ref> chose 11 physiognomic features, and <ref type="bibr" target="#b11">Cunningham (1986)</ref> chose 26, but it is unknown exactly how many features should be studied. Furthermore, because of model identification issues and multicollinearity concerns, both studies included some interaction terms in their models, such as eye area, eye roundness, and chin area, but they did not include all possible interactions. Many interactions that might have an effect are missing from the models-e.g., the ratio of eye distance to face length, the angle of the eyes to the nostril tip, etc. This method especially is not useful if the faces studied are similar on these typical physiognomic features, such as in the case of print advertisement where the actors used have similar measurements on most of these typical physiognomic features. People who do not fit the stereotypical look of a model are unlikely to be selected. Thus very limited variations exist among these typical physiognomic features in this context. Based on these limitations, to decompose faces we used a holistic method, the eigenface method, which can capture all subtle differences across faces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Eigenface Method</head><p>Eigenface is the gold standard method in computer science for face recognition and was first proposed by <ref type="bibr" target="#b37">Turk and Pentland (1991)</ref>. It uses principal component analysis (PCA) to project training face images onto a set of dominant eigenvectors. Because each dominant eigenvector looks roughly like a face, these eigenvectors are also called eigenfaces. This method is easy to implement, is computationally efficient, achieves good accuracy in face recognition tasks, and thus is widely used in the computer science field <ref type="bibr" target="#b43">(Zhao et al. 2003)</ref>. Its implementation is briefly described as follows (for more details, see <ref type="bibr" target="#b37">Turk and Pentland 1991)</ref>:</p><p>Step 1. Acquire a training set of face images. Ideally, these images are all the same size, in a fixed position, and facing forward under constant lighting. The faces show neutral emotion and do not wear accessories (e.g., glasses). Assume that there are M gray-scaled face images in the training set and the size of each image is H × W pixels.</p><p>Step 2. Stack each face image into a H W × 1 vector, denoted as X i . The training set of images is represented by a H W × M matrix, denoted as X.</p><p>Step 3. Calculate the meanX = 1/M X i and subtract the mean from X. The mean vectorX could be unstacked back to an H × W matrix and displayed, which looks roughly like a face with blurry contour. This is called the average face.</p><p>Step 4. Use PCA to calculate the eigenvectors and eigenvalues of the covariance matrix. At this step, we obtain M eigenvectors and the corresponding M eigenvalues.</p><p>Step 5. Keep the K most important/dominant eigenvectors and project each image in the training set onto these K eigenvectors, stacked together and denoted as EV H W × K . Thus, each image in the training set (X i ) can be approximated and represented by a unique loading vector, L i K × 1 . Each image can be reconstructed as X i ≈ EV × L i +X. The choice of K depends on how many eigenfaces are needed to get a good reconstruction of training images <ref type="bibr" target="#b37">(Turk and Pentland 1991)</ref>. Once the average face and K dominant eigenvectors are stored, given a face image, either an image from the training set or a new image, it is easy to calculate the loading vector of this face image. The dissimilarity between two face images can be well represented by the difference between two corresponding loading vectors. An illustration of the eigenface decomposition is shown in Figure <ref type="figure">1</ref>.</p><p>Despite its wide use in face recognition, the eigenface method has rarely been used to study the effect of facial features on viewers' responses. Only Branham (2002) made the first attempt to apply the eigenface method to her virtual agent study. However, the faces used in her study were synthetic faces generated by software, not real human faces. To date, no study has applied the eigenface method to real faces to study people's perceptions or reactions to print advertisements.</p><p>Unlike the physiognomic method, which requires a predefined set of facial distances, no prior information is needed for the eigenface method. The extracted eigenvectors contain the major differences among training images; thus it is a holistic measurement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Heterogeneity in Viewers' Responses to Faces</head><p>All of the previous studies that link facial features to people's reactions were conducted at the aggregate level, not the individual level, and attempted to use one model to explain how people make inferences from faces. People were treated as homogeneous in these studies; individual differences were ignored. One underlying assumption is that people share in common what facial features influence their impressions and how important these facial features are in forming their perceptions. For example, based on <ref type="bibr" target="#b2">Berry and McArthur's (1985)</ref> findings, a trustworthy face must have big eyes and a wide chin. The major theory underlying this assumption is that the perception of facial features has adaptive value and that trait impressions are based on those facial qualities that demand the greatest attention for the survival of the species-namely, physical fitness, age, and emotional state <ref type="bibr" target="#b41">(Zebrowitz 1998)</ref>. Faces with features that are indicative of these qualities are believed to have pronounced overgeneralization effects. Thus, there is considerable consistency and universal consensus in the way people make inferences from faces <ref type="bibr" target="#b14">(Cunningham et al. 1995)</ref>.</p><p>However, this assumption has been greatly challenged. Ample evidence shows that the heterogeneity among people is not trivial and that it influences their way of making inferences from faces. A comparison between the results from the studies by <ref type="bibr" target="#b11">Cunningham (1986)</ref> and <ref type="bibr" target="#b12">Cunningham et al. (1990)</ref> reveals a gender difference in inferring attractiveness. <ref type="bibr" target="#b34">Solomon et al. (1992)</ref> proposed six distinct types of attractive looks. <ref type="bibr" target="#b30">Pincott (2010)</ref> reported that women from areas with good healthcare conditions (e.g., Sweden) prefer feminine-looking men, whereas women from areas without good healthcare systems (e.g., Russia) prefer masculine-looking men. <ref type="bibr" target="#b17">Ekman and Friesen (2003)</ref> reported that culture and individual heterogeneity has an effect on both the exhibited face side and the recipient side. Based on these arguments, people should be studied in separate segments defined by factors such as gender, ethnicity, etc. Hence, multiple segments of people should be identified based on the way they make inferences from faces. Within each segment, people share similar preferences toward faces, whereas across segments, people show substantially different preferences toward faces.</p><p>Resolving this controversy for marketing practitioners is important, because quite different marketing strategies might need to be considered to optimize the effects of advertisements on consumer perceptions and behavior. If our results reveal that people are somehow similar and that the one best face exists, then an advertising agency's job is to find a spokesperson with a face that closely resembles the best face for the advertisement. However, if we find that people are heterogeneous in their facial preferences and multiple best faces exist with each appealing to a different segment of consumers, which may or may not depend on product categories, then an advertising agency would want to identify and define specific customer segments and create multiple advertisements, each with a distinct face that closely matches the best face for that specific segment of customers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Design Stimulus Advertisements</head><p>To mimic advertising practice, we used real models' faces as stimuli in this study. As a result, whatever effect we identify will not be artificial as a result of the poor choice of faces (e.g., using faces that will Marketing Science 33(3), pp. 338-352, © 2014 INFORMS never be selected by practitioners). We followed a rigorous face selection process in this study. First, we collected thousands of faces of male models from fashion websites such as Macy's, Brooks Brothers, and MyHabit.com; modeling agency websites such as Elite and Ford; and other graphic websites such as Google Images, Flickr, and Getty Images. Then, we narrowed the image pool down to a face database with 60 distinctive faces that satisfied the following criteria: (a) Caucasian male, between 25 and 35 years old; (b) no accessories, no obvious moustache, moderate hairstyle; (c) mild smile, positioned right-side up, facing forward; (d) not a celebrity (and no resemblance to a celebrity); and (e) reasonable resolution. Finally, we randomly selected 12 faces from the face database and used them as stimulus faces.</p><p>The product categories were selected based on the following criteria: (a) the category often features human faces in print ads, (b) the general public has some knowledge of the product category, and (c) it is appropriate to feature a man's face in an advertisement in the category. Of the categories that fit these criteria, we selected 12 that also have substantial variation in hedonism so that we could test whether people's reaction to faces are related to the hedonism characteristic of a product category. Hedonism is a variable often used in the literature to represent different product categories (e.g., <ref type="bibr" target="#b31">Raghunathan and Irwin 2001</ref><ref type="bibr" target="#b8">, Carroll and Ahuvia 2006</ref><ref type="bibr" target="#b25">, Inman et al. 2009</ref>). It is indirectly indicated in the literature that hedonism might affect the relationship between facial features and people's responses. For example, <ref type="bibr" target="#b36">Todorov et al. (2005)</ref> found that competent faces are more likely to be elected for political positions (less hedonic context); <ref type="bibr" target="#b16">Englis et al. (1994)</ref> found that attractive faces are frequently featured in ads for fashion products such as clothing and perfume (more hedonic context). However, to our knowledge, the interaction between hedonism and facial features has never been studied in the literature. The 12 categories selected for this study are beer, restaurant, job search agent, men's cologne, coffee, computer, hotel, jeans, sports utility vehicle (SUV), sports shoes, camcorder, and car dealer.</p><p>Based on the face selection results (12 stimulus faces) and category selection results (12 categories), we created 12 × 12 = 144 stimulus ads. To create a more natural advertisement viewing experience for participants, the stimulus ads were created from real ads where the original face was replaced with one of the stimulus faces while holding all other elements constant with the following exception: the original brand names were replaced with some generic names and logos were removed. We hired professional graphic designers to create the stimulus ads to make sure that they looked reasonably natural at a quick glance. At the end of the empirical study, we asked the participants whether they observed anything out of place or abnormal in the ads. Only a few participants indicated that they sensed that some of the faces in the ads might have been photoshopped.</p><p>For four categories (restaurant, job search agent, computer, and sports shoes), we included the original faces in the stimulus ads as a baseline. The other eight original faces were not used because they wore accessories such as glasses, had beards, or were celebrities. Altogether, we created 148 stimulus ads.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Extraction of Facial Features</head><p>Using the eigenface method, we first extracted the facial image from the original pictures and removed the noise related to lighting and angle. Second, we normalized each face and placed it into a 180 × 180 pixel-sized plane. This allowed us to construct the training set of 60 images. Third, we used the PCA method to obtain the eigenvectors and eigenvalues. We retained 12 eigenvectors that explain almost 75% of the variance among training images and can reconstruct the faces reasonably well. The root-meansquare pixel-by-pixel error in representing cropped versions of training face images, i.e., reconstruction errors, was less than 10%. The average face and 12 eigenfaces extracted from the 60 training images are shown in Figure <ref type="figure" target="#fig_1">2</ref>.</p><p>Finally, the loading vector (12 × 1) of each stimulus face was calculated. Eigenface loadings ranged from −4 130 69 to 5 467 63 and thus were resized by dividing by 1,000. The resized eigenface loadings were the facial features we extracted from the stimulus faces. These loadings were used as independent variables in our subsequent data analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Procedures</head><p>A total of 989 participants participated in this study. Of those, 676 undergraduate students at a major U.S. university completed the study in an on-campus computer laboratory for course credit. The remaining 313 participants were recruited from the Amazon Mechanical Turk subject pool; each of them received $2 for their participation. In terms of gender, 472 were male (48%) and 517 (52%) were female. In terms of ethnicity, 755 participants were Caucasian (77%), 25 were African American (3%), 42 were Hispanic (4%), 125 were Asian (12%), 22 were multiracial (2%), and 20 were categorized as other (2%). Ages ranged from 18 to 69 years old, with a mean of 24.36 and a standard deviation of 10.27 years.</p><p>We applied a between-subject design. Each participant was presented with 12 print advertisements, one for each product category. Within each product category, one stimulus advertisement out of 12 (or 13 if the original face was used in the category) was randomly assigned to each participant. The sequence of 12 product categories was also randomized for each participant. The average time spent on each advertisement evaluation was 11.4 seconds. After participants viewed all 12 print advertisements, they began evaluating them one by one on attitude toward the ad, attitude toward the brand, and purchase intention. After evaluating all 12 ads, participants were asked to evaluate the hedonism levels of the 12 product categories, followed by a survey about demographics, cognitive style, and value system. At the end of the empirical study, they were asked to evaluate the faces they saw on six trait dimensions that have been identified in the literature as facial characteristics that affect people's responses: baby-facedness <ref type="bibr" target="#b2">(Berry and McArthur 1985</ref><ref type="bibr" target="#b15">, Dumas and Testé 2006</ref><ref type="bibr" target="#b22">, Gorn et al. 2008</ref>, masculinity <ref type="bibr" target="#b30">(Pincott 2010)</ref>, attractiveness <ref type="bibr" target="#b34">(Solomon et al. 1992)</ref>, trustworthiness <ref type="bibr" target="#b2">(Berry and McArthur 1985</ref><ref type="bibr" target="#b22">, Gorn et al. 2008</ref><ref type="bibr" target="#b35">, Stirrat and Perrett 2010</ref>, aggressiveness <ref type="bibr" target="#b7">(Carré et al. 2009)</ref>, and competence <ref type="bibr" target="#b36">(Todorov et al. 2005)</ref>.</p><p>We used the scale from <ref type="bibr" target="#b27">Miniard et al. (1990)</ref> to measure three key ad metrics. Three items (bad/good, uninteresting/interesting, dislike/like) were used to measure attitudes toward the advertisement on a seven-point scale. Attitudes toward the brand Marketing Science 33(3), pp. 338-352, © 2014 INFORMS were measured using a three-item seven-point scale (unfavorable/favorable, negative/positive, dislike/ like). Purchase intention was measured using a two-item seven-point scale (unlikely/likely, improbable/probable). Reliabilities for the three constructs are 0.88, 0.89, and 0.91, respectively.</p><p>In our study, hedonism was measured using a fouritem seven-point scale (unpleasant/pleasant, awful/ nice, sad/happy, disagreeable/agreeable) <ref type="bibr" target="#b10">(Crowley et al. 1992)</ref>. Reliability for hedonism is 0.89. A 36-item seven-point scale was used to measure cognitive style <ref type="bibr" target="#b23">(Hauser et al. 2009)</ref>, and a 30-item nine-point scale was used to measure value style <ref type="bibr" target="#b33">(Schwartz 1992)</ref>. Each of the six trait dimensions was measured on a seven-point bipolar scale (i.e., baby-faced/mature, feminine/masculine, unattractive/attractive, untrustworthy/trustworthy, unaggressive/aggressive, and incompetent/competent).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Estimation and Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Faces on Key Ad Metrics at the Aggregate Level</head><p>As indicated in the experimental design section, the only difference in the stimulus ads for each product category was the face appearing on the ad; therefore, any differences in key ad metrics can be attributed to the face used in the ad. For each category, we calculated the means for each face for each key ad metric (see Table <ref type="table" target="#tab_0">1</ref>).</p><p>The results show that faces do have an effect on advertising effectiveness. For example, by comparing means, Face 6 in the beer ad significantly outperformed Face 12 on all three key ad metrics. For each category and each key ad metric, the face with highest mean significantly beats the face with lowest mean at the p &lt; 0 05 level.</p><p>A comparison between the results for the 12 stimulus faces and the original faces justifies careful face selection. For example, for sports shoes, by changing from the original face to Face 7, the print ad achieved about a 0.5-point increase on evaluations of all three key ad metrics. As our face selection procedures show, these 12 stimulus faces were randomly selected from among 60 male models' faces. It is very possible that by applying our method to a large sample of faces, practitioners would achieve even greater improvement.</p><p>It is worth noting that the preferences for faces were different across categories, which indicates a strong interaction between face effect and category. For example, for attitude toward ad, Face 11 achieved the highest mean for the jeans ad but the lowest for the car dealer ad.</p><p>To help answer the second question on whether practitioners should care about such a difference in effect, we calculated the percentages of high-rating participants (evaluation of key ad metric &gt; 6) for each category and each key ad metric. For example, in business practice, practitioners care most about the customers who give high ratings to their products or services <ref type="bibr" target="#b38">(Urban and Hauser 1993)</ref>. We report both the percentage for each face for each ad (in Table <ref type="table" target="#tab_2">2</ref>) as well as absolute maximum improvement between the best and worst face for each product category (in Figure <ref type="figure">3</ref>).</p><p>The effect is quite striking. For example, Table <ref type="table" target="#tab_2">2</ref> shows that for the cologne ad, by merely changing the face from Face 2 to Face 1, advertisers could achieve a more than 10% increase in attitude toward ad (from 8% to 25.8%), attitude toward brand (from 5.3% to 21.6%), and purchase intention (from 9.3% to 20.6%). In other words, such a change would double or even triple the number of high rating participants. We plotted the maximum absolute percentage improvement (the percentage of high-rating participants for the best face of high rating minus the percentage of highrating participants for the worst face of high rating) in Figure <ref type="figure">3</ref>. <ref type="bibr">2</ref> Figure <ref type="figure">3</ref> shows that by merely changing from the worst face of high rating to the best face of high rating, each ad could achieve an increase in the number of high-rating people ranging from 4% to 21% for each key ad metric. The interaction of face effect with product categories can also be seen in a comparison of high-rating people. For example, Figure <ref type="figure">3</ref> shows that for the cologne ad, the face effect on all three key ad metrics is huge, whereas for the computer ad, the face effect is much smaller. For the restaurant ad, the face effect for Aad and Abrand is substantial, but it is minor for PI.</p><p>These results indicate that different faces do have an effect on advertising effectiveness, and that the effect is nontrivial. Hence, we conclude that advertisers should carefully select faces/spokespersons to appear in print advertisements.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Segmentation Analysis Using Facial Features</head><p>We used 12 eigenface loadings and 12 interaction terms between eigenface loadings and hedonism as independent variables and the three key ad metrics as dependent variables simultaneously in the segmentation analysis. To explore possible heterogeneity in how people respond to facial features, we used the latent class multivariate regression model proposed by <ref type="bibr" target="#b32">Ramaswamy et al. (1993)</ref>. Specifically, Notes. For each category and each key ad metric, the face that achieves the highest mean is deemed the best face of mean and marked in bold, whereas the face with lowest mean is deemed the worst face of mean and marked in bold and italic. For each category and each key ad metric, evaluations from participants who viewed the ad with best face of mean are significantly higher than evaluations from those who viewed the same ad with worst face of mean at the p &lt; 0 05 level. In four categories, four original faces were also tested in the experiment and thus compared here. For each category, the original face refers to the face that was featured in the real ad. So even though they are all called original face, they are unique for each category and different from each other.   Car dealer Aad 5 5 0 0</p><formula xml:id="formula_0">Y i ∼ G i Y i w = k w k f Y i X i k k (1)</formula><formula xml:id="formula_1">0 0 0 0 1 4 3 6 1 1 2 0 1 2 1 2 1 2 0 0 N/A Abrand 6 8 1 2 1 1 1 5 1 4 2 4 0 0 3 9 1 2 1 2 1 2 0 0 PI 4 1 0 0 1 1 1 5 1 4 1 2 0 0 3 9 1 2 1 2 1 2 1 4</formula><p>Notes. For each category and each key ad metric, the face that achieves the highest percentage of high-rating participants is deemed the best face of high rating and is marked in bold, whereas the face with the lowest percentage of high-rating people is deemed the worst face of high rating and is marked in bold and italic. For each category and each key ad metric, the percentage of high-rating participants for the best face of high rating is significantly higher than the percentage for the worst face at the p &lt; 0 05 level. Note that for most categories and key ad metrics, the best and worst faces of high rating are the same with best and worst faces in terms of mean (see Table <ref type="table" target="#tab_0">1</ref>) but are different for some cases. Notes. For each category and each key ad metric, the maximum absolute percentage improvement equals the percentage of high-rating participants for the best face of high rating minus the percentage of high-rating participants for the worst face of high rating. For each category and each key ad metric, the best face of high rating refers to the face that achieves the highest percentage of high-rating participants, whereas the worst face of high rating refers to the face that achieves the lowest percentage of high-rating participants.</p><p>where</p><formula xml:id="formula_2">f Y i X i k k = 2 − T /2 k − 1/2 exp − 1 2 Y i −X i k −1 k Y i −X i k (2)</formula><p>and k ≥ 0</p><formula xml:id="formula_3">K k=1 k = 1 (3) Here, Y i = Y i1 Y iT is a T × 3 matrix with i = 1</formula><p>I as an indicator of participant and T as the total number of replications, and 3 refers to the three key ad metrics, i.e., attitude toward the ad, attitude toward the brand, and purchase intention in our case; X i is a T × J matrix of independent variables for participant i, where J refers to the number of independent variables; k is the prior probability of segment k; K is the predefined number of segments, an assumption to be imposed on the finite mixture model; k is the J × 1 parameter vector for segment k; and = 1 k , where k is the T × T variancecovariance matrix for segment k.</p><p>By introducing an indicator variable z ik = 1 iff participant i belongs to segment k 0 otherwise the likelihood can be presented as</p><formula xml:id="formula_4">L = i k w k f Y i X i k k z ik (4)</formula><p>We used the Latent GOLD Syntax Module for implementation, 3 which is mainly based on the expectation-maximization algorithm for model estimation <ref type="bibr" target="#b39">(Vermunt and Magidson 2005)</ref>. Considering that we dealt with only 12 faces, although the model including all 24 independent variables was identified, it was very unstable and the convergence was bad. Thus, we added a variable selection procedure to the segmentation model. Given K, we used a stepwise greedy search for variable selection <ref type="bibr" target="#b3">(Bishop 1996)</ref>.</p><p>We used the Bayesian information criterion (BIC) for variable selection <ref type="bibr" target="#b0">(Andrews and Currim 2003)</ref>. In this case, a variable will enter into the model if its coefficient is significant in at least one segment, and a variable will exit out of the model if its coefficient is insignificant in all segments. The heuristic is briefly described below.</p><p>Step 1. Select a K.</p><p>Step 2. Run a K-segment finite mixture model with empty set P 0 = , i.e., only intercepts, no x's.</p><p>Step 3. Select the next best variable x + = arg min x P k • BIC P k +x to enter into the K-segment finite mixture model.</p><p>Step 4. Update</p><formula xml:id="formula_5">P k+1 = P k + x + ; k = k + 1.</formula><p>Step 5. Remove the worst variable x − = arg min x∈P k • BIC P k − x from the K-segment finite mixture model if removing it will help decrease the BIC value of the model.</p><p>Step 6. Update P k+1 = P k − x − ; k = k + 1.</p><p>Step 7. Repeat Steps 5 and 6 until removing any variable in the model will not decrease the BIC value.</p><p>Step 8. Repeat Steps 3-7 until adding any variable into the model or removing any variable from the model will not help decrease the BIC value, or all 24 variables are included in the model.</p><p>We tested for K = 1 2 3 4 5, and 6, and the five segment result is the best model based on the BIC criterion. The variables selected were hedonism×L1, hedonism × L4, hedonism × L5, hedonism × L6, hedonism × L7, hedonism × L10, hedonism × L11, and hedonism × L12. <ref type="bibr">4</ref> The five segments were composed of 40, 82, 386, 344, and 137 participants, respectively. The estimation for the best model is shown in Table <ref type="table" target="#tab_5">3</ref>. Substantial heterogeneity is shown across segments. For example, in terms of attitude toward the ad, participants in Segments 1 and 2 do not favor faces that load heavily on Eigenface 1, especially in ads for hedonic products; participants in Segments 4 and 5, by contrast, do favor faces that load heavily on Eigenface 1, especially in ads for hedonic products; and participants in Segment 3 do not care about face loadings on Eigenface 1   at all, no matter how hedonic the featured product would be. It is worth noting that all variables entering into the best model are interaction terms, which gives more evidence supporting the conjecture that face effect interacts with product categories. Because the sizes of Segments 3 and 4 are substantially bigger than those of Segments 1, 2, and 5, we focus our following discussion mainly on Segments 3 and 4.</p><p>To further explore the heterogeneity across segments, we ran a classification and regression tree algorithm (a supervised learning method; see Bishop 2006 for more details) of the segment labels on the demographic information as well as the cognitive style and value system evaluation. Three demographic vari- a If the feature is not included in the cell, it means that this feature for this segment is similar to the entire sample. For example, gender information is described for Segments 1, 2, and 4, but not for Segments 3 and 5. This means the gender distribution in Segments 3 and 5 is similar to the entire sample.</p><p>b The original scales for these three items are as follows: "Please indicate how much you agree or disagree with the following statements from 1 (strongly disagree) to 7 (strongly agree).</p><p>• I'm usually more interested in the whole than in parts and details. • I will read an explanation of a graph/chart before I try to understand the graph/chart on my own. • I find that to adopt a careful, analytical approach to making decisions takes too long." c The original scales for these two items are as follows: "Please rate the values below very carefully and then rate each value on an importance scale 'AS A GUIDING PRINCIPLE IN MY LIFE,' from 7 (of supreme importance) to 6 (very important), to 3 (important), to 0 (not important), to −1 (opposed to my values).</p><p>• Authority.</p><p>• Choosing own goals." ables (age, gender, and ethnicity), three cognitive items (prefer the whole versus parts and details, visually driven, and analytical), and two values (authority and choosing own goals) emerged as important variables to classify the participants into five identified segments. A pairwise comparison on these eight variables across five segments was run afterwards to explain segment heterogeneity. We also conducted a set of mediation tests <ref type="bibr" target="#b1">(Baron and Kenny 1986)</ref> with the six trait variables we measured. Results are shown in Table <ref type="table" target="#tab_6">4</ref>.</p><p>It is shown that Segment 3 mainly comprises young, visually driven people who value choosing their own goals. The effect of eigenface features on all three key ad metrics appears to be mediated by masculinity, attractiveness, trustworthiness, and competence; the effect of eigenface features on purchase intention is partially mediated by aggressive- ness, but aggressiveness does not play a role for attitude toward the ad or attitude toward the brand. Compared with Segment 3, Segment 4 is more male and less white, and it comprises people with holistic views who are not visually driven, are analytical, value authority, and do not care much about choosing their own goals. In Segment 4, the effect of eigenface features on ad metrics is mediated by attractiveness, trustworthiness, aggressiveness, and competence. Baby-facedness plays a role in attitude toward the ad and purchase intention, but not in attitude toward the brand; masculinity plays a role in attitude toward the ad and brand, but not in purchase intention. It is worth noting that even though attractiveness, trustworthiness, and competence are important mediating variables for both Segments 3 and 4, the mediation effect is different across the two segments. For example, for Segment 3, competence partially mediates the effects of L6 and L7 on attitude toward the ad, whereas for Segment 4, competence partially mediates the effect of L1, L4, L5, L6, L7, L10, and L11 on attitude toward the ad. Therefore, although competence is important for both Segments 3 and 4, the faces that are regarded as competent are different for these two segments. The competence order of the 12 stimulus faces for Segment 3 is totally different from the order for Segment 4. Face 9 is regarded as the most competent and Face 3 the least competent for Segment 3; Face 5 is regarded as the most competent and Face 1 the least competent for Segment 4.</p><p>Based on these results, we conclude that people make reasonably consistent inferences from facial features, and substantial heterogeneity exists in the way people make inferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect of Faces on Key Ad Metrics at the Segment Level</head><p>How do the segmentation results help advertisers understand people's heterogeneity in making inferences from facial features? To address this question, we compared the best faces of mean at the segment level (see Figure <ref type="figure">4</ref>).</p><p>We found substantial heterogeneity from segment to segment. All three panels in Figure <ref type="figure">4</ref> show that different faces are preferred for different segments and diverge from the best face of mean at the aggregate level. For example, for the computer ad, participants at the aggregate level favored Face 7 the most and Face 5 the least in terms of evaluation of attitude toward the ad, but at the segment level, participants in Segment 3 favored Face 1 the most and Face 4 the least, whereas those in Segment 4 favored Face 2 the most and Face 1 the least.</p><p>Substantial heterogeneity can also be easily seen by comparing high-rating people at the segment level, as shown by the maximum absolute improvement in percentage of high-rating people at the segment level (see Figure <ref type="figure">5</ref>). Different faces are preferred, and the magnitude of face effect also differs across segments. Interestingly, in contrast with the diverging trend for the three key ad metrics at the aggregate level (see Figure <ref type="figure">3</ref>), the three key ad metrics move in a similar direction at the segment level. This provides evidence that segmentation with three dependent variables works.</p><p>Hence, ad agencies should not only be careful when selecting faces for their ads, but they also should take heterogeneity among target audiences into consideration. Ideally, multiple advertisements, each with a different face, should be created to appeal to different segments of the target audience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusions and Discussion</head><p>In this paper, we empirically demonstrated the effect of different faces on advertising effectiveness for various product categories. To answer the three questions that were raised at the beginning of this paper, we conclude that (1) faces do affect how a viewer reacts to an ad on the metrics that advertisers care about, (2) the effect is substantial, and (3) people show reasonably consistent preferences toward faces, and substantial heterogeneity among individuals and product categories exists in how viewers react to advertisements. Moreover, eigenface features are practical for segmenting people based on their preferences toward different faces.</p><p>The present study contributes theoretically to the existing literature in several ways. First, we focused specifically on faces in print advertisements and empirically demonstrated the effect of different faces on advertising effectiveness by using real ads and real faces. Second, we introduced a quantitative method, the eigenface method, into marketing research, which will hopefully encourage future face studies in marketing. Third, we provided evidence for the interaction of face effects with product categories, and we empirically demonstrated that hedonism is a useful category feature that differentiates product categories and interacts with face effects. Finally, we resolved the controversy over people's heterogeneity in face preferences while contributing to the face literature in general.</p><p>In practice, this study has several implications for advertisers and ad agencies. The substantial effect of different faces on advertising effectiveness indicates that ad agencies should be careful when selecting faces to appear in print advertisements. Ad agencies should also pay attention to possible heterogeneity in the preferences of the target audience and use different faces to target different customer segments. In addition, the methods used in the present study provide a new approach for professionals interested in conducting a quantitative study to assist in the screening and selection of print media spokespersons. It is worth noting that for the categories that included the original faces, the original faces were very rarely selected as the best face of either mean or high rating. Thus, the ad hoc face selection process in practice does not generate the best result, showing the value of our quantitative method.</p><p>We propose using the eigenface method for face screening purposes. From an ad agency perspective, such face screening can be done with the following steps. First, ask modeling agencies to submit the faces of the models they represent and pool all of the faces into one database (containing perhaps 1,000 or more faces of professional models). Second, decompose these faces into loadings on a set of eigenfaces.</p><p>As a result, every face in the face database will be represented by a vector of loadings on these eigenfaces. Third, measure the hedonism of a product category and identify the segment(s) that best match the segments of the target customers. Fourth, identify the top or 10 faces from the face database using the results from this paper. These top faces could be used for copy testing later. The ad agency need only do the first and second steps once. The third step is specific for each client and requires some very reasonable effort. The fourth step is also specific for each client but can be done automatically. Note that an ad agency can conduct a study similar to what we did in this paper for a specific client and a specific product category using the client's target segment as the sample. The results will be used for the third step above. This may yield a more precise choice of face to represent the client, and it obviously requires substantially more effort (but is still feasible).</p><p>The eigenface method is good for most practices that use faces extensively, such as print ads that feature a real human face or a virtual agent that features a synthetic face. Unlike a real human face whose eigenface loadings are fixed corresponding to a specific face, a virtual agent's face is synthetic so that its eigenface loadings can be more easily changed so as to morph the face. For a virtual agent, the steps described above can be used not only for face screening but also for face morphing to construct the optimal virtual agent face for a certain condition.</p><p>This paper is the first attempt to apply a quantitative approach to studying faces in the marketing field. We hope the introduction of this quantitative approach (specifically, the eigenface method) will encourage fruitful future research on faces. Here, we list several promising directions for future research. First, the eigenface method suffers from the limitation that it is hard to interpret and quite nonintuitive. By looking at the eigenfaces, it is very hard to tell exactly how each eigenface is different from the others. Future research should focus on creating an intuitive way to interpret the eigenface method and its result. Second, this paper focuses on static faces with constant expressions; future research could go one step further by studying the effect of different facial expressions. Third, in the current study, we controlled all elements except for the faces and product categories. It might be interesting to study the interaction of face effect with other elements (body shape, hairstyle, costume, gender, age, etc.) in the future. Fourth, we used one category feature, hedonism, to represent product categories. Other category features might also interact with face effect. In addition to category features, other variables in the ad context, such as brand personality <ref type="bibr" target="#b34">(Solomon et al. 1992</ref>), might interact with face effect as well. It might be worthwhile exploring other variables for interactions with face effect. Fifth, we used greedy search for variable selection. Greedy search is a generic method that is sometimes unable to generate the global optimal model. It might be worthwhile exploring other variable selection methods (e.g., the Metropolis-Hastings method) in future research. Finally, this study focuses on print ads. Future researchers might consider studying the effects of faces in video ads, given the dominant role of TV advertising in total media ad spending <ref type="bibr" target="#b28">(Nielsen 2013</ref>).</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1Eigenface Decomposition</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2The Average Face and 12 Most Dominant Eigenfaces</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Hedonism * L1 −0 26 * * −0 01 −0 11 * −0 21 * * −0 18 * * −0 18 * * −0 01 0 01 0 05 * * 0 19 * * 0 19 * * 0 24 * * 0 14 * * 0 12 * * −0 08 * * Hedonism * L4 0 42 * * 0 00 0 41 * * 0 31 * * 0 28 * * 0 21 * * 0 00 −0 03 −0 09 * * −0 20 * * −0 16 * * −0 23 * * −0 12 * * * 0 31 * * 0 32 * * 0 19 * −0 08 −0 08 −0 12 * * −0 41 * * −0 34 * * −0 44 * * −0 29 * * −0 14 * 0 31 * * Hedonism * L6 1 01 * * −0 12 0 70 * * 1 46 * * 1 31 * * 1 42 * * −0 03 −0 11 −0 24 * * −1 41 * * −1 27 * * −1 61 * * −0 63 * * −0 56 * * 0 68 * * Hedonism * L7 −0 40 −0 06 −0 45 −1 00 * * −0 84 * * −1 05 * * 0 14 0 17 * 0 34 * * 1 37 * * 1 26 * * 1 51 * * 0 95 * * 0 84 * * −0 32 * * Hedonism * L10 −0 41 * * 0 00 −0 58 * * −0 64 * * −0 63 * * −0 59 * * 0 13 * * 0 12 * * 0 18 * * 0 74 * * 0 71 * * 0 89 * * 0 61 * * 0 49 * * −0 28 * * Hedonism * L11 −0 76 * * 0 19 −0 95 * * −0 98 * * −0 90 * * −0 87 0 11 0 18 * * 0 18 * * 0 92 * * 0 83 * * 1 04 * * 0 42 * * 0 27 * * −0 41 * * Hedonism * L12 1 07 * * −0 12 0 54 * * 1 61 * * 1 44 * * 1 44 * * −0 31 * * −0 32 * * −0 45 * * −1 48 * * −1 33 * * −1 63 * * −0 87 * * −0 65 * * 0 59 * * * Significant at p &lt; 0 10; * * significant at p &lt; 0 05.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 4Best Face of Mean for Each Category and Segment</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figure 5Maximum Absolute Percentage Improvement for High-Rating Participants, by Segment</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Mean of Key Ad Metrics by Product Category and Face</figDesc><table><row><cell>Category</cell><cell>Face 1</cell><cell>Face 2</cell><cell>Face 3</cell><cell>Face 4</cell><cell>Face 5</cell><cell>Face 6</cell><cell>Face 7</cell><cell>Face 8</cell><cell>Face 9</cell><cell>Face 10</cell><cell>Face 11</cell><cell>Face 12</cell><cell>Original</cell></row><row><cell>Beer</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aad</cell><cell>3 26</cell><cell>3 56</cell><cell>2</cell><cell>2 81</cell><cell>3 04</cell><cell>3 66</cell><cell>3 05</cell><cell>3 03</cell><cell>3 21</cell><cell>3 12</cell><cell>2 77</cell><cell>2 63</cell><cell>N/A</cell></row><row><cell>Abrand</cell><cell>3 37</cell><cell>3 60</cell><cell>2 99</cell><cell>3 07</cell><cell>3 21</cell><cell>3 73</cell><cell>3 35</cell><cell>3 15</cell><cell>3 43</cell><cell>3 37</cell><cell>3 28</cell><cell>2 90</cell><cell></cell></row><row><cell>PI</cell><cell>3 30</cell><cell>3 65</cell><cell>2 85</cell><cell>2 86</cell><cell>2 92</cell><cell>3 44</cell><cell>3 23</cell><cell>2 92</cell><cell>3 07</cell><cell>3 12</cell><cell>2 96</cell><cell>2 70</cell><cell></cell></row><row><cell>Restaurant</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aad</cell><cell>4 75</cell><cell>4 41</cell><cell>4 42</cell><cell>4 54</cell><cell>4 63</cell><cell>4 46</cell><cell>4 41</cell><cell>4 83</cell><cell>4 15</cell><cell>4 39</cell><cell>4 32</cell><cell>4 59</cell><cell>4 75</cell></row><row><cell>Abrand</cell><cell>4 88</cell><cell>4 78</cell><cell>4 69</cell><cell>4 82</cell><cell>4 90</cell><cell>4 58</cell><cell>4 78</cell><cell>5 05</cell><cell>4 42</cell><cell>4 69</cell><cell>4 57</cell><cell>4 95</cell><cell>5 00</cell></row><row><cell>PI</cell><cell>4 81</cell><cell>4 97</cell><cell>4 77</cell><cell>4 87</cell><cell>4 96</cell><cell>4 68</cell><cell>4 80</cell><cell>5 06</cell><cell>4 57</cell><cell>4 76</cell><cell>4 53</cell><cell>4 89</cell><cell>4 95</cell></row><row><cell>Job search agent</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aad</cell><cell>3 25</cell><cell>3 52</cell><cell>3 22</cell><cell>3 24</cell><cell>3 25</cell><cell>3 71</cell><cell>3 06</cell><cell>3 56</cell><cell>3 04</cell><cell>3 35</cell><cell>3 65</cell><cell>3 21</cell><cell>3 37</cell></row><row><cell>Abrand</cell><cell>3 64</cell><cell>3 81</cell><cell>3 48</cell><cell>3 73</cell><cell>3 56</cell><cell>3 90</cell><cell>3 29</cell><cell>3 75</cell><cell>3 28</cell><cell>3 64</cell><cell>3 91</cell><cell>3 62</cell><cell>3 66</cell></row><row><cell>PI</cell><cell>3 24</cell><cell>3 34</cell><cell>2 83</cell><cell>3 03</cell><cell>2 95</cell><cell>3 41</cell><cell>2 69</cell><cell>3 15</cell><cell>2 76</cell><cell>3 03</cell><cell>3 44</cell><cell>3 09</cell><cell>3 09</cell></row><row><cell>Cologne</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aad</cell><cell>4 93</cell><cell>3 91</cell><cell>4 69</cell><cell>4 36</cell><cell>4 46</cell><cell>4 65</cell><cell>4 56</cell><cell>4 14</cell><cell>4 12</cell><cell>4 65</cell><cell>4 55</cell><cell>4 02</cell><cell>N/A</cell></row><row><cell>Abrand</cell><cell>4 80</cell><cell>3 90</cell><cell>4 57</cell><cell>4 39</cell><cell>4 38</cell><cell>4 63</cell><cell>4 34</cell><cell>4 21</cell><cell>4 10</cell><cell>4 62</cell><cell>4 49</cell><cell>3 99</cell><cell></cell></row><row><cell>PI</cell><cell>4</cell><cell>3 25</cell><cell>3 95</cell><cell>3 84</cell><cell>3 81</cell><cell>4 17</cell><cell>3 77</cell><cell>3 64</cell><cell>3 45</cell><cell>4 01</cell><cell>3 99</cell><cell>3 23</cell><cell></cell></row><row><cell>Coffee</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aad</cell><cell>3 74</cell><cell>3 10</cell><cell>3 62</cell><cell>2 83</cell><cell>3 30</cell><cell>3 80</cell><cell>3 70</cell><cell>3 01</cell><cell>2 93</cell><cell>3 42</cell><cell>3 12</cell><cell>2 88</cell><cell>N/A</cell></row><row><cell>Abrand</cell><cell>3 81</cell><cell>3 30</cell><cell>3 71</cell><cell>3 07</cell><cell>3 41</cell><cell>3 84</cell><cell>3 78</cell><cell>3 31</cell><cell>3 34</cell><cell>3 45</cell><cell>3 28</cell><cell>3 29</cell><cell></cell></row><row><cell>PI</cell><cell>3 16</cell><cell>2 85</cell><cell>3 28</cell><cell>2 67</cell><cell>3 19</cell><cell>3 50</cell><cell>3 39</cell><cell>2 84</cell><cell>3 15</cell><cell>3 18</cell><cell>2 99</cell><cell>2 84</cell><cell></cell></row><row><cell>Computer</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aad</cell><cell>3 08</cell><cell>3 34</cell><cell>3 17</cell><cell>3 04</cell><cell>2 54</cell><cell>3 19</cell><cell>3 39</cell><cell>2 79</cell><cell>3 01</cell><cell>3 10</cell><cell>3 32</cell><cell>3 12</cell><cell>3 30</cell></row><row><cell>Abrand</cell><cell>3 33</cell><cell>3 54</cell><cell>3 18</cell><cell>3 36</cell><cell>2 82</cell><cell>3 22</cell><cell>3 53</cell><cell>3 07</cell><cell>3 09</cell><cell>3 23</cell><cell>3 41</cell><cell>3 38</cell><cell>3 20</cell></row><row><cell>PI</cell><cell>2 68</cell><cell>2 88</cell><cell>2 73</cell><cell>2 73</cell><cell>2 19</cell><cell>2 62</cell><cell>2 85</cell><cell>2 31</cell><cell>2 39</cell><cell>2 85</cell><cell>2 88</cell><cell>2 58</cell><cell>2 44</cell></row><row><cell>Hotel</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aad</cell><cell>3 37</cell><cell>3 51</cell><cell>3 58</cell><cell>3 18</cell><cell>3 02</cell><cell>3 61</cell><cell>3 97</cell><cell>3 53</cell><cell>3 08</cell><cell>3 24</cell><cell>3 42</cell><cell>3 20</cell><cell>N/A</cell></row><row><cell>Abrand</cell><cell>3 52</cell><cell>3 94</cell><cell>3 89</cell><cell>3 50</cell><cell>3 51</cell><cell>3 88</cell><cell>4 23</cell><cell>3 81</cell><cell>3 44</cell><cell>3 75</cell><cell>3 65</cell><cell>3 65</cell><cell></cell></row><row><cell>PI</cell><cell>3 29</cell><cell>3 72</cell><cell>3 64</cell><cell>3 19</cell><cell>3 24</cell><cell>3 45</cell><cell>4 00</cell><cell>3 48</cell><cell>3 14</cell><cell>3 42</cell><cell>3 13</cell><cell>3 37</cell><cell></cell></row><row><cell>Jeans</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aad</cell><cell>3 70</cell><cell>3 29</cell><cell>3 66</cell><cell>3 06</cell><cell>3 03</cell><cell>3 81</cell><cell>3 56</cell><cell>3 59</cell><cell>3 54</cell><cell>3 18</cell><cell>3 94</cell><cell>3 30</cell><cell>N/A</cell></row><row><cell>Abrand</cell><cell>3 68</cell><cell>3 19</cell><cell>3 67</cell><cell>2 97</cell><cell>2 99</cell><cell>3 70</cell><cell>3 51</cell><cell>3 71</cell><cell>3 39</cell><cell>3 25</cell><cell>3 80</cell><cell>3 19</cell><cell></cell></row><row><cell>PI</cell><cell>3 26</cell><cell>2 71</cell><cell>3 19</cell><cell>2 61</cell><cell>2 66</cell><cell>3 42</cell><cell>3 00</cell><cell>3 13</cell><cell>2 98</cell><cell>2 76</cell><cell>3 35</cell><cell>2 83</cell><cell></cell></row><row><cell>SUV</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aad</cell><cell>4 32</cell><cell>3 92</cell><cell>4 36</cell><cell>4 19</cell><cell>3 95</cell><cell>3 69</cell><cell>4 17</cell><cell>3 93</cell><cell>3 63</cell><cell>4 13</cell><cell>4 26</cell><cell>3 85</cell><cell>N/A</cell></row><row><cell>Abrand</cell><cell>4 20</cell><cell>3 92</cell><cell>4 17</cell><cell>4 05</cell><cell>3 81</cell><cell>3 78</cell><cell>4 07</cell><cell>3 90</cell><cell>3 72</cell><cell>3 99</cell><cell>4 10</cell><cell>3 95</cell><cell></cell></row><row><cell>PI</cell><cell>3 09</cell><cell>2 81</cell><cell>2 92</cell><cell>3 23</cell><cell>2 93</cell><cell>2 83</cell><cell>3 13</cell><cell>2 91</cell><cell>2 73</cell><cell>2 89</cell><cell>2 99</cell><cell>3 22</cell><cell></cell></row><row><cell>Sports shoes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aad</cell><cell>4 75</cell><cell>4 26</cell><cell>4 59</cell><cell>4 52</cell><cell>4 69</cell><cell>4 58</cell><cell>4 99</cell><cell>4 29</cell><cell>4 42</cell><cell>4 35</cell><cell>4 58</cell><cell>4 38</cell><cell>4 46</cell></row><row><cell>Abrand</cell><cell>4 76</cell><cell>4 38</cell><cell>4 51</cell><cell>4 57</cell><cell>4 69</cell><cell>4 53</cell><cell>4 84</cell><cell>4 30</cell><cell>4 28</cell><cell>4 33</cell><cell>4 57</cell><cell>4 30</cell><cell>4 37</cell></row><row><cell>PI</cell><cell>4 14</cell><cell>3 98</cell><cell>3 99</cell><cell>3 92</cell><cell>4 19</cell><cell>4 13</cell><cell>4 33</cell><cell>3 78</cell><cell>3 66</cell><cell>3 64</cell><cell>3 92</cell><cell>3 73</cell><cell>3 84</cell></row><row><cell>Camcorder</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aad</cell><cell>3 61</cell><cell>3 39</cell><cell>3 83</cell><cell>3 21</cell><cell>3 45</cell><cell>3 90</cell><cell>3 48</cell><cell>3 56</cell><cell>3 46</cell><cell>3 34</cell><cell>3 52</cell><cell>3 40</cell><cell>N/A</cell></row><row><cell>Abrand</cell><cell>3 75</cell><cell>3 60</cell><cell>4 05</cell><cell>3 50</cell><cell>3 63</cell><cell>4 07</cell><cell>3 59</cell><cell>3 78</cell><cell>3 62</cell><cell>3 52</cell><cell>3 54</cell><cell>3 56</cell><cell></cell></row><row><cell>PI</cell><cell>2 99</cell><cell>2 90</cell><cell>3 02</cell><cell>2 80</cell><cell>3 02</cell><cell>3 07</cell><cell>2 90</cell><cell>2 89</cell><cell>2 97</cell><cell>2 96</cell><cell>2 68</cell><cell>2 90</cell><cell></cell></row><row><cell>Car dealer</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Aad</cell><cell>2 49</cell><cell>2 36</cell><cell>2 25</cell><cell>2 23</cell><cell>2 04</cell><cell>2 36</cell><cell>2 08</cell><cell>2 35</cell><cell>1 89</cell><cell>2 24</cell><cell>1 73</cell><cell>2 44</cell><cell>N/A</cell></row><row><cell>Abrand</cell><cell>3 00</cell><cell>2 85</cell><cell>2 67</cell><cell>2 69</cell><cell>2 52</cell><cell>2 58</cell><cell>2 53</cell><cell>2 83</cell><cell>2 40</cell><cell>2 76</cell><cell>2 20</cell><cell>2 76</cell><cell></cell></row><row><cell>PI</cell><cell>2 42</cell><cell>2 42</cell><cell>2 30</cell><cell>2 18</cell><cell>2 09</cell><cell>2 20</cell><cell>2 05</cell><cell>2 44</cell><cell>2 09</cell><cell>2 48</cell><cell>1 74</cell><cell>2 51</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2</head><label>2</label><figDesc>Percentage of High-Rating Participants (Key Ad Metric Evaluated Above 6) for Each Key Ad Metric by Product Category and Face</figDesc><table><row><cell>%</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 3</head><label>3</label><figDesc>Preference of Facial Structure of Each Segment, by Different Key Ad Metrics</figDesc><table><row><cell></cell><cell cols="2">Segment 1 (40)</cell><cell></cell><cell cols="2">Segment 2 (82)</cell><cell></cell><cell cols="3">Segment 3 (386)</cell><cell cols="3">Segment 4 (344)</cell><cell cols="3">Segment 5 (137)</cell></row><row><cell>Variable</cell><cell>Aad</cell><cell>Abrand</cell><cell>PI</cell><cell>Aad</cell><cell>Abrand</cell><cell>PI</cell><cell>Aad</cell><cell>Abrand</cell><cell>PI</cell><cell>Aad</cell><cell>Abrand</cell><cell>PI</cell><cell>Aad</cell><cell>Abrand</cell><cell>PI</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4</head><label>4</label><figDesc></figDesc><table><row><cell cols="2">Segment Characteristics</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Trait</cell><cell>Segment 1</cell><cell>Segment 2</cell><cell>Segment 3</cell><cell>Segment 4</cell><cell>Segment 5</cell></row><row><cell>Size</cell><cell>40</cell><cell>82</cell><cell>386</cell><cell>344</cell><cell>137</cell></row><row><cell>Demographics a</cell><cell>More female</cell><cell>More female</cell><cell>Younger</cell><cell>More male</cell><cell>Older</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Less Caucasian</cell><cell>Mainly Caucasian</cell><cell></cell></row><row><cell cols="2">Cognitive style a b Prefer parts and details</cell><cell>Less visually driven</cell><cell>More visually driven</cell><cell>Prefer the whole</cell><cell></cell></row><row><cell></cell><cell>More visually driven</cell><cell></cell><cell></cell><cell>Less visually driven</cell><cell></cell></row><row><cell></cell><cell>Less analytical</cell><cell></cell><cell></cell><cell>More analytical</cell><cell></cell></row><row><cell>Value system a c</cell><cell>Value authority less</cell><cell>Value choosing own goals</cell><cell>Value choosing own goals</cell><cell>Value authority more</cell><cell>Value authority less</cell></row><row><cell></cell><cell></cell><cell>more</cell><cell>more</cell><cell>Value choosing own goals less</cell><cell></cell></row><row><cell>Baby-facedness</cell><cell></cell><cell></cell><cell></cell><cell>Aad, PI</cell><cell>Aad, Abrand</cell></row><row><cell>Masculinity</cell><cell></cell><cell>Aad, Abrand</cell><cell>Aad, Abrand, PI</cell><cell>Aad, Abrand</cell><cell>Aad, Abrand, PI</cell></row><row><cell>Attractiveness</cell><cell>Aad</cell><cell>Aad, Abrand, PI</cell><cell>Aad, Abrand, PI</cell><cell>Aad, Abrand, PI</cell><cell>Aad, Abrand, PI</cell></row><row><cell cols="2">Trustworthiness Aad, PI</cell><cell>Aad, Abrand, PI</cell><cell>Aad, Abrand, PI</cell><cell>Aad, Abrand, PI</cell><cell>Aad, Abrand, PI</cell></row><row><cell>Aggressiveness</cell><cell></cell><cell></cell><cell>PI</cell><cell>Aad, Abrand, PI</cell><cell>PI</cell></row><row><cell>Competence</cell><cell>Aad</cell><cell>Aad, Abrand, PI</cell><cell>Aad, Abrand, PI</cell><cell>Aad, Abrand, PI</cell><cell>Aad, Abrand, PI</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1"> AdForum.com  chooses what it deems the five best ads every week for inclusion in its database. Ads may be print, video, or online.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">We did not plot the maximum relative percentage improvement (the percentage of high-rating participants for the best face of high rating divided by the percentage of high-rating participants for the worst face of high rating) because, for several categories, the percentage of high rating participants for worst face of high rating was zero.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We thank Wayne DeSarbo for recommending the model and software.4  To test the robustness of the result, we also ran the mixture model with the eight selected variables for K = 1 8. The model with K = 5 achieves the smallest BIC value as well.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank Gary Lilien, Wayne DeSarbo, Jun Liu, Xinwei Deng, and participants from the 2011 Marketing Science Conference in Houston and the Annual Ph.D. Student Presentations at Pennsylvania State University for their helpful comments. This research is supported by a Smeal Small Research Grant and a National Natural Science Foundation of China fund [Grant 71232008].</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A comparison of segment retention criteria for finite mixture logit models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Currim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="235" to="243" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">The moderator-mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations</title>
		<author>
			<persName><forename type="first">R</forename><surname>Baron</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kenny</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Personality Soc. Psych</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1173" to="1182" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Some components and consequences of a babyface</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">S</forename><surname>Berry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">Z</forename><surname>Mcarthur</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Personality Soc. Psych</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="312" to="323" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Neural Networks for Pattern Recognition</title>
				<meeting><address><addrLine>Oxford, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
	<note>1st ed.</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Bishop</surname></persName>
		</author>
		<title level="m">Pattern Recognition and Machine Learning Springer Science + Business Media</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Is beauty best? Highly versus normally attractive models in advertising</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bower</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Landreth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Modeling physical personalities for virtual agents by modeling trait impressions of the face: A neural network analysis. Doctoral dissertation, Department of Computer Science</title>
		<author>
			<persName><forename type="first">S</forename><surname>Brahnam</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<pubPlace>New York, New York</pubPlace>
		</imprint>
		<respStmt>
			<orgName>City University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Facial structure is a reliable cue of aggressive behavior</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Carré</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">M</forename><surname>Mccormick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Mondloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Sci</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1194" to="1198" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Some antecedents and outcomes of brand love</title>
		<author>
			<persName><forename type="first">B</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ahuvia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Lett</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="79" to="89" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The contributions of appearance to occupational outcomes in civilian and military settings</title>
		<author>
			<persName><forename type="first">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Zebrowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Appl. Soc. Psych</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="129" to="163" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Measuring the hedonic and utilitarian dimensions of attitudes toward product categories</title>
		<author>
			<persName><forename type="first">A</forename><surname>Crowley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Spangenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hughes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Lett</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="239" to="249" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Measuring the physical in physical attractiveness: Quasi-experiments on the sociobiology of female facial beauty</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Cunningham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Personality Soc. Psych</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="925" to="935" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">What do women want? Facialmetric assessment of multiple motives in the perception of male facial physical attractiveness</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Barbee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">L</forename><surname>Pike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Personality Soc. Psych</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="72" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Marketing Science</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="338" to="352" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Their ideas of beauty are, on the whole, the same as ours: Consistency and variability in the cross-cultural perception of female physical attractiveness</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">R</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">P</forename><surname>Barbee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">B</forename><surname>Druen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">H</forename><surname>Wu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Personality Soc. Psych</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="261" to="279" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The influence of criminal facial stereotypes on juridic judgments</title>
		<author>
			<persName><forename type="first">R</forename><surname>Dumas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Testé</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Swiss J. Psych</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="237" to="244" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Beauty before the eyes of beholders: The cultural encoding of beauty types in magazine advertising and music television</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G</forename><surname>Englis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Solomon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">D</forename><surname>Ashmore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="49" to="64" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Unmasking the Face: A Guide to Recognizing Emotions from Facial Expressions</title>
		<author>
			<persName><forename type="first">P</forename><surname>Ekman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">V</forename><surname>Friesen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2003" />
			<publisher>Malor Books</publisher>
			<pubPlace>Cambridge, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Advertising spokesperson effects: An examination of endorser type and gender on two audiences</title>
		<author>
			<persName><forename type="first">J</forename><surname>Freiden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising Res</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="33" to="41" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Despite risks, celebrity endorsers raise print advertising awareness</title>
		<author>
			<persName><forename type="first">Mri</forename><surname>Gfk</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011-02-23" />
		</imprint>
	</monogr>
	<note type="report_type">Press release</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Sex roles in advertising: A comparison of television advertisements in Australia, Mexico, and the United States</title>
		<author>
			<persName><forename type="first">M</forename><surname>Gilly</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="75" to="85" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">The impact of corporate credibility and celebrity credibility on consumer reaction to advertisements and brands</title>
		<author>
			<persName><forename type="first">R</forename><surname>Goldsmith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lafferty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Newell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="43" to="54" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Babyfaces, trait inferences, and company evaluations in a public relations crisis</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Johar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="36" to="49" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Website morphing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liberali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Braun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="202" to="223" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Spokesperson fame and vividness effects in the context of issue-relevant thinking: The moderating role of competitive setting</title>
		<author>
			<persName><forename type="first">T</forename><surname>Heath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Mccarthy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mothersbaugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="520" to="534" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The interplay among category characteristics, customer characteristics, and customer activities on in-store decision making</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Inman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Winer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">S</forename><surname>Ferraro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="19" to="29" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Agents with faces: The effect of personalization</title>
		<author>
			<persName><forename type="first">T</forename><surname>Koda</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Maes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th IEEE Internat. Workshop Robot Human Comm</title>
				<meeting>5th IEEE Internat. Workshop Robot Human Comm</meeting>
		<imprint>
			<date type="published" when="1996" />
			<biblScope unit="page" from="189" to="194" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">On the formation and relationship of ad and brand attitudes: An experimental and causal analysis</title>
		<author>
			<persName><forename type="first">P</forename><surname>Miniard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bhatla</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Rose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="290" to="303" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Global AdView Pulse Lite Quarter 4</title>
		<author>
			<persName><surname>Nielsen</surname></persName>
		</author>
		<ptr target="http://nielsen.com/us/en/reports/2013/global-adview-pulse-lite---q4-2012.html" />
		<imprint>
			<date type="published" when="2012-04-22" />
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">The impact of celebrity spokespersons&apos; perceived image on consumers&apos; intention to purchase</title>
		<author>
			<persName><forename type="first">R</forename><surname>Ohanian</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising Res</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="46" to="54" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Why women don&apos;t want macho men</title>
		<author>
			<persName><forename type="first">J</forename><surname>Pincott</surname></persName>
		</author>
		<ptr target="http://online.wsj.com/news/articles/SB10001424052748704100604575145810050665030" />
	</analytic>
	<monogr>
		<title level="j">Wall Street Journal</title>
		<imprint>
			<date type="published" when="2010-03-27" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Walking the hedonic product treadmill: Default contrast and mood-based assimilation in judgments of predicted happiness with a target product</title>
		<author>
			<persName><forename type="first">R</forename><surname>Raghunathan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Irwin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="355" to="368" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">An empirical pooling approach for estimating marketing mix elasticities with PIMS data</title>
		<author>
			<persName><forename type="first">V</forename><surname>Ramaswamy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Desarbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Reibstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">T</forename><surname>Robinson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="103" to="124" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Universals in the content and structure of values: Theoretical advances and empirical tests in 20 countries</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">H</forename><surname>Schwartz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Experiment. Soc. Psych</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="1" to="65" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The beauty match-up hypothesis: Congruence between types of beauty and product images in advertising</title>
		<author>
			<persName><forename type="first">M</forename><surname>Solomon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Ashmore</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Longo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="23" to="34" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Valid facial cues to cooperation and trust: Male facial width and trustworthiness</title>
		<author>
			<persName><forename type="first">M</forename><surname>Stirrat</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Perrett</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Sci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="349" to="354" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Inferences of competence from faces predict election outcomes</title>
		<author>
			<persName><forename type="first">A</forename><surname>Todorov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mandisodza</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Goren</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Hall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">308</biblScope>
			<biblScope unit="issue">5728</biblScope>
			<biblScope unit="page" from="1623" to="1626" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Face recognition using eigenface</title>
		<author>
			<persName><forename type="first">M</forename><surname>Turk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Pentland</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="86" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Design and Marketing of New Products</title>
		<author>
			<persName><forename type="first">G</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Hauser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Prentice Hall</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
	<note>2nd ed.</note>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">Technical Guide for Latent GOLD 4.0: Basic and Advanced (Statistical Innovations</title>
		<author>
			<persName><forename type="first">J</forename><surname>Vermunt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Magidson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<pubPlace>Belmont, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The use of black models in advertising</title>
		<author>
			<persName><forename type="first">J</forename><surname>Wheatley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="390" to="392" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<author>
			<persName><forename type="first">L</forename><surname>Zebrowitz</surname></persName>
		</author>
		<title level="m">Reading Faces: Window to the Soul? New Directions in Social Psychology</title>
				<meeting><address><addrLine>Boulder, CO</addrLine></address></meeting>
		<imprint>
			<publisher>Westview Press</publisher>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Finally, faces find favor</title>
		<author>
			<persName><forename type="first">L</forename><surname>Zebrowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soc. Cognition</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="657" to="701" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Face recognition: A literature survey</title>
		<author>
			<persName><forename type="first">W</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Chellappa</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Rosenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Phillips</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Comput. Surveys</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="399" to="458" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
