<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Recommending Products When Consumers Learn Their Preference Weights</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Daria</forename><surname>Dzyabura</surname></persName>
							<email>ddzyabur@stern.nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">New Economic School</orgName>
								<address>
									<postCode>121353</postCode>
									<settlement>Moscow</settlement>
									<country key="RU">Russia</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Stern School of Business</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>10012</postCode>
									<settlement>New York</settlement>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">John</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
							<email>hauser@mit.edu</email>
							<affiliation key="aff2">
								<orgName type="department">MIT Sloan School of Management</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<postCode>02142</postCode>
									<settlement>Cambridge</settlement>
									<region>Massachusetts</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Recommending Products When Consumers Learn Their Preference Weights</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
					</monogr>
					<idno type="DOI">10.1287/mksc.2018.1144</idno>
					<note type="submission">Received: March 22, 2016 Revised: October 31, 2017; April 24, 2018 Accepted: May 1, 2018 History: K. Sudhir served as the senior editor and Peter Fader served as associate editor for this article.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:24+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>recommendation systems</term>
					<term>learned preferences</term>
					<term>multiattribute utility</term>
					<term>consumer search</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Consumers often learn the weights they ascribe to product attributes ("preference weights") as they search. For example, after test driving cars, a consumer might find that he or she undervalued trunk space and overvalued sunroofs. Preference-weight learning makes optimal search complex because each time a product is searched, updated preference weights affect the expected utility of all products and the value of subsequent optimal search. Product recommendations, which take preference-weight learning into account, help consumers search. We motivate a model in which consumers learn (update) their preference weights. When consumers learn preference weights, it may not be optimal to recommend the product with the highest option value, as in most search models, or the product most likely to be chosen, as in traditional recommendation systems. Recommendations are improved if consumers are encouraged to search products with diverse attribute levels, products that are undervalued, or products for which recommendation-system priors differ from consumers' priors. Synthetic data experiments demonstrate that proposed recommendation systems outperform benchmark recommendation systems, especially when consumers are novices and when recommendation systems have good priors. We demonstrate empirically that consumers learn preference weights during search, that recommendation systems can predict changes, and that a proposed recommendation system encourages learning.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Our basic premises are that (1) in some product categories consumers learn their preference weights by searching products and (2) many recommendation systems can anticipate a consumer's (true) preference weights better than novice consumers. (By "preference weights," we refer to the weights that a consumer places on an attribute level in an additive multiattribute utility function.) We argue that premise (1) changes a consumer's optimal search path and that premises (1) and (2) change the recommendation that a recommendation system should make.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">Motivation of Premise (1): Preference-</head><p>Weight Learning Consider Candace and Dave, who were moving to a new city. They wanted a condominium with two bedrooms, two bathrooms, a good school district, hardwood floors, an island kitchen, adequate lighting, proximity to work, and a full-service concierge. They had full access to Multiple Listing Service (MLS) listings and could search attributes of condominiums easily but sought a real estate agent's recommendations. Based on an agent's recommendation, they visited one condominium that had a playground across the street. Seeing the playground, Candace and Dave realized how convenient this feature would be for them. Although they always valued playgrounds, they had not previously considered proximity to playgrounds to be an important decision criterion for a home. Their preference weight for playgrounds was substantially larger after seeing the condominium near a playground than before. As they decided what to search further, playground proximity was weighted more heavily. Playground proximity influenced their selection of condominiums to search and their choice of which condominium to buy.</p><p>Preference-weight learning applies broadly, for example, to a high school student learning about what to value in undergraduate research programs during college search, consumers learning about new features as they search for new automobiles, first-time parents learning how nannies affect their lifestyle, and even many singles dating and searching for partners. See <ref type="bibr" target="#b14">Cook (2012)</ref>, <ref type="bibr" target="#b18">Finkel et al. (2012)</ref>, and <ref type="bibr" target="#b47">Sheehy (2013)</ref> for further examples. The common thread in all these examples is that novice consumers, the kind most likely to seek recommendations, revised their preference weights after carefully evaluating products, services, or people during costly search. Consumers updated prior beliefs about preference weights after search and used the updated preference weights for subsequent search and for choice at the end of search. Preference-weight learning appears common even in information-rich environments in which consumers have easy access to attribute levels for most products in the market.</p><p>Premise ( <ref type="formula">1</ref>) is different from the vast literature in marketing on search with Bayesian learning because consumers learn their preference weights during search rather than simply learning the utility of products, services, or people. This difference is important because learned (or updated) preference weights affect the relative utility of every product that has (or doesn't have) the corresponding attribute level. In contrast, in most analytical models, when consumers learn product utilities by searching, the learning affects primarily the utility of the product that is searched.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">Motivation for Premise (2): Recommendation-</head><p>System Knowledge In our vignette, Candice and Dave received a recommendation from a real estate agent. The agent was sufficiently experienced to know that a young couple with small children would value playground proximity and observed that Candice and Dave were not putting sufficient weight on it. The agent had a better understanding of Candice and Dave's true preferences than did Candice and Dave at the start of the search. This phenomenon is common. For example, <ref type="bibr">Rogers (2013, p. F4)</ref> suggests, "Often people don't know what they want . . . You may think you want X, but if you're shown Y, you may love Y better than you ever loved X . . . Even (or especially) in these days of consumer online access, some of an agent's value lies in her being able to offer a buyer a choice different from his preconception." College counselors help high school students learn what to value in colleges, childcare agencies help new parents learn what to value in nannies, and automotive websites help consumers learn what to value in new automobile purchases. A recommender often has knowledge of the attribute levels of products on the market and also knowledge of how attribute levels influenced consumers' purchases in the past. This knowledge translates to insight on the trade-offs consumers make among attribute levels. Good recommenders use this knowledge to guide future consumers' search.</p><p>Depending on the availability of information on product attributes, a recommender's value lies in helping the consumer learn product attributes and/or helping the consumer learn preference weights or both. Attribute-level search is well studied. We focus on preference-weight learning recognizing that many recommenders do both.</p><p>Existing automated recommendation systems value the ability to accurately predict preferred products. Machine-learning methods, such as collaborative filters, content-based filters, and Bayesian-update systems, learn preference weights from past users and apply them to new users (reviewed in Section 2). When preference weights are relatively homogeneous or when preference weights can be tied to observable characteristics, recommendation systems can efficiently learn consumers' true preference weights. Although automated recommendation systems use the knowledge of consumers' preference weights to make recommendations, we know of no automated recommendation system that recommends products that help consumers learn their own preferences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3.">Product Categories for Which Preference-</head><p>Weight Learning Is Likely to Be Relevant We expect preference-weight learning to be relevant in product or service categories in which the product or service is multiattributed, infrequently purchased, costly to experience without purchase or extensive search, and sufficiently valuable to justify extensive and costly search. The set of categories includes real estate, colleges, automobiles, childcare, mates, vacations, furniture, sailboats, and even high-cost industrial equipment. Henceforth, we use "product" to refer to all relevant categories. In these categories, consumers routinely seek advice from human recommenders and/or automated recommendation systems. Anecdotes abound to suggest that human recommenders take preference-weight learning into account in these categories. We hope to extend that capability to automated recommendation systems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4.">Overview of Model and Results</head><p>We assume that the consumer learns (updates) beliefs about the preference weights for attribute levels after searching a product with the corresponding attribute levels. Search is costly, and a purchase, if any, occurs at the end of search. The benefit the consumer derives from purchase, if any, is based on the consumer's true utility, which the consumer experiences from purchase and consumption. In searching optimally, the consumer weighs the vision of this anticipated utility (possibly discounted) against anticipated search cost. To focus on preference-weight learning, we assume that the information about attribute levels of all products is available at low cost from sources such as the Multiple Listing Service (real estate), Kelly Blue Book (automobiles), or popular press ratings (colleges).</p><p>We demonstrate that existing search-theory solutions may not be optimal when preference weights are learned, even when the consumer searches without a <ref type="bibr">Dzyabura and Hauser:</ref> Recommending Products When Consumers Learn Their Preferences recommendation. For example, it is not always best to search products with high option values. We next introduce a recommendation system and argue that the typical criterion used to evaluate recommendation systems, highest predicted utility, does not always identify recommendations that maximize a consumer's net utility when preference weights are learned. Instead, a knowledgeable recommendation system should recommend products with diverse attributes (thus providing a theoretical explanation for recent trends) and/or recommend products that are undervalued by the consumer. Such products are effective recommendations even if the products have a low probability of being the chosen product because the recommendations make the consumer's subsequent search more efficient. We use numerical examples to illustrate how benevolent recommendation systems can direct the consumer to the optimal-net-utility choice. We also illustrate nonbenevolent recommendation systems that lead consumers to profitable products that may not be best for the consumer. Our arguments and examples suggest practical preference-weight-learning recommendation systems. We test the proposed recommendation systems (and a standard benchmark) with synthetic data and explore when each system is most advantageous. We close the paper with an empirical test to demonstrate that our premises are reasonable and that a proposed recommendation system helps consumers learn preference weights better than either the standard benchmark recommendation system or allowing consumers to choose without a recommendation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Related Literature</head><p>We build on two pieces of related literature: the recommendation-systems literature, mostly from computer science, and the sequential-search literature, mostly from economics and marketing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Literature on Recommendation Systems</head><p>Traditionally, the primary goal of a (top-N) recommendation system is to recommend N items that maximize a user's utility <ref type="bibr" target="#b2">(Adomavičius and Tuzhilin 2005)</ref>. Typically, the recommendation system observes a utility surrogate, a rating or a rank, for some users and some items and attempts to extrapolate the surrogate to all users and items. As a result, most recommendation systems are evaluated on the accuracy of that extrapolation <ref type="bibr">(Herlocker et al. 2004</ref><ref type="bibr" target="#b39">, McNee et al. 2006</ref><ref type="bibr" target="#b54">, Zhang and Hurley 2008</ref>. This focus was most notable in the $1M Netflix Challenge that began in 2006 and finished in 2009. The Netflix Challenge sought the recommendation-system algorithm that best predicted held-out user ratings. Successful recommendation systems focus on similarities among users (collaborative filters), similarities among items (content-based filters), attribute-based utility models, or hybrids to recommend products with high expected utility <ref type="bibr" target="#b49">(Urban and Hauser 2004</ref><ref type="bibr" target="#b2">, Adomavičius and Tuzhilin 2005</ref><ref type="bibr" target="#b42">, Moon and Russell 2008</ref><ref type="bibr" target="#b32">, Jacobs et al. 2016</ref>. Although some recommendation systems attempt to match attribute-based utility, attributes are typically defined with taxonomies, such as genre <ref type="bibr" target="#b3">(Ansari et al. 2000)</ref>. A related literature in marketing uses attribute-level preferences to predict whether consumers will choose a recommended product <ref type="bibr" target="#b25">(Häubl and Trifts 2000</ref><ref type="bibr" target="#b53">, Ying et al. 2006</ref><ref type="bibr" target="#b15">, De Bruyn et al. 2008</ref><ref type="bibr" target="#b13">, Chung and Rao 2012</ref><ref type="bibr" target="#b21">, Ghose et al. 2012</ref><ref type="bibr" target="#b38">, Lu et al. 2016</ref>. Although both the recommendation-systems literature and the marketing literature demonstrate that recommendation systems can learn consumer preference weights well, many authors have criticized the focus on predictive accuracy as, in practice, providing recommendations that are too similar to previously purchased items, for example, recommending the same author after a book is purchased <ref type="bibr" target="#b39">(McNee et al. 2006</ref><ref type="bibr" target="#b54">, Zhang and Hurley 2008</ref><ref type="bibr" target="#b19">, Fleder and Hosanagar 2009</ref>, or too obvious, for example, recommending bread, milk, eggs, and bananas to all grocery store shoppers <ref type="bibr">(Herlocker et al. 2004)</ref>.</p><p>In response, researchers have proposed algorithms, and metrics to evaluate those algorithms, that include goals that complement predictive accuracy <ref type="bibr">(Herlocker et al. 2004</ref><ref type="bibr" target="#b5">, Bodapati 2008</ref>. New algorithms avoid recommending items that the consumer would have bought without a recommendation. They augment predictive accuracy with diversity, novelty, and serendipity <ref type="bibr" target="#b56">(Ziegler et al. 2005</ref><ref type="bibr">, Celma and Herrera 2008</ref><ref type="bibr" target="#b20">, Ge et al. 2010</ref><ref type="bibr" target="#b55">, Zhou et al. 2010</ref><ref type="bibr" target="#b1">, Adamopoulos and Tuzhilin 2014</ref>. Diverse items are items that are not similar to one another; novel items are items the consumer would not have chosen without a recommendation; serendipitous items are items that are unexpected, relevant, and useful. To achieve these goals, recommendation systems penalize recommendations that are similar to "accurate" recommendations or recommend products from the "long tail." Product attributes, when used, are used to define product similarity metrics. Diversity, novelty, and serendipity are based on products, not the levels of attributes of the products. We augment this literature by studying how a recommendation system might incorporate preference-weight learning when making recommendations. Our results challenge the traditional recommendation-system focus on products that are likely to be chosen or likely to have high utility. By contrast, our analyses provide a theoretical explanation for why diversity, novelty, and serendipity work better in practice than pure predictive accuracy. We suggest modifications to recommendation systems that are based on a reinterpretation of <ref type="bibr" target="#b57">Dzyabura and</ref><ref type="bibr">Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417-441, © 2019 INFORMS</ref> these concepts and highlight when such modifications benefit consumers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Literature on Sequential Search</head><p>Papers in marketing and economics recognize the importance of the consumer's search for information and have studied it empirically and theoretically. For example, <ref type="bibr" target="#b35">Kim et al. (2010)</ref> use Amazon's view-rank data to infer consumer preferences for observed attributes of camcorders. Consumers know these attribute levels without search, but consumers search to resolve the unobserved utility of the products (error term). <ref type="bibr" target="#b7">Bronnenberg et al. (2016)</ref> study observed online search and find that search is over a relatively small region of attribute space that declines with subsequent search. The final choice is rarely the first item searched. <ref type="bibr" target="#b30">Hong and Shum (2006)</ref>, <ref type="bibr" target="#b45">Seiler (2013)</ref>, <ref type="bibr" target="#b31">Honka (2014)</ref>, and <ref type="bibr" target="#b11">Chen and Yao (2016)</ref> analyze search-path data to infer price distributions and/or search costs. Although a few authors consider nonsequential search, <ref type="bibr" target="#b7">Bronnenberg et al. (2016)</ref> report strong evidence to support sequential search.</p><p>Much of this literature is based on theory derived by <ref type="bibr" target="#b51">Weitzman (1979)</ref>, who studied search over products whose utilities are independently distributed. Weitzman derives the optimal search strategy for this model, which is based on an option value index-the upper tail of the utility distribution. The optimal strategy is to search the products with the highest indices as long as they are above the reservation value. See extensions by <ref type="bibr" target="#b4">Bikhchandani and Sharma (1996)</ref> and <ref type="bibr" target="#b0">Adam (2001)</ref>. <ref type="bibr" target="#b6">Branco et al. (2012)</ref> focus on the optimal search for multiple attributes of a single product. The optimal strategy in this setting is also index-based: the consumer searches as long as utility is bounded between purchase and not-purchase thresholds. <ref type="bibr" target="#b34">Ke et al. (2016)</ref> extend the model to derive appropriate bounds for two products.</p><p>Our analyses are consistent with this literature in the sense that the consumer's optimal search path is the solution to a dynamic program (a Bellman equation). However, we modify the recursion to allow consumers to update their preference weights for attributes as they search. Because products share attribute levels, the optimal search strategy is no longer indexable (e.g., Weitzman's solution). High option value or high variance in product utility matters less; strategies to learn preference weights efficiently matter more.</p><p>Finally, our model of preference-weight learning is consistent with examples of preference-weight learning in the marketing-science literature. <ref type="bibr" target="#b24">Greenleaf and Lehmann (1995)</ref> demonstrate that consumers delay purchases to learn preference weights, and <ref type="bibr" target="#b46">She and MacDonald (2013)</ref> show that "trigger features" cause consumers to update preference weights. <ref type="bibr" target="#b26">Hauser et al. (2014a)</ref> show that as consumers become more expert, their preference weights stabilize. Predictions, even one to three weeks later, improve. <ref type="bibr" target="#b17">Dzyabura et al. (2019)</ref> and <ref type="bibr" target="#b16">Dzyabura and Jagabathula (2018)</ref> demonstrate that preference weights change when consumers evaluate physical products rather than their online descriptions. Most of these changes persist if consumers go back to the online channel after evaluating physical products, which is consistent with learning preference weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Model of Consumer Search with Preference-Weight Learning</head><p>To model preference-weight learning, we decompose product utilities into components corresponding to product attribute levels and allow consumers to learn their preference weights for attribute levels as they search products. We start by defining the utility of a product and then present the model of search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Consumer Utility Is Defined on</head><p>Attributes Levels Let j 1, . . ., J index products and i 1, . . ., I index attributes. For ease of exposition, we begin with binary attributes such that a product either has or does not have an attribute. When it is clear in context, we refer to binary attributes simply as "attributes." Later, in Section 4.1.2, when we discuss multilevel attributes, we introduce terminology to distinguish attribute levels from attributes. Let x ij 1 if product j has binary attribute i, and let x ij 0 otherwise. Let x j be the binary vector that describes product j.</p><p>Let u j be the utility of product j, and let w i be the relative preference weight that the consumer places on attribute i such that</p><formula xml:id="formula_0">u j u( x j ) I i 1 w i x ij .</formula><p>(1)</p><p>Let w [w 1 , . . .w I ] be the vector of preference weights for all the attributes. The consumer has a prior belief about the values of w i . The prior probability density for the consumer's prior beliefs is denoted by f 0 i (w i ) for each attribute i. This belief can be updated when the consumer observes a product with attribute i. We assume the prior distributions (and any updated distributions) are independent over i.</p><p>To focus on preference-weight learning, we assume that consumers know, or can search at negligible cost, whether a product has an attribute. That is, we assume that they know x j . This simplification is not unrealistic. Zillow, Trulia, and MLS provide attribute levels of new homes; U.S. News &amp; World Report and Business Week provide attribute levels for colleges; Autotrader, Edmunds, and Kelly Blue Book provide attribute levels for automobiles; and travel websites, dating websites, and Amazon provide attribute levels for other products. We focus on situations in which attribute levels are easy to observe, but more costly search is necessary for consumers to experience attributes and learn their preference Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences weights. We revisit this assumption and the assumption of discrete attribute levels in Section 9.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Consumers Learn Preference Weights</head><p>During Search Consumers engage in sequential search, searching one product at a time. Searching represents sufficient effort by a consumer to examine and evaluate product j, for example, by test-driving a car, visiting a condominium for sale, visiting a college, or interviewing a caregiver. The cost of searching a product is c &gt; 0. There is a true value of w i , which we label w r i (r for "revealed"). During search, the consumer updates beliefs about w i toward w r i . For infrequently purchased products (as in Section 1.3), the consumer fully learns the consumer's preference weights when consuming the chosen product; thus, the utility the consumer ultimately gets is computed according to w r i , that is, I i 1 w r i x ij . Let t index sequential searches, and let s t be the tth product search. Whenever x t ij 1, the consumer receives a signal about the true value of the consumer's preference weight. This signal takes the form of a probability density function g(w r i |w i , s t j) for the true value w r i . Using Bayes theorem, the consumer's evaluation during search of product j enables the consumer to update beliefs about w i . If x t ij 0, the consumer cannot update beliefs about w i . Let F t ( j s t ) {i : x t ij 1}; then the consumer's belief distribution about preference weight i after the tth search is</p><formula xml:id="formula_1">f t+1 i (w i ) ≡ f t+1 i (w i |w r , s t j) ⎧ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎨ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎪ ⎩ f t i (w i ) for all i ∉ F t ( j), g(w r i |w i , s t j)f t i (w i ) ∫ g(w r i |w i , s t j)f t i (w i )dw i for all i ∈ F t ( j).<label>(2)</label></formula><p>We refer to f t i (w i ) as the prior beliefs before the tth search and f t+1 i (w i ) as the posterior beliefs after the tth search. Equation (2) allows the Bayesian updating to remain general. For the numeric examples and synthetic data experiments, we make a functional assumption-we use normally distributed priors leading to normally distributed posteriors. The online appendix summarizes the formulas.</p><p>As t increases, we expect the mean of f t i (w i ) to approach w r i and the variance to approach zero. The rate at which the posterior beliefs converge can vary. For example, one of our colleagues was dead set against swimming pools when searching for vacation homes in a beach community, but when she saw the perfect swimming pool layout for her children, she immediately updated her preference weights and bought the house. Another colleague searched three homes in a community before he fully updated his preference weight for a neighborhood-owned swimming pool. We explore differences in the rate at which preferences are updated in our numerical examples and synthetic data experiments.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Optimal Search</head><p>If no recommendations are made, the consumer searches sequentially and optimally. If recommendations are made, the consumer searches all recommended products, updates the preferences, and searches optimally thereafter. The consumer is forward looking; therefore, the consumer solves a dynamic programming recursion to select the next product to search or to stop and purchase. The state is the set of products already searched S t , and the beliefs prior to search are f t ( w). When prior distributions are independent over i, and when an observation of an attribute only updates preference weights for that attribute, posterior beliefs are independent over attributes. Probabilistic independence implies f t ( w) ∏ i 1 to I f t i (w i ). If J(S t , f t ) is the continuation value, the Bellman equation for search without recommendations recognizes that this value is the maximum over choosing the outside option denoted by U * , choosing the maximum utility product without searching based on f t , or continuing to search. The value of continuing to search is the maximum over all unsearched products taking into account that preferences will be updated through further search (if further search is optimal). Expectations are based on f t , which is the consumer's belief about the preference weights when the search decision is made. The resulting Bellman equation is</p><formula xml:id="formula_2">J(S t , f t ) max U * , max j 1 to J E[Σ i 1to I w i x ij | f t ], max k∉S t −c + βE J S t ∪ {k}, f t+1 | f t ,<label>(3)</label></formula><p>where β ≤ 1 represents the discount factor. A key part of this optimization problem, relative to the searchtheory literature, is that the belief distribution f t is part of the state space and is defined over product attributes (rather than products). Naturally, Equation (3) could be extended to include uncertainty over the x j 's for research to marry preference-weight learning to attribute-level search.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Recommendations</head><p>We model product recommendations as follows.</p><p>A "recommendation" is a single product that is recommended to the consumer at a given time. We assume that the consumer follows that recommendation and searches the recommended product. A human recommender might be a real estate agent offering to show the home buyer a particular property or a childcare agency <ref type="bibr" target="#b57">Dzyabura and</ref><ref type="bibr">Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417-441, © 2019 INFORMS</ref> scheduling interviews for parents with potential caregivers. We are particularly interested in automated recommendation systems. After searching the recommended product, the consumer continues to search optimally given the consumer's beliefs, according to Equation (3).</p><p>For simplicity, we prefer to make the assumption that the consumer searches the recommended product, but the assumption also can be motivated with an assumed utility bonus (U bonus &gt; 0) to represent a belief by the consumer that the recommender knows something about the recommended product (not known to the consumer). The consumer trusts that, for some reason to be revealed during search, consumption utility is increased by the utility bonus. In other words, the consumer believes that the expected utility of recommended product ℓ is E[Σ i 1 to I w i x il | f t ] + U bonus . If the bonus is sufficient but not so large that the consumer purchases product ℓ without searching, then it is optimal for the consumer to search the recommended product. At the end of search, knowledge gained by searching overwhelms any ephemeral utility bonus. The consumer's consumption utility is based on w r .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Preference-Weight Learning vs. Attribute-</head><p>Level Learning Equation ( <ref type="formula" target="#formula_2">3</ref>) is reminiscent of the Bellman equations used in classical models of optimal sequential search but with key differences. For example, Equation (3) shares <ref type="bibr">Weitzman's (1979, p. 643</ref>) assumption that "the sum of search costs is paid during search, whereas the maximum reward is collected after search has been terminated." However, unlike in <ref type="bibr" target="#b51">Weitzman's (1979)</ref> model, the updates in Equation (3) do not necessarily reveal the value of the searched product with a single observation. Slower learning is assumed in learning models, such as in <ref type="bibr" target="#b12">Chick and Frazier (2012)</ref>, when, each time the consumer searches, the consumer observes a random draw from a distribution rather than the true parameter value. More critically, in search models, such as <ref type="bibr" target="#b51">Weitzman (1979)</ref>, and search with learning models, such as <ref type="bibr" target="#b12">Chick and Frazier (2012)</ref>, product utilities are independent. Independence is often assumed in search models because independence enables relatively simple search policies called "index policies." With an index policy for search, the optimal search strategy continues until the revealed product (or attribute) exceeds an index determined by a simpler Bellman equation. Index strategies break the curse of dimensionality. When independence during search is lost because of preference-weight learning, we know of no optimal or near-optimal index strategies.</p><p>Index strategies are also important for a different, but related, set of dynamic programs: multiarmed bandit problems. Multiarmed bandit problems share the property of search with learning problems that multiple alternatives are each described by reward distributions, but multiarmed bandit problems differ because rewards can be obtained in each period rather than only at the end of search. The consumer decides which alternative ("arm") to try by balancing immediate rewards versus the long-term benefits from learning about the reward distribution to choose better in the future. The consumer sequentially tries alternatives, but unlike search problems, the consumer receives a potential payoff every time an arm is pulled rather than only receiving the reward from the chosen product (or outside option) at the end of search. When the alternatives are independent, <ref type="bibr" target="#b22">Gittins (1979)</ref> demonstrated that the optimal policy is to choose the alternative with the largest index. <ref type="bibr" target="#b52">Whittle (1988)</ref> extended index policies to restless bandits with which the value of the nonchosen alternatives can change independently. Many bandit problems have been shown to be indexable <ref type="bibr" target="#b23">(Gittins et al. 2011)</ref>, including the partially observable Markov processes in website and banner morphing <ref type="bibr" target="#b28">(Hauser et al. 2009</ref>). When there is a switching cost between arms, the bandit is said to have "memory," and multiple indices might be required <ref type="bibr" target="#b33">(Jun 2004)</ref>. In some cases, structured interdependence is allowed, and greedy policies perform near optimally <ref type="bibr" target="#b40">(Mersereau et al. 2009</ref>). In the marketing literature, multiarmed bandit models have been used to model consumer purchases in consumer packaged goods categories <ref type="bibr" target="#b36">(Lin et al. 2014)</ref>, to optimize advertising creative <ref type="bibr" target="#b44">(Schwartz et al. 2017)</ref>, and in revenue management for optimal pricing <ref type="bibr" target="#b41">(Misra et al. 2017)</ref>. Research on multiarmed bandits is extensive and ongoing. In time, concepts from this literature might provide new insights into search models with preference-weight learning.</p><p>The very nature of preference-weight learning induces interdependence among product utilities: every time a preference weight is updated, the utilities of all products with the corresponding attribute level, including those already searched, can change. Index policies are unlikely to be optimal. We know of no simplifying policy that provides an optimal solution for Equation (3), nor for recommendations that influence a consumer who bases optimal search on Equation (3). Even in simple two-product, two-attribute markets, relationships to determine the optimal policy are complex. The curse of dimensionality applies. (See the appendix, which illustrates Equation (3) with and without a recommendation system.)</p><p>Interdependence and the curse of dimensionality require that realistic recommendation systems rely on heuristic policies. For example, if all attribute combinations were feasible in a product space with 10 attributes at six levels each, a single recommendation would require that we evaluate almost 60 million candidate recommendations. This number would grow to more than three quadrillion pairwise recommendations for a top-two recommendation system (which recommends two products sequentially). Without any special structure, the memory requirement of the dynamic program in Equation ( <ref type="formula" target="#formula_2">3</ref>) grows exponentially with the size of the problem. It is no surprise that applied recommendation systems rely on heuristics. To be consistent with applications and with the recommendationsystems literature, we explore recommendation-system modifications that are likely to be feasible in applied situations. These modifications are necessarily heuristic. We develop potential heuristics by examining the structure of consumer search and the implied recommendation policies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Insights About Search and Recommendation</head><p>Equation ( <ref type="formula" target="#formula_2">3</ref>) implies that the consumer must make trade-offs among search costs and the reward to purchasing without search versus the knowledge gained from further search and improved rewards that come from a later purchase. Equation ( <ref type="formula" target="#formula_2">3</ref>) becomes even more challenging when a recommendation system is introduced. The complexities, because of the interdependence imposed by preference-weight learning, require that we seek qualitative insights toward potential heuristic modifications to recommendation systems. This section provides insights; Section 7 develops and tests recommendation systems that implement modifications based on the insights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Recommendation-System Beliefs</head><p>A key component of the Candice and Dave condominium vignette was that the agent had beliefs about Candice and Dave's preference weights and that these beliefs were better (closer to the true preferences) than Candice and Dave's initial beliefs. Let f rec (w i ) be the recommendation system's beliefs about the consumer's preference weights. For some attributes, the recommendation system's priors may match the consumer's priors ( f rec i f t i ), but for other attributes, the recommendation system may believe that the consumer's beliefs are not accurate (</p><formula xml:id="formula_3">f rec i ≠ f t i ).</formula><p>In this notation, we do not require that the recommendation system know the consumer's true beliefs w r i perfectly. The recommendation system's beliefs may be a probability distribution. However, if the recommendation system is to be valuable, f rec ( w) should, in some sense, be closer to w r than is f t ( w). We quantify "closer" as follows. (We assume that the recommendation system cannot credibly inform the consumer of its beliefs about the consumer's preference weights; it must do so implicitly by recommending products to the consumer.)</p><p>By assumption, if the recommendation system recommends product j at time t, then s t j. The key difference between the recommendation system and the consumer is that the recommendation system expects the first (or first few) updates to be based on f rec . When the number of potential recommendations is small, as in the example in the appendix, the optimal recommendation can be found by exhaustive enumeration. When the number of products is more typical, we must rely on heuristic policies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Aspect Diversity</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Consumer Search in a Full-Factorial Product</head><p>Space. Consider first a full-factorial product space in which, for I binary attributes, all 2 I possible combinations of attribute levels are available as products. In Equation ( <ref type="formula" target="#formula_2">3</ref>), the search costs are product based, not attribute based; thus, searching a product j with x ij 1 for I attributes is no more costly than searching products with x ij 1 for only one attribute. By contrast, if the consumer were to search the product with I attributes present, the consumer would gain more information than the consumer would by searching a product with one attribute present. (The consumer can still decide to purchase the one-attribute-present product. Unlike bandit problems, there is no immediate reward during search. Search produces knowledge to improve net consumption utility after a product or the outside option is chosen.) If the optimal solution at t 1 were for the consumer to search a product, then the best product to search is the product j with all I attributes present x ij 1 for all i. The insight has intuitive appeal. Real estate agents often recommend that consumers search homes outside their price range to experience and learn about as many attributes as possible, such as proximity to playgrounds, swimming pools, full-service concierge, island kitchens, and media rooms. Automobile dealers often maintain test-drive cars with many "options." (For interested readers, a formal proof in a two-product, two-attribute product space is available from the authors.) 4.2.2. Full-Factorial Product Spaces Are Rare, Especially with Multilevel Attributes. The value of searching a fully attributed product to learn (update) preference weights raises a conundrum. It seems obvious that the consumer should always begin by searching the product with all I attributes present-no recommendations are needed. But recommendation systems are popular and highly researched. The answer to the conundrum is simple. In most realistic cases, fullfactorial product spaces are not available. Highly featured cars are priced high and may be outside the consumer's price range, leading to "sticker shock." Many possible attributes describe homes-a fully attributed property is exceedingly rare. The same can be said for caregivers, colleges, jobs, furniture, and dating opportunities. Recommendations are particularly valuable in product spaces with multilevel attributes in which, by definition, a fully attributed alternative is not available: a vehicle cannot simultaneously be a sedan, a coupe, a station wagon, a crossover, a minivan, an SUV, and a truck. Henceforth, to avoid confusion, we follow <ref type="bibr" target="#b48">Tversky (1972)</ref> and refer to a binary attribute level as an "aspect." A multilevel attribute is then a collection of aspects with the constraint that exactly one of the aspects in an attribute has x ij 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.3.">Aspect Diversity.</head><p>Despite the sparsity of fullfactorial product spaces, the insights about fully attributed products are useful. When consumers learn preference weights, it is valuable to search a product that has a diverse set of aspects. This insight is related to recent recommendation-system trends toward diverse, novel, or serendipitous products and may provide a partial theoretical explanation for those trends. However, aspect diversity is subtly different because it focuses on learning about preferences for aspects rather than for the products themselves.</p><p>Recommendation systems provide value by recommending products that improve the consumer's search, resulting in a higher terminal utility net of search costs relative to what the consumer would have searched without them. Thus, it is valuable to recommend products with aspects that have a high true preference weight but which the consumer would not otherwise have searched. This value comes into Equation (3) primarily in the continuation value J(S t ∪ {k}, f t+1 | f rec ). If product k has aspects the consumer would not have otherwise searched, the recommendation helps the consumer to make better subsequent search decisions and, ultimately, identify a higher utility product (net of search costs) to purchase and consume. We call a recommendation-system modification that implements this modification, "aspect diversity." There are many ways to implement an aspectdiversity heuristic. We have found that it is effective to modify the standard recommendation-system criterion (maximize expected utility based on f rec ) to include a penalty for recommending aspects the consumer would otherwise have searched. If s * t indicates the product the consumer would have searched without a recommendation, then the aspect diversity criterion becomes</p><formula xml:id="formula_4">x rec arg max j 1 to J E[Σ i 1to I w i x ij | f rec ] − λΣ i 1 to I x is * t x ij . (<label>4</label></formula><formula xml:id="formula_5">)</formula><p>The parameter λ determines how much emphasis the recommendation system places on diverse aspects. When λ 0, the recommendation system recommends the maximum-expected-utility product; when λ → ∞, the recommendation focuses primarily on diversity.</p><p>As is typical in recommendation-system applications, λ is a tuning parameter that is best chosen by experience or experimentation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Recommendation Systems That Use</head><p>Information About Expected Preference Weights Equations ( <ref type="formula" target="#formula_1">2</ref>) and ( <ref type="formula" target="#formula_2">3</ref>) rely on the consumer's priors f t , the recommendation system's priors f rec , and the signal distribution g(w r i |w i , s t j). In theory, recommendations might depend on the full distributions. For example, recommendations may vary depending on the rate at which the consumer learns preference weights. However, full distributions ( f t , f rec , and g) might be hard for the recommendation system to observe; the recommendation system might be much better at observing or predicting the mean of the distributions. For such cases, we begin with recommendationsystem modifications that rely only on the expected values of the preference weights and later consider recommendation-system modifications based on the full distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.1.">Conceptual Example.</head><p>Consider three condominiums that are similar on all attributes except playground proximity, type of kitchen <ref type="bibr">(traditional, open-concept, island)</ref>, and type of service (live-in superintendent, full-service concierge). Suppose that Candice and Dave's prior beliefs are such that they do not value playground proximity and prefer an island kitchen in a building with a full-service concierge. Suppose that the recommendation system believes that Candice and Dave undervalue playground proximity and correctly value an island kitchen but overvalue a fullservice concierge. Finally, suppose that the condominium stock in Candice and Dave's target market is limited-not all combinations of playground proximity, kitchens, and service are available. Intuitively, the recommendation that would lead to the largest shift in Candice and Dave's beliefs about their preference weights is a condominium, if available, that has playground proximity but a live-in superintendent. By improving Candice and Dave's understanding of their preference weights, the recommendation may lead them to purchase and consume a condominium with playground proximity. Candice and Dave may learn to forego a full-service concierge and allocate their limited budget to other high-valued aspects. (If nothing else, condo fees are less with a live-in superintendent than with a full-service concierge.) 4.3.2. Undervalued Products. The intuitive recommendation in the condominium example is based on both components of Equation ( <ref type="formula" target="#formula_2">3</ref>), E[Σ i 1 to I w i x ij | f rec ] and J(S t ∪ {k}, f t+1 | f rec ). By recommending a condominium near a playground, the recommendation system improves the for playground proximity (pp). It does so by shifting the priors toward a high-valued attribute level that the consumer currently undervalues. If the mean of f rec is closer to w r than the mean of f t , then the expected purchase and consumption utility is also improved. The continuation value comes into play because Candice and Dave can search more effectively for the next condominium when further search is optimal. They can do so because their objective function better matches their true utility (J(S t ∪ {k},f t+1 | f rec ) increases). The recommendation is a good recommendation if these gains are greater than the search cost c.</p><p>The suggested modification to a recommendation system is to recommend undervalued products, and "undervalued" implies that the expected utility based on the recommendation system's beliefs is higher than the expected utility based on the consumer's priors; that is,</p><formula xml:id="formula_6">E[Σ i 1 to I w i x ij | f rec ] &gt; E[Σ i 1 to I w i x ij | f t ].</formula><p>We implement the heuristic by identifying the products for which the difference between the recommendations system's beliefs about the consumer's expected utility and the consumer's beliefs about the expected utility is maximized</p><formula xml:id="formula_7">x rec arg max j 1 to J E[Σ i 1 to I w i x ij | f rec ] − E[Σ i 1 to I w i x ij | f t ].</formula><p>(5)</p><p>We call a recommendation system that implements this modification "undervalued products."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Differences in the Distributions of f rec and f t</head><p>In some cases, the recommendation system might be able to measure the variance (or the full distributions) of f rec and f t . If so, we might improve recommendations by allowing the recommendation system to use its knowledge of the preference-weight belief distributions and the signal, not just the means of the distributions. For example, a recommendation system might favor recommending products with aspects for which preference weights are updated more rapidly (less posterior variance) or products with aspects for which the recommendation system has tighter beliefs. We propose two such recommendation-system heuristics.</p><p>4.4.1. Option Value Discrepancy. We draw insight from search theory and focus on the option values for the attribute levels of a searched product. However, unlike in optimal search models, we take both f rec and f t into account. Because option values are easiest to understand for multilevel attributes, we temporarily modify our notation to accommodate multilevel attributes. In particular, let x iℓj 1 if product j has attribute i at level ℓ. We define w iℓ similarly. Then we implement the heuristic as follows:</p><p>x rec arg max j 1 to J</p><formula xml:id="formula_8">I i 1 ℓ : x iℓj 1 ∞ w * i w iℓ df rec (w iℓ ) − ∞ w * i w iℓ df t (w iℓ ) , (<label>6</label></formula><formula xml:id="formula_9">)</formula><p>where w * i is the highest expected value over ℓ of w iℓ . (To make Equation ( <ref type="formula" target="#formula_8">6</ref>) feasible, we use the expected value for w * i rather than integrate over all possible outcomes.) We call a recommendation system that implements this modification "option value discrepancy." 4.4.2. Kullback-Liebler. We might also attempt to quantify the difference between the two distributions f rec and f t and use the quantified difference. A formal measure of distance between two distributions is the Kullback-Liebler divergence from f t to f rec , D KL ( f t f rec ). Kullback-Liebler divergence measures the nonsymmetric difference between two probability distributions. If a larger divergence between the two distributions leads to the most learning, then, returning to the x ij notation, a heuristic based on this concept is the following in which D KL,j is the Kullback-Liebler divergence for product j:</p><p>x rec arg max j 1 to J i:</p><formula xml:id="formula_10">x ij 1 D KL,j ( f t i f rec i ).<label>(7)</label></formula><p>We call a recommendation system that implements this modification "Kullback-Liebler." We provide more specific formulae in Section 7, in which we make distributional assumptions about f rec and f t .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Preference-Weight Learning Criteria</head><p>Preference-weight learning introduces new twists to existing literatures in recommendation systems and search theory. In particular, the modifications in Section 4 are based on criteria that differ from the typical criteria in the recommendation-systems literature and in the search-theory literature. In this section, we explore those differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Compared with Typical Recommendation-</head><p>System Criteria In the recommendation-systems and marketing-science literatures, most recommendation systems are evaluated on their ability to predict the products that consumers will choose. This is a reasonable criterion when the consumer knows the consumer's preference weights because, in such cases, the goal is to recommend the product that will deliver maximum purchase and consumption utility. This criterion will not maximize <ref type="bibr" target="#b57">Dzyabura and</ref><ref type="bibr">Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417-441, © 2019 INFORMS</ref> purchase and consumption utility when consumers learn preference weights.</p><p>Consider the condominium example. If the recommendation system were to recommend the condominium that maximizes expected utility based on f t , then Candice and Dave would choose a condominium without playground proximity in a full-service building. Candice and Dave would never know what they missed. Our example in Section 4.3.1 also implies that the best recommendation may not be the product Candice and Dave are most likely to choose. Instead, the best recommendation might be a condominium that the recommendation system believes Candice and Dave will never buy. Searching a condominium with a less desired kitchen but with playground proximity and their true preferred level of service might be the most efficient way for Candice and Dave to learn their preference weights for playground proximity and level of service. After updating their preference weights, Candice and Dave are more likely to search the product that maximizes the purchase and consumption utility net of search costs. The trends of product diversity, novelty, and serendipity can be interpreted as improving the continuation value in Equation ( <ref type="formula" target="#formula_2">3</ref>) because consumers learn their preference weights.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Compared with Typical Search-Theory Criteria</head><p>Because most search-theory analyses assume independence among products, efficient optimal policies are based on indices (e.g., <ref type="bibr" target="#b51">Weitzman 1979</ref><ref type="bibr" target="#b6">, Branco et al. 2012</ref>. Although the details vary, the indices tend to favor the upper tail of the probability distribution of product utility rather than the expected value of the product utility or the expected value of a level of the attribute. Upper-tail criteria (indices) represent the option value from the searched product (choose it, continue to search, or choose an already searched product). The option value represents the expected gain in utility if the product turns out to have higher utility than the current best option. If the expected utilities of two products are equal, these criteria favor products with high variance in utility distributions (if the distributions are from the same distributional family).</p><p>These criteria do not necessarily apply when consumers learn their preference weights in part because of the interdependence in Equation (3). Assume that Candice and Dave are now sure that their preference weight for playground proximity w playground is high, but they don't know how high. They have decided on an open-concept kitchen and a live-in superintendent but are now considering whether they want a condominium with an eat-in kitchen, a media room, or both. (Attribute level weights are net of added price.) There are three types of condominiums left to search:</p><p>1. {playground proximity = good, media room = yes, kitchen = not eat-in} 2. {playground proximity = good, media room = no, kitchen = eat-in} 3. {playground proximity = bad, media room = yes, kitchen = eat-in} Candice and Dave do not know whether they prefer a media room or an eat-in kitchen, but they know that having both has less preference weight than playground proximity, that is, w playground &gt; w media + w eat-in kitchen . Candice and Dave may choose to search condominiums in type 3 to resolve their preference weights for media rooms and eat-in kitchens even though the option values of both type 1 and 2 condominiums are higher. After resolving the uncertainty by evaluating type 3 condominiums, they can then choose a condominium of either type 1 or type 2. Their actual decision, and the decision on whether to continue to search, depends on the preference-weight distributions, the search costs, and the discount rate. We argue in Section 5.3 that prior preference-weight distributions exist such that the best strategy is to search type 3 condominiums and that such distributions are reasonable. The Candice and Dave example provides a counterexample to maximizing the option value of the searched products. The optimal product to search, a condominium of type 3, has no option value if Pr(w playground &gt; w media + w eat-in kitchen ) 1 because a condominium of type 3 would never have the highest utility. It also provides a counterexample to maximizing the option value of preference-weight distributions. The option value of the weight on playground proximity can be higher than the option value for the weights on the other attributes, but resolving playground-proximity uncertainty does not change Candice and Dave's decision.</p><p>The key mathematical insight is that, for preferenceweight learning, the continuation value in Equation ( <ref type="formula" target="#formula_2">3</ref>) is not separable in either products (j) or attributes (i) if the product space is not full factorial (if all 2 I products are not available). Resolving uncertainty by updating f t to f t+1 occurs for all aspects in the searched products, which, in turn, affects the option values of all products searched and to be searched.</p><p>The Candice and Dave vignette illustrates search without a recommendation. It is easy to embellish the vignette for recommendations. If f rec f t , the best recommendation remains type 3 condominiums. But suppose that f rec is such that the recommendation system believes that Candice and Dave undervalue eat-in kitchens; then the motivation for recommending a search of type 3 condominiums is even stronger.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Formal Demonstration of Intuition</head><p>Sections 5.1 and 5.2 provide intuitive examples to illustrate that neither the consumer's optimal search nor the best recommendations are based on the Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences traditional criteria. It remains to demonstrate that we can actually choose f t and/or f rec such that traditional criteria do not apply. The appendix contains two formal proofs for a product space with three aspects. The first formalization addresses optimal search when there is no recommendation system. The second formalization adds a recommendation system. Together the two results formalize the intuition from Sections 5.1 and 5.2. Because we need only establish the existence of consumer search and recommendation systems for which standard criteria do not apply, the formalizations allow the consumer to update beliefs fully with a single observation of an aspect.</p><p>Specifically, the appendix establishes that the criteria for the optimal search without a recommendation and for the optimal recommendation under preferenceweight learning:</p><p>• Differ from typical criteria in recommendation systems.</p><p>• The best recommendation may not be the product with the highest expected utility.</p><p>• The best recommendation may be a product that the consumer is unlikely to choose.</p><p>• Differ from typical criteria in optimal search.</p><p>• The best product to search (recommend) may not be the product with the highest option value.</p><p>• The best product to search (recommend) may not have the largest variance in utility.</p><p>The formal demonstrations tell us what the recommendation should not do. In Section 4, we proposed three criteria for new recommendation systems:</p><p>• Modification 1: Recommend products with diverse aspects.</p><p>• Modification 2: Recommend products with undervalued expectations (E[ f rec ] versus E[ f t ]).</p><p>• Modification 3: Recommend products to move the consumer's priors closer to the recommendation system's priors.</p><p>The suggested modifications are consistent with and provide a marketing-science explanation for recent trends in the recommendation-systems literature (diversity, novelty, and serendipity). However, preference-weight learning suggests that diversity should be with respect to aspects, novelty should be based on not-yet-searched aspects, and serendipity should focus on products with aspects that are undervalued.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Recommendations When Consumers Learn Preference Weights</head><p>Before we test the proposed recommendation-system modifications, we gain insight by exploring how recommendations influence the consumer's search path.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Structure of the Synthetic Data</head><p>We examine a product space defined by three six-level attributes. The 18 (18 3 × 6) aspects in our product space are sufficient to illustrate interesting phenomena but not so complex as to make calculating postrecommendation search infeasible. With three six-level attributes, 6 × 6 × 6 216 feasible products exist in the product space. Let L k denote the set of aspects that correspond to levels of attribute k. The consumer's prior beliefs f 0 i for all aspects i are normally distributed and independent over aspects. We denote the means and standard deviations of the aspect-based normal distributions byw i and σ i such that f 0 i 1(w 0 i , σ 0 i ). The signal obtained about the preference weight by searching a product with the corresponding aspect is also normally distributed g 1(w r i , σ s i ). These assumptions imply that the posterior distributions, updated from product search, are normally distributed f t i 1(w t i , σ t i ). The formulas for the posterior distributions are standard and given in the online appendix. The posterior mean is a convex combination of the prior mean and the true mean. For ease of notation, we assume both the consumer and the recommender system know the preference weight for a base level (aspect) of each attribute. We set the preference weight of the base level to zero. (For example, such assumptions are necessary for identification in choice-based conjoint analysis.) The specific values of w → 0 , σ → 0 , and w → r are given in the online appendix.</p><p>Patterns similar to those discussed in this section emerge for a wide range of parameter values and numbers of attributes.</p><p>To simplify the search problem, we assume that all 216 products are available. We call such product spaces "fully crossed" to distinguish them from the much larger full-factorial aspect spaces. In a fully crossed product space, the maximum-utility product is the product with the maximum-preference-weight level for each attribute. In a fully crossed product space, the search problem can be broken down by attribute. Returning to the multilevel attribute notation introduced in Section 4.4, for each attribute i, the consumer searches the product that maximizes (over levels) the option value of searching level ℓ in each attribute i, ∫ ∞ w * i w iℓ df t (w iℓ ), where w * i was defined in Section 4.4. Because the product space is fully crossed, there exists a product that has attributes at the maximizing levels. (Note that these option values apply attribute by attribute and only in a fully crossed product space. This does not contradict the option value result in Section 5.3.)</p><p>The attribute-level maximization policy is heuristic rather than optimal because the lower limit of the integral is based on expected values rather than a full (infeasible) solution to the Bellman equation. The attribute-level maximization heuristic approaches optimality as the signal variances (σ s i ) 2 approach zero. The attribute-level maximization heuristic outperforms other known heuristics, such as that by Chick and In this section, we evaluate the impact of a single recommendation for each consumer. A single recommendation is sufficient to affect the consumer's search path and illustrate the phenomena made possible by preference-weight learning. We allow multiple recommendations when we test the proposed recommendation-system modifications in Section 7.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Comparison of Recommended and</head><p>Chosen Products We evaluate recommendations of each of the 216 possible products. We assume that U bonus is such that the consumer searches the recommended product and then continues searching (near) optimally. At the (endogenous) end of search, the consumer either chooses a product or the outside option. We summarize the results in Figures <ref type="figure" target="#fig_1">1 and 2</ref>.</p><p>The vertical axis of Figure <ref type="figure" target="#fig_1">1</ref> plots the consumer's net payoff: the utility of the chosen product minus the incurred search costs. The horizontal axis of Figure <ref type="figure" target="#fig_1">1</ref> represents the true utility of the recommended product (based on w r ). The consumer learns (updates) f 1 after searching the recommended product and, perhaps, continuing to search. In Figure <ref type="figure" target="#fig_1">1</ref>, all recommendations lead the consumer to purchase one of three products, as indicated by the horizontal clusters. The net utility of the chosen product differs slightly because search costs differ. (Three products are not a general result. Different parameter values give different numbers of postsearch products.)</p><p>We first examine the product recommendation in Figure <ref type="figure" target="#fig_1">1</ref> that is represented by the diamond ( ). In this case, the recommendation system recommended the highest-utility product, and the consumer chose that product but ultimately did so after incurring more search costs than would have been incurred for other recommendations. This suggests that even if a recommendation system has perfect knowledge of consumer utility, the highest-utility product may not be the best recommendation if the consumer has to learn the consumer's own preferences. The recommendation indicated by a triangle ( ) also leads the consumer to the highest-utility product but does so by recommending a much lower-utility product. After receiving this recommendation ( ), the consumer learns efficiently that some attributes are more important and some are less important than previously thought.</p><p>The recommendation indicated by a square ( ) is interesting. For such recommendations, the consumer is satisfied with the recommended product and has no incentive to search further. Such recommendations by nonbenevolent recommenders (or poorly designed recommendation systems) exploit the consumer's naiïveté and lead the consumer to purchase a product that is not the highest true utility. The consumer would not update the priors sufficiently and never learn of better-than-expected-utility products but would be satisfied with the chosen product at the time of purchase. The consumer might even thank the recommendation system for a recommendation. For example, a nonbenevolent real estate agent might have incentives to recommend the agent's own listing to obtain both seller and buyer commissions <ref type="bibr" target="#b3">(Ansari et al. 2000)</ref>. Similarly, and with similar concerns, short-term gains might be tempting if paid advertising supported a recommendation system. The other interesting feature about the recommendation denoted by a square ( ) is that other recommendations ( ) exist with lower initial utility that lead to higher postsearch utility.</p><p>Recommendations, such as indicated by a circle ( ), lead the consumer to choose low-utility products. After following such recommendations, the consumer, acting optimally based on priors, updates some of the preference weights but never updates preference weights sufficiently to find the highestutility product. Postsearch, the consumer believes falsely that the consumer has found the product that has the highest utility. Despite the opportunity loss, the consumer might be satisfied. Without a recommendation and without search, the consumer in this example would have chosen the product the consumer believes would maximize utility. The consumer would have expected to receive utility of 11.4 from this purchase but, on consumption, would only have received utility of 9.4. Had the consumer searched without a recommendation and chosen optimally after searching this product, the consumer would have received utility of 10.7, basically in the middle tier of products that could have been recommended.</p><p>Figure <ref type="figure" target="#fig_2">2</ref> provides a different perspective based on the same set of candidate recommendations. Figure <ref type="figure" target="#fig_2">2</ref> compares net postsearch utility to recommendationsystem beliefs. In this illustration, the mean of the recommendation-system beliefs f rec is a convex function of the mean of the consumer's prior beliefs f 0 and the consumer's true beliefs f ( w r ). As anticipated by Section 5 and as represented by a hexagon ( ), a recommended product, thought by the recommendation system to be the highest-utility product, does not lead the consumer to the highest-utility product. After receiving that recommendation ( ), the consumer, acting optimally based on priors, would not search sufficiently to find the true highest-net-utility product. A recommendation system would have served the consumer better had it recommended the product indicated by a diamond ( ) or even the product indicated by a triangle ( ). In the latter case ( ), the recommendation itself would not have been a high-utility product, but the recommendation would have caused the consumer to update beliefs and continue searching until the highest-net-utility product was found.</p><p>In Figures <ref type="figure" target="#fig_1">1 and 2</ref>, the utilities of the recommended products and the net utilities of the chosen products are correlated (ρ 0.43, ρ 0.28, respectively), but the relationship is well below 1.0. Preference-weight learning drives the lack of perfect correlation. Detailed examination of the search path reinforces the insights obtained from Section 4: the best recommendations are those that encourage the consumer to search products that reveal diverse aspects and undervalued aspects. Figure <ref type="figure" target="#fig_2">2</ref> reinforces the insight Marketing <ref type="bibr">Science, 2019</ref><ref type="bibr">, vol. 38, no. 3, pp. 417-441, © 2019</ref> that good recommendations provide valuable information. Figures <ref type="figure" target="#fig_1">1 and 2</ref> allow the consumer to be surprised either positively (preference weight higher than priors) or negatively (preference weight lower than priors). Both forms of preference-weight learning are valuable to consumers.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Preference-Weight-Learning Recommendation-System Evaluations</head><p>To explore whether the modifications suggested in Section 4 improve recommendation-system performance, we expand the analyses of Section 6 to 5,000 consumers in multiple experimental conditions. Because the value of preference-weight learning depends on differences in f rec and f t , our experimental conditions vary with respect to the quality of consumers' priors (naïveté), the quality of the recommendation system's priors (recommendation-system knowledge), and the rate at which consumers update their preference weights. By design, consumers learn their preference weights as they search products. Our synthetic-data experiments are proof-of-concept experiments: we examine whether the recommendationsystem modifications improve recommendationsystem performance when consumers learn their preferences. We complement these synthetic-data experiments with an empirical demonstration in Section 8. We expect preference-weight learning to be particularly relevant for naïve consumers who are new to a product category. Naïveté is more likely for infrequent purchases, such as automobiles, housing, college choice, and nannies. Naïveté is also more likely for consumers who feel they need recommendations. Because the preference-weight-learning modifications use more complete knowledge about f rec and f t than do typical recommendation-system benchmarks, we expect the incremental value of the preference-weightlearning modifications to generally increase with recommendation-system knowledge. The exception is low recommendation-system knowledge when we expect that no recommendation system does well. We expect that faster updating should favor the preference-weight-learning modifications.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1.">Product Space and True Consumer Utilities</head><p>We simulate a product space of three six-level attributes using the same structure that we used in Section 6. We consider recommendation systems that recommend two products sequentially. For each experimental condition and for each of 5,000 consumers in that experimental condition, we draw true aspect preference weights from a mixture of two normal distributions: one with a low mean to represent unimportant aspects and one with a high mean to represent important aspects. The consumer's prior beliefs are normally distributed and independent over aspects and depend on naïveté, as described in Section 7.2. The variances of the consumers' priors (v i in the online appendix) are drawn independently and identically distributed from an exponential distribution. The specific values of the parameters of the preference-weight distributions are given in the online appendix. For readers wishing to explore other parameter values, other recommendationsystem modifications, or other combinations of naïveté, recommendation-system knowledge, or the rate of updating, the software is available from the authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.">Characteristics Varied in the Synthetic</head><p>Data Experiments 7.2.1. Consumer Naïveté. For each consumer, we set the prior means equal to the true means for a fraction of the aspects. For the remaining aspects, we redraw the prior means randomly. A consumer is more naïve (less expert) if a larger fraction of the consumer's prior beliefs are redrawn randomly. We vary this fraction (η in the online appendix). An expert has naïveté equal to zero, and a novice has naïveté equal to one.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2.2.">Recommendation-System Knowledge.</head><p>For some aspects, we set the recommendation system's priors to the consumer's priors (probability P c ). For the remaining aspects, we set the mean of the recommendation system's priors to the true partworths with probability P rec , and we set the recommendation system's priors randomly with probability 1 − P rec . Larger P rec implies greater recommendation-system knowledge. We maintain the P c parameter to recognize that, even with P rec 1, recommendation systems are unlikely to ever know the true preference weights perfectly. The variances of the recommendation-system priors are constant for all consumers. (In theory, we can manipulate recommendation-system knowledge by manipulating the means, the variances, or both. Exploratory simulations suggest that it is sufficient to manipulate the means.)</p><p>There are a number of well-established methods by which recommendation systems learn consumers' priors and consumers' true preferences. Collaborative filters, content-based filters, and statistical model-based systems, as reviewed in Section 2, are just a few examples. Methods for such firm-side learning are well established in theory and in practice, but research on improvements continues. In a related context, <ref type="bibr" target="#b27">Hauser et al. (2014b)</ref> illustrate that, in automated systems, firm-side learning about the best "morph" can be decoupled from learning about consumers' cognitive styles. (The analogy is recommendation policy ⇔ morph and consumer beliefs ⇔ cognitive style. The mathematical structure, while related, is not identical.) Recommendation-system knowledge is likely to <ref type="bibr">Dzyabura and Hauser:</ref> Recommending Products When Consumers Learn Their Preferences be greater if consumers are more homogeneous, if consumers' priors can be measured directly, if true preferences can be estimated as a function of observable characteristics of the consumer, or if the recommender system has access to more data. (Manipulating the heterogeneity of the environment provides an alternative method to manipulate recommendation-system knowledge. Results are similar.) 7.2.3. Rate of Updating. The rate at which the consumer converges to the true utility parameters depends on the variance of the signal, (σ s i ) 2 in the online appendix. We vary this parameter in our experiments. In some experimental conditions, consumers update their priors rapidly (low signal variance), and in other experimental conditions, consumers update their priors slowly (high signal variance).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.">Preference-Weight-Learning Recommendation</head><p>Systems and Benchmark We test four recommendation-system modifications that implement the insights and equations from Section 4. We compare these modifications to the typical benchmark recommendation system. The basic concepts are reviewed here. Recommendation system priors are</p><formula xml:id="formula_11">f rec i 1 (w rec i , σ rec i ). 7.3.1. Maximum-Expected-Utility Benchmark.</formula><p>The maximum-expected-utility recommendation system recommends products that it expects will give the consumer the highest utility (based on f rec ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.2.">Aspect Diversity.</head><p>The aspect-diversity modification modifies the benchmark recommendation system by subtracting a penalty proportional to the number of aspects in common with the product the consumer would have searched without a recommendation [Equation ( <ref type="formula" target="#formula_4">4</ref>)].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3.3.">Undervalued Products.</head><p>The undervalued-products modification compares the consumer's mean prior beliefs f t to the recommendation system's mean beliefs f rec and maximizes the difference in expect utility [Equation ( <ref type="formula">5</ref>)]. Preliminary experiments suggest that we improve recommendations for this modification when make the recommendation less sensitive to small variations. When the variation is below a threshold, it is likely the consumer has learned the consumer's preferences; we revert to the benchmark. 7.3.5. Kullback-Liebler. The Kullback-Liebler modification compares the Kullback-Liebler divergence for every aspect in product j and recommends the product for which the divergence is largest (Equation ( <ref type="formula" target="#formula_10">7</ref>)). When the consumer's prior beliefs and the recommendation system's beliefs are normally distributed, the Kullback-Liebler divergence D KL,j for each product j is given by Equation ( <ref type="formula" target="#formula_12">8</ref>):</p><formula xml:id="formula_12">D KL,j ( f t f rec ) 1 2 i:x ij 1 σ t i σ rec i 2 + (w rec i −w t i ) 2 (σ rec i ) 2 + 2 ln σ rec i σ t i − 1 .<label>(8)</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4.">Results of the Synthetic Data Experiments</head><p>We vary consumer naïveté and recommendationsystem knowledge in 10 equal steps each from 0.1 to 1.0 for each level of signal variance and for each of five recommendation systems. In each of the experimental conditions, each of 10,000 consumers receives two sequential recommendations. The consumer searches the first recommended product and updates preference weights. The consumer then searches the second recommended product. The consumer either purchases a product or continues to search (near) optimally until the optimal stopping rule is reached. Performance is the difference between net utility achieved by a consumer who searches the product recommended by the recommendation-system modification and the net utility the consumer would have achieved without a recommendation. Net utility is the true utility of the chosen product, if any, minus the incurred search costs.</p><p>To visualize the patterns that emerge from the synthetic data experiments, we plot performance of the system while varying one parameter and holding two other experimental variables constant. Because consumer preference weights are redrawn for each of the 10,000 consumers, we subtract from net utility the utility of the product the consumer would have chosen without a recommendation. Because we are interested in performance relative to the benchmark (maximum expected value recommendations), we subtract benchmark performance from the performance of each recommendation system in our plots. (The performance of the benchmark, relative to no recommendation, is plotted in the online appendix. As expected, the benchmark performance increases for both consumer naïveté and recommendation system knowledge.)</p><p>Figure <ref type="figure" target="#fig_4">3</ref> plots relative performance versus consumer naïveté holding recommendation-system knowledge constant; Figure <ref type="figure" target="#fig_5">4</ref> plots relative performance versus recommendation-system knowledge holding consumer naïveté constant. Each figure contains a plot for <ref type="bibr" target="#b57">Dzyabura and</ref><ref type="bibr">Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417-441, © 2019 INFORMS</ref> slow consumer updating (high signal variance) and for fast consumer updating (low signal variance). We chose intermediate values for the experimental variable that is held constant: naïveté = 0.6 and recommendationsystem knowledge = 0.6. Figures <ref type="figure" target="#fig_4">3 and 4</ref> illustrate how naiveté and recommendation system knowledge affect relative performance as a function of consumer naïveté, recommendation-system knowledge, and the rate of updating.</p><p>Figures <ref type="figure" target="#fig_4">3 and 4</ref> suggest that aspect diversity, undervalued-products, and option-value discrepancy improve recommendations relative to the improvement achieved by the recommendation-system benchmark. We did not plot the performance of Kullback-Liebler to keep Figures <ref type="figure" target="#fig_4">3 and 4</ref> readable. Although Kullback-Liebler takes the full distributions of f rec and f t into account rather than just their means, its complexity appears to be a handicap. It does not perform as well as the simpler recommendation systems.</p><p>The performance of the Kullback-Liebler recommendation system is available from the authors.</p><p>Diverse aspects does better than the recommendationsystem benchmark over the entire range of naiveté. Undervalued-products and option-value discrepancy do extremely well for highly naïve consumers but are slightly counterproductive relative to the benchmark for expert consumers. The latter is not surprising. There is little value to exploration of preference weights when consumers already know their preference weights. Furthermore, when consumers know their preference weights, they are more likely than the tested recommendation system to choose the best product to search. Overall, the best recommendation system for naïve consumers is undervalued products. The best recommendation for expert consumers is diverse aspects, although it does not do much better than the benchmark. The proposed recommendation systems do slightly better when consumers update their preference weights rapidly; however, the relative improvement is slight, and the pattern is similar to that of the slow-updating case.</p><p>When we vary recommendation-system knowledge holding consumer naïveté constant at an intermediate value (0.6), all the proposed recommendation systems beat the benchmark. Undervalued products tends to be best except for very high recommendation-system knowledge. Once again, the algorithms do slightly better when consumers update their preference weights rapidly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.5.">Summary of Synthetic Data Experiments</head><p>Figures <ref type="figure" target="#fig_4">3 and 4</ref> demonstrate that situations exist in which recommendation-system modifications based on preference-weight learning improve the consumer's net utility more than the typical recommendationsystem benchmark. (Improvement is relative to no recommendation.) All three proposed modifications do well over most of the ranges, and the performance appears to be robust with respect to the rate of updating. With refinement and tuning, we expect the relative performances of all the modifications to improve further. For example, we might test a heuristic that combines the best features of the undervaluedproducts and the aspect diversity modifications, or we might tune either or both modifications. We might modify Kullback-Liebler to be more robust. For readers wishing to explore refinements, software is available from the authors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Empirical Demonstration</head><p>We began Section 1 with premises that (1) consumers learn preference weights while searching products and (2) recommendation systems can anticipate consumers' (true) preference weights. Based on these premises, we proposed recommendation systems that take preference-weight learning into account. Synthetic Marketing <ref type="bibr">Science, 2019</ref><ref type="bibr">, vol. 38, no. 3, pp. 417-441, © 2019</ref> data suggest that undervalued products shows promise relative to a benchmark recommendation system, maximum expected utility, and relative to allowing consumers to choose without a recommendation. (For the remainder of this section, for simplicity, we call the three methods to search products "undervalued," "max expected," and "choice," respectively.) In this section, we describe an empirical study in which we demonstrate that the two premises are reasonable and that undervalued helps consumers learn preference weights better than either max expected or choice.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.1.">Context of the Empirical Demonstration</head><p>We consider a product space of five bicycles and six attributes. We created rich realistic descriptions of the five bicycles that, when studied by consumers, simulate product search. The bicycles vary on five of the six attributes of gel seat, folding ability, hydraulic brakes, nighttime visibility, and a low bar for stepthrough access. These attributes were chosen based on discussions with potential bicycle customers and a review of the bicycles available on the market. If a bicycle had the attribute, the rich realistic descriptions highlighted the attribute and its benefits in text and pictures. By design, none of the rich realistic descriptions mentioned the sixth attribute, variety of colors. With only five bicycles, the product space was not full factorial. There was no obviously dominant search strategy.</p><p>To encourage respondents to search and evaluate the bicycles seriously, respondents were asked to provide ratings and qualitative comments about any bicycles that they evaluated. Following standard procedures, before any analyses, we eliminated respondents who answered too fast, answered the same for all questions, or provided nonsense qualitative answers (13 respondents were eliminated). The sample was drawn from Amazon Mechanical Turk.</p><p>Respondents received the standard honorarium for completing the tasks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.2.">Basic Design</head><p>Figure <ref type="figure" target="#fig_6">5</ref> summarizes the study design. In the first stage, prior to providing recommendations or allowing the respondent to choose which bicycle to search, we collected data and trained a model by which the recommendation system can predict consumers' true preference weight distribution f rec ( w) (left side of Figure <ref type="figure" target="#fig_6">5</ref>). Next, respondents were assigned randomly to one of three experimental cells: choice (92 respondents), undervalued (110 respondents), or max expected (106 respondents) (right side of Figure <ref type="figure" target="#fig_6">5</ref>). The choice cell acts as a control: if assigned to choice, respondents chose which bicycle to search based on attribute-level summaries. If a respondent was assigned to undervalued or max expected, the recommendation system chose the bicycle for the respondent to search based on the algorithms in Section 7.3. Respondents who received a recommendation then searched the recommended bicycle. In all three cells, respondents first stated their prior preference weights w 0 , searched a bicycle (viewed a rich realistic description), rated their likelihood of purchase, and then stated their preference weights w 1 again. Preference weights were measured with a 10-point scale on which the most important attribute is given a 10. Likelihood of purchase was measured with a three-point scale. The study was pretested with 37 respondents to ensure that the respondent tasks were clear and relevant.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.3.">Training a Predictive Model for f rec ( w)</head><p>To train f rec ( w), we measure respondents' preference weights after they have searched all available bicycles (training data). We also measure consumer characteristics, such as age, gender, where they live (urban, suburban, rural, other), and how they plan to use the bicycle. Using linear regression, we predict w r E[ w| f rec ] as a function of these variables and the respondents' prior preference weights w 0 . The last variable accounts for heterogeneity in preference weights that is not tied to the observed characteristics. The predictive model is trained on 93 respondents. These respondents did not participate in the consumer search on the right side of Figure <ref type="figure" target="#fig_6">5</ref>. In practice, a recommendation system's underlying predictive model would be based on tens of thousands of respondents (or more); hence, our empirical demonstration is conservative.</p><p>8.4. Results of the Empirical Demonstration 8.4.1. Manipulation Checks. We first check whether the recommendation systems recommended bicycles that were different between recommendation systems and different from bicycles that respondents chose to search on their own. The distributions of bicycles differ among the three experimental cells (χ 2 117.8, d.f . 8, p &lt; 0.01); undervalued differs from max expected (χ 2 24.0, d.f . 4, p &lt; 0.01) and from choice (χ 2 77.9, d.f . 4, p &lt; 0.01). The attribute "variety of colors" serves as a control attribute: we do not anticipate that its preference weight would change after search. It did not: w 1 i − w 0 i = 0.12, 0.12, and 0.07 for undervalued, max expected, and choice, respectively, and no differences were statistically significant from zero nor statistically different between pairs of experimental cells. Finally, we expect undervalued to sacrifice the overall expected consumption utility of the recommended bicycle relative to max expected (and relative to choice) but hope the sacrifice is not substantial. Our surrogate for expected consumption utility is the stated likelihood of purchase. The average values were 2.2, 2.3, and 2.3 for undervalued, max expected, and choice, respectively; no differences were statistically significant between pairs of experimental cells. The data pass the manipulation checks: respondents in each of the three experimental cells chose or were recommended different bicycles, the preference weights for the control attribute did not change, and the surrogate for expected consumption utility behaved as anticipated.</p><p>8.4.2. Change in Preference Weights. We test the first premise by comparing preference weights before and after search using root-mean-square-change (RMSC) and the sum over all attributes. Additionally, we test whether undervalued is better at helping consumers to learn preference weights. Specifically, we test whether preference weights change more for undervalued than for the other two experimental cells. Changes are as predicted: RMSC = 0.81, 0.39, and 0.46, and the sum over attributes is 1.69, 0.20, and 0.53, respectively, for undervalued, max expected, and choice. Sums are significantly different from zero for undervalued and choice (p's &lt; 0.05). The change in the undervalued experimental cell is significantly larger than the change in either max expected or choice for both RMSC and for the sum of changes (p's &lt; 0.05), but the change in max expected is not significantly different than that in choice (p 0.34). On an attribute-by-attribute basis, the average preference weights (other than for the control attribute) increase significantly or marginally significantly when respondents search bicycles recommended by undervalued (p's &lt; 0.05 for gel seat, folding ability, and a low bar; p's &lt; 0.10 for hydraulic brakes and nighttime visibility). These changes are larger than for those in the other two experimental cells. No attribute-level preference weights change significantly for max expected, and only hydraulic brakes increase significantly for choice (p 0.03). Qualitative comments were consistent, for example, "I changed the folding ability up to 10. I think I really want that in my next bike."</p><p>Thus, the data demonstrate that (1) product search can cause preference weights to change (at least for undervalued) and (2) searching undervalued recommendations causes preference weights to change more than searching benchmark recommendations (max expected) or searching without a recommendation (choice).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.4.3.">Moving Preference Weights Toward Their True</head><p>Values. Empirically, we cannot observe w r , but we can observe E[ w| f rec ]. To evaluate preference-weight learning, we compare the observed preference-weight change w 1 − w 0 with the predicted preference-weight change E[ w| f rec ] − w 0 . (We compare differences with control for heterogeneity in the w 0 .) We expect the two differences to move in the same direction if (1) the search changes preference weights and (2) the predictive model is reasonable. We test the movement with regressions (for each attribute and each experiment cell) in which the observed change is a function of the predicted change. We focus on directional movement, recognizing that the predictive models are based on simple regressions using training data for four variables from 93 respondents. Typical commercial recommendation systems might be based on hundreds of variables, tens of thousands of respondents, and state-of-the-art machine-learning methods. Users of commercial recommendation systems would likely search more products than the one recommended product in our tests.</p><p>For the undervalued experimental cell, the regression coefficient is significant for gel seat, folding ability, and hydraulic brakes (p's &lt; 0.05) and marginally significant for low bar (p &lt; 0.10). All coefficients are positive. For the max expected experimental cell, <ref type="bibr" target="#b57">Dzyabura and</ref><ref type="bibr">Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417-441, © 2019 INFORMS</ref> all coefficients are positive, but none are significant. For the choice experimental cell, the gel seat coefficient is positive and significant (p &lt; 0.05), and the low bar coefficient is positive and marginally significant (p &lt; 0.10). The coefficient is negative but not significant for visibility. Thus, when respondents search bicycles recommended by undervalued, their preference weights move in the direction that is predicted for the true preference weights. This movement is greater than the movement when respondents search benchmark recommendations (max expected) or when respondents search on their own (choice).</p><p>To summarize, the empirical demonstration is consistent with both premises (consumers can learn preference weights, and a recommendation system can predict that learning). The empirical demonstration also suggests that a proposed recommendation system leads to greater preference-weight learning than either a benchmark recommendation system or search without recommendations. We consider this empirical demonstration a proof of concept that we hope will be refined in subsequent tests.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Summary and Discussion</head><p>9.1. Summary When consumers update their preference weights as they search, the optimal search strategy becomes more complex because interdependence among products is introduced by preference-weight learning. Whenever a preference weight is updated, the update changes the utilities of all searched products and the expected utilities of all products yet to be searched. Optimal policies in classic search models, such as the policy derived in <ref type="bibr" target="#b51">Weitzman (1979)</ref>, are no longer optimal. When we introduce a recommendation system, the policies by which the optimal recommendations should be chosen are even more complex. In contrast to traditional recommendation-systems literature but consistent with recent developments with respect to diversity, novelty, and serendipity, preference-weight learning suggests that recommendation systems should not be evaluated solely on accuracy (probability of choice or expected utility of the recommended product).</p><p>Despite the complexity, we gain insight about effective recommendation systems for consumers who learn their preference weights by using intuition and examining the Bellman equation. These insights suggest modifications to recommendation systems: recommend products with diverse aspects, recommend products that the consumer undervalues, and recommend products most likely to update the consumer's prior beliefs. Recommendation systems based on these modifications perform well in synthetic data experiments, especially for naïve consumers and when recommendation systems can predict consumers' preference weights. The proposed recommendation systems perform well as long as they are not too complex.</p><p>We demonstrate empirically that consumers update their preference weights from searching even a single rich realistic description of a bicycle. Preference-weight learning is greater when consumers search a bicycle recommended by one of the proposed recommendation systems-greater than search based on a benchmark recommendation system or search without a recommendation. Furthermore, the actual change in preference weights moves as predicted, especially when consumers search products recommended by the proposed recommendation system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.2.">Generality</head><p>We expect the insights from the numerical examples, the synthetic data experiments, and the empirical demonstration to scale to larger product spaces. The proposed modifications are stylized proof-of-concept recommendation systems; we expect more sophisticated modifications to achieve even greater improvements, especially when tuned to specific settings. Our formal model assumes that consumers know attribute levels. Relaxing this abstraction greatly complicates the model but does not change the insight that preferenceweight learning affects search. Preference-weight learning and attribute-level learning are complementary phenomena.</p><p>We assumed that attributes are described by discrete levels (aspects). We did not restrict the attributes to be horizontal (type of kitchen) or vertical (livein superintendent versus full-service concierge), although we did assume that learning about one aspect does not affect the priors with respect to another aspect. Continuous attributes, such as the square footage in a condominium or the proximity to a playground, can be handled in one of two ways-both are common for typical preference-weight measurement methods, such as conjoint analysis. Either we discretize the continuous attribute or assume a parametric form (linear, quadratic, logarithmic) for the preference function. Discretized attributes are handled with no modification. For parametric preferences, we need to specify updating rules. For example, the consumer's preferences might be linearly increasing in square footage. The consumer updates that linear weight in a matter analogous to the updating rules in Equation (2). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.3.">Future Research</head><p>The analyses in this paper demonstrate that preferenceweight learning can have a major impact on the study of consumer search and on the design of recommendation systems. Further avenues of research are promising. Researchers might explore interdependence among preference weights for aspects and model how learning about one aspect informs preference weights about another aspect. Interdependence is especially interesting for discretized vertical attributes. Recommendation systems might be developed that identify the consumer's relative naïveté and change algorithms depending on that naïveté. Ensembles of recommendation systems might do well. We focused on situations in which consumers have ready access to attribute-level information. Combining preference-weight learning and attributelevel search is a complex and interesting challenge.</p><p>In Section 6, nonbenevolent recommendation systems influenced outcomes to the benefit of the recommendation system yet left the consumer satisfied. Such recommendation systems could prove interesting. We assumed that forward-looking consumers solve Equation ( <ref type="formula" target="#formula_2">3</ref>). An alternative interpretation is that heuristic solutions to Equation (3) approximate consumer search. For example, <ref type="bibr" target="#b36">Lin et al. (2014)</ref> illustrate situations in which consumers use a cognitively simple learning strategy that approximates a complex dynamic program.</p><p>We focused on benevolent recommendation systems that maximize consumers' net purchase and consumption utility. One justification for an assumption that the consumer searched recommended products is the utility bonus. It is possible that the utility bonus is not sufficient: the consumer might decline searching further if the expected utility of the recommended product is too low. This phenomenon might hamper the recommendation system's reputation and provide incentives to the recommendation system to avoid low-expected-utility recommendations even when such recommendations are in the best interests of the consumer. Such situations are worth studying.</p><p>Our examples and references from the marketingscience literature motivate preference-weight learning. Research on the underlying mechanism could improve insight. There are rich literatures in both recommendation systems and in marketing about firm-side learning of preference weights. When such algorithms are coupled with the modifications suggested in this paper, we expect that recommendations to consumers will improve.</p><p>Finally, our empirical demonstration was a proof of concept. Experiments might explore recommendations in other product categories with more attributes, in situations in which commercial prediction algorithms are used, for more extensive search, or with endogenous stopping rules.</p><p>Appendix. Formal Demonstrations A.1. Consumer Search Criteria When consumers learn their preference weights, there exist product spaces in which the consumer, searching optimally without a recommendation, may use search criteria that differ from the typical criteria in either search-theory or recommendation systems. In particular, unlike typical criteria in search theory, the consumer may choose to search a product that does not have the highest option value (highest variance). Unlike typical recommendation-systems criteria, the consumer may choose to search a product that does not have the highest expected utility. The product may even have a low or zero probability of being chosen.</p><p>Recognizing that β∫ ∞ max{0,w r 1 } w 2 df 0 2 (w 2 ) ≤ β∫ ∞ 0 w 2 df 0 2 (w 2 ) &lt; c for β ≤ 1, the consumer will not search x 3 after x 2 ; hence, E [J({ x 2 }, f )] max{0,w 1 }. Furthermore, because β∫ ∞ 0 w 1 • df 0 1 (w 1 ) − c &gt;w 1 , βE[ J({ x 2 }, f 1 )] − c &gt;w 1 ; hence, the consumer prefers to search x 2 rather than simply choose x 2 .</p><p>The expected value of searching x 3 is E[ J({ x 3 }, f 1 )] max 0,w 2 , −c + β ∞ max{0,w2} w 1 df 0 1 (w 1 ) ≤ max{0,w 2 } ∞ 0 w 2 df 0 2 (w 2 ) &lt; c, (A.9) which implies that the consumer will not choose to search x 3 (without a recommendation). Putting these together, if no recommendations are made, the consumer would search x 2 and then either purchase x 2 if w r 1 ≥ 0 or accept the outside option, U * 0, if w r 1 &lt; 0. The expected payoff based on the consumer's beliefs is given in Equation (A.10). Because f rec 1 (w 1 ) f 0 1 (w 1 ), this is also the recommendation system's belief about what the consumer will achieve without any recommendation.</p><formula xml:id="formula_13">E [J(Ø, f 0 )| f rec ] −c + β ∞ 0 w 1 df 0 1 (w 1 ) −c + β ∞ 0</formula><p>w 1 df rec 1 (w 1 ). (A.10)</p><p>We now analyze the cases in which the recommendation system recommends a product, x 2 or x 3 , and the consumer follows that recommendation. We assume the consumer acts optimally after the recommendation. (We later consider what would happen if the recommendation system could recommend both products.) We seek to establish a case in which the recommendation system recommends x 3 even though ∫ ∞ 0 w 2 df rec 1 (w 2 ) &lt; ∫ ∞ 0 w 1 df rec 1 (w 1 ). We first consider the expected payoff if the recommendation system recommends x 2 only. If x 2 is the recommendation, then the consumer does not deviate from the optimal path that the consumer would have chosen without a recommendation. Define J({ x 2 } rec , f 1 ) as the continuation value given that the consumer searched x 2 because of a recommendation. Then</p><formula xml:id="formula_14">E [J({ x 2 } rec , f 1 )| f rec ] −c + β ∞ 0 w 1 df rec 1 (w 1 ). (A.11)</formula><p>We now consider the expected payoff if the recommendation system recommends x 3 . After searching the recommended product, the consumer may stop and purchase x 3 , take the outside option (U * 0), or search the remaining product, x 2 . [Our condition that β∫ ∞ 0 w 1 df 0 1 (w 1 ) − c &gt;w 1 ensures that the consumer will not purchase x 2 without searching. It's easy to show that Equation (A.12) does not change that.] From the consumer's perspective, E [ J({ x 3 } rec , f 1 | f 0 )] max 0,w 2 , −c + β ∞ max{0,w2} w 1 df 0 1 (w 1 ) .</p><p>(A.12)</p><p>The consumer will search x 2 if β∫ ∞ max{0,w2} w 1 df 0 1 &gt; c +w 2 . We are interested in the recommendation system's expectation of this payoff, or E[ J({ x 3 } rec , f 1 )| f rec ]. This value depends on whether the consumer would choose to search x 2 after searching x 3 . Definew 2 to be the maximum observed value of w r 2 for which it would be optimal for the consumer to search x 2 after x 3 . This value is defined implicitly by β∫ ∞ w2 w 1 df 0 1 c +w 2 . If w r 2 &gt;w 2 , the consumer purchases x 3 and does not search x 2 because w r 2 &gt; −c + β∫ ∞ w2 w 1 df 0 1 (w 1 ). To compute the expected value, we consider three regions for the outcome of the x 3 search. Each outcome corresponds to a different action by the consumer after searching x 3 . These regions are w r 2 ≤ 0, 0 &lt; w r 2 ≤w 2 , and w r 2 &gt;w 2 . Note thatw 2 is defined by f 0 , but we compute expectations based on the recommendation system's beliefs f rec . Case 1. w r 2 ≤ 0. In this region, the consumer expects to search x 2 after x 3 because β∫ ∞ 0 w 1 df 0 1 (w 1 ) &gt; c. After searching x 2 , there are no products left to search; the consumer purchases x 2 if w r 1 &gt; 0 and takes the outside good if w r 1 ≤ 0. In this region, the recommendation believes</p><formula xml:id="formula_15">−c + βE [J({ x 3 } rec , f 1 )|w r 2 ≤0, f rec ] −(1 + β)c + β ∞ 0</formula><p>w 1 df rec 1 (w 1 ).</p><p>(A.13)</p><p>Case 2. 0 &lt; w r 2 ≤w 2 . In this region, by the definition ofw 2 , the consumer expects to search x 2 after x 3 , after which there are no products left to search. The net expected payoff to the consumer is −(1 + β)c + β max{0, w r 1 , w r 2 } according to the recommendation system's beliefs. Marketing <ref type="bibr">Science, 2019</ref><ref type="bibr">, vol. 38, no. 3, pp. 417-441, © 2019</ref> Note that we would also obtain the right-hand side of Equation (A.15) if the recommendation system were to recommend both x 2 and x 3 . Thus, we have shown that recommending x 3 alone weakly dominates recommending both products for sufficiently large β ≤ 1. We now rearrange the limits of integration to obtain (w 2 − w 1 )df rec 1 (w 1 )df rec 2 (w 2 ). (A.16) Equation (A.16) is a general condition for when the recommendation system will recommend x 3 to the consumer. All that remains to complete the proof is to establish at least one example in which the last two integrals in Equation (A.16) exceed c. We can do this for many distributions. We do it for at least one.</p><formula xml:id="formula_16">−c + βE[ J({ x 3 } rec , f 1 )| f rec ] ≥ −(1 + β)c + β ∞</formula><p>We consider uniform distributions, all of which have the zero mean: f 0 1 (w 1 ) f rec 1 (w 1 ) 8[−b 1 , b 1 ], f rec 2 (w 2 ) 8[ − αb 1 , αb 1 ], and f 0 2 (w 2 ) 8[−b 2 , b 2 ], where α &lt; 1 ensures that the option value of x 3 is less than the option value of x 2 and the variance of u( x 3 ) is less than the variance of u( x 2 ). If β 1, we ensure that β∫ ∞ 0 w 2 df 0 2 (w 2 ) &lt; c with b 2 &lt; 4c/β. We ensure that β∫ ∞ 0 w 1 df 0 1 (w 1 ) β∫ ∞ 0 w 1 df rec 1 (w 1 ) &gt; c and β∫ ∞ 0 w 2 df rec 2 (w 2 ) &gt; c with αb 1 &gt; 4c/β. The value of the next-to-last integral is βαb 1 /8, and the value of the last integral is βα 2 b 1 /24. Thus, for any positive α &lt; 1, the result holds as long as α 2 b 1 /24 +αb 1 /8 &gt; c/β. Because α &lt; 1, we have that α 2 &lt; α. Thus, we require only that α 2 b 1 &gt; 6c/β. This condition and the condition αb 1 &gt; 4c/β are satisfied for many values of α and b 1 . For example, if α 1/2, then it is sufficient that b 1 &gt; 24c/β. Prob{choose</p><formula xml:id="formula_17">x 3 } 1 4 + α 8 &lt; 1 2 − α 8</formula><p>Prob{choose x 2 } for all α &lt; 1. Finally, replacing the support of w 2 with f rec (w 2 ) 8[ −αb 1 − , αb 1 − ], condition (A.16) becomes −c/β + (αb 1 − ) 2 /8αb 1 + (αb 1 − ) 3 /24αb 2 1 &gt; 0. We choose &gt;0 so that E rec [8( x 3 )] &lt;E rec [u( x 2 )]. With 1/2, b 1 3, and c/β 0.1, setting 0.05 suffices. This completes the proof.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences expected reward because E[w pp x pp,j | f rec ]&gt; E[w pp x pp,j | f t ]</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Net Utility of Product Chosen After Search vs. Utility of Recommended Products</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 2 .</head><label>2</label><figDesc>Figure 2. Net Utility of Product Chosen After Search vs. Recommendation System's Beliefs About the Utility of the Recommended Product</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>7.3.4. Option-Value Discrepancy. The option-value discrepancy modification recommends products for which the attribute-based option values as calculated by the recommendation system are larger than the attribute-based option values as calculated by the consumer [Equation (6)]. Preliminary experiments suggest a threshold does not improve this modification.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Improvement in Net Utility as a Function of the Consumer's Naïveté</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Improvement in Net Utility as a Function of Recommendation System Knowledge</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. (Color online) Basic Design of the Empirical Demonstration</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Case 3.w 2 &lt; w r 2 . In this region, by the definition ofw 2 , the consumer chooses x 3 and does not search x 2 . But, because w 1 ) and w r 2 &gt; 0, we know E[ J({ x 3 } rec , f 1 | f rec )] max 0, net payoff in Case 3 is at least as large as that which the consumer would obtain by searching x 2 after x 3 , thus, the next payoff is at least as large as −(1 + β)c + β max{0, w r 1 , w r 2 }. By combining Cases 2 and 3, which occur according to the recommendation system's beliefs with probability Pr(w 2 &gt; 0) ∫ ∞ 0 w 2 df rec 2 (w 2 ), we obtain a lower bound on the recommendation system's beliefs for Cases 1-3 as−(1 + β)c + β max{0, w r 1 , w r 2 }: −c + βE[ J({ x 3 } rec , f 1 )| f rec ] rec 1 (w 1 )df rec 2 (w 2 ). (A.15) Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head></head><label></label><figDesc>− w 1 )df rec 1 (w 1 )df rec 2 (w 2 ) ≥ βE[ J(Ø, f 0 )| f rec ] − c + β</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc><ref type="bibr" target="#b57">Dzyabura and</ref> Hauser: Recommending Products When Consumers Learn Their Preferences   Marketing Science, 2019, vol. 38, no. 3, pp. 417-441, © 2019 INFORMS   </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences   Marketing Science, 2019, vol. 38, no. 3, pp. 417-441, © 2019 INFORMS  Frazier (2012, which is optimized for search with attribute-level learning among independent products. (Details available from the authors.)</figDesc><table /></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">MarketingScience, 2019, vol. 38, no. 3, pp. 417-441, © 2019 </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Proof. The formal analysis is based on binary attributes. However, to show the result, we need at least three binary attributes and not a full-factorial product space. Thus, we consider a product space of x 1 (0, 0, 0), x 2 (1, 0, 0), x 3 (0, 1, 0), x 4 (0, 0, 1), x 5 (1, 1, 0), x 6(1, 0, 1), and x 7 (0, 1, 1). In a proof available from the authors and as illustrated in Section 4, we demonstrate that the consumer will prefer searching those products that reveal two attributes, x 5 , x 6 , or x 7 , rather than those products that reveal only one attribute.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Because this result is an existence proof, we need only show an example. (We actually show a class of examples.) For our example, we assume zero signal variance such that the posterior distributions are δ(w r i ) when the consumer searches a product with x ij 1. We consider distributions for the consumer's prior beliefs in which the consumer prior beliefs assure that w r 1 , w r 2 , w r 3 ≥ 0 and min{w r 3 } ≥ max{w r 1 , w r 2 }. Our result is not limited to such distributions, but such distributions suffice. There are many distributions that satisfy these properties. For example, the conditions hold for uniformly distributed beliefs w i~8 [a i , b i ], with parameters a 1 , a 2 ≥ 0 and</p><p>The assumption of nonnegative true importances simplifies the tree of conditions in the dynamic program and ensures that the consumer weakly prefers x 5 to x 1 , x 2 , and x 3 ; weakly prefers x 6 to x 1 , x 2 , and x 4 ; and weakly prefers x 7 to x 1 , x 3 , and x 4 . We need only consider a product space of x 5 , x 6 , and x 7 . These are really the most interesting products for our purposes. The outside option is U * u( x 1 ) 0.</p><p>We first consider searching on x 5 . With min{w r 3 } ≥ max{w r 1 , w r 2 }, the consumer would never choose x 5 but may consider searching x 5 to learn w r 1 and w r 2 efficiently. We assume that β ≤ 1 is sufficiently large to justify search. After searching x 5 , the consumer will either choose the outside option, one of x 5 , x 6 , and x 7 , or search x 6 or x 7 , and perhaps if the consumer searches, the consumer will continue thereafter. Using Equation (3) in the text, we obtain</p><p>With min{w r 3 } ≥ max{w r 1 , w r 2 }, there is no value to searching to reveal w r 3 because knowing w r 3 does not change the consumer's decision. Using w r 1 , w r 2 , w r 3 ≥ 0, we eliminate the outside option as a choice. Using min{w r 3 } ≥ max{w r 1 , w r 2 }, we </p><p>The last step uses the consumer's prior beliefs to compute expected values for the w r i 's that are revealed by search. We now consider searching on x 6 . Using similar reasoning to Equation (A.1), we obtain</p><p>We first examine the value of further search. Searching either x 5 or x 7 reveals w r 2 , so the consumer is indifferent between searching x 5 or x 7 . We replace the value of further search by the value of searching one of the two products. As in the case of searching x 5 , further search beyond x 6 and x 5 or x 6 and x 7 has no value. Thus, we have, if the consumer were to choose to search,</p><p>If, after searching only x 6 , the consumer were to choose without search, then w r 1 and w r 3 are revealed, but the consumer expectsw 2 if x 5 or x 7 is chosen. Recall that the outside option and x 5 are dominated if consumer beliefs follow the example class of distributions. Thus, the value of choosing without search, that is, the second internal max in Equation (A.3), is given by the following:</p><p>Putting it all together and factoring out w r 3 , we obtain</p><p>Suppose that w r 1 ≥w 2 . Then, for all w r 1 , max{w r 1 ,w 2 , −c + βE w2 [max{w r 1 , w 2 }]} ≤ βE w2 [max{w r 1 , w 2 }] for sufficiently large β ≤ 1. This is true because, for the last internal max, max{w r 1 , w 2 } ≥ We have demonstrated that the consumer prefers to search x 5 rather than x 6 . The consumer's preference for searching x 5 rather than x 7 follows by symmetry. We have also demonstrated that, after the first product is searched, the consumer does not search further. Finally, we can easily show that the consumer will choose to search whenever −c + βE w1,w2 [max{w 1 , w 2 }] ≥ max{w 1 ,w 2 }. This must hold for some c and for sufficiently large β ≤ 1. By design, all possible realized values of w 3 are greater than any possible realized value of either w 1 or w 2 ; hence, both the expected utility and the option value of u( x 6 ) and u( x 7 ) dominate the expected utility and option value of u( x 5 ). By option value, we mean that</p><p>We have nowhere restricted the variances of prior beliefs. The result holds even if the variance of w 3 is greater than the variance of w 1 and the variance of w 2 . Finally, all possible realized values of w 3 are greater than any possible realized value of either w 1 or w 2 , and the consumer will never choose x 5 after searching x 5 . This completes the proof.</p><p>A.2. Recommendation System Criteria. For recommendation systems that take preference-weight learning into account, the optimal product to recommend may not satisfy the typical criterion that it be the highest expected utility (most likely to be chosen). The product might even have a low or zero probability of being chosen. Furthermore, the product may not have the largest option value as might be expected from optimal search theory.</p><p>Proof. This result is also based on binary attributes. We consider a three-product product space: x 1 (0, 0), x 2 (1, 0), and x 3 (0, 1). Because this result is an existence proof, we need only show an example. We begin by deriving general conditions and then show that there exists a class of examples that satisfy the general conditions.</p><p>We first examine the consumer's optimal search path in the absence of a recommendation. The consumer makes decisions based on the consumer's prior beliefs and revealed values. We are particularly interested in the case in which one of the attributes is undervalued by the consumer but not by the recommendation system:</p><p>The other attribute is not undervalued: f rec 1 (w 1 ) f 0 1 (w 1 ) and β∫ ∞ 0 w 1 df 0 1 (w 1 ) β∫ ∞ 0 w 1 df rec 1 (w 1 ) &gt; c. We are interested in the case in which the consumer searches (at least) x 2 , so we further assume that β∫ ∞ 0 w 1 df 0 1 (w 1 ) −c &gt;w 1 . For simplicity, we set the utility of the outside option to the utility of choosing x 1 (0, 0) such that U * u( x 1 ) 0.</p><p>We evaluate whether the consumer searches x 2 . The expected value of searching x 2 is E [ J({ x 2 }, f 1 )] max 0,w 1 , − c + β ∞ max{0,w r 1 } w 2 df 0 2 (w 2 ) .</p><p>(A.8) </p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Learning while searching for the best alternative</title>
		<author>
			<persName><forename type="first">K</forename><surname>Adam</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econom. Theory</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="252" to="280" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">On unexpectedness in recommender systems: or how to better expect the unexpected</title>
		<author>
			<persName><forename type="first">P</forename><surname>Adamopoulos</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tuzhilin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Intelligent Systems Tech</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="32" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions</title>
		<author>
			<persName><forename type="first">G</forename><surname>Adomavičius</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tuzhilin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowledge Data Engrg</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="734" to="749" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Internet recommendation systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Essegaier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="363" to="376" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Optimal search with learning</title>
		<author>
			<persName><forename type="first">S</forename><surname>Bikhchandani</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sharma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econom. Dynam. Control</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="333" to="359" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Recommendation systems with purchase data</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bodapati</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="77" to="93" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Optimal search for product information</title>
		<author>
			<persName><forename type="first">F</forename><surname>Branco</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Villas-Boas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="2037" to="2056" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Zooming in on choice: How do consumers search for cameras online?</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Bronnenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">F</forename><surname>Mela</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="693" to="712" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Novelty and diversity metrics for recommender systems: choice, discovery and relevance</title>
		<author>
			<persName><forename type="first">P</forename><surname>Castells</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName><forename type="first">C</forename><surname>Macdonald</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Clarke</surname></persName>
		</author>
		<title level="m">Proc. Internat. Workshop Diversity Document Retrieval</title>
				<meeting>Internat. Workshop Diversity Document Retrieval<address><addrLine>Dublin, Ireland</addrLine></address></meeting>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A new approach to evaluating novel recommendations</title>
		<author>
			<persName><surname>Celmaò</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Herrera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2008 ACM Conf. Recommender Systems</title>
				<meeting>2008 ACM Conf. Recommender Systems<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="179" to="186" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Sequential search with refinement: Model and application with clickstream data</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Yao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4345" to="4365" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Sequential sampling with economics of selection procedures</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Chick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Frazier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="550" to="569" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A general consumer preference model for experience products: Application to internet recommendation services</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chung</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><forename type="middle">R</forename><surname>Rao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="289" to="305" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">MiniDates schedules real-life (legitimately) blind dates for you</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cook</surname></persName>
		</author>
		<ptr target="https://techcrunch.com/2012/05/30/minidates-schedules-real-life-legitimately-blind-dates-for-you/" />
		<imprint>
			<date type="published" when="2012-05-30" />
		</imprint>
	</monogr>
	<note type="report_type">TechCrunch</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Offering online recommendations with minimum customer input through conjoint-based decision aids</title>
		<author>
			<persName><forename type="first">A</forename><surname>De Bruyn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Liechty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Ekre</forename><surname>Huizingh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Lilien</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="443" to="460" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Offline assortment optimization in the presence of an online channel</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dzyabura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagabathula</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="2767" to="2786" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Accounting for discrepancies between online and offline product evaluations</title>
		<author>
			<persName><forename type="first">D</forename><surname>Dzyabura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Jagabathula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Muller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="88" to="106" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Online dating: A critical analysis from the perspective of psychological science</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Finkel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">W</forename><surname>Eastwick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Karney</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">T</forename><surname>Reis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Sprecher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Sci. Public Interest</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="66" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Blockbuster culture&apos;s next rise or fall: The impact of recommender systems on sales diversity</title>
		<author>
			<persName><forename type="first">D</forename><surname>Fleder</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hosanagar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="697" to="712" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Beyond accuracy: Evaluating recommender systems by coverage and serendipity</title>
		<author>
			<persName><forename type="first">M</forename><surname>Ge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Delgado-Battenfeld</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Jannach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2008 ACM Conf. Recommender Systems</title>
				<meeting>2008 ACM Conf. Recommender Systems<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="257" to="260" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Designing ranking systems for hotels on travel search engines by mining user-generated and crowdsourced content</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="493" to="520" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Bandit processes and dynamic allocation indices</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gittins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Statist. Soc. Ser. B (Methodological)</title>
		<imprint>
			<biblScope unit="volume">41</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="148" to="177" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Gittins</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Glazebrook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Weber</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>London</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Multi-armed Bandit Allocation Indices</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Reasons for substantial delay in consumer decision making</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Greenleaf</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="186" to="199" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Consumer decision making in online shopping environments: The effects of interactive decision aids</title>
		<author>
			<persName><forename type="first">G</forename><surname>Häubl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">V</forename><surname>Trifts</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="21" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Self-reflection and articulated consumer preferences</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Product Innovation Management</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="17" to="32" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Website morphing 2.0: Switching costs, partial exposure, random exit, and when to morph</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liberali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1594" to="1616" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Website morphing</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Liberali</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Braun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="202" to="224" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Recommending Products When Consumers Learn Their Preferences Herlocker</title>
		<author>
			<persName><surname>Dzyabura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">; J</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Terveen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Trans. Inform. Systems</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5" to="53" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>Evaluating collaborative filtering recommender systems</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Using price distributions to estimate search costs</title>
		<author>
			<persName><forename type="first">H</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Shum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econom</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="257" to="275" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Quantifying search and switching costs in the US auto insurance industry</title>
		<author>
			<persName><forename type="first">E</forename><surname>Honka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econom</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="847" to="884" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Model-based purchase predictions for large assortments</title>
		<author>
			<persName><forename type="first">Bjd</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Donkers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="389" to="404" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A survey on the bandit problem with switching costs</title>
		<author>
			<persName><forename type="first">T</forename><surname>Jun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Economist</title>
		<imprint>
			<biblScope unit="volume">152</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="513" to="541" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Search for information on multiple products</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">T</forename><surname>Ke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z-Jm</forename><surname>Shen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="3576" to="3603" />
			<date type="published" when="2016" />
			<publisher>Villas-Boas</publisher>
		</imprint>
	</monogr>
	<note>JM</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Online demand under limited consumer search</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">B</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">J</forename><surname>Bronnenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1001" to="1023" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Learning from experience, simply</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="19" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Online evolutionary collaborative filtering</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">N</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Xiang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Yang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 4th ACM Conf. Recommender Systems</title>
				<meeting>4th ACM Conf. Recommender Systems<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2010" />
			<biblScope unit="page" from="95" to="102" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A video-based automated recommender (VAR) system for garments</title>
		<author>
			<persName><forename type="first">S</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="484" to="510" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Accurate is not always good: How accuracy metrics have hurt recommender systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Riedl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Konstan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Extended Abstracts on ACM Human Factors in Computing Systems</title>
		<imprint>
			<biblScope unit="page" from="1097" to="1101" />
			<date type="published" when="2006" />
			<publisher>ACM</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A structured multiarmed bandit problem and the greedy policy</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Mersereau</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Rusmevichientong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">N</forename><surname>Tsitsiklis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Automatic Control</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2787" to="2802" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Dynamic online pricing with incomplete information using multi-armed bandit experiments. Working paper</title>
		<author>
			<persName><forename type="first">K</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Abernethy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<pubPlace>Ann Arbor</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Michigan</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Predicting product purchase from inferred customer similarity: An autologistic model approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Moon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="71" to="82" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">After you read the listings, your agent reads you</title>
		<author>
			<persName><forename type="first">A</forename><surname>Rogers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New York Times</title>
		<imprint>
			<biblScope unit="page">F4</biblScope>
			<date type="published" when="2013-03-26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Customer acquisition via display advertising using multi-armed bandit experiments</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Schwartz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="500" to="522" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">The impact of search costs on consumer behavior: A dynamic approach</title>
		<author>
			<persName><forename type="first">S</forename><surname>Seiler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Quant. Marketing Econom</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="155" to="203" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Trigger features on prototypes increase preference for sustainability</title>
		<author>
			<persName><forename type="first">J</forename><surname>She</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">F</forename><surname>Macdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 25th ASME Internat. Conf. Design Theory Methodology</title>
				<meeting>25th ASME Internat. Conf. Design Theory Methodology<address><addrLine>Portland, OR</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Study: High school grads choosing wrong college majors</title>
		<author>
			<persName><forename type="first">K</forename><surname>Sheehy</surname></persName>
		</author>
		<ptr target="http://www.usnews.com/education/blogs/high-school-notes/2013/11/11/study-high-school-grads-choosing-wrong-college-majors" />
	</analytic>
	<monogr>
		<title level="j">U.S. News World Rep</title>
		<imprint>
			<date type="published" when="2013-11-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Elimination by aspects: A theory of choice</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Rev</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="281" to="299" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Listening-in&apos; to find and explore new combinations of customer needs</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="72" to="87" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Rank and relevance in novelty and diversity metrics for recommender systems</title>
		<author>
			<persName><forename type="first">S</forename><surname>Vargas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Castells</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 5th ACM Conf. Recommender Systems</title>
				<meeting>5th ACM Conf. Recommender Systems<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="109" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Optimal search for the best alternative</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">L</forename><surname>Weitzman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="641" to="654" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Restless bandits: Activity allocation in a changing world</title>
		<author>
			<persName><forename type="first">P</forename><surname>Whittle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Appl. Probab</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="287" to="298" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Leveraging missing ratings to improve online recommendation systems</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Ying</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Feinberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="355" to="365" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Avoiding monotony: Improving the diversity of recommendation lists</title>
		<author>
			<persName><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Hurley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 2008 ACM Conf. Recommender Systems</title>
				<meeting>2008 ACM Conf. Recommender Systems<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2008" />
			<biblScope unit="page" from="123" to="130" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Solving the apparent diversity-accuracy dilemma of recommender systems</title>
		<author>
			<persName><forename type="first">T</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Kuscsik</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J-G</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Medo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Wakeling</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y-C</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. Natl. Acad. Sci</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="4511" to="4515" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Improving recommendation lists through topic diversification</title>
		<author>
			<persName><forename type="first">C-N</forename><surname>Ziegler</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcnee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Konstan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Lausen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">ACM Proc. 14th Internat. Conf. World Wide Web</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="22" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<author>
			<persName><forename type="first">Hauser</forename><surname>Dzyabura</surname></persName>
		</author>
		<title level="m">Recommending Products When Consumers Learn Their Preferences Marketing Science</title>
				<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="417" to="441" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
