<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Explaining Preference Heterogeneity with Mixed Membership Modeling</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2020-03-03">March 3, 2020</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Marc</forename><forename type="middle">R</forename><surname>Dotson</surname></persName>
							<email>marc.dotson@byu.edu</email>
							<affiliation key="aff0">
								<orgName type="institution" key="instit1">Marriott School of Business</orgName>
								<orgName type="institution" key="instit2">Brigham Young University</orgName>
								<address>
									<postCode>84602</postCode>
									<settlement>Provo</settlement>
									<region>Utah</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Joachim</forename><surname>Büschken</surname></persName>
							<email>joachim.bueschken@kuei.de</email>
							<affiliation key="aff1">
								<orgName type="institution">Catholic University of Eichstätt-Ingolstadt</orgName>
								<address>
									<postCode>85072</postCode>
									<settlement>Eichstätt</settlement>
									<country key="DE">Germany</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Greg</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
							<email>allenby.1@osu.edu</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Fisher College of Business</orgName>
								<orgName type="institution" key="instit2">Ohio State University</orgName>
								<address>
									<postCode>43210</postCode>
									<settlement>Columbus</settlement>
									<region>Ohio</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Explaining Preference Heterogeneity with Mixed Membership Modeling</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
						<imprint>
							<date type="published" when="2020-03-03">March 3, 2020</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.2019.1185</idno>
					<note type="submission">Received: February 16, 2017 Revised: January 18, 2018; March 5, 2019; May 29, 2019 Accepted: June 7, 2019</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>choice models</term>
					<term>mixed membership models</term>
					<term>hierarchical Bayes</term>
					<term>grade of membership</term>
					<term>preference heterogeneity</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please scroll down for article-it is on subsequent pages</head><p>With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning opportunities for individual professionals, and organizations of all types and sizes, to better understand and use O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Marketing researchers have increasing access to data that can potentially explain preference heterogeneity. Such data are often discrete, including binary responses to select-all-that-apply questions, fixed-point rating scales, records of consumer behavior, and text, and are useful if they can point to individual-level differences in preference. However, these data often require models for their interpretation because the raw data can be prone to confounding effects <ref type="bibr" target="#b36">(Rossi et al. 2001)</ref> or may require summarization to provide greater meaning and context <ref type="bibr" target="#b9">(Büschken and Allenby 2016)</ref>. Hierarchical Bayesian (HB) choice models that incorporate preference heterogeneity are effective for determining what products consumers prefer. However, these models have proven less successful at explaining and interpreting preference heterogeneity. This paper explores a new model to incorporate discrete covariates into a choice model with heterogeneous preferences.</p><p>Including covariates to explain preferences in choice models can be problematic because of the resulting dimensionality of the coefficient matrix relating covariates to model parameters. For example, relating 10 part-worths in a conjoint study to 20 covariates in a model of heterogeneity requires at least a 10 × 20 coefficient matrix for the simplest data, which can be too demanding for even a moderately sized survey with 500 respondents. We investigate integrating a choice model with a covariate model to reduce the dimensionality and improve the interpretation of the coefficient matrix relating covariates and part-worths. The reduction in dimensionality comes from using parameters from the covariate model as regressors in the choice model rather than using the covariates themselves.</p><p>We develop a new HB choice model that relates individual-level part-worths to unobserved, individuallevel membership vectors from a grade of membership (GoM) model to discrete covariates <ref type="bibr" target="#b44">(Woodbury et al. 1978</ref><ref type="bibr" target="#b13">, Erosheva et al. 2007</ref>). The GoM model is related to the latent Dirichlet allocation (LDA) model, which serves as a touchstone within text analysis and topic modeling <ref type="bibr" target="#b8">(Blei et al. 2003)</ref>. Both LDA and GoM are part of a larger class of models known as mixed membership models that provide individual-level, low-dimensional representations of discrete data <ref type="bibr" target="#b0">(Airoldi et al. 2014)</ref>. This is accomplished by identifying patterns within the discrete data across respondents along with how each respondent relates to these patterns. We apply our model to two conjoint data sets and find that the integrated choice and GoM model improves predictive fit relative to either directly using the covariates as regressors or using competing models of heterogeneity.</p><p>This paper also contributes to efforts at using mixed membership models in marketing. The application of this class of models to marketing contexts is still in development. However, the dimension reduction inherent in these models is appealing. Extant research has focused on LDA models, using product reviews and online forums to inform market structure <ref type="bibr" target="#b26">(Lee and</ref><ref type="bibr">Bradlow 2011, Netzer et al. 2012)</ref> and to identify preferences for product features <ref type="bibr" target="#b6">(Archak et al. 2011)</ref>. More recently, <ref type="bibr" target="#b40">Tirunillai and Tellis (2014)</ref> used LDA to conduct brand analysis, <ref type="bibr" target="#b23">Jacobs et al. (2016)</ref> employed LDA to help predict purchases, <ref type="bibr" target="#b9">Büschken and Allenby (2016)</ref> developed a sentence-constrained supervised LDA to better predict review ratings, <ref type="bibr" target="#b41">Toubia and Netzer (2017)</ref> used topic models to explore idea generation, and <ref type="bibr" target="#b4">Ansari et al. (2018)</ref> developed a scalable recommendation system based on supervised topic modeling. However, mixed membership models have yet to be employed in the context of choice modeling. We believe this paper provides an important step in this regard.</p><p>The remainder of this paper will be organized as follows. We specify our model in Section 2. In Section 3, we explore the boundary conditions of the proposed model relative to competing models by way of an extensive simulation study. We detail our two empirical applications in Section 4. In Section 5, we compare results from our proposed model and alternative models. We discuss implications of and extensions to this research in Section 6.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Model Specification</head><p>We detail the components of our proposed model before specifying their integration. First, we briefly review HB choice models and the use of covariates in explaining preference heterogeneity. Second, we outline the class of mixed membership models generally and the GoM model specifically, along with a comparison with related and competing covariate models. Finally, we specify the integrated choice and GoM model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Hierarchical Bayesian Choice Model</head><p>Hierarchical Bayesian choice models enable both individual and aggregate-level preference parameter estimation, even in the presence of few choices per individual, by sharing information across individuals through the model of heterogeneity <ref type="bibr" target="#b33">(Rossi and</ref><ref type="bibr">Allenby 2003, Rossi et al. 2005)</ref>. Market simulators make use of individual-level preference estimates to forecast the results of potential product policies, whereas aggregate-level preference estimates are used to explain individual-level preference heterogeneity and inform targeting and promotion decisions.</p><p>The likelihood in an HB choice model is typically assumed to be a multinomial logit model such that the probability of individual n for choice task h choosing product alternative p is a function of the M attribute levels x p,h that compose alternative p for choice task h and individual n's M attribute-level part-worths β n : Pr y n,h p|β n ( ) exp x p,h β n ( )</p><formula xml:id="formula_0">∑ P p 1 exp x p,h β n ( ),<label>(1)</label></formula><p>where there are P alternatives. The distribution of heterogeneity, or upper level, models preference heterogeneity across the individual-level β n 's. This model of heterogeneity is typically assumed to be multivariate normal (MVN) and, in the presence of covariates to part-worths for individual n, can be written down as</p><formula xml:id="formula_1">β n Γq n + ξ n , ξ n ∼ N 0, V β ( ) ,<label>(2)</label></formula><p>where q n is a vector of observed covariates of length J, and Γ is the J × M coefficient matrix relating variation across N × J covariates Q to variation across N × M part-worths B. A simple variant of this model is given by q n 1 and J 1 so that Γ contains an intercept only, resulting in β n ∼ MVN(β, V β ). In the model with covariates, the prior expectation to β n is Γq n and, thus, heterogeneous. Information is shared across respondents through Γ and the M × M heterogeneity covariance matrix V β <ref type="bibr" target="#b35">(Rossi et al. 2005</ref>). In the intercept-only model, the prior expectation to β n is homogeneous across respondents (β), resulting in shrinkage of individual-level estimates to a common mean. Thus, in order to better explain preference heterogeneity, covariates are incorporated into the model to potentially allow for differences in prior expectations to the β n and, in this sense, distinct points of shrinkage of their a posteriori estimates. The directed acyclic graph (DAG) in Figure <ref type="figure" target="#fig_0">1</ref> provides a visual representation of the HB choice model with observed covariates. Plates in this DAG represent replications of variables, white nodes represent parameters, grey nodes represent fixed hyperparameters, and black nodes represent data. We use ν and V as degrees of freedom and the M × M scale matrix for a conjugate inverse Wishart prior on the heterogeneity covariance matrix V β , respectively; Γ is the J × M mean, and A is the J × J precision matrix for a conjugate normal prior on the coefficient matrix Γ; β n is a vector of M part-worth coefficients, y n is a vector of H choices, and q n is a vector of J covariates. Following Figure <ref type="figure" target="#fig_0">1</ref>, the joint posterior distribution of the standard HB choice model is as follows, with the fixed design matrix X suppressed to reduce clutter:</p><formula xml:id="formula_2">p B, Γ, V β |Y, Q, Γ, A, ν, V ( ) ∝ ∏ N n 1 p y n |β n ( ) p β n |q n , Γ, V β ( ) [ ] p Γ|V β , Γ, A ( ) p V β |ν, V ( ) ,<label>(3)</label></formula><p>where Y is an N × H matrix of choices,</p><formula xml:id="formula_3">∏ N n 1 p(y n |β n ) is the likelihood, ∏ N n 1 p(β n |q n , Γ, V β )</formula><p>is the distribution of heterogeneity, and p(Γ|V β , Γ, A) and p(V β |ν, V) are priors <ref type="bibr" target="#b35">(Rossi et al. 2005)</ref>.</p><p>Different covariates Q to part-worths have been used in the choice modeling literature in the context of the model given by Equation (3). For example, <ref type="bibr" target="#b1">Allenby and Ginter (1995)</ref> use demographic variables, <ref type="bibr" target="#b28">Lenk et al. (1996)</ref> include expertise, and <ref type="bibr" target="#b10">Chandukala et al. (2011)</ref> use consumer needs to explain variation in the part-worths. However, explaining preference heterogeneity has not met with much success generally, as manifested in performance not markedly different from a model without covariates <ref type="bibr" target="#b37">(Rossi et al. 1996</ref><ref type="bibr" target="#b22">, Horsky et al. 2006</ref>.</p><p>We propose integrating a standard HB choice model and a covariate model in order to introduce dimension reduction, allow for distinct points of shrinkage, and maintain a parsimonious Γ even in the presence of a large number of covariates. Assuming covariates that are actually drivers of preference heterogeneity, a covariate model will need to accomplish three things. First, it will need to provide individual-level summaries of the covariates so we can use parameters from the covariate model as substitutes for q n . Second, it will need to allow for each reduced dimension to be characterized by different observations. Third, it will need to be a generative model because we will rely on the results from the integrated covariate model to understand the reduced dimensions and explain preference heterogeneity. For this, a "black box" predictive model of the β n would not be sufficient. We will evaluate the proposed and competing covariate models according to these three criteria.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Mixed Membership Models</head><p>Mixed membership models are a class of models for grouping discrete data. These data can be as diverse as categorical responses in a survey to words in a document. However, unlike related models, instead of each observational unit being assigned to a particular group, a mixed membership model is characterized by having a unit-level membership vector that describes partial membership in each group. Mixed membership models also allow for different patterns in the data to be characterized by different observations.</p><p>Assume we have a collection of J discrete survey questions where each question j has L j response categories. The probability of individual n responding to question j with response category is a function of individual n's partial membership in each of K groups as described by the K-dimensional, individual-level membership vector g n and the response patterns for question j across K groups and L j response categories as described by the K × L j matrix λ j :</p><formula xml:id="formula_4">Pr w n,j |g n , λ j ( ) ∑ K k 1 g n,k λ j,k ( ),<label>(4)</label></formula><p>where K is specified by the analyst. For survey data, the K groups are known as "profiles." Each respondent is assumed to be a partial member of all profiles based on how similar their responses are to each profile. The membership vector g n defines this individual-level mixture and is constrained so that each element is nonnegative and ∑ K k 1 g n,k 1. Thus, the mixed membership lives on the simplex defined by the K profiles, as illustrated in Figure <ref type="figure">2</ref>. Profiles are often referred to as "extreme," as they define the corners of the K-dimensional simplex within which (all) observations are located. Extreme membership weights (e.g., 0, 1, 0, . . . , 0) indicate identity of unit and a single profile. The K × L j matrix λ j is made up of K vectors λ j,k describing how likely each categorical</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2. Example of Mixed Membership</head><p>Notes. This simplex is defined by three "extreme" profiles, P1, P2, and P3, located in the corners of the K space, with each of the dots representing a respondent's mixed or partial membership in each of the three profiles. Of the four cases depicted here, two are located toward one of the extreme profiles, which implies uneven mixed membership, whereas the two others have nearly equal mixed membership, which is manifested by a position at the center of the latent profile space. <ref type="bibr">Allenby: Explaining Preference Heterogeneity Marketing Science, 2020, vol. 39, no. 2, pp. 407-426, © 2020 INFORMS</ref> response is for question j for a hypothetical respondent that is only a member of profile k. Each vector λ j,k in λ j is also constrained with nonnegative elements so that ∑L j 1 λ j,k ( ) 1. Because the number of categorical responses L j is question specific, the J × K × L j array {λ j } J j 1 is potentially ragged. This mixed membership model for categorical survey response data is the GoM model. It was originally developed to classify disease patterns using discrete patient-level clinical data <ref type="bibr" target="#b44">(Woodbury et al. 1978</ref><ref type="bibr" target="#b11">, Clive et al. 1983</ref> and has since been applied to modeling survey data <ref type="bibr">(Erosheva et al. 2007, Gross and</ref><ref type="bibr" target="#b21">Manrique-Vallier 2014)</ref>. However, the interest in identifying patterns across observations as well as how each observation relates to these patterns is general for all mixed membership models. What differs is the group structure and the sum-to-one constraints based on the type of data. For example, in LDA, the membership vector g n is replaced with a topic vector θ n that describes document n's partial membership in each topic k, and the profile array {λ j } J j 1 is replaced by a topic matrix Φ that describes the weight associated with each word j for each topic k so that ∑ J j 1 Φ k 1 for each k. The difference between profiles and topics is a result of the data being modeled. Respondents can repeat the same words, but they can select a response category only once for any given survey question.</p><p>The DAG in Figure <ref type="figure" target="#fig_1">3</ref> provides a visual representation of the GoM model. The plate notation demonstrates the three model levels: responses J, respondents N, and aggregate profiles K. To be clear, α and τ are both hyperparameters for conjugate Dirichlet priors on g n and {λ j } J j 1 , where α is a vector of length K and τ is a potentially ragged array of J vectors, each with separate lengths L j . Following Figure <ref type="figure" target="#fig_1">3</ref>, the joint posterior distribution of the GoM model is</p><formula xml:id="formula_5">p Z, G, {λ j } J j 1 |W, α, τ ( ) ∝ ∏ N n 1 p w n |z n , λ j { } J j 1 ( ) p z n |g n ( ) p g n |α ( ) [ ] p λ j { } J j 1 |τ ( ) ,<label>(5)</label></formula><p>where Z is an N × J matrix of latent profile assignments, G is an N × K matrix of membership vectors, W is an N × J matrix of observed responses, ∏ N n 1 p(w n |z n , {λ j } J j 1 )p(z n |g n ) is the likelihood, and ∏ N n 1 p(g n |α) and p({λ j } J j 1 |τ) are priors. If K &lt; J, the model reduces the dimensions of the data from N × J to N × K. In the GoM, the latent profile assignments z n,j are analogous to topic assignments to words in the LDA model. Both are assumed to be independent and identically distributed (i.i.d.) draws from the unit-level profiles g n (θ n in LDA), allowing for the collection of individuallevel responses w n to result from a mix of latent profiles (or topics). In our Bayesian estimation of the integrated choice and GoM model (Online Appendix A), the latent z n are augmented, which allows us to "observe" how respondents switch from profile to profile as they move from question to question.</p><p>We can see from Figure <ref type="figure" target="#fig_1">3</ref> and Equation ( <ref type="formula" target="#formula_5">5</ref>) that the GoM model satisfies our three requirements for a covariate model. First, the respondent-level membership vectors g n can be used as substitutes for q n in Equation (2). Second, the latent profile assignments z n,j allow for each observation j to potentially characterize different profiles k such that the pattern of responses defining each profile is generated only by those responses associated with the given profile. Third, the GoM is a generative model, able to explain the origin of the covariate data. Probabilities {λ j } J j 1 express archetypes in a population, and the corresponding individual-level profile weights G can be used to explain response heterogeneity across respondents.</p><p>There are a number of related or competing covariate models. However, some of these do not satisfy all three requirements. We consider three competing models: a finite mixture model, a factor model, and a constrained GoM model. To illustrate model differences, the DAGs in Figure <ref type="figure">4</ref> provide visual representations of the GoM model and the three competing covariate models.</p><p>First, a standard finite mixture model for J discrete survey questions defines the probability of respondent n providing response to question j:</p><formula xml:id="formula_6">Pr w n,j |g j , λ j ( ) ∑ K k 1 g j,k λ j,k ( ),<label>(6)</label></formula><p>with a membership vector g j and profiles λ j <ref type="bibr" target="#b25">(Kamakura and</ref><ref type="bibr">Russell 1989, Frühwirth-Schnatter 2006)</ref>. <ref type="bibr">Figure 4(b)</ref> is the associated DAG. It is clear that finite mixture models assume population-level membership Dotson, Büschken, and Allenby: Explaining Preference Heterogeneity vectors g j and thus do not satisfy the first of our criteria for a covariate model of providing the desired summary of covariate data on the individual level. Finite mixture models can be viewed as a special case of mixed membership models <ref type="bibr" target="#b13">(Erosheva et al. 2007</ref><ref type="bibr" target="#b17">, Galyardt 2014</ref>, whereas mixed membership models are often referred to as individual-level mixture models. This difference in membership vectors aligns with model use. Finite mixture models segment respondents, whereas mixed membership models describe how respondents relate to extreme profiles. Second, factor analysis has long been a standard approach in marketing for dimension reduction <ref type="bibr" target="#b39">(Stewart 1981)</ref>. The basic assumption of factor analysis is that a set of variables can be reduced to a smaller number of latent constructs called factors. In standard factor analysis, the data for respondent n and question j are assumed to arise as follows:</p><formula xml:id="formula_7">w n,j c j + ζ n λ j + η n,j , ζ n ∼ N 0, Ψ ( ), η n,j ∼ N 0, σ 2 j ( ) ,<label>(7)</label></formula><p>where c j is a scalar constant, ζ n is a vector of individuallevel factor scores of length K, each λ j is a vector of regression coefficients of length K commonly known as factor loadings, and Ψ is a K × K matrix of prior covariances of ζ n . In matrix notation,</p><formula xml:id="formula_8">w n c + ζ n Λ + η n ,<label>(8)</label></formula><p>where w n is a vector of observations of length J, c is a common vector of variable baselines, η n is a vector of errors of length J, and Λ is a J × K matrix of factor loadings collected across equations. The form of factor analysis in Equation ( <ref type="formula" target="#formula_8">8</ref>) is similar to that of the GoM model in Equation ( <ref type="formula" target="#formula_4">4</ref>), with factor scores in place of the membership vector and factors in place of the profiles. However, the DAG of factor analysis in Figure <ref type="figure">4</ref>(c) reveals an important difference when compared with the GoM model: Factor analysis does not allow for each factor to be characterized by different observations <ref type="bibr" target="#b29">(Manton et al. 1994</ref><ref type="bibr" target="#b30">, Marini et al. 1996</ref>. In factor analysis, the individual-level factor scores ζ n are mapped to the covariates in a homogeneous fashion. The DAGs in Figure <ref type="figure">4</ref> make this clear, with λ j specified for factor analysis and λ j,k specified for the GoM model. In other words, each regression in Equation ( <ref type="formula" target="#formula_8">8</ref>) has a unique set of coefficients that hold across respondents. Thus, factor analysis satisfies only two of our three requirements.</p><p>Despite both providing dimension reduction, the goals associated with the use of factor analysis and the GoM model differ. Note that Equation (8) implies</p><formula xml:id="formula_9">w n − c ∼ N 0, λΨλ + I J σ 2 ( ) ,<label>(9)</label></formula><p>where I J is the J × J identity matrix and σ 2 is the vector of residual variances for the variables <ref type="bibr" target="#b26">(Lee 2007)</ref>. In applying factor analysis, it is typically assumed that the factor scores are uncorrelated and the variances of the factor scores are constrained to one for identification of the scale of the factor loadings so that Ψ I K , as follows:</p><formula xml:id="formula_10">w n − c ∼ N 0, λλ + I J σ 2 ( ) .<label>(10)</label></formula><p>Equation ( <ref type="formula" target="#formula_10">10</ref>) demonstrates that factor analysis exploits correlation among the covariates by finding a set of factors accounting for this correlation. Thus, although factor analysis satisfies the three criteria for a covariate model, the objective of factor analysis is to uncover a limited number of latent constructs underlying a set of variables, whereas the objective of the GoM model is to both uncover extreme profiles of respondents and measure each respondent's proximity to these profiles. In other words, the GoM model has the description of respondents and respondent heterogeneity as the objects of inference. Third, Figure <ref type="figure">4</ref>(d) is the DAG of a constrained version of the GoM model. In this model, subjects are assumed to belong to only one of the K profiles. This is achieved by removing the z n from the J plate. As a result, it is assumed that z n is generated by way of a single draw from g * n and that all z n,j are identical replicates of that draw. In other words, responses for an individual are assumed to originate from λ j,k z n . In our empirical analysis, we consider this constrained GoM model, which still satisfies the three criteria for a covariate model, to test the empirical importance of a mixed membership approach to our data. Note that this constrained GoM model is not equivalent to standard finite mixture models because g * n of this model resides on the N level. It is also not equivalent to factor analysis because it allows for each profile to be characterized by different observations (i.e., λ j,k ).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Integrated Hierarchical Bayesian Choice and</head><p>GoM Model The proposed model integrates an HB choice model and a GoM model in order to introduce dimension reduction, uncover distinct points of shrinkage for the individual-level part-worths, and maintain a parsimonious mapping from covariates to part-worth estimates (when K &lt;&lt; J). By integrating these component models, we arrive at a "supervised" GoM model with choice data as additional "downstream" likelihood information to the latent G (see Figure <ref type="figure" target="#fig_2">5</ref>). This is similar to a supervised LDA, which is prototypical of using multiple observed responses to estimate latent variables in the context of discrete data <ref type="bibr" target="#b7">(Blei and McAuliffe 2007)</ref>.</p><p>On the individual-level, our choice model remains a multinomial logit, as specified in Equation ( <ref type="formula" target="#formula_0">1</ref>), and the distribution of heterogeneity remains multivariate normal as in Equation ( <ref type="formula" target="#formula_1">2</ref>). Because the GoM provides g n for each respondent, as shown in Equation (4), we use these membership vectors in the place of the covariates q n to explain heterogeneity in the part-worths B (i.e., β n Γg n + ξ n ). The likelihood of the integrated model is</p><formula xml:id="formula_11">p Y, W|B, Γ, V β , Z, G, λ j { } J j 1 ( ) ∏ N n 1 p y n |β n ( ) p β n |g n , Γ, V β ( ) p w n |z n , λ j { } J j 1 ( ) p z n |g n ( ) .<label>(11)</label></formula><p>Figure <ref type="figure" target="#fig_2">5</ref> illustrates the proposed integrated HB choice and GoM model. From the DAG, we can see that the proposed model is a three-level model where only the categorical response vector w n and choice vector y n for each respondent are observed. The membership vector g n serves as the link between the choice and GoM components of the model. Thus, g n is informed by both the categorical responses w n and the chosen alternatives y n . Following Figure <ref type="figure" target="#fig_2">5</ref>, the joint posterior distribution of the proposed model is</p><formula xml:id="formula_12">p B, Γ, V β , Z, G, λ j { } J j 1 |Y, Γ, A, ν, V, W, α, τ ( ) ∝ ∏ N n 1 p y n |β n ( ) p β n |g n , Γ, V β ( ) p w n |z n , λ j { } J j 1 ( ) [ • p z n |g n ( ) p g n |α ( ) ] p Γ|V β ,Γ, A ( ) p V β |ν, V ( ) p λ j { } J j 1 |τ ( ) ,<label>(12)</label></formula><p>Dotson, Büschken, and Allenby: Explaining Preference Heterogeneity</p><formula xml:id="formula_13">where ∏ N n 1 p(y n |β n )p(β n |g n , Γ, V β )p(w n |z n , {λ j } J j 1 )p(z n |g n ) is the likelihood, and ∏ N n 1 p(g n |α), p(Γ|V β ,Γ, A), p(V β |ν, V</formula><p>), and p({λ j } J j 1 |τ) are the priors. A complete list of the variables in Equation ( <ref type="formula" target="#formula_12">12</ref>) is given in Table <ref type="table">1</ref>. Details on estimation, model validation, and computational complexity are provided in Online Appendix A.</p><p>In our model, Γ maps complete sets of individuallevel profiles weights g n to part-worths β n ; that is, for any admissible combination of g n,k , Γ generates a prior expectation with respect to β n . Given the constraint to profile weights in the GoM model (i.e., ∑ K k 1 g n,k 1), any combination of g n,k with nonnegative values that add up to 1 is admissible, and Γ can always be interpreted as providing their mapping to β n . However, as regression coefficients, Γ cannot be interpreted in the standard way (i.e., change of y as x 1 changes by one unit, holding all other x fixed). This is because any g n,k cannot change independently from g n,−k ; as one weight in g n changes, at least one other weight must change as well.</p><p>If a standard interpretation of Γ is desired, one needs to transform the compositional covariates g n . One way to achieve this is by applying the isometric log-ratio (ILR) transformation with respect to profile K, where the ordering of profiles is not consequential: Number of categorical responses for question j w n J-dimensional vector of respondent n's categorical responses z n J-dimensional vector of respondent n's profile assignments g n K-dimensional membership vector for respondent n {λ j } J j 1 Array of probability distributions λ j,k over the L j response options for each question j and profile k which projects g n onto an orthonormal base. This orthonormal base allows for a standard interpretation of Γ as the g † n,k are unconstrained and can therefore move independently. Note that if g n 1/K, . . . , 1/K ( ) , the resulting g † n 0, . . . , 0 ( ) , which implies that the baseline of a regression model using ILR-transformed compositional data indicates the expected value of the dependent variable when all original component shares are equal (i.e., centered within the simplex as in Figure <ref type="figure">2</ref>). Also note that as result of the transformation in Equation ( <ref type="formula" target="#formula_14">13</ref>), g † n,K 0. In the following, we use g † n to describe the transformed membership vectors, omitting the values from the Kth profile, as this carries no information, and adding a baseline so that g</p><formula xml:id="formula_14">g † n,k ̅̅̅̅̅̅̅̅̅̅̅̅ K − k K − k + 1 √ × ln g n,k K−k ̅̅̅̅̅̅̅̅̅̅̅̅̅̅ ∏ K i k+1 g n,i √ ,<label>(13)</label></formula><formula xml:id="formula_15">† n (1, g † n,1 , g † n,2 , . . . , g † n,K−1 ).</formula><p>In the likelihood of our model in Equation ( <ref type="formula" target="#formula_11">11</ref>), the ILR transformation itself can actually be ignored because Equation ( <ref type="formula" target="#formula_14">13</ref>) is deterministic, which implies p(g † n |g n ) 1. In our empirical analysis, we use the model with ILR-transformed G for obtaining estimates of cross-sectional Γ so that its coefficients can be interpreted the usual way. We provide details on estimating the integrated choice and GoM model using ILR-transformed G in Online Appendix A.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Boundary Conditions</head><p>In this section, we present results from a simulation study in which we explore the boundary conditions of our proposed integrated choice and GoM model. More specifically, we investigate the conditions under which it is possible to empirically distinguish the proposed model from a set of competing models when the data are generated by the proposed model. Each of the models under consideration differs in terms of the nature of the regressors used in the upper-level of the choice model. The models are the proposed integrated choice and GoM model with the membership vector as regressors (i.e., the membership vector model), the standard model with observed binary covariates as regressors (i.e., the binary covariate model), the integrated choice and factor analysis model with the factor scores as regressors (i.e., the factor score model), and the integrated choice and constrained GoM model (i.e., the constrained membership model). The constrained membership model arises from assuming that all profile assignments z n,j arise from a single draw from g n , as detailed in Section 2. The binary covariate, factor score, and constrained membership models are included in the simulation study because they are the standard approach to using covariates or the primary competing covariate models, respectively.</p><p>We evaluate performance by computing the ability of the model to predict the complete vector of partworth utilities for holdout respondents. To achieve this, we use in-sample data to conduct inference with respect to how observed covariates map to the part-worths and then predict these part-worths for out-ofsample respondents using the mapping scheme implied by each upper-level model. Note that we do not use holdout tasks for this analysis or likelihood-based measures of in-sample fit. Likelihood-based fit measures or accuracy of predicting holdout tasks implies choices on the individual level to be observed. The upper-level model plays only a partial role in making such calculations and will be influential only if the number of observed choices is small. Our goal is different. We want to answer the question of how well we can predict the distribution of heterogeneity for a new sample of respondents. For this, we compute the hit probability across all choices of holdout respondents given knowledge of the mapping of covariates to part-worths implied by the upper level of each model.</p><p>For this analysis, we generate 200 data sets from the membership vector model. For each data set, we fix N 500, L j 2 for all j, and V β 0.33I M throughout, and generate Γ j,m ∼ U(−4, 4) for all j and m. Our search grid to establish boundary conditions is defined by the following variables, for which we randomly pick a single value for each data set from the indicated range:</p><p>• J ∈ (5, 6, . . . , 20),</p><p>• K ∈ (2, 3, . . . , 8), and • α, τ ∈ (0.1, 0.5, 1, 2, 4, 8, 16). The number of responses generated ( J ≤ 20) is similar to what most marketing surveys, given respondents' time constraints, contain. The number of latent archetypes (K) is, on average, smaller than J, reflecting the typical desire in marketing research to reduce dimensionality and complexity in describing heterogeneity. In applications of latent class models, managers are often limited to a small number of types; α and τ are generated from a large range of values, allowing for very different relationships between extreme types and observables and also different distributions of weights in the population. Having obtained draws of these variables, we generate G and {λ j } J j 1 from Dirichlet distributions, given values of α and τ, respectively. Given G and {λ j } J j 1 , we generate J binary covariates (because L j 2 for all j) for each respondent through draws from a binomial distribution. The draw of β n given G, {λ j } J j 1 , and V β is then β n ∼ MVN(Γg n , V β ). The simulation of choice data then proceeds in the usual way. We generate P 4 choice options for each of H 15 tasks, each consisting of M 12 attribute levels. For each choice set, the "observed" choice is given by the option with highest utility, given Xβ n + ξ, where ξ is a vector of P independent error draws from an extreme value distribution. We generate entries of the P × M design matrix of choice options X i.i.d. from N(0, 2).</p><p>The search grid defined by our setup considers different situations. Small values for α characterize a situation in which respondents are similar to a single Dotson, Büschken, and Allenby: Explaining Preference Heterogeneity extreme while large values for α characterize a situation in which respondents have more of a mixed membership across profiles. Small values for τ indicate that, given a profile k, only few covariates are indicative of that profile. The term K specifies the dimensionality of the underlying latent profile space. Note that we consider scenarios where K &gt; J, implying that there are more extreme profiles than measurement indicators in the population. Our goal is to establish the conditions under which the true data-generating mechanism performs better than competing models.</p><p>The out-of-sample hit probability is the average posterior probability of a set of holdout respondents N * and post-burn-in Markov chain Monte Carlo (MCMC) draws R given a model D:</p><formula xml:id="formula_16">HP(D) 1 N * ∑ N * n * 1 1 H ∑ H h 1 1 R ∑ R r 1 Pr y n * ,h |β D n * ,r , X h ( ) n * ( ) [ ] ,<label>(14)</label></formula><p>where y n * ,h is the observed choice for holdout respondent n * for choice task h, and β D n * ,r are respondent n * 's estimated coefficients for post-burn-in MCMC draw r and model D. These β D n * ,r are drawn from the distribution of heterogeneity MVN(Γ</p><formula xml:id="formula_17">D r q D n , V D β,r )</formula><p>for the binary covariate model.</p><p>For the proposed membership vector model, we need to first generate out-of-sample membership vectors g D n * before we can draw β D n * ,r from the distribution of heterogeneity MVN(Γ D r g D n * , V D β,r ). For this, we first generate an initial g D n * from Dirichlet(α * ). In the absence of a model that estimates α from calibration data, we determine α * by minimizing the Kullback-Leibler divergence of the "observed" distribution of g D n and Dirichlet(α * ) with respect to possible values of α * . The membership vectors g D n * ,r are then successively updated for each of the post-burn-in MCMC draws using the out-of-sample sample response data w n * ,j , the draws of λ D j,k,r , and α * :</p><formula xml:id="formula_18">z D n * ,j,r Multinomial p D 1 , . . . , p D K ( ) ,<label>where</label></formula><formula xml:id="formula_19">p D k ∝ g D n * ,k,r λ D j,k,r w n * ,j ( ) , g D n * ,r ∼ Dirichlet z D n * ,j,r + α * ( ) .</formula><p>We can then draw</p><formula xml:id="formula_20">β D n * ,r ∼ MVN(Γ D r g D n * ,r , V D β,r )</formula><p>for the outof-sample respondents and compute the hit probability. A similar process is followed for the constrained membership model. To compute hit probabilities for the factor score model, we first generate draws of ζ D n using the observed covariates and across-subject factor loadings Λ. For this step, we use standard conjugate results from Bayesian factor modeling <ref type="bibr" target="#b26">(Lee 2007)</ref>. Given the ζ D , we generate β D n * using results from the hierarchical regression by way of drawing from MVN</p><formula xml:id="formula_21">( Γ ζ D n * , V β</formula><p>) . To compute hit probabilities for out-of-sample respondents, we use data from N 250 randomly selected respondents to calibrate the model and then predict all H 15 choices for the N * 250 out-ofsample respondents. We compare the binary covariate model, the factor score model, and the membership vector model with respect to this measure. A first result from our simulations is the average hit probability obtained from alternative models. These probabilities are 50.4%, 51.0% and 49.3%, averaged over the 200 data sets, for the membership vector, binary covariate, and factor score models, respectively. This suggests that the proposed membership vector model is not generally preferred in terms of fit to out-ofsample respondents across all (and equally weighted) scenarios considered here. The implication is that our set of simulated data sets is not skewed toward a particular model a priori. On average, the binary covariate model seems to better predict out-of-sample part-worths and implied choices. In Figure <ref type="figure" target="#fig_3">6</ref>, we show how relative hit probabilities vary with values of α and τ, marginalized with respect to K and J.</p><p>It is clear from Figure <ref type="figure" target="#fig_3">6</ref> that the relative performance of the true model is dependent on how the data are generated. Relative to the binary covariate model (left panel), performance of the membership vector improves as both α and τ get larger. For small values of these parameters (0.1, 0.5), the performance disadvantage of the membership vector model can be as high as 15%. Small values for α and τ imply that respondents are well characterized by a single extreme profile of which a small set of covariates is highly indicative (probabilities approaching 1). Under such conditions, unobserved membership to latent profiles can be substituted by observed covariates. If, however, α and τ get large (&gt; 2), this is no longer possible, and the performance advantage of the membership vector over the binary covariate model can exceed 10% (Figure <ref type="figure" target="#fig_3">6</ref>). In other words, if respondents occupy the corners of the latent K space and single covariates describe this position well, there is little to be gained by the membership vector model compared with the binary covariate model. Both will result in very similar descriptions of the distribution of heterogeneity of preferences in the data. This is no longer true when respondents are a mix of profiles (i.e., α &gt;&gt; 1) and covariates do not exhibit a deterministic relationship to profiles (i.e., τ &gt;&gt; 1). The right panel of Figure <ref type="figure" target="#fig_3">6</ref> shows the hit probabilities of the membership vector model relative to the factor score model, revealing a reversed pattern: Larger values for α and τ lead to the factor model generating hit probabilities almost equal to the membership vector model. Instead, for the membership vector model to perform better, τ needs to be small.</p><p>For a more granular analysis of results from the simulation, we employ a logit regression model using all parameters in our simulation simultaneously (Table <ref type="table" target="#tab_3">2</ref>). The dependent variable in this regression analysis is a binary indicator of the true membership vector model outperforming the benchmark model with respect to out-of-sample choice predictions. That is, if the average hit probability from the membership vector across all 250 × 15 out-of-sample choices is higher than that of the benchmark model considered, we code this result as 1 and otherwise as 0. As covariates, we include the main effects of our simulation parameters as well as all two-way interaction effects. We find a (binary) logit regression model to be a more accurate summary of our simulation results than a linear regression model (and using the relative hit probabilities as the dependent variable) because of the highly nonnormal distribution of residuals from the linear model and the nonlinear relationship of many covariates to the indicator of model preference (see Figure <ref type="figure" target="#fig_3">6</ref>). As benchmark models to the membership vector model, we consider the binary covariate model, the factor score model, and the constrained membership model with individual-level profiles weights constrained to be 0 or 1.</p><p>Table <ref type="table" target="#tab_3">2</ref> reveals that the interaction effects of our simulation parameters are important drivers of the membership vector being distinguishable from the benchmark models. Relative to the binary covariate model, the membership vector model is preferred when both α and τ increase, confirming results from our marginal analysis (Figure <ref type="figure" target="#fig_3">6</ref>). We also find that as both α and K increase, the membership vector is preferred over both the binary covariate model and the factor score model, as indicated by positive coefficients in both analyses. For the binary covariate model, the β (reg) of covariate α × K is 0.07 (probability to be different from 0 is 92.8%), and for the factor score model it is 0.09 (probability to be different from 0 is 99.3%). We obtain a similar result from covariate τ × K. As this variable increases, the probability of the membership vector model being preferred over both the binary covariate and factor score models increases. We note that the estimate of this coefficient for the factor score model (0.034) has a probability of 92.3% of being different from 0. We find the main  Dotson, Büschken, and Allenby: Explaining Preference Heterogeneity effect of K as well as that of J to be effectively 0 for all models, and we also find that K &gt; J is not a scenario favoring any model, implying that the dimensionality of the latent space plays no role as such. With respect to the constrained membership model, we find regression coefficients from our analysis to be very similar to those in the factor score model. This suggests that the conditions that allow us to distinguish the membership vector model from the factor score model also allow us to distinguish it from the constrained membership model. We also note that the model-based results in Table <ref type="table" target="#tab_3">2</ref> allow for prediction of the relative performance of our models outside the search grid of our simulation (e.g., J &gt; 20).</p><p>In conclusion, we find the proposed membership vector model to be identifiable as the true model compared with both the binary covariate model and the factor score model when respondents exhibit partial membership to multiple extreme profiles (i.e., larger α) and, simultaneously, the relationship of profiles to the observed covariates is of a probabilistic, not deterministic, nature (i.e., larger τ). The latter is the case when the probability of observing a certain outcome, given profile k, approaches 1. The analysis also shows that the number of latent profiles K plays an important role, but only in concert with α or τ. A larger number of latent profiles works in favor of the membership vector model only if α or τ also increase. This suggests that the membership vector model does not benefit from more extreme types in the population as such. These types must contribute to partial membership (i.e., not push respondents into corners of the K space) and not be uniquely measurable by specific covariates.</p><p>An implication of this result is that the standard approach in marketing (using covariates directly as predictors of part-worths) works reasonably well when respondents (a) are effectively one of the latent types and (b) these types can be identified by specific covariates. Some combination of the observed covariates is then a reasonably good predictor of membership to latent types, implying that this observed pattern can approximate the latent g n well. The factor score model, a typical approach to latent variable modeling in marketing, works well under similar conditions, combined with a relatively small number of latent types. Neither the factor score model nor the covariate model is an appropriate modeling approach, however, if respondents truly exhibit mixed membership (i.e., g n away from 0 and 1) and if the number of latent types K is large.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Empirical Applications</head><p>In our empirical analysis, we use data from two surveys of preferences regarding robotic vacuums and smartphones using national samples in the United States and Germany, respectively. Whereas the robotic vacuum data come from an emerging market, the smartphone data represent a well-established market, providing us a broad test for the proposed membership vector model. For the robotic vacuum data, a total of 332 respondents were carefully screened to ensure that the product options under consideration were relevant to them. In particular, qualified respondents had to own a robotic vacuum, currently be shopping for their first robotic vacuum, or might consider a robotic vacuum sometime in the next five years. For the smartphone data, a total of 147 respondents were similarly screened to ensure they were in the market for a new smartphone.</p><p>Before the conjoint experiment, respondents were asked to detail why the product was relevant to them or anyone in their household. For the robotic vacuum data, respondents selected from a list of 11 statements on cleaning that robotic vacuums might help address and a list of 7 statements that described problems with robotic vacuums. The combined list of 18 statements regarding cleaning and robotic vacuums is provided in Table <ref type="table" target="#tab_4">3</ref>. For the smartphone data, respondents selected from a list of 53 statements on smartphones that described their interests and usage. A subset of the 53 statements regarding smartphones is provided in Table <ref type="table" target="#tab_5">4</ref>. The full list is given in Online Appendix D. Thus, our discrete data consist of two possible response categories (i.e., L j 2) for all J 18 or J 53 where not selecting an item is coded as 0 and selecting an item is coded as 1.</p><p>After selecting from applicable statements on cleaning and robotic vacuums or on smartphone interest and usage, respondents proceeded through a series of choice tasks where they were asked to select which of a given number of product alternatives they most preferred. For the robotic vacuum data, this set of alternatives included an outside option to not select any of the given alternatives. For smartphones, no such option was given. Each alternative was composed of separate attributes. Figure <ref type="figure" target="#fig_4">7</ref> is a screenshot of one of these choice tasks from the robotic vacuum data. The estimable attribute levels, excluding the reference levels in grey, are included in Tables <ref type="table" target="#tab_6">5 and 6</ref>. Note that the smartphone data do not include an outside option.</p><p>For the robotic vacuum data, we see from Table <ref type="table" target="#tab_6">5</ref> that the attributes are defined in terms of brand, price, and different features, including the vacuum's performance (i.e., what percentage of dirt and debris it picks up), capacity (i.e., how often it needs to be emptied), the type of navigation (i.e., does it change directions by just bumping into things or is it "smart" and able to scan and determine an optimal path), where it can be programmed, and whether virtual borders can be set to keep the robotic vacuum away from certain areas of the home. For the smartphone data, we see from Table <ref type="table" target="#tab_7">6</ref> that the attributes are defined in terms of functional attributes, including display size (i.e., the effective size of the phone), display resolution, camera quality for the front camera, available memory, and price. A summary of the data sets using model notation is provided in Table <ref type="table" target="#tab_8">7</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head><p>In this section, we report results from applying the proposed membership vector model to our data sets. We start by comparing the fit of the proposed model to several competing models that differ in terms of their treatment of covariates. We then present results from the proposed membership vector model.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Model Comparison</head><p>For comparison of our proposed model, we consider several alternative upper-level models for covariates. A natural benchmark is the binary covariate model, which uses the observed q n as (exogeneous) regressors, representing the standard practice of using these variables in a choice model. The proposed membership vector model uses the membership vectors g n from the integrated GoM model as regressors. The factor score model utilizes an alternative assumption about the latent structure of the covariates and uses the factor scores ζ n from the integrated factor analysis model as regressors. Estimation details for this model are provided in Online Appendix B. The constrained membership vector model assumes respondents belong to only one of the K profiles and uses the (constrained) membership vector g * n as regressors. The factor scores and constrained membership vector models are the primary competing covariate models.</p><p>If the binary covariate model is the standard approach to using covariates and the membership vector, factor score, and constrained membership vector models represent competing ways to model covariates, the last alternative model considered provides a third approach. We use a Bayesian variable selection (VS) model operating on main and interaction effects of the observed covariates. The VS model applied here is a multivariate version of the stochastic search VS The apps on my SP only run with the newest OS.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>3.</head><p>A more recent OS is worth a higher price.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>4.</head><p>A more recent OS shows that a SP is up-to-date. 5.</p><p>It's always useful to have a more recent OS. 6.</p><p>I don't care about the OS on my SP. 7.</p><p>I want to use my SP to make payments. . . . . . .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>49.</head><p>During the night, I always switch my SP off. 50.</p><p>I switch my SP to vibrate in the night. 51.</p><p>I switch my SP to vibrate only when necessary. 52.</p><p>I like to surf the web on my SP. 53.</p><p>I use QR codes with my SP.</p><p>Note. OS, operation system; SP, smartphone.  <ref type="bibr" target="#b18">George and McCulloch (1993)</ref>.</p><p>The upper-level model for individual n is then β n Γ(δq n ) + ξ n , where δ is a cross-sectional vector of binary latent variables indicating inclusion of the (complete) covariate vector q n to the design matrix. Details for this model are provided in Online Appendix C. In our application, we consider all two-way and all three-way interactions for the robotic vacuum data and all two-way interactions for the smartphone data, giving rise to J 1,159 and J 1,432 covariates for the robotic vacuum data and the smartphone data, respectively. We include interactions for the VS model to allow for a large search space δ so that the VS model can empirically differ from the binary covariate model, which is not necessarily the case when only main effects are considered. The VS model can, of course, result in the binary covariate model (i.e., when δ 0 for all interactions). Estimation of the VS model using our data results in 95% and 77% of covariates being excluded for the smartphone data and robotic vacuum data, respectively. This implies that coefficients are credibly different from zero for a selection of interaction variables in both data sets. In our model comparison, we show that this, however, does not favor the VS model. We report five fit statistics for each of the models on each of the data sets: three in-sample and two predictive. Prior to computing any fit statistic, we checked for but found no substantial evidence of label switching. Fit statistics reported for the membership vector model are based on the GoM model without ILR transformation of G. Our first in-sample fit measure is the <ref type="bibr" target="#b32">Newton and Raftery (1994)</ref> approximation of the log marginal density (LMD), a standard Bayesian measure for model fit. The second is the deviance information criterion (DIC; <ref type="bibr" target="#b38">Spiegelhalter et al. 2002)</ref>, which explicitly penalizes overparameterized models. The third is a Bayesian-specific improvement on the DIC, the Watanabe-Akaike information criterion (WAIC; Watanabe 2010). For all three in-sample fit statistics, values closer to zero indicate improvement in fit. We only consider the likelihood contribution from the observed choices for purposes of model comparison, which allows to directly compare standard and integrated models. Consider that the binary covariate model treats covariates as exogenous, which implies that these provide no likelihood contribution. For computation of out-of-sample predictive fit, we use hit rates (i.e., correct prediction, yes or no) and hit probabilities as detailed in Section 3.</p><p>Note that in our application of latent variable models, the number of profiles or factors was not part of the model(s) and determined by us. <ref type="bibr" target="#b24">Joutard et al. (2007)</ref> provides a review of the various model selection criteria for mixed membership models, from using a Dirichlet process prior to estimate K to using various information criterion to select K. Given the added computational complexity of estimating K, we chose to use LMD and the DIC to select K. For the membership vector, factor scores, and constrained membership models, we first ran the covariate models on covariates in Tables <ref type="table" target="#tab_4">3 and 4</ref> and then determined the number of profiles or factors given fit.</p><p>As an example of our approach, Figure <ref type="figure" target="#fig_5">8</ref> shows LMD and the DIC for GoM models given K 2 to K 18 run on the robotic vacuum data. In terms of fit, both LMD and the DIC indicate a solution with a (relative to J = 18) medium number of profiles (five to seven). Whereas this procedure is helpful, we have also found an evaluation of the profiles themselves to be informative when choosing K. With the range of possible models narrowed, we ran the proposed membership vector model for K 5 to K 7. Comparing results to find profiles that are sufficiently differentiated and nonrepeating, the model with K 5 was deemed best. Determining differentiated profiles is a somewhat subjective step but is essential in order to find sufficiently different archetypes to define the simplex in the latent K space. The same process was repeated for the smartphone data. A similar procedure was followed  to select K for the factor scores and constrained membership models. Table <ref type="table" target="#tab_9">8</ref> presents in-sample and out-of-sample fits across all models and data sets. The model exhibiting the best fit, given measure of fit, is indicated in bold. Predictive fit is computed on a random holdout sample of 20% of respondents from each data set. With respect to in-sample fit, we find that the variable selection model fits the data best for both data sets. Recall that this model operates on main and (included) interaction effects. This allows for very flexible adaption of this model to the data and, hence, excellent in-sample fit. Putting aside the VS model as an outlier in terms of in-sample fit, the proposed membership vector model performs best among the remaining models, as indicated by italics in the table, for all of the in-sample fit statistics for the smartphone data set. That said, it does not perform markedly differently from either the binary covariate model or other latent variable models for either data set, suggesting that for estimation of β n from choice data, specification of the upper level of the model plays a minor role in terms of in-sample fit.</p><p>Out-of-sample predictive fit uniformly favors the proposed membership vector model. Compared with the second-best-fitting integrated model (for smartphones, the factor score model, and for robotic vacuums, the constrained membership model), this model results in lifts of hit rates of 15% and 12% for robotic vacuum and smartphone data, respectively. Compared with the binary covariate model, the lift is 15% for robotic vacuums and 19% for smartphones. Relative to the flexible variable selection model, the proposed membership vector model lifts hit rates by 33% for robotic vacuums and 9% for smartphones. Because the purpose of our model is explaining preference heterogeneity, predicting all the choices of holdout respondents is the best indicator of model performance. Given our empirical results, we therefore conclude that a mixed membership approach to modeling covariates in a choice model is the best way to capture the true distribution of preferences.</p><p>The variable selection model, which performs so well in-sample, is outperformed with respect to outof-sample predictive fit by both the membership vector model and the constrained membership vector model for both data sets, suggesting that a direct approach to explaining part-worths is not preferred even when (many) interactions are potential drivers.  Interestingly, the VS model provides the worst predictive fit across all models for the robotic vacuum data.</p><p>A tentative conclusion from this is that including interaction effects in the upper level of a hierarchical choice model does not substitute for a mixed membership approach. The reason for this result is that the regression model with (or without) variable selection considers the role of a focal covariate conditionally (i.e., while keeping all covariates fixed). In comparison, the membership vector model defines a joint probability space across covariates, and changes in the G imply changes in all covariates simultaneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Results from the Membership Vector Model</head><p>In the following, we present results from our proposed model. We start by looking at estimates of G.</p><p>As shown in our analysis of boundary conditions in Section 3, the proposed membership vector model performs better relative to alternative models when membership in extreme profiles is truly "mixed," which implies that, a posteriori, α &gt;&gt; 1. Figure <ref type="figure" target="#fig_6">9</ref> displays the distribution of estimated membership vectors for our two data sets suggesting that, indeed, α &gt; 1. Figure <ref type="figure" target="#fig_6">9</ref> reveals that for both data sets, all respondents exhibit mixed membership across all profiles, as evidenced by positions toward the center of the simplex. No respondents are positioned in the corners of the K space. Given our analysis of boundary conditions in Section 3, this result provides a partial explanation as to why the membership vector model apparently better captures preference heterogeneity: Note. The best-performing model for the given data set and fit statistic is in bold. Similarly, the second best-performing model for the given data set and fit statistic (in-sample only) is in italics; prob, probability.  <ref type="bibr">Allenby: Explaining Preference Heterogeneity Marketing Science, 2020, vol. 39, no. 2, pp. 407-426, © 2020 INFORMS</ref> respondents in both data sets cannot be described adequately by one of the profiles only. This also explains why the constrained membership model does not perform very well out-of-sample (Table <ref type="table" target="#tab_9">8</ref>).</p><p>In the following, we investigate how the proposed integrated choice and GoM model improves our ability to explain preference heterogeneity. For space considerations, we illustrate using model output from the robotic vacuum data. For details on model output for the smartphone data, the reader is referred to Online Appendix D. All results presented from the membership vector model are using ILR-transformed G (Online Appendix A) to facilitate standard interpretation of the matrix of regression coefficients Γ from this model. Recall that in the model with untransformed or "raw" G, the matrix Γ can be meaningfully applied only to full sets of g n .</p><p>We start by considering the transposed posterior means of Γ from the binary covariate model. Table <ref type="table" target="#tab_10">9</ref> displays the complete Γ matrix. The attribute levels are on the left, and each column in the matrix is associated with the intercept or one of the statements from Table <ref type="table" target="#tab_4">3</ref>. The marginal posteriors with means in bold have 95% credible intervals that do not contain zero. This matrix should inform a marketer concerning the drivers of preference for promotion and targeting strategies. However, making sense of the significant values and how they might co-occur is cumbersome because coefficients are not clustered or grouped for interpretation. The parsimonious representation of the data that the profiles provide becomes increasingly important as the number of covariates included increases.</p><p>For example, we can use Table <ref type="table" target="#tab_10">9</ref> to infer that respondents who are concerned about germs and dirt (i.e., Statement 5, "I worry about germs and dirt on my floor and carpet") prefer any brand of robotic vacuum relative to the outside good while not being concerned about getting the highest level of performance. We might expect this is because they are cleaning frequently (e.g., Statement 10, "I spend over two hours per week cleaning") and having a robotic vacuum is simply one part of a larger cleaning solution, but this model cannot illuminate such cooccurrence. Besides issues with interpretability, as the number of covariates increases (e.g., for the smartphone data set) the size of this coefficient matrix becomes too demanding.</p><p>In comparison, the proposed membership vector model produces a much more parsimonious coefficient matrix Γ and also provides, through {λ j } J j 1 , insights into how different items co-occur by identifying differentiated respondent profiles. Table <ref type="table" target="#tab_11">10</ref> details the profiles as described by the estimates of the {λ j } 18 j 1 array. Recall that because L j 2 for all J, the profiles can be presented in terms of the {λ j (1)} 18 j 1  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Note.</head><p>The marginal posteriors with means in bold have 95% credible intervals that do not contain zero; Int., Intercept; S, Statement.</p><p>Dotson, Büschken, and Allenby: Explaining Preference Heterogeneity matrix because {λ j (0)} 18 j 1 is simply its complement. Because respondents were qualified by owning or being interested in a robotic vacuum, it is not surprising that nearly every profile as described in Table <ref type="table" target="#tab_11">10</ref> has Statement 1, "I enjoy coming home to a clean house," occurring with high probability. Profile 1 is differentiated from the other models by Statement 10, "I spend over two hours per week cleaning," occurring with high probability. We name this profile "Constantly Cleaning."</p><p>Profile 2 is differentiated by Statement 8, "I don't like touching dirty things," along with a number of statements expressing anxiety about cleanliness with high probability. We name this profile "Anxious About Cleanliness." Profile 3, like profile 2, has high probability for a number of statements expressing anxiety about cleanliness and is differentiated by Statement 7, "I don't like going to someone's home that is dirty," and Statement 5, "I worry about germs and dirt on my floor and carpet," occurring with high probability. We name this profile "Anxious About Germs." Unlike the previously profiles, profile 4 is differentiated by Statement 9, "I don't spend much time cleaning." We simply name this profile "Little Cleaning." Finally, profile 5 is differentiated by functional concerns like Statement 17, "Robotic vacuums don't spend enough time on the really dirty spots on the floor." We name this profile "Specific Cleaning Concerns." The profile names for the robotic vacuum data are summarized in Table <ref type="table" target="#tab_13">11</ref>. We find similarly distinct extreme profiles with interpretable usage features for the smartphone data (Online Appendix D).</p><p>Table <ref type="table" target="#tab_3">12</ref> displays the transposed matrix of estimated coefficients Γ that maps variability in the membership vectors as regressors to variability in the part-worths. Again, the marginal posteriors with means in bold have 95% credible intervals that do not contain zero. Recall that these profiles are archetypal or extreme where each individual is a partial member in each profile as defined by the weights of their membership vector g n . To avoid the compositional nature of the original membership vectors, we imposed the ILRtransformation in Equation ( <ref type="formula" target="#formula_14">13</ref>) that resulted in g † n for all N respondents. This transformation allows us to interpret Table <ref type="table" target="#tab_3">12</ref> in the standard way and gives us a baseline that equals the preference structure of a respondent belonging equally to all latent profiles. Note that Table <ref type="table" target="#tab_3">12</ref> contains a column for each of K 5 profiles, which is the result of using all profiles as contrast (Online Appendix A).</p><p>As with Table <ref type="table" target="#tab_10">9</ref>, the matrix in Table <ref type="table" target="#tab_3">12</ref> should inform a marketer concerning the drivers of preference for promotion and targeting strategies. However, using the proposed model, we are able to explain preferences in terms of the extreme profiles. For example, profile 1, Constantly Cleaning, includes Statements 5, "I worry about germs and dirt on my floor and carpet," and 10, "I spend over two hours per week cleaning," with high probability. With this profile, we can answer what was only suggested from Table <ref type="table" target="#tab_10">9</ref>, that an individual No. Statements λ j,1 (1) λ j,2 (1) λ j,3 (1) λ j,4 (1) λ j,5 (1) who is aligned with this profile prefers a high-capacity robotic vacuum relative to the outside good. In other words, because they are cleaning often, they want a robotic vacuum with high capacity in order to effectively assist in their cleaning efforts. We can better inform targeting and promotion strategies using the proposed model by tailoring promotional messages using the groups of significant coefficients in each membership profile and targeting those respondents with high membership probabilities in a given profile. Thus, we can use the coefficient matrix as a road map for targeting by matching what respondents prefer with a far more parsimonious and richly detailed explanation of what is driving those preferences. For example, on average, consumers prefer a robotic vacuum with high cleaning performance and are very price sensitive relative to the cheapest price of $299. For consumers who are in profile 3, Anxious About Germs, we know that price promotions should be especially effective because they have demand for robotic vacuums but are very price sensitive. The dimension reduction provided by employing an integrated choice and GoM model makes this plausible with the 12 × 6 Γ matrix in Table <ref type="table" target="#tab_3">12</ref> compared with a similar task using the 12 × 19 Γ matrix in Table <ref type="table" target="#tab_10">9</ref> from the binary covariate model.</p><p>Identifying respondent profiles is akin to a segmentation analysis. The blocks of significant attributelevel coefficients in Table <ref type="table" target="#tab_3">12</ref> are reminiscent of such solutions. Unlike finite mixture models, where a respondent is assigned to a single category, mixed membership models like the GoM allow for the more realistic description of each respondent being a partial member of each profile, with weights determined heterogeneously.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Discussion</head><p>In this paper, we show that an integrated choice and covariate model does more to explain consumer preferences than the discrete covariates on their own. To be effective in explaining preference heterogeneity, the covariate model needs to provide individual-level summaries of the covariates, each reduced dimension to be characterized by different observations, and enable inference. An integrated choice and mixed membership model meets these criteria and outperforms the standard model and competing covariate and predictive models when respondents are a genuine mixture across profiles. In other words, mixed membership models fill the space between intercept-only and finite mixture models.</p><p>Choice modeling remains an essential fixture of marketing research. The mixed membership component of our integrated choice model uncovers both patterns across survey responses as well as how individual consumers relate to these patterns. Insomuch as these patterns or profiles relate to extremes in preference heterogeneity, and individual consumers' partial memberships in these profiles are sufficiently extreme, the integrated hierarchical Bayesian choice and GoM model (i.e., the membership vector model) uncovers distinct points of shrinkage for the model of heterogeneity. This aligns with arguments that identifying extreme responses is important for designing and promoting successful new products <ref type="bibr" target="#b1">(Allenby and Ginter 1995)</ref>. For example, extreme response behavior can be used to more efficiently target prospects with a high probability of adopting an innovation.</p><p>Conceptualizing consumer heterogeneity as a continuous distribution of preferences has been shown to aid in the identification of extreme responses <ref type="bibr" target="#b2">Rossi 1998, Allenby et al. 1998</ref>). The GoM model  Note. The marginal posteriors with means in bold have 95% credible intervals that do not contain zero.</p><p>Dotson, Büschken, and Allenby: Explaining Preference Heterogeneity represents discrete response behavior as a continuous proximity to a limited number of extreme profiles. Given that marketers often search for a limited number of product offerings for reasons of efficiency or resource limitations, a concept of heterogeneity that expresses differences among consumers in the space of a small number of extreme response profiles is appealing.</p><p>The empirical applications utilize typical survey and conjoint data in both an emerging market and an established category to demonstrate the use of the proposed model. However, with a growing number of potential covariates, including unstructured collections of discrete data, we see this approach as an important step to utilizing such data to improve choice modeling. LDA, as another mixed membership model, provides an obvious extension. Text data results in the same kind of sparse matrix as the multinomial data used in the GoM model, with LDA proceeding with words instead of items or statements and a single document for each individual. The dimension reduction using text is even more dramatic when starting with potentially thousands of unique words in the count matrix. However, the amount of data needed to run LDA with words composing the collection of discrete data is significant because of the large number of words in any given vocabulary. Without enough data, there are a variety of developments in topic modeling that are ripe for application within marketing, including using Dirichlet process priors <ref type="bibr" target="#b15">(Ferguson 1973</ref><ref type="bibr" target="#b5">, Antoniak 1974</ref>) as a kind of distribution of heterogeneity over topic proportions. We leave the practical problems of using text in the place of traditional survey questions as an extension to this research.</p><p>Another extension relates to estimating the concentration parameter α and the optimal size of K. In working to properly account for extremes in the distribution of heterogeneity, we have seen that generating the predictive distribution of heterogeneity is sensitive to the Dirichlet hyperprior. Whereas we have minimized the influence of α in generating that predictive distribution, one might consider how to inform an additional model layer so that α can be estimated instead. Additionally, although there is not a consensus as to which measure of model fit provides the gold standard for determining the size of K, there are a number of extant methods for navigating across possible model dimensions that could be employed to include K as a parameter in the model <ref type="bibr">(Green 1995</ref><ref type="bibr" target="#b20">, Green et al. 2015</ref>. The technical details of how to incorporate such methods into the proposed model are left for future research.</p><p>More generally, we see the use of supervised mixed membership models as an effective approach to mapping categorical responses to observed or latent outcomes of interest. This mapping is what introduces parsimony in the coefficient matrix relating the upper-level regressors and part-worths. This is also related to using mixed membership models as a modelbased approach to classifying consumers that yields a more realistic description of the individual as being a mixture of various extreme consumer profiles in a way that allows us to get into the extremes of the distribution of heterogeneity. This paper serves as a step toward fulfilling a broader need to provide more complete descriptions and explanations of consumer preference heterogeneity.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Figure 1. Hierarchical Bayesian Choice Model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Grade of Membership Model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 5 .</head><label>5</label><figDesc>Figure 5. Integrated Hierarchical Bayesian Choice and GoM Model</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 6 .</head><label>6</label><figDesc>Figure 6. Relative Out-of-Sample Hit Probabilities</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 7 .</head><label>7</label><figDesc>Figure 7. (Color online) Example Robotic Vacuum Choice Task</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 8 .</head><label>8</label><figDesc>Figure 8. Selecting K for the Robotic Vacuum Data Set</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 9 .</head><label>9</label><figDesc>Figure 9. Distributions of Estimated Membership Vectors</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Figure 4. Related and Competing Covariate Models</figDesc><table><row><cell>Dotson, Büschken, and Allenby: Explaining Preference Heterogeneity</cell></row><row><cell>Marketing Science, 2020, vol. 39, no. 2, pp. 407-426, © 2020 INFORMS</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc> Allenby: Explaining Preference Heterogeneity   Marketing Science, 2020, vol. 39, no. 2, pp. 407-426, © 2020 INFORMS   </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc> Allenby: Explaining Preference Heterogeneity   Marketing Science, 2020, vol. 39, no. 2, pp. 407-426, © 2020 INFORMS   </figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>Performance of Membership Vector Model Relative to Alternative Models</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Constrained</cell></row><row><cell></cell><cell cols="2">Binary covariates</cell><cell cols="2">Factor scores</cell><cell cols="2">membership</cell></row><row><cell></cell><cell cols="6">Coefficient SE Coefficient SE Coefficient SE</cell></row><row><cell>Intercept</cell><cell>1.747</cell><cell>2.039</cell><cell>−2.069</cell><cell>1.600</cell><cell>−3.451</cell><cell>2.729</cell></row><row><cell>α</cell><cell>0.450</cell><cell>0.431</cell><cell>−0.191</cell><cell>0.215</cell><cell>−1.917</cell><cell>0.549</cell></row><row><cell>τ</cell><cell>−0.176</cell><cell>0.201</cell><cell>−0.210</cell><cell>0.153</cell><cell>−0.010</cell><cell>0.180</cell></row><row><cell>K</cell><cell>−0.653</cell><cell>0.366</cell><cell>0.232</cell><cell>0.288</cell><cell>0.261</cell><cell>0.465</cell></row><row><cell>J</cell><cell>−0.233</cell><cell>0.155</cell><cell>0.151</cell><cell>0.106</cell><cell>0.154</cell><cell>0.174</cell></row><row><cell>α × τ</cell><cell>0.153</cell><cell>0.049</cell><cell>0.004</cell><cell>0.012</cell><cell>−0.002</cell><cell>0.026</cell></row><row><cell>α × K</cell><cell>0.072</cell><cell>0.042</cell><cell>0.086</cell><cell>0.032</cell><cell>0.528</cell><cell>0.130</cell></row><row><cell>α × J</cell><cell>−0.029</cell><cell>0.024</cell><cell>−0.007</cell><cell>0.011</cell><cell>−0.007</cell><cell>0.019</cell></row><row><cell>τ × K</cell><cell>0.071</cell><cell>0.030</cell><cell>0.034</cell><cell>0.019</cell><cell>0.025</cell><cell>0.023</cell></row><row><cell>τ × J</cell><cell>−0.031</cell><cell>0.016</cell><cell>0.000</cell><cell>0.007</cell><cell>−0.003</cell><cell>0.009</cell></row><row><cell>K × J</cell><cell>0.038</cell><cell>0.026</cell><cell>−0.014</cell><cell>0.018</cell><cell>−0.024</cell><cell>0.029</cell></row><row><cell>Hit rate</cell><cell></cell><cell>86%</cell><cell></cell><cell>70%</cell><cell></cell><cell>87%</cell></row></table><note>Notes. Reported are maximum likelihood estimates from a binary logit model with preference for the membership vector model over the comparison benchmark model (i.e., yes or no) as the dependent variable. Coefficients credibly different from 0 (95% level or higher) are in bold. Hit rate indicates share of correct predictions. SE, Standard error of estimate.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Statements on Cleaning and Robotic Vacuums</figDesc><table><row><cell>No.</cell><cell>Item</cell></row><row><cell>1.</cell><cell>I enjoy coming home to a clean house.</cell></row><row><cell>2.</cell><cell>I don't feel relaxed when I know my home isn't clean.</cell></row><row><cell>3.</cell><cell>I worry about pet hair and dander in the home.</cell></row><row><cell>4.</cell><cell>I have trouble keeping the floor beneath my furniture</cell></row><row><cell></cell><cell>clean.</cell></row><row><cell>5. . . .</cell><cell>I worry about germs and dirt on my floor and carpet. . . .</cell></row><row><cell>14.</cell><cell>Robotic vacuums often need to be "rescued" because</cell></row><row><cell></cell><cell>they get stuck.</cell></row><row><cell>15.</cell><cell>Robotic vacuums need to have their trash containers</cell></row><row><cell></cell><cell>changed too often.</cell></row><row><cell>16.</cell><cell>Robotic vacuums don't do a good enough job cleaning</cell></row><row><cell></cell><cell>the floor and carpet.</cell></row><row><cell>17.</cell><cell>Robotic vacuums don't spend enough time on really</cell></row><row><cell></cell><cell>dirty spots on the floor.</cell></row><row><cell>18.</cell><cell>Robotic vacuums scare household pets.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Statements on Smartphone Interest and UsageThe security of the OS on my SP is very important to me. 2.</figDesc><table><row><cell>No.</cell><cell>Item</cell></row><row><cell>1.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 .</head><label>5</label><figDesc>Robotic Vacuum Attribute Levels</figDesc><table><row><cell>Attributes</cell><cell></cell><cell></cell><cell>Levels</cell><cell></cell><cell></cell></row><row><cell>Brand</cell><cell>Outside option</cell><cell>Neato</cell><cell>iRobot</cell><cell>Samsung</cell><cell>Black &amp; Decker</cell></row><row><cell>Performance</cell><cell>70%</cell><cell>85%</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Capacity</cell><cell>Every use</cell><cell>Every 2-3 uses</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Navigation</cell><cell>Random</cell><cell>Smart</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Programming</cell><cell>Base unit</cell><cell>App</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Virtual borders</cell><cell>No</cell><cell>Yes</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Price</cell><cell>$299</cell><cell>$399</cell><cell>$499</cell><cell>$599</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 .</head><label>6</label><figDesc>Smartphone Attribute Levels</figDesc><table><row><cell>Attribute</cell><cell></cell><cell>Levels</cell><cell></cell><cell></cell></row><row><cell>Display size</cell><cell>4 inch</cell><cell>4.7 inch</cell><cell>5 inch</cell><cell>5.5 inch</cell></row><row><cell>Display resolution</cell><cell>Standard</cell><cell>HD</cell><cell></cell><cell></cell></row><row><cell>Camera (front)</cell><cell>4 MP</cell><cell>6 MP</cell><cell>8 MP</cell><cell>12 MP</cell></row><row><cell>Memory</cell><cell>4 GB</cell><cell>16 GB</cell><cell>32 GB</cell><cell>64 GB</cell></row><row><cell>Price</cell><cell>$400</cell><cell>$600</cell><cell>$800</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 7 .</head><label>7</label><figDesc>Data Summary</figDesc><table><row><cell cols="3">Dotson, Büschken, and Allenby: Explaining Preference Heterogeneity</cell></row><row><cell>Variables</cell><cell>Robotic vacuums</cell><cell>Smartphones</cell></row><row><cell>N, total number of respondents</cell><cell>332</cell><cell>147</cell></row><row><cell>H, number of choice tasks for each respondent n</cell><cell>16</cell><cell>17</cell></row><row><cell>P, number of alternatives in each choice task</cell><cell>5</cell><cell>3</cell></row><row><cell>M, number of attribute levels in each choice task</cell><cell>12</cell><cell>12</cell></row><row><cell>J, number of categorical questions</cell><cell>18</cell><cell>53</cell></row><row><cell>L j , number of categorical responses for each question j</cell><cell>2</cell><cell>2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 8 .</head><label>8</label><figDesc>Model Fit</figDesc><table><row><cell>In-sample</cell><cell>Predictive</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 9 .</head><label>9</label><figDesc>Robotic Vacuum Binary Covariate Model Γ</figDesc><table><row><cell>Estimates</cell></row><row><cell>Int.</cell></row><row><cell>Attribute levels</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 10 .</head><label>10</label><figDesc>Robotic Vacuum Membership Vector Model {λ j (1)} 18 j 1 Estimates</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 11 .</head><label>11</label><figDesc>Robotic Vacuum Profile Names</figDesc><table><row><cell>No.</cell><cell>Robotic vacuums</cell></row><row><cell>1.</cell><cell>Constantly Cleaning</cell></row><row><cell>2.</cell><cell>Anxious About Cleanliness</cell></row><row><cell>3.</cell><cell>Anxious About Germs</cell></row><row><cell>4.</cell><cell>Little Cleaning</cell></row><row><cell>5.</cell><cell>Specific Cleaning Concerns</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 12 .</head><label>12</label><figDesc>Robotic Vacuum Membership Vector Model ILR-Transformed Γ Estimates</figDesc><table><row><cell>Attribute levels</cell><cell>Baseline</cell><cell>P1</cell><cell>P2</cell><cell>P3</cell><cell>P4</cell><cell>P5</cell></row><row><cell>Neato</cell><cell>−0.22</cell><cell>1.89</cell><cell>−3.05</cell><cell>1.35</cell><cell>−3.74</cell><cell>3.04</cell></row><row><cell>iRobot</cell><cell>1.21</cell><cell>0.88</cell><cell>−2.95</cell><cell>1.42</cell><cell>−3.49</cell><cell>3.39</cell></row><row><cell>Samsung</cell><cell>0.81</cell><cell>1.16</cell><cell>−2.92</cell><cell>2.10</cell><cell>−3.61</cell><cell>3.24</cell></row><row><cell>Black &amp; Decker</cell><cell>0.46</cell><cell>1.60</cell><cell>−3.20</cell><cell>1.96</cell><cell>−3.70</cell><cell>3.31</cell></row><row><cell>Cleaning Performance: 85%</cell><cell>3.68</cell><cell>0.15</cell><cell>1.05</cell><cell>−0.71</cell><cell>0.94</cell><cell>−2.02</cell></row><row><cell>Capacity: Every 2-3 uses</cell><cell>0.78</cell><cell>0.26</cell><cell>0.05</cell><cell>0.00</cell><cell>−0.26</cell><cell>−0.11</cell></row><row><cell>Smart navigation</cell><cell>0.92</cell><cell>0.38</cell><cell>0.34</cell><cell>−0.11</cell><cell>0.07</cell><cell>−0.15</cell></row><row><cell>App programming</cell><cell>0.01</cell><cell>0.24</cell><cell>0.20</cell><cell>−0.18</cell><cell>−0.21</cell><cell>0.03</cell></row><row><cell>Virtual borders</cell><cell>0.69</cell><cell>0.00</cell><cell>0.51</cell><cell>−0.86</cell><cell>0.45</cell><cell>0.04</cell></row><row><cell>$399</cell><cell>−2.09</cell><cell>−1.35</cell><cell>1.90</cell><cell>−0.89</cell><cell>−1.16</cell><cell>0.94</cell></row><row><cell>$499</cell><cell>−5.60</cell><cell>−2.05</cell><cell>4.11</cell><cell>−1.46</cell><cell>−2.38</cell><cell>2.01</cell></row><row><cell>$599</cell><cell>−8.56</cell><cell>−2.74</cell><cell>5.14</cell><cell>−1.87</cell><cell>−3.53</cell><cell>2.64</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">MarketingScience, 2020, vol. 39, no. 2, pp. 407-426, © 2020 </note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Airoldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Erosheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Fienberg</surname></persName>
		</author>
		<title level="m">Handbook of Mixed Membership Models and Their Applications</title>
				<meeting><address><addrLine>Boca Raton, FL</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note>Chapman &amp; Hall/CRC</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Using extremes to design products and segment markets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Ginter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="392" to="403" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Marketing models of consumer heterogeneity</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="57" to="78" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">On the heterogeneity of demand</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Arora</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L</forename><surname>Ginter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="384" to="389" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Probabilistic topic model for hybrid recommender systems: A stochastic variational Bayesian approach</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">Z</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="987" to="1008" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Mixtures of Dirichlet processes with applications to Bayesian nonparametric problems</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">E</forename><surname>Antoniak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1152" to="1174" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Deriving the pricing power of product features by mining consumer reviews</title>
		<author>
			<persName><forename type="first">N</forename><surname>Archak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1485" to="1509" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Supervised topic models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Mcauliffe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Platt</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Koller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Singer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">T</forename><surname>Roweis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 20th Internat. Conf. Neural Inform. Processing Systems</title>
				<meeting>20th Internat. Conf. Neural Inform. essing Systems<address><addrLine>Red Hook, NY</addrLine></address></meeting>
		<imprint>
			<publisher>Curran Associates</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="121" to="128" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Latent Dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Machine Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sentence-based text analysis for customer reviews</title>
		<author>
			<persName><forename type="first">J</forename><surname>Büschken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">H</forename><surname>Allenby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="953" to="975" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Identifying unmet demand</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Chandukala</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><forename type="middle">D</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="61" to="73" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Fuzzy and crisp settheoretic-based classification of health and disease</title>
		<author>
			<persName><forename type="first">J</forename><surname>Clive</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Woodbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">C</forename><surname>Siegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Medical Systems</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="317" to="332" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Rcpp: Seamless R and C++ integration</title>
		<author>
			<persName><forename type="first">D</forename><surname>Eddelbuettel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Francois</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Allaire</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Ushey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Kou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Bates</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Chambers</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=Rcpp" />
		<imprint>
			<date type="published" when="2018-08-28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Describing disability through individual-level mixture models for multivariate binary data</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Erosheva</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Fienberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Joutard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Appl. Stat</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="346" to="384" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">archetypes: Archetypal analysis</title>
		<author>
			<persName><forename type="first">Mja</forename><surname>Eugster</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Leisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Seth</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=archetypes" />
		<imprint>
			<date type="published" when="2014-08-28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A Bayesian analysis of some nonparametric problems</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">S</forename><surname>Ferguson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Statist</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="209" to="230" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Frühwirth-Schnatter</surname></persName>
		</author>
		<title level="m">Finite Mixture and Markov Switching Models</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Springer-Verlag</publisher>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">Interpreting mixed membership. Handbook of Mixed Membership Models and Their Applications</title>
		<author>
			<persName><forename type="first">A</forename><surname>Galyardt</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Chapman &amp; Hall/CRC</publisher>
			<biblScope unit="page" from="39" to="65" />
			<pubPlace>Boca Raton, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Variable selection via Gibbs sampling</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">I</forename><surname>George</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Mcculloch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">88</biblScope>
			<biblScope unit="issue">423</biblScope>
			<biblScope unit="page" from="881" to="889" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Reversible jump Markov chain Monte Carlo computation and Bayesian model determination</title>
		<author>
			<persName><forename type="first">Büschken</forename><surname>Dotson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allenby</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Explaining Preference Heterogeneity Marketing Science</title>
				<imprint>
			<date type="published" when="1995" />
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="711" to="732" />
		</imprint>
	</monogr>
	<note>© 2020 INFORMS Green PJ</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Bayesian computation: A summary of the current state, and samples backward and forwards</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Łatuszyński</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Pereyra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">P</forename><surname>Robert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Statist. Comput</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="835" to="862" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">A mixed-membership approach to the assessment of political ideology from survey responses. Handbook of Mixed Membership Models and Their Applications</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Manrique-Vallier</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Chapman &amp; Hall/CRC</publisher>
			<biblScope unit="page" from="119" to="139" />
			<pubPlace>Boca Raton, FL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Observed and unobserved preference heterogeneity in brand-choice models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Horsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Misra</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="322" to="335" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Model-based purchase predictions for large assortments</title>
		<author>
			<persName><forename type="first">Bjd</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Donkers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Fok</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="389" to="404" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Discovery of latent patterns with hierarchical Bayesian mixed-membership models and the issue of model choice</title>
		<author>
			<persName><forename type="first">C</forename><surname>Joutard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">M</forename><surname>Airoldi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Fienberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Love</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining Patterns: New Methods and Applications</title>
				<editor>
			<persName><forename type="first">F</forename><surname>Masseglia</surname></persName>
			<persName><forename type="first">M</forename><surname>Teisseire</surname></persName>
		</editor>
		<meeting><address><addrLine>Hershey, PA</addrLine></address></meeting>
		<imprint>
			<publisher>IGI Global</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="240" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">A probabilistic choice model for market segmentation and elasticity structure</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Kamakura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="379" to="390" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<title level="m">Structural Equation Modeling: A Bayesian Approach</title>
				<meeting><address><addrLine>Hoboken, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Automated marketing research using online customer reviews</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="881" to="894" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Hierarchical Bayes conjoint analysis: Recovery of partworth heterogeneity from reduced experimental designs</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Desarbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="191" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Manton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Woodbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">D</forename><surname>Tolley</surname></persName>
		</author>
		<title level="m">Statistical Application Using Fuzzy Sets</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Wiley</publisher>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Characterizing latent structure: Factor analytic and grade of membership models</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">M</forename><surname>Marini</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">L</forename><surname>Fan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sociol. Methodology</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="133" to="164" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Mine your own business: Market-structure surveillance through text mining</title>
		<author>
			<persName><forename type="first">O</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goldenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fresko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="521" to="543" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Approximate Bayesian inference with the weighted likelihood bootstrap</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Newton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Statist. Soc. B</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="48" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">bayesm: Bayesian inference for marketing/microeconometrics</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=bayesm" />
		<imprint>
			<date type="published" when="2018-08-28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Bayesian statistics and marketing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="304" to="328" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Mcculloch</surname></persName>
		</author>
		<title level="m">Bayesian Statistics and Marketing</title>
				<meeting><address><addrLine>Hoboken, NJ</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Overcoming scale usage heterogeneity: A Bayesian hierarchical approach</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gilula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">96</biblScope>
			<biblScope unit="issue">453</biblScope>
			<biblScope unit="page" from="20" to="31" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The value of purchase history data in target marketing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Mcculloch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="321" to="340" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Bayesian measures of model complexity and fit</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">J</forename><surname>Spiegelhalter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">P</forename><surname>Carlin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Van Der Linde</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Royal Statist. Soc. B</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="583" to="639" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The application and misapplication of factor analysis in marketing research</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Stewart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Mining marketing meaning from online chatter: Strategic brand analysis of big data using latent Dirichlet allocation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tirunillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Tellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="463" to="479" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Idea generation, creativity, and prototypicality</title>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Netzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title level="m" type="main">loo: Efficient leave-one-out cross-validation and WAIC for Bayesian models</title>
		<author>
			<persName><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=loo" />
		<imprint>
			<date type="published" when="2018-08-28" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Asymptotic equivalence of Bayes cross validation and widely applicable information criterion in singular learning theory</title>
		<author>
			<persName><forename type="first">S</forename><surname>Watanabe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Machine Learn. Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="3571" to="3594" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Mathematical typology: A grade of membership technique for obtaining disease definition</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Woodbury</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Clive</forename><forename type="middle">J</forename><surname>Garson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><genName>Jr</genName></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comput. Biomedical Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="277" to="298" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title/>
		<author>
			<persName><forename type="first">Büschken</forename><surname>Dotson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Allenby</forename></persName>
		</author>
		<imprint>
			<publisher>Explaining Preference Heterogeneity</publisher>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
