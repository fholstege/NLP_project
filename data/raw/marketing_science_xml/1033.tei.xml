<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org A Hierarchical Bayesian Methodology for Treating Heterogeneity in Structural Equation Models</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Asim</forename><surname>Ansari</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kamel</forename><surname>Jedidi</surname></persName>
						</author>
						<author role="corresp">
							<persName><forename type="first">Sharan</forename><surname>Jagpal</surname></persName>
							<email>jagpal007@gateway.net</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Graduate School of Business</orgName>
								<orgName type="institution">Columbia University</orgName>
								<address>
									<addrLine>Uris Hall</addrLine>
									<postCode>3022, 10027-6902</postCode>
									<settlement>Broadway, New York</settlement>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Faculty of Management</orgName>
								<orgName type="institution">Rutgers University</orgName>
								<address>
									<settlement>Newark</settlement>
									<region>NJ</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org A Hierarchical Bayesian Methodology for Treating Heterogeneity in Structural Equation Models</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.19.4.328.11789</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please scroll down for article-it is on subsequent pages</head><p>With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning opportunities for individual professionals, and organizations of all types and sizes, to better understand and use O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>first application illustrates our methods on synthetic data, whereas the second application uses consumer satisfaction data involving measurements on satisfaction, expectation disconfirmation, and performance variables obtained from a panel of subjects. Our results from the synthetic data application show that our Bayesian procedures perform well in recovering the true parameters. More importantly, we find that models that ignore heterogeneity can yield a severely distorted picture of the nature of associations among variables and can therefore generate misleading inferences. Specifically, we find that ignoring heterogeneity can result in inflated estimates of measurement reliability, wrong signs of factor covariances, and can yield attenuated model fit and standard errors. The results from the consumer satisfaction study show that individuals vary both in means and covariances and indicate that conventional psychometric methods are not appropriate for our data. In addition, we find that heterogeneous models outperform the standard structural equation model in predictive ability. Managerially, we show how one can use the individual-level factor scores and structural parameter estimates from the Bayesian approach to perform quadrant analysis and refine marketing policy (e.g., develop a one-on-one marketing policy).</p><p>The framework introduced in this paper and the inference procedures we describe should be of interest to researchers in a wide range of disciplines in which measurement error and unobserved heterogeneity are problematic. In particular, our approach is suitable for studies in which panel data or multiple observations are available for a given set of respondents or objects (e.g., firms, organizations, markets). At a practical level, our procedures can be used by managers and other policymakers to customize marketing activities or policies.</p><p>Future research should extend our procedures to deal with the general nonrecursive structural equation model and to handle binary and ordinal data situations. <ref type="bibr">(Structural Equation Models; Heterogeneity; Hierarchical Bayes; MCMC Procedures; Metropolis-Hastings Algorithm; Gibbs Sampling; Customer Satisfaction)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Structural equation models are widely used in marketing and psychometric literature to model relationships among unobserved constructs and manifest variables, and to control for measurement error. Most applications of structural equation models assume that the data come from a homogeneous population, and hence implicitly ignore the influence of unobserved sources of heterogeneity. This approach is problematic: As the vast literature on heterogeneity in regression and discrete choice models clearly shows, a failure to adequately account for unobserved sources of heterogeneity is likely to result in misleading inferences.</p><p>Many different sources of unobserved heterogeneity are possible in structural equation models. To illustrate these sources, consider a product positioning study that uses a structural equation approach to model the structure of consumer preferences for automobiles. Suppose theory suggests that the salient unobserved perceived benefits that affect preference are safety, reliability, and economy, and assume that a set of scales are available to operationalize these unobservable constructs. The measurement model that captures consumer perceptions of the unobserved benefits can be affected by many types of unobserved heterogeneity. For example, the mean perceptual scores (i.e., factor means for safety, reliability, and economy) may vary in the population. The correlational structure of benefits can also vary across consumers. Thus, some consumers may exhibit a halo effect; for example, safety and reliability may be positively correlated for one type of consumers (e.g., novices) but may be orthogonal for another type (e.g., experts). Finally, consumers may provide information with different degrees of accuracy (e.g., variability in measurement error for any given scale item could differ across individuals). The structural model may also be affected by unobserved heterogeneity. For example, consumers may differ in their importance weights (i.e., the structural parameters) for perceived benefits. As we show in this paper, when such general types of measurement and structural heterogeneity are present, analyzing the pooled data using a conventional structural equation model that ignores the sources of individual differences can result in misleading inferences and incorrect conclusions. See also <ref type="bibr" target="#b20">Muthén (1989)</ref>, <ref type="bibr" target="#b12">Jedidi et al. (1997)</ref>, and <ref type="bibr">Jagpal (1999, Chapter 4)</ref> for more theoretical discussion and examples.</p><p>In marketing literature, researchers have used either a finite-mixture <ref type="bibr" target="#b15">(Kamakura and Russell 1989)</ref> or a random-coefficient approach <ref type="bibr">Rossi 1999, Chintagunta et al. 1991</ref>) for modeling heterogeneity. <ref type="bibr" target="#b12">Jedidi et al. (1997)</ref> recently developed a finite-mixture approach for response-based segmentation in structural equation models. In psychometric literature on structural equations models, heterogeneity is typically handled using random-coefficient procedures (also called multilevel models; see <ref type="bibr" target="#b20">Muthén 1989</ref><ref type="bibr" target="#b20">Muthén , 1994</ref><ref type="bibr" target="#b17">Longford and Muthén 1992</ref>) that allow variation only in mean structures (i.e., in factor means or measurement intercepts). In many marketing applications (as in the product positioning example above), the data may exhibit heterogeneity not only in mean structures but also in structural parameters and covariance structures. Existing random-coefficient models cannot be used in such contexts. In fact, the classical procedures that are used for estimating these models cannot be adapted to accommodate general forms of heterogeneity. A random-coefficient approach that allows the specification and estimation of heterogeneity in both mean and covariance structures (i.e., in structural parameters, measurement error variances, and factor covariances) is clearly needed. In this paper we describe such an approach.</p><p>We develop a hierarchical Bayesian framework for modeling general forms of heterogeneity in partially recursive structural equation models. Our framework elucidates the motivations for accommodating heterogeneity and illustrates theoretically the types of misleading inferences that can result when unobserved heterogeneity is ignored. We describe in detail the choices that researchers can make in incorporating different forms of measurement and structural heterogeneity. We also develop Markov Chain Monte Carlo (MCMC) procedures to perform Bayesian inference in partially recursive, random-coefficient structural equation models.</p><p>The hierarchical Bayesian approach is eminently suitable for studies in which panel data or multiple observations are available for a given set of respondents or objects (e.g., firms). This approach allows for appropriate pooling of information while taking into account heterogeneity. We illustrate our approach using two applications. The first application illustrates our methods on synthetic data, whereas the second application uses consumer satisfaction data involving measurements on satisfaction, expectation disconfirmation, and performance variables obtained from a panel of subjects. We find that models that ignore heterogeneity can yield a severely distorted picture of the nature of associations among variables and can therefore generate misleading inferences. Specifically, we show that ignoring heterogeneity leads to inflated estimates of measurement reliability, can generate wrong signs of factor covariances, and can result in attenuated model fit and standard errors. In addition, we find that heterogeneous models outperform the standard structural equation model in predictive ability.</p><p>The hierarchical Bayesian approach provides several theoretical and practical advantages over classical methods in treating heterogeneity in structural equation models. (See Allenby and Rossi 1999 for a lucid discussion of the advantages of the Bayesian methodology in the context of choice models.) From a practical viewpoint, Bayesian methods allow the flexible incorporation of prior information, whenever available, about model parameters. In addition, Bayesian methods allow the estimation of individual-specific estimates while accounting for the uncertainty in such estimates. Specifically, in our modeling context, the hierarchical Bayesian structural equation methodology provides individual-specific estimates of the factor scores, structural coefficients, and other model parameters. Thus, managers can use our approach to target selected individuals or groups in a highly focused manner using customized marketing strategies.</p><p>From a statistical viewpoint, sampling-based Bayesian methods are appealing because they do not rely on asymptotic theory, a practice that is known to be misleading when the sample size is small (see <ref type="bibr" target="#b24">Scheines et al. 1999)</ref>. The Bayesian approach is well-suited for dealing with unbalanced designs, a common problem in marketing studies. As discussed later, by using MCMC procedures one can obtain simulation-based estimates of the parameters of a structural equation model. This circumvents the evaluation of complex multidimensional integrals that are required to implement maximum likelihood methods on panel data.</p><p>The rest of the paper is organized as follows. Section 2 presents the hierarchical Bayesian approach for estimating structural equation models. Section 3 discusses the specification of the priors and briefly describes the MCMC method for inference. Section 4 describes the results from a synthetic data set. Section 5 illustrates our approach on customer satisfaction study, and § 6 provides a summary and discusses directions for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Hierarchical Structural Equation Model</head><p>A hierarchical structural equation model can be specified in two stages. In the first stage, structural and measurement models are specified for each individual.</p><p>In the second stage, a population distribution is specified to model variation in individual-level parameters across all individuals. Let i ‫ס‬ 1 to I represent individuals and let j ‫ס‬ 1 to N i index the observations belonging to the ith individual. Suppose each individual provides multivariate observations on q endogenous and p exogenous indicator (manifest) variables, y ij and x ij , respectively. The associations among these manifest variables can be described in terms of latent constructs using a structural equation model. Let the (m ‫ן‬ 1) vector n ij and the (n ‫ן‬ 1) vector g ij , respectively, contain the exogenous and endogenous latent variables. As is well-known, the complete model for individual i consists of a measurement model that describes the relationship between observed and latent variables and a structural model that relates the exogenous and endogenous latent variables. Specifically, the measurement model for individ ual i can be written as follows:</p><formula xml:id="formula_0">x ‫ס‬ ␣ ‫ם‬ K n ‫ם‬ d , ij i,x i,x ij ij y ‫ס‬ ␣ ‫ם‬ K g ‫ם‬ ⑀ , (<label>1</label></formula><formula xml:id="formula_1">) ij i, y i,y ij ij</formula><p>for j ‫ס‬ 1 to N i , where ␣ i,x and ␣ i, y are p ‫ן‬ 1 and q ‫ן‬ 1 measurement intercept vectors, respectively, for the exogenous and endogenous indicator variables. The (p ‫ן‬ m) matrix K i,x and the (q ‫ן‬ n) matrix K i, y contain the factor loadings. The terms d ij ϳ N(0, H i,x ) and ⑀ ij ϳ N(0, H i, y ), respectively, represent the vectors of measurement errors. The p ‫ן‬ p matrix H i,x and the q ‫ן‬ q matrix H i, y are diagonal and contain the measurement error variances. The m latent factors in n ij are assumed to be normally distributed N( i , U i ), where i is a (m ‫ן‬ l) vector of factor means and U i is a m ‫ן‬ m covariance matrix of factor scores.</p><p>The structural model that relates the latent constructs n ij and g ij for each individual i is</p><formula xml:id="formula_2">B g ‫ס‬ c ‫ם‬ C n ‫ם‬ f (2) i ij 0i i ij ij</formula><p>where B i is a (n ‫ן‬ n) matrix of structural parameters specifying the links among the endogenous latent variables, c 0i is a (n ‫ן‬ 1) vector of structural intercept terms, C i is a (n ‫ן‬ m) coefficient matrix denoting the effects of n ij on g ij , and f ij is a n ‫ן‬ 1 vector of disturbances. The disturbances f ij are assumed to be uncorrelated with n ij and are distributed N(0, W i ), where W i is a (n ‫ן‬ n) covariance matrix that captures the residual variation in the structural model. In our model, B i is restricted to being triangular.</p><p>When each individual provides enough observations (i.e., when N i is large for all i), separate models can be estimated for each individual. In most situations, however, only a limited number of observations are available for at least some individuals, thus precluding individual-level analyses. Moreover, in most substantive enquiries, researchers are primarily interested in summarizing the relationships among constructs at the population level while controlling for individual differences. A hierarchical approach is, therefore, eminently suitable in such situations, because this method appropriately pools information across all individuals to estimate the desired relationships. A hierarchical model accounts for observed and unobserved sources of heterogeneity by specifying a second-stage population distribution that describes how individual-specific parameters in Equations ( <ref type="formula" target="#formula_0">1</ref>) and (2) vary in the population. Specifically, in the second stage of the hierarchical model, the individual-</p><formula xml:id="formula_3">level parameters u i ‫ס‬ {␣ i,x , ␣ i, y , K i,x , K i, y , i , U i , H i,x , H i, y , B i , c 0i , C i , W i</formula><p>} are specified as random variables drawn from a general population distribution h(u i ).</p><p>It is important to note that a very general hierarchical model that allows all parameters to vary freely across individuals is not identifiable. We need to restrict certain parameters at both the individual and population levels for identification purposes. As in conventional structural equation models, we can also include additional restrictions based on prior theory to obtain parsimonious models. Figure <ref type="figure">1</ref> provides a graphical summary of the potential sources of heterogeneity in structural equation models. We discuss below how different types of heterogeneity can be specified in the measurement and structural models. We also discuss the types of restrictions that are needed for the identification of parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Measurement Heterogeneity</head><p>Previous attempts to capture heterogeneity using random parameter formulations have focused solely on capturing individual differences in mean structures. In the psychometric literature on multilevel models (see <ref type="bibr" target="#b20">Muthén 1989</ref><ref type="bibr" target="#b20">Muthén , 1994</ref><ref type="bibr" target="#b9">Goldstein and McDonald 1988)</ref>, researchers have either allowed measurement intercepts to vary across individuals or have assumed that factor means differ across individuals (see Figure <ref type="figure">1</ref>). In many studies, researchers are primarily interested in modeling individual differences in underlying constructs. We follow this approach and allow factor means to differ across individuals. Specifically, we set ␣ i,x ‫ס‬ ␣ x , and ␣ i, y ‫ס‬ ␣ y for all i and assume that individual-level factor means i are distributed multivariate normal N(0, D) in the population. We assume a zero mean for this population distribution to fix the location of the grand mean and ensure identification. This is analogous to setting the factor means of the first group to zero in multigroup structural equation models <ref type="bibr" target="#b14">(Jö reskog 1971</ref><ref type="bibr" target="#b25">, Sö rbom 1981</ref>.</p><p>Allowing solely for differences in mean structures results in a model that assumes that individuals have identical covariance structures. As is clear from the product positioning example in §1, the assumption implicit in multilevel models that factor covariances and measurement error variances are invariant may not hold in empirical applications. For example, experts may provide more precise measures, i.e., they may have lower measurement error variances. Moreover, experts often possess more refined knowledge structures than novices; hence experts are able to discriminate finely among latent constructs. Thus, factor covariance matrices, U i , may be nearly diagonal for experts; in contrast, factor covariance matrices for novices may exhibit high correlations because of halo effects.</p><p>The literature on multigroup structural equation models <ref type="bibr" target="#b14">(Jö reskog 1971</ref><ref type="bibr" target="#b25">, Sö rbom 1981</ref> allows for differences in covariance structures across a small number of a priori (exogenously) specified groups. The multigroup model assumes a fixed-effects approach to heterogeneity and typically requires a large number of observations per group. Recent research on finite mixtures of structural equation models <ref type="bibr" target="#b12">(Jedidi et. al. 1997)</ref> and confirmatory factor models <ref type="bibr" target="#b27">(Yung 1997</ref>) has also considered differences in covariance structures across endogenously determined groups of individuals in which the number of groups is small. In this paper, we are interested in a random-effects formulation of heterogeneity. Consequently, we allow the factor covariances U i and the measurement error variances H i to vary across individuals by specifying continuous population distributions. Specifically, we assume that the precision matrices come from a</p><formula xml:id="formula_4">‫1מ‬ U i common Wishart population distribution W( q, R),</formula><p>where q is the degrees of freedom and R is a m ‫ן‬ m positive definite scale matrix. To make the factor scores comparable across individuals (see <ref type="bibr" target="#b27">Yung 1997)</ref> and to preserve the definition and interpretability of the constructs, we assume that the factor loading matrices are invariant across individuals, i.e., K i,x ‫ס‬ K x and K i, y ‫ס‬ K y for i ‫ס‬ 1 to I. Because the scales of the latent factors are arbitrary, we can proceed by setting the appropriate elements in the loading matrices to unity. As in other structural equation models, additional constraints must be imposed on a case-by-case basis to ensure identification. Finally, we allow the measurement error variances H i,x , and H iy , to vary across individuals. Specifically, we assume that each measurement error variance comes from an independent inverse gamma population distribution <ref type="bibr">IG(h; a, b)</ref>.</p><p>To understand the implications of ignoring measurement heterogeneity, we need to examine the unconditional implied covariance matrix R of the structural equation model.   <ref type="bibr" target="#b18">(Lord and</ref><ref type="bibr">Novick 1968, Muthén 1989)</ref>. Secondly, the magnitude and the signs of the covariances in U Agg will be distorted. For example, if the elements E[U i,kj ] and D kj are of the same sign, then the magnitude of will be amplified. If, on the Agg U kj other hand, E[U i,kj ] and D kj are of the opposite sign, then may get attenuated or may have the wrong Agg U kj sign. Such a situation can clearly have unfortunate consequences for theory development. Other types of distortions are also possible. We report these in the applications to follow.</p><formula xml:id="formula_5">͚ ‫1מ‬ ‫1מ‬Ј ‫1מ‬ K B (C(E[U ] ‫ם‬ D)CЈ‫ם‬ W)B KЈ ‫ם‬ E[H ] K B C(E[U ] ‫ם‬ D)KЈ y i y i y y i x . ‫1מ‬Ј K (E[U ] ‫ם‬ D)CЈB KЈ K (E[U ] ‫ם‬ D)KЈ ‫ם‬ E[H ] x i y x i x i x (<label>3</label></formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Structural Heterogeneity</head><p>The structural model is crucially important to decision makers, because it includes structural parameters that measure the impact of key antecedent variables on outcomes. In many research studies, this relationship is of primary interest, and researchers often focus on studying individual differences in structural parameters. Previous research on multilevel models has not allowed for such forms of heterogeneity. In contrast, we allow structural coefficients to vary across individuals. Specifically, let vector p i contain the terms in B i , c i 0 , and C i . Then p i is assumed to be distributed multivariate normal N(Z i , ⌼), where Z i is a matrix that contains individual specific covariates (e.g., gender or age). Such a specification allows for both observed and unobserved sources of heterogeneity. Specifically, the inclusion of covariates through Z i allows a researcher to test for specific moderating effects. If individuallevel covariates are not available, then Z i reduces to an identity matrix. The parameters in explain the individual differences in the structural parameters in terms of the individual-level covariates. The ⌼ matrix captures the covariation in the structural parameters resulting from unobserved individual-level variables and, for parsimony, is assumed to be invariant across individuals. Because of the scale indeterminacy of the endogenous factors, we impose E(c i 0 ) ‫ס‬ 0 for identification. Although the population mean of the structural intercepts is fixed to zero, note that the individual-level intercepts are estimable subject to this constraint. This is analogous to fixing the intercept of one group to zero in a multigroup analysis (see <ref type="bibr" target="#b14">Jö reskog 1971</ref><ref type="bibr" target="#b25">, Sö rbom 1981</ref>.</p><p>Taking into account the individual-level models and the heterogeneity specifications, the complete twostage model can be written as: Stage 1:</p><formula xml:id="formula_6">x ‫ס‬ ␣ ‫ם‬ K n ‫ם‬ d ij x x ij ij y ‫ס‬ ␣ ‫ם‬ K g ‫ם‬ ⑀ ij y y ij ij B g ‫ס‬ c ‫ם‬ C n ‫ם‬ f i ij 0i i ij ij d ϳ N(0, H ) ij i,x ⑀ ϳ N(0, H ) ij i, y n ϳ N( , U ) ij i i f ϳ N(0, W) (4) ij Stage 2: ϳ N(0, D) i ‫1מ‬ U ϳ W(q, R) i p H ϳ IG(a , b ) ix ͟ k k k‫1ס‬ q H ϳ IG(a , b ) iy ͟ y y k‫1ס‬ p ϳ N(Z , ⌼) (5) i i</formula><p>Recall that, following the tradition in multigroup structural equation models, we assume that E( i ) ‫ס‬ 0 and E(c i 0 ) ‫ס‬ 0 to fix the origin of the factors. As is standard in structural equation models, we also restrict the loading of one indicator variable per factor to one to fix the scale of the factors. Note, however, that the identification of the structural equation model in Equation (4) requires that both the measurement and structural models are identified. <ref type="bibr">Bollen (1989, pp. 88-104 and pp. 238-254)</ref> discusses the identification issues in structural equation models and provides general rules for identification that can be followed on a case-by-case basis.</p><p>The hierarchical structural equation model defined by Equations ( <ref type="formula">4</ref>) and ( <ref type="formula">5</ref>) subsumes a variety of models as special cases. These include hierarchical confirmatory (first-order and second-order) factor analysis, hierarchical multivariate regression, and hierarchical simultaneous equation models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Inference</head><p>While the foregoing discussion on the different types of heterogeneity and its impact on inference is relevant for the general structural equation model, we now consider inference procedures for the case in which B i is triangular but W i is unrestricted. Let w ij ‫ס‬ {y ij , x ij } be the joint vector of manifest variables for an arbitrary observation j for individual i. According to the model represented in Equations ( <ref type="formula">4</ref>) and ( <ref type="formula">5</ref>), this observation comes from a multivariate normal distribution f i (w ij ; l i , R i ) with conditional mean vector</p><formula xml:id="formula_7">‫1מ‬ ␣ ‫ם‬ K B (c ‫ם‬ C ) y y i i 0 i i l ‫ס‬ (6) i ␣ ‫ם‬ K x x i</formula><p>and conditional covariance matrix</p><formula xml:id="formula_8">‫ס‬ ͚i ‫1מ‬ ‫1מ‬ ‫1מ‬Ј K B C U KЈ K B (C U CЈ ‫ם‬ W)B KЈ ‫ם‬ H y i i i x y i i i i i y iy . ‫1מ‬Ј K U KЈ ‫ם‬ H K U CЈB KЈ x i x ix x i i i y (<label>7</label></formula><formula xml:id="formula_9">)</formula><p>The likelihood for individual i is</p><formula xml:id="formula_10">N ‫2/1מ‬ i ‫(מ‬p‫ם‬q)/2 L ‫ס‬ (2p) i ͟ ͚i Η Η j‫1ס‬ 1 ‫1מ‬ exp ‫מ‬ (w ‫מ‬ l )Ј (w ‫מ‬ l ) (<label>8</label></formula><formula xml:id="formula_11">) ij i ͚ ij i i 2</formula><p>and the unconditional likelihood for a random sample of I individuals is given by the continuous mixture</p><formula xml:id="formula_12">I L ‫ס‬ • • • L (l (u), R (u))h(u)du (9) ͟ i i i Ύ Ύ Ύ i‫1ס‬</formula><p>where h(u) is the continuous population distribution that captures the heterogeneity in the parameters for the individuals. The unconditional likelihood L given in Equation ( <ref type="formula">9</ref>) is a function of the parameters</p><formula xml:id="formula_13">u ‫ס‬ {␣ x , ␣ y , K x , K y , q, R, D, a x , b x , a y , b y , ,<label>⌼</label></formula><p>, W} and cannot be written in closed form, making maximum likelihood estimation extremely difficult. We therefore use a simulation-based Bayesian approach that uses MCMC methods to estimate the parameters. Bayesian inference requires the specification of priors for the model parameters. Let K ‫ס‬ , ␣ ‫ס‬</p><formula xml:id="formula_14">K O x ( ) O K y H i ‫ס‬ , a ‫ס‬ and b ‫ס‬ . The un- ␣ H O ␣ b x i x x x ( ), (<label>) ( ), ( )</label></formula><formula xml:id="formula_15">␣ O H ␣ b y i y y y</formula><p>known parameters for the model are then given by u ‫ס‬ {␣, K, q, R, D, a, b, , ⌼, W}. <ref type="bibr" target="#b16">Lee (1981)</ref> and Arminger and Muthén (1998) discuss different forms of prior distributions for factor analysis and covariance structure models. Appendix 1 describes the prior distributions over the parameters in our model. Inference in the Bayesian framework is based on the joint posterior of all unknowns. Because this posterior density is very complex, we use simulation-based methods to obtain random draws from the posterior density (see Appendices 1 and 2 for details). Inference can then be based on the empirical distribution of the draws. The complexity of the posterior density precludes the use of direct methods for obtaining these draws. We therefore use Markov Chain Monte Carlo (MCMC) methods to obtain these draws. Specifically, our MCMC procedure involves Gibbs sampling <ref type="bibr" target="#b8">(Geman and</ref><ref type="bibr">Geman 1984, Gelfand and</ref><ref type="bibr">Smith 1990)</ref> and <ref type="bibr">Metropolis-Hastings (Metropolis et al. 1953</ref><ref type="bibr" target="#b10">, Hastings 1970</ref><ref type="bibr" target="#b5">, Chib and Greenberg 1995</ref> steps in tandem with data augmentation <ref type="bibr" target="#b26">(Tanner and Wong 1987)</ref> to obtain the requisite draws. The MCMC methods require sampling parameter estimates from the full conditional distribution of each block of parameters. In the context of our model, we need to generate random draws for the blocks {␣, K, {n ij }, {g ij }, { i }, U i , q, R, D, H i , {a k }, {b k }, p i , , ⌼, W}. Each iteration of the MCMC procedure involves sequentially sampling from the full conditional distributions associated with each block of parameters. The MCMC procedure also provides samples of the factor scores f ij ‫ס‬ {n ij , g ij } and i , thus enabling posterior inference about these quantities. Appendix 2 describes the full conditional distributions and the simulation steps involved in each iteration of the MCMC procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Synthetic Data Application</head><p>In this section we demonstrate our estimation procedures on artificial data. The aim is to illustrate the types of misleading inferences that are possible when models that ignore heterogeneity are applied to heterogeneous data. We generated a data set with 200 individuals and 30 observations per individual according to the model described in Equations ( <ref type="formula">4</ref>) and (5). The data set includes four exogenous variables (x 1 , . . . , x 4 ) and four endogenous variables (y 1 , . . . , y 4 ). The association among the manifest variables is modeled in terms of two exogenous factors (n 1 and n 2 ) and two endogenous factors (g 1 and g 2 ). Figure <ref type="figure" target="#fig_1">2</ref> shows the model structure. We set</p><formula xml:id="formula_16">1 0.8 0 0 KЈ ‫ס‬ KЈ ‫ס‬ , (<label>10</label></formula><formula xml:id="formula_17">)</formula><formula xml:id="formula_18">x y 0 0 0.8 1.0 1 ‫3.0מ‬ 0.6 0.4 E[U ] ‫ס‬ , D ‫ס‬ , (<label>11</label></formula><formula xml:id="formula_19">) i ‫3.0מ‬ 1 0.4 0.6 and E[H i,x ] ‫ס‬ E[H i, y ] ‫ס‬ diag(1.0)</formula><p>for the measurement model. For the structural model, we used a population distribution, p i ϳ N(, ⌼) for the individual level structural coefficients in  We used SAS and our MCMC procedures to estimate two models on the data. The first model (NH) is a nonhierarchical model that ignores the nature of the clustering of the observations and assumes that each individual has the same set of parameters. We estimated this model using Proc Calis in the SAS software. The second model is the true model represented by Equations ( <ref type="formula">4</ref>) and (5). In estimating the second model we used priors that are similar to those outlined in Appendix 1. The estimates for the second model are based on 3,000 draws from the joint posterior distribution obtained after discarding 1,000 draws from the initial transient portion of the chain. Convergence was assessed using a variety of diagnostics detailed in the CODA package <ref type="bibr" target="#b3">(Best et al. 1995)</ref> and by using time series plots to graphically assess the quality of the mixing of the chain.</p><formula xml:id="formula_20">g ‫ס‬ b g ‫ם‬ c ‫ם‬ c n ‫ם‬ f , 1 i 2 i1 i3 1 1 g ‫ס‬ c ‫ם‬ c n ‫ם‬ f , (<label>12</label></formula><formula xml:id="formula_21">) 2 i 2 i4 2 2</formula><formula xml:id="formula_22">b i ] ‫ס‬ ‫,5.0מ‬ E[c i 1 ] ‫ס‬ 0, E[c i 2 ] ‫ס‬ 0, E[c i 3 ] ‫ס‬ ‫,2מ‬ E[c i4 ] ‫ס‬ 2}</formula><p>Table <ref type="table" target="#tab_2">1</ref> reports the within-factor covariance matrix U for the first model and the population expectation of the U i matrices, E(U i ) for the fully heterogenous model <ref type="bibr">(FH)</ref>. It also reports the across-individual covariance matrix D of the mean factor scores i for Model FH. In §2.1, we showed that ignoring heterogeneity in factor means and measurement error leads to an aggregate factor covariance matrix U Agg that confounds the within-individual U and betweenindividual D factor covariance matrices. We also showed that this confound can lead to sign reversal of the factor covariances under some conditions. A comparison of the factor covariance estimates from the nonhierarchical model (NH) with the sum of the estimated within-and between-factor covariance matrices from the fully heterogeneous model (FH) clearly confirms this theoretical relationship. For example, U 11 from NH is 1.61. This value is approximately equal to the sum of U 11 ‫ס‬ 1.0 and D 11 ‫ס‬ 0.58 obtained from FH. Most importantly, we see that the covariance estimate U 12 from NH has the wrong sign because of this confounding. Finally, note that the estimates from the correct model (FH) are close to the true values as expected. Similarly, the estimates of D obtained from Model (FH) are close to the true values.</p><p>Table <ref type="table" target="#tab_3">2</ref> reports the structural model parameters. The top portion of the table reports the structural coefficients for the nonhierarchical model and the population expectation of the individual-level coefficients for   the hierarchical model. Whereas the magnitudes of the coefficients are approximately the same for the two models, the confidence interval for b for Model NH does not cover the true value. A comparison of the error variances across the two models reveals that the aggregate model provides inflated estimates of the error variances. This result is not surprising because the aggregate model (NH) forces the error terms to absorb the unobserved heterogeneity in the parameters. <ref type="bibr" target="#b12">Jedidi et al. (1997)</ref> found the same results, based on an extensive simulation. Specifically, they found that the aggregate model captures the population means of the structural parameters very well but confounds the variance due to heterogeneity with the error variance.</p><p>Table <ref type="table" target="#tab_4">3</ref> reports the estimated factor loadings and the measurement error variances for the two models. The table also shows the 95% posterior intervals associated with the parameters. It is clear from the table that both models yield almost identical estimates of the factor loadings. This is not surprising, as the data-generating mechanism assumed identical K for all individuals. Comparing the estimated measurement error variances H for the NH model and the population expectation of H i for the FH model, we see that the magnitude of the estimates are similar. A closer look at the variance estimates associated with x 1 and x 2 reveals that the confidence intervals for the first model do not cover the true value of 1.0. The posterior intervals for the full model (FH) are wider, as they properly reflect the uncertainty arising from heterogeneity and cover the true value for all parameters.</p><p>In summary, it is clear from the above example that ignoring heterogeneity can yield misleading inferences. In fact, we see that aggregate models may have wrong signs for covariance parameters, thus providing a distorted picture of the association structure of variables. In addition, aggregate models may report inflated estimates of factor variances, thus overstating the reliability of factors. Finally, models that pool data across individuals and thus ignore heterogeneity may underappreciate uncertainty in parameter estimates and provide a false sense of precision.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">A Customer Satisfaction Application</head><p>Many researchers have analyzed the antecedents of customer satisfaction (see Oliver 1997 for a review).</p><p>Typically, researchers have postulated that overall customer satisfaction with a product or service is affected by its perceived performance and by the extent to which a customer's expectations are met or disconfirmed (e.g., <ref type="bibr" target="#b22">Oliver 1993 and</ref><ref type="bibr" target="#b13">Johnson et al. 1995)</ref>.</p><p>We used the hierarchical Bayesian approach to estimate a structural equation model of satisfaction, using panel data from a study on campus dining services conducted at a large northeastern university. The data were collected using the following procedure. The population of interest consisted of students who had purchased all-inclusive meal plans for the fall semester. At the beginning of the semester during registration week, subjects from the population were recruited, using sign-up sheets circulated by experimenters in booths set up in dining outlets and dormitories at the university. Sixty individuals signed up to attend an information session; of these, 55 agreed to participate in the panel. Each subject who participated in the study was paid $50 and was required to complete a daily diary for 39 consecutive days, using the following procedure. As soon as possible after dinner every day, subjects were required to record their degree of satisfaction with the dining service and their perception of the service provider's performance along key dimensions, including food, service, and the dining environment. Subjects also recorded their expectancy disconfirmation, i.e., the degree to which their expectations of performance were met or disconfirmed. All the observable variables (items) were measured using seven-point scales. We excluded two subjects from the analysis because of limited data for those individuals. Because of missing data for some subjects, our final data set contains 1,542 observations from the remaining 53 subjects. We have therefore, an average of 29 observations per subject.</p><p>We specified a model in which customers' satisfaction (g) with the dining service depends on perception of the dining service's performance on food (n 1 ), service (n 2 ), and the dining environment (n 3 ). In addition, satisfaction depends on disconfirmation (n 4 ). Satisfaction for each service episode was measured using the following three items: very dissatisfied to very satisfied (y 1 ); felt terrible to delighted (y 2 ); liked very little to liked very much (y 3 ). Food performance was measured using the following three observable indicators: unpalatable to palatable (x 1 ), bad taste to good taste (x 2 ), and not nutritious to nutritious (x 3 ). Service performance was measured on four items: indifferent to responsive (x 4 ), unfriendly to friendly (x 5 ), inefficient to efficient (x 6 ), and uncaring to caring (x 7 ). Dining environment was measured using three items: unpleasant to pleasant (x 8 ), dirty to clean (x 9 ), and stressful to relaxing (x 10 ). Finally, disconfirmation was measured using two items: much better than expected to much worse than expected (x 11 and x 12 ). Figure <ref type="figure">3</ref> presents a graphical summary of the structure of the satisfaction model. Note that to avoid clutter, Figure <ref type="figure">3</ref> does not show the covariances among the factors.</p><p>As discussed in §2, the data can contain several forms of heterogeneity. For example, in the measurement model, the factor means i , the factor covariances, U i , and the measurement error variances H i can differ across individuals. In the structural model, the structural coefficients (i.e., importance weights of the antecedents of satisfaction) c i can differ across respondents.</p><p>To understand the nature of heterogeneity in the customer satisfaction process, we specified and estimated six models. These model specifications are described in the table below. The base model, Model NH, is the conventional structural equation model that assumes that the data do not contain any measurement or structural heterogeneity. The other models add increasing levels of heterogeneity. Model FH, for instance, allows heterogeneity in factor means, factor covariances, measurement error variances, and structural coefficients and, therefore, is the most general model. In estimating the models, we imposed appropriate restrictions on parameters to accommodate the indeterminacy in the scales and origins of the factors. For example, in all the models, for each factor we set the loading of one indicator variable to unity. In addition, following the usual practice in structural equation modeling, we set the mean of each factor to zero for Model NH. In contrast, for the other models, we assume that the factor means i vary across individuals with a grand mean E( i ) ‫ס‬ 0. As discussed earlier, we also set the population mean of the structural intercept to zero, i.e., E(c i 0 ) ‫ס‬ 0. Note that the measurement parameters in the models are identified because each factor has at least two indicators and the factors are allowed to covary (see <ref type="bibr">Bollen 1989, pp. 238-251)</ref>. The structural parameters are also identified, because the structural model is a multiple regression equation.</p><p>We used the MCMC procedure described in § 3 and in Appendix 2 to estimate the models. The MCMC algorithm was coded using the C language. Furthermore, we estimated Model NH, using Proc Calis in SAS to compare our Bayesian estimates with those obtained from the maximum likelihood estimator (MLE). Appendix 1 reports the prior distributions we used. The parameter estimates for all models are based on 20,000 draws obtained after discarding the first 10,000 iterations. Convergence was assessed using a variety of diagnostics detailed in the CODA package <ref type="bibr" target="#b3">(Best et al. 1995)</ref> and by using time series plots to graphically assess the quality of the mixing of the chain.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Model Assessment</head><p>In this section we compare model performance using marginal likelihood values computed from the simulation output. We also compute the out-of-sample performance on a holdout data set to assess whether accounting for unobserved heterogeneity leads to improvements in predictive ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.1.">Model Comparison.</head><p>We computed the logmarginal likelihood using the importance sampling method illustrated in <ref type="bibr" target="#b21">Newton and Raftery (1994)</ref> to compare the six models. A model with a higher marginal likelihood is the preferred model. The differences in the marginal likelihood values from those of a base model (Model NH) can be used to assess model improvements. The differences in log-marginal likelihood for the models are (a) Model ML: 103.51, (b) Model HS: 146.6, (c) Model HSHC: 248.69, (d) Model HSHV: 1603.15, and (e) Model FH: 1741.2. These values clearly suggest that accounting for unobserved heterogeneity is important in this application. Among all the models that account for some form of heterogeneity,  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2.">Predictive Ability.</head><p>To further assess the benefits of accounting for unobserved heterogeneity, we compared the predictive ability of the conventional structural equation model (Model NH) with that of the full model (Model FH). To compute the out-of-sample performance, we created a holdout data set consisting of 427 observations from our original calibration sample. This data set was created by randomly selecting approximately 8 observations from each of the 53 subjects in the sample. We estimated the NH and FH models, using the remaining 1,115 observations and used these estimates to compute measures of predictive performance from the holdout data set. We assessed how well the models perform in recovering the mean and covariance structure of the data set. Table <ref type="table" target="#tab_6">4</ref> reports the Mean Absolute Deviations (MAD) in predicting the means of the exogenous and endogenous manifest variables. It is clear from the table that the model that incorporates heterogeneity outperforms the aggregate model in predicting the means across all of the manifest variables.</p><p>As structural equation models capture the covariance structure of the variables, we also investigated how well the two models did in recovering the withinindividual covariance matrix R W , the betweenindividual R B covariance matrix, and the total R T covariance matrix of the data. Table <ref type="table" target="#tab_7">5</ref> reports two measures of fit (MAD and RMR) for these covariance matrices. The MAD represents the mean absolute deviation between the elements of the actual and the predicted matrices. The RMR <ref type="bibr" target="#b4">(Bollen 1989)</ref> represents the square root of the mean squared deviation between the elements of actual and predicted matrices. In computing these measures, only the nonredundant elements of the covariance matrices are used. Table <ref type="table" target="#tab_7">5</ref> shows that the hierarchical model clearly outperforms the simple model in recovering both the within-and betweencovariance matrices. It is also interesting to note that the two models do not differ in their ability to recover the total covariance matrix. This result is consistent with the insight that aggregate models do well in recovering the aggregate aspects of a data set but do poorly in representing the association structure at the microlevel. This result is also consistent with the simulation results of <ref type="bibr" target="#b12">Jedidi et al. (1997)</ref>, who found that fit measures that are based on the aggregate covariance matrix (e.g., GFI and RMR) are not useful for detecting heterogeneity.</p><p>In summary, the marginal likelihood values and the predictive comparisons unambiguously suggest the importance of accounting for both mean and covariance heterogeneity in the satisfaction data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Parameter Estimates</head><p>We now examine the parameter estimates from our models. These estimates are based on the entire calibration sample consisting of 1,542 observations from 53 individuals. To avoid clutter, we report the estimates for only three models. These models include the simple nonhierarchical model (Model NH), the multilevel model (Model ML), and the full model (Model FH). For the NH model, we report both the Bayesian and the maximum likelihood (MLE) estimates that we obtained using SAS Proc Calis. We first discuss the results from the measurement model and then analyze the structural model estimates. Table <ref type="table" target="#tab_8">6</ref> shows the factor loadings from the measurement model. The MLE factor loadings for Model NH, reported in Column 3, are virtually identical to those obtained from the Bayesian analysis of the model (see Column 4). The similarity of the estimates is expected, because we used diffuse priors and our sample size is large (1,542 observations). It is also clear from Table <ref type="table" target="#tab_8">6</ref> that the loading estimates differ only slightly across all three models. This finding is not surprising, because we assumed common factor loadings for all individuals. Overall, all factor loadings are significant, suggesting that the indicators are reliable measures for the underlying factors.</p><p>Table <ref type="table" target="#tab_9">7</ref> reports the measurement error variances. First, as in Table <ref type="table" target="#tab_8">6</ref>, the maximum likelihood estimates (MLE) of Model NH are almost identical to those obtained from the Bayesian analysis. Second, the estimates from Model NH and Model ML are essentially similar, as both of these models assume identical measurement error variances across individuals. The population mean estimates from Model FH, however, show considerable differences from the estimates obtained for Models NH and ML. In addition, it is important to note that the standard deviation of the population means are much higher for Model FH, as should be expected in a model that incorporates heterogeneity. Thus, conventional models can provide distortions in inference when applied to heterogeneous data. Finally, the last column of Table <ref type="table" target="#tab_9">7</ref> reports the across-individual variation, Std(h i ), in the measurement error variances. 1 Clearly, there is considerable heterogeneity in the measurement error variances in our sample. That is, subjects respond to questions with different degrees of accuracy.  </p><formula xml:id="formula_23">1 As h ik ϳ IG(a, b k ), E(h ik ) ‫ס‬ 1/(b k (a ‫מ‬ 1)) and Std(h ik ) ‫ס‬ . 2 2 1/(b (a ‫מ‬ 1) (a ‫מ‬ 2)) Ί k</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>U i W(q, R). Column 5 of Table 8 reports the population means of the</head><p>. The last column of the table reports UЈs i the estimated D, which captures the heterogeneity in mean factor scores ( i ) across individuals. When Model NH is used to analyze data originating from a process that involves general forms of measurement and structural heterogeneity (e.g., as in Model FH), the estimation bias manifests itself in a complex manner across different sets of parameters. The results show that the parameter estimates are indeed different across the three models.</p><p>Focusing on the estimates for U for Model FH, we see that all the exogenous factors are positively correlated. The estimates of D show that the mean factor scores are also positively correlated across individuals. In addition, the large magnitudes of the diagonal elements of D show that there is considerable heterogeneity in factor means across individuals.</p><p>Table <ref type="table" target="#tab_12">9</ref> reports the regression coefficients from the structural model. In interpreting the table, recall that Model FH captures heterogeneity in the impact of the antecedent constructs on satisfaction by assuming that the individual-specific coefficients come from a multivariate normal population distribution N(, ⌼). The population mean, , for the structural coefficients and the standard deviation of the individual specific coefficients are reported in Columns 5 and 6, respec-⌼ Ί kk  tively, of the table. The mean estimates for Model FH show that satisfaction is significantly affected by perceived performance on food, service, and the environment. In addition, the positive coefficient for disconfirmation confirms the previous findings in the literature that better-than-expected performance increases satisfaction. The magnitudes of the acrossindividual standard deviations (see the last column), are large and confirm that the importance weights of the antecedent dimensions on satisfaction vary significantly across subjects.</p><p>The differences in the magnitudes of the coefficients across the models show that ignoring heterogeneity can yield misleading inferences about the structural parameters. Furthermore, it appears that Model NH and Model ML seriously overstate statistical significance, because they understate the posterior standard deviations of all structural parameter estimates. In addition, the last row of Table <ref type="table" target="#tab_12">9</ref> shows that by failing to allow for structural heterogeneity, Models NH and ML understate the goodness-of-fit of the structural model. This result is not surprising, because the unaccounted heterogeneity is absorbed by the structural error term.</p><p>To illustrate how the model can be used for managerial purposes, we performed a "quadrant analysis" (see Figure <ref type="figure">4</ref>). For each antecedent of satisfaction, we plotted for each individual the mean factor scores (which are automatically produced by the Bayesian approach) and structural parameter estimates; in addition, we partitioned the appropriate space into four quadrants, based on the corresponding mean factor scores and mean importance weights in the sample. (Recall that the grand mean for each antecedent factor was set to zero.) Thus, in Figure <ref type="figure">4</ref>, individuals corresponding to points in the upper-right quadrant have above-average scores on the food factor; in addition, for these individuals, food has an above-average effect on overall satisfaction.</p><p>Using this partitioning into quadrants, managers selectively target consumers and develop marketing pol-</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4</head><p>Quadrant Analysis: Perceived Performance (Factor Scores) vs. Importance icies, including one-on-one marketing. Managers can target consumers based on both the importance weights of key dimensions and the levels of those dimensions (factor scores). For example, in Figure <ref type="figure">4</ref> consider the set of points in the upper-left quadrant for the panel associated with food. These points correspond to those consumers for whom food is important and, in addition, the food performance of the dining facility is below the average for the population. Consider Subject 9. This subject has below-average importance weights for food and service but has aboveaverage importance weights for environment and disconfirmation. Moreover, this customer has a belowaverage factor score on all factors. These results clearly show that Subject 9 is relatively unsatisfied with all components of the service. Depending on costs, the optimal policy for the dining facility for Subject 9 may be to improve his or her perception of environment. An alternative strategy that may be effective for the dining facility is to manage this customer's expectations to reduce the likelihood of these expectations being disconfirmed.</p><p>It is important to note that managers need to exercise caution in using individual-level point estimates for targeting. The extent of uncertainty associated with an individual's estimates depends intricately on the number of observations available from that individual and also on the extent of shrinkage induced by the choice of priors. In fact, Bayesian methods allow a proper assessment of uncertainty. For example, the figure shows the 95% confidence ellipsoids associated with Individual 9. The figure shows that there is considerable uncertainty about the individual-level parameters. This is not surprising, as a highly parametrized model is being fitted to relatively few observations from a person. The confidence ellipsoids also show that the uncertainty is higher for the importance weights when compared to the uncertainty in the perceptual scores. This is possible because the importance weights link two sets of latent variables (i.e., factor scores) and are therefore farther removed from the observed data. Such assessments need to be used for sensitivity analysis in decision making.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Summary and Conclusions</head><p>This paper develops and tests a hierarchical Bayesian framework for handling general forms of unobserved heterogeneity in structural equation models. Our methodology is appropriate when the heterogeneity in the population can be measured on a continuum and multiple observations are available for each individual. An important feature of our method is that it automatically provides individual-specific estimates of model parameters and factor scores.</p><p>We tested the Bayesian methodology, using both synthetic data and data from a satisfaction study. The results from the synthetic data application show that the nonheterogeneous (aggregate) model confounds random variability (i.e., measurement and structural errors) with variability because of heterogeneity. In the measurement model, this confounding led to inflated indicator reliabilities and resulted in sign reversal of the factor covariances. In the structural model, the confounding led to lower model fit. In addition, the nonheterogeneous model understated the standard errors of the measurement and structural parameter estimates.</p><p>The results from the satisfaction study show that the structural parameters vary significantly in the population (i.e., it is incorrect to analyze the pooled data set using a conventional structural equation model). As in the case of the synthetic data example, the estimates obtained from a conventional structural equation model (i.e., a model that does not allow for unobservable heterogeneity) were misleading, even though the model was comparable to the other models on prediction of aggregate quantities such as the total covariance matrix R T . In particular, the nonhierarchical model understated the goodness-of-fit for the structural equation and provided biased estimates of the structural parameters. Perhaps most importantly, the nonhierarchical model seriously understated the standard errors of the structural parameters; that is, models that ignore heterogeneity overstate statistical significance. Finally, we showed that the traditional psychometric methods (e.g., multilevel models) do not fully capture the heterogeneity in our data. Thus, accounting for heterogeneity in both mean and covariance structures is important for obtaining proper inferences.</p><p>From a managerial viewpoint, we showed how one can use the individual-level factor scores and structural parameter estimates from the Bayesian approach to perform quadrant analysis and refine marketing policy (e.g., develop a one-on-one marketing policy). From a substantive viewpoint, our Bayesian procedure should be applied to a broad range of marketing problems in which the data contain unobservable heterogeneity and structural equation modeling is appropriate (e.g., instances involving measurement error and latent constructs). From a methodological viewpoint, we designed our MCMC procedures to deal with the partially recursive structural model and assumed interval-scaled data. Future research should extend our procedures to deal with the general nonrecursive structural equation model and to accommodate ordinal data <ref type="bibr" target="#b23">(Rossi et al. 1999</ref>) and binary data situations <ref type="bibr" target="#b1">(Ansari and Jedidi 2000)</ref>. <ref type="bibr">2</ref> assumed to be multivariate normal N(j, A). The covariance matrix A can be specified to be diagonal with the elements (variances) set to large values to represent vague knowledge. The exact location of this distribution is no longer critical once, a large variance has been assumed; therefore, without a loss of generality j can be set to zero. For the application we used N(0, 100I), where I is an identity matrix with appropriate dimensionality.</p><p>The combined factor loading matrix K has a patterned structure owing to the identifiability restrictions that require setting some of the elements of K to zero or to one. We therefore specified independent multivariate normal priors over the free elements within each row of the matrix. We have for row k a prior N(g k , H k ). The covariance matrix H k is specified to be diagonal with large variances to ensure a diffuse prior. Thus, the prior over the loading matrix is the product of the independent priors associated with the rows of K. In the application, we specified the prior distribution for each row to be N(0, 100I).</p><p>The m ‫ן‬ m matrix R ‫1מ‬ associated with the Wishart population distribution, W(q, R), is assumed to come from conjugate Wishart prior W(q R , (q R S) <ref type="bibr">‫1מ‬</ref> ). Smaller values of q R correspond to more vague prior distributions. For the application, we used a prior of W(5, 5I). We assumed a univariate truncated normal N(0, s q ) prior over log(q). For the population Wishart distribution W(q, R) to be proper, the truncation must be such that q is greater than p. The prior variance, s q , can be set to a large value to ensure a diffuse prior. For the application we set s q ‫ס‬ 100. Alternatively, a truncated gamma prior can be used, and its parameters can be chosen appropriately to ensure minimal influence.</p><p>The precision matrix D ‫1מ‬ associated with the population distribution i ϳ N(0, D) is a p ‫ן‬ p positive definite matrix. In keeping with standard Bayesian analysis of linear models, we assumed a Wishart prior W(d, (dX) ‫1מ‬ ), where X ‫1מ‬ can be considered the expected prior precision of the i s. Smaller d values correspond to vaguer prior distributions. For the application we set d ‫ס‬ 5 and X ‫ס‬ I to ensure a proper prior.</p><p>There are r ‫ס‬ (p ‫ם‬ q) different population distributions IG(a k , b k ), k ‫ס‬ 1 to r, for the measurement error variances contained in H i . We therefore need to specify priors over the set of unknowns {{a k }, {b k }}. We chose independent conjugate inverse gamma priors, b k ϳ IG(g k , h k ), for k ‫ס‬ 1 to r, to quantify prior uncertainty about the scale parameters. In the application we assumed a k ‫ס‬ a and g k ‫ס‬ 2 and b k ‫ס‬ 2 for all k. Finally, we assumed independent univariate normal N(0, s k ) priors over log(a k ) for k ‫ס‬ 1 to r. The prior variance, s k , must be set to a large value to ensure a diffuse prior. In the application we set s k ‫ס‬ 100.</p><p>The prior for the vector is specified to be multivariate normal N(c, C). The covariance matrix C can be assumed to be diagonal and its entries chosen to represent vague knowledge. The exact location vector c is no longer critical once a large variance has been assumed; hence, without loss of generality we set c to zero. In the application we therefore set c ‫ס‬ 0 and C ‫ס‬ 100I.</p><p>We assumed a Wishart prior W(q t , (q t R t ) ‫1מ‬ ) over the precision matrix ⌼ ‫1מ‬ associated with the structural parameters p i . Smaller q t values correspond to vaguer prior distributions. We therefore set q t ‫ס‬ 5 and R t ‫ס‬ 0.1I. Finally, we assumed a Wishart prior W(q w , (q w R w ) ‫1מ‬ ) over the precision matrix W ‫1מ‬ of the structural model. If the structural model consists of a single equation, then an inverse gamma prior over the single structural error variance parameter can be assumed instead. In the application we chose IG(3, 1000) for the prior over the univariate w.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix 2: Full Conditional Distributions</head><p>The (m ‫ם‬ 1)th iteration of the MCMC algorithm requires us to generate random draws from the following full conditional distributions:</p><p>(a) The measurement intercepts ␣ are generated from the multivariate normal full conditional distribution given by</p><formula xml:id="formula_24">p(␣|K, {f }, {H }, {w }) ‫ס‬ N(␣, V ) (A.1) ij i ij ␣</formula><p>where ‫ס‬ A ‫1מ‬ ‫ם‬ and</p><formula xml:id="formula_25">‫ס‬ V ␣ [A ‫1מ‬ j ‫ם‬ ‫1מ‬ I ‫1מ‬ V ͚ N H␣ ␣ i‫1ס‬ i i (w ij ‫מ‬ Kf ij )]. I ‫1מ‬ N i ͚ H ͚ i‫1ס‬ i j ‫1ס‬</formula><p>(b) The loading matrix K is a patterned matrix containing both fixed and free elements. Of the fixed elements, some are fixed to zero, whereas others are fixed at one to impose identifiability constraints. The full conditional distribution for the free elements in a row of the matrix K is multivariate normal. Given the choice of the prior distributions, the full conditionals pertaining to the different rows are independent. Therefore, the rows can be handled sequentially. Let k k be the vector of free elements in row k. The prior for k k is given by p(k k ) ‫ס‬ N(g k , H k ). Let be the vector of factor scores correspondf ijk ing to the elements in row k of K that are set to one and let f ‫מ‬ijk contain the remaining factor scores from f ij . Form the adjusted variable w ijk ‫ס‬ w ijk ‫מ‬ iЈ ‫מ‬ ␣ k , where i is a vector of ones. Given thẽ f ijk prior, the vector k k can be sampled from the full conditional distribution given by</p><formula xml:id="formula_26">p(k |{w }, { f }, h ) k ijk ‫מ‬ijk i,k I N i ‫1מ‬ ‫1מ‬ ‫ס‬ N D h f w ‫ם‬ H g , D (A.2) k ͚ ͚ i,k ‫מ‬ijk ijk k k k ΄ ΅ i‫1ס‬ j‫1ס‬</formula><p>where .</p><formula xml:id="formula_27">‫1מ‬ I n ‫1מ‬ ‫1מ‬ i D ‫ס‬ ͚ ͚ h f fЈ ‫ם‬ H k i ‫1ס‬ j‫1ס‬ i,k ‫מ‬ijk ‫מ‬ijk k (c)</formula><p>The full conditional distribution for the factor scores n ij is a multivariate normal distribution. The mean and variance of this distribution can be obtained by considering the prior n ij ϳ N( i , U i ) and the two data sources for n ij . The first "data" we consider are g ij . Consider the structural equation Model,</p><formula xml:id="formula_28">B i g ij ‫ס‬ c i 0 ‫ם‬ C i n ij ‫ם‬ f ij . Define ‫ס‬ B i g ij ‫מ‬ c i 0 . An intermediate posterior distribution for g ij n ij can be written as V 1,g,i ), where ‫1מ‬ ‫1מ‬ ‫1מ‬ N(n , V ‫ס‬ U ‫ם‬ CЈ W C 1,ij 1,g,i i i i</formula><p>and . This intermediate posterior</p><formula xml:id="formula_29">‫1מ‬ ‫1מ‬ n ‫ס‬ V [U ‫ם‬ CЈWg ] 1,ij 1,g,i i i i ij</formula><p>acts as a prior for the other data source x ij . Taking into account the measurement equation, x ij ‫ס‬ ␣ x ‫ם‬ K x n ij ‫ם‬ d ij , the full conditional for n ij can be written as V g,i ), where</p><formula xml:id="formula_30">‫ם‬ ‫1מ‬ ‫1מ‬ N(n , V ‫ס‬ V ij g,i 1,g,i and ‫ס‬ V g,i ‫ם‬ (x ij ‫מ‬ ␣ x )]. ‫1מ‬ ‫1מ‬ ‫1מ‬K Ј H K n [V n KЈ H x i x x i j 1,g,i ij x i,x</formula><p>(d) The full conditional distribution for the individual-level factor means i is a multivariate normal distribution that can be written as p( |{n }, U , D) ‫ס‬ N( , V ), (A.3) ͚ j‫1ס‬ (f) The full conditional for the precision matrix D ‫1מ‬ of the factor means is a Wishart distribution. Given the prior W(d, (dX) ‫1מ‬ ), the full conditional can be written as</p><formula xml:id="formula_31">I ‫1מ‬ ‫1מ‬ p(D |{ }) ‫ס‬ W d ‫ם‬ I, Ј ‫ם‬ dX . (A.5) i ͚ i i ΄ ΅ i‫1ס‬ (g)</formula><p>The full conditional distributions for the diagonal elements of the measurement error variances H i for each individual, i.e., h i,k , k ‫ס‬ 1 to r, are independent inverse gamma distributions. These distributions follow from standard Bayesian theory and can be written as</p><formula xml:id="formula_32">p(h |k , ␣ , {f }) ‫ס‬ i,k k k ij N ‫1מ‬ i 2 (w ‫מ‬ ␣ ‫מ‬ kЈ f ) ͚ ijk k k ij N j‫1ס‬ i ‫1מ‬ IG ‫ם‬ a , ‫ם‬ b (A.6) ΄ ΅ k k 2 2</formula><p>where k k is a vector containing the elements of row k of K.</p><p>(h) The full conditional for the hyperparameter b k of the inverse gamma population distribution over the kth measurement error variance, h i,k , is also an inverse gamma distribution. Given the conjugate inverse gamma prior, IG(g k , h k ), the full conditional can be written as</p><formula xml:id="formula_33">I ‫1מ‬ ‫1מ‬ ‫1מ‬ p(b |{h }, a ) ‫ס‬ IG Ia ‫ם‬ g , h ‫ם‬ h (A.7) k i,k k k k k ͚ i,k ΄ ΅ i‫1ס‬</formula><p>Parameter draws can be sequentially made from the full conditional distributions of each b k , k ‫ס‬ 1 to r.</p><p>(i) The full conditional for the hyperparameter la k ‫ס‬ log(a k ) of the inverse gamma population distribution for the kth measurement error variance, h i,k , cannot be written in closed form. The likelihood of the "data" can be written as</p><formula xml:id="formula_34">I ‫1מ‬ exp(la ‫1ם)‬ ‫1מ‬ ‫1מ‬ k (h ) exp(‫מ‬b h ) i,k k i,k L({h }|la , b ) ‫ס‬ (A.8) i,k k k ͟ exp(la ) k C(exp(la ))b i‫1ס‬ k k</formula><p>The prior density of la k is univariate normal p(la k ) ‫ס‬ N(0, s k ). The full conditional is proportional to the product of the likelihood and the prior. We use a random-walk Metropolis-Hastings step to generate random draws of la k . To generate a candidate , we use a  </p><formula xml:id="formula_35">g i i0 i i i j y iy i . ␣ )] y (k)</formula><p>The full conditional for the structural parameters p i ‫ס‬ {B i , c i 0 , C i } associated with individual i is a multivariate normal distribution. For a recursive system of simultaneous equations, the structural model B i g ij ‫ס‬ c i,0 ‫ם‬ C i n ij ‫ם‬ f ij is a general triangular system (see <ref type="bibr">Zellner 1971, p. 252)</ref>. This system can be recast as g ij ‫ס‬ N ij p i ‫ם‬ f ij , where N ij is an appropriately dimensioned matrix containing both the exogenous and endogenous factor scores. The key feature of a triangular system is that the determinant of the matrix of the coefficients of the endogenous variables g vanishes. Thus we can treat the system g ij ‫ס‬ N ij p i ‫ם‬ f ij as a seemingly unrelated regression (SUR) system. Given the prior p(p i ) ‫ס‬ N(F i , ⌼), the full conditional is given by V p ), where and</p><formula xml:id="formula_36">‫1מ‬ ‫1מ‬ N ‫1מ‬ i N(p , V ‫ס‬ ⌼ ‫ם‬ ͚ NЈ W Np ‫ס‬ i p j‫1ס‬ ij ij i ‫1מ‬ N ‫1מ‬ i V [⌼ F ‫ם‬ ͚ NЈ W g ] p i j ‫1ס‬ ij ij ( l )</formula><p>The full conditional distribution for the precision matrix W ‫1מ‬ of the structural model is Wishart and is given by  (n) The full conditional for the precision matrix ⌼ ‫1מ‬ of the individual-level structural parameters p i is a Wishart distribution. Given the prior W( q t , (q t R t ) ‫1מ‬ ), the full conditional can be written as</p><formula xml:id="formula_37">‫1מ‬ p(⌼ |{p }) ‫ס‬ i I ‫1מ‬ W q ‫ם‬ I, (p ‫מ‬ Z )(p ‫מ‬ Z )Ј ‫ם‬ q R . (A.12) v ͚ i i i i v v ΄ ΅ i‫1ס‬ (o)</formula><p>The full conditional distribution for the hyperparameter R ‫1מ‬ is a Wishart distribution. The likelihood associated with this full conditional distribution is a product of Wishart distributions. As the population distribution for the factor precisions U i is given by ‫1מ‬ U i ϳ W(exp(qЈ), R), the likelihood can be written as ‫1מ‬ L({U }|qЈ, R) </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1Sources of Heterogeneity</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2</head><label>2</label><figDesc>Figure 2Model Structure for Synthetic Data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>and ⌼ ‫ס‬ diag(0.1). The structural errors f come from a normal distribution N(0,</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>of from iteration m. The tuning constant t a in the (m) la k proposal density is chosen to allow rapid mixing and to avoid excessively frequent rejections of the candidates. The generated candidate is accepted with the following acceptance probability |{h }, b )p(la ) |{h }, b )p(la ) k i,k k k</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>‫1מ‬ p(W |{n }, {g }, {c , C , B }) ‫ס‬ W(q , R ) (A.10)    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>as the elements of U Agg are necessarily larger than the</head><label></label><figDesc>corresponding elements in the population matrix E[U i ], factor reliability estimates based on U</figDesc><table><row><cell>)</cell></row><row><cell>Typically, researchers are interested in understand-</cell></row><row><cell>ing the within-individual factor covariance structure</cell></row><row><cell>represented in E[U i ]. It is clear from the above equation</cell></row><row><cell>that E[U i ] and D are not separately identifiable based</cell></row><row><cell>on the aggregate covariance matrix. Hence, an aggre-</cell></row><row><cell>gate model would generate U Agg ‫ס‬ E[U i ] ‫ם‬ D. Thus,</cell></row><row><cell>a conventional structural equation analysis on data</cell></row><row><cell>containing measurement heterogeneity can generate</cell></row><row><cell>two types of misleading inferences about the factor</cell></row><row><cell>structure. First,</cell></row></table><note>Agg will be inflated</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 1 Factor Covariance Matrices</head><label>1</label><figDesc></figDesc><table><row><cell>Parameter</cell><cell>True</cell><cell>NH</cell><cell>FH</cell></row><row><cell>U 11</cell><cell>1.0</cell><cell>1.61</cell><cell>1.0</cell></row><row><cell></cell><cell></cell><cell>(1.51, 1.70)</cell><cell>(0.92, 1.08)</cell></row><row><cell>U 12</cell><cell>‫3.0מ‬</cell><cell>0.13</cell><cell>‫82.0מ‬</cell></row><row><cell></cell><cell></cell><cell>(0.07, 0.18)</cell><cell>‫,33.0מ(‬ ‫)32.0מ‬</cell></row><row><cell>U 22</cell><cell>1.0</cell><cell>1.60</cell><cell>0.95</cell></row><row><cell></cell><cell></cell><cell>(1.51, 1.70)</cell><cell>(0.87, 1.04)</cell></row><row><cell>D 11</cell><cell>0.6</cell><cell>-</cell><cell>0.58</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(0.46, 0.72)</cell></row><row><cell>D 12</cell><cell>0.4</cell><cell>-</cell><cell>0.42</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(0.32, 0.54)</cell></row><row><cell>D 22</cell><cell>0.6</cell><cell>-</cell><cell>0.63</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(0.51, 0.78)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 Structural Model Parameters</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell cols="2">Population Regression Coefficients</cell><cell></cell></row><row><cell>Parameter</cell><cell>Actual</cell><cell>NH</cell><cell>FH</cell></row><row><cell>b</cell><cell>‫5.0מ‬</cell><cell>‫55.0מ‬</cell><cell>‫35.0מ‬</cell></row><row><cell></cell><cell></cell><cell>‫,75.0מ(‬ ‫)25.0מ‬</cell><cell>‫,95.0מ(‬ ‫)74.0מ‬</cell></row><row><cell>c 1</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>c 2</cell><cell>0</cell><cell>0</cell><cell>0</cell></row><row><cell>c 3</cell><cell>‫2מ‬</cell><cell>‫69.1מ‬</cell><cell>‫20.2מ‬</cell></row><row><cell></cell><cell></cell><cell>‫,20.2מ(‬ ‫)98.1מ‬</cell><cell>‫,11.2מ(‬ ‫)29.1מ‬</cell></row><row><cell>c 4</cell><cell>2</cell><cell>1.99</cell><cell>2.0</cell></row><row><cell></cell><cell></cell><cell>(1.92, 2.05)</cell><cell>(1.91, 2.09)</cell></row><row><cell></cell><cell></cell><cell>Error Variances</cell><cell></cell></row><row><cell>W 11</cell><cell>0.4</cell><cell>1.62</cell><cell>0.38</cell></row><row><cell></cell><cell></cell><cell>(1.43, 1.81)</cell><cell>(0.28, 0.5)</cell></row><row><cell>W 12</cell><cell>0.2</cell><cell>0.21</cell><cell>0.21</cell></row><row><cell></cell><cell></cell><cell>(0.10, 0.32)</cell><cell>(0.13, 0.26)</cell></row><row><cell>W 22</cell><cell>0.4</cell><cell>0.62</cell><cell>0.42</cell></row><row><cell></cell><cell></cell><cell>(0.44, 0.78)</cell><cell>(0.32, 0.53)</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 Measurement Model Parameters</head><label>3</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell cols="2">Factor Loadings</cell><cell cols="3">Measurement Error Variances</cell></row><row><cell cols="2">Parameter True</cell><cell>NH</cell><cell>FH</cell><cell>True</cell><cell>NH</cell><cell>FH E(H i )</cell></row><row><cell>y 1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1.0</cell><cell>1.02</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(0.89, 1.10)</cell><cell>(0.91, 1.12)</cell></row><row><cell>y 2</cell><cell>0.8</cell><cell>0.79</cell><cell>0.79</cell><cell>1</cell><cell>1.0</cell><cell>1.0</cell></row><row><cell></cell><cell></cell><cell>(0.78, 0.81)</cell><cell>(0.78, 0.81)</cell><cell></cell><cell>(0.93, 1.07)</cell><cell>(0.92, 1.08)</cell></row><row><cell>y 3</cell><cell>0.8</cell><cell>0.81</cell><cell>0.80</cell><cell>1</cell><cell>1.02</cell><cell>1.02</cell></row><row><cell></cell><cell></cell><cell>(0.79, 0.82)</cell><cell>(0.79, 0.82)</cell><cell></cell><cell>(0.96, 1.08)</cell><cell>(0.93, 1.1)</cell></row><row><cell>y 4</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0.97</cell><cell>0.97</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(0.88, 1.05)</cell><cell>(0.88, 1.07)</cell></row><row><cell>x 1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0.94</cell><cell>0.96</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(0.89, 0.99)</cell><cell>(0.88, 1.03)</cell></row><row><cell>x 2</cell><cell>0.8</cell><cell>0.80</cell><cell>0.80</cell><cell>1</cell><cell>0.93</cell><cell>0.95</cell></row><row><cell></cell><cell></cell><cell>(0.76, 0.82)</cell><cell>(0.77, 0.83)</cell><cell></cell><cell>(0.89, 0.97)</cell><cell>(0.89, 1.01)</cell></row><row><cell>x 3</cell><cell>0.8</cell><cell>0.79</cell><cell>0.80</cell><cell>1</cell><cell>1.05</cell><cell>1.04</cell></row><row><cell></cell><cell></cell><cell>(0.76, 0.82)</cell><cell>(0.77, 0.83)</cell><cell></cell><cell>(1.00, 1.09)</cell><cell>(0.98, 1.12)</cell></row><row><cell>x 4</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1.03</cell><cell>1.04</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(0.97, 1.08)</cell><cell>(0.97, 1.12)</cell></row></table><note>Note: All loadings equal to 1 are fixed for identification.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 Predictive Ability: MAD for Variable Means</head><label>4</label><figDesc></figDesc><table><row><cell>Factor</cell><cell>Indicator</cell><cell>Model NH</cell><cell>Model FH</cell></row><row><cell>Food</cell><cell>x 1</cell><cell>1.134</cell><cell>0.955</cell></row><row><cell></cell><cell>x 2</cell><cell>1.207</cell><cell>1.095</cell></row><row><cell></cell><cell>x 3</cell><cell>1.087</cell><cell>0.986</cell></row><row><cell>Service</cell><cell>x 4</cell><cell>0.959</cell><cell>0.912</cell></row><row><cell></cell><cell>x 5</cell><cell>0.968</cell><cell>0.910</cell></row><row><cell></cell><cell>x 6</cell><cell>1.033</cell><cell>0.953</cell></row><row><cell></cell><cell>x 7</cell><cell>1.063</cell><cell>0.952</cell></row><row><cell>Envir.</cell><cell>x 8</cell><cell>1.096</cell><cell>1.018</cell></row><row><cell></cell><cell>x 9</cell><cell>1.127</cell><cell>0.964</cell></row><row><cell></cell><cell>x 10</cell><cell>1.121</cell><cell>0.968</cell></row><row><cell>Disc.</cell><cell>x 11</cell><cell>1.193</cell><cell>1.114</cell></row><row><cell></cell><cell>x 12</cell><cell>1.317</cell><cell>1.248</cell></row><row><cell>Satis.</cell><cell>y 1</cell><cell>1.176</cell><cell>1.097</cell></row><row><cell></cell><cell>y 2</cell><cell>1.147</cell><cell>1.044</cell></row><row><cell></cell><cell>y 3</cell><cell>1.146</cell><cell>1.036</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell cols="4">Predictive Ability: Covariance Matrices</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Model NH</cell><cell></cell><cell></cell><cell>Model FH</cell><cell></cell></row><row><cell>Measure</cell><cell>R W</cell><cell>R B</cell><cell>R T</cell><cell>R W</cell><cell>R B</cell><cell>R T</cell></row><row><cell>RMR</cell><cell>0.379</cell><cell>0.367</cell><cell>0.138</cell><cell>0.153</cell><cell>0.135</cell><cell>0.138</cell></row><row><cell>MAD</cell><cell>0.361</cell><cell>0.356</cell><cell>0.107</cell><cell>0.135</cell><cell>0.118</cell><cell>0.107</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 Measurement Model Results: Factor Loadings</head><label>6</label><figDesc></figDesc><table><row><cell cols="6">Factor Indicator Model NH (MLE) Model NH (Bayes) Model ML Model FH</cell></row><row><cell>Food</cell><cell>x 1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell>x 2</cell><cell>1.106</cell><cell>1.109</cell><cell>1.067</cell><cell>1.053</cell></row><row><cell></cell><cell></cell><cell>(0.023)</cell><cell>(0.023)</cell><cell>(0.023)</cell><cell>(0.018)</cell></row><row><cell></cell><cell>x 3</cell><cell>0.717</cell><cell>0.719</cell><cell>0.723</cell><cell>0.711</cell></row><row><cell></cell><cell></cell><cell>(0.026)</cell><cell>(0.026)</cell><cell>(0.026)</cell><cell>(0.024)</cell></row><row><cell>Service</cell><cell>x 4</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell>x 5</cell><cell>1.028</cell><cell>1.028</cell><cell>1.031</cell><cell>1.021</cell></row><row><cell></cell><cell></cell><cell>(0.025)</cell><cell>(0.024)</cell><cell>(0.025)</cell><cell>(0.019)</cell></row><row><cell></cell><cell>x 6</cell><cell>0.994</cell><cell>0.996</cell><cell>1.009</cell><cell>0.953</cell></row><row><cell></cell><cell></cell><cell>(0.028)</cell><cell>(0.029)</cell><cell>(0.030)</cell><cell>(0.025)</cell></row><row><cell></cell><cell>x 7</cell><cell>1.015</cell><cell>1.016</cell><cell>1.027</cell><cell>0.995</cell></row><row><cell></cell><cell></cell><cell>(0.027)</cell><cell>(0.028)</cell><cell>(0.028)</cell><cell>(0.023)</cell></row><row><cell>Envir.</cell><cell>x 8</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell>x 9</cell><cell>1.220</cell><cell>1.216</cell><cell>1.234</cell><cell>1.120</cell></row><row><cell></cell><cell></cell><cell>(0.029)</cell><cell>(0.030)</cell><cell>(0.029)</cell><cell>(0.027)</cell></row><row><cell></cell><cell>x 10</cell><cell>1.016</cell><cell>1.018</cell><cell>1.027</cell><cell>1.040</cell></row><row><cell></cell><cell></cell><cell>(0.029)</cell><cell>(0.029)</cell><cell>(0.029)</cell><cell>(0.027)</cell></row><row><cell>Disc.</cell><cell>x 11</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell>x 12</cell><cell>0.984</cell><cell>0.984</cell><cell>0.987</cell><cell>0.982</cell></row><row><cell></cell><cell></cell><cell>(0.024)</cell><cell>(0.024)</cell><cell>(0.024)</cell><cell>(0.023)</cell></row><row><cell>Satis.</cell><cell>y 1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell></cell><cell>y 2</cell><cell>1.038</cell><cell>1.040</cell><cell>1.042</cell><cell>1.020</cell></row><row><cell></cell><cell></cell><cell>(0.019)</cell><cell>(0.019)</cell><cell>(0.019)</cell><cell>(0.016)</cell></row><row><cell></cell><cell>y 3</cell><cell>1.080</cell><cell>1.082</cell><cell>1.083</cell><cell>1.046</cell></row><row><cell></cell><cell></cell><cell>(0.019)</cell><cell>(0.019)</cell><cell>(0.019)</cell><cell>(0.016)</cell></row></table><note>Note: Posterior standard deviations are shown in parentheses.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 7 Measurement Model Results: Measurement Error Variances</head><label>7</label><figDesc>Posterior standard deviations are shown in parentheses. E(h i ) and Std(h i ) denote the population and standard deviation of the measurement variances.</figDesc><table><row><cell>Model FH</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 8</head><label>8</label><figDesc>reports the estimated covariance matrix U of the exogenous factors, n ij , for Models NH and ML and the population expectation of the U i matrices, E(U i ), for Model FH. For Models ML and FH, the table also reports the covariance matrix D of mean factor scores i across individuals. As in the previous tables, the MLE estimates are very similar to those obtained from the Bayesian analysis of Model NH. Recall that the multilevel model (Model ML) only captures heterogeneity in the factor means, i . As we saw in the previous synthetic data application, ignoring heterogeneity in means results in a confounding of the withinand between-covariance matrices of the factors, i.e., U ModelNH ‫ס‬ U ModelML ‫ם‬ D ModelML .</figDesc><table><row><cell>The results for Model</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 8 Estimated Covariance Structure of Antecedent Factors U D</head><label>8</label><figDesc>Posterior standard deviations are in parentheses. U ‫ס‬ Unduplicated elements in covariance matrix of exogenous factors. D ‫ס‬ Unduplicated elements in covariance matrix of mean factor scores for exogenous factors.</figDesc><table><row><cell></cell><cell>Model NH</cell><cell>Model NH</cell><cell>Model</cell><cell>Model</cell><cell>Model</cell><cell>Model</cell></row><row><cell>Parameter</cell><cell>(MLE)</cell><cell>(Bayes)</cell><cell>ML</cell><cell>FH</cell><cell>ML</cell><cell>FH</cell></row><row><cell>Food-Food</cell><cell>1.569</cell><cell>1.562</cell><cell>1.165</cell><cell>1.388</cell><cell>0.426</cell><cell>0.433</cell></row><row><cell></cell><cell>(0.074)</cell><cell>(0.074)</cell><cell>(0.055)</cell><cell>(0.155)</cell><cell>(0.093)</cell><cell>(0.095)</cell></row><row><cell>Food-Service</cell><cell>0.617</cell><cell>0.618</cell><cell>0.399</cell><cell>0.416</cell><cell>0.216</cell><cell>0.224</cell></row><row><cell></cell><cell>(0.043)</cell><cell>(0.043)</cell><cell>(0.032)</cell><cell>(0.083)</cell><cell>(0.063)</cell><cell>(0.067)</cell></row><row><cell>Food-Envir.</cell><cell>0.764</cell><cell>0.765</cell><cell>0.414</cell><cell>0.457</cell><cell>0.331</cell><cell>0.343</cell></row><row><cell></cell><cell>(0.048)</cell><cell>(0.047)</cell><cell>(0.032)</cell><cell>(0.079)</cell><cell>(0.080)</cell><cell>(0.085)</cell></row><row><cell>Food-Disc.</cell><cell>1.232</cell><cell>1.230</cell><cell>0.997</cell><cell>1.296</cell><cell>0.229</cell><cell>0.230</cell></row><row><cell></cell><cell>(0.061)</cell><cell>(0.061)</cell><cell>(0.050)</cell><cell>(0.159)</cell><cell>(0.062)</cell><cell>(0.063)</cell></row><row><cell>Service-Service</cell><cell>1.170</cell><cell>1.170</cell><cell>0.881</cell><cell>1.131</cell><cell>0.285</cell><cell>0.305</cell></row><row><cell></cell><cell>(0.059)</cell><cell>(0.060)</cell><cell>(0.046)</cell><cell>(0.131)</cell><cell>(0.064)</cell><cell>(0.070)</cell></row><row><cell>Service-Envir.</cell><cell>0.691</cell><cell>0.694</cell><cell>0.409</cell><cell>0.417</cell><cell>0.266</cell><cell>0.289</cell></row><row><cell></cell><cell>(0.042)</cell><cell>(0.044)</cell><cell>(0.029)</cell><cell>(0.073)</cell><cell>(0.066)</cell><cell>(0.072)</cell></row><row><cell>Service-Disc.</cell><cell>0.602</cell><cell>0.603</cell><cell>0.428</cell><cell>0.457</cell><cell>0.161</cell><cell>0.173</cell></row><row><cell></cell><cell>(0.046)</cell><cell>(0.046)</cell><cell>(0.037)</cell><cell>(0.099)</cell><cell>(0.049)</cell><cell>(0.051)</cell></row><row><cell>Envir.-Envir.</cell><cell>1.297</cell><cell>1.297</cell><cell>0.852</cell><cell>0.963</cell><cell>0.426</cell><cell>0.453</cell></row><row><cell></cell><cell>(0.070)</cell><cell>(0.070)</cell><cell>(0.046)</cell><cell>(0.113)</cell><cell>(0.093)</cell><cell>(0.100)</cell></row><row><cell>Envir.-Disc.</cell><cell>0.704</cell><cell>0.707</cell><cell>0.462</cell><cell>0.596</cell><cell>0.218</cell><cell>0.234</cell></row><row><cell></cell><cell>(0.050)</cell><cell>(0.050)</cell><cell>(0.038)</cell><cell>(0.101)</cell><cell>(0.059)</cell><cell>(0.063)</cell></row><row><cell>Disc.-Disc.</cell><cell>1.801</cell><cell>1.799</cell><cell>1.534</cell><cell>2.143</cell><cell>0.231</cell><cell>0.222</cell></row><row><cell></cell><cell>(0.087)</cell><cell>(0.087)</cell><cell>(0.079)</cell><cell>(0.252)</cell><cell>(0.056)</cell><cell>(0.054)</cell></row><row><cell>Notes:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 9 Structural Model: Regression Coefficients</head><label>9</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Model FH</cell></row><row><cell>Exogenous</cell><cell>Model NH</cell><cell>Model NH</cell><cell>Model</cell><cell></cell><cell></cell></row><row><cell>Factor</cell><cell>(MLE)</cell><cell>(Bayes)</cell><cell>ML</cell><cell></cell><cell></cell><cell>⌼ Ί kk</cell></row><row><cell>Food</cell><cell>0.311</cell><cell>0.311</cell><cell>0.258</cell><cell></cell><cell>0.366</cell><cell>0.236</cell></row><row><cell></cell><cell>(0.027)</cell><cell>(0.028)</cell><cell cols="2">(0.028)</cell><cell>(0.052)</cell><cell>(0.031)</cell></row><row><cell>Service</cell><cell>0.108</cell><cell>0.108</cell><cell>0.110</cell><cell></cell><cell>0.079</cell><cell>0.260</cell></row><row><cell></cell><cell>(0.022)</cell><cell>(0.023)</cell><cell cols="2">(0.022)</cell><cell>(0.039)</cell><cell>(0.040)</cell></row><row><cell>Envir.</cell><cell>0.058</cell><cell>0.057</cell><cell>0.053</cell><cell></cell><cell>0.094</cell><cell>0.206</cell></row><row><cell></cell><cell>(0.022)</cell><cell>(0.023)</cell><cell cols="2">(0.021)</cell><cell>(0.041)</cell><cell>(0.028)</cell></row><row><cell>Disc.</cell><cell>0.536</cell><cell>0.536</cell><cell>0.588</cell><cell></cell><cell>0.503</cell><cell>0.246</cell></row><row><cell></cell><cell>(0.027)</cell><cell>(0.027)</cell><cell cols="2">(0.028)</cell><cell>(0.048)</cell><cell>(0.036)</cell></row><row><cell>W</cell><cell>0.285</cell><cell>0.285</cell><cell>0.266</cell><cell></cell><cell>0.168</cell></row><row><cell></cell><cell>(0.019)</cell><cell>(0.019)</cell><cell cols="2">(0.019)</cell><cell>(0.015)</cell></row><row><cell cols="7">Notes: Posterior standard deviations are shown in parentheses. denotes</cell></row><row><cell cols="4">the population mean of the structural coefficients.</cell><cell>⌼ Ί kk</cell><cell cols="2">denotes the popu-</cell></row><row><cell cols="5">lation standard deviation of the structural coefficients.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head></head><label></label><figDesc>The full conditional distribution for the precision matrix ‫1מ‬ U i of the individual-level factor scores is Wishart and is given by pos ‫ס‬ q ‫ם‬ N i and R pos ‫ס‬ [(n ij ‫מ‬ i )(n ij ‫מ‬ i )Ј ‫ם‬ R ‫1מ‬ ] ‫1מ‬ .</figDesc><table><row><cell>(e) ‫1מ‬ p(U |{n }, { }) ‫ס‬ W(q , R ) i i j i pos pos</cell><cell>(A.4)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>where q</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell>i</cell><cell>i j</cell><cell>i</cell><cell>i</cell><cell>i</cell></row><row><cell></cell><cell>where</cell><cell>‫1מ‬ i</cell><cell>‫1מ‬</cell><cell cols="2">and N i i ‫1מ‬ ‫1מ‬ i i j ‫1ס‬ ij . i</cell></row></table><note>i V ‫ס‬ D ‫ם‬ N U ‫ס‬ V U ͚ n N i</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head></head><label></label><figDesc>. Parameter draws can be sequentially made for each la k , k ‫ס‬ 1 The full conditional for the factor scores g ij is a multivariate normal distribution. Consider the reduced form for the structural model g ij ‫ס‬</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>(m) la k</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>to r.</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">( j ) . Let ‫1מ‬ B ( c ‫ם‬ C n ‫ם‬ f ) i i 0 i ij ij</cell><cell>‫1מ‬ X ‫ס‬ B WB Ј ‫1מ‬ i i</cell><cell>. Then the</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>full conditional is given by</cell><cell>N(g , ij</cell><cell>V g ), where ‫1מ‬ V ‫ס‬ X ‫ם‬ ‫1מ‬ g</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">and KЈH Kg ‫ס‬ V [X (B c ‫ם‬ B C n ) ‫ם‬ KЈ H (y ‫מ‬ ‫1מ‬ ‫1מ‬ ‫1מ‬ ‫1מ‬ ‫1מ‬ y iy y ij</cell></row><row><cell>If the candidate is accepted, then</cell><cell>(m‫)1ם‬ la k</cell><cell>c ‫ס‬ la k</cell><cell>, otherwise,</cell><cell>(m‫)1ם‬ la k</cell><cell>‫ס‬</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head></head><label></label><figDesc>where q pos ‫ס‬ q w ‫ם‬ N and ‫ם‬ q w R w ] ‫1מ‬ and‫ס‬ B i g ij ‫מ‬ c i,0 ‫מ‬ C i n ij .</figDesc><table><row><cell></cell><cell></cell><cell>ij</cell><cell>ij</cell><cell>i,0</cell><cell>i</cell><cell>j</cell><cell>p o s</cell><cell>p o s</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">I R ‫ס‬ [͚ pos i‫1ס‬</cell><cell>N i ͚ggЈ j‫1ס‬ ij ij</cell></row><row><cell>g ij</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="8">(m) The full conditional for the population structural parameters</cell></row><row><cell cols="8">is a multivariate normal distribution and can be written aŝ</cell></row><row><cell></cell><cell></cell><cell cols="6">p(|{p }, ⌼) ‫ס‬ N(, V ) i</cell><cell>(A.11)</cell></row><row><cell>where</cell><cell>‫1מ‬</cell><cell>‫ס‬ C ‫1מ‬ ‫ם‬</cell><cell></cell><cell cols="4">⌼ ‫1מ‬ F i and IV ͚ FЈ i‫1ס‬ i</cell><cell>‫ס‬ V (C ‫1מ‬ c ‫ם‬</cell></row><row><cell></cell><cell cols="2">⌼ ‫1מ‬ p i ).</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>I ͚ FЈ i‫1ס‬ i</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Marketing Science/Vol.19, No. 4, Fall 2000  </note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix 1: Prior Distributions</head><p>In this paper, we specify the prior distribution over u as a product of independent priors. We use proper but diffuse priors over all model parameters. U i full conditional is proportional to the product of the likelihood expression specified above, and the prior density of qЈ, which is a univariate normal p( qЈ) ‫ס‬ N(0, s rho ). We therefore use a random-walk Metropolis-Hastings step to generate random draws of qЈ. To generate a candidate qЈ c , we use a univariate normal proposal density N( qЈ <ref type="bibr">(m)</ref> , t) that is centered on the old value of qЈ <ref type="bibr">(m)</ref> . The tuning constant t in the proposal density is chosen to allow rapid mixing and to avoid excessively frequent rejections of the candidates. The generated candidate qЈ c is accepted with the following acceptance probability:</p><p>If the candidate is accepted, then qЈ (m‫)1ם‬ ‫ס‬ qЈ c ; otherwise, pЈ (m‫)1ם‬ ‫ס‬ qЈ(m).</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Using extremes to design products and segment markets</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">L E</forename><surname>Ginter ; P</surname></persName>
		</author>
		<author>
			<persName><surname>Rossi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<editor>Marketing and Econometrics. T. Wansbeek and M. Wedel</editor>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1" to="2" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
	<note>J. Econometrics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Bayesian factor analysis for multilevel binary observations</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ansari</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jedidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">A Bayesian approach to nonlinear latent variable models using the Gibbs sampler and the Metropolis-Hastings algorithm</title>
		<author>
			<persName><forename type="first">G</forename><surname>Arminger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="271" to="300" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">CODA: Convergence Diagnostics and Output Analysis Software for Gibbs Sampler Output: Version 0.3</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">G</forename><surname>Best</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">K</forename><surname>Cowles</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Vines</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biostatistics Unit-MRC</title>
		<imprint>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
	<note type="report_type">Technical report</note>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Structural Equations with Latent Variables</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">A</forename><surname>Bollen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1989" />
			<publisher>Wiley Interscience</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Understanding the Metropolis-Hastings algorithm</title>
		<author>
			<persName><forename type="first">S</forename><surname>Chib</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Greenberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. Statist</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="327" to="335" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Investigating heterogeneity in brand preferences in logit models for panel data</title>
		<author>
			<persName><forename type="first">P</forename><surname>Chintagunta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Vilcassim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="417" to="428" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Sampling-based approaches to calculating marginal densities</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Gelfand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<editor>A. F. M. Smith</editor>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="972" to="985" />
			<date type="published" when="1990" />
			<publisher>Chapman and Hall</publisher>
		</imprint>
	</monogr>
	<note>Model determination using sampling-based methods</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Stochastic relaxation, Gibbs distributions and the Bayesian restoration of images</title>
		<author>
			<persName><forename type="first">S</forename><surname>Geman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Geman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Pattern Anal. Machine Intelligence</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="721" to="741" />
			<date type="published" when="1984" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A general model for the analysis of multilevel data</title>
		<author>
			<persName><forename type="first">H</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">P</forename><surname>Mcdonald</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">553</biblScope>
			<biblScope unit="page" from="455" to="467" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Monte Carlo sampling methods using Markov chains and their applications</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">K</forename><surname>Hastings</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biometrika</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="97" to="109" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Marketing Strategy and Uncertainty</title>
		<author>
			<persName><forename type="first">Sharan</forename><surname>Jagpal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Finite-mixture structural equation models for response-based segmentation and unobserved heterogeneity</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jedidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Jagpal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Desarbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="39" to="59" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Rational and adaptive performance expectations in a customer satisfaction framework</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">D</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">W</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Fornell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="695" to="707" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Simultaneous factor analysis in several populations</title>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Jö Reskog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="409" to="426" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A probabilistic choice model for market segmentation and elasticity structure</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Kamakura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="379" to="390" />
			<date type="published" when="1989-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A Bayesian approach to confirmatory factor analysis</title>
		<author>
			<persName><forename type="first">S.-Y</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="153" to="160" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Factor analysis for clustered observations</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">T</forename><surname>Longford</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="581" to="597" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Statistical Theories of Mental Test Scores</title>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">M</forename><surname>Lord</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Novick</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968" />
			<publisher>Addison-Wesley</publisher>
			<biblScope unit="page" from="129" to="131" />
			<pubPlace>Reading, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Equations of state calculations by fast computing machines</title>
		<author>
			<persName><forename type="first">N</forename><surname>Metropolis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">W</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">N</forename><surname>Rosenbluth</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Teller</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Teller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Chem. Phys</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1087" to="1091" />
			<date type="published" when="1953" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Latent variable modeling in heterogeneous populations</title>
		<author>
			<persName><forename type="first">B</forename><surname>Muthén</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multilevel covariance structure analysis. Sociol. Methods Res</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="page" from="376" to="398" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
	<note>Psychometrika</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Approximate Bayesian inference by the weighted likelihood bootsrap (with discussion)</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Newton</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">E</forename><surname>Raftery</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Roy. Statis. Soc. Ser. B</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="page" from="3" to="18" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Cognitive, affective, and attribute bases of the satisfaction response</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Oliver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Satisfaction: A Behavioral Perspective on the Consumer</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>McGraw-Hill</publisher>
			<date type="published" when="1993" />
			<biblScope unit="volume">20</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Overcoming scale heterogeneity. Working paper</title>
		<author>
			<persName><forename type="first">P</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><surname>Gilula</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Allenby</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<pubPlace>Chicago, IL</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Chicago</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Bayesian estimation and testing of structural equation models</title>
		<author>
			<persName><forename type="first">R</forename><surname>Scheines</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Hoijtink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Boomsma</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="37" to="52" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Structural equation models with structured means</title>
		<author>
			<persName><forename type="first">D</forename><surname>Sö Rbom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Systems Under Indirect Observation: Causality, Structure, And Prediction</title>
				<editor>
			<persName><forename type="first">K</forename><forename type="middle">G</forename><surname>Joreskog</surname></persName>
			<persName><forename type="first">H</forename><surname>Wold</surname></persName>
		</editor>
		<meeting><address><addrLine>Amsterdam, Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>North Holland</publisher>
			<date type="published" when="1981" />
			<biblScope unit="page" from="183" to="195" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The calculation of posterior distributions by data augmentation (with Discussion)</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">A</forename><surname>Tanner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">H</forename><surname>Wong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="528" to="550" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Finite mixtures in confirmatory factor-analysis models</title>
		<author>
			<persName><forename type="first">Yiu-Fai</forename><surname>Yung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="297" to="330" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">An Introduction to Bayesian Inference in Econometrics</title>
		<author>
			<persName><forename type="first">Arnold</forename><surname>Zellner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1971" />
			<publisher>Wiley</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">This paper was received August 5, 1999, and has been with the authors 6 months for 3 revisions; processed by Greg Allenby</title>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
