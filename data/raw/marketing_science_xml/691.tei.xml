<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Real-Time Evaluation of E-mail Campaign Performance</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2008-10-07">October 7, 2008.</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">André</forename><surname>Bonfrer</surname></persName>
							<email>andrebonfrer@smu.edu.sg</email>
						</author>
						<author>
							<persName><forename type="first">Xavier</forename><surname>Drèze</surname></persName>
							<email>xdreze@wharton.upenn.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Lee Kong Chian School of Business</orgName>
								<orgName type="institution">Singapore Management University</orgName>
								<address>
									<postCode>178899</postCode>
									<settlement>Singapore</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">University of Pennsylvania</orgName>
								<address>
									<postCode>19104</postCode>
									<settlement>Philadelphia</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org Real-Time Evaluation of E-mail Campaign Performance</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 e 1526-548X 09 2802 0251</idno>
						<imprint>
							<date type="published" when="2008-10-07">October 7, 2008.</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.1080.0393</idno>
					<note type="submission">Received: November 2, 2006; accepted: January 25, 2008; processed by Michel Wedel.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:26+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please scroll down for article-it is on subsequent pages</head><p>With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning opportunities for individual professionals, and organizations of all types and sizes, to better understand and use O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>E-mail can be a powerful vehicle for marketing communications. Many marketers favor this medium because it provides a cheaper and faster way to reach their customers. Further, the online environment allows marketers to more accurately measure consumers' actions <ref type="bibr" target="#b33">(Weible and Wallace 2001)</ref>. This is a boon for marketing scientists in their desire to increase the effectiveness of marketing efforts and measure the return on investment (ROI) of marketing expenditures.</p><p>Although e-mail response rates started out high (especially when compared with those reported for online and offline advertising), they declined over time and are now below 2.5% <ref type="bibr">(Direct Marketing Association 2005)</ref>. Finding ways to raise these response rates is critical for e-mail marketers. A useful tool to achieve this is an effective e-mail testing methodology. Identifying potential strengths and weaknesses of the content (the e-mail creative) and the target population before the e-mail is sent at full scale can help marketers improve the response rates for their campaigns.</p><p>Testing elements of the marketing mix is not new to marketing scientists. In new product development (and distribution) the ASSESSOR model <ref type="bibr" target="#b28">(Silk and Urban 1978</ref>, <ref type="bibr" target="#b32">Urban and Katz 1983)</ref> has been used for decades to forecast the success of new products through laboratory based test marketing. <ref type="bibr" target="#b23">Moe and Fader (2002)</ref> use advance purchase orders made via the CDNOW website to generate early indicators of new product sales for music CDs. In advertising, the efficacy of an advertising campaign is assessed using a battery of tests designed to identify the best creative campaign to use (e.g., the most persuasive or the most memorable) using selected members of the target audience. Field experiments with split-cable television technology have also been used to study the impact of advertising on brand sales <ref type="bibr" target="#b22">(Lodish et al. 1995</ref><ref type="bibr" target="#b2">, Blair 1988</ref>.</p><p>Testing is also popular in Internet marketing applications <ref type="bibr" target="#b9">(Drèze and Zufryden 1998)</ref>. Online advertisers track banner ad performance in real time to identify the appeal (click-through) of various advertising creatives. Click-stream models can be implemented to test the appeal of content by measuring the click-through rates (CTR) or website stickiness <ref type="bibr" target="#b3">(Bucklin and Sismeiro 2003)</ref>. Eye tracking technology may be used to identify where (and if) a customer is viewing the advertising message embedded on a webpage <ref type="bibr" target="#b8">(Drèze and Hussherr 2003)</ref>.</p><p>In direct marketing, modeling techniques have been developed to help marketers select the right customer group for a given content. <ref type="bibr" target="#b4">Bult and Wansbeek (1995)</ref> build a regression model to predict each customer's likelihood of responding to a direct marketing communication, and then select which customers should be contacted by explicitly maximizing the expected profits generated by each communication. <ref type="bibr" target="#b1">Bitran and Mondschein (1996)</ref> take the profit maximization objective a step further by incorporating inventory policies (inventory and out-of-stock costs) into the decision. <ref type="bibr" target="#b13">Gönül and Shi (1998)</ref> extend this model by allowing customers to optimize their purchase behavior over multiple periods (i.e., both the firm and the customer are forward looking). Recognizing that customers can order from old catalogs and that one can still garner new sales from old customers who were not sent a new catalog, <ref type="bibr" target="#b14">Gönül et al. (2000)</ref> propose a hazard function model of purchases where customers are sent a catalog only if the expected profits with the additional mailing exceeds the profits without the mailing. <ref type="bibr" target="#b10">Elsner et al. (2004)</ref> use Dynamic Multilevel Modeling (DMLM) to simultaneously optimize customer segmentation and communication frequency. <ref type="bibr" target="#b11">Gönül and Ter Hofstede (2006)</ref> find the optimal mailing policy for a catalog marketer given individual level predictions of customers' order incidence and volume.</p><p>While some of these methods may be adapted to the context of e-mail marketing, some unique features of e-mail present several new modeling challenges. First, many firms have implemented tracking technologies for e-mail campaigns that monitor whether and when a customer responds to an e-mail. Given the goal of real-time testing, it is essential that we make full use of this continuous time data.</p><p>Second, in contrast to a typical click-stream setting, e-mail communications are initiated by the firm rather than the customer. This adds a layer of complexity in that, while the delivery of an e-mail is often close to instantaneous, there is a delay between the time the e-mail is sent and the time it is opened. This delay will depend on how often users check their e-mail.</p><p>A third difference in e-mail marketing involves the lead time for generating both the creative and the execution of the campaign. While e-mail delivery is neither free nor instantaneous, even a large email campaign can be sent at relatively low cost and delivered in a matter of hours. Consequently, campaigns are short lived and often run with short lead times and compressed deadlines-such as weekly (e.g., American Airlines, Travelocity, The Tire Rack), bi-weekly (e.g., Longs Drugstore), or even daily (e.g., Sun Microsystems). These short lead times place significant constraints on testing.</p><p>For these reasons, effective e-mail marketing communication requires a testing methodology that can generate predictions of open incidence and the CTR (CTR = clicks/opens) of any e-mail campaign as quickly and accurately as possible. Our paper describes the development and performance of such a model. We begin by developing a split-hazard model of open behavior using a log-logistic hazard function to predict the distribution of open times. Click behavior is then modeled using both a censored splithazard model and a simpler binomial model. To help produce stable estimates even when data are sparse (a common occurrence when trying to test campaigns in a short amount of time), we use Bayesian shrinkage estimation with correlated priors between open and clicks.</p><p>When applying our model to field data, we find it necessary to account for intraday variations in customer responses (e.g., to account for fewer e-mails opened at night). Consequently, we develop a concept of virtual time that allows us to produce a model that fits the data well while keeping the specification simple. Virtual time involves adjusting the speed of time through the day to adapt to the marketers' and customers' availability. For instance, compare an e-mail sent at noon to an e-mail sent at two in the morning.</p><p>While both e-mails might ultimately be opened, it is likely that the delay between send and open will be smaller for the e-mail sent in the middle of the day than for the e-mail sent in the middle of the night simply because the average recipient is more likely to be awake and checking his e-mail during the day than during the night. To reflect that recipients' availability fluctuates throughout the day, we speed up and slow down time. An hour of real time at noon (when customers are available) could be expanded to two hours of virtual time to reflect that a lot can happen during this interval while an hour at two in the morning (when most customers are asleep) could be compressed to half an hour to reflect that little would happen in the middle of the night. Using virtual time allows us to keep the model specification simple. This makes shrinkage straightforward and allows for an easy interpretation of the model parameters.</p><p>Our model offers a number of substantial practical benefits. (1) Fast evaluation of a campaign allows for early warnings about the probable success or failure of the campaign. This can lead to timely go/no-go decisions for either campaigns or creative the selected e-mail. (2) The model provides diagnostic information that can be integrated in a formal decision process to improve the results of an underperforming campaign or discard any campaign that does not perform above some threshold level of response. (3) Only a small sample is required for testing. The small sample size makes it easy to test the effectiveness of multiple advertising copies or to test the reaction of different target groups of customers. (4) Our process incorporates historical data and thus leads to better decisions as more campaigns are tested. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Research Setting and Data Description</head><p>We calibrate and test our models using a database of 25 e-mail campaigns sent as part of the online newsletter of an entertainment company (see Table <ref type="table" target="#tab_0">1</ref> for summary statistics of the e-mail campaigns). Most of the e-mails are in the form of promotions aimed at inducing customers to purchase a movie title online or offline, or to click on links to access further content.</p><p>(Different campaigns have different purposes.) Each e-mail has a subject line displaying the purpose of the promotion (e.g., "Spiderman III now out on DVD!").</p><p>The main body of the e-mail is only visible after the recipient has opened the e-mail. Within the body of the e-mail, recipients can click on various links to learn more about the promotion or go to a moviespecific website. It is important to note that clicks can only occur if a recipient opens the e-mail. Figures <ref type="figure">1(a</ref>) and 1(b) present histograms of the time (in hours) it takes for customers to open the e-mail after it is sent and the time (in minutes) it takes customers to click on the e-mail once opened. Given our objective of reducing the time allocated to testing, several features of our data are highly pertinent to model construction.</p><p>1. Most e-mails are opened within 24 hours of sending; clicks occur within a minute of opening.</p><p>2. It takes a few hours for response rate to build. There is a relatively low level of e-mail activity immediately after a campaign is launched, followed by a buildup around two hours later.</p><p>3. The histogram of the delay between send and open (Figure <ref type="figure">1</ref>(a)) reveals a multimodal pattern during the first 24 hours after an e-mail is sent. This pattern is also visible on individual campaign histograms.</p><p>The first feature requires that a rapid testing model of open and click rate work well with censored data. Indeed, by shortening the testing time, we reduce the amount of uncensored data available to us. The second feature suggests that we must be careful about our assumptions about the data generation process when building our model. This is particularly important in our case, as we are trying to make predictions about the entire distribution of e-mail activity based on only a few hours of activity. The multimodal pattern found in the time until opening is troublesome as it does not conform to any standard distribution and might be difficult to capture with a simple model. To understand what may be driving this multimodal pattern, we plot the distribution of e-mail openings throughout the day (see Figure <ref type="figure">2</ref>). This graph shows considerable variation. There are fewer e-mails opened late at night and early in the morning than during the day. We refer to this pattern as intraday seasonality. In the next section we show how this seasonality may be the cause of the multimodal feature of Figure <ref type="figure">1</ref>(a).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Model Setup</head><p>We develop a rapid testing methodology for a specific application: the testing of online e-mail campaigns. Rapid testing provides early feedback on whether a campaign is likely to be successful or not. In the spirit of traditional testing models, it is important that our methodology consumes as few resources as possible. Ideally, the model would also be parsimonious. It would estimate quickly such that a test could be implemented in real time and would allow for the monitoring of a campaign as it is being sent. Indeed, an overly complex or overparameterized model that takes hours to generate predictions would defeat the purpose of rapid testing. We first describe in more detail how the model accommodates intraday seasonality. Next, we develop a split-hazard model of open and click probabilities that takes into account the possibility that some e-mails are never opened or clicked on. We then derive the shrinkage estimators for the open and click models and state the likelihood function used in the estimation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">From Physical Time to Virtual Time</head><p>A traditional approach to handling seasonality, such as that displayed in Figures <ref type="figure">1(a</ref>) and 2, is to introduce time-varying covariates in the model. There are two main problems with this approach. First, the covariates are often ad hoc (e.g., hourly dummies). Second, they often make the other parameters less interpretable (e.g., a low open rate during peak hours could be larger than a high open rate during off peak hours). To alleviate these concerns, we build on the approach proposed by Radas and Shugan (1998), (hereafter RS), who deseasonalized a sales process by changing the speed at which time flows. They showed that by speeding up time during high seasons, and slowing down time during low seasons, one can create a new (virtual) time series that is devoid of seasonality. The benefits of this approach, assuming that one has the right seasonality pattern, is that one can use straightforward models in virtual time and easily interpret the meaning of the parameters of these models.</p><p>The effectiveness of the RS approach hinges on having a good handle on the seasonal pattern present in the data. In their application (the movie industry) they produce seasonal adjustments by combining past sales data with industry knowledge. A shortcoming of this approach is that some of the seasonality may be endogenous to the firms' decisions. For instance, if movie studios believe that Thanksgiving weekend is a "big" weekend, they may choose to release their movies during that weekend rather than during offpeak weekends <ref type="bibr" target="#b0">(Ainslie et al. 2005)</ref>. Thus, part of the seasonality observed during Thanksgiving will stem from the fact that more consumers have the time and desire to see movies on that weekend (consumerinduced seasonality), and part of the seasonality will stem from the fact that more movies are available (firm-induced seasonality). If one uses past data as a base for seasonal adjustment without considering the decisions of the firm, one can potentially overcorrect and attribute all the seasonal effects to consumer demand while it in fact also partly stems from firm supply.</p><p>In our case, we are confronted by both consumerand firm-induced seasonality. For instance, the average consumer is much less likely to open e-mails at four in the morning than at four in the afternoon. Similarly, firms do not work 24 hours a day. If we look at when the firm sends its e-mail (Figure <ref type="figure" target="#fig_3">3</ref>), we observe little (but some) activity during the night, then a peak at eight in the morning, a peak at noon, and a lot of activity in the afternoon. It is likely that these peaks are responsible for some of the increase in activity we see in Figure <ref type="figure">2</ref> at similar times.</p><p>To separate consumer-from firm-induced seasonality, we benefit from two features of our modeling environment not present in RS. First, we have continuous time individual level data. While RS had to work with aggregate weekly measures, we know the exact time each e-mail is sent and opened. Second, while a movie can open on the same day throughout the country, e-mails cannot all be sent at the same time. E-mails are sent sequentially; for example, a million-e-mail campaign can take up to 20 hours to  send. Thus, we can simulate an environment that is devoid of firm based seasonality by resampling our data such that the number of e-mails sent at any point in time is constant through the day (i.e., Figure <ref type="figure" target="#fig_3">3</ref> for such a firm would be flat).</p><p>To resample the data, we proceed in three steps. First, for each minute of the day, we collect all e-mails that were sent during that minute. Second, we randomly select with replacement 100 e-mails from each minute of the day (144,000 draws). Third, we order the open times of these 144,000 e-mails from 00:00:00 to 23:59:59 and associate with each actual open time a virtual time equal to its rank divided by 144,000. The relationship between real and virtual time based on their cumulative density functions is shown in <ref type="bibr">Figure 4</ref>. This represents the passing of time as seen by consumers independent of the actions of the firm.</p><p>We can use the relationship depicted in Figure <ref type="figure">4</ref> to compute the elapsed virtual time between any two events. For instance, if an e-mail were sent at midnight and opened at two in the morning, we would compute the elapsed virtual time between send an open by taking the difference between the virtual equivalent of two a.m. (i.e., 00:29:44 virtual) and midnight (i.e., 00:00:00 virtual) to come up with 29 minutes and 44 seconds. Similarly, if the e-mail had been sent at noon and opened at two p.m., then the elapsed virtual time would be 11:05:10-09:08:30 = 1 hour 56 minutes and 40 seconds.</p><p>Our approach does not account for another form of endogeneity that could arise if the firm were to strategically send good and bad e-mail campaigns at different times of the day such that the two types of campaigns would not overlap. Fortunately, this was not company policy in our application-e-mail campaigns were sent out whenever they were ready. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">A Split-Hazard Model of Open and Click Time</head><p>The time it takes for a customer to open an e-mail from the time it is sent and the time it takes to click on an e-mail from the time a customer opens it are both modeled using a standard duration model (e.g., <ref type="bibr" target="#b23">Moe and</ref><ref type="bibr">Fader 2002, Jain and</ref><ref type="bibr" target="#b17">Vilcassim 1991)</ref>. Because both actions can be modeled using a similar specification, we discuss them interchangeably. Starting with opens, we account for the fact that in an accelerated test, a failure to open an e-mail means one of two things. Either recipients are not interested in the e-mail or they have not had a chance to see it yet (i.e., the data is censored). Of course, the shorter the time allocated to a test, the higher the likelihood that a nonresponse is indicative of censoring rather than lack of interest. Thus, we model the open probability and the open time simultaneously in a right-censored split-hazard model <ref type="bibr">(Kamakura et al. 2004, Sinha and</ref><ref type="bibr" target="#b29">Chandrashekaran 1992)</ref>.</p><p>The probability that a customer will open or click an e-mail varies from campaign to campaign and is denoted with where e is a superscript that identifies a specific email campaign, k is a subscript that identifies the model used is a vector of parameters to be estimated.</p><formula xml:id="formula_0">(k ∈ o = open c = click ), i is an index of</formula><p>The likelihood function in (1) needs to be adjusted to account for the fact that some recipients will never open or click on the e-mail. Let e k denote the probability that e-mail e will be opened or clicked. The estimation of e k and e k for any parametric hazard function can be performed by maximum likelihood estimation.</p><p>We tested a variety of candidate hazard rate specifications (including the exponential, Weibull, lognormal, and the more general Box-Cox specification) to model the open and click processes (see the Technical Appendix, which can be found at http://mktsci. pubs.informs.org, for details and results). Overall, the tests revealed that the log-logistic distribution is best suited for our application. The probability density function and the survivor function for the log-logistic are (see <ref type="bibr" target="#b19">Kalbfleisch and Prentice 1985)</ref> f t = t −1 1 + t 2 and</p><formula xml:id="formula_1">S t = 1 1 + t (3)</formula><p>where &gt; 0 is a location parameter and &gt; 0 is a shape parameter. Consistent with previous notation, we refer to the shape and location parameters for any given campaign (e) and e-mail response action (k ∈ o c ) as e k , and e k , respectively. Depending on the value of , the log-logistic hazard is either monotonically decreasing ( ≤ 1) or inverted U-shape ( &gt; 1) with a turning point at t = − 1 1/ / .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Shrinkage Estimators</head><p>As in most practical applications, we benefit from having data available from past campaigns. This information can be used to improve the performance of our model. Specifically, we use the parameters estimated from past campaigns to build priors for new campaigns. This is especially useful at the beginning of a campaign when data are sparse.</p><p>Because we use the log-logistic hazard function in our application, each of the split-hazard models has three parameters (</p><p>). When building priors for these parameters, it is reasonable to assume that the open and click rates for a campaign are correlated. Indeed, broad appeal campaigns should yield both high open and high click rates while unappealing campaigns would exhibit both low open and low click rates. To accommodate the possibility of correlated open and click rates, we use a bivariate beta as the prior distribution for the ( o c ). As in <ref type="bibr" target="#b6">Danaher and Hardie (2005)</ref>, we implement the bivariate distribution proposed by <ref type="bibr" target="#b21">Lee (1996)</ref> </p><formula xml:id="formula_2">o c ∼ g x 1 x 2 = f x 1 a 1 b 1 f x 2 a 2 b 2 × 1 + x 1 − 1 x 2 − 2</formula><p>where f x i a i b i is the univariate beta density for x i given parameters (a i b i ), i is the mean of the univariate beta for x i , = Corr x 1 x 2 / 1 2 is a function of the correlation between x 1 and x 2 , and where</p><formula xml:id="formula_3">2 i = a i b i / a i + b i 2 a i + b i + 1 is the variance of the univariate beta.</formula><p>There is no reason to believe that the hazard rate parameters for clicks and opens will be correlated because one process (opens) depends on the availability of recipients to open e-mails while the other process (clicks) is conditional on the recipients having opened the e-mail (thus being available), and depends on the amount of processing needed to understand the e-mail and react to it. It is possible, however, that the shape and location parameters of each hazard rate are correlated. Thus, we use a bivariate log-normal distribution for the prior on k and k k and k of the log-normal distribution is adjusted for possible small sample bias using the correction factor described in <ref type="bibr">Johnson and Kotz (1972, p. 20</ref>):</p><formula xml:id="formula_4">a k k ∼ Log-Normal k k (4)</formula><formula xml:id="formula_5">LN = exp LN − 1 exp 2 − 1 exp 2 − 1 (5)</formula><p>The combination of the likelihood functions given in (2) with the log-logistic hazard specification in (3) and the bivariate beta and log-normal priors gives the following likelihood function to be estimated for a given campaign (omitting the e superscript for clarity): </p><formula xml:id="formula_6">L t o R o t c R c T = LN o o o o LN c c c c ×Beta o a o b o Beta c a c b c • 1+w o − a o a o +b o c − a c a c +b c × N i=1 o o o o t io o −1 1+ o t io o 2 R io • 1− o 1− 1 1+ o T o 1−R io</formula><formula xml:id="formula_7">× N i=1 c c c c t ic −t io c −1 1+ c t ic −t io c 2 R ic • 1− c 1− 1 1+ c T −t io c 1−R ic R io (6)</formula><p>3.4. An Alternative Approach to Estimating Click Rates Although theoretically sound, using a split-hazard model to estimate the parameters of the click times (conditional on an open) might be overly complex. Because most consumers are likely to click on an email within seconds of opening it, few click observations are right censored. Thus, we can test a simpler model for the estimation of click rates that does not take censoring of clicks into account. Our hope is that this more parsimonious model will perform better at the beginning of a test, when few data points are available.</p><p>Formally, we assume that clicks follow a binomial process. Using the same bivariate beta prior for ( o c ) as we did in the full model, the likelihood function for this simplified model is</p><formula xml:id="formula_8">L S t o R o t c R c T = LN o o o o LN c c c c × Beta o a o b o Beta c a c b c • 1 + w o − a o a o + b o c − a c a c + b c × N i=1 o o o o t io o −1 + o t io o 2 R io • 1 − o 1 − 1 1 + o T o 1−R io • R ic c 1 − c 1−R ic R io (7)</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Comparisons with Benchmarks:</head><p>The Doubling Method Before discussing the application of our model, we would like to draw a comparison with existing approaches for predicting the success rate of direct marketing campaigns. The most common model used by practitioners is the doubling method (Nash 2000; it is sometimes referred to as the half-life analysis as in <ref type="bibr" target="#b16">Hughes 2006</ref>). This method involves first looking at the responses of past direct marketing campaigns and computing the amount of time it takes for 50% of the responses to be received (the doubling point).</p><p>The analyst then uses the heuristic that for any future campaigns, the predicted total number of responses is equal to double the number of responses observed at the doubling point. In direct marketing, for first class mailing firms will wait a minimum of two weeks; for third class mailing, they will wait four weeks. Once the test results are in, the decision maker needs to make a go/no-go decision based on profitability. In our case, the doubling point is 14 hours (see Table <ref type="table" target="#tab_0">1</ref>).</p><p>The doubling method is a powerful and simple heuristic. It makes three implicit assumptions. First, it assumes that not everybody will respond. Second, it assumes that it takes time for people to respond. Third, it assumes that the timing of the responses is independent of the rate of response and constant across campaigns. As a nonparametric method, it makes no assumptions about the underlying response process, nor does it provide ways to test whether the current campaign conforms to the data collected from previous campaigns or runs faster or slower than expected. Hence, it does not provide ways to evaluate whether a current test should be run longer or could be finished early. Our model provides this important piece of information.</p><p>In essence, the doubling method aggregates time into two bins-each containing half of the responses. This aggregation loses vital timing information that could be used to better model the response process. If one wanted to speed up the doubling method, any other quantile could be used to perform a test. For example, the 25th percentile would give a quadrupling method.</p><p>Another benchmark examined in this paper is waiting for a predetermined time period and counting the number of opens and clicks observed at that time. The campaign would be deemed a success if these numbers exceed a predefined threshold. While this benchmark does not predict open and click rates, it can be used as a decision rule. We discuss this and other decision rules in more detail in §3.2.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Application of the Model to E-mail Campaign Pretesting</head><p>We now apply our models to the data from the e-mail campaigns described earlier and evaluate the relative predictive validity of various models. Estimation of the parameters is based on a numerical maximization of the censored likelihood functions in Equations ( <ref type="formula">6</ref>) and ( <ref type="formula">7</ref>) using SAS (with the quasi-Newton optimization algorithm). For both real and virtual time, we compare the predictions of our models with those of the doubling method. We then use our model in a campaign selection simulation and benchmark it against other possible heuristics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Simulation and Validation</head><p>The main purpose of the simulation and validation stages is to validate the models proposed in the paper by studying the accuracy of the predictions they make out-of-sample. We also want to find out which of the models has the best predictive performance and whether we can generate estimates that are useful for decision making within a short amount of time (say hours) such that testing is feasible for campaign planning. When doing so, we compare the models based on real time (no time transformation) and virtual time, for both the full model and the simplified click formulation. In summary, we fit and validate the following four models:</p><p>(1) Full model in real time (using Equation ( <ref type="formula">6</ref>) and real time).</p><p>(2) Full model in virtual time (using Equation ( <ref type="formula">6</ref>) and transformed time).</p><p>(3) Simplified model in real time (using Equation ( <ref type="formula">7</ref>) and real time).</p><p>(4) Simplified model in virtual time (using Equation ( <ref type="formula">7</ref>) and transformed time).</p><p>In each simulation, we adopt the perspective of a marketer who wishes to pretest campaigns before committing to the final send. To this end, we look at each campaign assuming that the remaining (E − 1) campaigns have been completed. Prior to the test, we know nothing about a focal campaign except the number of e-mails that need to be sent. However, we can use all the information collected through the other campaigns to build our priors.</p><p>We set the sample test size at 2,000 e-mails. As a robustness check, we varied the sample size between 1,000 and 2,000 in 200-e-mail increments; this did not yield any substantive difference in findings. We simulated different test lengths in 30-minute increments, ranging from 30 minutes to 8 hours. For each test length, any e-mail that had been opened prior to the simulated end of test was used in the noncensored component of the log-likelihood. All other observations are coded as censored (e.g., if an open were recorded 45 minutes after an e-mail was sent, this observation would be coded as censored when we simulate a 30-minute test, and as an open for a 60-minute test and any subsequent tests). Based on this set of censored and uncensored observations, the parameters of the full and simplified models are estimated using priors based on all other campaigns.</p><p>As a practical matter, the distributions of open and click times exhibit long tails, such that some responses continue to come in long after a campaign has run its course. Historical data reveal that 99% of all email responses are observed within 3 weeks of being sent. Typically, the company conducts postcampaign debriefing 2-3 weeks after the e-mails are sent. Thus, the cutoff date is set at 3 weeks (504 hours), and the number of opens and clicks observed at that time is used as the true value the models need to predict. Our forecast of the number of opens and clicks at 3 weeks is constructed using the parameter estimates for each of the censored samples; standard errors are calculated using the Delta method. The cumulative distribution of opens and clicks at 504 hours is calculated using</p><p>(1)  The MAD statistics for the first four hours are reported in Table <ref type="table" target="#tab_7">2</ref>. For all the open models tested, the MAD declines as testing time increases. Based on the MAD prediction error, the virtual-time models outperform the real-time models. The virtual-time models achieve a prediction error that is equal or better than that of the doubling method in as little as three hours. This represents a reduction in test time of close to 80%. For real time, it takes slightly over four hours before the tested model outperforms the doubling time model. At the doubling time point (14 hours), all the tested models were superior in predictive performance to the doubling method.</p><p>Although, in the interest of space, we do not present the standard errors for the various campaigns' parameter estimates, we find that using virtual time also produces tighter and more stable estimates (i.e., smaller confidence intervals) than the model using real-time data. Because virtual-time models also estimate faster, they are well suited to test the performance of a campaign in compressed-time applications.</p><p>The prediction errors for clicks exhibit a similar pattern. The simplified model slightly outperforms the full model in the early stages of testing (up to about 5 hours for the real-time model, and 1.5 hours for the virtual-time model). The simplified model in virtual time achieves a predictive performance similar to the doubling method in only 2.5 hours-an 82% reduction in testing time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">A Campaign Selection Decision Rule</head><p>The results reported in the preceding section demonstrate that our models can produce estimates of the open and click rates faster and more accurately than the doubling method. While these results show a clear improvement in speed and accuracy, a natural  <ref type="formula">7</ref>)) (Equation ( <ref type="formula">7</ref>)) (Equation ( <ref type="formula">7</ref>)) (Equation ( <ref type="formula">6</ref>)) (Equation ( <ref type="formula">7</ref>)) (Equation ( <ref type="formula">6</ref> question arises: Are the benefits of the new models substantial from a managerial standpoint? To investigate this in the context of our application, we develop a formal decision rule based on the testing methodology developed in §2. We take the perspective of a campaign manager who wishes to improve the ROI of his marketing actions by eliminating underperforming campaigns. One possible reason for not wanting to use a low-yield campaign is that the e-mails cost more to send than the expected returns. Such underperforming campaigns also represent an opportunity cost in that they tie up resources that could be used to send more profitable campaigns. Furthermore, sending undesirable material could lead to higher customer attrition <ref type="bibr" target="#b15">(Hanson 2000)</ref>.</p><p>Imagine that our manager wishes to eliminate any campaigns with a CTR lower than the historical average of 2% (across 25 campaigns). Clearly, rejecting any campaigns with response rates lower than the historical average will have the consequence of improve response rates across future campaigns and help the firm achieve growth objectives <ref type="bibr" target="#b26">(Pauwels and Hanssens 2007)</ref>. If the manager wishes to further improve response rates, it is also possible to set this threshold higher. To make a go/no-go decision on campaigns, the manager could consider one of the following four decision rules:</p><p>Rule 1: Doubling Method. Under the doubling method, the decision rule is quite simple. For a given campaign, send out the test sample, wait 14 hours, and observe the CTR. If the CTR is greater than 1% (1/2 of 2%), then run the full campaign; otherwise cancel it.</p><p>Rule 2: The Horse Race. 1 If the manager needs only to make a go/no-go decision rather than predict the actual outcome of the campaign, he or she can compare the results of the current campaign to the other campaigns at some point during the testing phase. If these results are better than average, go ahead with the full campaign, or else, cancel it. In essence, the manager is entering the campaign in a horse race, pitching the current campaign against previous ones.</p><p>This approach is simple and parameter free. It has the advantage of being faster than the doubling method and is simpler than our proposed model. If all one cares about is picking the right campaign, it may be sufficient to use this approach. We implemented this approach by using the same 2.5-hour cutting point as we use in Rule 3.</p><p>Rule 3: The Proposed Model. Under Rule 3, the manager will run the test for 2.5 hours, then fit our model and use its output to predict the long-run CTR. If the predicted result is larger than 2%, then the manager proceeds with the campaign; otherwise it is cancelled.</p><p>Rule 4: Sequential Statistical Test Under Proposed Model. Rule 3 makes a go/no-go decision based on the CTR predicted by our model. In doing so, it ignores the uncertainty around this estimate. A more astute manager would consider this uncertainty when making the go/no-go decision. There are many ways to do this. One way is to continue the test until there are enough data to conduct a statistical test that would reject the null hypothesis that the CTR is equal to 2% (we call this Rule 4). This approach is in the spirit of adaptive learning, i.e., technology used by the firm to adapt in real time to tested customer preferences <ref type="bibr" target="#b31">(Sun 2006)</ref>. A related approach is to incorporate a loss function into the decision (see <ref type="bibr" target="#b5">Calabria and Pulcini 1996</ref><ref type="bibr" target="#b25">, Pandey 1997</ref><ref type="bibr" target="#b34">, Zellner 1986</ref>). This is Rule 5, which is discussed in the Technical Appendix at http://mktsci.pubs.informs.org.</p><p>Under Rule 4, the decision process adopted by the manager is as follows:</p><p>Step 1. Send 2,000 test e-mails.</p><p>Step 2. Wait M minutes. Step 3. Fit our proposed model.</p><p>Step 4. Predict the end of campaign CTR.</p><p>Step 5. Use standard error around the prediction to test the hypothesis that CTR = 2%.</p><p>Step 6. If the test fails to reject the null hypothesis, go back to Step 2.</p><p>Step 7. If the test shows that CTR &gt; 2% then proceed with the campaign, otherwise cancel it.</p><p>This method has the advantage of making the most of the data available to the analyst. It considers not only the point estimate CTR, but also the uncertainty around the estimate. Finally, it adapts to each campaign by cutting short the test if the results are clearly significant, or running the test longer if more precision is needed.</p><p>In our test, we set the significance level for the statistical test at p = 0 05 (two-tailed) and we set M at 30 minutes to limit the number of models we need to fit (25 campaigns in 30-minute increments leads to 400 runs for an 8-hour test). In practice, one could use a much shorter pooling interval. Our model estimates in a matter of seconds. One could even consider running the test in real time and reestimating the model when a new open or click is recorded.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1.">Comparison of Decision</head><p>Rules. The results of decision rules 1 to 4 are reported in Table <ref type="table" target="#tab_10">3</ref>. Seven of the 25 campaigns have a true CTR greater than 2%. If only these seven campaigns were selected, then the average CTR would be 4.45%-see the column labeled Actual. We use the doubling method (Rule 1) as the method to beat. In our case, the doubling method selects 11 campaigns, the 7 correct campaigns plus 4 underperforming campaigns, yielding a CTR of 3.34%. The horse race (Rule 2) does not perform as well as the doubling method and leads to a decrease in response rate of 20% (2.66% versus 3.34% CTR); it is not very discriminate and retains too many campaigns. Looking at the campaigns that are added erroneously, we find that these campaigns are the ones with the highest parameters in the open-hazard function. That is, these campaigns start off strong, but quickly deteriorate. Because Rule 2 only looks at the overall clicks after 2.5 hours of testing without adjusting for the timing of the clicks, it is not surprising that it is less able to discriminate between the campaigns that deteriorate quickly and overall strong performers.</p><p>Our model (Rule 3) performs better than the doubling method. The average campaign response rate increases by 28% (4.29% CTR versus 3.34%) by using our model and waiting 2.5 hours of virtual time. One can gain a further 15% (4.77% versus 3.63%, for a total improvement of 43%) by using the sequential testing rule (Rule 4) rather than a fixed time stopping rule. Rule 4 actually overperforms by selecting only six of the seven correct campaigns and having no false positives.</p><p>Looking at CTR only does not fully reflect the economic consequences of sending more or fewer campaigns. One can always improve click-through rates by being more cautious and having a high cutoff rate. This of course leads to fewer campaigns selected and thus less income for the firm <ref type="bibr" target="#b4">(Bult and</ref><ref type="bibr">Wansbeek 1995, Steenburgh et al. 2003)</ref>. To consider the economic impact of each decision rule, one can use a per e-mail sent profit function, T = o b + c p − mc, where b represents the revenue to the firm from an open only (i.e., a billboard effect, the recipients might read the e-mail, then buy from a third party), p represents the revenue to the firm when a click occurs, and mc is the cost of sending the e-mail. For the purpose of illustration, we set mc at $0.02, b at $0.01, and p at $1.00.</p><p>The last two rows of Table <ref type="table" target="#tab_10">3</ref> show the average revenue per e-mail sent and the total revenue per name (assuming the same names are used in all campaigns). The economic consequences of the various decision rules are best exemplified by looking at Rules 2 and 4. Rule 2 has a revenue per e-mail sent that is only one third of the ideal ($0.009 versus $0.027). Nevertheless, because it results in twice as many campaigns being selected, it generates total revenue that is almost two thirds of ideal ($0.122 versus $0.190). In contrast, Rule 4 has a revenue per e-mail sent that is larger than the ideal ($0.031 versus $0.027), but it sends fewer emails, and thus yields a slightly smaller overall profit ($0.183 versus $0.190).</p><p>It should be noted that, when using a statistical test to decide when to stop testing, the testing time varies widely across campaigns. On average, the adaptive testing rule requires 2 hours 57 minutes. The fastest campaign reaches statistical significance in as little as 1 hour. The slowest campaign needs 6 hours. In short, our tests demonstrate that our method performs better than a simple comparison of campaign performance after a fixed time (be it the doubling method rule or the horse race). Further, by taking advantage of the fact that our method produces not only a point estimate but also a distribution around the point estimate, one can further improve decision making either through a sequential testing method or the use of a loss function that reflects manager beliefs.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">When Is the Best Time to Test?</head><p>Our comparison of the predictive ability for the splithazard rate model suggests that, on average, we can learn as much in 2.5 hours as we can learn from the doubling method in 14 hours. However, it is important to remember that these 2.5 hours are measured in virtual time. In real time, the test will require more or less time depending on the time of day when it is conducted. Figure <ref type="figure" target="#fig_8">5</ref> shows how long 2.5 virtual hours correspond to in real time, depending on when the test starts. There appears to be a sweet spot in the afternoon, between 13:00 and 19:00 hours where a 2.5-virtual-hour test can be carried out in fewer than 2 actual hours (the shortest it could take would be 1 hour and 15 minutes by starting at 17:34 hours). Starting after 19 hours will impose delays as the test because it is unlikely to be finished before people go to bed; if the test is started at 22:12 hours it will take almost 6.5 hours to complete.</p><p>Given the speed at which the tests can be carried out, an e-mail marketer could implement a sequential refinement approach starting with a series of concepts tested at 09:00 hours. The results would come in by noon. Between noon and 13:00 hours, the marketer could refine the winning concept by producing  different variations of it. At 13:00 hours, the refined concepts can be tested, with the results coming in by 15:00 hours. The winning concepts of this second phase are used to produce a final set of concepts that are tested at 16:00 hours with the results out by 18:00 hours. At that time the marketer can select the final creative and send it out. This series of concept creation/testing/selection can be carried out in a day and should produce much better results than sending out untested creatives. A key advantage of our methodology is the ability to develop multiple results in quick succession, a feature that is crucial for a sequential testing procedure.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Discussion and Conclusion</head><p>The value of information increases with its timeliness. Knowing quickly whether a campaign is going to be successful provides the opportunity to correct potential problems before it is too late or even to stop the campaign before it is completed. It is therefore imperative to develop methods that improve both the accuracy and speed with which campaign testing can be done. In this article, we study a testing procedure that can be implemented for the fast evaluation of e-mail campaign performance. The performance of an e-mail campaign is defined by its open and CTR. The methodology we propose predicts these rates quickly based on estimates produced with small samples of the main campaign. We propose to send 2,000 e-mails and to wait fewer than two hours to produce estimates of how the campaign will perform after three weeks. In two hours, fewer than 100 opens and fewer than 10 clicks are typically observed. The key to successful prediction of the ultimate results of an e-mail campaign based on so few data points lies in using the information to its fullest potential.</p><p>There are three elements that make our methodology successful: (1) using the appropriate model specification, (2) transforming time to handle intraday seasonality, and (3) using informative priors. Each of these three elements provides its own unique contribution to the overall fit and predictive performance of the model.</p><p>The appropriate hazard function is critical because our compressed-time tests produce observations that are heavily right censored. Thus, we are often fitting a whole distribution based only on its first quartile (or even less). We find that the best fitting parametric model for open times is the log-logistic. For modeling clicks, we find that the straight binomial process is a good descriptor of the phenomenon given that consumers respond quickly after opening an e-mail. Thus, the CTR (the total number of clicks for a campaign, unconditional on open) is best predicted using Marketing Science 28(2), pp. 251-263, © 2009 INFORMS a combination of a binomial model for the clicks, and a log-logistic split-hazard model for the opens.</p><p>We apply our split-hazard model in a virtualtime setting. The virtual-time transformation removes intraday seasonality and makes our testing procedure invariant to time of day. This is a key factor in the robustness of our model in that it allows us to bypass the need to handle seasonality directly in the model and allows for a straightforward specification with only three parameters for opens and one for clicks. By limiting the number of parameters, we make the best use of our limited data and produce parameters that are directly interpretable.</p><p>Another benefit of our time transformation is that by making each campaign independent of the time of day, it is possible to compare results across campaigns, and to easily build informative priors for each of the parameters. This yields a procedure that produces meaningful estimates and confidence intervals with a minimal amount of data. It also allows a firm to conduct tests serially. That is, the firm could choose to modify either a campaign's creative or target population as the result of a test, then retest the campaign and compare the new results to the first.</p><p>Overall, by putting these three elements together, the model is capable of running a test in one hour and fifteen minutes that produces similar results to a traditional test in 14 hours (a 91% decrease in testing time). The model can be estimated within a matter of seconds, and could therefore be used in real time. Thus, our methodology can be used not only for testing but also for live monitoring. A manager could terminate an underperforming campaign early or change the campaign's creative midstream. If done right, this could significantly improve average response rates by limiting the detrimental impact of poor performing campaigns.</p><p>Our model represents a first step towards better online marketing testing. As such, we see several avenues for further research in this area. For instance, because of the lack of individual level information in our data set, we could not include covariates in our models. It is likely that adding such information, when available, would improve the fit and predictive power of the model. Further, if the data set contained many data points per recipient (we have an average of two e-mails sent per name) it would be possible to incorporate unobserved heterogeneity.</p><p>One could also include campaign covariates in the model to account for the fact that different movies will appeal to different audiences. We attempted to do so by using different priors for different genres of movies (e.g., action, romance, and others). However, because of the small number of campaigns at our disposal the analysis did not produce meaningful results (the details of the analysis and the results are reported in the Technical Appendix, which can be found at http://mktsci.pubs.informs.org).</p><p>Another issue is the link between click and purchase behavior. The assumption is that click behavior is a measure of interest and is highly correlated to purchase. As many campaign managers are evaluated based on clicks, we feel our analysis is appropriate. However, in future applications and with better data, it should be possible to link click and purchase behavior, and thus optimize purchases rather than clicks.</p><p>In conclusion, our model has demonstrated strong performance advantages over extant methods used in practice. Our methodology leverages features unique to e-mail as a form of direct marketing. These features include compressed-time intervals available for testing, near real-time response measurement, and individual recipient tracking. Beyond e-mail marketing, emerging technologies in marketing that also share these characteristics (e.g., mobile phone communications) could benefit from the testing methodology developed in this paper.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>252</head><label></label><figDesc>Marketing Science 28(2), pp.251-263, © 2009 INFORMS    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 1Histograms of Elapsed Time Between Sent and Open (a) and Between Open and Click (b) Events, Across All Campaigns 300</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 2 Distribution of E-mail Opens Through the Day (Pacific Standard Time) 200 180 160 140 120 100 80 60 40 20 0 00:00 04:00 08:00 12:00 16:00 20:00 Time of day</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3</head><label>3</label><figDesc>Figure 3Distribution of E-mail Sends Through the Day (Pacific Standard Time)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>e k , where e is a superscript identifying different campaigns, and the subscript k denoting an open (k = o) or click (k = c). The likelihood function is constructed as follows. We start with a basic censored hazard rate model of the open or click time distribution:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Marketing</head><label></label><figDesc>Science 28(2), pp. 251-263, © 2009 INFORMS Then the likelihood component for action k at censor time T e is</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>For a given</head><label></label><figDesc>campaign, we use the method of moments to estimate the parameters (a o b o a c b c Corr Open Click o o o o ) based on the parameters ( o o o c c c ) obtained from all other campaigns. The correlation, LN , between parameters</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>4.1.1. Predictive Performance of the Models. The full results for each campaign and each censoring point consist of a set of parameters ( clicks. To assess the performance of the models in the precampaign tests, we calculate the mean absolute deviation (MAD) for the predicted number of clicks and opens at each censoring point. The MAD expresses the absolute prediction error in terms of the number of clicks and number of opens averaged across campaigns and is calculated by comparing the predicted opens and clicks with the true opens and clicks.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 5</head><label>5</label><figDesc>Figure 5Test Length as a Function of Time of Day</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell cols="3">Campaign Summary Statistics</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Mean</cell><cell>Minimum</cell><cell>Maximum</cell><cell>Std. dev.</cell></row><row><cell>E-mails</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sent/campaigns</cell><cell>24,681</cell><cell>5,171</cell><cell>84,465</cell><cell>20,393</cell></row><row><cell>Opens/campaigns</cell><cell>4,457</cell><cell>600</cell><cell>13,116</cell><cell>3,877</cell></row><row><cell>Clicked/campaigns</cell><cell>387</cell><cell>53</cell><cell>1,444</cell><cell>360</cell></row><row><cell>Open rate</cell><cell>0 181</cell><cell>0 081</cell><cell>0 351</cell><cell>0 073</cell></row><row><cell>Click-through | open</cell><cell>0 096</cell><cell>0 035</cell><cell>0 303</cell><cell>0 061</cell></row><row><cell>Click-through rate</cell><cell>0 016</cell><cell>0 005</cell><cell>0 105</cell><cell>0 021</cell></row><row><cell>Doubling time (hours)</cell><cell>13 76</cell><cell>4</cell><cell>29</cell><cell>5 57</cell></row><row><cell>First open (minutes)</cell><cell>6 41</cell><cell>0 07</cell><cell>14 68</cell><cell>2 08</cell></row><row><cell>First click (seconds)</cell><cell>2 08</cell><cell>1 0</cell><cell>6 0</cell><cell>1 656</cell></row><row><cell>Number of campaigns</cell><cell>25</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Note. All campaign statistics are reported based on real time.</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head></head><label></label><figDesc>Bonfrer and Drèze: Real-Time Evaluation of E-mail Campaign Performance</figDesc><table><row><cell>Marketing Science 28(2), pp. 251-263, © 2009 INFORMS</cell><cell>257</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head></head><label></label><figDesc>Open 504 =ˆ e o × F 504 hours</figDesc><table><row><cell>e o</cell><cell>ˆ e o × (Number</cell></row><row><cell>sent for campaign e), and</cell><cell></cell></row><row><cell>(2) Click 504 =ˆ e c × F 504 hours e c</cell><cell>ˆ e c × (Estimated</cell></row><row><cell>opens for campaign e).</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 2</head><label>2</label><figDesc>Mean Absolute Deviation (MAD), by Model, for Split-Hazard Parameters and for Selected Censoring Points</figDesc><table><row><cell>Method</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Notes. For the doubling time method, MAD at 14 hours for clicks is 156.7 and for opens it is 917.5. MAD numbers in boldface indicate the first time (in 30-minute increments) that the model outperforms the doubling time method.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>))</cell></row><row><cell>0:30</cell><cell>2 308 7</cell><cell>2 545 8</cell><cell>258 411</cell><cell>254 6</cell><cell>293 9</cell><cell>303 5</cell></row><row><cell>1:00</cell><cell>1 522 6</cell><cell>2 084 4</cell><cell>185 152</cell><cell>181 8</cell><cell>249 8</cell><cell>254 9</cell></row><row><cell>1:30</cell><cell>1 222 3</cell><cell>1 791 5</cell><cell>170 594</cell><cell>176 2</cell><cell>199 3</cell><cell>201 2</cell></row><row><cell>2:00</cell><cell>1 165 1</cell><cell>1 446 2</cell><cell>187 473</cell><cell>195 2</cell><cell>167 7</cell><cell>167 1</cell></row><row><cell>2:30</cell><cell>1 161 4</cell><cell>1 110 4</cell><cell>161 224</cell><cell>165 2</cell><cell>146 4</cell><cell>148 8</cell></row><row><cell>3:00</cell><cell>1 101 5</cell><cell>906 6</cell><cell>147 196</cell><cell>148 1</cell><cell>121 7</cell><cell>122 1</cell></row><row><cell>3:30</cell><cell>977 9</cell><cell>763 7</cell><cell>128 365</cell><cell>129 5</cell><cell>9 9 8</cell><cell>100 0</cell></row><row><cell>4:00</cell><cell>914 5</cell><cell>703 9</cell><cell>126 8</cell><cell>128 7</cell><cell>9 5 5</cell><cell>9 5 2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_10"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell cols="4">Results from the Decision Rule Simulation</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell cols="2">Rule 1 Rule 2</cell><cell>Rule 3</cell><cell>Rule 4</cell></row><row><cell></cell><cell></cell><cell cols="4">Doubling Horse Proposed Adaptive</cell></row><row><cell></cell><cell cols="2">Actual method</cell><cell>race</cell><cell>model</cell><cell>model</cell></row><row><cell>Number of campaigns</cell><cell>7</cell><cell>11</cell><cell>14</cell><cell>7</cell><cell>6</cell></row><row><cell>selected</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>True positives</cell><cell></cell><cell>7</cell><cell>6</cell><cell>6</cell><cell>6</cell></row><row><cell>False positive</cell><cell></cell><cell>4</cell><cell>8</cell><cell>1</cell><cell>0</cell></row><row><cell>False negative</cell><cell></cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell></row><row><cell>Average testing</cell><cell></cell><cell>14:00</cell><cell>02:30</cell><cell>02:30</cell><cell>02:57</cell></row><row><cell>time (hours)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Minimum testing time</cell><cell></cell><cell>14:00</cell><cell>02:30</cell><cell>02:30</cell><cell>01:00</cell></row><row><cell>Maximum testing time</cell><cell></cell><cell>14:00</cell><cell>02:30</cell><cell>02:30</cell><cell>06:00</cell></row><row><cell>Click-through rate (%)</cell><cell>4.45</cell><cell>3.34</cell><cell>2.66</cell><cell>4.29</cell><cell>4.77</cell></row><row><cell>Improvement over no</cell><cell>123</cell><cell>67</cell><cell>33</cell><cell>114</cell><cell>139</cell></row><row><cell>rule (%)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Revenue per e-mail</cell><cell>0.027</cell><cell>0.016</cell><cell>0.009</cell><cell>0.025</cell><cell>0.031</cell></row><row><cell>sent ($)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Revenue per name</cell><cell>0.190</cell><cell>0.172</cell><cell>0.122</cell><cell>0.178</cell><cell>0.183</cell></row><row><cell>(= revenue per e-mail</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>sent × no. of</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>campaigns) ($)</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Bonfrer and Drèze: Real-Time Evaluation of E-mail Campaign Performance Marketing Science 28(2), pp. 251-263, © 2009 INFORMS</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We thank an anonymous reviewer for proposing this alternative methodology.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>This research was funded in part by the Wharton-SMU Research Centre, Singapore Management University, and in part by a Wharton e-Business Initiative (WeBI)-Mack Center grant. The authors thank Eric Yorkston for suggesting computing the optimal testing time.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Modeling movie life cycles and market share</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Drèze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zufryden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="508" to="517" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mailing decisions in the catalog sales industry</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">D</forename><surname>Bitran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">V</forename><surname>Mondschein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1364" to="1381" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">An empirical investigation of advertising wearin and wearout</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">H</forename><surname>Blair</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Advertising Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="45" to="50" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A model of web site browsing behavior estimated on clickstream data</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">E</forename><surname>Bucklin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Sismeiro</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">33</biblScope>
			<biblScope unit="page" from="249" to="267" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Optimal selection for direct mail</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Bult</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Wansbeek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="378" to="394" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Point estimation under asymmetric loss functions for left-truncated exponential samples</title>
		<author>
			<persName><forename type="first">R</forename><surname>Calabria</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Pulcini</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comm. Statist. Theory Methods</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="585" to="600" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Bacon with your eggs? Applications of a new bivariate beta-binomial distribution</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Danaher</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">G S</forename><surname>Hardie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. Statistician</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="282" to="286" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m">Direct Marketing Association. 2005. The DMA 2005 response rate report</title>
				<meeting><address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>Direct Marketing Association</publisher>
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Internet advertising: Is anybody watching?</title>
		<author>
			<persName><forename type="first">X</forename><surname>Drèze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F.-X</forename><surname>Hussherr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Interactive Marketing</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="8" to="23" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">A Web-based methodology for product design evaluation and optimization</title>
		<author>
			<persName><forename type="first">X</forename><surname>Drèze</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Zufryden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Oper. Res. Soc</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1034" to="1043" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Optimizing Rhenania&apos;s mail-order business through dynamic multilevel modeling (DMLM) in a multicatalog-brand environment</title>
		<author>
			<persName><forename type="first">R</forename><surname>Elsner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Krafft</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Huchzermeier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="192" to="206" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">How to compute optimal catalog mailing decisions</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gönül</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><forename type="middle">Ter</forename><surname>Hofstede</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="65" to="74" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Real-Time Evaluation of E-mail Campaign Performance</title>
		<author>
			<persName><forename type="first">Drèze</forename><surname>Bonfrer</surname></persName>
		</author>
		<idno>INFORMS 263</idno>
	</analytic>
	<monogr>
		<title level="j">Marketing Science</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="251" to="263" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Optimal mailing of catalogs: A new methodology using estimable structural dynamic programming models</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gönül</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1249" to="1262" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Mailing smarter to catalog customers</title>
		<author>
			<persName><forename type="first">F</forename><surname>Gönül</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B.-D</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Z</forename><surname>Shi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Interactive Marketing</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="2" to="16" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Principles of Internet Marketing</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Hanson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<publisher>South-Western College Publishing</publisher>
			<pubPlace>Cincinnati</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Strategic Database Marketing</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Hughes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<publisher>McGraw-Hill</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
	<note>3rd ed</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Investigating household purchase timing decisions: A conditional hazard function approach</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">C</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">J</forename><surname>Vilcassim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="23" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Distributions in Statistics Continuous Multivariate Distributions</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">L</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kotz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1972" />
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">The Statistical Analysis of Failure Time Data</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Kalbfleisch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">L</forename><surname>Prentice</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1985" />
			<publisher>John Wiley &amp; Sons</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Identifying innovators for the cross-selling of new products</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">A</forename><surname>Kamakura</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">S</forename><surname>Kossar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Wedel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1120" to="1133" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Properties and applications of the Sarmanov family of bivariate distributions</title>
		<author>
			<persName><forename type="first">M.-L</forename><forename type="middle">T</forename><surname>Lee</surname></persName>
		</author>
		<ptr target="http://www.informaworld.com/smpp/content∼content=a780019996∼db=all" />
	</analytic>
	<monogr>
		<title level="j">Comm. Statist. Theory Methods</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1207" to="1222" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">How T.V. advertising works: A meta-analysis of 389 real world split cable T.V. advertising experiments</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">M</forename><surname>Lodish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Abraham</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Kalmenson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Livelsberger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lubetkin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Richardson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">E</forename><surname>Stevens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="125" to="139" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Using advance purchase orders to forecast new product sales</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Moe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">S</forename><surname>Fader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="347" to="364" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Direct Marketing</title>
		<author>
			<persName><forename type="first">E</forename><surname>Nash</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Testimator of the scale parameter of the exponential distribution using LINEX loss function</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">N</forename><surname>Pandey</surname></persName>
		</author>
		<ptr target="http://www.informaworld.com/smpp/content∼content=a780134236∼db=all" />
	</analytic>
	<monogr>
		<title level="j">Comm. Statist. Theory Methods</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="2191" to="2202" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Performance regimes and marketing policy shifts</title>
		<author>
			<persName><forename type="first">K</forename><surname>Pauwels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Hanssens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="293" to="311" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Seasonal marketing and timing introductions</title>
		<author>
			<persName><forename type="first">S</forename><surname>Radas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Shugan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="296" to="315" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Pre-test-market evaluation of new packaged goods: A model and measurement methodology</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">J</forename><surname>Silk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Urban</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="171" to="191" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A split hazard model for analyzing the diffusion of innovations</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">V</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chandrashekaran</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="116" to="127" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Massively categorical variables: Revealing the information in zip codes</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">J</forename><surname>Steenburgh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ainslie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">H</forename><surname>Engebretson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="40" to="57" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Technology innovation and implications for customer relationship management</title>
		<author>
			<persName><forename type="first">B</forename><surname>Sun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="594" to="597" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Pre-test-market models: Validation and managerial implications</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Katz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="234" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">The impact of the internet on data collection</title>
		<author>
			<persName><forename type="first">R</forename><surname>Weible</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wallace</surname></persName>
		</author>
		<editor>P. S. Richardson</editor>
		<imprint>
			<date type="published" when="2001" />
			<publisher>McGraw-Hill</publisher>
			<biblScope unit="page" from="274" to="281" />
			<pubPlace>Irwin, Boston</pubPlace>
		</imprint>
	</monogr>
	<note>Internet Marketing Readings Online Resources</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Bayesian estimation and prediction using asymmetric loss functions</title>
		<author>
			<persName><forename type="first">A</forename><surname>Zellner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">394</biblScope>
			<biblScope unit="page" from="446" to="451" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
