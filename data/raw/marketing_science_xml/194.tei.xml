<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Effect of Calorie Posting Regulation on Consumer Opinion: A Flexible Latent Dirichlet Allocation Model with Informative Priors</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date>Jul Nov Mar Jul Nov Jul Mar Nov Mar Jul Nov Mar 2007 2008 2009 2010</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Dinesh</forename><surname>Puranam</surname></persName>
							<email>puranam@marshall.usc.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Marshall School of Business</orgName>
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<postCode>90089</postCode>
									<settlement>Los Angeles</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vishal</forename><surname>Narayan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">NUS Business School</orgName>
								<orgName type="institution">National University of Singapore</orgName>
								<address>
									<postCode>119245</postCode>
									<country key="SG">Singapore</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Vrinda</forename><surname>Kadiyali</surname></persName>
							<email>kadiyali@cornell.edu</email>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Samuel Curtis Johnson Graduate School of Management</orgName>
								<orgName type="institution" key="instit2">Cornell University</orgName>
								<address>
									<postCode>14853</postCode>
									<settlement>Ithaca</settlement>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<persName><forename type="first">Pradeep</forename><surname>Chintagunta</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Dominique</forename><surname>Hanssens</surname></persName>
						</author>
						<author>
							<persName><forename type="first">John</forename><surname>Hauser</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Robert</forename><surname>Mcculloch</surname></persName>
						</author>
						<title level="a" type="main">The Effect of Calorie Posting Regulation on Consumer Opinion: A Flexible Latent Dirichlet Allocation Model with Informative Priors</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
						<imprint>
							<date type="published">Jul Nov Mar Jul Nov Jul Mar Nov Mar Jul Nov Mar 2007 2008 2009 2010</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.2017.1048</idno>
					<note type="submission">Received: December 17, 2013 Revised: October 31, 2014; April 3, 2016; January 14, 2017 Accepted: February 4, 2017</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Bayesian estimation</term>
					<term>data mining</term>
					<term>word-of-mouth The Effect of Regulation on Consumer Opinion</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In 2008, New York City mandated that all chain restaurants post calorie information on their menus. For managers of chain and standalone restaurants, as well as for policy makers, a pertinent goal might be to monitor the impact of this regulation on consumer conversations. We propose a scalable Bayesian topic model to measure and understand changes in consumer opinion about health (and other topics). We calibrate the model on 761,962 online reviews of restaurants posted over eight years. Our model allows managers to specify prior topics of interest such as "health" for a calorie posting regulation. It also allows the distribution of topic proportions within a review to be affected by its length, valence, and the experience level of its author. Using a difference-in-differences estimation approach, we isolate the potentially causal effect of the regulation on consumer opinion. Following the regulation, there was a statistically small but significant increase in the proportion of discussion of the health topic. This increase can be attributed largely to authors who did not post reviews before the regulation, suggesting that the regulation prompted several consumers to discuss health in online restaurant reviews.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>In the face of rising obesity, Mayor Michael Bloomberg of New York City pushed a regulation in 2008 that required chain restaurants (those with 15 or more units nationwide) to display calories for every item on all menu boards and menus in a font that was at least as prominent as the price. Two years later, the Affordable Health Care Act of 2010 mandated that restaurants with multiple locations prominently display calories for every item on all menus. The desired impact of both of these laws was to make it easier for consumers to choose healthier foods, as posting calorific information should make health more salient in the minds of consumers when eating out. Implementing this national regulation "has gotten extremely thorny," in the words of the Commissioner of the Food and Drug Administration <ref type="bibr">(FDA)</ref>. "There are very, very strong opinions and powerful voices both on the consumer and public health side, and on the industry side, and we have worked very hard to figure out what really makes sense" <ref type="bibr" target="#b23">(Jalonick 2013)</ref>.</p><p>Past research has shown us that regulations pertaining to health claims on food labels affect consumer search and behavior in various ways <ref type="bibr" target="#b34">(Roe et al. 1999</ref><ref type="bibr" target="#b8">, Bollinger et al. 2011</ref><ref type="bibr" target="#b15">, Downs et al. 2013</ref>. Unlike these papers, we focus on consumers' postconsumption opinions of the product. Our data are 761,962 reviews of 9,805 restaurants in New York City, posted on a leading restaurant review site 1 in an eight-year period from the website's inception in October 2004 to December 2012. Online reviews remain in the public domain for long time periods and can be leading indicators of future trends in consumption behavior. We are unaware of studies that estimate the impact of regulation changes on consumer opinion or word of mouth.</p><p>We propose an automated and scalable probabilistic model that summarizes this large volume of free, unsolicited, rich user-generated reviews into a few interpretable topics. These topics can offer managerial and policy insights into how consumer opinion or the "voice of the consumer" <ref type="bibr" target="#b20">(Griffin and</ref><ref type="bibr">Hauser 1993, Lee and</ref><ref type="bibr" target="#b26">Bradlow 2011)</ref> was influenced by the implementation of a calorie posting regulation in New York City. Traditional approaches to measure the effects of regulations, such as surveys and focus groups, might be expensive, time consuming, and potentially subject to recall biases and demand effects <ref type="bibr" target="#b33">(Netzer et al. 2012)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Puranam, Narayan, and Kadiyali: The Effect of Regulation on Consumer Opinion</head><p>Marketing <ref type="bibr">Science, 2017</ref><ref type="bibr">, vol. 36, no. 5, pp. 726-746, © 2017</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>727</head><p>Unlike such approaches, which rely on primary data collected over a short time, our data are available over several years. Therefore, relative to primary data collection, our approach is especially useful for studying the impact of temporally distant events (such as past regulations) by comparing periods before and after such events. A long time series also allows us to study shortand long-term effects of the focal event. <ref type="bibr">2</ref> Based on our data and methods, we pose and answer the following managerially-and policy-relevant questions about online reviews of chain restaurants:</p><p>(a) What were the major topics or attributes of chain restaurants that consumers discussed in online reviews before and after the mandatory calorie posting regulation was enforced?</p><p>(b) Was health a topic of discussion before and after the regulation? If so, what proportion of this discussion was on health? Which topics were discussed to a larger extent relative to health?</p><p>(c) Was health a topic of discussion for a few reviewers, or was the discussion widespread across several reviewers? Did this distribution change after the regulation?</p><p>Our analysis provides the following managerial and regulatory insights: First, should there be a postregulation increase in health as a topic of discussion by a large set of consumers, this can be seen as a measure of the regulation's success in making health more salient in the minds and voices of consumers. Second, textual content posted in online consumer reviews affects subsequent demand <ref type="bibr" target="#b2">(Archak et al. 2011</ref><ref type="bibr" target="#b18">, Ghose et al. 2012</ref>. That is, we might expect a greater discussion of health across a large number of online reviews to be accompanied by an increased consumption of healthier foods. Third, changes in patterns of consumer opinion can provide continuous, timely, and free inputs into more traditional forms of marketing research. Increased discussion of health in online reviews can serve as a basis for commissioning costlier investigations into changes in consumer buying behavior. Fourth, how widespread health discussion is (i.e., variance in how deeply reviews discuss health as a topic, conditional on the mean level of health topics across reviews) can provide insights into consumer segments (e.g., a small segment of reviewers dominating the health discussion versus a large segment of reviewers discussing health albeit to a small extent). Such information can also serve as the basis of studies aimed at identifying individuals who might influence restaurant choices of the population, and at ascertaining the demographic correlates of those individuals who are most vocal about health. Note that there is also a widespread media discussion of health and in particular this regulation; we confine ourselves to the analysis of consumers' postconsumption data for the reasons outlined above.</p><p>We now briefly discuss our model and research design. Our model belongs to a class of probabilistic topic models termed Latent Dirichlet Allocation (LDA) models <ref type="bibr" target="#b6">(Blei et al. 2003)</ref>, which have been developed by computer scientists (specifically in the machine learning discipline) to analyze words in large sets of original text to discover the themes or topics within. We summarize a large collection of reviews into a few representative latent topics (e.g., price, service, menu item, cuisine) and characterize these topics by a probability distribution over all words in reviews. For the position of each word in a review, a topic is first chosen. Conditional on the choice of topic, a word is chosen from the vocabulary to take that position. This process continues until the review adequately represents the topics of interest of the writer. Each review is composed of a random mixture of several topics (e.g., a restaurant review could be simplistically represented as 20% price, 20% service, and 60% Mexican cuisine). This process represents a probabilistic interpretation of the data generation process for the observed reviews. Estimation challenges arise because (a) we do not observe the topics, (b) the same word could belong to different topics necessitating a flexible modeling approach, and (c) the large scale of the data (761,962 reviews) necessitates scalable estimation techniques.</p><p>Because the scope of the regulation was limited to chain restaurants, we analyze data from chain and standalone restaurants separately, such that standalone restaurants serve as a useful contrast and as a natural control group. <ref type="bibr">3</ref> To isolate the causal effects of the regulation on consumer opinions in chain restaurants, we control for differences in characteristics between chain and standalone restaurants, for differences in reviews of all restaurants between the two time periods (before and after the regulation), and for geographical differences in topic proportions (via zip code dummies). We conduct several additional tests for robustness of causal inference. In sum, we combine current methods from computer science with causal inference techniques.</p><p>Within the existing research, our paper is related to the literature on extracting useful information from large masses of text of reviews <ref type="bibr" target="#b12">(Decker and</ref><ref type="bibr">Trusov 2010, Ghose et al. 2012)</ref>. Methodologically, our work is close to four papers. <ref type="bibr" target="#b26">Lee and Bradlow (2011)</ref> automatically extract phrases from consumer reviews, which are then rendered into word vectors that record the frequencies with which words appear in the corresponding phrase. Phrases are clustered according to their similarity, measured as the distance between the word vectors. <ref type="bibr" target="#b33">Netzer et al. (2012)</ref> use a similar approach, with the difference being that they define similarity between products based on their co-mention in the data. <ref type="bibr" target="#b37">Tirunillai and Tellis (2014)</ref> apply the LDA model on consumer reviews to infer the latent dimensions <ref type="bibr">Marketing Science, 2017</ref><ref type="bibr">, vol. 36, no. 5, pp. 726-746, © 2017</ref> of product quality, to understand brands positions on these dimensions, and to estimate how dimensions and brand positions vary over time. <ref type="bibr" target="#b9">Büschken and Allenby (2016)</ref> propose an LDA model that uses the sentence structure of reviews, leading to improved prediction of consumer ratings.</p><p>Our model generalizes previous marketing approaches for extracting topics in two important ways. First, managers or policy makers might have informed priors about how consumer opinions might change due to specific events. For example, the enforcement of a new sales tax might alter the level of discussion of "price" as a topic when consumers review the focal product online. In the papers discussed above, words or phrases are allocated to topics, and topics are interpreted by the researcher. By contrast, our approach allows the analyst to prespecify constructs or topics of interest, and to then track changes in consumer opinion as it pertains to those topics. This is achieved by specifying an informative prior distribution of topics over the words in the vocabulary. This enables us to parsimoniously integrate managerial intuition and interest with information from thousands of reviews. Combining managerial intuition with statistical modeling has a long tradition in marketing and psychology, and has even been shown to improve model fit compared with purely statistical modeling <ref type="bibr" target="#b39">(Yaniv and</ref><ref type="bibr">Hogarth 1993, Wierenga 2006)</ref>. For example, <ref type="bibr" target="#b4">Blattberg and Hoch (1990)</ref> show that out-of-sample sales forecasts at the stock-keeping unit (SKU) level improve substantially when data pertaining to product characteristics and price are combined with managers' intuitions about these forecasts.</p><p>Second, current marketing and computer science research assumes that the distribution of topics in a document is independent of the author's decision on how many words to write. We allow topic distributions to vary with the length of the document, its valence, and its author's experience. Other than improved model performance, allowing topic distributions to vary by the length of the review, and other characteristics has substantive implications. Authors of reviews focused solely on health are more likely to lead consumer opinion on health, and to be more important than the general reviewing population for targeting. To the extent that shorter reviews are more likely to discuss one or only a few topics, the length of a review might be an important summary statistic of user-generated content to consider in identifying such reviews and reviewers.</p><p>From a substantive standpoint, our identification strategy (i.e., comparing reviews of chain restaurants before and after the regulation to reviews of the control group of standalone restaurants) helps us use textual data to make causal inferences of the impact of the regulation on consumer postconsumption reviews.</p><p>We complement recent research on temporal dynamics in the ratings and textual content of online reviews <ref type="bibr" target="#b37">(Tirunillai and</ref><ref type="bibr">Tellis 2014, Godes and</ref><ref type="bibr" target="#b19">Silva 2013)</ref>, by inferring how levels of discussion of various topics vary over time (and across locations) due to an exogenous event. Our work also complements academic research on the effect of the calorie posting regulation on consumer behavior <ref type="bibr" target="#b8">(Bollinger et al. 2011</ref><ref type="bibr" target="#b15">, Downs et al. 2013</ref>. Such research provides insights from survey and transactional data from a single chain of restaurants (e.g., Starbucks for <ref type="bibr" target="#b8">Bollinger et al. 2011)</ref>. Our data are from 9,805 restaurants including 77 unique chains, and we focus on postconsumption opinions.</p><p>Because the backdrop for the regulation is concerns over rising obesity, we can safely conjecture that there was a need for regulation since consumers are likely not as health-aware. Therefore, our expectation is that before regulation, the discussion of health topics in reviews was likely to be small; thus, the uptick in health discussion will not be large. Indeed, we find that health is discussed only in a small proportion of reviews (less than 7%). This proportion increased for chain restaurants after the regulation, but not for standalone restaurants, suggesting that the regulation increased the salience of health among a small segment of health-conscious consumers. Given the overall trends of increasing obesity in the United States, even small postregulation increases in the health topic discussion in restaurant reviews might be cause for celebration and offer the potential for significant long-term implications (see Section 4 for details). We also find that much of the increase in health topic discussion post regulation can be attributed to a small segment of new authors.</p><p>Next, we discuss the model specification. Section 3 presents the data, and discusses specific estimation challenges. Section 4 presents the results from the model, and their implications. Section 5 provides concluding remarks.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Model</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Model Specification</head><p>We start with some standard definitions and notation. A corpus is a concatenation of all documents (i.e., reviews) in the data set. Each document d (d 1, . . . , D) is composed of n d words. The number of total word instances in the corpus is N. The corpus is therefore defined by an N-dimensional vector w {w 11 , w 12 , . . . , w di , . . . , w Dn D }, where w di is the ith word of document d. A vocabulary is the set of V unique words across all documents; each word is denoted by v. Each word in the vocabulary belongs to each topic, such that topic φ k (k 1, . . . , K) is a probability distribution over all v in {1, 2, . . . , V }. Element φ kv denotes the probability of word v given topic k. Document d is a mixture of the K topics. A K-dimensional vector (θ d ) represents the proportions of each topic in document d.</p><p>We briefly describe our textual data to enable a better understanding of the model. The mean length of all 761,962 reviews is 126.7 words <ref type="bibr">(SD 109.6</ref>). Each sentence is split into its component words using the Natural Language Toolkit's Tokenizer <ref type="bibr" target="#b3">(Bird et al. 2009</ref>). After eliminating stop words ("a," "the," etc.) and words that occurred fewer than five times in the entire corpus <ref type="bibr">Steyvers 2004, Lu et al. 2011</ref>) the number of unique words in the corpus is 44,276. Although the calorie posting regulation was implemented over a few months, we assume July 1, 2008 as the implementation date for comparing pre-and post-regulation consumer opinion. We discuss the robustness of our results to this assumption in Section 4.3.</p><p>The LDA model assumes a generative process by which the textual data in each document is generated. Topic proportion θ d is drawn from a Dirichlet distribution with K-dimensional parameter vector α d . The topic assignment z di for the word i in document d is drawn from a categorical distribution with parameter θ d . Given the topic assignment z di , the word i in document d is drawn from a categorical distribution associated with the assigned topic. To exploit conjugacy, each topic distribution is also specified Dirichlet with hyperparameter β. This process is repeated for each word in each document. It ignores the order of words in a document, i.e., LDA is a "bag-of-words" model <ref type="bibr" target="#b16">(Eliashberg et al. 2007</ref><ref type="bibr" target="#b33">, Netzer et al. 2012</ref>. The generative process for document d can be summarized as follows:</p><p>(</p><formula xml:id="formula_0">a) θ d | α d ∼ Dirichlet(α d ). (b) z di | θ d ∼ Categorical(θ d ). (c) w di | (z di k), φ ∼ Categorical(φ k ) where φ [φ 1 , φ 2 , φ 3 , . . . , φ k ]. (d) φ k | β ∼ Dirichlet(β).</formula><p>The researcher does not observe the topics, the membership of words in each topic, the distribution of topics for each document or the choice of topic that led to a specific choice of a word. The central computational problem is to use the observed documents to infer these distributions. The process described above defines a joint probability distribution over the observed and hidden random variables. We use this joint distribution to compute the conditional (or posterior) distribution of the hidden variables given the observed documents and words.</p><p>The model described so far ignores document characteristics that might affect the distribution of topics. Longer documents might discuss more topics and therefore could have more evenly spread topic distributions. It is also plausible that authors writing for the first time discuss fewer topics than more experienced authors, suggesting that documents with similar levels of author experience might have similar topic distributions. Online reviews tend to be disproportion-ately positive in valence, so it is possible that authors posting negative reviews elaborate on more topics to better justify the negative evaluation. We incorporate these intuitions into our model by allowing the hyperparameter α d to vary with various observed characteristics of the document. More specifically, we allow α kd for topic k in document d to depend on the document's length (measured by the number of words), its valence (as captured by a five-point ordinal scaled numerical rating), and the past reviewing experience of the author (measured by the number of reviews in our data set posted by the author of document d, before she posted document d). This leads to the following specification:</p><formula xml:id="formula_1">α kd exp λ k0 + λ k1 n d + λ k2 e x d + λ k3 r 1d + λ k4 r 2d + λ k5 r 3d + λ k6 r 4d , (1)</formula><p>where n d is the number of words in document d; e x d is the experience of its author; r 1d , r 2d , r 3d , and r 4d are dummy variables that take the value 1 if the rating of document d is 1, 2, 3, and 4, respectively, and 0 otherwise. The exponential function preserves the positivity of the parameter. We allow the effects of metadata to vary across topics. If longer documents involve the discussion of more topics entailing a more evenly spread topic distribution, we expect λ k1 to be positive. <ref type="bibr">4</ref> Next, we address the central question of this research: How did the proportion of health topic discussion in online reviews change due to the regulation? Because the regulation was implemented for chain restaurants only, standalone restaurants fall outside of our domain of substantive interest, except as a control group for inferring the causal effect of the regulation on chain restaurants (which form the treatment group). To draw causal inference, we must compare changes (before versus after the regulation) in the same construct across the groups. This construct is the health topic proportion estimated on the treatment group, i.e., chain restaurants. We first estimate changes in health topic proportions in the treatment group, and then compare this to changes in the exact same topic in the control group. To identify the causal effect of the regulation on the proportion of health discussion, we implement a difference-in-differences methodology. We calculate the causal effect of a treatment (i.e., the regulation) on the outcome variable (proportion of health discussion) by comparing the average change in the outcome variable for the treatment group (chain restaurants) to the average change for the control group (standalone restaurants). We regress the outcome variable on two main effects (the effect of belonging to the treatment group on the outcome, and the effect of the treatment on the outcome), the interaction of these two effects, and several control variables, as follows:</p><formula xml:id="formula_2">θ kd υ 0k + υ 1k Chain d + υ 2k Post d + υ 3k Chain d _Post d + υ 4k ZipCode d + υ akd + υ f kd + ε kd ,<label>(2)</label></formula><p>Marketing <ref type="bibr">Science, 2017</ref><ref type="bibr">, vol. 36, no. 5, pp. 726-746, © 2017</ref> where θ kd is the proportion of topic k in document d (the outcome variable), and Chain d is the dummy variable that accounts for the effect of belonging to the treatment group. It controls for unobserved factors that might affect topic proportions of chain and standalone restaurants differently. The dummy variable Post d accounts for the effect of the treatment. It is possible that at the time of implementation of the regulation, there were unobserved events that affected topic proportions of all restaurants (including chains) in New York City. The main effect of Post d controls for how topic proportions for all restaurants changed after implementation of the regulation. The coefficient of the interaction term (Chain d _Post d ) captures the crucial effect of the treatment on the treatment group. Furthermore, we control for spatial variation (across locations in New York City), and temporal variation (over the duration of the data), in the health topic discussion in reviews of all restaurants in our data. To control for spatial variation, we note that our reviews represent restaurants from 134 zip codes. The term ZipCode d contains 133 dummy variables, all of which are zero, except the variable corresponding to the zip code of the focal restaurant, which takes the value 1. The random effect of author a of document d for topic k is captured by 5 υ akd and the random effect of restaurant f is captured by υ afd . Both effects are assumed to be normally distributed with zero mean.</p><p>We first estimate the model on reviews posted over four years (i.e., 16 quarters) starting July 1, 2006 (we show robustness to the choice of time periods in Section 4.3). This period was chosen so that the duration of time before and after July 1, 2008 (date of regulation implementation), is the same. Sixteen quarters correspond with 16 dummy variables, one for each quarter. The dummy variable corresponding to the quarter in which document d was posted takes the value 1; all others take the value 0. Furthermore, of the 16 dummy variables, 8 correspond to the post regulation period. The eight variables sum to the variable Post d . So, to avoid collinearity issues, we drop one of these eight variables. Similarly, the remaining eight dummy variables correspond to the pre regulation period. These eight variables sum to (1 − Post d ). So, we drop one of these eight dummy variables to avoid collinearity. Error terms are assumed independent and identically distributed (IID) and normally distributed. All parameters are topic-specific.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Model Estimation</head><p>We estimate the hyperparameters α d and β d , the document level topic proportions θ d , the vector of word level assignments of topics z d , the topic level parameter φ k , and the parameters associated with the regression model in Equation ( <ref type="formula" target="#formula_2">2</ref>). Assuming documents are conditionally IID, the likelihood of the data conditional on the hyperparameters is calculated as follows:</p><formula xml:id="formula_3">(L|α, β) D d 1 ∫ φ ∫ θ p(θ d | α d ) × p(φ | β) • n d i 1 K k 1 V v 1 [φ k, v × θ k d ] I(w id v) dφ dθ,<label>(3)</label></formula><p>where I is the indicator function, and α d is a K-dimensional vector with element exp(x t d λ k ). We face two estimation challenges: This function does not have a closed-formed analytical solution due to the product term involving φ k, v and θ k d <ref type="bibr" target="#b14">(Dickey 1983)</ref>, and the dimensionality of our parameter space is very high. The dimensionality problem stems from the large number of unique words in the corpus (V), the potentially large number of topics, and the large number of documents (note that θ d is document specific). Following the computer science literature <ref type="bibr" target="#b21">(Griffiths and Steyvers 2004)</ref>, instead of estimating φ k or θ d as parameters, we first estimate the posterior distribution of the assignment of words to topics, P(z | w) based on the equation P(z | w) P(z, w)/ z P(z, w). The numerator of the right-hand side (RHS) of this equation can be factorized and simplified as P(z, w) P(w | z)P(z). We now turn our attention to P(w | z) and P(z). Given the conjugacy between the distribution of observing word w given topic k and the Dirichlet prior (φ k | β ∼ Dirichlet(β), ∀ k), the posterior distribution of P(w | z) is as follows:</p><formula xml:id="formula_4">P(w | z) Γ(V β) Γ(β) V K K k 1 V v 1 Γ(β + n kv ) Γ(V β + n k ) ,<label>(4)</label></formula><p>where Γ( • ) is the standard gamma function. In Equation (4), n kv is the number of times the word v in the vocabulary is assigned to topic k in the corpus; n k is the number of words in the corpus which are assigned to topic k. Similarly, the conjugacy between the topic assigned to each word in a document (assumed to be a Categorical Distribution) and the Dirichlet prior (θ</p><formula xml:id="formula_5">d | α d ∼ Dirichlet(exp(x t d λ k ))</formula><p>) yields document specific topic assignments. These topic assignments are conditionally independent across documents and can be multiplied to yield Note that while P(z, w) may be factored and computed as described above, z P(z, w) cannot be computed directly because it does not factorize and involves K N terms, which is again computationally challenging. We thus adopt a Markov Chain Monte Carlo (MCMC) approach that relies on Gibbs sampling of the latent topic assignment variable z <ref type="bibr" target="#b21">(Griffiths and Steyvers 2004</ref>). <ref type="bibr">6</ref> The full conditional distribution of z is free of φ k and θ d , enabling us to estimate φ k and θ d by averaging the means of the posterior Dirichlet distributions across iterations from a single MCMC chain. <ref type="bibr">7</ref> The Gibbs sampling scheme for (2) can be derived from ( <ref type="formula" target="#formula_4">4</ref>) and ( <ref type="formula">5</ref>) as follows:</p><formula xml:id="formula_6">P(z i j | z −i , w) d ∝ n w j, −i + β V β + n j − 1 n d j, −i + exp(x t d λ j ) Σ k exp(x t d λ k ) + n d − 1 .<label>(6)</label></formula><p>In each Gibbs iteration, the probability of assigning topic j to the word w in position i in document d is proportional to the product of two ratios. The first ratio is the number of times word w was assigned topic j as a proportion of the total words assigned to topic j (adjusted for smoothing) in the entire corpus. The second ratio is the number of words in document d assigned to topic k as a proportion of the total number of words in the document d (adjusted for smoothing). Any topic assignment is thus a function of the corpus and the document.</p><p>We now describe how λ k is estimated. For each topic k, λ k is a topic specific M + 1 dimensioned vector of parameters, with prior distribution N(0, σ 2 I). <ref type="bibr">8</ref> The joint probability of z and λ can be written as follows:</p><formula xml:id="formula_7">P(z, λ) D d 1 Γ(Σ k exp(x t d λ k )) Π k (Γ(exp(x t d λ k ))) • K k 1 Γ(exp(x t d λ k ) + n kd ) Γ(Σ k exp(x t d λ k ) + n d ) • K k 1 M m 1 1 √ 2πσ 2 exp λ k, m 2σ 2 . (<label>7</label></formula><formula xml:id="formula_8">)</formula><p>We maximize the likelihood of the topic assignments for each word in the corpus with respect to the parameters λ k, m using the Stochastic Expectation Maximization (EM) <ref type="bibr" target="#b31">(Mimno and McCallum 2008)</ref>. This estimation algorithm consists of alternating between the MCMC iterations using (6) and the stochastic EM step where ( <ref type="formula" target="#formula_7">7</ref>) is maximized with respect to the parameters λ k, m . Instead of assuming that β is known <ref type="bibr" target="#b31">(Mimno and McCallum 2008)</ref>, we explicitly estimate the hyperparameter β, in addition to λ, to address this issue. See Online Appendix 1 for details.</p><p>Finally, we estimate Equation ( <ref type="formula" target="#formula_2">2</ref>) in each iteration of the MCMC sampler. In each iteration, we first obtain an estimate of the posterior mean of θ kd , and estimate the coefficients by regressing this iteration-specific estimate on the covariates. Posterior estimates of θ kd vary across iterations depending on their inherent variability. Low (high) posterior variance of θ kd would entail low (high) variability across iterations. In this way, we naturally accommodate the variability of θ kd in our analysis and inference. The estimation algorithm is implemented in MALLET 9 and was modified to accommodate seeding, to estimate β, and to generate output relevant for our analysis. The MCMC chain ran for 15,000 iterations, with the first 1,500 iterations for burn-in. We then estimate all hyperparameters (λ and β) every 100 iterations. The last 5,000 iterations (using a sampling lag of 10) yielded 500 samples that were used to compute the moments of the posterior parameter distributions. Identical results were obtained by computing the moments from 5,000 posterior draws.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.1.">Seeding.</head><p>Our model permits the researcher to specify words to belong to a topic, such that the seeded topic becomes a topic of central interest. The posterior parameter distributions can then be used to infer changes to the distribution of this topic across documents and over time. We seed a topic, which we simply label "health," by allowing the prior distribution φ k of this topic over the vocabulary to contain the following words or "seeds" with high probability: calorie, calories, fat, diet, health, healthy, light, fit, cardio, lean, and protein. This list is based on a review of Section 81.50 of the New York City Health Code that articulates the regulation. The words "calorie," "calories," and "health" are the most frequently occurring health related words in the policy document.</p><p>To initialize our data set, we randomly assign each word in each document to one of K topics. Note that in this stage of the estimation process, topics do not actually exist: We are simply labeling words to topic indices. Using this initial allocation of words to topics, we make an initial estimate of φ kv , the probability of word v given topic k. We count how many times each word in the vocabulary was assigned to topic k. We then compute n k , the total number of times any word was assigned to topic k. Suppose, for illustrative purposes, that n k for topic 0 is 1,000. Dividing the number of times each word was assigned to topic 0 by n k yields a probability distribution over the vocabulary.</p><p>To incorporate seeds, we randomly choose a topic (as topics are exchangeable this does not result in any loss of generality). For this "seeded" topic, we then increment the counts of n kv for each seed word v, thus increasing the prior probability of each seed word v in that topic. We call these incremental units pseudocounts. Intuitively, we are simply saying that these words were a priori assigned to this topic more often than a random initialization would indicate. As the Gibbs iterations proceed, the counts n kv and n k are</p><p>Marketing <ref type="bibr">Science, 2017</ref><ref type="bibr">, vol. 36, no. 5, pp. 726-746, © 2017</ref> updated, such that they could overwhelm the pseudocounts (i.e., their posterior estimates might differ considerably from the prior values). <ref type="bibr">10</ref> After some experimentation, we chose five as the value of this pseudocount in our application. This choice is sufficiently flexible to allow for the possibility that the posterior estimate of φ k will contain (a) seeds with low probability, and (b) other words with high probability. Given the large volume of data, this choice of pseudocounts does not affect the results. To verify this, we included a low frequency health-related word "cardio" as a seed. "Cardio" receives a low posterior probability assignment in the health topic and is not in the top 20 words used to describe the topic. In Section 4.3, we discuss the robustness of our results to the choice of seeds.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Analysis and Evaluation</head><p>We start by reporting the top 10 words across all reviews for chain restaurants in our data. In Figure <ref type="figure" target="#fig_0">1</ref>(A), we present their ranking, based on the frequency with which they appear in each of the four groups of interest: chain restaurants preregulation, chain restaurants postregulation, standalone restaurants preregulation, and standalone restaurants postregulation. For example, the word "salad" is the eighth most frequently appearing word in the reviews of chain restaurants posted before the regulation. We find the top 10 words are dominated by popular menu items (burger, fries), product attributes ($ possibly denotes price), and words connoting valence (good, love). None of these words explicitly reference health. Given the general view that health is not a very important consideration when eating out, this is not surprising. Although the words fries and steak (possibly connoting high calorie foods) rank higher (based on frequency of occurrence) in reviews of chain restaurants than in reviews of standalone restaurants, so does the word "salad," which is perhaps a healthier option. We do not discern any trends in frequency changes after the regulation from this figure, possibly because it pertains to just 10 of 44,276 unique words in our corpus. Extending this Figure <ref type="figure" target="#fig_0">1(A)</ref>. Most Frequently Occurring Words by Restaurant Type and Time Period analysis to 100 words did not reveal any other substantively useful insights. <ref type="bibr">11</ref> Next, we present a more granular time series plot by month of the top 10 most frequently occurring words in our data, as well as key words denoting health such as calorie, calories, fat, and nutrition. We present the frequencies of occurrence for each month divided by the number of reviews of chain restaurants posted in that month (Figure <ref type="figure" target="#fig_0">1</ref>(B)). The words "calories" and "calorie" occurred with greater frequency (per review) post regulation than earlier, providing model free evidence of the success of the calorie posting regulation. On the other hand, words potentially connoting unhealthiness such as "fat," "burger," and "fries" seem to occur with lower frequency (per review) post regulation.</p><p>Although this analysis is useful to obtain a preliminary sense of the data, it cannot be used to draw any meaningful or robust substantive inferences as to changes of consumer opinion due to the regulation. Because our objective is to infer topics of discussion from the data, analyses pertaining to counting specific words in the corpus, and how these frequencies vary over time are also not helpful. First, except for the health topic, it is a priori unclear which words or topics to look for in the corpus. Second, even if a reliable list of topics were available, any choice of words for measuring the level of discussion of specific topics would be subjective; results pertaining to levels of topic discussions and their changes are sensitive to such choices. LDA offers a data-based, replicable, objective, and principled methodology of inferring topics from text corpuses.</p><p>A major challenge in all topic models is the interpretability of estimated topics. Models with large numbers of topics typically fit the data better and can support finer-grained distinctions in the text. However, some topics are more interpretable than others in the judgment of domain experts. Furthermore, the number of less interpretable topics often increases with the number of topics <ref type="bibr" target="#b32">(Mimno et al. 2011)</ref>. Measures of model performance such as out-of-sample fit, although commonly used in marketing, do not correlate well with human judgments of topic interpretability <ref type="bibr" target="#b11">(Chang et al. 2009</ref>). This has led to an increased interest among computer scientists in developing automated metrics that can better predict topic interpretability. A useful insight from this research is that if a topic is highly interpretable (to humans), pairs of words with a high probability of association with this topic should frequently co-occur in several documents of the corpus. For example, a topic in which the words "healthy" and "vegetables" are highly probable is likely to be more interpretable or coherent if both of these words occur in several restaurant reviews. <ref type="bibr" target="#b32">Mimno et al. (2011)</ref> provide evidence for this result, and use it to develop a coherence metric for each topic. We now discuss how we choose the number of topics (K) and label each one. We maximize the dissimilarity between topics <ref type="bibr" target="#b13">(Deveaud et al. 2012</ref><ref type="bibr" target="#b10">, Cao et al. 2009</ref> by computing a distance between every pair of topics where each is a probability distribution across the vocabulary. We use the Jensen-Shannon statistic <ref type="bibr">(Lin 1991, Steyvers and</ref><ref type="bibr" target="#b36">Griffiths 2007)</ref> which is similar to the Kullback-Leibler divergence statistic <ref type="bibr" target="#b24">(Kullback and Leibler 1951)</ref>, except that it is symmetric (i.e., the order of distributions does not matter) and always takes finite values; these are desirable properties. On estimating our model for various values of K, we found that this statistic is maximum at K 200. All results therefore pertain to 200-topic models. Because not all topics are of substantive interest, we follow the computer science literature and restrict substantive inferences to a few coherent topics only <ref type="bibr" target="#b32">(Mimno et al. 2011</ref><ref type="bibr" target="#b1">, AlSumait et al. 2009</ref>. Specifically, we present 20 topics in Table 1(A), i.e., the seeded "health" topic discussed earlier, and 19 topics with the greatest values of the topic coherence metric (henceforth referred to as the top 19 topics). <ref type="bibr">12</ref> Coherence scores of all other topics are available from the authors. Following convention, each topic is represented by listing the most probable words in the topics <ref type="bibr" target="#b11">(Chang et al. 2009</ref><ref type="bibr" target="#b6">, Blei et al. 2003</ref>. We extend this principle to label topic k in terms of the two distinct words with the greatest posterior probability of belonging to that topic (per φ k ). Although other words associated with the topic are likely meaningful, we choose this method for its objectivity, conciseness, and because it does not require human intervention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Results and Implications</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Results</head><p>We first discuss the major topics of interest in our data. In Table <ref type="table" target="#tab_0">1</ref>(A), we present the top 10 words in decreasing order of posterior probability of being in each of the 20 topics, as inferred from the analysis of all reviews of chain restaurants. These comprise 19 topics that did better than other topics on established coherence metrics, and the "health" topic. <ref type="bibr">13</ref> Each topic is labeled by concatenating the two most probable words in the topic. First, we find that a substantial number of topics focus on specific menu items (e.g., steak:potatoes, bbq:chicken, burger:fries). Second, several topics focus on specific restaurant brands: Wolfgang (topic 6), Potbelly (topic 13), and Dominos (topic 15). Third, different aspects of service are captured across topics. Topic 5 captures service aspects unrelated to food (e.g., the words wireless, wifi, location, and access). Topic 14 alludes to nonfood related restaurant services (e.g., waitress, seated, check, server).</p><p>Next, we present the top 19 topics based on the means (across reviews of chain restaurants) of the posterior mean of the topic proportions θ d . Because there are 200 topics, in the absence of any information we might expect the proportion of each topic to be about 0.5%. Service related topics (e.g., place:good, time:back) and topics associated with American staple fast foods such as burgers, fries, and steak are discussed to a greater extent than the average topic (see Table <ref type="table" target="#tab_0">1(B)</ref>). The seeded health topic is discussed at about an average level. We note that several topics are common across the two tables, suggesting that more interpretable topics are discussed to a larger extent.</p><p>To understand how widespread the discussion of health is, we compute the proportion of chain restaurant reviews for which the health topic proportion is greater than the baseline topic proportion of 0.5%. We find that just 6.8% of such reviews contain the health topic to an extent greater than 0.5%. In as many as 63% of all reviews, the proportion of this topic is less than 0.05%. This is a general pattern in the data; the discussion of a specific topic is skewed such that a small proportion of all reviews account for most of the discussion. As examples, burger:fries and steak:potatoes are discussed in just 17.4% and 19.4% of all reviews of chain restaurants (to an extent of at least 0.5%). Figure <ref type="figure">2</ref> shows the relative frequency of occurrence of the top 20 words in each of the top 20 topics. See Online Appendix 2 for a list of the rest of the topics and Online Appendix 3 for further details on the extent of the discussion on each topic.</p><p>Figure <ref type="figure" target="#fig_2">3</ref> shows the temporal trends over a 48-month window of the posterior 95% of credible intervals of the mean of topic proportions (within a month) for the health topic separately for (a) chain restaurants, (b) standalone restaurants, and (c) the difference between the two. July 2008 is the approximate date of regulation implementation (marked by a vertical line). This visual representation suggests a minor increasing trend for health topic proportions for chain restaurants, a diminishing trend of health topic proportions for standalone restaurants, and much smaller credible intervals for topic proportions for standalone restaurants (this is enabled by the large number of reviews for standalone restaurants), and (d) an increasing trend of the difference in topic proportions of the chain and standalone restaurants. Whether this increase in the difference of health discussion between the types of restaurants is statistically significant, and whether this trend changes postregulation, is difficult to infer from these charts. See Online Appendix 4 for temporal trends in proportions for the top 19 topics. <ref type="bibr">14</ref> Next, we present the results of the difference-indifferences analyses for the health topic as specified in Equation (2), with key parameters presented in Table <ref type="table" target="#tab_3">2</ref>. Several insights emerge. First, after controlling for chain characteristics (compared to standalone restaurants), temporal trends, restaurant locations, and time-specific shocks, we find that the proportion of the  health topic in chain restaurants increases to a greater extent than in standalone restaurants, after the regulation (the coefficient of Chain d _Post d is positive). This can be construed as evidence supporting the success of the regulation. The proportions of topics connoting high calorie foods such as "steak:potatoes" and "burger:fries" also increase after implementation of the regulation. From the coefficients of Post, it is evident that topics related to brands such as Potbelly (sandwich:potbelly) and Chipotle (chipotle:burrito) garner a lower proportion of online reviews after July 1, 2008. Such trends can serve as informative signals for brand managers of the focal and competing brands. Lower online discussion of a brand might be a precursor to decreasing demand. However, we cannot draw inferences about    health discussion from topics other than the seeded health topic. The health topic, irrespective of whether it is seeded, contains the words calorie, calories, and health with high probabilities, and thus seems pertinent to studying the effect of the posting regulation. Now consider the econometrics of inferring topics. Our approach of inferring topics is based on maximizing the dissimilarity between topics by computing a distance between every pair of topics where each is a probability distribution over the vocabulary. It follows that the 199 topics other than the health topic are least similar to the health topic, and unsuitable for drawing inferences about health. Next, we investigate the source of increase in the proportion of health topic discussion in reviews of chain restaurants. Specifically, we ask if this increase is driven by a small number of authors who are very vocal about health, or by a relatively large number of reviewers who do not write as much about health. For this purpose, we focused on authors who posted at least one chain restaurant review in the data period. We classified each such author as a "high" or "low" discussant of "health," based on whether the mean health topic proportion of the reviews exceeds the overall mean health topic proportion (0.41%) in all <ref type="bibr">Marketing Science, 2017</ref><ref type="bibr">, vol. 36, no. 5, pp. 726-746, © 2017</ref>   <ref type="table" target="#tab_4">3</ref>, we present the number of "high" and "low" authors across the two periods. We find that in both time periods, less than 15% of all authors of reviews of chain restaurants are "high" discussants. This suggests that the increase in health topic proportion post regulation can be traced to a small group of authors. <ref type="bibr">15</ref> We then examined the health topic proportions of reviews posted in each of the four cells (high/low health discussants versus pre/postregulation). We find that the health topic proportion substantially increased post regulation in reviews posted by "high" health discussants (who are much fewer in number), and decreased for the much larger segment of "low" health discussants. This provides further evidence that the increase in health topic proportion can be attributed to a small segment of authors who generally write more (than the average) about health.</p><p>We next examine if this increase in health topic discussion post regulation is driven by authors who also posted reviews before the regulation or by new authors. We start by noting that in the post period, 825 authors posted reviews with above-average health topic discussion. Of these, as many as 802 did not post any review in the preimplementation period. Similarly, of the 5,683 authors who posted reviews with below average health topic discussion in the post period, 5,546 did not post any reviews in the preimplementation period. This suggests that the overall health discussion in the post implementation period and any increase from the pre period are driven by reviewers who did not review chain restaurants on the focal website before the regulation. In summary, we find that the increase in health topic discussion post regulation is due to reviews posted by a small proportion of authors who did not post reviews before the regulation. Finally, we discuss how the hyperparameter α kd that affects topic distributions for the health topic is affected by observed characteristics of reviews and the author. Parameter estimates pertaining to Equation (1) are shown in Table <ref type="table" target="#tab_5">4</ref>. As expected, we find that longer reviews have lower values of this parameter, suggesting a more evenly spread distribution of the health topic. The more negative the valence of the review, the lower is the value of α kd . This suggests that authors posting more negative reviews are more balanced in their discussion of the health topic versus other topics. Reviews posted by authors with more prior experience in writing reviews tend to be more focused on fewer topics of discussion. 16</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Dynamic Topic Model</head><p>The proposed model assumes that the topics themselves do not change over the duration of our data (i.e., the probability of word v given topic k is invariant over time). It is possible that the words representing a topic may evolve with time due to changes in word use. <ref type="bibr">17</ref> To verify this, we estimated a Dynamic Topic Model <ref type="bibr" target="#b5">(Blei and Lafferty 2006)</ref> by allowing φ tkv , the probability of word v given topic k in time period t to depend on the natural parameter of the same topic in the previous time period as follows: φ tkv | φ t−1, kv ∼ N(φ t−1, kv , σ 2 I), where I is a V-dimensional identity matrix. We incorporated the review specific characteristics in the model as outlined in Section 2.1. This model may reveal interesting patterns of topic evolution, and may also alleviate any potential biases that could arise from assuming that topics do not evolve over time on a continuous basis.</p><p>In deciding the time period of analysis, we note that our data are 10,823 reviews of chain restaurants over the eight years from January 2005 to December 2012. Of these reviews, 10,779 were posted by 7,156 authors from 2006 to 2012. Because reviews were sparsely posted in 2005, we drop 44 from 2005 for estimation of the dynamic topic model. We use reviews for every month post 2005 until December 2012 for estimation. Because of the sparsity of reviews at the weekly level, we use month as our unit of analysis. We modeled topic dynamics from January 1, 2006 until December 31, 2012 at the monthly level. To estimate this model, we  <ref type="bibr" target="#b6">Blei et al. (2003)</ref>. <ref type="bibr">18</ref> We found that an 8-topic model maximizes model fit per the Jensen-Shannon statistic. So this model in effect requires us to estimate eight topics in each of the 84 months (which is effectively 8 × 84 684 topics). Although these topics are not independent, they are far more numerous than the 200 topics in the static model. Table <ref type="table" target="#tab_6">5</ref>(A) shows the top 20 words by posterior means of the probability (φ kv ) in the health topic and the corresponding probabilities for every 20th month (in addition to the 84th month). We note that there is little temporal change in the set of top 20 words in the health topic (based on the posterior probability of belonging to the topic). Differences in adjacent time periods are even less noticeable. To ensure that this insight is not specific to the seeded health topic, we present the evolution of the top 20 words for a topic that is ranked high by coherence and importance metrics in our data set (burger:fries) in Table <ref type="table" target="#tab_6">5</ref>(B). We find little evidence of topic evolution over time (18 words are common to the top 20 words across the first and last month). We find that the same pattern holds if we extend this analysis</p><p>Marketing <ref type="bibr">Science, 2017</ref><ref type="bibr">, vol. 36, no. 5, pp. 726-746, © 2017</ref> to the top 50 words. We infer that topics do not evolve to a large extent during the data window.</p><p>Based on the dynamic model estimates, the resulting measure of health discussion in chain restaurants increases from 0.38% in the pre period to 0.45% in the post period; this is consistent with our static model. Given the limited evidence of dynamics in topics across the time periods of interest, we conclude that our assumption of static topics is reasonable. Finally, the dynamic model (Perplexity 477.93) and the static model (Perplexity 487.76) offer a similar fit to the data. Perplexity is a measure of fit for LDA models and is described in more detail in Section 4.5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Robustness Checks</head><p>We now investigate the robustness of our estimate of a causal effect of the regulation on health topic proportion to several features of the model and the data.</p><p>Treatment timing and duration of analysis. Section 81.5 of the New York City Health Code 19 makes the calorie posting regulation effective from May 5, 2008. This code states that the New York City Health Department would begin citing violations of this requirement from May 5, 2008 and may impose monetary penalties from July 18, 2008. It is plausible that restaurants made changes before the regulation date of July 18, 2008 (e.g., healthier menus or lower calorie ingredients) in anticipation of calorie posting. Such changes could have affected health topic proportions even before the regulation was implemented. We estimated the model including Equation (2) for different temporal breaks (before and after July 1, 2008), and find that our results hold (Table <ref type="table" target="#tab_7">6</ref>(A)).</p><p>To further account for the possibility that factors other than the regulation might affect topic proportions of chain restaurants, but not those of standalone restaurants, we conduct a regression discontinuity analysis. Such analysis elicits causal effects of interventions more cleanly by assigning a threshold above or below which an intervention is assigned. Such a threshold in our context is simply the time of implementation of the calorie posting regulation (July 1, 2008). The treatment (mandatory calorie posting) is assigned to chain restaurants only after this cutoff. By comparing observations lying closely on either side of the threshold, it is possible to estimate the local treatment effect in contexts in which randomization was unfeasible. As a result, we estimate the regressions discussed above not for all reviews in our data period, but for reviews posted in a period of, e.g., X months before and after the date of implementation. The smaller the time period of analysis around the date of implementation, the less likely is the occurrence of any events which could affect topic proportions of chain restaurants only. We estimate the regressions for X 24 months (i.e., on all reviews posted 24 months before and after the regulation), X 18, X 12, and X 6 months. Although the regression coefficients vary in magnitude (Table <ref type="table" target="#tab_7">6</ref>(B)), the coefficients' signs remain the same, showing a positive effect of the regulation from the 12th month onward. The null effect for shorter time periods could be driven by implementation delays that prevent a clean or widespread implementation of the policy on the date of enforcement, or by lower statistical power or by consumers taking time to absorb the information from calorie posting. Differences between treatment and control groups. We analyze if our results are driven by two differences between the treatment group (chain) and control group (standalone) in the pre regulation period, i.e., the large difference in mean health topic proportion between the two groups (0.85% versus 0.35%), and the large difference in sample size (there are 61.7 times more reviews of standalone restaurants than of chain restaurants). For this purpose, we sampled preregulation reviews of standalone restaurants to form an alternate control group such that (a) the mean of health topic proportions of this control group is the same as that of all preregulation reviews of chain restaurants (treatment group), and (b) the number of reviews in the new control group are the same as those in the control group.</p><p>We estimated the regression model on this data and again found a positive and significant coefficient of the interaction effect of Chain and Post (Posterior mean 2.13; Posterior SD 0.77). Although this analysis is subject to limitations (ideally selection to the control and treatment groups should be random), it shows that our results are not affected by differences between chain and standalone restaurants. <ref type="bibr">20</ref> Increase in number of authors and reviews. There are many more unique authors and reviews in the postperiod compared to the preperiod for chain and standalone restaurants (Table <ref type="table" target="#tab_4">3</ref>). One concern is that this growth in volume of new authors or reviews might be leading to the increased discussion of "health" in chain restaurants. It is unlikely that this sharp increase in the number of new authors stems from the regulation itself. Indeed, we find in our data that the number of authors posting reviews for the first time increases substantially over time for both types of restaurants.</p><p>Our main concern is whether the regulation led to a change in this trend for chain restaurants, which was different from the change for standalone restaurants. To analyze this, we regressed the number of new authors in month t for chain and standalone restaurants (t 1, . . . , 48) against month t, t_Chain (interaction of t and the dummy variable for chain restaurants) and t_Chain_Post (interaction of t_Chain with a dummy variable which takes the value 1 from July 2008).</p><p>As expected, we find an increasing temporal trend in the number of new authors for all restaurants (coefficient of t 39.46, p &lt; 0.01), and a greater temporal increase in the number of new authors for standalone restaurants (compared with chains) over the entire data period (coefficient of t_Chain −36.37 p &lt; 0.01). Most important, we find that the trend in the number of new authors after the regulation does not differ across types of restaurants (coefficient of t_Chain_Post −1.33, p &lt; 0.384). Given this similarity in trends after the regulation, we conclude that the regulation did not have a causal effect on the number of new authors reviewing chain restaurants. <ref type="bibr">21</ref> We repeated the same regression analysis with the total number of authors as the dependent variable, and obtained the same result. Regressing the number of reviews leads to the same inference. Combined with the results obtained from the LDA model, we infer that the regulation affected the content of discussion in reviews of chain restaurants, but not the number of authors or reviews.</p><p>Choice of seeds. To understand if our results are driven by our choice of seed words from the regulation document, we estimated the model using another set of seed words. Specifically, Wikipedia (one of the most widely used sources of information globally) contains a description of the word "nutrition" and lists a table of nutrients that should be consumed for healthy living (http://en.wikipedia.org/wiki/Nutrition). We used all of the words describing the nutrients in this table as seeds. These seed words are calories, fat, protein, vitamin, cholesterol, calcium, magnesium, sodium, potassium, iron, and iodine. We reestimated the model using these words as seeds, and found that our results are very similar to those obtained using seeds from this source instead of those from the regulation document. Topic proportions did not vary based on the choice of seeds. <ref type="bibr">22</ref> Document specific hyperparameters. To demonstrate how allowing for document specific hyperparameters α kd affects the within-topic distribution, we estimated the model on online reviews of all chain restaurants in our data set, assuming that α is known to the researcher, and studied topic proportions for different values of α. We estimated three models differing only in the value of α kd (0.001, 0.25, and 100). For each model, we assumed α kd to be the same for all topics and documents. For all three models we assumed 20 topics, and set the hyperparameter β 0.1. Topic proportions for the three models (corresponding to three values of α kd ) are presented in Figure <ref type="figure" target="#fig_3">4</ref>. Larger values of α are clearly associated with more evenly spread topic distributions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.4.">Implications for Managers and Policy Makers</head><p>We first discuss implications for policy makers interested in promoting healthy habits among consumers eating out. We find that health is not a prominent topic of discussion among hundreds of thousands of reviewers of restaurants in New York City. With over 57% of all adults in the city being overweight or obese, 23 this is worrisome. Most reviewers of restaurants discuss health to a very low extent or not at all. Interestingly, much of the discussion of health is skewed towards a small segment of reviewers who can be readily identified online. They could serve as useful starting points for initiatives to identify influencers or evangelists who might be successful in changing online public opinion about health.</p><p>We find that the calorie posting regulation was successful in increasing the proportion of discussion of health-related words among online reviews of chain restaurants. Regulators are interested in understanding the effect of the regulation on the overall level of discussion of health. This is a function of (a) changes in the volume of reviews posted after the regulation, and (b) changes in the mean proportion of health topic discussion across reviews. In this research, we focus on the latter: This is methodologically much more difficult to address, and more novel to the literature. Yet we note that the volume of reviews of chain restaurants increased over seven times after the regulation (from 1,287 reviews in the 24 months before the regulation period to 9,536 reviews in the 24 months after). A small increase in health topic proportion per review, combined with a very large increase in the volume of reviews, suggests a substantially positive overall effect of the regulation on the level of online health discussion. Managers of restaurants with healthier offerings might be encouraged by this trend and managers of restaurants with less healthy offerings might consider conducting more market research to determine whether and how to alter their strategy. This is an encouraging sign of success of the regulation, and it provides a basis for conducting further (and costlier) studies into consumption of healthier prod-ucts as a logical next step. We find that the increase in health discussion after the regulation was largely driven by reviewers who were not active in posting reviews before the regulation, but posted many more reviews after the regulation. Several consumers discussed health in online restaurant reviews for the first time (on the focal website) after the regulation. Policy makers might be interested in understanding what kinds of reviewers were more vocal about health after the regulation. We find that it is not the most prolific reviewers, but a small number of new reviewers, who were responsible for greater health discussion after the regulation.</p><p>Although these results are econometrically significant, are they economically significant? Our estimate of a 17.1% increase in health topic proportion (from 0.35% to 0.41%) is consistent with research based on transaction data. <ref type="bibr" target="#b8">Bollinger et al. (2011)</ref> estimate a 6% decrease in calories per transaction at Starbucks after the regulation, but no change in overall revenues. Irrespective of the data source and research methodology, such small effect sizes might suggest that the regulation was not a success. However, anecdotal evidence suggests that this effect might be material in economic and social terms. Small changes in consumer behavior have been known to bring about major changes in obesity levels. <ref type="bibr" target="#b25">Kuo et al. (2009)</ref> estimate that even if 10% of restaurant patrons in Los Angeles County were to reduce calorie consumption by 100 calories per meal, as much as 40.6% of the average annual weight gain in the entire county population would be averted. Reduction in obesity levels has a monumental social and economic significance in the United States where over 250,000 deaths every year are attributable to obesity <ref type="bibr" target="#b0">(Allison et al. 1999)</ref>. Obesity related costs in the United States in 2008 were estimated to be a staggering $147 billion <ref type="bibr" target="#b17">(Finkelstein et al. 2009)</ref>, and are rising.</p><p>Another key finding is that topics pertaining to health, price, and service garner a smaller proportion of online reviews than those pertaining to brands and menu items. To the extent that these topics are correlated with product attributes that consumers use for choice decisions, this serves as a free and externally valid input into product management decisions. For trade-offs between investing in service or menu redesign, it is useful for managers to know that menu items are discussed far more than service. Among menu items, the fact that steaks, burgers, and sandwiches are discussed more than salads and appetizers is an indication of the relative popularity of various food items for eating out in New York City.</p><p>It is also important for health regulators to understand whether there are differential effects of the health regulation. Especially, regulators may have a goal that the regulation not leave behind less healthy consumers, i.e., the regulation benefits not just the healthier consumers. In the absence of disaggregated data on health measures at the zip code level, researchers have often used race as a proxy <ref type="bibr" target="#b7">(Boardman et al. 2005)</ref>, given the greater prevalence of food-correlated diseases (specifically obesity, hypertension, and diabetes) among African Americans. We separated reviews from African American majority zip codes 24 (henceforth referred to as African American neighborhoods), from other reviews. We find that the mean level of health discussion of chain restaurants in African American neighborhoods increased from 0.33% before the regulation to 0.63% afterward. <ref type="bibr">25</ref> By contrast, health discussion of standalone restaurants in African American neighborhoods fell from 0.87% to 0.76%, which is consistent with the general view of declining salience of health.</p><p>In the other neighborhoods, health discussion of chain restaurants increased to a much lesser extent (from 0.35% to 0.42%) and fell from 0.85% to 0.77% for standalone restaurants. A regression analysis of health topic discussion on dummies for chain (1 if chain), post (1 if post regulation, 0 otherwise), race (1 if African American neighborhood, 0 otherwise), interactions of chain_post, chain_race, post_race, and chain_post_race, along with restaurant and author specific random effects, revealed that the crucial coefficient of chain_post_race is positive and significant at the 10% level (M 0.88, SD 0.51). This seems to indicate that the regulation had a (10% level of significance) larger impact on potentially less healthy zip codes.</p><p>However, replacing the binary race variable with a continuous measure (proportion of African American population) reduces the statistical significance even further. Although the evidence that an increase in health discussion of chain restaurants is greater for African American neighborhoods is not very compelling from a statistical standpoint, we can confidently say that the regulation did not differentially favor healthy zip codes or leave behind less healthy zip codes. This should be reassuring to regulators, even if a larger effect of less healthy zip codes could be more reassuring.</p><p>Finally, our analysis reveals useful insights for brand managers of restaurants. Topics in Table <ref type="table" target="#tab_0">1</ref>(A) show words that are commonly used along with certain brand names in consumer reviews. We note that Subway is the only brand among the top 10 words for the topic "sandwich:potbelly" suggesting that Potbelly and Subway are perceived to be similar by consumers. This could serve as a useful input for future store choice decisions where one brand might want to avoid proximity to the other. Food items frequently mentioned with a brand indicate the items with which that brand is associated. Based on this, Chipotle is more strongly associated with burritos and chicken, and not as much with tacos or beef. This could serve as input into a formal menu planning exercise, i.e., more items related to burritos and chicken might strengthen these brandproduct associations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.5.">Model Comparison</head><p>We assess improvement in model performance due to the incorporation of two features unique to the marketing literature, i.e., (a) allowing the researcher to seed certain topics with specific words that are considered substantively important, and (b) allowing the distribution of topics within a document to be affected by the characteristics of the document (length, rating, and author experience). Model A is an unseeded model, i.e., we do not impose any prior distribution φ k of any topic to contain any word with high probability. Model B is identical to the proposed model with the exception that we assume that θ d is drawn from a Dirichlet distribution with parameter α which is invariant across reviews, and does not depend on review characteristics. For model comparison, we compute the perplexity score, i.e., the likelihood of observing a collection of words given a model of how the words were generated. Perplexity scores for Model A, Model B, and the proposed model are 481.73, 531.40, and 487.76, respectively. Our seeded model is comparable in fit to the more flexible unseeded model (Model A). <ref type="bibr">26</ref> Therefore, seeding enables incorporation of managerial intuition and offers much richer managerial insights, at very little cost in terms of model fit. Note that a separate health topic emerges even in the unseeded model. The top 10 words by posterior probability for this topic are calories, calorie, healthy, menu, fat, count, chicken, low, protein, and meal. Model B performs worse than the proposed model, providing empirical validity to the notion that longer reviews and reviews with more positive valence have a more even distribution of topics.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Conclusion</head><p>The growth of the Internet has led to the availability of very large quantities of data that are often less structured than data collected offline. Such data are often in the form of consumers' opinions (e.g., blogs, product reviews), are from an increasingly representative subset of the population, are in the public domain, and are available for long periods of time (e.g., eight years in this research). This provides an unprecedented opportunity for marketers to not only understand what consumers are saying about their products at a given point in time but also to continuously track changes in consumer opinion over time. However, a major challenge for researchers is that much of these data are textual. Techniques to analyze large volumes of text are at a nascent stage even in computer science. Yet there is considerable interest from practitioners in using these data to gain usable knowledge. A recent report by the McKinsey Global Institute <ref type="bibr">(Manyika et al. 2011, p. 23)</ref> suggests that analyzing such data will become a "key basis of competition, underpinning new waves of productivity growth, innovation, and consumer surplus."</p><p>Marketing <ref type="bibr">Science, 2017</ref><ref type="bibr">, vol. 36, no. 5, pp. 726-746, © 2017</ref> Early research using online textual data in marketing has focused on inferring market structure and product attributes in specific product categories, ascertaining the extent to which these correlate with consumer level data collected from more traditional experimental and survey based techniques, and incorporating measurements of such data in demand models. We extend this work using textual data to address an issue that has perhaps been infeasible otherwise: How can researchers track changes in consumer opinion over time, and assess the impact of exogenous events on such changes? Specifically, we assess the impact of a regulation to post calories in chain restaurants on consumer opinion pertaining to chain restaurants. Across marketing and computer science, we were unable to find other research that uses textual data to infer the effect of any factor on consumer opinion. We find significant changes in proportions of various topics of discussion due to the implementation of the regulation. Methodologically, we extend the LDA set of models in computer science. Future research can explore more flexible heterogeneity specifications of the hyperparameter α kd (e.g., restaurant and author-specific random effects) and allow for correlated probabilities of words belonging to a topic, across time periods, in the dynamic topic model. We look forward to several strategy-and policy-relevant applications as well as more sophisticated models in this area of topic detection and measurement.</p><p>1 Per Alexa.com, an independent research firm, this was among the top 70 most popular websites in the United States in July 2014. Owing to the legal terms of service of this website, we are unable to reveal its identity. 2 Despite large sample sizes, user-generated textual content might suffer from biases; indeed, no market research technique is perfect. As such we do not propose to replace traditional approaches, but instead to augment them with data that are available free, in larger quantities, and over longer periods of time. <ref type="bibr">3</ref> We refer to restaurants with less than 15 units nationwide as "standalone" (as opposed to chain) for ease of understanding. As mentioned, such restaurants were outside the scope of the regulation. 4 Topic proportions could vary due to unobserved restaurant characteristics. In another specification, we allowed λ k0 to vary across restaurants by estimating a restaurant specific intercept. Our results remain unchanged, suggesting that the observed metadata are sufficient to account for heterogeneity in topic proportions. 5 There are 1.5 reviews per author on average, which restricts our ability to identify author specific effects. To address this issue, we assume the same random effect for authors who posted the same number of reviews in our data.</p><p>6 Variational Inference (VI) methods are also commonly used in computer science and statistics for large-scale problems with intractable integrals. Whereas Monte Carlo methods provide numerical approximations of the exact posterior by sampling, VI methods provide a locally optimal but precise analytical solution to an approximation of the posterior. We estimated the model using a VI method and obtained almost identical results with comparable computational speed. We chose Monte Carlo methods as they are more common in the marketing literature. 7 For example, P(φ k | z, w) Dirichlet(β + n 1 k , . . . , β + n v k ) and the estimated mean vector of this distribution from a single MCMC iteration is ((β + n 1 k )/(V β + n k ), . . . , (β + n v k )/(V β + n k )). 8 Directionally, results are not sensitive to the choice of variance for this prior. We used different variance values (0.5, 5, 25), but our findings remain the same. 9 http://people.cs.umass.edu/~mccallum/mallet/.</p><p>10 For example, we included the word "health" as a seed word for the health topic because it had appeared in the calorie posting regulation document and was also consistent with our intuition. However, "health" is not in the top 10 most probable words in the posterior distribution of the health topic. It features in another topic with the following top 10 words: health, department, properly, unclean, dirty, roach, grade, equipment, NYC, contact. This topic relates to health safety and hygiene and is unrelated to the calorie content of food. The data overwhelmed the prior and assigned "health" to another topic. 11 Because the regulation pertains to posting of calorific information, we investigated the occurrence of the words calorie and calories in our data. These words represent 0.07% of all words in reviews of chain restaurants before the regulation, and 0.10% of all chain restaurant reviews after the regulation. However, they represent just 0.01% of all reviews of standalone restaurants, before and after the regulation. In other words, calories were discussed more in chain restaurants than in other restaurants before the regulation, and this trend intensified after the regulation. 12 In further analysis to test robustness of topics, we measured how far away the most probable words of the topics are from uniform distributions. The closer a topic's top words follow a uniform distribution, the less likely that the topic is informative. Empirically we expect Zipf's law to apply; most of the probability mass in each topic is allocated to a few words. Using this measure did not change the results in the paper. <ref type="bibr">13</ref> To improve interpretability, it might be tempting to combine topics that appear similar. This is better achieved by estimating models with fewer topics than by manually combining topics post estimation, since manual combinations might be subjective. However, such models would offer a poorer fit. Thus, we follow the standard approach of drawing substantive inferences from the best fitting model. 14 Figure <ref type="figure" target="#fig_2">3</ref> shows the large variation in topic proportions within a month or quarter. To account for this within-period variation, we replaced the quarterly dummies in Equation (2) with the following variable: the posterior standard deviation across reviews posted in that quarter, of the topic proportion θ kd . Our results remain unchanged. Replacing this variable with measures of monthly standard deviation also does not affect our results. 15 Although it is plausible that "low" health discussants contribute to the health discussion by posting more reviews (per author) than "high" health discussants, we find the opposite: "Low" health discussants post an average of 1.43 reviews in the data period, compared to 1.83 reviews posted by the average "high" health discussant. So a typical "high" health discussant not only discusses more about health in a typical review but also posts more reviews.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 (</head><label>1</label><figDesc>Figure 1(B). Monthly Frequency of Occurrence of Words in Reviews of Chain Restaurants Per Review (July 2006-June 2010)"Calories" "Calorie" "Fat"</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Note.</head><label></label><figDesc>Bars represent the frequencies of occurrence of each of the top 20 words in a topic.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Figure 3. Temporal Trend of the Posterior 95% Credible Intervals of the Mean of Topic Proportions (Within a Month) for the Health Topic</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Figure 4. Distribution of Topic Proportions for a 20-Topic Model for Various Values of α</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 (</head><label>1</label><figDesc>A). Major Topics, Associated Words, and Topic Proportions (Based on Coherence Scores)</figDesc><table><row><cell>Coherence</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1 (</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell>Mean topic</cell><cell>Top 10 words in decreasing order of posterior</cell></row><row><cell>ID</cell><cell>Name</cell><cell>proportion (%)</cell><cell>probability of belonging to the topic</cell></row><row><cell>1</cell><cell>"Health"</cell><cell>0.41</cell><cell>Calories, calorie, fat, menu, healthy, count, low, counts, muscle, diet</cell></row><row><cell>2</cell><cell>Place:Good</cell><cell>4.88</cell><cell>Place, good, youre, people, eat, theyre, make, time, find, eating</cell></row><row><cell>3</cell><cell>Time:Back</cell><cell>4.20</cell><cell>Time, back, make, give, ill, experience, eat, meal, made, long</cell></row><row><cell>4</cell><cell>Didnt:Back</cell><cell>3.62</cell><cell>Didnt, back, wanted, ordered, wasnt, place, asked, walked, time, friend</cell></row><row><cell>5</cell><cell>Taste:Hot</cell><cell>2.30</cell><cell>Taste, hot, flavor, fresh, meat, cheese, made, side, sauce, delicious</cell></row><row><cell>6</cell><cell>Steak:Potatoes</cell><cell>2.20</cell><cell>Steak, potatoes, filet, good, spinach, cooked, mashed, dessert, sides, salad</cell></row><row><cell>7</cell><cell>Burger:Fries</cell><cell>2.10</cell><cell>Burger, fries, guys, burgers, toppings, free, cheeseburger, cajun, regular, joint</cell></row><row><cell>8</cell><cell>Menu:Options</cell><cell>1.85</cell><cell>Menu, options, tasty, choose, option, great, pretty, good, choice, side</cell></row><row><cell>9</cell><cell>Place:Service</cell><cell>1.85</cell><cell>Place, service, time, worst, bad, eat, horrible, terrible, awful, money</cell></row><row><cell>10</cell><cell>Good:Service</cell><cell>1.80</cell><cell>Good, service, place, pretty, bad, decent, bit, wasnt, average, slow</cell></row><row><cell>11</cell><cell>Table:Waiter</cell><cell>1.78</cell><cell>Table, waiter, service, server, waitress, seated, drinks, ordered, meal, check</cell></row><row><cell>12</cell><cell>Chain:Place</cell><cell>1.68</cell><cell>Chain, place, prices, nyc, places, good, quality, youre, decent, fast</cell></row><row><cell>13</cell><cell>Great:Good</cell><cell>1.60</cell><cell>Great, good, place, service, recommend, amazing, worth, highly, price, expensive</cell></row><row><cell>14</cell><cell>Taste:Good</cell><cell>1.60</cell><cell>Taste, good, meat, bland, tasted, flavor, didnt, wasnt, dry, ordered</cell></row><row><cell>15</cell><cell>Price:Worth</cell><cell>1.59</cell><cell>Price, worth, pay, meal, expensive, drink, cost, money, dollars, $10</cell></row><row><cell>16</cell><cell>Great:Place</cell><cell>1.54</cell><cell>Great, place, delicious, time, love, awesome, amazing, back, eat, perfect</cell></row><row><cell>17</cell><cell>Great:Service</cell><cell>1.53</cell><cell>Great, service, good, nice, friendly, staff, experience, excellent, attentive, nyc</cell></row><row><cell>18</cell><cell>Lunch:Line</cell><cell>1.52</cell><cell>Lunch, line, long, time, lines, rush, location, busy, order, wait</cell></row><row><cell>19</cell><cell>Chipotle:Burrito</cell><cell>1.47</cell><cell>Chipotle, burrito, burritos, qdoba, mexican, chicken, chips, tacos, guacamole, bowl</cell></row><row><cell>20</cell><cell>Good:Pretty</cell><cell>1.47</cell><cell>Good, pretty, nice, place, bad, service, theyre, bit, tasty, quick</cell></row></table><note>B). Major Topics, Associated Words, and Topic Proportions (Based on Topic Proportions)</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>MarketingScience, 2017Science,  , vol. 36, no. 5, pp. 726-746, © 2017 INFORMSFigure 2. A Visual Representation of Major Topics</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="3">"Health"</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Juice:Orange</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">Steak:Potatoes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Artist:Content</cell></row><row><cell>Calories</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Orange</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Steak</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Artist</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Calorie</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Juice</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Potatoes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Content</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Fat</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Cheap</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Filet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Puerto</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Menu</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Plastic</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Good</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Trumps</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Healthy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Business</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Spinach</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Canada</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Count</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Buy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Cooked</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Sexual</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Low</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Buying</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Mashed</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Kevin</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Counts</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Cups</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Dessert</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Art</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Muscle</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Buckets</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Sides</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Silent</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Diet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Freshly</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Salad</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Rico</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Protein</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Youre</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Wine</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Warhol</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>1,000</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Squeezed</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Lobster</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Problem;</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Item</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>realize</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Crab</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Moments</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Maker</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Puts</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Dinner</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Rican</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sodium</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Clear</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Great</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Bucket</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Listed</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ice</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Mignon</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Downright</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Website</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Appears</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ordered</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Cd</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Nutrition</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Practices</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Creamed</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>James</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wrap</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Deceptive</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Shrimp</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tgifriday</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Information</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Cosi</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Medium</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Climates</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>50</cell><cell cols="2">100</cell><cell>150</cell><cell cols="2">200</cell><cell>250</cell><cell>300</cell><cell>0</cell><cell cols="2">10</cell><cell cols="2">20</cell><cell cols="2">30</cell><cell>40</cell><cell></cell><cell>50</cell><cell>0</cell><cell>100</cell><cell>200</cell><cell>300</cell><cell>400</cell><cell>500</cell><cell>600</cell><cell>700</cell><cell>800</cell><cell>0</cell><cell>2</cell><cell></cell><cell>4</cell><cell cols="2">6</cell><cell>8</cell><cell>10</cell><cell>12</cell></row><row><cell></cell><cell></cell><cell cols="5">Account:Free</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="6">Steak:Wolfgangs</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Didnt:Back</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Mini:Home</cell></row><row><cell>Account Free Cosi Page Wireless Wifi</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Steak Wolfgangs Bacon Lugers Peter Steakhouse</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Didnt Back Wanted Ordered Wasnt Place</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Mini Home Kelly Delta Doughnuts Nanny</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sns</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Porterhouse</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Asked</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Qs</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Access</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Spinach</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Walked</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>American</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Location</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Sides</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Time</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Daddys</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>July</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Creamed</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Friend</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Daddy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Service</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Potatoes</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Decided</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Favourite</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Cancelation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>German</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Thought</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Wins</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Locations</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Luger</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Looked</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Record</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Login</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Steaks</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Finally</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Stole</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sip</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Meat</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Couldnt</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tattoos</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Surf</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Thick</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Order</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Broken</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Pay</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Wine</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Eat</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Granny</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Give</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Wolfgang</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Made</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Slippery</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Internet</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Sizzling</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Guy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>HIgh-fiving</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Show</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>House</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Gave</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Anna</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>10</cell><cell>20</cell><cell>30</cell><cell></cell><cell>40</cell><cell>50</cell><cell>60</cell><cell>70</cell><cell>0</cell><cell>100</cell><cell>200</cell><cell>300</cell><cell cols="2">400</cell><cell>500</cell><cell>600</cell><cell>700</cell><cell>800</cell><cell>0</cell><cell>100</cell><cell>200</cell><cell>300</cell><cell>400</cell><cell>500</cell><cell>600</cell><cell>700</cell><cell>800</cell><cell>0</cell><cell cols="2">5</cell><cell></cell><cell>10</cell><cell cols="2">15</cell><cell>20</cell><cell>25</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="3">Nom:Bubba</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Capital:Grille</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">Place:Good</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Bbq:Chicken</cell></row><row><cell>Nom</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Capital</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Place</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Bbq</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Bubba</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Grille</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Good</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Hawaiian</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Cola</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Week</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Youre</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Chicken</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Gump</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Cake</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>People</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Salad</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Coca</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Chocolate</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Eat</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ll;</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sq</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Dessert</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Theyre</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Rice</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sarah</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Creme</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Make</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Hawaii</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Elite</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Sirloin</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Time</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Spam</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>$2500</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Chowder</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Find</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Katsu</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Yada</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Rw</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Eating</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Macaroni</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Riff</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Kona</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Doesnt</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Lunch</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Beginning</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Brulee</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Things</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Plate</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Raff</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Calm</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Feel</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Pork</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Tv</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Flourless</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Isnt</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Musubi</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Gumps</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Espresso</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Give</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Sauce</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Amused</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Truffle</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Bad</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Sushi</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Badge</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Salmon</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Big</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Combo</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Proud</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Menu</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Pretty</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ribs</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wondering</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Steakhouse</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Places</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Fried</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Steve</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Shallot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Reason</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Beef</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell cols="2">5</cell><cell>10</cell><cell></cell><cell>15</cell><cell></cell><cell>20</cell><cell>25</cell><cell>0</cell><cell>20</cell><cell>40</cell><cell>60</cell><cell>80</cell><cell>100</cell><cell>120</cell><cell>140</cell><cell>160</cell><cell>180</cell><cell>0</cell><cell>200</cell><cell>400</cell><cell>600</cell><cell></cell><cell>800</cell><cell>1,000</cell><cell>1,200</cell><cell>1,400</cell><cell>0</cell><cell>20</cell><cell cols="2">40</cell><cell>60</cell><cell>80</cell><cell cols="2">100</cell><cell>120</cell><cell>140</cell></row><row><cell></cell><cell></cell><cell cols="5">Sandwich:Potbelly</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Table:Waiter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">Pizza:Dominos</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Time:Back</cell></row><row><cell>Sandwich</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Table</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Pizza</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Time</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Potbelly</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Waiter</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Dominos</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Back</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sandwiches</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Service</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Papa</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Make</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Bread</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Server</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Johns</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Give</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Peppers</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Waitress</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Order</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ill</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Hot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Seated</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Delivery</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Experience</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Wreck</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Drinks</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Sauce</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Eat</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Subway</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ordered</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Crust</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Meal</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Italian</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Meal</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Slice</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Long</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Turkey</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Check</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Pizzas</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Made</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Shop</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Asked</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Garlic</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Home</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Toasted</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Didnt</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Online</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Review</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Toppings</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Order</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ordering</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Times</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Roast</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Water</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Cheese</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Fact</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Cookies</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Menu</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Cheesy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>End</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Potbellys</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Brought</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Pepperoni</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Didnt</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Beef</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Drink</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ordered</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Put</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Live</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Arrived</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Hot</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Bad</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Chips</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Sat</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Large</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Things</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Lunch</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Hostess</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Thin</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Fine</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell>100</cell><cell>200</cell><cell>300</cell><cell>400</cell><cell>500</cell><cell>600</cell><cell>700</cell><cell>800</cell><cell>0</cell><cell>100</cell><cell></cell><cell>200</cell><cell>300</cell><cell></cell><cell>400</cell><cell cols="2">500</cell><cell>600</cell><cell>0</cell><cell>100</cell><cell>200</cell><cell>300</cell><cell>400</cell><cell>500</cell><cell>600</cell><cell>700</cell><cell>800</cell><cell>0</cell><cell>100</cell><cell>200</cell><cell cols="2">300</cell><cell>400</cell><cell>500</cell><cell>600</cell><cell>700</cell><cell>800</cell></row><row><cell></cell><cell></cell><cell cols="5">Chipotle:Burrito</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Stix:Chinese</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="5">Games:Game</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="4">Burger:Fries</cell></row><row><cell>Chipotle</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Stix</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Games</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Burger</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Burrito</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Chinese</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Game</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Fries</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Rice</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Owned</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Fun</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Guys</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Beans</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Nebraska</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Play</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Burgers</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Salsa</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Lincoln</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Tickets</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Toppings</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Chicken</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Mi</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Dave</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Free</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Bowl</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Suppose</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Busters</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Cheeseburger</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Cream</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Blimpie</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Arcade</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Cajun</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Sour</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Fck</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Kids</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Regular</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Guacamole</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Seminar</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Playing</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Peanuts</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Black</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Hours</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Card</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Joint</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Corn</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Muy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Db;</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Fast</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Cheese</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Vino</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Drinks</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Order</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Lettuce</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Omaha</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Video</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Patties</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Extra</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Inject</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Machine</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Greasy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Guac</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Banh</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>bar</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Double</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Spicy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Hopping</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Win</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Juicy</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Pico</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Insert</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Played</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Bag</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>De</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Suey</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Machines</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Hamburger</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Steak</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Dancing</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Ticket</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Patty</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>0</cell><cell cols="2">100</cell><cell>200</cell><cell></cell><cell>300</cell><cell cols="2">400</cell><cell>500</cell><cell>0</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell><cell>6</cell><cell>7</cell><cell>8</cell><cell>9</cell><cell>0</cell><cell>50</cell><cell>100</cell><cell>150</cell><cell>200</cell><cell>250</cell><cell>300</cell><cell>350</cell><cell>400</cell><cell>0</cell><cell>200</cell><cell>400</cell><cell>600</cell><cell>800</cell><cell>1,000</cell><cell>1,200</cell><cell>1,400</cell><cell>1,600</cell><cell>1,800</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2 .</head><label>2</label><figDesc>The Effect of the Calorie Posting Regulation on Topic Proportions Notes. M and SD stand for the posterior mean and posterior standard deviation of the coefficient estimate. Coefficients whose 95% credible intervals do not contain zero appear in bold. Posterior Means and Posterior SDs of Coefficients of Equation (2).</figDesc><table><row><cell></cell><cell cols="3">Mean topic proportions</cell></row><row><cell></cell><cell>Coefficient of</cell><cell>Coefficient of</cell><cell>Coefficient of</cell></row><row><cell>Topic</cell><cell>Chain</cell><cell>Post</cell><cell>Chain × Post</cell></row><row><cell>"Health"</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>7.70</cell><cell>(1.18)</cell><cell>4.66</cell></row><row><cell>SD</cell><cell>1.78</cell><cell>0.24</cell><cell>1.90</cell></row><row><cell>Pizza:Bbq</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>−1.69</cell><cell>0.45</cell><cell>3.96</cell></row><row><cell>SD</cell><cell>8.56</cell><cell>1.16</cell><cell>9.14</cell></row><row><cell>Burger:Fries</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>165.21</cell><cell>3.01</cell><cell>38.39</cell></row><row><cell>SD</cell><cell>11.21</cell><cell>1.53</cell><cell>11.96</cell></row><row><cell>Good:Place</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>−508.14</cell><cell>−49.44</cell><cell>−27.62</cell></row><row><cell>SD</cell><cell>26.35</cell><cell>3.59</cell><cell>28.10</cell></row><row><cell>Sandwich:Bread</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>52.92</cell><cell>8.88</cell><cell>42.86</cell></row><row><cell>SD</cell><cell>6.63</cell><cell>0.90</cell><cell>7.07</cell></row><row><cell>Salad:Soup</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>115.75</cell><cell>(1.97)</cell><cell>(49.58)</cell></row><row><cell>SD</cell><cell>7.17</cell><cell>0.98</cell><cell>7.65</cell></row><row><cell>Steak:Lobster</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>40.92</cell><cell>30.74</cell><cell>59.00</cell></row><row><cell>SD</cell><cell>20.50</cell><cell>2.80</cell><cell>21.87</cell></row><row><cell>Table:Waitress</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>121.64</cell><cell>6.19</cell><cell>−69.28</cell></row><row><cell>SD</cell><cell>9.69</cell><cell>1.32</cell><cell>10.33</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3 .</head><label>3</label><figDesc>Author Level Analysis of Increase in Health Topic Discussion</figDesc><table><row><cell></cell><cell cols="2">Number of authors discussing health</cell><cell></cell></row><row><cell></cell><cell cols="2">before and after the regulation</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Pre-regulation</cell><cell>Post-regulation</cell></row><row><cell cols="2">"High" health discussants</cell><cell>112</cell><cell>825</cell></row><row><cell cols="2">"Low" health discussants</cell><cell>711</cell><cell>5,683</cell></row><row><cell cols="4">Mean (across reviews) of health topic proportions</cell></row><row><cell></cell><cell cols="2">before and after the regulation</cell><cell></cell></row><row><cell></cell><cell cols="3">Pre-regulation (%) Post-regulation (%) Change (%)</cell></row><row><cell>"High" health</cell><cell>1.61</cell><cell>2.36</cell><cell>46.79</cell></row><row><cell>discussants</cell><cell></cell><cell></cell><cell></cell></row><row><cell>"Low" health</cell><cell>0.13</cell><cell>0.05</cell><cell>−63.08</cell></row><row><cell>discussants</cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="3">reviews of chain restaurants. In Table</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 4 .</head><label>4</label><figDesc>Effect of Review and Author Characteristics on Hyperparameter α kd for the Health Topic</figDesc><table><row><cell></cell><cell></cell><cell>Review</cell><cell>Author</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Intercept</cell><cell>length</cell><cell>experience</cell><cell>Rating 1</cell><cell>Rating 2</cell><cell>Rating 3</cell><cell>Rating 4</cell></row><row><cell>Posterior Mean</cell><cell>−0.790</cell><cell>−0.562</cell><cell>0.005</cell><cell>−0.401</cell><cell>−0.322</cell><cell>−0.106</cell><cell>−0.016</cell></row><row><cell>Posterior SD</cell><cell>0.002</cell><cell>0.006</cell><cell>0.002</cell><cell>0.001</cell><cell>0.001</cell><cell>0.001</cell><cell>0.001</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 5 (</head><label>5</label><figDesc>A). Temporal Evolution of the "Top 20" Words in the "Health" Topic</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell cols="2">Time period (in months)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>t 0</cell><cell>t 20</cell><cell>t 40</cell><cell>t 60</cell><cell>t 80</cell><cell>t 84</cell></row><row><cell>Greatest</cell><cell>Calories</cell><cell>Calories</cell><cell>Calories</cell><cell>Calories</cell><cell>Calories</cell><cell>Calories</cell></row><row><cell>Words in decreasing order of</cell><cell>Fat</cell><cell>Fat</cell><cell>Fat</cell><cell>Fat</cell><cell>Fat</cell><cell>Fat</cell></row><row><cell>posterior probability of a</cell><cell>Light</cell><cell>Light</cell><cell>Light</cell><cell>Light</cell><cell>Light</cell><cell>Light</cell></row><row><cell>word being in health topic</cell><cell>Calorie</cell><cell>Calorie</cell><cell>Calorie</cell><cell>Calorie</cell><cell>Calorie</cell><cell>Calorie</cell></row><row><cell></cell><cell>Count</cell><cell>Count</cell><cell>Count</cell><cell>Count</cell><cell>Count</cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 6 (A). Difference</head><label>6</label><figDesc></figDesc><table><row><cell></cell><cell cols="3">-in-Differences Analyses with Varying</cell></row><row><cell cols="2">Policy Implementation Dates</cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="3">Dependent variable Health topic proportion</cell></row><row><cell></cell><cell cols="3">Coefficient of Coefficient of Coefficient of</cell></row><row><cell>Model</cell><cell>Chain</cell><cell>Post</cell><cell>Chain × Post</cell></row><row><cell>Policy date</cell><cell></cell><cell></cell><cell></cell></row><row><cell>July 1, 2008</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>7.70</cell><cell>−1.18</cell><cell>4.66</cell></row><row><cell>SD</cell><cell>1.78</cell><cell>0.24</cell><cell>1.90</cell></row><row><cell>Policy date</cell><cell></cell><cell></cell><cell></cell></row><row><cell>October 1, 2008</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>7.80</cell><cell>−0.99</cell><cell>4.70</cell></row><row><cell>SD</cell><cell>1.60</cell><cell>0.22</cell><cell>1.74</cell></row><row><cell>Policy date</cell><cell></cell><cell></cell><cell></cell></row><row><cell>April 1, 2008</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>7.80</cell><cell>−1.68</cell><cell>4.44</cell></row><row><cell>SD</cell><cell>1.94</cell><cell>0.26</cell><cell>2.05</cell></row></table><note>Notes. M and SD stand for the posterior mean and posterior standard deviation of the coefficient estimate. Coefficients whose 95% credible intervals do not contain zero appear in bold.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 6 (B). Difference</head><label>6</label><figDesc></figDesc><table><row><cell></cell><cell cols="3">-in-Differences Analyses with Varying</cell></row><row><cell cols="3">Time Window Around Policy Implementation</cell><cell></cell></row><row><cell></cell><cell cols="3">Dependent variable Health topic proportion</cell></row><row><cell></cell><cell>Coefficient of</cell><cell>Coefficient of</cell><cell>Coefficient of</cell></row><row><cell>Model</cell><cell>Chain</cell><cell>Post</cell><cell>Chain × Post</cell></row><row><cell>±24 months</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>8.05</cell><cell>−0.35</cell><cell>4.04</cell></row><row><cell>SD</cell><cell>1.83</cell><cell>0.27</cell><cell>1.90</cell></row><row><cell>±18 months</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>9.19</cell><cell>0.19</cell><cell>2.34</cell></row><row><cell>SD</cell><cell>1.88</cell><cell>0.30</cell><cell>2.35</cell></row><row><cell>±12 months</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>8.40</cell><cell>0.59</cell><cell>2.85</cell></row><row><cell>SD</cell><cell>2.20</cell><cell>0.35</cell><cell>2.83</cell></row><row><cell>±6 months</cell><cell></cell><cell></cell><cell></cell></row><row><cell>M</cell><cell>12.45</cell><cell>1.94</cell><cell>−5.43</cell></row><row><cell>SD</cell><cell>2.99</cell><cell>0.49</cell><cell>3.96</cell></row></table><note>Notes. M and SD stand for the posterior mean and posterior standard deviation of the coefficient estimate. Coefficients whose 95% credible intervals do not contain zero appear in bold.</note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">P(z) D d 1 Γ(Σ k exp(x t d λ k )) Π k (Γ(exp(x t d λ k ))) • K k 1 Γ(exp(x t d λ k ) + n kd ) Γ(Σ k exp(x t d λ k ) + n d ) ,(5)where n kd is the number of words in document d assigned to topic k, and n d is the length in words of document d.Puranam, Narayan, and Kadiyali: The Effect of Regulation on Consumer OpinionMarketingScience, 2017, vol. 36, no. 5, pp. 726-746, © 2017 </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Puranam, Narayan, and Kadiyali: The Effect of Regulation on Consumer OpinionMarketingScience, 2017, vol. 36, no. 5, pp. 726-746, © 2017 </note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16">The author topic model<ref type="bibr" target="#b35">(Rosen-Zvi et al. 2004</ref>) extends the LDA model to include authorship information. It assumes that each</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>The authors thank Claire Cardie, David Mimno, and Anirban Mukherjee for useful comments. The authors also thank seminar participants at INSEAD, Georgetown University, the QME Conference 2014, and the Marketing Science Conference 2014.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>745</head><p>author has a different mix of topic proportions. A document with multiple authors is then modeled as a distribution over topics that is a mixture of the author-specific distributions. Because all documents in our application are authored by a single individual only, we did not adopt this approach. <ref type="bibr">17</ref> We thank an anonymous reviewer for highlighting this possibility.</p><p>18 This model takes advantage of the multinomial distribution's representation via its mean parameterization. A standard result from the analysis of exponential distributions is that the ith component of the natural parameter β k of a topic (a multinomial with V dimensions) with mean parameter (π 1, k , . . . , π i, k , . . . , π V, k ) is β i, k log(π i, k /π V, k ).</p><p>Mean parameters (π k, t ) for a topic in any period can be recovered using this result.</p><p>19 https://www1.nyc.gov/nycbusiness/description/calorie-posting (accessed March 2016). 20 Our identification strategy might not be as robust if consumers who visit chain restaurants did not visit standalone restaurants. Further analyses of authors of reviews of chain restaurants in our data showed that most of these authors also post reviews of standalone restaurants. This suggests overlaps in consumer segments across the two types of restaurants.</p><p>21 These results are robust to inclusion of the following additional covariates in the regression: t 2 , t 3 , Chain, and Post. Inclusion of more covariates leads to a larger standard error of the coefficient of t_Chain_Post.</p><p>22 Because our interest is specific to the discussion of health, seeding only one topic is sufficient in our context. Recent advances in the LDA literature <ref type="bibr" target="#b22">(Jagarlamudi et al. 2012</ref>) allow for seeding multiple topics, such that each topic is a mixture of two distributions, i.e., a seeded topic and a regular topic. Such methods are more appropriate for contexts with multiple topics of interest. 23 https://www.health.ny.gov/statistics/chac/general/g74.htm.</p><p>24 2010 census conducted by the U.S. Census Bureau. https://www .census.gov/2010census/. 25 Zip codes capture resident demographics. We assume this is also a proxy for restaurant customer demographics. <ref type="bibr">26</ref> We prefer a seeded model to an unseeded model as it allows us to focus the analysis of the corpus on a few specific words of interest. We do not depend solely on the data to generate the topic of interest. Managers and regulators can use seeded models to measure policy-relevant variables of interest, or to monitor the effects of their actions. However, drawing inferences from seeded models might not be advisable if they offer much lower fit.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Annual deaths attributable to obesity in the United States</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">B</forename><surname>Allison</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><forename type="middle">R</forename><surname>Fontaine</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Manson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">D</forename><surname>Vanitallie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Medical Assoc</title>
		<imprint>
			<biblScope unit="volume">282</biblScope>
			<biblScope unit="issue">16</biblScope>
			<biblScope unit="page" from="1530" to="1538" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Topic significance ranking of LDA generative models</title>
		<author>
			<persName><forename type="first">L</forename><surname>Alsumait</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Barbará</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Gentle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Domeniconi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Joint Eur. Conf. Machine Learn. Knowledge Discovery Databases: Part I</title>
		<title level="s">Lecture Notes Comput. Sci.</title>
		<editor>
			<persName><forename type="first">W</forename><surname>Buntine</surname></persName>
			<persName><forename type="first">M</forename><surname>Grobelnik</surname></persName>
			<persName><forename type="first">D</forename><surname>Mladenić</surname></persName>
			<persName><forename type="first">J</forename><surname>Shawe-Taylor</surname></persName>
		</editor>
		<meeting>Joint Eur. Conf. Machine Learn. Knowledge Discovery Databases: Part I<address><addrLine>Berlin Heidelberg</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2009" />
			<biblScope unit="volume">5781</biblScope>
			<biblScope unit="page" from="67" to="82" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deriving the pricing power of product features by mining consumer reviews</title>
		<author>
			<persName><forename type="first">N</forename><surname>Archak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1485" to="1509" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Bird</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Loper</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Klein</surname></persName>
		</author>
		<title level="m">Natural Language Processing with Python</title>
				<meeting><address><addrLine>Sebastopol, CA</addrLine></address></meeting>
		<imprint>
			<publisher>O&apos;Reilly Media Inc</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Database models and managerial intuition: 50% model + 50% manager</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">C</forename><surname>Blattberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">J</forename><surname>Hoch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="887" to="899" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Dynamic topic models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Lafferty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 23rd Internat. Conf. Machine Learn</title>
				<editor>
			<persName><forename type="first">D</forename><surname>Cohen</surname></persName>
			<persName><forename type="first">A</forename><surname>Moore</surname></persName>
		</editor>
		<meeting>23rd Internat. Conf. Machine Learn<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2006" />
			<biblScope unit="page" from="113" to="120" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Latent Dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Machine Learn. Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Race differentials in obesity: The impact of place</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">D</forename><surname>Boardman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Saint Onge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">G</forename><surname>Rogers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">T</forename><surname>Denney</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Health Soc. Behav</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="229" to="243" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Calorie posting in chain restaurants</title>
		<author>
			<persName><forename type="first">B</forename><surname>Bollinger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Leslie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sorensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. Econom. J.: Econom. Policy</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="91" to="128" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Sentence-based text analysis for customer reviews</title>
		<author>
			<persName><forename type="first">J</forename><surname>Büschken</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="953" to="975" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A density-based method for adaptive LDA model selection</title>
		<author>
			<persName><forename type="first">J</forename><surname>Cao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Tang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurocomputing</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="issue">7-9</biblScope>
			<biblScope unit="page" from="1775" to="1781" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Reading tea leaves: How humans interpret topic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Boyd-Graber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gerrish</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Neural Inform. Processing Systems</title>
		<editor>Bengio Y, Schuurmans D, Lafferty JD, Williams CKI, Culotta A</editor>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Estimating aggregate consumer preferences from online product reviews</title>
		<author>
			<persName><forename type="first">R</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Trusov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Res. Marketing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="293" to="307" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">LIA at TREC 2012 Web track: Unsupervised search concepts identification from general sources of information</title>
		<author>
			<persName><forename type="first">R</forename><surname>Deveaud</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bellot</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 21th Text Retrieval Conf. (TREC 2012)</title>
				<meeting>21th Text Retrieval Conf. (TREC 2012)<address><addrLine>Gaithersburg, MD</addrLine></address></meeting>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Multiple hypergeometric functions: Probabilistic interpretations and statistical uses</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Dickey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Amer. Statist. Assoc</title>
		<imprint>
			<biblScope unit="volume">78</biblScope>
			<biblScope unit="issue">383</biblScope>
			<biblScope unit="page" from="628" to="637" />
			<date type="published" when="1983" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Supplementing menu labeling with calorie recommendations to test for facilitation effects</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Downs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Wisdom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wansink</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Loewenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. J. Public Health</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1604" to="1609" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">From story line to box office: A new approach for green-lighting movie scripts</title>
		<author>
			<persName><forename type="first">J</forename><surname>Eliashberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="881" to="893" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Annual medical spending attributable to obesity: Payer and service specific estimates</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Finkelstein</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Trogdon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Dietz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health Affairs</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="822" to="831" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Designing ranking systems for hotels on travel search engines by mining user-generated and crowdsourced content</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="493" to="520" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Sequential and temporal dynamics of online opinion</title>
		<author>
			<persName><forename type="first">D</forename><surname>Godes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Silva</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="448" to="473" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The voice of the customer</title>
		<author>
			<persName><forename type="first">A</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<author>
			<persName><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<title level="m">Finding scientific topics. Proc. Natl. Acad. Sci. USA</title>
				<imprint>
			<date type="published" when="2004" />
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="page" from="5228" to="5235" />
		</imprint>
	</monogr>
	<note>Suppl</note>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Incorporating lexical priors into topic models</title>
		<author>
			<persName><forename type="first">J</forename><surname>Jagarlamudi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Daumé</surname></persName>
		</author>
		<author>
			<persName><surname>Iii</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Udupa</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 13th Conf. Eur. Chapter Assoc. Comput. Linguistics</title>
				<meeting>13th Conf. Eur. Chapter Assoc. Comput. Linguistics</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="204" to="213" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">FDA head says menu labeling &quot;thorny&quot; issue</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">C</forename><surname>Jalonick</surname></persName>
		</author>
		<ptr target="http://www.foxnews.com/health/2013/03/12/fda-head-says-menu-labeling-thorny-issue.html" />
		<imprint>
			<date type="published" when="2013-03-12" />
			<publisher>Associated Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">On information and sufficiency</title>
		<author>
			<persName><forename type="first">S</forename><surname>Kullback</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Leibler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann. Math. Statist</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="79" to="86" />
			<date type="published" when="1951" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Menu labeling as a potential strategy for combating the obesity epidemic: A health impact assessment</title>
		<author>
			<persName><forename type="first">T</forename><surname>Kuo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">J</forename><surname>Jarosz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Simon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Fielding</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. J. Public Health</title>
		<imprint>
			<biblScope unit="volume">99</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1680" to="1686" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Automated marketing research using online customer reviews</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="881" to="894" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Divergence measures based on the Shannon entropy</title>
		<author>
			<persName><forename type="first">J</forename><surname>Lin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Inform. Theory</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="145" to="151" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Multi-aspect sentiment analysis with topic models</title>
		<author>
			<persName><forename type="first">B</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Cardie</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Tsou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Spiliopoulou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Cook</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Pei</forename><forename type="middle">J</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><surname>Zaïane</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Data Mining Workshops (ICDMW), 2011 IEEE 11th Internat. Conf</title>
				<imprint>
			<publisher>IEEE Computer Society</publisher>
			<date type="published" when="2011" />
			<biblScope unit="page" from="81" to="88" />
		</imprint>
	</monogr>
	<note>Washington, DC</note>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Big data: The next frontier for innovation, competition, and productivity</title>
		<author>
			<persName><forename type="first">J</forename><surname>Manyika</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Chui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Bughin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Dobbs</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Roxburgh</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">H</forename><surname>Byers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>McKinsey Global Institute</publisher>
			<pubPlace>Chicago</pubPlace>
		</imprint>
	</monogr>
	<note type="report_type">Report</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Marketing Science</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="726" to="746" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Topic models conditioned on arbitrary features with Dirichlet-multinomial regression</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Twenty-Fourth Conf. Annual Conf. Uncertainty Artificial Intelligence</title>
				<meeting>Twenty-Fourth Conf. Annual Conf. Uncertainty Artificial Intelligence<address><addrLine>Arlington, VA</addrLine></address></meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Optimizing semantic coherence in topic models</title>
		<author>
			<persName><forename type="first">D</forename><surname>Mimno</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">M</forename><surname>Wallach</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Talley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Leenders</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Mccallum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Conf. Empirical Methods Natural Language Processing</title>
				<meeting>Conf. Empirical Methods Natural Language essing</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="262" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Mine your own business: Market-structure surveillance through text mining</title>
		<author>
			<persName><forename type="first">O</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goldenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fresko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="521" to="543" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The impact of health claims on consumer search and product evaluation outcomes: Results from FDA experimental data</title>
		<author>
			<persName><forename type="first">B</forename><surname>Roe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">S</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">M</forename><surname>Derby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Public Policy Marketing</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="89" to="105" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The authortopic model for authors and documents</title>
		<author>
			<persName><forename type="first">M</forename><surname>Rosen-Zvi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 20th Conf. Uncertainty Artificial Intelligence</title>
				<meeting>20th Conf. Uncertainty Artificial Intelligence<address><addrLine>Arlington, VA</addrLine></address></meeting>
		<imprint>
			<publisher>AUAI Press</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="487" to="494" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">Probabilistic topic models. Handbook Latent Semantic Anal</title>
		<author>
			<persName><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">427</biblScope>
			<biblScope unit="page" from="424" to="440" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Mining marketing meaning from chatter: Strategic brand analysis of big data using latent Dirichlet allocation</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tirunillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="463" to="479" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Motion pictures: Consumers, channels, and intuition</title>
		<author>
			<persName><forename type="first">B</forename><surname>Wierenga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="674" to="677" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Judgmental versus statistical prediction: Information asymmetry and combination rules</title>
		<author>
			<persName><forename type="first">I</forename><surname>Yaniv</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Sci</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="58" to="62" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
