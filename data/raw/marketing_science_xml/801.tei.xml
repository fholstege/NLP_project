<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2005-01-25">January 25, 2005</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Michael</forename><surname>Yee</surname></persName>
							<email>myee@ll.mit.edu</email>
						</author>
						<author>
							<persName><forename type="first">Ely</forename><surname>Dahan</surname></persName>
							<email>edahan@ucla.edu</email>
						</author>
						<author>
							<persName><forename type="first">John</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
							<email>jhauser@mit.edu</email>
						</author>
						<author>
							<persName><forename type="first">James</forename><surname>Orlin</surname></persName>
							<email>jorlin@mit.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="laboratory">Lincoln Laboratory</orgName>
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<addrLine>244 Wood Street</addrLine>
									<postCode>02420-9108</postCode>
									<settlement>Lexington</settlement>
									<region>Massachusetts</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">UCLA Anderson School</orgName>
								<address>
									<addrLine>110 Westwood Plaza, B-514</addrLine>
									<postCode>90095</postCode>
									<settlement>Los Angeles</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<addrLine>E40-179, 50 Memorial Drive</addrLine>
									<postCode>02142</postCode>
									<settlement>Cambridge</settlement>
									<region>Massachusetts</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="institution">Massachusetts Institute of Technology</orgName>
								<address>
									<addrLine>E53-363, 50 Memorial Drive</addrLine>
									<postCode>02142</postCode>
									<settlement>Cambridge</settlement>
									<region>Massachusetts</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<address>
									<settlement>Delray Beach, Florida</settlement>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 e 1526-548X 07 2604 0532</idno>
						<imprint>
							<date type="published" when="2005-01-25">January 25, 2005</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.1060.0213</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>lexicography</term>
					<term>noncompensatory decision rules</term>
					<term>choice heuristics</term>
					<term>optimization methods in marketing</term>
					<term>conjoint analysis</term>
					<term>product development</term>
					<term>consideration sets History: This paper was received</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>G reedoid languages provide a basis to infer best-fitting noncompensatory decision rules from full-rank conjoint data or partial-rank data such as consider-then-rank, consider-only, or choice data. Potential decision rules include elimination by aspects, acceptance by aspects, lexicographic by features, and a mixed-rule lexicographic by aspects (LBA) that nests the other rules. We provide a dynamic program that makes estimation practical for a moderately large numbers of aspects.</p><p>We test greedoid methods with applications to SmartPhones (339 respondents, both full-rank and considerthen-rank data) and computers (201 respondents from <ref type="bibr" target="#b37">Lenk et al. 1996)</ref>. We compare LBA to two compensatory benchmarks: hierarchical Bayes ranked logit (HBRL) and LINMAP. For each benchmark, we consider an unconstrained model and a model constrained so that aspects are truly compensatory. For both data sets, LBA predicts (new task) holdouts at least as well as compensatory methods for the majority of the respondents. LBA's relative predictive ability increases (ranks and choices) if the task is full rank rather than consider then rank. LBA's relative predictive ability does not change if (1) we allow respondents to presort profiles, or (2) we increase the number of profiles in a consider-then-rank task from 16 to 32. We examine trade-offs between effort and accuracy for the type of task and the number of profiles.</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Noncompensatory Decision Processes</head><p>We explore new methods to study heuristic decision processes. These methods use "greedoid languages" and dynamic programming to solve combinatorial computational problems significantly more efficiently than as reported in the extant literature. We demonstrate how the methods can be used to identify the heuristic decision processes that best describe observed consideration and/or choice. Because the methods work with either rank-order data or consider-then-rank data, we are able to examine empirically how well each data-collection format predicts choice. A consider-then-rank task might be more enjoyable and less effortful for respondents (e.g., <ref type="bibr" target="#b41">Malhotra 1986</ref><ref type="bibr" target="#b49">, Oppewal et al. 1994</ref><ref type="bibr" target="#b58">, Srinivasan and Park 1997</ref> and, hence, might mean shorter questionnaires (less cost) and might encourage more respondents to complete the task (fewer nonresponse issues). Noncompensatory decision processes are important both academically and managerially. Academically, there is ample evidence in the psychology, consumer behavior, and marketing science literatures that consumers simplify consideration and/or choice with a heuristic process. 1 Such processes are identified using a variety of methodologies ranging from verbal <ref type="bibr">1</ref> Examples include <ref type="bibr" target="#b1">Bettman et al. (1998)</ref>, <ref type="bibr" target="#b0">Bettman and Park (1980)</ref>, <ref type="bibr" target="#b3">Br√∂der (2000)</ref>, <ref type="bibr" target="#b8">Einhorn (1970)</ref>, <ref type="bibr" target="#b9">Einhorn and Hogarth (1981)</ref>, <ref type="bibr" target="#b15">Gigerenzer and Goldstein (1996)</ref>, <ref type="bibr" target="#b19">Hauser (1978)</ref>, <ref type="bibr" target="#b21">Hauser and Wernerfelt (1990)</ref>, <ref type="bibr" target="#b27">Johnson and Meyer (1984)</ref>, <ref type="bibr" target="#b40">Luce et al. (1999)</ref>, <ref type="bibr" target="#b42">Martignon and Hoffrage (2002)</ref>, <ref type="bibr" target="#b45">Montgomery and Svenson (1976)</ref>, <ref type="bibr" target="#b50">Payne (1976)</ref>, <ref type="bibr" target="#b52">Payne et al. (1993)</ref>, <ref type="bibr" target="#b54">Roberts and Lattin (1991)</ref>, <ref type="bibr" target="#b56">Shugan (1980)</ref>, <ref type="bibr" target="#b65">Urban and Hauser (2004)</ref>. <ref type="bibr">Yee, Dahan, Hauser, and Orlin: Greedoid-Based</ref>  Cell Phones and SmartPhones process tracing to information display mechanisms (e.g., Mouselab), and researchers have studied how consumers adapt and/or construct decision processes based on the characteristics of the decision environment (see <ref type="bibr" target="#b52">Payne et al. 1993</ref> for a review). Greedoid methods attempt to infer such processes from less intrusive observations where respondents are asked either to rank profiles, provide partial profile orders, or indicate whether or not they will consider a profile. These methods are, thus, complementary to existing methods.</p><note type="other">Noncompensatory Inference</note><p>Consider Figure <ref type="figure">1</ref> from a SmartPhone Web site 2 that encourages consumers to select SmartPhones for further consideration based on features such as carrier, brand, size, and price. Consumers can choose to keep or eliminate levels of these features to form a consideration set. If consumers use a heuristic, noncompensatory process and we can identify the features that drive the process, then the Web site designer knows which features to use, the product designer knows which features to include in the product line, and the advertising manager knows which features to emphasize.</p><p>Typically, compensatory conjoint analysis methods are used in these situations to identify the features with the largest partworths. Such methods are computationally tractable and often provide excellent paramorphic approximations of consumer consideration and/or choice processes. However, if consumers are not making compensatory trade-offs among features but, rather, are using noncompensatory heuristics, a method to identify those heuristics might be appealing. Heretofore, analyzing rank, partial rank, or consideration data to infer noncompensatory processes has not been computationally feasible for moderately sized problems because the number of potential noncompensatory descriptions grows as n! where n is the number of distinct feature levels (aspects). <ref type="bibr">3</ref> We provide an algorithm that can identify 534 Marketing Science 26(4), pp. 532-549, ¬© 2007 INFORMS the best-fitting heuristic in seconds (rather than days). We illustrate the algorithm on two data sets and with experiments that vary the consumers' decision environment. Some of these experimental manipulations are designed to replicate existing findings; some experimental manipulations are new.</p><p>The paper proceeds as follows. First, we briefly review the literature on heuristic processes and provide examples. Next, we describe the respondents' tasks. We present greedoid-based methods and discuss the traditional methods to which they are compared. We test the methods empirically in a 2 √ó 2 experiment in which 339 respondents choose from 32 Smart-Phones chosen from a fractional factorial 4 3 2 4 design. We examine the impact of the number of profiles, the respondents' tasks, and sorting on the relative predictability of noncompensatory models. For comparison, we reanalyze classic data in which 201 respondents rated 16 computers chosen from a fractional factorial 2 13 design. Finally, we close by illustrating how greedoid analysis provides managerial insight.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Brief Review of Noncompensatory Decision Processes</head><p>We consider decision processes in which products are represented by their features and consumers decide which product to purchase or consume. While the process by which consumers encode products into features can be complex and important <ref type="bibr" target="#b9">(Einhorn and Hogarth 1981)</ref>, that topic is beyond the scope of this paper. Our scope includes situations in which such encoding is feasible and reasonably descriptive of consumer decision processes. For practical applications, we might use voice-of-the-customer methods to identify a representative set of features (e.g., <ref type="bibr">Hauser 1993, Zaltman 1997)</ref>. When a feature is binary, it is called an aspect (e.g., <ref type="bibr" target="#b64">Tversky 1972)</ref>. Multilevel features can be considered collections of aspects that are related (Verizon versus Cingular versus Nextel versus Sprint for SmartPhone service providers).</p><p>A profile is the aspect description of a product.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Noncompensatory Processes</head><p>In a compensatory process, high levels on some aspects compensate for low levels on other aspects. In a noncompensatory process, high levels on some aspects cannot compensate for low levels on other aspects. One well-known noncompensatory process is a lexicographic process: Consumers evaluate profiles first by one feature, then another, until a judgment or choice is made <ref type="bibr" target="#b11">(Fishburn 1974</ref><ref type="bibr" target="#b46">, Nakamura 2002</ref>. For example, consider an illustrative example in which consumers rank SmartPhones that differ on the features of brand and operating system. As illustrated by the first row of Figure <ref type="figure">2</ref>, a consumer might rank first on the feature of brand, putting first all Black-Berry SmartPhones, then Nokias, Samsungs, and, last, Sony Ericssons, then rank on the feature of operating system (within brand) by putting all Microsoft-based SmartPhones before PalmOS-based SmartPhones. We call this process lexicographic by features (LBF).</p><p>Other heuristics are possible. A consumer might rank SmartPhones by aspects, say, by first accepting BlackBerry SmartPhones, then Microsoft-based Smart-Phones, Nokias, and, finally, Samsungs until all SmartPhones are ranked (second row of Figure <ref type="figure">2</ref>). (Whenever there is a tie, the consumer moves to the next aspect in the lexicographic order.) For ease of reference, we call such processes acceptance by aspects (ABA). ABA is related to Tversky's elimination-byaspects process (EBA) in which consumers successively eliminate aspects (third row of Figure <ref type="figure">2</ref>). Tversky defines EBA as a random process in which the probability that an aspect is chosen is proportional to its measure. In this paper, we follow <ref type="bibr" target="#b28">Johnson et al. (1989)</ref>, <ref type="bibr" target="#b45">Montgomery and Svenson (1976)</ref>, <ref type="bibr" target="#b51">Payne et al. (1988)</ref>, and <ref type="bibr" target="#b62">Thorngate (1980)</ref>, and use EBA to refer to a deterministic process in which an aspect order is given. Finally, consumers may mix acceptance and elimination criteria. We call such a mixed process lexicographic by aspects (LBA). Because ABA, EBA, and LBF are special cases of LBA, we focus on LBA.</p><p>When a feature has more than two aspects, eliminating an aspect (Sony Ericsson) is the same as accepting its complement (BlackBerry ‚à™ Nokia ‚à™ Samsung), but EBA is not equivalent to an ABA process of accepting BlackBerry, then Nokia, then Samsung. The ABA process orders BlackBerry-Nokia-Samsung, while the EBA process does not. However, for twolevel aspects, there exists an equivalent EBA process for every ABA process. Figure <ref type="figure">3</ref> illustrates this equivalency for SmartPhones that differ on three binary aspects (brand, operating system, and carrier).</p><p>ABA, EBA, LBA, and LBF define orderings and hence can be used to explain either full or partial rankings, including respondent tasks such as rank all profiles, choose a single profile, or indicate which profiles are worth further consideration. Finally, the processes can be modified to include constraints within features such as "lower prices are always preferred to higher prices."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Compensatory Processes</head><p>Many authors represent a compensatory process as an arithmetic rule in which each aspect receives a weight and consumers sum the weights associated with the aspects in a profile to form "utility." Consumers then choose the product with the highest "utility." However, not all sets of aspect partworths imply a compensatory process. If the aspect partworths follow  an appropriate geometric sequence (e.g., 2 1‚àín for the nth aspect), then an additive model produces a lexicographic process in which no set of lower ranked aspects can compensate for the lack of a higher ranked aspect <ref type="bibr" target="#b26">(Jedidi et al. 1996</ref><ref type="bibr" target="#b33">, Kohli and Jedidi 2004</ref><ref type="bibr" target="#b48">, Olshavsky and Acito 1980</ref>. Thus, we reserve the word "compensatory" for additive models that are truly compensatory, e.g., when the partworths are constrained so that the presence of other aspects can compensate for the lack of an important aspect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Constructive Processes</head><p>Research suggests that consumer decision processes are contingent on many context effects including the range of aspects, correlation among aspects, base-rate information, reference points, the size of the choice set, the relevance of the decision, and the difficulty of comparison (see review in <ref type="bibr" target="#b52">Payne et al. 1993)</ref>. To the extent that data collection approximates the essential characteristics of real choice environments, greedoid methods provide insight into how context affects respondents' tendency to use noncompensatory decision rules. Our empirical experiments illustrate this context-dependent variation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Existing Methods to Infer Noncompensatory Processes</head><p>Many measurement examples in the marketing science literature are consistent with noncompensatory decision processes. For example, both <ref type="bibr" target="#b60">Srinivasan and Wyner's (1988)</ref> Casemap and <ref type="bibr" target="#b29">Johnson's (1991)</ref> adaptive conjoint analysis (ACA) include steps in which respondents are asked to eliminate unacceptable levels. Because this task is often difficult for respondents <ref type="bibr" target="#b17">(Green et al. 1988</ref><ref type="bibr" target="#b32">, Klein 1988</ref>, other researchers have attempted to infer the elimination process in a single estimation step <ref type="bibr" target="#b7">(DeSarbo et al. 1996</ref><ref type="bibr" target="#b16">, Gilbride and Allenby 2004</ref><ref type="bibr" target="#b13">, Gensch 1987</ref><ref type="bibr" target="#b14">, Gensch and Soofi 1995</ref><ref type="bibr" target="#b25">, Jedidi and Kohli 2005</ref><ref type="bibr" target="#b26">, Jedidi et al. 1996</ref><ref type="bibr" target="#b31">, Kim 2004</ref><ref type="bibr" target="#b54">, Roberts and Lattin 1991</ref><ref type="bibr" target="#b61">, Swait 2001</ref>. For example, <ref type="bibr">Gilbride and Allenby (2004, p. 399)</ref> use hierarchical Bayes methods to analyze choice-based conjoint data to infer screening rules for cameras. They estimate that 58% of the respondents screen on a single feature, 33% on two features, 2% on three features, and 8% use fully compensatory processes. In psychology, <ref type="bibr" target="#b3">Br√∂der (2000)</ref> analyzes choices among two profiles described by four aspects. He compares the fit of an unconstrained additive model to two additive models: (1) a model in which the aspects are constrained to 2 1‚àín (noncompensatory), and (2) a model with equal weights <ref type="bibr">(Dawes' 1979 model)</ref>. In one experiment, 28% of the 40 respondents are classified as noncompensatory while none are classified as Dawes'. The remaining 72% could not be classified. <ref type="bibr" target="#b3">Br√∂der's (2000)</ref> method is feasible for a small number of aspects-with four aspects, the ratio of the largest-to-smallest partworth in a noncompensatory model is 2 3 ‚Üí 8 1. For 16 aspects, as in our experiments, the range of partworths in a noncompensatory model would be at least 2 15 ‚Üí 32 768 1, a ratio that puts severe strains on any statistical regression-like procedure. <ref type="bibr">4</ref> Kohli <ref type="bibr" target="#b33">and Jedidi (2004)</ref> propose a greedy heuristic to estimate a linear representation of lexicographic processes from metric conjoint data. <ref type="bibr">5</ref> They modify <ref type="bibr" target="#b3">Br√∂der's (2000)</ref> procedure by computing the number of violated pairs between predicted and observed rank orders for both additive and 2 1‚àín models. Their t-statistics suggest that a 2 1‚àín representation is not significantly different from an unconstrained additive model for 67% of the 69 respondents who evaluated profiles with 5 features (11 aspects). Our approach differs from <ref type="bibr" target="#b33">Kohli and Jedidi (2004)</ref> along a number of dimensions including respondent task, estimation algorithms, and focus. Nonetheless, these parallel independent studies suggest many opportunities to apply discrete optimization methods to infer noncompensatory processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Respondents' Tasks</head><p>It is easier to understand greedoid methods if we first review the respondents' tasks as illustrated with an example from our empirical experiments. <ref type="bibr">6</ref> In Figure <ref type="figure">4</ref>, respondents are first introduced to the product category and the 7 features (16 aspects). Figure <ref type="figure">4a</ref> is one of many screens. Respondents are then presented with SmartPhone profiles (Figure <ref type="figure">4b</ref>). Respondents in the consider-then-rank cells simply click on those profiles they would seriously consider-part of the screen is shown in Figure <ref type="figure">4c</ref>. These respondents then see only their considered profiles; they are asked to rank them by successively clicking on the profile they would choose from the offered set (Figure <ref type="figure">4d</ref>). That profile disappears and they choose again until all considered profiles are chosen. Respondents in the full-rank cells skip the consideration task. In Figure <ref type="figure">4</ref>, we illustrate an additional twist. Some, but not all, respondents were allowed to presort the profiles in either or both tasks. A priori, we expect the ability to sort tasks to encourage lexicographic processing. In a later section, we describe the full experimental protocol (incentives, filler tasks, holdout measures, etc.) and provide statistics such as response rates. Two comments are in order. First, respondents are not asked to indicate unacceptable feature levels (aspects) directly. Elimination aspects, if any, are inferred from the data. Second, the measurement tasks themselves do not assume that either judgment (consideration) or decision (choice or rank) processes are compensatory or that they are noncompensatory.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Identifying Lexicographic Processes with Greedoid Languages</head><p>For ease of exposition, we focus our discussion on lexicographic aspect orders that represent acceptance-byaspects (ABA) decision rules. Elimination by aspects (EBA) can be estimated with the same algorithm by redefining aspects by their negation; lexicographic by features (LBF) can be estimated by imposing constraints on the aspect orders; and lexicographic by aspects (LBA) can be estimated with only a slight modification in the algorithms.</p><p>To identify the best lexicographic representation for a given set of observed data, we develop a procedure to identify the aspect order that maximizes fit (minimizes errors) on some metric. Unfortunately, as <ref type="bibr">Martignon and Hoffrage (2002, Theorem 2, p. 39)</ref> demonstrate, this problem is NP-hard. They suggest exhaustive enumeration. For example, they sought to determine the aspect order (state capital, soccer team in the national league, etc.) that best explains the relative populations of pairs of German cities. Because their problem had nine aspects, they needed to search 9! orderings-"a UNIX machine" took two days to find the best ordering. Their problem is a relatively small problem. For our 4 3 2 4 empirical problem, exhaustive enumeration needs to check 7! √ó 4! 3 orders for LBF, 16! aspect orders for ABA or EBA, and 2 16 √ó 16! orders for LBA. 7 Because 7! √ó 4! 3 = 192 √ó 9!, their algorithm would have taken over a year per respondent for LBF. Because 16! = 300 300 √ó 7! √ó 4! 3 , their algorithm would have taken over 300 millennia for ABA or EBA and substantially longer for LBA.</p><p>Marketing Science 26(4), pp. 532-549, ¬© 2007 INFORMS Although faster computers help, it is clear that practical analysis for moderate-to-large problems requires a more efficient algorithm.</p><p>We address computational efficiency in two steps. We first demonstrate that the collection of lexicographic orders of aspects, as they relate to a partial ordering of profiles, forms a "greedoid language." 8 This enables us to use established results to find the appropriate lexicographic aspect order, if one exists, much more efficiently than existing methods. Because the profile ordering need only be partial, we can handle consideration, partial-rank, full-rank, or choice data.</p><p>A perfect lexicographic ordering of aspects is extremely rare. With 32 profiles, there are 32! rank orders but only 2 16 √ó 16! aspect orders. Thus, the chances that an arbitrary profile order is consistent with an aspect order is less than 5 2 √ó 10 ‚àí18 . Furthermore, any respondent errors are likely to cause the data to be inconsistent with an aspect order. <ref type="bibr">9</ref> Using the greedoid structure, we prove that a dynamic program can find the lexicographic ordering that maximizes a commonly used goodness-of-fit metric. The dynamic programming algorithm substantially reduces computation and makes it feasible to identify the best lexicographic ordering for large samples of respondents and moderately large numbers of aspects. For example, for 16 aspects, the dynamic program need only consider 2 16 = 65 536 subsets of aspects, much less than the 1 4 √ó 10 18 potential LBA aspect orders. We begin with notation and definitions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Partial Orders and Consistency</head><p>Let N be the total number of aspects, and let L = L 1 L a be an ordered subset of a aspects where a ‚â§ N . For a given profile P , we let L i P be one if profile P contains aspect L i , and zero otherwise. We write P L P if L i P = 1 and L i P = 0, where i is the first (smallest) index for which L i P = L i P . For example, in the ABA row of Figure <ref type="figure">2</ref>, L = BlackBerry Microsoft Nokia Samsung . The first ranked SmartPhone is P = BlackBerry Microsoft .</p><formula xml:id="formula_0">L 1 P = 1, L 2 P = 1, L 3 P = 0, and L 4 P = 0. P = BlackBerry Microsoft L P = BlackBerry PalmOS because L 2 P = 1 and L 2 P = 0.</formula><p>Each totally ordered set L of aspects implies a unique order of profile preferences, but the converse is not true. Different orders of aspects can lead to the same order of profiles. This is particularly true for the consideration task. If a respondent will consider only Verizon SmartPhones that flip open, then the orders L = Verizon flip and L = flip Verizon are both consistent with the respondent's consideration process.</p><p>Suppose that X is a partial order of profiles revealed by the respondent. For example, X might define which profiles are in a consideration set and which are not, or X might define a rank order within a consideration set. We write P X P if profile P is preferred to (or ranked higher than) profile P according to X. We say that an ordered subset L of aspects is lexicoinconsistent with a partial order X of profiles if there are profiles P and P that are ranked differently by aspect order L and profile order X. In symbols, L and X are inconsistent if there exist P and P such that P X P while P L P . Otherwise, we say that L and X are lexicoconsistent. For example, in the ABA row of Figure <ref type="figure">2</ref>, the aspect order in the ranking rule column (BlackBerry, Microsoft, Nokia, Samsung) is lexicoconsistent with the order of the eight profiles in the final column.</p><p>If L is an ordered subset of aspects and e L is an aspect, then let L e denote the ordered subset of aspects obtained by appending aspect e to the end of L. Let L\Y denote the set L with all elements of Y deleted. For example, if L = BlackBerry Microsoft Nokia Samsung , e = flip, and Y = (Samsung), then L e = BlackBerry Microsoft Nokia Samsung flip and L\Y = BlackBerry Microsoft Nokia . Finally, let be the empty set, and let the number of elements in a set L be denoted by L .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Greedoid Languages</head><p>Greedoid languages were developed by <ref type="bibr" target="#b35">Korte and Lov√°sz (1985)</ref> to study conditions under which a greedy algorithm can solve optimization problems. <ref type="bibr">10</ref> They have proved useful in sequencing and allocation problems (e.g., <ref type="bibr" target="#b47">Ni√±o-Mora 2000)</ref>. We believe that this is the first application in marketing or consumer behavior. <ref type="bibr" target="#b2">Bj√∂rner and Ziegler (1992)</ref> and <ref type="bibr" target="#b36">Korte et al. (1991)</ref> are excellent references that provide numerous examples of greedoids. In this work, we introduce a new type of greedoid where partial orders of profiles (X induce a greedoid language defined on aspect orders (L . It is this linkage that enables us to identify LBA and other aspect-or feature-based explanations of profile orders.</p><p>Let E be a set of aspects and let G be a collection of ordered subsets of E. We say that G is a greedoid language if the following conditions are satisfied:</p><p>1. ‚àà G. 2. If L ‚àà G, and if element e ‚àà E is the last element of L, then L\e ‚àà G.</p><p>3. If L ‚àà G and if L ‚àà G and if L &gt; L , then there is an element e in L \L such thatL = L e andL ‚àà G.</p><p>In the appendix, we demonstrate that the set of partial orderings of the aspects that are consistent with a partial ordering of the profiles form a greedoid language. Corollary 1 follows from Proposition 1 because Algorithm 1 is a greedy algorithm that either finds a lexicoconsistent aspect order, L ‚àà G, of maximum length or terminates early. <ref type="bibr">11</ref> Proposition 1. Let E be the set of aspects, and let X be a partial order on the profiles. Let G be the collection of ordered subsets of E that are lexicoconsistent with X. Then, G is a greedoid language.</p><p>Corollary 1. Algorithm 1 determines whether there exists a lexicographic ordering of aspects L that is lexicoconsistent with a profile ordering X and, if an ordering exists, finds an ordering.</p><p>Algorithm 1 (for determining if L is lexicoconsistent with X). begin L = while L &lt; E do begin if (there exists e in E\L such that L e is lexicoconsistent with X) replace L with L e else quit (because X is not lexicographic) end end Finding Lexicographic Descriptions that Maximize Fit If there is no ordering of aspects that is lexicoconsistent with a profile order, i.e., Algorithm 1 terminates with L &lt; E , we might still like to find ordering(s) of aspects that best fit a profile order. As a measure of fit between aspect orders (L and profiles (X , we relate "closeness" to the number of inconsistencies (violated pairs) between the profile order induced by L and that observed in X. <ref type="bibr">12</ref> We now develop an algorithm to find the closest lexicographic ordering. We begin with Proposition 2, which explores the implications of the greedoid structure. Proposition 2 implies Algorithm 2, which is a dynamic program on the set of all subsets of the aspects. Because this set has dimensionality 2 n , and because 2 n is substantially less than n!, Algorithm 2 can still be feasible when exhaustive enumeration is not.</p><p>In the appendix, we prove Proposition 2 by showing that the marginal inconsistencies induced by adding a new aspect to an existing aspect order depend only on that aspect and the set of aspects preceding it, but not on the order of the preceding aspects. This implies a (forward) recursive structure that allows the problem to be solved with dynamic programming (Corollary 2). This dynamic program is similar to <ref type="bibr" target="#b23">Held and Karp's (1962)</ref> classic dynamic programming algorithm for the traveling-salesman problem. For those readers not familiar with dynamic programming, we provide a technical appendix (available at http://mktsci.pubs.informs.org on the Marketing Science Web site) that illustrates how Algorithm 2 would apply to a simple playing card example.</p><p>Proposition 2. Let L and L be two different permutations of a subset E of aspects, and let e be any aspect not in E . Then, the number of lexico-inconsistencies directly caused by e in L e is the same as the number of inconsistencies caused by e in L e .</p><p>Corollary 2. Algorithm 2 identifies the lexicographic ordering of aspects L that best fits the (partial) ordering of profiles X.</p><p>When Algorithm 2 terminates, J E is the minimum number of lexico-inconsistencies between the respondent's profile ordering X and any ordering of the aspects in E. L E are the best-fitting lexicographic orders, which might or might not be unique. Algorithm 2 applies directly to either acceptance by aspects or elimination by aspects. Fortunately, for lexicographic by aspects, the number of steps in the algorithm only doubles. This is a significant improvement relative to exhaustive enumeration, which would cause the number of steps to grow by a factor of 2 n for LBA. Specifically, in the innermost loop of Algorithm 2 we need only check both i and its negation. We call Algorithm 2 a greedoid-based dynamic program.</p><p>Algorithm 2 (for finding aspect order L that provides the best fit to profile order X). begin </p><formula xml:id="formula_1">J = 0 for k = 1 to E for all (unordered) subsets, S ‚äÜ E of size k for all i ‚àà S c S\ i i = number of inconsistencies caused by aspect i following set S\i next i J S = min i‚ààS J S\ i + c S\ i i L S</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>next S next k end</head><p>We programmed Algorithm 2 in Java running on an IBM 1.7-GHz laptop. For a 16-aspect problem, the run time was approximately 1.85 seconds per respondent. Relative to <ref type="bibr" target="#b42">Martignon and Hoffrage (2002)</ref>, some savings are due to Algorithm 2 and some are due to faster computers. We project that <ref type="bibr" target="#b42">Martignon and Hoffrage's (2002)</ref> exhaustive enumeration would take 14 years for a 16-aspect EBA problem on the same computer. <ref type="bibr">13</ref> We provide two further results. Proposition 3 extends the theory (and Algorithms 1 and 2) to allow the researcher to place greater emphasis on some ordered pairs in X, say, the ordered pairs corresponding to highly ranked profiles. Proposition 4 reduces the running time of Algorithm 2 by enabling it to begin with any consistent ordered subset of aspects (e.g., the largest such ordered subset) and then use the dynamic program on the remaining aspects.</p><p>Proposition 3. If weights are associated with each ordered pair in X, then (1) the new G is a greedoid language, (2) Algorithm 1 determines whether there exists an L lexicoconsistent with X, (3) Proposition 2 extends to the new G, and (4) Algorithm 2 finds the best fit if c ‚Ä¢ is redefined to c S\ i i = sum of weighted violations caused by aspect i following set S\ i . Proposition 4. Suppose that L is an ordered subset of aspects that is lexicoconsistent with the preferences of X. Then, there is an optimal ordering of aspects that begins with the order L.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Benchmarks</head><p>To evaluate the ability of the greedoid methods to fit partial-or full-rank data and predict holdout validations, we identify benchmark models. Because hierarchical Bayes methods appear to be the most popular method to estimate additive models, our primary comparison is a hierarchical Bayes-ranked logit model (HBRL, e.g., <ref type="bibr" target="#b55">Rossi and Allenby 2003)</ref>. We provide an alternative benchmark with linear programming estimation (LINMAP). We use the most recent version of LINMAP, which enforces strict rankings <ref type="bibr" target="#b57">(Srinivasan 1998)</ref>. Both benchmark methods predict holdouts slightly better than either traditional LIN-MAP <ref type="bibr" target="#b59">(Srinivasan and Shocker 1973)</ref> or analytic center estimation <ref type="bibr" target="#b63">(Toubia et al. 2003</ref>). <ref type="bibr">14</ref> With HBRL (or LINMAP) we must address the conceptual issue that additive models nest lexicographic models. The best-fitting additive model might estimate partworths that are equivalent to a lexicographic process. For example, estimated partworths that satisfy a 2 1‚àín relationship have this property. This would be fine if our only interest were predictive ability. However, we also seek to use greedoid methods to gain insight on consumers' heuristic processes.</p><p>To estimate additive models that do not nest lexicographic models, we constrain the additive model so that all estimated partworths are truly compensatory. By the principle of optimality, such a constraint cannot be estimated by fitting data. <ref type="bibr">15</ref> On the other hand, such a constraint might improve holdout performance by the principle of complexity control <ref type="bibr" target="#b5">(Cui and</ref><ref type="bibr">Curry 2005, Evgeniou et al. 2005)</ref>.</p><p>The form of our constraints is motivated by behavioral researchers who have sought to identify whether compensatory or noncompensatory models fit or predict observed choices better. For example, <ref type="bibr" target="#b3">Br√∂der (2000)</ref> defines a respondent as compensatory if the respondent's partworths are "not too extreme." Specifically, Br√∂der requires that w ic = w lc for all l = i, where w ic is the partworth of the ith aspect for respondent c. We generalize <ref type="bibr" target="#b3">Br√∂der's (2000)</ref> precedent by defining a respondent as "q-compensatory" if w ic ‚â§ qw lc for all l = i. With this definition, we can examine a continuum between Dawes' (1979) model as tested by Br√∂der q = 1 and the unrestricted additive benchmark q = that nests lexicographic models. Because there is no a priori theory with which to select q, we provide holdout predictions for values of q ranging from 1 to . We estimate q-compensatory benchmarks with rejection sampling in the hierarchical Bayes sampler or by imposing additional constraints on the linear program. We label these q-compensatory benchmarks HBRL(q and LINMAP(q . In a supplemental appendix (available on the Marketing Science Web site), we use synthetic data to explore the implications of q for "true" models that vary from highly compensatory to highly lexicographic. For these simulations, selecting q = 4 provides a reasonable ability to discriminate respondents with "compensatory" partworths from those with "lexicographic" partworths.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">SmartPhone Empirical Study</head><p>To test greedoid methods, we invited respondents to complete a web-based questionnaire about Smart-Phones. The respondents were students drawn from the undergraduate and graduate programs at two universities. To the best of our knowledge, they were unaware of greedoid methods or the purpose of our study. As an incentive to participate, they were offered a one-in-ten chance of winning a laptop bag worth $100, yielding a 63% response rate. Pretests in related contexts suggested that SmartPhones were likely to include noncompensatory features and thus represented an interesting category for a first test of greedoid methods.</p><p>The survey consisted of six phases. The first three phases are as described in Figure <ref type="figure">4</ref>: Respondents reviewed the category and SmartPhone features, indicated which SmartPhones they would consider (in half the cells), and successively chose SmartPhones in order to rank their considered products (or rank all products, depending on cell). Respondents then completed a mini-IQ test to cleanse memory-a task which pretests suggested was engaging and challenging. Following this filler task, respondents completed a holdout task consisting of two sets of four Smart-Phones chosen randomly from a different 32-profile fractional factorial design. <ref type="bibr">16</ref> The final task was a short set of questions about the survey itself-data which we use to compare task difficulty. For the holdout task, to avoid unwanted correlation due to common measurement methods, we used a different interface. Respondents used their pointing device to shuffle the profiles into a rank order as one might sort slides in PowerPoint. Pretests suggested that respondents understood this task and found it different from the task in Figure <ref type="figure">4d</ref>.</p><p>The survey was programmed in PHP and debugged through a series of pretests with 56 respondents chosen from the target population. By the end of the pretests, all technical glitches were removed. Respondents understood the tasks and found them realistic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Design</head><p>Respondents were assigned randomly to experimental cells. The basic experimental design is a 2 √ó 2 design in which respondents complete either a fullrank or a consider-then-rank task and are given the opportunity to presort profiles or not (Figure <ref type="figure">5</ref>). In the consider-then-rank sort cell, respondents could sort prior to consideration and prior to choice. Respondents in the sort cells could re-sort as often as they liked. We also included an additional cell (described below) to test whether the results vary by the number of profiles presented to the respondents in the consider-then-rank cells. This experimental design enables us to test greedoid methods with different data collection tasks and to illustrate how greedoid methods might be used to explore how context affects respondents' processing strategies. <ref type="bibr">16</ref> Future research might investigate the effect of wear-out on lexicographic processing with cells that place the holdout tasks earlier in the survey. See also <ref type="bibr" target="#b20">Hauser and Toubia (2006)</ref> and <ref type="bibr" target="#b38">Liechty et al. (2005)</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task Difficulty</head><p>Greedoid methods can be used to analyze any fullor partial-order respondent task. We first examine whether the consider-then-rank task is more natural and easier for respondents than the full-rank task. The results are reported in Figures <ref type="figure">6a and 6b</ref>. We oriented both axes such that down is better. In the base condition of no sorting, the consider-then-rank task is seen as significantly more enjoyable, accurate, and engaging (t = 2 2, p = 0 03), saves substantial time (3.75 minutes compared to 8.75 minutes,  t = 2 8, p = 0 01), and appears to increase completion rates (94% versus 86%, t = 1 7, p = 0 09). Sorting (as implemented) mitigates these advantages: Neither attitudes, time, nor completion rates are significantly different between the full-rank and consider-thenrank tasks when respondents can presort profiles. 17 A possible explanation is that sorting made the full-rank task "easier" (though not necessarily more enjoyable) and the consider-than-rank task more complex.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Predictive Ability</head><p>We first compare the most general greedoid method (LBA) to the unconstrained additive models HBRL and LINMAP, as averaged across respondents (see Table <ref type="table" target="#tab_3">1</ref>). Holdout predictions are based on two metrics. Hit rate provides fewer observations per respondent (two) and leads to more ties, but it is not optimized directly by either greedoid methods or the benchmarks. The percent of violated pairs provides more observations per respondent (12 potential pairs from two sets of four ranked profiles), but it is the metric optimized by greedoid methods and, to some extent, by LINMAP. Empirically, the two metrics are significantly correlated (&lt; 0 001 level) for all methods and provide similar comparative qualitative interpretations. <ref type="bibr">18</ref> As expected, the unconstrained LINMAP, which nests LBA and optimizes a metric similar to the fit metric, provides the best fit. However, LBA fits almost as well. The more interesting comparisons are on the two holdout metrics. For both metrics, LBA is better than both benchmarks and significantly better on hit rates. It appears that, for these data, greedoid methods are more robust than the unconstrained additive models that could, in theory, fit a lexicographic process. This apparent robustness is consistent with predictions by <ref type="bibr" target="#b44">Mitchell (1997)</ref> and <ref type="bibr">Martignon and Hoffrage (2002, p. 31)</ref>. We address the last column of Table <ref type="table" target="#tab_3">1</ref> later in this section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Comparison to q-compensatory Processes</head><p>Following <ref type="bibr" target="#b3">Br√∂der (2000)</ref>, we examine whether respondents are described better by lexicographic or q-compensatory processes. Three comments are in order. First, this description is paramorphic. We say only that respondents rank (choose, consider) profiles as if they were following one or the other process. Second, we have some confidence in the descriptions because LBA predicts better for synthetic respondents <ref type="bibr">17</ref> For the sorting cells, attitudes (t = 0 9, p = 0 37), time (t = 0 4, p = 0 70), and completion rate (t = 1 1, p = 0 26) are not significantly different. Using analysis of variance, there is an interaction between sorting and task for time, but it is not significant (F = 2 6, p = 0 11). For attitudes only, task is significant (F = 4 9, p = 0 03). <ref type="bibr">18</ref> For example, correlations between the metrics are 0.70 for LBA, 0.64 for HBRL, and 0.66 for LINMAP. who are lexicographic, and a constrained additive model (q-compensatory) predicts better for synthetic respondents who are q-compensatory (see supplemental appendix available on the Marketing Science Web site). Third, for simplicity of exposition, we compare LBA to the HBRL benchmark. This benchmark does slightly better than LINMAP in Table <ref type="table" target="#tab_3">1</ref> and, as we will see later, better for a second data set. Comparisons to LINMAP are in a supplemental appendix (available on the Marketing Science Web site). <ref type="bibr">19</ref> Figure <ref type="figure">7</ref> plots holdout predictions as a function of q. Predictions improve as the models become less constrained (larger q , consistent with a perspective that some aspects are either being processed lexicographically or have large relative partworths. HBRL(q approaches LBA's holdout percent pairs predicted for large q but falls short on holdout hit rates.</p><p>At the level of the individual respondent, comparisons depend upon the choice of q. As an illustration, we use q = 4. When q = 4, the respondent is acting as if he or she is making trade-offs among aspects by weighing their partworths. Furthermore, the analysis of synthetic data suggests that at q = 4 respondents who are truly compensatory are classified as compensatory and respondents who are truly lexicographic are classified as lexicographic.</p><p>For holdout percent pairs, LBA predicts better than HBRL(4) for 56% of the respondents, worse for 43% of the respondents, and tied for 1% of the respondents. On average, LBA's predictive ability is about five percentage points higher than HBRL(4). The corresponding comparative percentages for hit rates are 46%, 30%, and 24%. <ref type="bibr">20</ref> On average, LBA's hit rate is about 11 percentage points higher than HBRL(4). Figure <ref type="figure">8</ref> provides a visual comparison of the distributions of holdout metrics for individual respondents. Positive numbers (darker bars) indicate those respondents for which LBA predicts better than HBRL(4). These percentages and Figure <ref type="figure">8</ref> suggest that greedoid methods are a viable method to complement more traditional methods to evaluate whether respondents are using compensatory or noncompensatory processes.</p><p>Constructed Processes-Full Rank vs. Consider Then Rank; Sorting vs. Not Sorting Behavioral researchers hypothesize that consumers construct their decision processes as they make their  decisions and hence that these decision processes can be influenced by the nature of the decision task. We examine this issue by comparing the influence of task (consider then rank versus full rank) and the availability of a presorting mechanism (sorting allowed versus not allowed). Figure <ref type="figure">9</ref> compares the predictive ability (holdout violations) for the four cells of our basic experiment. Some insights from Figure <ref type="figure">9</ref> are: ‚Ä¢ Allowing respondents to presort SmartPhones does not have a significant effect on either LBA or HBRL(4). Task has a significant effect on both LBA and HBRL(4). <ref type="bibr">21</ref> ‚Ä¢ On average, LBA predicts significantly better than a q-compensatory model in full-rank cells (t = 6 0, p = 0 0) but not in the consider-then-rank cells (t = 0 4, p = 0 69).</p><p>‚Ä¢ A lexicographic model predicts better than a q-compensatory model for more respondents in the <ref type="bibr">21</ref> Using analysis of variance, task is significant for both LBA (F = 51 1, p = 0 00) and HBRL(4) (F = 3 7, p = 0 05). Sorting is not significant for either LBA (F = 2 1, p = 0 14) or HBRL(4) (F = 0 1, p = 0 79).</p><p>Marketing Science 26(4), pp. 532-549, ¬© 2007 INFORMS full-rank cells than in the consider-then-rank cells (62% versus 50%, t = 2 2, q = 0 03). <ref type="bibr">22</ref> We obtain a similar pattern of results for hit rates, with the exception that hit rates are a coarser measure at the level of the individual respondent (more ties) and require a relative measure. <ref type="bibr">23</ref> Constructed Processes-Predictive Ability vs. Effort Data in the previous section are consistent with a hypothesis that the more effortful experimental cells (full rank versus consider then rank) lead to more lexicographic processing. We can also manipulate effort by the number of profiles that the respondent is asked to evaluate. Indeed, behavioral theory suggests that respondents are more likely to use a lexicographic process for choice (rank) if there are more profiles (e.g., <ref type="bibr" target="#b1">Bettman et al. 1998</ref><ref type="bibr" target="#b28">, Johnson et al. 1989</ref><ref type="bibr" target="#b39">, Lohse and Johnson 1996</ref>. <ref type="bibr">Payne et al. (1993, pp. 253-254)</ref> suggest as important research the study of such manipulations on consideration set formation.</p><p>To examine this issue, we assigned an additional 86 respondents to a fifth cell in which respondents evaluated fewer profiles (16 versus 32) using the considerthen-rank task. With this manipulation, we found no significant differences in the relative predictive ability of LBA versus HBRL(4) between cells (t = 0 2, p = 0 88 for percent pairs predicted, and t = 1 0, p = 0 31 for the percent of respondents for whom LBA predicts better). We obtain the same pattern of results with hit rates. Interestingly, the differences in effort are also not significant for 16 versus 32 profiles when the task is consider then rank. <ref type="bibr">24</ref> Perhaps the number of profiles has less of an effect on consideration than that reported in the literature for choice-an empirical result worth examining in future experiments. Alternatively, the 16-profile task might have already been sufficiently difficult to trigger the use of simplifying heuristics for consideration.</p><p>We did not include a cell in which respondents were asked to provide full ranks for 16 profiles. However, to gain insight, we simulate a 16-profile full-rank cell by randomly choosing one-half of the 32 profiles for estimation. Predictions degrade with half the profiles, but the loss is less than three percentage points (80.8% versus 77.9%, t = 4 3, p = 0 00). <ref type="bibr">25</ref> The effect of task type seems to have a larger impact than the number of profiles. LBA estimates from the full-rank task predict significantly better than those from the consider-then-rank task (review Figure <ref type="figure">9</ref>). On average (combining sort and no-sort cells), 81% of the holdout pairs are predicted correctly in the full-rank cells compared to 69% in the consider-thenrank cells (t = 2 6, p = 0 01). On the other hand, the consider-then-rank task took significantly less time to complete in the no-sort cell (8 3 4 versus 3 3 4 minutes). The three effort comparisons (full rank versus consider then rank, 16 versus 32 profiles for consider then rank, 16 versus 32 profiles for full rank) suggest an interesting managerial trade-off between predictive ability and task time. With specific loss functions on predictability and task time, such comparisons enable managers to design more efficient market research studies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Aspects vs. Features</head><p>Finally, we address whether respondents process profiles by features or by aspects when they use lexicographic processes. Recall that lexicographic by features (LBF) is a restricted form of LBA where respondents rank by features (e.g., Verizon versus Sprint versus Nextel versus Cingular) rather than aspects (Verizon versus not Verizon). Because LBA nests LBF, LBA's fit statistics will be better. However, there is no guarantee that LBA's holdout predictions will be better than those of LBF. If respondents process profiles by features, then LBF could predict as well as LBA, perhaps better if LBA exploits random variations.</p><p>Table <ref type="table" target="#tab_3">1</ref> compares LBA to LBF. On average, LBA predicts significantly better on both holdout violations and hit rates. LBA predicts better in all four cells and significantly better in three of the four cells (t's = 1.8, 7.1, 2.4, and 4.5; p's = 0.07, 0.00, 0.02, and 0.00 in cells 1-4). However, LBF predicts better for about a third of the respondents (35% for holdout violations and 34% for hit rates, with no significant differences between experimental cells).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Analysis of Computer Data from</head><p>a Study by <ref type="bibr" target="#b37">Lenk et al. (1996)</ref> We were fortunate to obtain a classic conjoint-analysis data set in which respondents evaluated full profiles of computers that varied on 13 binary features: telephone service hotline, amount of memory, screen size, CPU speed, hard disk size, CD ROM, cache, color, availability, warranty, bundled software, guarantee, and price. Respondents were presented with 16 full percentages are based only on the full-rank cells, they differ slightly from those in Table <ref type="table" target="#tab_3">1</ref>.</p><p>profiles and asked to provide a rating on a 10-point likelihood-of-purchase scale. They were then given a holdout task in which they evaluated four additional profiles on the same scale. These data were collected and analyzed by <ref type="bibr" target="#b37">Lenk et al. (1996)</ref>, who suggest excellent fit and predictive ability with hierarchical Bayes compensatory models. Based on their analysis and our intuition, we felt that the features in this study were more likely to be compensatory than those in the SmartPhone study. However, this is an empirical question. <ref type="bibr">26</ref> We first degraded the data from ratings to ranks. For example, if Profile A were rated as a 10 and Profile B were rated as a 1, we retained only that Profile A was preferred to Profile B. Because there were 10 scale points and 16 profiles, there were many ties-an average of 6.6 unique ratings per respondent. Interestingly, even though there were many ties, there were approximately 96 ranked pairs of profiles per respondent-80% of what would be obtained with full ranks. Because the degraded data are partial ranks, we can analyze the data with greedoid methods and compare predictions to HBRL and HBRL q . <ref type="bibr">27</ref> Table <ref type="table" target="#tab_4">2</ref> reports the fit and prediction results for the computer data. As with the SmartPhone data, we address the predictive ability of LBA compared to (1) an unconstrained additive model and (2) a q-compensatory model. On these data, the unconstrained additive model predicts better than LBA, significantly so for holdout pairs. (The difference in hit rates is only 1 respondent out of 201 respondents.) However, LBA predicts significantly better than the q-compensatory model. Comparisons for other values of q are available in a supplemental appendix available on the Marketing Science Web site.</p><p>For the computer data, LBA predicts better for 58% of the respondents compared to 25% for HBRL(4); the remainder are tied. We distinguish fewer respondents by hit rate because hit-rate classification is a coarser measure: 32% LBA, 20% HBRL(4), and 47% tied. Interestingly, LBA on the degraded data does as well as metric hierarchical Bayes on the ratings data (0.687; <ref type="bibr">Lenk et al. 1996, p. 181</ref>) and better than either OLS (0.637; <ref type="bibr">Lenk et al. 1996, p. 181)</ref> and latent class analysis (0.408; <ref type="bibr">Lenk et al. 1996, p. 181). 28</ref> In this case, <ref type="bibr">26</ref> There are other differences between the data sets that are worth further study. For example, the rating task might induce more compensatory processing than the full-rank or consider-then-rank tasks. <ref type="bibr">27</ref> For the <ref type="bibr" target="#b37">Lenk et al. (1996)</ref> data, HBRL predictions are significantly better than those by LINMAP. For holdout pairs, LINMAP predicts 0.734 (t = 5 3, p = 0 00). For hit rates, LINMAP predicts 0.597 (t = 2 6, p = 0 01). <ref type="bibr">28</ref> We compare to the highest hit rate they report-that for hierarchical Bayes estimated with 12 profiles. For 16 profiles, they report a hit rate of 0.670. For other statistics, hierarchical Bayes with 16 profiles performs better than with 12 profiles <ref type="bibr">(Lenk et al. 1996, p. 181)</ref>. a reduction in effort (ranking versus rating) might have had little effect on predictive ability. For further discussion of ranking versus rating data, see <ref type="bibr" target="#b24">Huber et al. (2002)</ref>.</p><p>Table <ref type="table" target="#tab_4">2</ref> is consistent with the analysis of metric data by <ref type="bibr" target="#b25">Jedidi and Kohli (2005)</ref>, who found that a different lexicographic model (binary satisficing, LBS) fit almost as well as an unconstrained additive model (0.93 fit pairs for LBS versus 0.95 for classic LINMAP; no data available on holdouts). The <ref type="bibr" target="#b25">Jedidi and Kohli (2005)</ref> context is remarkably similar to that of <ref type="bibr" target="#b37">Lenk et al. (1996)</ref>: metric ratings of 16 laptop computers described by memory, brand, CPU speed, hard drive size, and price (in a 3 3 2 2 fractional design).</p><p>Comparing the SmartPhone and computer data, we get surprisingly similar respondent-level comparisons. LBA predicts at least as well as HBRL(4) for 57% of the SmartPhone respondents and 75% of the computer respondents. <ref type="bibr">29</ref>  <ref type="bibr" target="#b25">Jedidi and Kohli (2005)</ref> did not test a q-compensatory model, but they did find that an unconstrained additive model was not significantly different from LBS for 67% of their respondents. Thus, on all data sets for more than half of the respondents, noncompensatory models predict holdout data at least as well as q-compensatory models.</p><p>We can also compare the predictive ability of LBA to an unconstrained additive model. LBA predicts at least as well as HBRL for 49% of the SmartPhone respondents and 62% of the computer respondents. Thus, even compared to an unconstrained additive model, LBA is promising as a predictive tool.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="8.">Managerial Implications</head><p>Manufacturers, retailers, or Web site designers seek to design products, store layouts, or Web sites that have (or emphasize) those aspects that strongly influence which products customers select for further consideration. They seek to avoid those aspects that customers use to eliminate products. In the parlance of product development, these are the "must-have" or "must-not-have" aspects or features <ref type="bibr" target="#b22">(Hauser et al. 2005)</ref>  to us that the identification of must-have aspects is an extremely important goal of their product development efforts (private communication). Table <ref type="table" target="#tab_6">3</ref> lists the six aspects that were used most often by Smart-Phone respondents and indicates whether they were used to retain profiles as in ABA or eliminate profiles as in EBA (second column), the percentage of consumers who used that aspect as one of the first three aspects in a lexicographic order (third column), and the percent who used that aspect as the first aspect in a lexicographic order (fourth column).</p><p>Table <ref type="table" target="#tab_6">3</ref> has a number of implications. First, for our student sample, there are clear price segments-for almost half the sample, high price is an EBA aspect. Second, "flip" and "small" are each ABA aspects for about 30% of the respondents. For this sample, any manufacturer would lose considerable market share if it did not include SmartPhones that were small and flip. The keyboard aspect is interesting. Keyboard is an ABA aspect for 17.3% of the respondents and an EBA aspect for 7.5% of the respondents (not shown). On this aspect, a manufacturer would be best advised to offer both SmartPhones with keyboards and SmartPhones without keyboards. Finally, brand, service provider, and operating system are not high in the summary of lexicographic orderings.</p><p>It is interesting that in our data price aspects were often, but not always, EBA aspects, while all other aspects were ABA aspects. (This is true for aspects not shown in Table <ref type="table" target="#tab_6">3</ref>.) We do not know if this generalizes to other categories. Furthermore, although "high price" was the top lexicographic aspect in our study, this could be a consequence of the category or our student sample. We do not expect price to be the top lexicographic aspect in all categories nor do we feel that this result affected the basic scientific and methodological findings about lexicographic processing or predictive ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="9.">Summary, Conclusions, and Future Research</head><p>In this paper, we propose methods to estimate noncompensatory process descriptions with either fullrank or partial-rank data. Estimation is a nontrivial combinatorial problem which has hitherto been too time-consuming to solve. Greedoids provide a structure and theory to transform an n! problem into a 2 n problem, which for practical problems decreases running time by a factor the order of 10 13 . We tested greedoid methods empirically for Smart-Phones and computers. The data suggest that the estimated lexicographic models predict well. Noncompensatory models predict at least as well as compensatory models for more than half of the respondents in both studies. Greedoid methods are flexible. We applied the methods with full-rank, consider-then-rank, and degraded ratings tasks, but the methods apply to any partial-order task, including repeated choice tasks. We believe they are promising for the study of noncompensatory decision rules.</p><p>Based on simulations, the SmartPhone data, and the computer data, we present the following summary.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methodological</head><p>‚Ä¢ It is feasible to estimate noncompensatory processes with a greedoid dynamic program.</p><p>‚Ä¢ Noncompensatory estimates predict holdout pairs and holdout hit rates well.</p><p>‚Ä¢ Greedoid methods appear to be robust-they predict well even though additive models can represent lexicographic processes.</p><p>‚Ä¢ A consider-then-rank task reduces task time, increases completion rates, and improves perceived enjoyment, accuracy, and interest, although at some loss in predictive ability.</p><p>‚Ä¢ Doubling the number of profiles from 16 to 32 improves predictive ability slightly for the full-rank task, but has no significant effect for the considerthen-rank task.</p><p>‚Ä¢ Enabling respondents to sort profiles by aspects is seen as more difficult and time-consuming, but does not increase predictive ability.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consumer Behavior</head><p>‚Ä¢ Compared to a q-compensatory model, LBA predicts at least as well for more than half of the respondents.</p><p>‚Ä¢ More respondents appear to process aspects rather than features lexicographically.</p><p>‚Ä¢ The full-rank task (versus a consider-then-rank task) does increase the percent of respondents for whom a lexicographic model fits better than a q-compensatory model.</p><p>‚Ä¢ Enabling respondents to sort profiles does not increase the percentage of respondents for whom LBA predicts better than a q-compensatory model.</p><p>‚Ä¢ Increasing the number of profiles in a considerthen-rank task does not increase the percentage of respondents for whom LBA predicts better than a q-compensatory model; this varies from the literature that finds that increasing the number of profiles does increase heuristic processing for a choice rank task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Managerial (for Our Sample and Category)</head><p>‚Ä¢ Price is often used as an EBA aspect. Nonprice aspects seem to be used as ABA aspects.</p><p>‚Ä¢ "Small" and "flip" are key aspects for Smart-Phones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Future Directions</head><p>Greedoid methods provide a promising tool to study consumer behavior. Researchers can use the greedoid inference engine to investigate many impacts of consumers' constructive judgment and decision processes-manipulations that might be too intrusive if implemented by verbal protocols or information display tasks.</p><p>Methodologically, the exact dynamic program is still exponential in the number of aspects. We handled 16 aspects in 1.85 seconds. At this rate, greedoid methods can be used to evaluate up to 21 aspects in under a minute. However, we can handle much larger problems if we concentrate on the first few lexicographic aspects in a respondent's LBA process. Because the theory applies to partial orders, we can stop the dynamic program after m aspects yielding a running time proportional to n C m . For example, we could identify the top 5 out of 50 aspects in approximately 1 minute. Partial-order greedoid methods can be used to identify satisficing processes in which some aspect levels are considered as equivalent by respondents. Other heuristics might also be used <ref type="bibr">Jedidi 2004, Kohli et al. 2006)</ref>.</p><p>Finally, there are interesting commonalities and differences between the SmartPhone and computer data sets and, perhaps, some empirical generalizations.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix. Proofs of the Formal Propositions</head><p>Proposition 1. Let E be a set of aspects, and let X be a partial order on the profiles. Let G be the collection of ordered subsets of E that are lexicoconsistent with X. Then, G is a greedoid language.</p><p>Proof. We show that greedoid properties (2) and ( <ref type="formula">3</ref>) hold for collection G. Property (1) is implied by (2). Property (2): Lexicoconsistent means that there is no pair of profiles P and P with P L P and P X P . So, if L is consistent with X, then L\e is consistent with X because the relations with respect to L\e are a subset of the relations with respect to L. Property (3): Let e be the first aspect in L such that e L. Such an e is guaranteed to exist since L &gt; L . We show that (L e ‚àà G via a contradiction. Suppose that there are profiles P and P with P L e P and P X P . Because L and X are consistent, it follows that P and P are unrelated with respect to L and, thus, P e P . Let L be aspects in L prior to e. Then, L ‚äÜ L, so P and P are unrelated in L . It follows that P L e P and, thus, P L P , contradicting that L is consistent with X. We conclude that Property 3 is true.</p><p>Proposition 2. Let L and L be two different permutations of a subset E of aspects, and let e be any aspect not in E . Then, the number of inconsistencies directly caused by e in (L, e) is the same as the number of inconsistencies caused by e in (L e Proof. Suppose that for profiles P and P , P X P . Aspect e causes an inconsistency with respect to profiles P and P in L e if and only if the following conditions hold: (i) profiles P and P are undifferentiated by the aspects in L, and (ii) P e P . These are the same conditions under which e causes an inconsistency with respect to P and P in L e . Proposition 3. If weights are associated with each ordered pair in X, then (1) the new G is a greedoid language, (2) Algorithm 1 determines whether there exists an L consistent with X, (3) Proposition 2 extends to the new G, and (4) Algorithm 2 finds the best lexicographic description if c(‚Ä¢ is redefined to c S\ i i = sum of weights of violations caused by aspect i following set S\ i .</p><p>Proof. Proposition 1 and Algorithm 1 are unaffected by nonunit weights because the determination of consistency does not depend on the weights associated with inconsistencies. Proposition 2 extends easily to the case where nonunit weights are allowed. With essentially the same proof, it can be shown that the sum of the weights of inconsistencies directly caused by aspect e in order L e is still independent of the permutation of the preceding aspects L. With the redefinition of c S\ i i , the validity of the new dynamic programming formulation follows from the extension of Proposition 2.</p><p>Marketing Science 26(4), pp. 532-549, ¬© 2007 INFORMS Proposition 4. Suppose that L is an ordering of a subset of aspects that is consistent with the preferences of X. Then, there is an optimal ordering of aspects that begins with the order L.</p><p>Proof. Suppose that L is an optimal ordering of aspects, that is, it is the one that minimizes the number of inconsistencies with respect to X. Let L be obtained from L by moving the aspects of L to the front of the order. We will show that any inconsistency with respect to L is also an inconsistency with respect to L , thus showing that L is at least as optimal as L . Suppose that for profiles P and P , P X P and P L P . Let e be the first aspect in L that differentiates P and P . Because L is consistent with X, it follows that e L. Therefore, e is also the first aspect in L that differentiates P and P , so P L P . It follows that P and P also cause an inconsistency with respect to L , proving the proposition.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>Figure 1Cell Phones and SmartPhones</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Figure 2Examples of Lexicographic Heuristic Processes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 4Illustrative Respondent's Task</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 5SmartPhone Experimental Design (32 Profiles in 4 3 2 4 Fractional DesignConsider-then-rank Full-rank</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Figure 6Task Difficulty (Less Is Better on Both Graphs)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>Figure 7Comparison of Holdout Prediction for q-compensatory Models</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>Figure 8Histograms of Comparative Predictive Ability</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>Figure 9Predictive Ability by Experimental Cell, Lexicographic vs. q-compensatory Processes</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>verizon verizon Sprint Ericsson SONY Ericsson</head><label></label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Marketing Science 26(4), pp. 532-549, ¬© 2007 INFORMS</cell></row><row><cell></cell><cell>heuristic Simplifying</cell><cell>TLA acronym) letter (Three-</cell><cell></cell><cell></cell><cell cols="8">Ranking rule</cell><cell></cell><cell>choice First</cell><cell>Partially choice by 2nd diverge</cell><cell>choice 3rd</cell><cell>choice 4th</cell><cell>Totally choice by 5th diverge</cell><cell>choice 6th</cell><cell>choice 7th</cell><cell>choice Last</cell></row><row><cell></cell><cell></cell><cell></cell><cell cols="12">(BlackBerry &gt; Nokia &gt;</cell><cell>Micro Soft</cell><cell>palm</cell><cell>Micro Soft</cell><cell>palm</cell><cell>Micro Soft</cell><cell>palm</cell><cell>Micro Soft</cell><cell>palm</cell></row><row><cell></cell><cell>Lexicographic by features</cell><cell>LBF</cell><cell></cell><cell cols="6">Samsung &gt;</cell><cell cols="4">SONY Ericsson</cell><cell>),</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell>(</cell><cell cols="3">Micro Soft</cell><cell cols="2">&gt;</cell><cell cols="3">PalmOS</cell><cell>)</cell></row><row><cell></cell><cell>by aspects Acceptance</cell><cell>ABA</cell><cell></cell><cell cols="11">BlackBerry, Nokia , Samsung , Micro Soft</cell><cell>Micro Soft</cell><cell>palm</cell><cell>Micro Soft</cell><cell>Micro Soft</cell><cell>Micro Soft</cell><cell>palm</cell><cell>palm</cell><cell>palm</cell></row><row><cell></cell><cell>by aspects Elimination</cell><cell>EBA</cell><cell></cell><cell cols="3">SONY Ericsson</cell><cell cols="2">,</cell><cell cols="4">PalmOS</cell><cell>,</cell><cell>Micro Soft</cell><cell>Micro Soft</cell><cell>Micro Soft</cell><cell>palm</cell><cell>palm</cell><cell>palm</cell><cell>Micro Soft</cell><cell>palm</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="11">Samsung, Nokia</cell></row><row><cell></cell><cell>Lexicographic by aspects</cell><cell>LBA</cell><cell cols="12">, BlackBerry, Micro SONY Ericsson , Nokia Soft</cell><cell>Micro Soft</cell><cell>palm</cell><cell>Micro Soft</cell><cell>Micro Soft</cell><cell>palm</cell><cell>palm</cell><cell>Micro Soft</cell><cell>palm</cell></row><row><cell>Figure 3</cell><cell cols="14">Equivalent Processes for Binary Features (Two-Aspect Features)</cell></row><row><cell></cell><cell></cell><cell>TLA</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell>Simplifying heuristic</cell><cell>(Three-letter acronym)</cell><cell></cell><cell></cell><cell cols="8">Ranking rule</cell><cell></cell><cell>First choice</cell><cell>2nd choice</cell><cell>3rd choice</cell><cell>4th choice</cell><cell>5th choice</cell><cell>6th choice</cell><cell>7th choice</cell><cell>Last choice</cell></row><row><cell></cell><cell>Lexicographic by features</cell><cell>LBF</cell><cell cols="7">( NOKIA &gt; ( &gt; Micro Soft</cell><cell cols="3">PalmOS</cell><cell cols="2">) ,</cell><cell>) ,</cell><cell>Micro Soft</cell><cell>Micro Soft</cell><cell>palm</cell><cell>palm</cell><cell>Micro Soft</cell><cell>Micro Soft</cell><cell>palm</cell><cell>palm</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(</cell><cell cols="11">&gt; verizon Sprint</cell><cell>)</cell><cell>verizo n</cell><cell>Sprint</cell><cell>verizo n</cell><cell>Sprint</cell><cell>verizo n</cell><cell>Sprint</cell><cell>verizo n</cell><cell>Sprint</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Micro Soft</cell><cell>Micro Soft</cell><cell>palm</cell><cell>palm</cell><cell>Micro Soft</cell><cell>Micro Soft</cell><cell>palm</cell><cell>palm</cell></row><row><cell></cell><cell>Acceptance by aspects</cell><cell>ABA</cell><cell cols="3">NOKIA,</cell><cell></cell><cell cols="4">Micro Soft</cell><cell>,</cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>verizo n</cell><cell>Sprint</cell><cell>verizo n</cell><cell>Sprint</cell><cell>verizo n</cell><cell>Sprint</cell><cell>verizo n</cell><cell>Sprint</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>Micro Soft</cell><cell>Micro Soft</cell><cell>palm</cell><cell>palm</cell><cell>Micro Soft</cell><cell>Micro Soft</cell><cell>palm</cell><cell>palm</cell></row><row><cell></cell><cell>Elimination by aspects</cell><cell>EBA</cell><cell cols="3">Ericsson SONY,</cell><cell cols="6">PalmOS</cell><cell>,</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>verizo n</cell><cell>Sprint</cell><cell>verizo n</cell><cell>Sprint</cell><cell>verizo n</cell><cell>Sprint</cell><cell>verizo n</cell><cell>Sprint</cell></row><row><cell></cell><cell>Lexicographic by aspects</cell><cell>LBA</cell><cell cols="3">SONY,</cell><cell></cell><cell cols="4">Micro Soft</cell><cell cols="2">,</cell><cell></cell><cell>Micro Soft</cell><cell>Micro Soft</cell><cell>palm</cell><cell>palm</cell><cell>Micro Soft</cell><cell>Micro Soft</cell><cell>palm</cell><cell>palm</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>verizo n</cell><cell>Sprint</cell><cell>verizo n</cell><cell>Sprint</cell><cell>verizo n</cell><cell>Sprint</cell><cell>verizo n</cell><cell>Sprint</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 1</head><label>1</label><figDesc>Comparison of Fit and Prediction for Unconstrained Models LBA significantly better than LBF. * * LBA significantly better than HBRL, LINMAP, and LBF. ‚Ä† LINMAP significantly better than LBA and HBRL. Tests at the 0.05 level.</figDesc><table><row><cell></cell><cell></cell><cell>Hierarchical</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Lexicographic</cell><cell>Bayes</cell><cell></cell><cell>Lexicographic</cell></row><row><cell></cell><cell>by aspects</cell><cell cols="3">ranked logit LINMAP by features</cell></row><row><cell>Fit (percent pairs)</cell><cell>0 955  *</cell><cell>0.871</cell><cell>0 969  ‚Ä†</cell><cell>0.826</cell></row><row><cell>Holdout percent pairs</cell><cell>0 745  *</cell><cell>0.743</cell><cell>0 737</cell><cell>0.658</cell></row><row><cell>Holdout hit rate</cell><cell>0 597  *  *</cell><cell>0.549</cell><cell>0 549</cell><cell>0.481</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>*   </note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2</head><label>2</label><figDesc>Comparison of Fit and Prediction for Computer Data<ref type="bibr" target="#b37">(Lenk et al. 1996)</ref> </figDesc><table><row><cell></cell><cell></cell><cell>Hierarchical</cell><cell>Hierarchical</cell></row><row><cell></cell><cell>Lexicographic</cell><cell>Bayes</cell><cell>Bayes ranked</cell></row><row><cell></cell><cell>by aspects</cell><cell>ranked logit</cell><cell>logit (q = 4</cell></row><row><cell>Fit (percent pairs)</cell><cell>0 899  *</cell><cell>0 906  *</cell><cell>0.779</cell></row><row><cell>Holdout (percent pairs)</cell><cell>0 790  *</cell><cell>0 827  *  *</cell><cell>0.664</cell></row><row><cell>Holdout hit rate</cell><cell>0 686  *</cell><cell>0 692  *</cell><cell>0.552</cell></row><row><cell cols="4">*  LBA and HBRL significantly better than HBRL(4)-at 0.05 level.  *  *  HBRL</cell></row><row><cell cols="2">significantly better than LBA and HBRL(4).</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head></head><label></label><figDesc>. Both General Motors and Nokia have indicated</figDesc><table><row><cell>Marketing Science 26(4), pp. 532-549, ¬© 2007 INFORMS</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3</head><label>3</label><figDesc>Top Lexicographic Aspects for SmartPhones (for Our Sample) Column sums to 300% over all aspects. ‚Ä† Column sums to 100% across all aspects. Most aspects not shown.</figDesc><table><row><cell></cell><cell></cell><cell>Affect</cell><cell>Top</cell></row><row><cell>Aspect</cell><cell>ABA or EBA</cell><cell>consideration  *  (%)</cell><cell>aspect  ‚Ä† (%)</cell></row><row><cell>Price-$499</cell><cell>EBA</cell><cell>49.2</cell><cell>26 1</cell></row><row><cell>Flip</cell><cell>ABA</cell><cell>32.0</cell><cell>10 4</cell></row><row><cell>Small</cell><cell>ABA</cell><cell>29.4</cell><cell>10 0</cell></row><row><cell>Price-$299</cell><cell>EBA</cell><cell>19.8</cell><cell>4 2</cell></row><row><cell>Keyboard</cell><cell>ABA</cell><cell>17.3</cell><cell>7 5</cell></row><row><cell>Price-$99</cell><cell>ABA</cell><cell>14.5</cell><cell>4 8</cell></row><row><cell>*</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">http://www.myphonefinder.com/, used with permission.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Excellent methods exist for small numbers of aspects and for approximations to the best fit. Examples include Gensch (1987), Gilbride and Allenby (2004),<ref type="bibr" target="#b33">Kohli and Jedidi (2004)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">The ratio is not as severe if we allow partial lexicographic orders. However,<ref type="bibr" target="#b3">Br√∂der's (2000)</ref> method cannot handle partial orders without first solving the combinatorial problems we describe later.5  Both approaches were developed independently. We became aware of one another's approaches after all empirical work had been completed and papers written.6  Greedoid analysis can be extended to tasks such as those used by<ref type="bibr" target="#b3">Br√∂der (2000)</ref>,<ref type="bibr" target="#b15">Gigerenzer and Goldstein (1996)</ref>, or<ref type="bibr" target="#b16">Gilbride and Allenby (2004)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">In a 4 3 2 4 design, there are 3 √ó 4 + 4 √ó 1 = 16 aspects.Yee, Dahan, Hauser, and Orlin: Greedoid-Based Noncompensatory Inference</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">Early theory examined partially ordered set greedoids such as might be defined on orderings of profiles. The greedoid in this paper describes aspects as they relate to profiles, not profiles directly.9  Interestingly, less that one-tenth of 1% of the profile orderings are consistent with linear combination of aspect measures. This includes both compensatory and noncompensatory linear combinations.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">Greedoids were initially formulated in the context of set systems. However, the language representation is equivalent and more appropriate for our application.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11"><ref type="bibr" target="#b33">Kohli and Jedidi (2004)</ref> use a greedy algorithm on permutation matrices to identify a metric representation of a lexicographic ordering when there is no response error. They apply their algorithm to metric data.12 Minimizing violated pairs is equivalent to maximizingKendall's  tau (1975)  where = 1 ‚àí 2 * (fraction violated).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">Exhaustively enumerating LBA would take over 900 millennia. Exhaustively enumerating a nine-aspect problem would take nine seconds for EBA (or ABA), but 1.3 hours for LBA.14 Details on classical LINMAP and analytic-center estimation are available from the authors.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15">Unconstrained models necessarily fit better than the constrained models that they nest; thus, fit cannot be used as a criterion.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="19">For the SmartPhone data, for some values of q, LINMAP does better than HBRL. The relative performances of the benchmarks are interesting but beyond the scope of this paper.20  At the level of individual respondents, hit rates are coarser measures than the percent of violated pairs, hence more ties are observed.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="22">This observation is tempered with the realization that the fullrank cells provide more ordered pairs than the consider-then-rank cells (496 versus 183, on average).23  For many respondents, the hit-rate prediction of LBA is tied with HBRL(4). Among those that are not tied, significantly more fit better with LBA in the full-rank cells than in the consider-then-rank cells (t = 2 3, p = 0 02).24  The comparisons are enjoyment, interest, and accuracy (2.07 versus 2.04, t = 0 1, p = 0 90); task time (3.40 versus 3.75 minutes, t = 0 5, p = 0 64) for 16 versus 32 profiles in a consider-then-rank task.25  Hit rates are worse by 2.9 percentage points, but the difference is not significant t = 1 7, p = 0 00 . Because the predicted holdout</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Effects of prior knowledge and experience and phase of the choice process on consumer decision processes: A protocol analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">W</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="234" to="248" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Constructive consumer choice processes</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Luce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="187" to="217" />
			<date type="published" when="1998-12" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Introduction to greedoids</title>
		<author>
			<persName><forename type="first">A</forename><surname>Bj√∂rner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Ziegler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Matroid Applications, Encyclopedia of Mathematics and Its Applications</title>
				<editor>
			<persName><forename type="first">N</forename><surname>White</surname></persName>
		</editor>
		<meeting><address><addrLine>London, UK</addrLine></address></meeting>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1992" />
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="page" from="284" to="357" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Assessing the empirical validity of the &quot;Take the Best&quot; heuristic as a model of human probabilistic inference</title>
		<author>
			<persName><forename type="first">A</forename><surname>Br√∂der</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">J. Experiment. Psych.: Learn</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1332" to="1346" />
		</imprint>
	</monogr>
	<note>Memory, Cognition</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Prediction in marketing using the support vector machine</title>
		<author>
			<persName><forename type="first">D</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Curry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="595" to="615" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The robust beauty of improper linear models in decision making</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Dawes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Amer. Psychologist</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="571" to="582" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A stochastic multidimensional unfolding approach for representing phased decision outcomes</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Desarbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">R</forename><surname>Lehmann</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><surname>Sinha</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrica</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="485" to="508" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
	<note>Sept</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The use of nonlinear, noncompensatory models in decision making</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Einhorn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Bull</title>
		<imprint>
			<biblScope unit="volume">73</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="230" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Behavioral decision theory: Processes of judgment and choice</title>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J</forename><surname>Einhorn</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annual Rev. Psych</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="52" to="88" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Generalized robust conjoint estimation</title>
		<author>
			<persName><forename type="first">T</forename><surname>Evgeniou</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Boussios</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Zacharia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="415" to="429" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Lexicographic orders, utilities and decision rules: A survey</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">C</forename><surname>Fishburn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1442" to="1471" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Cognitive reflection and decision making</title>
		<author>
			<persName><forename type="first">S</forename><surname>Frederick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econom. Perspectives</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="25" to="42" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A two-stage disaggregate attribute choice model</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Gensch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="223" to="231" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Information-theoretic estimation of individual consideration sets</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">H</forename><surname>Gensch</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">S</forename><surname>Soofi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Res. Marketing</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="25" to="38" />
			<date type="published" when="1995-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Reasoning the fast and frugal way: Models of bounded rationality</title>
		<author>
			<persName><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">G</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Rev</title>
		<imprint>
			<biblScope unit="volume">1003</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="650" to="669" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A choice model with conjunctive, disjunctive, and compensatory screening rules</title>
		<author>
			<persName><forename type="first">T</forename><surname>Gilbride</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="391" to="406" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Completely unacceptable levels in conjoint analysis: A cautionary note</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">M</forename><surname>Krieger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Bansal</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="293" to="300" />
			<date type="published" when="1988-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The voice of the customer</title>
		<author>
			<persName><forename type="first">A</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="27" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Testing the accuracy, usefulness and significance of probabilistic models: An information theoretic approach</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Oper. Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="1978-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The impact of utility balance and endogeneity in conjoint analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="498" to="507" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">An evaluation cost model of consideration sets</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Wernerfelt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="393" to="408" />
			<date type="published" when="1990-03" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Research on innovation: A review and agenda for Marketing Science</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Tellis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Griffin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="687" to="717" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A dynamic programming approach to sequencing problems</title>
		<author>
			<persName><forename type="first">M</forename><surname>Held</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">M</forename><surname>Karp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SIAM J. Appl. Math</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="196" to="210" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Expressing preferences in a principal-agent task: A comparison of choice, rating and matching</title>
		<author>
			<persName><forename type="first">J</forename><surname>Huber</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Ariely</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><surname>Fischer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organ. Behav. Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="66" to="90" />
			<date type="published" when="2002-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Probabilistic subset-conjunctive models for heterogeneous consumers</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jedidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kohli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="483" to="494" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Consideration sets in conjoint analysis</title>
		<author>
			<persName><forename type="first">K</forename><surname>Jedidi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Desarbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="364" to="372" />
			<date type="published" when="1996-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Compensatory choice models of noncompensatory processes: The effect of varying context</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Meyer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="528" to="541" />
			<date type="published" when="1984-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">When choice models fail: Compensatory models in negatively correlated environments</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">J</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Ghose</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="255" to="290" />
			<date type="published" when="1989-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Comment on adaptive conjoint analysis: Some caveats and suggestions</title>
		<author>
			<persName><forename type="first">R</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="223" to="225" />
			<date type="published" when="1991-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">G</forename><surname>Kendall</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rank Correlation Methods. Charles Griffin &amp; Company, Ltd</title>
		<imprint>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Dynamic heterogeneous choice heuristics: A Bayesian hidden Markov mixture model approach. Working paper</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">G</forename><surname>Kim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIT Sloan School of Management</title>
		<imprint>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Assessing unacceptable attribute levels in conjoint analysis</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">M</forename><surname>Klein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adv. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="154" to="158" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Representation and inference of lexicographic preference models and their variants</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jedidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="380" to="399" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Subset-conjunctive rules for breast cancer diagnosis</title>
		<author>
			<persName><forename type="first">R</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Krishnamurthi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Jedidi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Discrete Appl. Math</title>
		<imprint>
			<biblScope unit="volume">154</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1100" to="1132" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Basis graphs of greedoid and twoconnectivity</title>
		<author>
			<persName><forename type="first">B</forename><surname>Korte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lov√°sz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Math. Programming Stud</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="158" to="165" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">B</forename><surname>Korte</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lov√°sz</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Schrader</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Greedoids. Algorithms and Combinatorics Series</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="1991" />
			<publisher>Springer-Verlag</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Hierarchical Bayes conjoint analysis: Recovery of partworth heterogeneity from reduced experimental designs</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">J</forename><surname>Lenk</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Desarbo</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">R</forename><surname>Young</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="173" to="191" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Dynamic models incorporating individual heterogeneity: Utility evolution in conjoint analysis</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">C</forename><surname>Liechty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">K H</forename><surname>Fong</surname></persName>
		</author>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">S</forename><surname>Desarbo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="285" to="293" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">A comparison of two process tracing methods for choice tasks</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Lohse</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organ. Behav. Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="28" to="43" />
			<date type="published" when="1996-10" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Emotional trade-off difficulty and choice</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">F</forename><surname>Luce</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="143" to="159" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">An approach to the measurement of consumer preferences using limited information</title>
		<author>
			<persName><forename type="first">N</forename><surname>Malhotra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="33" to="40" />
			<date type="published" when="1986-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Fast, frugal, and fit: Simple heuristics for paired comparisons</title>
		<author>
			<persName><forename type="first">L</forename><surname>Martignon</surname></persName>
		</author>
		<author>
			<persName><forename type="first">U</forename><surname>Hoffrage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory Decision</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="29" to="71" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName><surname>Yee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Hauser</forename><surname>Dahan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Orlin</forename></persName>
		</author>
		<idno>INFORMS 549</idno>
		<title level="m">Greedoid-Based Noncompensatory Inference Marketing Science</title>
				<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="page" from="532" to="549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title/>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">M</forename><surname>Mitchell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Machine Learning. WCB McGraw-Hill</title>
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">On decision rules and information processing strategies for choices among multiattribute alternatives</title>
		<author>
			<persName><forename type="first">H</forename><surname>Montgomery</surname></persName>
		</author>
		<author>
			<persName><forename type="first">O</forename><surname>Svenson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scandinavian J. Psych</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page" from="283" to="291" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Lexicographic quasilinear utility</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Nakamura</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Math. Econom</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="157" to="178" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">On certain greedoid polyhedra, partially indexable scheduling problems, and extended restless bandit allocation indices</title>
		<author>
			<persName><forename type="first">J</forename><surname>Ni√±o-Mora</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Economics Working Papers</title>
		<imprint>
			<biblScope unit="volume">456</biblScope>
			<date type="published" when="2000" />
		</imprint>
		<respStmt>
			<orgName>Department of Economics and Business, Universitat Pompeu Fabra</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">An information processing probe into conjoint analysis</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">W</forename><surname>Olshavsky</surname></persName>
		</author>
		<author>
			<persName><forename type="first">F</forename><surname>Acito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Sci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="451" to="470" />
			<date type="published" when="1980-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Modeling hierarchical conjoint processes with integrated choice experiments</title>
		<author>
			<persName><forename type="first">H</forename><surname>Oppewal</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">J</forename><surname>Louviere</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">J P</forename><surname>Timmermans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="92" to="105" />
			<date type="published" when="1994-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Task complexity and contingent processing in decision making: An information search</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organ. Behav. Human Performance</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="366" to="387" />
			<date type="published" when="1976" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Adaptive strategy selection in decision making</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Experiment. Psych.: Lear., Memory</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="534" to="552" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
	<note>Cognition</note>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">The Adaptive Decision Maker</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>Cambridge, UK</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Reality in Advertising</title>
		<author>
			<persName><forename type="first">R</forename><surname>Reeves</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1961" />
			<publisher>Knopf Publishing</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Development and testing of a model of consideration set composition</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">H</forename><surname>Roberts</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">M</forename><surname>Lattin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="429" to="440" />
			<date type="published" when="1991-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Bayesian statistics and marketing</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">E</forename><surname>Rossi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">M</forename><surname>Allenby</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="304" to="328" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The cost of thinking</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">M</forename><surname>Shugan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Consumer Res</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="99" to="111" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">A strict paired comparison linear programming approach to nonmetric conjoint analysis</title>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Operations Research: Methods, Models, and Applications. Quorum Books</title>
				<editor>
			<persName><forename type="first">J</forename><forename type="middle">E</forename><surname>Aronson</surname></persName>
			<persName><forename type="first">S</forename><surname>Zionts</surname></persName>
		</editor>
		<meeting><address><addrLine>Westport, CT</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="97" to="111" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Surprising robustness of the selfexplicated approach to customer preference structure measurement</title>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">S</forename><surname>Park</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="286" to="291" />
			<date type="published" when="1997-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Linear programming techniques for multidimensional analysis of preferences</title>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Shocker</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="337" to="369" />
			<date type="published" when="1973" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Casemap: Computer-assisted self-explication of multiattributed preferences</title>
		<author>
			<persName><forename type="first">V</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">A</forename><surname>Wyner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Handbook on New Product Development and Testing. D. C. Heath</title>
				<editor>
			<persName><forename type="first">W</forename><surname>Henry</surname></persName>
			<persName><forename type="first">M</forename><surname>Menasco</surname></persName>
			<persName><forename type="first">K</forename><surname>Takada</surname></persName>
		</editor>
		<meeting><address><addrLine>Lexington, MA</addrLine></address></meeting>
		<imprint>
			<date type="published" when="1988" />
			<biblScope unit="page" from="91" to="112" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">A noncompensatory choice model incorporating cutoffs</title>
		<author>
			<persName><forename type="first">J</forename><surname>Swait</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Transportation Res</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="903" to="928" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
	<note>Part B</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Efficient decision heuristics</title>
		<author>
			<persName><forename type="first">W</forename><surname>Thorngate</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral Sci</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="page" from="219" to="225" />
			<date type="published" when="1980-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Fast polyhedral adaptive conjoint estimation</title>
		<author>
			<persName><forename type="first">O</forename><surname>Toubia</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">I</forename><surname>Simester</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Dahan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="273" to="303" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Elimination by aspects: A theory of choice</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psych. Rev</title>
		<imprint>
			<biblScope unit="volume">79</biblScope>
			<biblScope unit="page" from="281" to="299" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Listening-in&quot; to find and explore new combinations of customer needs</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="72" to="87" />
			<date type="published" when="2004-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Rethinking market research: Putting people back in</title>
		<author>
			<persName><forename type="first">G</forename><surname>Zaltman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="424" to="437" />
			<date type="published" when="1997-11" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
