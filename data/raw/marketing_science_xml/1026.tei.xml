<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Accurate Retail Testing of Fashion Merchandise: Methodology and Application</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><forename type="first">Marshall</forename><surname>Fisher</surname></persName>
							<email>fisher@wharton.upenn.edu</email>
						</author>
						<author>
							<persName><forename type="first">Kumar</forename><surname>Rajaram</surname></persName>
							<email>kumar.rajaram@anderson.ucla.edu</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Operations and Information Management Department</orgName>
								<orgName type="department" key="dep2">The Wharton School</orgName>
								<orgName type="institution">The University of Pennsylvania Philadelphia</orgName>
								<address>
									<postCode>19104-6366</postCode>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="laboratory">Operations and Technology Management Area, The John E. Anderson Graduate School of Management The University of California at Los Angeles</orgName>
								<address>
									<postCode>90095-1481</postCode>
									<settlement>Los Angeles</settlement>
									<region>California</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Accurate Retail Testing of Fashion Merchandise: Methodology and Application</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.19.3.266.11800</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:30+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In a merchandise depth test, a retail chain introduces new products at a small sample of selected stores for a short period prior to the primary selling season and uses the observed sales to forecast demand for the entire chain. We describe a method for resolving two key questions in merchandise testing: (1) which stores to use for the test and (2) how to extrapolate from test sales to create a forecast of total season demand for each product for the chain. Our method uses sales history of products sold in a prior season, similar to those to be tested, to devise a testing program that would have been optimal if it had been applied to this historical sample. Optimality is defined as minimizing the cost of conducting the test, plus the cost of over-and understocking of the products whose supply is to be guided by the test.</p><p>To determine the best set of test stores, we apply a kmedian model to cluster the stores of the chain based on a store similarity measure defined by sales history, and then choose one test store from each cluster. A linear programming model is used to fit a formula that is then used to predict total sales from test sales.</p><p>We applied our method at a large retailer that specializes in women's apparel and at two major shoe retailers, comparing results in each case to the existing process used by the apparel retailer and to some standard statistical approaches such as forward selection and backward elimination. We also tested a version of our method in which clustering was based on a combination of several store descriptors such as location, type of store, ethnicity of the neighborhood of location, total store sales, and average temperature of the store location. We found that relative to these other methods, our approach could significantly improve forecasts and reduce markdowns that result from excessive inventory, and lost margins resulting from stockouts. At the</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>ACCURATE RETAIL TESTING OF FASHION MERCHANDISE: METHODOLOGY AND APPLICATION</head></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>apparel retailer the improvement was enough to increase profits by more than 100%.</p><p>We believe that one reason our method outperforms the forward selection and backward elimination methods is that these methods seek to minimize squared errors, while our method optimizes the true cost of forecast errors. In addition, our approach, which is based purely on sales, outperforms descriptor variables because it is not always clear which are the best store descriptors and how best to combine them. However, the sales-based process is completely objective and directly corresponds to the retailer's objective of minimizing the understock and overstock costs of forecast error.</p><p>We examined the stores within each of the clusters formed by our method to identify common factors that might explain their similar sales patterns. The main factor was the similarity in climate within a cluster. This was followed by the ethnicity of the neighborhood where the store is located, and the type of store. We also found that, contrary to popular belief, store size and location had little impact on sales patterns.</p><p>In addition, this technique could also be used to determine the inventory allocation to individual stores within a cluster and to minimize lost demand resulting from inaccurate distribution across size. Finally, our method provides a logical framework for implementing micromerchandising, a practice followed by a significant number of retailers in which a unique assortment of merchandise is offered in each store (or a group of similar stores) tuned to maximize the appeal to customers of that store. Each cluster formed by our algorithm could be treated as a "virtual chain" within the larger chain, which is managed separately and in a consistent manner in terms of product mix, timing of delivery, advertising message, and store layout. <ref type="bibr">(Merchandise Testing; Retailing; Mathematical Programming)</ref> </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>Retailers segment merchandise into basic and fashion products. Basic products have relatively stable demand and a long life-cycle, which make it fairly easy to forecast demand and manage inventory for a particular product using standard methods that rely on a sales history of the product. Forecasting and inventory management are much more difficult for fashion products. Their demand is highly unpredictable, and they have a short life-cycle-typically just a few months. They are often bought just once, at a time prior to the start of the actual sales season, and the decision of how much to buy is not based on actual sales of the product but merely on the subjective judgment of merchandisers and buyers about how well it will sell. We have found that these subjective forecasts have an average error of 50% or more. As a result, retailers frequently buy too little of some fashion products, resulting in lost sales and profit margin, and too much of other products, resulting in excess supply that must be marked down in price at the end of the season, frequently to the point where the product is sold at a loss.</p><p>To reduce these costly forecast errors, many retailers conduct experiments, called tests, in which products are offered for sale under carefully controlled conditions in a small number of stores. Tests are used to measure consumer reaction to a variety of variables including price, floor placement, marketing message, or some aspect of styling such as color, fabric, or silhouette. We focus here on a particular type of test, called a depth test, used to predict the season sales of a particular product. In a depth test, a supply of the product sufficient to avoid stockouts is placed in a small sample of stores for a two-to three-week period just prior to the start of the regular sales season. Sales in the test stores during this period are used to predict season sales for the chain, and this forecast is used as a basis for initial or replenishment orders. Although we focus specifically on depth testing in this paper, our method for choosing test stores could also be useful in other types of testing. For simplicity, we refer to this type of test as a merchandise test, or simply a test.</p><p>A retailer faces several issues in designing an effective merchandise test, including how many and in which specific stores to conduct the test and how to create a forecast for the entire chain based on test store sales. The decision of how many test stores to use must trade off the increased accuracy that comes from using more test stores against the cost of running the test, which is greater if more stores are used. The cost of running a test is incurred from administrative costs, the need to provide extra inventory to avoid stockouts during the test, possibly the cost of air-freighting merchandise to the test stores, and an opportunity cost on the store space used for the test, because test merchandise by its nature usually sells less well, on average, than regular merchandise. The high cost of testing generally leads retailers to use a small number of test stores (e.g., 5 to 25). Choosing a small sample of test stores from the hundreds of stores that comprise a large chain is challenging because of the variation in store characteristics such as location, climate, size, and demographics of the surrounding customer base.</p><p>Despite the practical relevance and complexity of this problem, we found nothing in the academic or managerial literature that describes how to design an effective merchandise test. There is extensive academic literature on test marketing (e.g., see <ref type="bibr" target="#b10">Urban and Hauser 1980</ref>) that would appear to be relevant but turns out not to be directly applicable because it involves longer duration and observation of trials and assumes repeat purchases.</p><p>A number of articles that review current retail practice <ref type="bibr" target="#b3">(Doyle and Gidengil 1977</ref><ref type="bibr" target="#b5">, Fox 1995</ref><ref type="bibr" target="#b6">, Hollander 1986</ref><ref type="bibr" target="#b9">, Pollack 1994</ref><ref type="bibr" target="#b11">, and Wilson et al. 1995</ref> emphasize the importance of merchandise testing and highlight a need for more effective procedures, but they do not themselves describe how to conduct an effective merchandise test. <ref type="bibr" target="#b3">Doyle and Gidengil (1977)</ref> review merchandise testing as part of the broader topic of retail experimentation and conclude that these methods, despite enormous potential, have thus far "made little contribution" to retailing because of both practical and theoretical problems.</p><p>We have been able to gather systematic information on testing practice as part of a broader, multiyear project involving 32 leading retailers of fashion type products, including apparel, computers, consumer electronics, entertainment software, books, music, toys, watches, and jewelry (see <ref type="bibr">Fisher et al. 1999</ref> for more details). Of the 27 retailers who answered the questions on testing, 25 indicated that they conducted merchandise tests of some type, which supports that testing is widely used by retailers. Retailers were also asked to rate the effectiveness of their testing program on a 10point scale, defining a 10 as the ability to predict sales from a test with an error of about 10%. The median answer was 6, suggesting that there is considerable room for improvement in testing accuracy in practice. In follow-up interviews, it appeared that the retailers who tested best had done an excellent job on many of the practical issues of testing but had not used any statistical methods to determine the most representative stores to use for a test or to interpret the results of a test. While retailers had diverse theories on how to test, to our knowledge none of them have subjected alternative approaches to a rigorous comparison to determine what actually works best.</p><p>This paper presents a methodology for resolving two key decisions in designing a merchandise test: in which stores to conduct the test, and how to create a season forecast for the chain based on test results. To choose test stores, we cluster the stores of the chain into groups that are similar based on historical sales of products that are similar to those to be tested. We apply linear programming to this sales history to estimate a formula to predict season sales for the chain from test store sales. We also consider clustering based on various store descriptor variables. Using data from three retailers-a specialty apparel retailer and two shoe retailers, Nine West and Meldisco-we compare the clustering methods to the existing process used by the apparel retailer and to two standard statistical approaches based on forecast accuracy and the cost of a supply plan. We find that sales-based clustering significantly outperforms the other methods on both metrics.</p><p>In the next section, we present the basic ideas behind our methodology. Section 3 presents the optimization models used to form clusters, select a test store within each cluster, and predict total season sales across all the stores of the chain from test store sales. Section 4 reports an application of these ideas to a retailer that specializes in women's fashion apparel, with over 1000 stores nationwide. Compared to the current testing process in place at the retailer, our method would reduce the cost of stockouts and of merchandise left over at the end of the season by enough to increase profit by 100%. In §5 we apply our method to data from two major shoe retailers, and obtain similar results. Section 6 presents conclusions to be drawn from our work and suggestions for future research.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Methodology</head><p>We describe a methodology for resolving the key decisions in designing a merchandise test: how many and specific stores in which to conduct the test, and how to create a season forecast for the entire chain based on test store sales. We assume that the retailer has (1) identified a set of products that they would like to test, (2) specified the time interval within which the products will be sold (the sales season), and (3) determined a test period during which the products will be offered for sale in selected stores to test their sales potential.</p><p>As mentioned in the introduction, retailers typically use a test period of two to three weeks just prior to the start of the regular season. The duration of the test presents the same trade-off as how many stores in which to test. A longer test is more accurate but more expensive. We have found two to three weeks to be typical practice, which seems to make sense. The test needs to be at least one week to control for interweek temporal effects. If the test occurs just prior to the start of the regular season, then the ending point of the test is constrained by the need to position supply based on the test by the start of the regular season. Hence, a longer test must start earlier, and the earlier the test begins, the greater the difference in conditions between the test period and the period when products will be sold.</p><p>We define the primary sales season as the period within the sales season during which the selling price of the product exceeds acquisition cost plus variable selling expenses, and the level of inventory at each store is sufficient to prevent supply shortages. We assume that the same price is charged at all stores during this period, although this common price may vary over time. It is important to restrict the sales data to the primary sales season; otherwise, sales below cost and supply shortages, both outcomes of bad planning, could distort the distribution of sales at individual stores. Note that this also ensures that sample sales are not influenced by substitution because of a stockout of the product the customer was seeking. However, sample sales can be influenced by the dependency of demand with complementary or competitive products. If a store contains more complementary (competitive) products during the test than will be there during the regular selling season, then this will bias test sales upward (downward). This is an inevitable source of noise in a merchandise test, but it can be minimized by making the set of products offered during the test period as similar as possible to what will be offered during the regular season.</p><p>Because the purpose of merchandise testing is to create a forecast used to determine purchase quantities, it is important to understand the costs that result from forecast errors. If S p is the actual demand for a product p during the primary season, U p the per-unit cost of buying less than demanded, and O p the per-unit cost of buying more than demanded, then the cost associated with forecast Ŝ p is U p max(S p ‫מ‬ Ŝ p , 0) ‫ם‬ O p max(Ŝ p ‫מ‬ S p , 0). The understock cost U p is often taken to be the profit contribution margin (price minus variable cost) that is lost if there is insufficient supply to meet demand. Excess supply is usually marked down in price at the end of the season and sold at a loss, so O p is set to variable cost minus the marked down price.</p><p>Before describing our computational procedure, it is helpful to outline some features of retailing considered in designing our method. We can think of a product as being defined by a set of values for various attributes. Consumers differ in their preferences for attribute values, and hence the same product will have different appeal to different customers. In a retail chain with a large number of stores, consumer preferences will differ from store to store. While it is hard to directly measure the attribute preferences of customers that shop at a given store, given that attribute preference influences purchase decisions, the actual sales of a store can be thought of as a summary of the attribute preferences of customers at that store. In particular, if the percentage mix of products bought by customers at two different stores is similar, then we might infer that the customers of the two stores have similar preferences. This is the whole basis for micromerchandising, a practice followed by a significant number of retailers, in which a unique assortment of merchandise is offered in each store (or a group of similar stores) tuned to maximize the appeal to customers of that store (see <ref type="bibr" target="#b8">Patterson 1995 and</ref><ref type="bibr">DiRomualdo 1998 for examples)</ref>.</p><p>Our approach to testing is designed to recognize these features by using past sales of similar products to identify a set of test stores that collectively span the diverse segments of a large chain. In the next section, we first describe a procedure for choosing test stores, assuming that the number of test stores k has been specified. We then show how to set k to minimize the combined cost of testing and cost of forecast errors resulting from the test.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Model Description</head><p>We assume that the retailer has assembled a sales history of comparable products that were offered in a prior season or seasons. Appropriate comparable products are usually last year's products within the same classification. Let n denote the number of stores in the chain, m the number of previous products for which we have a sales history, S ip the observed sales during the primary sales season at store i for product p, S p ‫ס‬ S ip , and S ip the sales of product p in store n ͚ i‫1ס‬ i during a period comparable in timing and duration to a period during which a test would be conducted.</p><p>To choose k test stores, we partition the n stores of the chain into k clusters. The stores within each cluster are chosen to minimize a measure of dissimilarity based on the percentage of total sales represented by sales of each of the prior products in each store. Two stores that sold exactly the same percentage of each of the prior products would be in the same cluster, and all the stores within a cluster would sell approximately the same percentage of each of the prior products. We then choose a single test store within each cluster that best represents the cluster, in the sense that using test sales at this store to forecast sales of other stores in the cluster minimizes the cost of forecast errors.</p><p>We first describe the optimization model used to form clusters and select a test store within each cluster. This model is a specialized integer program known as the k-median problem, which we solve with the highly efficient algorithm given in <ref type="bibr" target="#b1">Cornuejols et al. (1977)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Variables y j ‫ס‬</head><p>1, if store j is chosen as a test store, Ά 0, otherwise;</p><p>x ij ‫ס‬ 1, if store i is assigned to a cluster represented by test store j, Ά 0, otherwise.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Parameters</head><formula xml:id="formula_0">I ‫ס‬ (1, . . . n) ‫ס‬ store index set; P ‫ס‬ (1, . . . m) ‫ס‬ prior product index set; w i ‫ס‬ S ; ͚ ip pʦP b ip ‫ס‬ , i ʦ I, p ʦ P; S ip S ͚ ip pʦP d ij ‫ס‬ (U p max(b ip ‫מ‬ b jp , 0) ‫ם‬ O p max(b jp ‫מ‬ b ip , 0)).</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>͚ pʦP</head><p>The Test Store Selection Problem (TSSP) is represented by the following integer program:</p><formula xml:id="formula_1">Min w d x ,<label>(1)</label></formula><p>͚ ͚ i ij ij iʦI jʦI subject to:</p><formula xml:id="formula_2">x ‫ס‬ 1, j ʦ I, (2) ͚ ij iʦI y ‫ס‬ k,<label>(3)</label></formula><formula xml:id="formula_3">͚ j jʦI 0 Յ x Յ y Յ 1, i, j ʦ I, (<label>4</label></formula><formula xml:id="formula_4">) ij j</formula><p>x and y integral, i, j ʦ I.</p><p>(</p><formula xml:id="formula_5">)<label>5</label></formula><formula xml:id="formula_6">ij j</formula><p>Equation (2) enforces the condition that each store is assigned to a test store, (3) that we have exactly k test stores, and (4) that stores are assigned only to chosen test stores. Objective Function (1) is structured to select k test stores that minimize the total overstock and understock costs if test sales at each test store are extrapolated to develop forecasts for stores assigned to that test store. To illustrate this point, let store i be represented by test store j (i.e., x ij ‫ס‬ 1). Then it would not be unreasonable to forecast sales for individual products in store i as (w i /w j )S jp . The total cost associated with this forecast at this store is m w w</p><formula xml:id="formula_7">i i O max S ‫מ‬ S , 0 ‫ם‬ U max S ‫מ‬ S , 0 ͚ p jp ip p ip jp w w p‫1ס‬ j j m S S S S jp ip ip jp ‫ס‬ w O max ‫מ‬ , 0 ‫ם‬ U max ‫מ‬ , 0 ͚ i p p w w w w p‫1ס‬ j i i j m ‫ס‬ w (O max(b ‫מ‬ b , 0) ‫ם‬ U max(b ‫מ‬ b , 0) i ͚ p j p i p p i p j p p‫1ס‬ ‫ס‬ w d . i ij</formula><p>Hence, the k-median problem can be interpreted as forming clusters and choosing a test store in each cluster that minimizes the cost of forecast errors, if total season sales at the test store were the predictor variable for its cluster. This also minimizes the expected cost of forecast errors based on test period sales, provided that the percentage of season sales that occur during the test period is approximately the same for all stores within a cluster. In this regard, it is worth noting that stores can differ not only in their sales mix but in the timing of their sales. If the timing of sales differs, then two stores might have an identical sales mix for the season but a different mix during the test period. In this instance, one of the stores might not be a good predictor for the other. As a practical matter, we have found that the most common cause of timing differences is climate. Southern stores sell spring/summer merchandise earlier than northern stores, and sell fall/ winter merchandise later. We found in our testing that these climate differences also cause a difference in sales mix. Hence, while a timing difference that occurs separately from a mix difference is a potential problem, it did not occur in our test data. Were this to be an issue, we would recommend redefining d ij to be based on the difference in the mix of season sales for store i and test period sales for store j, or to use a combined optimization approach defined in the Appendix.</p><p>We also tested a version of our method in which the d ij were set based on a weighted combination of several store descriptors rather than on differences in stores' sales mix. The store descriptors were store latitude and longitude (the distance between two stores on this measure was simply the Euclidean distance between the stores), average temperature during the sales season, total store sales, ethnicity (percentage of white in the postal code where the store is located-not politically correct, but believed by many retailers to be indicative of sales patterns), neighborhood type (either urban, suburban or rural-we assigned a distance of 0 if the neighborhoods were the same and 1 if they were different), and store type (either mall, strip mall, or college campus-we assigned a distance of 0 if the store types were the same and 1 if different). The distance between two stores used in clustering was a weighted combination of the absolute difference of these six measures, with nonnegative weights summing to 1 chosen to equalize the average influence of each of the six measures. We also tested a combined approach in which the distance between two stores was based on a combination of the six store descriptors and the difference in stores sales mix, with weights chosen to equalize the impact of these seven factors.</p><p>While we suggested above that w i /w j was a reasonable weight to use in predicting sales of a product at store i from its sales at store j, to ensure that we have the best possible weights and to adjust for the fact that test sales are for a shorter time interval than the full season, we use the following linear program (called the Test Sales Extrapolation Problem (TSEP)) to determine the optimal set of weights (␣ 1 . ␣ k ), which scales test sales to estimate product sales for the entire season across the chain for a given set of k test stores.</p><formula xml:id="formula_8">Z (k) ‫ס‬ Min U h ‫ם‬ O c , 1 ͚ p p p p pʦP h Ն S ‫מ‬ S ∀p ʦ P, p p p c Ն S ‫מ‬ S ∀p ʦ P, p p p kS ‫ס‬ ␣ S ∀p ʦ P, p ͚ i ip i‫1ס‬ h , c Ն 0 ∀p ʦ P. p p</formula><p>In the discussion so far, we have assumed that the number of test stores k is given. To find the best number of test stores, we would choose k to minimize C(k) ‫ס‬ Z 1 (k) ‫ם‬ C T k, where C T is the fixed cost for testing at each store. The fixed cost C T results from the administrative cost of running the test at a store and the fact that test merchandise, by its nature, usually sells less well on average than regular merchandise; hence there is an opportunity loss on the shelf space dedicated to the test. Our procedure is fast enough that we can solve the optimization on k by enumeration of all values k ‫ס‬ 1, 2, . . . noting that the largest number of test stores we need to consider can be bounded by C(k)/C T for any value of k for which we have evaluated C(k), because using a number of stores larger than this would incur fixed costs greater than the total cost of a known solution.</p><p>It is possible to formulate a single optimization model to choose the identity of test stores and the weights in the linear forecast formula to minimize the total cost of overstock, understock, and testing. We tested this unified approach on the data described in §4 and found that it performed slightly worse than the approach described above. Further details of the unified approach are provided in the Appendix, including the formulation and our computational experience with it.</p><p>In the final analysis, the real test of our method is its ability to improve the accuracy of the merchandise testing process in an actual retail environment-a question we consider next.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Application at a Women's Specialty Apparel Retailer</head><p>We have tested these ideas with a large specialty women's apparel retailer with 1993 net sales that exceeded $1 billion, and with more than 1000 stores dispersed throughout the United States. In addition to varying by region, stores vary by size, format (mall, strip mall, etc.), urban vs. suburban, and the ethnicity of their target customer base. This retailer relied on testing as its primary tool for forecasting the demand for new products but also believed that the accuracy of its current methodology could be significantly improved, which is what led to our involvement.</p><p>In developing merchandise plans, the retailer divides the year into two seasons: fall/winter and spring/summer. The first week of the fall/winter season is the first full week of September, and the first week of the spring/summer season is the first full week in April. In their current methodology, they select 25 test stores whose total dollar sales are close to average store sales for the chain. Product tests are conducted at these stores over a three-week period. To develop a season forecast and supply plan for the entire chain, total sales during the test period are divided by two factors that are estimated from past sales history. The first factor equals the proportion of season sales that are historically observed during these three weeks; the second factor equals the proportion of season sales that are observed at these 25 stores.</p><p>To evaluate our approach and compare it to this approach, we considered the women's knit tops division, which historically represents one of the single largest portions of investment and the highest level of sales uncertainty. The data available on which to evaluate our approach consisted of 1993 sales by store, by week, and by size of the 250 style/colors that make up the products of this division. To estimate the timing and duration of the primary sales season in this division, we analyzed 1993 sales data at the store/size level for these 250 style/colors. This analysis revealed that merchandise was in place at all stores by the start of week 3, that there was sufficient inventory at all the stores to meet potential demand through week 12, and that products were typically sold below cost after week 18. Consequently, we used a 10-week period, from the beginning of week 3 through the end of week 12, as the primary sales season.</p><p>We used these data to simulate the way our method would have performed if it had been used to design a test of this merchandise to be conducted during weeks 3 through 5. We used half of the 250 style/colors to fit the parameters of our model and the other half to test the accuracy of the model predictions. The planners at the knit top division classified the 250 style/colors into 16 product groups based on similarity in style and fabric texture. We selected 125 style/colors by choosing half the products in each of these groups. Let P denote this set of selected styles and P the remainder. For each p ʦ P, we used the sales data by store and product over the 10-week primary season to calculate w i and d ij and solved TSSP to optimality by the technique described in <ref type="bibr" target="#b1">Cornuejols et al. (1977)</ref>. For a given k, assume without loss of generality that the chosen test stores are indexed 1 through k. We then solved TSEP using the OSL solver in GAMS (see <ref type="bibr" target="#b0">Brooke et al. 1992)</ref> to develop the linear function Ŝ p ‫ס‬ ␣ i S ip , where k ͚ i‫1ס‬ S ip is the actual sales of product p at store i during weeks 3 through 5, which is the period when a test would be conducted. For each p ʦ P , we computed Ŝ p ‫ס‬ ␣ i S ip , using S ip , the actual sales of product p at k ͚ i‫1ס‬ store i during weeks 3 through 5. We estimated the forecast error |Ŝ p ‫מ‬ S p |, where S p is the actual ͚ pʦP sales of product p across the chain during the primary season. Based on average selling price and costs during this period, we calculated the cost of these errors as the loss resulting from selling below cost and lost margin resulting from supply shortage, namely U p ͚ pʦP max(S p ‫מ‬ Ŝ p , 0) ‫ם‬ O p max(Ŝ p ‫מ‬ S p , 0).</p><p>To provide a comparison, we also evaluated forecast errors and cost for the rules used by the planners at this retailer, the k median method based on store descriptors, alone and combined with sales mix differences, and two standard approaches to variable selection in linear regression, where the problem of choosing k test stores and a linear prediction function based on test sales at these stores is viewed as choosing the best k out of n possible variables in a linear regression. Given actual sales S p and test sales S ip for i ‫ס‬ 1, . . . n and p ‫ס‬ 1, . . . m, we used the forward selection and backward elimination methods <ref type="bibr" target="#b7">(Myers 1990</ref>) to choose k out of the n test store sales variables that best predict actual sales in the sense of minimizing the coefficient of determination R 2 .</p><p>Notice that our method provides a sales forecast not only for the chain but for each cluster. The cluster forecasts were used to guide allocation of product to stores for the k-median clustering based on sales. In our prediction formula, ␣ p S pj represents the forecast of product j in the cluster of stores corresponding to test store p, and hence this quantity is the ideal amount to send to this cluster. Total sales volumes at individual stores were used as a basis to determine allocations to stores within a cluster through the formula ␣ p S pj w i / w i , ͚ iʦI p where I p is the set of stores in the cluster represented by I p . For other methods, we used the retailer's existing approach of allocating total supply in proportion to historical sales volume.</p><p>Forecast errors and costs for all six approaches for different values of k are shown in Table <ref type="table" target="#tab_0">1</ref>. Forecast errors and costs are an aggregate of these values determined at the store/style/color level. In aggregating forecast errors, we summed over all stores, styles, and colors the absolute difference between forecasted and actual sales and expressed it as a percentage of total actual sales. These results show that the k-median approach with clustering based on sales is significantly more accurate than the other methods. For example, for k ‫ס‬ 10, it reduces costs resulting from forecast errors relative to the regression methods, the existing method in use at the retailer, or clustering based on store descriptors, by at least 8% of revenue. This improvement drops straight to the bottom line and would more than double profit when one considers that retailers typically earn profit before income tax of about 3% to 5% of sales. The combined approach of clustering on store descriptors and sales mix difference comes close to, but is still dominated by, clustering on sales alone. We believe that one reason our method outperforms the forward selection and backward elimination methods is these methods seek to minimize squared errors, while our method optimizes the true cost of forecast errors. In addition, our approach, which is based purely on sales, outperforms descriptor variables because it is not always clear which are the best store descriptors and how best to combine them. However, the sales-based process is completely objective and directly corresponds to the retailer's objective of minimizing the understock and overstock costs of forecast error.</p><p>To better understand the underlying causes of sales differences, it may be desirable to relate sales differences as much as possible back to store descriptors. To do this, we correlated store distance measures based on sales differences with the store descriptor variables temperature, ethnicity, location, store type, and size. We find that these descriptors as a group explain 85% to 89% of the variation in sales differences, with temperature by far the most significant variable. We also found that, contrary to popular belief, store size and location had little impact on sales patterns. Details of this analysis can be found in <ref type="bibr" target="#b4">Fisher and Rajaram (2000)</ref> and in the online Appendix at ͗http://mktsci.pubs. informs.org͘.</p><p>We also conducted extensive analyses to address the following issues (details can also be found in Fisher and Rajaram 2000 and in the online Appendix): (1) assessing how the degree of collinearity between sales at the test stores affects the performance of these methods; (2) justifying our choice of 10 test stores to perform this analysis and evaluating the sensitivity of our method to the choice of the specific test store within a cluster; (3) the relationship between store size and test stores; and (4) the effect of temperature as an explanatory variable in the formation of the clusters.</p><p>Having evaluated our method on 1993 sales data, we also wanted to determine how well it would perform across multiple years because in actual use we would be fitting the model on sales that had occurred one year prior to actual introduction of the styles being tested. We obtained sales data for 30 style/colors from the 1994 fall season in the knit tops division that had been tested in 25 stores chosen by the planners. These were all new products that had not been on sale during 1993. We applied our clustering model as it was fit on the 1993 data to these (30) 1994 products. This exactly replicates how the model would be used in practice and hence is an accurate measure of its effectiveness.</p><p>Using the actual primary season sales (S q ) for these products in 1994, we computed total forecast error |Ŝ q ‫מ‬ S q | for all forecasts. Based on cost and ͚ qʦQ selling price for these products during each week of 1994, we computed for all supply plans the loss resulting from selling below cost, and lost margin resulting from supply shortages. Forecast errors and costs for all plans are shown in Table <ref type="table" target="#tab_2">2</ref>. The reduction in cost achieved by our plan relative to the other methods is 6.5% to 18%. This is better appreciated if we consider that the recorded net before tax profit in 1994 for these styles was 9% of revenue. Hence, our method could potentially improve profits by from 6.5/9 ‫ס‬ 72% to 18/9 ‫ס‬ 200%.</p><p>The way we analyzed costs for these 30 style/colors treats demand as sales. However, because of stockouts, true demand usually exceeds sales. This generally biased comparisons against our method relative to the existing method because the inventory levels that conditioned sales had been determined by the existing method.</p><p>Assessing this effect is difficult because information on lost demand is not recorded. To estimate lost demand and margins, we first identified when every product/size combination in this group sold out in each store. We then defined the profitable season as the period during which products sold above cost, and we tabulated the percentage of profitable season sales that occurred each week for this group in total. These data were used to estimate sales that would have occurred after a stockout in a store/product/size combination before the end of the profitable season.</p><p>We applied our method for estimating lost demand to 104 style/color/size combinations in the knit series group and estimated that, in total, lost demand resulting from stockouts equaled 134% of sales actually realized. The lost margins resulting from this potential 134% increase in sales were around 57% of sales actually realized. Even if we allow for substitution between products to lower these estimates, the lost margins are clearly enormous.</p><p>Much of this lost demand was because of inaccurate distribution of inventory across sizes. Often we observed that a particular size in a given style/color accounted for a large proportion of stockouts, while other sizes of this style/color had to be eventually sold at markdowns below cost. To reduce such misallocation within the size distribution of a product, our clustering method could be applied to historical data on sales by size for a product to form clusters of products that had similar size selling patterns. We would then examine the nature of the products in each cluster as a way to understand how size distribution differs by product. For example, this might result in 10 distinct size distributions and a definition of the types of products that had a particular distribution. A new product could be assigned the size distribution of the product type that it best fits.</p><p>Recall that a test period of three weeks was used in developing the data reported in Table <ref type="table" target="#tab_2">2</ref>. To determine the impact of the test period length on cost and forecast error, we applied k-median clustering based on sales with test periods of varying lengths. Results are reported in Table <ref type="table">3</ref> and suggest that the industry practice of a three-week test period is not unreasonable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Application at Two Shoe Retailers</head><p>In this section we describe the application of our method at two major shoe retailers, Nine West and Meldisco. Nine West is the largest U.S. manufacturer of women's dress shoes and sells casual, career, and dress footwear and accessories worldwide through over 1500 of its own stores and 7000 locations in department, specialty, and independent shoe stores. We used our method to design a merchandise test for the spring sandals line, to be conducted during the first three weeks of the season. Using data on sales per week per store for 11 high fashion spring sandals sold at 140 stores for the first 26 weeks of 1997, we solved the TSSP for different numbers of test stores and used the sales during the first three weeks to find the alpha coefficients in the chain prediction formula. With this formula and the chosen test stores, we then used sales for the first three weeks of the spring 1998 season to predict season sales for the 14 sandals in the 1998 spring line. Based on actual sales for these products in 1998, we computed forecast error and its associated understock and overstock costs, based on selling price, costs, and salvage value for each product. In computing costs, we assume that the initial order placed by the retailer is sufficient to cover the inventory requirements at stores from the start of the test to the time when the replenishment based on the revised forecast arrives.</p><p>We also applied all other methods described in our paper, except regression with variable elimination, which is computationally intensive and adds little ad-  <ref type="table" target="#tab_3">5</ref> shows the impact of test period length on forecast error and cost for these data for k-median clustering based on sales.</p><p>Meldisco is a retailer that operates 1300 leased shoe departments in Kmart Stores. We applied our method to weekly sales data for 26 products for their 52-week season, assuming that the test takes place in the first six weeks and that a revised forecast is made based on this test. We did not have price and cost data for Meldisco, so we applied our method to minimize forecast error by setting the per unit costs of buying less than demanded equal to the cost per unit of buying more than demanded. In computing costs, we assume that the initial order placed by the retailer is sufficient to cover the inventory requirements at stores from the start of the test to the time when the replenishment based on the revised forecast arrives. We used weekly sales for 13 of the products to select test stores and determine weights in the forecast formula. We then evaluated the test stores and forecast model on the remaining 13 products. We also applied all other methods, except regression, with variable elimination, which is computationally intensive and adds little additional information. Results are reported in Table <ref type="table">6</ref>. Note that our method is superior to others, although clustering based on store descriptors combined with sales is a close second. Table <ref type="table">7</ref> shows the impact of test period length on forecast error for this data for k-median clustering based on sales.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>Our goal in this paper is to expose the reader to an intellectually interesting problem context laden with opportunities for research that can have a high impact on retailer profits. The following are some conclusions to be drawn from the research reported here.</p><p>• The sales of a given product mix vary greatly among the stores of a large chain. Some, but not all, of this variation can be explained by store descriptors such as average temperature and ethnicity.</p><p>• A merchandise testing process that exploits this by clustering stores based on similarity of sales mix and choosing a single store within each cluster can provide forecasts of season demand for style/colors accurate to about 10% to 20%.</p><p>• This approach performs significantly better than alternative methods used in retail practice, based on standard statistical approaches or on clustering by store descriptor variables. The impact on cost of the superior performance is enough to double a retailer's profits.</p><p>The results reported here invite additional research on a number of topics.</p><p>• The unified approach described in the Appendix deserves further study.</p><p>• Choosing a small number of test stores from the many stores of a large chain is analogous to the statistical problem of choosing a parsimonious set of independent variables from a large potential set in a regression. The ability of the k-median approach to find variables that are minimally colinear, and hence more predictive, deserves study in this broader context.</p><p>• The relationship between the clusters formed by our algorithm and micromerchandising is worth exploring. Each cluster could be treated as a "virtual chain" within the larger chain, which is managed separately and in a consistent manner in terms of product mix, timing of delivery, advertising message, store layout, etc. While this may require more managerial effort and careful attention to detail, the increasingly sophisticated information systems being installed by many retailers offer the opportunity to gather the required information and to automate much of the tedious data analysis tasks.</p><p>In conclusion, we believe that these trials at multiple retailers show that the method described here can greatly increase retailer profitability by improving the accuracy of merchandise testing. 1</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix: Unified Optimization Approach</head><p>In this appendix we formulate an optimization model, which we call the Merchandise Testing Problem, to choose both the identity of k test stores and the weights of the linear forecast formula to minimize the total overstock and understock costs. As previously defined, n is the number of stores, i e I ‫ס‬ (1, . . . n) indexes the set of stores, m is the number of products for which we have sales history, p ⑀ P ‫ס‬ (1, . . . m) indexes the set of products, and S p : sales for product p for the entire season across the chain,</p><note type="other">1</note><p>This research was supported in part by Alfred P. Sloan Foundation Grant 96-10-6 to the University of Pennsylvania. Our research has benefited from the advice and encouragement of Gerry Schleiffer (Vice President of Planning and Allocation of Nine West Group, Inc., at the time this study was conducted, and now Vice President of Planning and Allocation of United Retailer) and Jack Swem (Vice President of Planning and Distribution, Meldisco). We would like to thank Andreas Robotis for developing the software and performing the computations described in the paper and Professors Don Morrison and Dave Rubenstien for their useful comments in the earlier drafts of this paper. Finally, we are deeply appreciative to the two referees, the area editor, and Professor Brian T. Ratchford for their input during the review process, which has greatly increased the quality of this paper.</p><p>S ip : sales of product p in store i during a period comparable in timing and duration to a period which a test would be conducted, U p : the understock cost per unit of buying less than demanded of product p, O p : the overstock cost per unit of buying more than demanded of product p, and M: a sufficiently large real number. (In this application, it was set to 1000.)</p><p>Define the variables:</p><formula xml:id="formula_9">y j ‫ס‬ 1</formula><p>, if store j is chosen as a test store, Ά 0, otherwise;</p><p>x ij ‫ס‬ 1, if store i is assigned to a cluster represented by test store j, Ά 0, otherwise;</p><p>␣ j : weight used to scale test sales at test store j to sales for the entire season across the chain; h p : number of understock units of product p; and c p : number of overstock units of product p.</p><p>The Merchandise Testing Problem (MTP) is given by the following mixed linear integer program: </p><formula xml:id="formula_10">m Z (k) ‫ס‬ Min U h ‫ם‬ O c ,<label>(1a)</label></formula><formula xml:id="formula_11">͚ j j‫1ס‬ n x ‫ס‬ 1 ∀i,<label>(8a)</label></formula><formula xml:id="formula_12">͚ ij j‫1ס‬ 0 Յ x Յ y Յ 1 ∀i, j, (<label>9a</label></formula><formula xml:id="formula_13">) ij j x , y ʦ {0, 1} ∀i, j. (<label>10a</label></formula><formula xml:id="formula_14">)</formula><formula xml:id="formula_15">ij j</formula><p>Objective function (1a) minimizes the total overstock and understock costs for the m products during the entire season across the chain; Equations (2a) and (3a) define overstock and understock quantities for each product, respectively; (4a) ensures that these values are nonnegative; (5a) estimates the forecast demand for each product by using test store sales at the k test stores; (6a) ensures that these weights are nonzero only if a store is chosen to be a test store; (7a) enforces the condition that we have exactly k test stores; (8a) that each store is assigned to a test store; and (9a) that stores are assigned only to chosen test stores. Integrality constraints are imposed by (10a).</p><p>Using data from the fashion apparel retailer, we solved MTP using the OSL solver in GAMS (see <ref type="bibr" target="#b0">Brooke et al. 1992)</ref>. Tables 1a and 2a report forecast errors (F.E.) and costs for the cases in which results were reported in Tables <ref type="table" target="#tab_0">1 and 2</ref>. Comparing the results in Tables <ref type="table" target="#tab_0">1a  and 2a</ref> with the results for other methods on the same cases, we see that the unified approach MTP did slightly worse than k-median clustering based on sales (1.2% higher cost on average for the cases in Table <ref type="table" target="#tab_0">1</ref> and 1.7% higher cost for the case in Table <ref type="table" target="#tab_2">2</ref>), but better than all other methods. It may seem surprising that a single optimization would not dominate the segmented approach computationally. The unified optimization MPT, by definition, can do no worse on the calibration sample than the segmented k-median clustering, but we found it performed worse on the evaluation samples. This could be because of a sampling error, although we believe the fact that k-median sales clustering uses full season sales in forming clusters results in a more robust choice of test stores. An advantage of the full optimization approach is that it better addresses a situation in which differences in timing of sales during the season are important to consider. Because of its greater simplicity and superior performance, we prefer the k-median sales clustering approach, but the differences between the two approaches are clearly small and the unified method deserves future research.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 Forecast Error (F.E.) as a % of Unit Sales and Costs as % of Revenue for Different Methods</head><label>1</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">k-Median</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">k-Median</cell><cell cols="2">Clustering Based</cell></row><row><cell></cell><cell cols="2">k-Median</cell><cell></cell><cell></cell><cell cols="2">Regression</cell><cell></cell><cell></cell><cell cols="2">Clustering Based</cell><cell></cell><cell>on Store</cell></row><row><cell></cell><cell cols="2">Clustering Based</cell><cell cols="2">Regression with</cell><cell cols="2">with Backward</cell><cell cols="2">Existing Method</cell><cell></cell><cell>on Store</cell><cell cols="2">Descriptors</cell></row><row><cell></cell><cell></cell><cell>on Sales</cell><cell cols="2">Forward Selection</cell><cell cols="2">Elimination</cell><cell cols="2">Used by Retailer</cell><cell cols="2">Descriptors</cell><cell cols="2">and Sales</cell></row><row><cell>k</cell><cell>F.E.</cell><cell>Costs</cell><cell>F.E.</cell><cell>Costs</cell><cell>F.E.</cell><cell>Costs</cell><cell>F.E.</cell><cell>Costs</cell><cell>F.E.</cell><cell>Costs</cell><cell>F.E.</cell><cell>Costs</cell></row><row><cell>1</cell><cell>36.0</cell><cell>40.0</cell><cell>37.9</cell><cell>42.2</cell><cell>38.6</cell><cell>43.0</cell><cell>71.0</cell><cell>74.0</cell><cell>39.8</cell><cell>44.3</cell><cell>38.2</cell><cell>42.4</cell></row><row><cell>5</cell><cell>17.0</cell><cell>25.9</cell><cell>27.0</cell><cell>35.9</cell><cell>28.0</cell><cell>37.0</cell><cell>52.1</cell><cell>58.0</cell><cell>23.3</cell><cell>32.8</cell><cell>20.3</cell><cell>30.6</cell></row><row><cell>10</cell><cell>12.9</cell><cell>20.9</cell><cell>19.1</cell><cell>29.2</cell><cell>20.0</cell><cell>30.1</cell><cell>41.9</cell><cell>46.0</cell><cell>19.0</cell><cell>28.9</cell><cell>16.7</cell><cell>23.0</cell></row><row><cell>15</cell><cell>12.0</cell><cell>19.5</cell><cell>17.1</cell><cell>26.0</cell><cell>16.8</cell><cell>23.7</cell><cell>38.1</cell><cell>42.3</cell><cell>16.8</cell><cell>23.2</cell><cell>15.9</cell><cell>22.4</cell></row><row><cell>16</cell><cell>11.7</cell><cell>19.3</cell><cell>16.8</cell><cell>23.6</cell><cell>16.6</cell><cell>23.0</cell><cell>37.7</cell><cell>41.9</cell><cell>16.5</cell><cell>22.9</cell><cell>15.4</cell><cell>22.2</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 4 Forecast Error (F.E.) as a % Unit Sales and Cost as % of Revenue for Different Methods applied to Nine West Data</head><label>4</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>k-Median</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>k-Median</cell><cell></cell><cell cols="2">Clustering Based</cell></row><row><cell></cell><cell>k-Median</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Clustering Based</cell><cell>on Store</cell><cell></cell></row><row><cell></cell><cell cols="2">Clustering Based</cell><cell cols="2">Regression with</cell><cell cols="2">Heuristic Used by</cell><cell>on Store</cell><cell></cell><cell cols="2">Descriptors</cell></row><row><cell></cell><cell>on Sales</cell><cell></cell><cell cols="2">Forward Selection</cell><cell cols="2">Another Retailer</cell><cell cols="2">Descriptors</cell><cell cols="2">and Sales</cell></row><row><cell>k</cell><cell>F.E.</cell><cell>Costs</cell><cell>F.E.</cell><cell>Costs</cell><cell>F.E.</cell><cell>Costs</cell><cell>F.E.</cell><cell>Costs</cell><cell>F.E.</cell><cell>Costs</cell></row><row><cell>1</cell><cell>49.1</cell><cell>45.3</cell><cell>56.2</cell><cell>51.8</cell><cell>61.0</cell><cell>56.2</cell><cell>53.7</cell><cell>49.4</cell><cell>51.1</cell><cell>46.6</cell></row><row><cell>5</cell><cell>18.9</cell><cell>18.1</cell><cell>27.5</cell><cell>26.8</cell><cell>29.8</cell><cell>28.5</cell><cell>23.5</cell><cell>22.9</cell><cell>20.7</cell><cell>20.0</cell></row><row><cell>10</cell><cell>17.6</cell><cell>16.6</cell><cell>26.0</cell><cell>24.9</cell><cell>27.9</cell><cell>27.1</cell><cell>22.1</cell><cell>21.1</cell><cell>19.1</cell><cell>18.2</cell></row><row><cell>15</cell><cell>17.0</cell><cell>15.4</cell><cell>24.7</cell><cell>24.1</cell><cell>27.3</cell><cell>26.8</cell><cell>21.2</cell><cell>20.3</cell><cell>18.5</cell><cell>17.6</cell></row><row><cell>20</cell><cell>16.7</cell><cell>15.0</cell><cell>24.6</cell><cell>23.9</cell><cell>26.8</cell><cell>25.9</cell><cell>20.8</cell><cell>19.8</cell><cell>18.2</cell><cell>17.3</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 Forecast Error and Cost for Models Fit on 1993 Data and Applied to 30 1994 Products</head><label>2</label><figDesc></figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>k-Median</cell></row><row><cell></cell><cell></cell><cell>k-Median</cell><cell></cell><cell></cell><cell></cell><cell>k-Median</cell><cell>Clustering</cell></row><row><cell></cell><cell></cell><cell>Clustering</cell><cell cols="2">Regression with</cell><cell></cell><cell>Clustering</cell><cell>Based on Store</cell></row><row><cell></cell><cell>Existing Method</cell><cell>Based on Sales</cell><cell cols="2">Forward Selection</cell><cell>Regression with</cell><cell>Based on Store</cell><cell>Descriptors and</cell></row><row><cell></cell><cell>with 25</cell><cell>with 10</cell><cell>with 10</cell><cell></cell><cell>Backward Elimination</cell><cell>Descriptors with</cell><cell>Sales with 10</cell></row><row><cell></cell><cell>Test Stores</cell><cell>Test Stores</cell><cell>Test Stores</cell><cell></cell><cell>with 10 Test Stores</cell><cell>10 Test Stores</cell><cell>Test Stores</cell></row><row><cell>Forecast Error as % of Sales</cell><cell>38.0</cell><cell>19.5</cell><cell>30.0</cell><cell></cell><cell>31.0</cell><cell>29.0</cell><cell>25.5</cell></row><row><cell>Markdown Cost as % of Revenue</cell><cell>30.6</cell><cell>19.0</cell><cell>28.0</cell><cell></cell><cell>29.0</cell><cell>25.0</cell><cell>24.0</cell></row><row><cell>Lost Margin as % of Revenue</cell><cell>14.4</cell><cell>8.0</cell><cell>11.0</cell><cell></cell><cell>12.0</cell><cell>11.0</cell><cell>9.5</cell></row><row><cell>Total of Markdown Cost and Lost Margin</cell><cell>45.0</cell><cell>27.0</cell><cell>39.0</cell><cell></cell><cell>41.0</cell><cell>36.0</cell><cell>33.5</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Table 3</cell><cell cols="4">Impact of Test Period Length on Forecast Error and Cost for</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="3">k-Median Clustering Based on Sales</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Length of</cell><cell></cell><cell>Forecast Error</cell><cell cols="2">Total Markdown Cost and</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Test Period</cell><cell></cell><cell>as % of Sales</cell><cell cols="2">Lost Margin as % Revenue</cell></row><row><cell></cell><cell></cell><cell></cell><cell>1</cell><cell></cell><cell>30.0</cell><cell></cell><cell>42.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>2</cell><cell></cell><cell>24.0</cell><cell></cell><cell>33.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>3</cell><cell></cell><cell>19.5</cell><cell></cell><cell>27.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>5</cell><cell></cell><cell>17.0</cell><cell></cell><cell>24.0</cell></row><row><cell></cell><cell></cell><cell></cell><cell>7</cell><cell></cell><cell>16.0</cell><cell></cell><cell>23.2</cell></row><row><cell></cell><cell></cell><cell></cell><cell>10</cell><cell></cell><cell>15.5</cell><cell></cell><cell>22.7</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 5 Impact of Test Period Length on Forecast Error and Cost for k-Median Clustering Based on Sales for Nine West Dataof Test Period Length on Forecast Error for k- Median Clustering Based on Sales for Meldisco Data</head><label>5</label><figDesc></figDesc><table><row><cell>Length of</cell><cell>Forecast Error</cell><cell>Total Markdown Cost and</cell></row><row><cell>Test Period</cell><cell>as % of Sales</cell><cell>Lost Margin as % Revenue</cell></row><row><cell>1</cell><cell>28.3</cell><cell>26.5</cell></row><row><cell>2</cell><cell>22.1</cell><cell>20.9</cell></row><row><cell>3</cell><cell>17.6</cell><cell>16.6</cell></row><row><cell>5</cell><cell>15.4</cell><cell>14.2</cell></row><row><cell>7</cell><cell>14.1</cell><cell>13.0</cell></row><row><cell>10</cell><cell>12.2</cell><cell>11.1</cell></row><row><cell>20</cell><cell>11.1</cell><cell>10.2</cell></row><row><cell>26</cell><cell>10.7</cell><cell>9.8</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table A2 Forecast Error and Cost for Combined Optimization Approach Fit on 1993 Data and Applied to 30 1994 Productsof Sales and Cost as % of Revenue for the Combined Optimization Approach</head><label>A2</label><figDesc></figDesc><table><row><cell cols="4">Table A1 Forecast Error (F.E.) as a % k 1 5 1 0</cell><cell>1 5</cell><cell>1 6</cell></row><row><cell>F.E.</cell><cell>37.1</cell><cell>18.6</cell><cell>14.3</cell><cell>13.2</cell><cell>13.0</cell></row><row><cell>Costs</cell><cell>41.2</cell><cell>26.3</cell><cell>22.1</cell><cell>21.2</cell><cell>20.9</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">Total of Markdown</cell></row><row><cell></cell><cell cols="2">Markdown Cost</cell><cell>Lost Margin</cell><cell cols="2">Cost and Lost</cell></row><row><cell>Forecast Error</cell><cell cols="2">as % of</cell><cell>as % of</cell><cell cols="2">Margin as %</cell></row><row><cell>as % of Sales</cell><cell cols="2">Revenue</cell><cell>Revenue</cell><cell cols="2">of Revenue</cell></row><row><cell>21.3</cell><cell>20</cell><cell></cell><cell>8.7</cell><cell>28.7</cell><cell></cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Marketing Science/Vol. 19, No. 3, Summer 2000</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">GAMS: A User&apos;s Guide</title>
		<author>
			<persName><forename type="first">A</forename><surname>Brooke</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Kendrick</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Meeraus</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1992" />
			<publisher>The Scientific Press</publisher>
			<pubPlace>San Francisco, CA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Location of bank accounts to optimize float: An analytic study of exact and approximate algorithms</title>
		<author>
			<persName><surname>Cornuejols</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Marshall</forename><forename type="middle">L</forename><surname>Gerard</surname></persName>
		</author>
		<author>
			<persName><forename type="first">George</forename><forename type="middle">L</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><surname>Nemhauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="789" to="810" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The Borders system. Presented at First Annual Harvard/Wharton Merchandising Effectiveness Conference</title>
		<author>
			<persName><forename type="first">Robert</forename><surname>Diromualdo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998-05-20" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A review of in-store experiments</title>
		<author>
			<persName><forename type="first">Peter</forename><surname>Doyle</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">Zeke</forename><surname>Gidengil</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Retailing</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="47" to="62" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Accurate retail testing of fashion merchandise: Methodology and application</title>
		<author>
			<persName><forename type="first">Marshall</forename><forename type="middle">L</forename><surname>Fisher</surname></persName>
		</author>
		<author>
			<persName><surname>Kumar Rajaram</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harvard Bus. Rev</title>
		<imprint>
			<date type="published" when="2000-07" />
		</imprint>
	</monogr>
	<note type="report_type">Working Paper</note>
	<note>Rocket science retailing is almost here-are you ready?</note>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">An integrated view of the assortment management process: The next frontier for leading retailers</title>
		<author>
			<persName><forename type="first">L</forename><forename type="middle">J</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chain Store Age Executive</title>
		<imprint>
			<date type="published" when="1995-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A rearview mirror might help us drive forward</title>
		<author>
			<persName><forename type="first">Hollander</forename><surname>Stanley</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Retailing</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="7" to="10" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Classical and Modern Regression with Applications</title>
		<author>
			<persName><forename type="first">R</forename><forename type="middle">H</forename><surname>Myers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1990" />
			<publisher>PWS-KENT Publishing Company</publisher>
			<pubPlace>Boston, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Target micromarkets its way to success: No 2 stores are alike</title>
		<author>
			<persName><forename type="first">Gregory</forename><forename type="middle">A</forename><surname>Patterson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Wall Street Journal</title>
		<imprint>
			<date type="published" when="1995-05-31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Raising the bar: Keys to high performance</title>
		<author>
			<persName><forename type="first">Elaine</forename><surname>Pollack</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1994" />
		</imprint>
	</monogr>
	<note>Chain Store Executive Age</note>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">Design and Marketing of New Products</title>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">L</forename><surname>Urban</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">R</forename><surname>Hauser</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>Prentice-Hall Inc</publisher>
			<pubPlace>Englewood Cliffs, NJ</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Quick hits in store level merchandise and inventory management</title>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">L</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Kingdom</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Reeve</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Chain Store Age Executive</title>
		<imprint>
			<biblScope unit="page" from="103" to="106" />
			<date type="published" when="1995-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">This paper was received June 25, 1996, and was with the authors 36 months for 4 revisions</title>
		<editor>Gary Lilien</editor>
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
