<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 https://raw.githubusercontent.com/kermitt2/grobid/master/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org A Structured Analysis of Unstructured Big Data by Leveraging Cloud Computing</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2016-04-28">April 28, 2016</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName><roleName>Param</roleName><forename type="first">Xiao</forename><surname>Liu</surname></persName>
							<email>xliu@stern.nyu.edu</email>
						</author>
						<author>
							<persName><forename type="first">Vir</forename><surname>Singh</surname></persName>
						</author>
						<author>
							<persName><forename type="first">Kannan</forename><surname>Srinivasan</surname></persName>
							<email>kannans@cmu.edu</email>
						</author>
						<author>
							<persName><forename type="first">Vir</forename><surname>Param</surname></persName>
						</author>
						<author>
							<persName><surname>Singh</surname></persName>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Stern School of Business</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<postCode>10012</postCode>
									<settlement>New York</settlement>
									<region>New York</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="department">Tepper School of Business</orgName>
								<orgName type="institution">Carnegie Mellon University</orgName>
								<address>
									<postCode>15213</postCode>
									<settlement>Pittsburgh</settlement>
									<region>Pennsylvania</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Publication details, including instructions for authors and subscription information: http://pubsonline.informs.org A Structured Analysis of Unstructured Big Data by Leveraging Cloud Computing</title>
					</analytic>
					<monogr>
						<idno type="ISSN">0732-2399 (print)</idno>
						<imprint>
							<date type="published" when="2016-04-28">April 28, 2016</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1287/mksc.2015.0972</idno>
					<note type="submission">Received: December 31, 2013; accepted: September 30, 2015; Pradeep Chintagunta, Dominique Hanssens, and John Hauser served as the special issue editors and Koen Pauwels served as associate editor for this article.</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.2" ident="GROBID" when="2021-07-06T11:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>big data</term>
					<term>cloud computing</term>
					<term>text mining</term>
					<term>user generated content</term>
					<term>Twitter</term>
					<term>Google Trends</term>
				</keywords>
			</textClass>
			<abstract>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Please scroll down for article-it is on subsequent pages</head><p>With 12,500 members from nearly 90 countries, INFORMS is the largest international association of operations research (O.R.) and analytics professionals and students. INFORMS provides unique networking and learning opportunities for individual professionals, and organizations of all types and sizes, to better understand and use O.R. and analytics tools and methods to transform strategic visions and achieve better outcomes. For more information on INFORMS, its publications, membership, or meetings visit http://www.informs.org</p></div>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>The average American watches 5.1 hours of television per day, which is more than the 4.6 self-reported daily hours that are spent on all work-related, educational, and housework activities <ref type="bibr" target="#b36">(Nielsen 2011</ref><ref type="bibr">, Bureau of Labor Statistics (BLS) 2011</ref>. This statistic explains why TV is the largest ad spending medium in the United States. Still, the ad spending in the medium remains relatively stable despite the significant growth of online advertising.</p><p>Accurate forecasts of television ratings are critical for many reasons. First, depending on the forecasts, networks often adjust the number of new shows for each series. Second, the pricing of advertising for TV shows can be made more dynamic and near real time. Current online advertising on content-based sites is realized in as little as 0.35 seconds based on dynamic real-time bidding models. The spillover to traditional television advertising is beginning to occur. Thus, better forecasts of the size of a viewing audience will enhance the ability to conduct price auctions, and advertisers can decide whether to participate and how much to bid. Third, depending on the projected ratings, firms can adjust many (endogenous) actions, such as advertisements for TV shows, paid blogs, and Tweets, to affect the ratings. Therefore, advertisers and broadcasting companies are eager to accurately predict the TV show's ratings.</p><p>A recent article in the New York Times (2015) emphasizes the industry significance of the issue studied in our paper. "So far, however, Twitter and Nielsen have avoided the most important question posed by <ref type="bibr">Liu, Singh, and</ref>  marketers and the TV industry: Exactly how much does chatter on Twitter lift the viewership of a particular show? Although Nielsen published data on the Twitter activity surrounding a show's broadcast as a complement to its more familiar TV ratings, it has said little about the relationship between the two." The issue that we examine in this paper is of paramount importance to the industry.</p><p>Currently, consumers use various online platforms to enhance their TV watching experience: They look for show-related information on search engines such as Google and share their viewing experience with friends on social networks such as Twitter and Facebook. These online platform footprints can help advertisers forecast demand. However, the content on these online platforms produces two challenges. First, the data that are produced are in an unstructured form (for example, texts, video, audio, and images). Second, the sheer volume of data makes standard data analysis procedures computationally unworkable or inefficient. Existing literature has attempted to incorporate user-generated content (UGC) in its analyses by including easy-tocalculate measures such as the volume or valence of relevant UGC on online platforms. Recent studies have attempted to examine content information (e.g., <ref type="bibr" target="#b24">Gopinath et al. 2014</ref><ref type="bibr" target="#b46">, Pauwels et al. 2013</ref>. These studies depend primarily on manual coders to classify the UGC, which limits the scale of the application, or they follow a supervised learning approach to classify the UGC. However, all of these studies are limited in the extent to which the UGC is typically classified into preconceived labels (such as sentiment, recommendation-oriented or emotion). We show that the information in the textual content can provide greater insight into user behavior and decision making. Moreover, an unsupervised learning approach can provide significant improvement in forecasting performance than measures such as volume and sentiment. We combine the methods from machine learning and text mining to more completely examine the textual content, and we endogenously identify distinct streams of information in the UGC. We use the tools and methods from cloud computing, such as Hadoop MapReduce, to manage millions of text documents. In this way, we confront a problem that is germane to text mining. We find that the number of distinct information streams identified is typically greater by an order of magnitude than the number of observations on the variable of interest. To address this concern, we conduct a massive dimension reduction using the Apache Mahout machine learning library to summarize the significant amount of information into several principal components. We find that these principle components have excellent predictive power in demand forecasting. None of the tasks described above are trivial when the volume of data is significant. The memory space and computing capacity of a single workstation cannot manage data of our scale. Instead, we use Amazon Web Services to perform the cloud computing tasks and pay with only a minimal budget.</p><p>We use the unstructured data of consumer behavior on online platforms, including Twitter, Google Trends, Wikipedia, the Internet Movie Database (IMDB), and Huffington Post (TGWIH) to predict consumers' offline TV viewing behavior for 30 TV series and prime time National Football League (NFL) games. We argue that consumers reveal their interests in TV programs through online platforms before actually watching TV. For example, a Twitter user's post, "I am going to watch Breaking Bad tonight," is a direct indication of her future TV watching intent for a specific show. If a user searches Google for an NFL game before the game begins, it is likely that he is going to watch it on TV. Therefore, by collecting publicly available data from TGWIH at a negligible cost, marketers and advertisers can leverage consumer-generated data to accurately forecast future demand rather than relying on the historical information from the Nielsen Rating data.</p><p>To achieve our goal, we use a large data set derived from the following five sources of online platforms:</p><p>(1) Twitter, 1.8 billion Tweets for five years from 2008 to 2013; (2) Google Trends, 1 113.3 million Google searches 2 (when combined with the Google AdWords keyword volume service, we can obtain the real search volume);</p><p>(3) Wikipedia views, 433.6 billion Wikipedia page views; (4) IMDB reviews, 4.3 thousand reviews; and (5) Huffington Post news, 5.5 million articles. We find that the predictive power of the surface-level measures of the UGC, such as the volume of Google searches (or Wikipedia views) or the volume and valence of Tweets (or IMDB reviews and Huffington Post news), is not as strong as the historical data for forecasting TV ratings. However, the refined information in Tweets exhibits a stronger power to predict TV ratings than historical ratings.</p><p>We conduct a rigorous, structured econometrics analysis of the processed unstructured data. Our results show that Tweets, Google searches, Wikipedia views, IMDB reviews, and Huffington Post News volume have a positive impact on TV ratings. The impact of the valance of Tweets on ratings is not statistically significant. Carefully summarized Tweet content that indicates future action has the highest predictive power.</p><p>Our paper makes two key contributions. First, from a managerial standpoint, we show that easily accessible 1 Google Trends is a public Web facility of Google, Inc. that is based on Google Search. It shows how often a particular search term is entered relative to the total search volume across various regions of the world and in various languages. <ref type="bibr">2</ref> Google Trends and Wikipedia views data are structured in a numerical format. The other three sources of data are in a text format.</p><p>365 public information from online platforms can be used to predict TV ratings. Particularly, surface-level information such as volume and valance is not more useful than the historical data; only a sophisticated content analysis can achieve high prediction accuracy. Our proposed method has a distinct advantage because it does not require classification of content into pre-conceived topics that may not be relevant. Instead, our method endogenously summarizes the information in Tweets into topics. That is, our approach classifies the relevant Twitter content into distinct streams of information that consumers are discussing. Second, we introduce state-of-the-art big data processing techniques through a cloud-based distributed computing framework called Hadoop MapReduce, which we demonstrate with Amazon Web Service tools. We hope marketing researchers can use these methods to conduct more structured research on large scale unstructured data. 3</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Literature Review</head><p>Our paper draws on three lines of literature, i.e., (1) using online platform data for predictions, (2) the effect of online UGC on product sales, and (3) text mining.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Online Platform Predictions</head><p>Research has suggested that Twitter feeds are early indicators of various economic and social phenomena, such as book sales <ref type="bibr" target="#b25">(Gruhl et al. 2005)</ref>, movie box office sales <ref type="bibr" target="#b34">(Mishne and Glance 2006)</ref>, opinion polls <ref type="bibr" target="#b40">(O'Connor et al. 2010)</ref>, elections <ref type="bibr" target="#b53">(Tumasjan et al. 2010)</ref>, the spread of contagious diseases <ref type="bibr" target="#b45">(Paul and Dredze 2011)</ref>, stock market performance <ref type="bibr" target="#b5">(Bollen et al. 2011)</ref>, and NFL game outcomes <ref type="bibr" target="#b50">(Sinha et al. 2013)</ref>. The predictive power of Twitter is derived from the information that is embedded in consumers' conversations. We follow this literature to predict the ratings of popular TV shows in the U.S. market. The literature concerning the demand prediction of new product introduction has studied products, including movies, books, cellphones, etc. By comparison, our focal product, TV shows, is unique because every week, a new "mini" product (i.e., episode) is released. <ref type="bibr">4</ref> This continuity makes TV show demand relatively easier to predict than the demand for other products. Beyond Twitter, research has also investigated other online platform data for predictions, such as Google searches <ref type="bibr" target="#b47">(Preis et al. 2010)</ref> and Wikipedia views <ref type="bibr" target="#b33">(Mestyán et al. 2013)</ref>. These studies typically capture information in Tweets by volume, valence or emotion. Furthermore, most papers in this area use machine learning methods with the objective of merely minimizing the prediction error. We instead use an econometrics model that corrects for the <ref type="bibr" target="#b39">Nickell (1981)</ref> bias to perform a more structured analysis (about providing economic explanations) of the unstructured data from multiple online platform sources.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">The Effect of Online UGC on Sales</head><p>Our paper is also closely related to the literature on the effect of UGC on demand/sales. As listed in Table <ref type="table" target="#tab_1">1</ref>, numerous studies have examined this topic in marketing and computer science for explanatory or prediction purposes. In these papers, researchers have used various forms of UGC, including online reviews, online ratings, and blogs to investigate their impact on the demand for the focal products. We instead use more popular online platforms, including TGWIH, to collect UGC. The advantage of our approach is that these platforms have a much wider user base; therefore, the predicted demand from using information from these platforms is more likely to represent emerging big data information sources.</p><p>Additionally, as Table <ref type="table" target="#tab_1">1</ref> demonstrates, metrics such as the volume, valence, and variance of UGC have been examined. However, the rich content information in text data has been underexploited. In fact, to our knowledge only three of the prior studies <ref type="bibr" target="#b41">(Onishi and Manchanda 2012</ref><ref type="bibr" target="#b24">, Gopinath et al. 2014</ref><ref type="bibr" target="#b46">, and Pauwels et al. 2013</ref>) have tried to perform text mining beyond basic sentiment analysis. Our paper extends this line of the literature with two major distinctions. First, we incorporate cloud-based, large scale text mining to extract useful information from a vast amount of data whose size is larger than the data in the previous literature by a magnitude of 1,000. Second, we exploit unsupervised learning techniques to allow the data to determine the issues rather than imposing any label on the features. (For example, <ref type="bibr" target="#b46">Pauwels et al. 2013</ref> selected conversations related to "went there/purchased," and <ref type="bibr" target="#b24">Gopinath et al. 2014</ref> classified online conversations as related to attributes/emotions/recommendations). Instead, we mine the data with an unsupervised learning approach and adopt a dimensionality reduction method (specifically, principal component analysis). By studying the loading of specific content, we can interpret the key principal components. Thus, our approach is consistent with the traditional marketing approach wherein the dimensionality reduction is first undertaken (such as factor analysis and principal component analysis), and then, the factors are interpreted.   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">Mining Unstructured Text Data</head><p>As noted by <ref type="bibr" target="#b2">Archak et al. (2011)</ref>, textual information embedded in UGC has largely been ignored in business research because of a lack of practical tools to analyze this unstructured data. <ref type="bibr" target="#b38">Netzer et al. (2012)</ref> also noted that the overwhelmingly large volume of data has made analysis extremely difficult if not impossible. Recently, with the aid of automated machine learning techniques, research has emerged to exploit the content of text data rather than its simple numeric volume to provide richer insights. These studies include <ref type="bibr" target="#b14">Das and Chen (2007)</ref>, <ref type="bibr" target="#b21">Ghose et al. (2007)</ref>, <ref type="bibr" target="#b18">Eliashberg et al. (2007)</ref>, <ref type="bibr" target="#b15">Decker and Trusov (2010)</ref>, <ref type="bibr" target="#b19">Ghose and Ipeirotis (2011)</ref>, <ref type="bibr" target="#b30">Lee and Bradlow (2011)</ref>, <ref type="bibr" target="#b20">Ghose et al. (2012)</ref>, and <ref type="bibr" target="#b29">Lee et al. (2013)</ref>. More applications that use text mining can be found in areas other than marketing, such as computer science (see <ref type="bibr" target="#b44">Pang and Lee 2008</ref> for a review).</p><p>Our paper goes beyond text mining by combining it with cloud-computing techniques to quickly and cost efficiently analyze big text data. To our knowledge, the amount of Twitter feed data that we process is much larger than the scale of any previous papers. See § §3 and 4 for details.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Data Description</head><p>Our primary goal is to use online platform data to predict TV ratings. Below, we explain how we collect the data for TV ratings and five sources of online platforms, including TGWIH.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">TV Series</head><p>We study a collection of 30 U.S. TV series during the 2008 to 2012 TV seasons. Table <ref type="table">2</ref> shows the number of episodes and each show's ranking in terms of total viewership over the five TV seasons. 5 Among these TV <ref type="bibr">5</ref> Among the shows, some (e.g., Breaking Bad) are cable shows (AMC is a cable network that generates revenue from user subscription fees), whereas other shows (e.g., The Big Bang Theory) are network broadcast shows (CBS is a broadcasting network whose revenue mainly comes from advertisements). Because cable shows generally have fewer viewers, the ranks of cable shows and network broadcast shows are not directly comparable.  shows, some are very popular, including The Big Bang Theory, Breaking Bad, Grey's Anatomy, NCIS, and Two and a Half Men. We chose these shows first because advertisers are eager to know their ratings because these shows are costly on a cost per thousand views (CPM) basis (for example, The Big Bang Theory commanded a staggering $326,260 per 30-second spot on CBS 6 in 2013, which ranked behind only Sunday Night Football (SNF)). Second, we chose these shows because their popularity may generate significant talk on online platforms, such as Twitter and Google searches. Other less well known shows are also included, such as Allen Gregory, Charlie's Angels, Hellcats, Harry's Law, and Gary Unmarried. These shows did not last more than two seasons. We include them because their ratings vary dramatically, and they are difficult to predict. We also examine other shows that are neither popular nor unpopular to demonstrate the generalizability of our findings. We focus on shows whose titles are unique enough 7 not to be confused with other common words that may appear in Tweets (e.g., if we search in Tweets for another popular show called Community, many non-related Tweets with the generic word "community" may appear).  <ref type="table" target="#tab_4">3</ref>, there are more games on Sundays than on Mondays or Thursdays.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">NFL</head><p>6 http://www.adweek.com/news/television/big-bang-theory-gets -highest-ad-rates-outside-nfl-153087. <ref type="bibr">7</ref> We also performed an analysis on six shows with common words as titles. We applied machine learning techniques to classify the relevant tweets rather than the method described in §3.4.2. Our results show that the Tweet Content Model also performs significantly better than other models for these shows. We thank the anonymous reviewer for suggesting this generalization test. <ref type="bibr">8</ref> The preseason and postseason games' advertising slots are normally not on the scatter market.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">A.C. Nielsen Ratings</head><p>We search the A.C. Nielsen Ratings data for the 18-49 year old age range (http://tvbythenumbers.zap2it.com) for each episode of the 30 TV series 9 and each prime time NFL game. By definition, rating means the percentage of all television-equipped households that were tuned in to that program at any given moment. Figure <ref type="figure">1</ref>(a) depicts the ratings of the five most popular TV series (Breaking Bad, The Big Bang Theory, Grey's Anatomy, NCIS, and Two and a Half Men, in Figure <ref type="figure">1</ref>(a)) and five unpopular TV series (Allen Gregory, Charlie's Angels, Gary Unmarried, Harry's Law, and Hellcats, in Figure <ref type="figure">1(b)</ref>) for the five seasons from 2008 to 2012. Each show has a unique trend throughout the five years. Breaking Bad experienced an upward trend over time and reached a dramatic spike for the final episode of the final season. The Big Bang Theory gradually improved its ratings every year. Grey's Anatomy's ratings decreased. NCIS' ratings remained stable, and Two and a Half Men lost popularity soon after the main character (Charlie Sheen) was replaced in 2011. All of the unpopular shows have a steep, downward-sloping ratings trend.</p><p>For the NFL games (in Figure <ref type="figure">2</ref>), SNF is the most watched, whereas Thursday Night Football is the least watched. Despite the trend across years, when we focus on each season, the ratings time series are relatively stationary.</p><p>Based on Figures 1(a) and 2, we know that each TV series and each game day of the week (Sunday, Monday, and Thursday) has a distinct time-series pattern and can be treated as one member of the panel data.</p><p>Next, we describe the data derived from five online platform sites, i.e., TGWIH.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Twitter</head><p>Founded in 2006, Twitter is a real-time information service where people around the world can post ideas, comments, news, photos, and videos in 140 characters or fewer. In 2012, there were more than 500 million registered users who posted 340 million Tweets per day. Twitter ranks as the second 10 most visited social <ref type="bibr">9</ref> Unfortunately, this website did not collect any ratings data for Breaking Bad for the 2008 and 2009 seasons. Therefore, we use only the 2010-2012 ratings data for that program. 10 Unfortunately, we could not access Facebook data. Moreover, although Facebook has a wider user base, most people make their Facebook status updates and content viewable only to their friends, which leaves only a small percentage of public Facebook updates involving TV shows that are available to researchers. This restriction significantly constrains the number of Facebook posts that we can analyze. Moreover, Twitter is known as "the place that hosts a real-time, public conversation about TV at scale" (http://www.mediaweek.co.uk/article/1288398/twitter-buys -secondsync-mesagraph). Therefore, we do not use Facebook data in this paper. 3.4.1. Data Gathering. The data we use are collected from Twitter (www.twitter.com) using the "garden hose" (10%) stream 12 on a daily basis from September 1, 2008 to October 27, 2013. <ref type="bibr">13</ref> Table <ref type="table" target="#tab_6">4</ref> shows the size of the data set per month as measured by the number of Tweets (in millions) and the text file storage size.</p><p>From this large number of Tweets, we first select the relevant Tweets that discuss the 30 TV series and NFL prime time games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">Selecting Relevant Tweets.</head><p>We use the following four types of identifiers to search for the relevant  Tweets for the five TV series: (1) name of the show (e.g., Breaking Bad); <ref type="bibr">14</ref> (2) official Twitter account of the show (e.g., @TwoHalfMen_CBS); (3) a list of hashtags associated with the show (e.g., #AskGreys); and (4) the characters' names on the show (e.g., Sheldon Cooper).</p><p>As to the NFL, we use similar identifiers, including (1) a list of the hashtags of the 32 teams 15 (e.g., #gosteelers) and ( <ref type="formula">2</ref>) the hashtags of the game (e.g., #SNF). We use Hadoop MapReduce to efficiently select all of the relevant Tweets. See §4 for technical details. Tables <ref type="table" target="#tab_7">5 and 6</ref> show some summary statistics of the Tweets for the five TV series and the NFL games.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.3.">TV Series.</head><p>The number of Tweets on Twitter still varies greatly. If we compare the number of Tweets per episode, Breaking Bad created the most buzz, with more than 57,000 tweets, whereas the least popular show, Gary Unmarried, had only 45. For all 30 TV series, the number of Tweets peaks during the show; consumers Tweet more frequently before the show than afterward. These results reflect that Twitter is a social platform that creates real-time engagement for viewers. It is no surprise that Nielsen is teaming up with Twitter to establish social TV ratings. <ref type="bibr">16</ref> 3.4.4. NFL. Similarly, the number of Tweets is more intensive during the NFL games than before or after the games (Table <ref type="table" target="#tab_9">6</ref>).</p><p>For the 32 NFL teams (Table <ref type="table" target="#tab_11">7</ref>), the most Tweeted team on Twitter was the New York Jets, which had five times more Tweets on average than the least Tweeted team, the Jacksonville Jaguars. The difference in Tweet frequency is largely because of the size of the fan base.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.5.">Google Trends</head><p>We also collected data from Google Trends (http://www .Google.com/trends/). Google Trends provides the  <ref type="table" target="#tab_1">569 119 1 077 9  293 0  3 998 1  5 369 0  44 9  586 0 27 9  32 0  90210  136 434  38 605  699 171  874 210 1 196 8  338 6  6 133 1  7 668 5  49 9  338 6 42 9  45 6  Allen Gregory  796  1 279  6 106  8 181  113 8  182 7  872 2  1 168 7  4 7  365 4 6 1  7 0  Blue Bloods  21 344  15 445  132 811  169 600  239 8  173 5  1 492 3  1 905 6  10 0  173 5 10 4  11 3  Body of Proof  6 741  4 826  21 066  32 633  160 5  114 9  501 6  777 0  6 7  114 9 3 5  4 6  Breaking Bad  525 234  687 585  1 199 180  2 412 016 12 505 5 16 371 3 28 552 0 57 428 8 521 1 16 371 3 199 7 341 8  Charlie's Angels  2 365  1 014  11 994  15 372  337 9  144 8  1 713 4  2 196 1  14 1  144 8 12 0  13</ref>  total search volume for a particular search item. The results can be further customized to a certain time range, location, and language. For the TV series data, we use the name of the show (e.g., Two and a Half Men) and character names on the show (e.g., Walden Schmidt) as the keywords. For the NFL data, we use the name of the football team (e.g., Pittsburgh Steelers) as the keyword.</p><p>In Figure <ref type="figure" target="#fig_3">3</ref>, we present the results for the search item "the big bang theory" for the three months from September to November 2013 in the United States. When a search for a term on Google Trends is performed, a graph similar to Figure <ref type="figure" target="#fig_3">3</ref> is shown. The numbers on the graph reflect how many searches have been conducted relative to the total number of searches In addition, we use the Google AdWords Keyword planner volume search service 17 to obtain the absolute search volume or, more specifically, a 12-month average of the number of searches for the exact keyword based on the selected location and the Search Network target settings. Combining these data with the Google Trend relative numbers (by multiplying the relative number by a ratio to transform it to an absolute number), we obtain the absolute search volume for each day.</p><p>We record the Google Trends data daily (by restricting each search query to three months) for each of the 30 TV series and the 32 NFL teams. When matching the Google search data to a particular NFL game, we  add the numbers for the two teams that participated in the game.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.6.">Wikipedia</head><p>Wikipedia is a free access, free content Internet encyclopedia. As of February 2014, Wikipedia had 18 billion page views and nearly 500 million unique visitors every month (see <ref type="bibr" target="#b13">Cohen 2014)</ref>. Many of the Wikipedia editors are committed followers of the TV industry who gather information and edit related articles earlier than the show's release date. Consumers may view the edited information before the show or before the NFL games; therefore, the Wikipedia edits or views may be good predictors of TV ratings. We extract the edits and page view statistics from the Wikimedia Downloads site (http://dumps.wikimedia .org/other/pagecounts-raw). Table <ref type="table">8</ref> shows the number of webpages and the size of the data files.</p><p>Instead of focusing only on the Wikipedia pages designated to the TV programs (for example, http:// en.wikipedia.org/wiki/How_I_Met_Your_Mother  the day after the show. Google searches peaked after each show day. Wikipedia views and Huffington Post news often gradually increased in the next several days after a show day. However, the timing of IMDB reviews is irregular and somewhat misaligned with the ratings. Over the entire season, the TV ratings first moved down, then gradually increased, and reached a peak at the finale.</p><p>Because Tweets and Google searches cluster around the show days, in Figure <ref type="figure">4</ref> we determine whether the pattern of Tweets and Google searches on one day (24 hours) before each episode shows a similar pattern to the ratings. In Figure <ref type="figure">5</ref>, we can see that in the general ratings patterns, Tweets and Google searches are similar, but Tweets and Google searches fail to capture some local variations in the ratings. As to the NFL (right panel of Figure <ref type="figure">5</ref>), the trend in Tweets and Google searches shows an even larger variation from the ratings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Structured Analysis</head><p>4.1.1. Dynamic Panel Data Linear Model. Our model is a dynamic panel data linear model <ref type="bibr" target="#b6">(Bond 2002</ref>) that naturally extends <ref type="bibr" target="#b3">Arellano and Bond (1991)</ref> (the AB approach). The AB approach is a single equation model with autoregressive dynamics and explanatory variables that are not strictly exogenous. It uses a Generalized Method of Moments (GMM) estimator to consider all of the potential orthogonality conditions. The AB approach solves the Nickell bias problem <ref type="bibr" target="#b39">(Nickell 1981</ref>) of a fixed effects model using dynamic panel data. Our model fits the assumptions of the AB approach because we assume that the TV ratings in the current period can be explained by the ratings in previous periods and by the information in TGWIH before the TV program. In Equation (1), i ∈ 1 2 I denotes the TV series or the day of the week of the NFL prime time game. For example, for a TV series, 1 = "2 Broke Girls," with the orders shown in Table <ref type="table">2</ref>. For the NFL, 1 = Sunday Night Football, 2 = Thursday Night Football, and 3 = Monday Night Football}. The subscript t denotes time. For a TV series, one period of time is one episode of the show, whereas for the NFL, one period is one week in the regular season. The j th lag of the current period's TV show rating is denoted as Rating it−j . The variable F Tweet it denotes the information from Tweets regarding show i at time t. Because Tweets are unstructured text data, we try several functional forms for F that are explained later. The variable Google it measures the number of Google searches. The number of Wikipedia views is denoted by Wiki. The variables F IMDB it and F Huffington it contain the content information from IMDB reviews and Huffington Post News. The control variables, Controls it , include a premier indicator, a finale indicator, the age of the show (which episode in the entire history) and seasonality (a winter dummy variable that indicates whether it is in the winter or not). The show-specific, time-invariant fixed effect that is unobserved to the researcher is captured by u i , and it is the unobserved shock. We use TGWIH shortly before the TV program begins so that these measures are exogenous to the current errors (u i + it ), but not strictly exogenous to the past errors</p><formula xml:id="formula_0">Rating it = + J j=1 j Rating it−j + F Tweet it + Google it + Wiki it + F IMDB it + F Huffington it + Controls it + u i + it (1)</formula><p>According to <ref type="bibr" target="#b3">Arellano and Bond (1991)</ref>, we begin by first-differencing the model to eliminate all of the showspecific effects, u i . Then, we use lags (up to period t − 2) of the dependent and explanatory variables as instruments to perform a GMM estimation. These lags are valid instruments because they are uncorrelated with the difference in the error term but are correlated with the first differences of the endogenous variables. We are careful to avoid using too many lags as instruments, which Roodman ( <ref type="formula">2009</ref>) emphasized as a problem. 21 4.1.2. Information in Tweets, IMDB Reviews, and Huffington Post News.</p><p>Information Measures of Content Count, Sentiment, and n-grams PCA. We use three measures to extract content information from the unstructured text data, including Tweets, IMDB reviews, and Huffington Post news. Below, we use Tweets as an illustration.</p><p>One easy measure of information in Tweets is how many times a TV program is discussed by Twitter users. When more users mention a TV program in Tweets, they are likely to watch the program, and the social network to which they are connected is likely to  be influenced to watch the program. We call this the "Tweet volume model." <ref type="bibr">22</ref> A second measure of information is sentiment, where Tweets are classified by polarity, i.e., positive, neutral, and negative. Positive (negative) Tweets express favorable (unfavorable) feelings about a show, whereas neutral Tweets are neither positive nor negative. Hypothetically, positive Tweets are likely to generate positive feedback for a show, which increases TV ratings, whereas negative Tweets signal that consumers may stop watching the show because they are dissatisfied, which lowers future ratings. We construct two variables, t_pos = # of positive tweets and t_neg = # of negative tweets, and test their effect on ratings in the "Tweet sentiment model." We constructed <ref type="bibr">22</ref> Thanks to one of the reviewers, we also considered a "length model" where the number of words in the documents (Tweets/IMDB reviews and Huffington Post news articles) is used as the explanatory variable. The results are similar to the "volume model." Estimates are available on request. a sentiment analysis classifier using the LingPipe 23 linguistic analysis package, which provides a set of open-source Java libraries for natural language processing tasks. We use the DynamicLMClassifier, which is a language model classifier that accepts training events of categorized character sequences. Training is based on a multivariate estimator for the category distribution and dynamic language models for the per-category character sequence estimators. To obtain labeled training data for the classifier, we hired two independent coders who have expertise in TV shows and NFL games to manually label 4% of the Tweets for each show/NFL team. We further adjusted the classified Tweets using the list of positive and negative opinion words that are provided by <ref type="bibr" target="#b27">Hu and Liu (2004)</ref>.</p><p>The third measure more closely examines the variety of content in Tweets. We discover that some Tweets that are related to a program may express only users' opinions concerning the program rather than indicating an intent to watch the upcoming program. For example, consider the following two sample Tweets about the show "Breaking Bad": "I learnt how to cook meth like the guy in breaking bad"; and "Pumped for the season finale of Breaking Bad tonight. Only 4 hours and 37 minutes to go."</p><p>The first Tweet discusses a featured behavior of the character in the show. From this Tweet, we can infer that the Twitter user has watched Breaking Bad and is interested in its story. Nevertheless, the second Tweet directly states the future viewing behavior of the user. If there are many Tweets similar to the second Tweet before the show starts, the show's ratings are likely to be high. By contrast, variations of Tweets similar to the first one may have far less predictive power.</p><p>Based on this rationale, we construct a third measure of information to make inferences from the full content of the Tweets. More specifically, we use the counts of  each n-gram in the Tweet. An n-gram is a continuous sequence of n words in the text. For example, "big data" is a 2-gram, and "big" is a 1-gram. The sample Tweet "I love Pittsburgh Steelers" contains four 1-gram, three 2-grams, two 3-grams, and one 4-gram. Because phrases provide more interpretable information than a single word, we count n-grams rather than counting only words. We label this the "Tweet content model." Information Timeliness. Another decision concerns the length of time to collect TGWIH before a show begins. The shows are generally broadcast weekly. Consistent with what we find in §3, Tweets and Google searches also follow a weekly trend where more instances occur around (shortly before and after) the show. Intuitively, on the first or second day after the previous show, consumers are more likely to focus on the old show, whereas one or two days before the new show, consumers are more likely to discuss the new show. Following this intuition, we use TGWIH 24 or 48 hours before the new show starts as the input variable. It is interesting to compare the performance of the 24-hour measure with the 48-hour measure to evaluate the value of information over time.  of unstructured data. For example, we have approximately 1.8 billion Tweets, 433 billion Wikipedia pages, and 5.5 million Huffington Post news articles. Our data-cleaning process includes the following three major procedures: (1) selecting relevant Tweets/Wikipedia/Huffington Post pages, (2) counting n-grams, and (3) using the stochastic singular value decomposition (SSVD). The first two tasks can be performed in a streaming fashion (no out-of-memory problems) but are extremely time consuming on a single machine given the volume of data. The last task cannot be performed on a single machine because the size of the matrix does not fit in memory.</p><p>For example, the content information in Tweets is substantial. Even when using the 24-hour measure, we selected 6,894,624 Tweets related to the 30 TV series and 2,004,987 Tweets that are related to the NFL. These Tweets generate 28,044,202 and 9,028,774 n-grams that appear at least five times. Moreover, in our regression model for the TV shows, we hope to incorporate all of the content information. One way to do this is to use the frequency of all n-grams as features. This approach provides us significant feature space. Therefore, we must rely on dimension reduction techniques such as Principle Component Analysis (PCA) to make the task more tractable. However, performing PCA on a 2,339 × 28,044,202 25 matrix cannot be accomplished on a single machine because the matrix is too large to be stored in memory.</p><p>Our solution to this challenge is to use the SSVD method developed by <ref type="bibr" target="#b26">Halko (2012)</ref>. The key idea behind the SSVD is that when a data matrix is too large to be stored in memory, randomized sampling (the stochastic element of SSVD) allows the algorithms to work in a streaming environment to rapidly construct a low-rank approximation of the matrix. The SSVD parallelizes and distributes the randomized sampling and factorization stages using Hadoop MapReduce.</p><p>Next, we explain how we solve these challenges using cloud computing services.</p><p>Because the computing task cannot be managed by a single machine, programs have been developed to exploit the capacities of massively distributed computational resources. MapReduce is a good example. <ref type="bibr">26</ref> MapReduce is a programming model for processing large data sets using a parallel, distributed algorithm on a cluster. It is very powerful because it abstracts the complexities of parallel programming down to two operations, i.e., a map and a reduce. Both the map and reduce steps can be parallelized on a cluster of computers. Between the map and reduce, the process involves shuffling and sorting the keys so that all keyvalue pairs of the same key go to the same reduce for the next step. Thus, data communication occurs only between the map and the reduce. The details, such as distributed computation, file storage, communication, and data transfer, are left for the framework, such as Hadoop, 27 to manage.</p><p>We implement MapReduce using Amazon Elastic MapReduce (EMR). 28 Specifically, we use EMR for all three tasks, which are (1) selecting the relevant Tweets/Wikipedia pages, (2) performing the n-gram counts, and (3) conducting the SSVD. Table <ref type="table" target="#tab_1">10</ref> summarizes how we design the map and reduce jobs for each task.</p><p>Here we use the Tweet n-gram count task as an illustration. In the first procedure, "Map" filters the input data in key value pairs. When reading one Tweet as the input, if we find one n-gram in the Tweet, then we set the key as the n-gram and the value as 1. The second procedure, "Reduce," then summarizes the key-value pairs generated by the "Map" procedure. "Reduce" adds all of the values of the same key (n-gram) as the summary count of the n-gram.</p><p>When implementing the SSVD, we used Mahout, an open-source machine learning library that uses Hadoop MapReduce to implement scalable distributed algorithms. Essentially, it breaks down the singular value decomposition of a huge matrix into two basic operations, which are matrix multiplication and orthogonalization. Because both operations can rely on MapReduce to be performed in distributed clusters, our computational challenge is resolved. 4.1.4. Alternative Machine Learning Models. In addition to the cloud-based PCA model and the dynamic panel linear model that are explained above, we use alternative content extraction models and machine learning models for prediction comparison. In terms of content extraction, we compare the current cloud-based PCA model with the Latent Dirichlet Allocation (LDA) Topic Modeling approach <ref type="bibr" target="#b4">(Blei et al. 2003)</ref>. Moreover, we compare the dynamic panel linear model <ref type="bibr">27</ref> Hadoop is an open-source software framework that allows the distributed processing of large data sets across clusters of computers using simple programming models. It contains (1) the Hadoop Common package, which provides file system and OS level abstraction, (2) Yarn, a MapReduce engine, and (3) the Hadoop Distributed File System. These mechanisms automatically break down jobs into distributed tasks, schedule jobs, and tasks efficiently at participating cluster nodes, and tolerate data and task failures. <ref type="bibr">28</ref> EMR was created to enable researchers, businesses, and developers to easily and efficiently process vast amounts of data in a pay-as-yougo fashion. For more detailed information about implementation, see Online Appendix A4.      We also conduct the sentiment analysis and n-gram PCA for IMDB reviews and Huffington Post news. The results are similar to columns 5 and 6 in Table <ref type="table" target="#tab_1">15</ref>.</p><formula xml:id="formula_1">&lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 Finale −0 209 −0 039 −0 025 −0 076 −0 027 −0 027 0 009 0 004 −0 040 0 008 −0 046 0 013 −0 014 −0 029 6 94E−05 −0 043 Age −0 019 −0 135 −0 133 −0 215 −0 143 −0 143 −0 128 −0 016 −0 135 −0 128 −0 177 −0 136 −0 146 −0 179 −0 139 −0 153 0 909 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 0 001 0 003 &lt; 0 001 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 Liu,</formula><formula xml:id="formula_2">&lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 AR(1) −2 463 −2 806 −3 022 −2 083 −4 254 −4 237 −4 318 −4 369 0 014 0 005 0 003 0 005 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 AR(2)</formula><p>with the machine learning models that are widely used in other papers related to Twitter predictions, including Auto Regression with Exogenous Independent Variables (Autoregression X), Multilayered feedforward neural networks, and the Self-organizing Fuzzy Neural Network (SOFNN) models. For detailed information concerning these alternative models, see Online Appendix A1. We discuss the prediction performance of these competing models in §5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Specification Tests and Fit</head><p>5.1.1. Stationarity Tests. We apply the Augmented Dickey-Fuller (ADF) unit root test on all of the variables (Ratings, Twitter Tweets, Tweet sentiments, Tweet Principal Components, Google searches, Wikipedia views, IMDB reviews, and Huffington Post news). In all cases, the null hypothesis that the series is nonstationary is rejected.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.2.">IV Validity and Serial Correlation.</head><p>We use the Sargan Chi-squared statistic to test the validity of the instruments. Tables <ref type="table" target="#tab_1">15 to 17</ref> report that all of the over-identifying test statistics are insignificant. Therefore, we cannot reject the joint validity of the instrument sets. In addition, we use the method developed by <ref type="bibr" target="#b3">Arellano and Bond (1991)</ref> to determine whether the errors are serially correlated (the AR(1) and AR(2) test scores in Tables <ref type="table" target="#tab_1">15-17</ref>). There is no evidence of first-order serial correlation. 29</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.3.">Number of Lags.</head><p>To determine the number of lags (J in Equation ( <ref type="formula">1</ref>)) of the dependent variable in our model, we use the MMSC-BIC statistics developed by <ref type="bibr" target="#b1">Andrews and Lu (2001)</ref>. Comparisons show that including only the first lag yields the lowest MMSC-BIC. Therefore, in Tables <ref type="table" target="#tab_1">15 to 17</ref>, we report the results with only the first lag included.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Main Findings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.1.">People Tweet About What They Are Going to Do.</head><p>The n-grams. In Table <ref type="table" target="#tab_1">11</ref>, we list the n-grams with the 1st, 2nd, and 3rd highest frequencies for each of the five TV series and the NFL. Across all five TV series, the most mentioned topic is the name of the program, such as Breaking Bad. Moreover, "watch" and "tonight" appear with very high frequency. In fact, we find many Tweets that discuss the consumer's intention to watch the show, for example, "I can't wait to watch Breaking Bad tonight." The content in this type of Tweet is a useful predictor for the ratings of      the program. Not surprisingly, we also find that the celebrities on the TV programs are another salient topic, such as Charlie Sheen in Two and a Half Men. Twitter users express their preference for a celebrity and also re-Tweet what the celebrity says. For example, many people Tweeted that "Two and A Half Men is never the same without Charlie Sheen" after Sheen was replaced on the show in 2011. Fans of The Big Bang Theory often Tweeted phrases such as "Bazinga! Love Sheldon," where "Sheldon" is a main character on the show, and "Bazinga" is a phrase that he frequently utters.</p><formula xml:id="formula_3">&lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 0 001 &lt; 0 001 &lt; 0 001 Liu,</formula><formula xml:id="formula_4">&lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 AR(1)</formula><p>Sentiment. We find several interesting phenomena in the sentiment analysis of the Tweets (Table <ref type="table" target="#tab_1">12</ref>). First, the majority of the Tweets are neutral and document consumers' mundane lives, such as their actions and plans. Second, consistent with the previous findings of <ref type="bibr" target="#b22">Godes and Mayzlin (2004)</ref>, consumers are much more positive than negative about the TV shows that they watch. On average, there are 7.7 times more positive Tweets than negative. However, this ratio is relatively lower for NFL games than for TV series.</p><p>One way to explain this result is self-selection bias. Consumers who Tweet about TV shows are those who enjoy the shows most. Thus, they are more positive than the entire population. However, the theory of cognitive dissonance indicates that people tend to justify their own mistakes. In our context, even if a consumer dislikes a show that she watched, she may be unwilling to admit that she made a mistake in choosing the show by broadcasting it on Twitter. These properties of the sentiment analysis of Tweets prevent this aspect from predicting TV ratings.</p><p>PCA. In the PCA, we follow the standard approach and use a "scree plot" <ref type="bibr" target="#b8">(Cattell 1966)</ref> to decide how many principal components to retain. If the largest few eigenvalues in the covariance matrix dominate in magnitude, then the scree plot will exhibit an "elbow." We apply this "elbow" rule and select four principal components from the 28,044,202 n-gram features based on Figure <ref type="figure">6</ref>.</p><p>It is interesting to examine the matrix of eigenvectors (loadings) to observe which n-grams contribute the most to the chosen principal components. Table <ref type="table" target="#tab_1">13</ref> shows the three n-grams with the largest loadings on each of the first four principal components (PC).</p><p>Consistent with our findings from the n-gram count, words and phrases such as "tonight," "can't wait," and "watch" have the largest projection on the first PC. Location-and device-related words such as "home" and "tv" contribute most to the second PC. The third PC captures consumers' attention to the "premiere" of the "season;" the fourth PC contains positive emotions such as "excited," "love," and another prominent topic, "finale." Overall, the first four PCs cover consumers' intention to watch the shows. Later, in the regression        results analysis, we confirm that this information summary is indicative of users' upcoming consumption (i.e., watching the show).</p><formula xml:id="formula_5">&lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001</formula><formula xml:id="formula_6">+ G + LR + T + G + LR + T + W + H + W + H + G + W + LR T G W H D LR + T + D LR + G + D T + Sen LR + T + Sen Topic LR + D + Topic D + Topic PC LR + D + PC D +</formula><formula xml:id="formula_7">&lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 &lt; 0 001 AR(1) −1 972 −2 235 −2 051 −1 972 −2 001 −1 963</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.2.">Twitter Content Is a Lead</head><p>Indicator of TV Ratings. In Table <ref type="table" target="#tab_1">14</ref>, we first list the variables included in the regression.</p><p>The results show that the lagged rating itself explains 75.1% of the variation in the current ratings (column 1 of Table <ref type="table" target="#tab_1">15</ref>). By contrast, the sheer volume of Tweets 24 hours before the show accounts for only 6.5% of the variation (column 2). Similarly, Google searches, Wikipedia views, IMDB review count, and Huffington Post news articles in the previous 24 hours explain a variation of only 4.9% (column 3), 12.1% (column 4), 4.8% (column 5), and 4.8% (column 6), respectively. Moreover, when we combine the lagged rating and Tweet counts (column 7) or Google searches (column 8), the R-squared increases little from the R-squared that includes only the lagged ratings (column 1). This result implies that the pure "volume model" has little explanatory power. Sentiments such as the proportion of positive or negative Tweets are not much better than volume in predicting TV ratings. As shown in Models 9 and 10 in Table <ref type="table" target="#tab_1">15</ref>, with Tweet volume, the effects of positive and negative Tweets are not statistically significant. We also experiment with other functional forms of the sentiment variables, such as quadratic terms and exponential terms; the results are  qualitatively similar to the linear form. Therefore, the "sentiment model" is also not useful for predicting TV ratings. However, the first four principal components from the Tweet n-gram features produce an R-squared of 0.756 (column 14), which is comparable with the R-squared of the model with only the lagged rating included. A better model fit is found when we combine PCs with the lagged rating (column 15) and both the lagged rating and Google searches (column 16). This result shows that the "Tweet content model" outperforms both the "Tweet volume model" and the "Tweet sentiment model" in predicting TV series ratings.</p><p>Similarly, when we use the LDA <ref type="bibr" target="#b4">(Blei et al. 2003)</ref> technique to extract the content information, we obtain an R-squared of 0.620 (column 11), which is close to the result that we obtain in the n-gram PCA case. Adding the lagged rating and other online platform information improves the R2 (columns 12 and 13). However, n-gram PCA performs better overall than LDA (we confirm this result in §5.3).</p><p>We also find marginal improvement in the R-squared by adding Google searches, Wikipedia views, IMDB reviews, and Huffington Post news. This result suggests that the information derived from Google searches (or Wikipedia views, IMDB reviews, and Huffington Post news) and Twitter posts may be mostly substitutes.</p><p>Table <ref type="table" target="#tab_1">15</ref> considers TGWIH measures 24 hours before the new TV shows start. Will it help to involve more information by extending the data collection period to 48 hours? Comparing the R-squareds from Table <ref type="table" target="#tab_1">16</ref> with the R-squareds from Table <ref type="table" target="#tab_1">15</ref>, we find that adding more information in TGWIH increases the model fit, but the increments are very small. For example, if we compare column 8 in Table <ref type="table" target="#tab_1">16</ref> with column 8 in Table <ref type="table" target="#tab_1">15</ref>, the R-squared improves by less than 2%. This result implies that consumer buzz on online platforms about TV shows is highly transient. Information value rapidly deteriorates with time. Most of the other findings from Table <ref type="table" target="#tab_1">15</ref> are replicated in Table <ref type="table" target="#tab_1">16</ref>. As to the NFL (Table <ref type="table" target="#tab_1">17</ref>), we find that the lagged rating is not a good predictor of the current rating (R2 = 0 248). The reason for this result is likely because the size of the fan base changes because the teams that play change every week. For example, if last week's SNF game was between the Dallas Cowboys and the Pittsburgh Steelers, the ratings would be much higher than this week's SNF game between the Jacksonville Jaguars and the Tennessee Titans.</p><p>Instead, when we use the number of Tweets related to two teams 24 hours before the game begins (Table <ref type="table" target="#tab_1">17</ref>, column 2), the R2 becomes 0.34, which is much higher than when we use the lagged rating as the only explanatory variable (column 1). Surprisingly, the number of Google searches, Wikipedia views, and Huffington Post news articles related to the two teams 24 hours before the game starts can explain variations in the rating of only 4%, 6%, and 6%, respectively; the estimated coefficients are not significant.</p><p>To resolve the problem of changing teams, we add team dummies (home and away separately) in the sixth specification of the model. The resulting R2 of 0.69 supports our conjecture that the size of the fan base is an important determinant of ratings. In columns 7 and 8, we combine the lagged rating with the team dummies and Tweets or Google searches. Together, this combination can explain approximately 78% of the variation in the ratings.</p><p>We confirm that the content analysis (using n-gram PCs or topics as features) of Tweets is a powerful predictor of TV ratings. Most strikingly, the good model fits remain even after we remove the team dummies. This is shown in columns 11, 14, and 17 of Table <ref type="table" target="#tab_1">17</ref>. Topics and PCs alone can explain variations in the ratings of 82% and 85%, respectively. If we combine all of the information, including the lagged rating, Tweets, Google searches, Wikipedia views, Huffington Post news articles, and PCs, almost 90% of the variation can be explained.</p><p>This result indicates that team-specific Tweets that capture consumers' intention to watch the games are the lead indicators of actual future consumption. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Forecasting</head><p>After the model is calibrated, we test how well it can be used to forecast TV ratings. For this, we use Nielsen ratings data from September to November 2013 as the test sample. These data include 411 episodes of the TV series and 39 NFL games. To test the model's performance, we use two measures, i.e., (1) the mean absolute percentage error (MAPE) and (2) the mean squared error (MSE).</p><p>Largely consistent with the results in Tables <ref type="table" target="#tab_1">15 and 16</ref>, Table <ref type="table" target="#tab_1">18</ref> demonstrates that without content analysis (Models 2 to 6), the mere volume of TGWIH performs much worse in predicting ratings than using content analysis (Models 11 to 16).</p><p>Interestingly, we find that the content information from Tweets can still adequately forecast ratings for obscure titles provided that the predictive power of the lagged rating is greatly decreased (Table <ref type="table" target="#tab_1">19</ref>). Specifically, for the five unpopular shows that did not last more than two seasons, 31 including Allen Gregory, Charlie's Angels, Hellcats, Harry's Law, and Gary Unmarried, we found that the prediction MAPE for the model that includes only the lagged ratings is significantly larger than the prediction MAPE for the other popular shows. However, the prediction MAPE for the model that includes Twitter content information is not much different from the prediction MAPE of the popular shows.</p><p>Similarly, Models 11 through 17 use content-selected Tweets and have the smallest prediction errors for the NFL sample (Table <ref type="table">20</ref>).</p><p>Next, we show the comparative advantage of our model. As shown in Table <ref type="table" target="#tab_1">21</ref>, our Dynamic Panel Linear Model with Cloud PCA outperforms the alternative models (including Auto Regression with Exogenous Independent Variables (Autoregression X), Multilayered feedforward neural networks, and the SOFNN models) in terms of out-of-sample prediction accuracy.</p><p>Moreover, cloud-based PCA is much faster than LDA. As shown in Table <ref type="table" target="#tab_31">22</ref>, cloud-based PCA takes approximately six minutes for the TV series task, whereas LDA takes approximately 37 minutes. This result shows that cloud computing can make computation more efficient, which can help advertisers predict demand faster, potentially in real time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Conclusions</head><p>Our paper shows that easily accessible online information such as Twitter Tweets, Google Trends, Wikipedia views, IMDB reviews, and Huffington Post news can be useful for marketers to accurately predict consumer demand for TV shows. We demonstrate the power of using machine learning, text mining, and cloud computing techniques to process large-scale unstructured data to conduct a structured econometric analysis. We conclude that information from online platforms, if carefully extracted and sorted, can provide a timely representation of consumer intentions. These results have important implications for forecasting purchases/consumption that should be of great interest to all firms. We acknowledge that the industry is leading marketing academia in conducting cloud analytics in the context of TV viewing. <ref type="bibr">32</ref> For example, Netflix is analyzing petabytes of data to recommend TV shows to consumers, optimize playback quality, and identify poorly translated subtitles. <ref type="bibr">33</ref> The cloud tools used by Netflix go beyond the simple MapReduce programming model and include Hive, Pig, Parquet, Presto, Spark, etc. <ref type="bibr">34</ref> Future marketing research that requires large-scale data analytics may consider adopting these tools.</p><p>Our paper has certain limitations. First, the real mechanism between online behavior and offline consumption is not revealed. Our study is not based on a well grounded theory that explains the entire path of a consumer's consumption experience. Thus, caution should be exercised in interpreting the results. Second, although Twitter has a wide user base, it is relatively more appealing to the young and urban demographic group, which is different from the general U.S. population. For example, our data show a discrepancy in the rankings of a TV series based on the volume of Tweets and ratings. NCIS has the highest average ratings but the lowest number of Tweets. This result is likely because of a mismatch between the Twitter user population and the fan base for the show. This limitation constrains Twitter's predictive power for consumption that is targeted toward other demographics. Finally, we predict the most popular TV shows, which have relatively stable ratings patterns. Predicting low-rated shows or newly debuted shows may pose significant additional challenges.</p><p>Our paper is only a first step in using consumers' online activities to predict offline consumption. Future research may consider gathering information from more consumer access points to predict demand and for other noninformation goods. More heterogeneous or location-specific analyses can also be performed to predict demand for certain demographics or in a specific local market. Methodologically, other text mining methods could be developed to extract the most useful information for predictions. Another promising</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure</head><label></label><figDesc>Figure 1(a) (Color online) Nielsen Ratings-Five Popular TV Series</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure2(Color online) Nielsen Ratings-NFL</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 3 (</head><label>3</label><figDesc>Figure 3 (Color online) Google Trend Plot</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>24    </figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>4.1.3. Challenges in Processing Enormous Unstructured Data-Cloud Computing Techniques. As shown in §3, our analysis involves an enormous amount Marketing Science 35(3), pp. 363-388, © 2016 INFORMS</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_13"><head></head><label></label><figDesc>, and Srinivasan: A Structured Analysis of Unstructured Big Data</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>Srinivasan: A Structured Analysis of Unstructured Big Data 364 Marketing Science 35(3), pp. 363-388, © 2016 INFORMS</figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 1</head><label>1</label><figDesc>Overview of Literature on UGC</figDesc><table><row><cell>Text mining tools</cell><cell></cell></row><row><cell>Data size</cell><cell></cell></row><row><cell>Text data</cell><cell></cell></row><row><cell>Outcome measures</cell><cell></cell></row><row><cell>Effect</cell><cell></cell></row><row><cell>Measure</cell><cell></cell></row><row><cell>UGC</cell><cell></cell></row><row><cell>Product</cell><cell></cell></row><row><cell>Year</cell><cell></cell></row><row><cell>Author</cell><cell>Godes and Mayzlin</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 3</head><label>3</label><figDesc></figDesc><table><row><cell cols="2">NFL Primetime Games (2010-2012)</cell><cell></cell><cell></cell></row><row><cell></cell><cell>2010</cell><cell>2011</cell><cell>2012</cell></row><row><cell>Sunday Night Football</cell><cell>18</cell><cell>18</cell><cell>19</cell></row><row><cell>Thursday Night Football</cell><cell>8</cell><cell>8</cell><cell>13</cell></row><row><cell>Monday Night Football</cell><cell>17</cell><cell>17</cell><cell>17</cell></row><row><cell cols="2">Data source. http://www.nfl.com/schedules.</cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 4 Number</head><label>4</label><figDesc></figDesc><table><row><cell></cell><cell>2008</cell><cell></cell><cell>2009</cell><cell></cell><cell>2010</cell><cell></cell><cell>2011</cell><cell></cell><cell>2012</cell><cell></cell><cell>2013</cell><cell></cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>GB)</cell></row><row><cell>1</cell><cell></cell><cell></cell><cell>22 17</cell><cell>3 67</cell><cell>121 02</cell><cell>32 56</cell><cell>292 99</cell><cell>114 34</cell><cell>762 28</cell><cell>316 53</cell><cell>1 282 95</cell><cell>577 33</cell></row><row><cell>2</cell><cell></cell><cell></cell><cell>20 65</cell><cell>3 34</cell><cell>126 70</cell><cell>35 58</cell><cell>300 93</cell><cell>117 83</cell><cell>768 13</cell><cell>319 75</cell><cell>1 170 41</cell><cell>524 69</cell></row><row><cell>3</cell><cell></cell><cell></cell><cell>20 89</cell><cell>3 30</cell><cell>163 07</cell><cell>47 48</cell><cell>369 83</cell><cell>147 29</cell><cell>860 95</cell><cell>361 32</cell><cell>1 286 31</cell><cell>600 46</cell></row><row><cell>4</cell><cell></cell><cell></cell><cell>23 19</cell><cell>3 39</cell><cell>181 11</cell><cell>54 03</cell><cell>386 54</cell><cell>151 37</cell><cell>893 34</cell><cell>380 43</cell><cell>1 267 80</cell><cell>579 93</cell></row><row><cell>5</cell><cell></cell><cell></cell><cell>9 21</cell><cell>1 76</cell><cell>210 18</cell><cell>63 37</cell><cell>429 47</cell><cell>167 58</cell><cell>949 08</cell><cell>407 89</cell><cell>1 342 71</cell><cell>615 73</cell></row><row><cell>6</cell><cell></cell><cell></cell><cell>14 26</cell><cell>3 41</cell><cell>244 58</cell><cell>74 56</cell><cell>450 20</cell><cell>177 58</cell><cell>1 004 92</cell><cell>434 91</cell><cell>1 321 88</cell><cell>607 61</cell></row><row><cell>7</cell><cell></cell><cell></cell><cell>28 17</cell><cell>6 85</cell><cell>168 61</cell><cell>52 39</cell><cell>508 13</cell><cell>207 34</cell><cell>1 095 50</cell><cell>478 38</cell><cell>1 409 66</cell><cell>650 34</cell></row><row><cell>8</cell><cell></cell><cell></cell><cell>50 96</cell><cell>12 61</cell><cell>97 81</cell><cell>31 74</cell><cell>537 77</cell><cell>224 20</cell><cell>1 120 58</cell><cell>493 33</cell><cell>1 418 14</cell><cell>654 46</cell></row><row><cell>9</cell><cell>9 45</cell><cell>1.49</cell><cell>65 55</cell><cell>16 34</cell><cell>198 62</cell><cell>69 23</cell><cell>524 76</cell><cell>219 77</cell><cell>1 050 63</cell><cell>464 29</cell><cell>1 287 45</cell><cell>592 95</cell></row><row><cell>10</cell><cell>16 17</cell><cell>2.55</cell><cell>73 56</cell><cell>18 49</cell><cell>216 35</cell><cell>80 60</cell><cell>570 28</cell><cell>241 26</cell><cell>1 111 40</cell><cell>506 26</cell><cell>1 299 44</cell><cell>601 49</cell></row><row><cell>11</cell><cell>21 06</cell><cell>3.40</cell><cell>82 91</cell><cell>20 99</cell><cell>225 63</cell><cell>88 90</cell><cell>612 91</cell><cell>256 41</cell><cell>1 131 26</cell><cell>519 72</cell><cell></cell><cell></cell></row><row><cell>12</cell><cell>20 65</cell><cell>3.38</cell><cell>93 37</cell><cell>24 27</cell><cell>263 78</cell><cell>101 99</cell><cell>685 82</cell><cell>284 17</cell><cell>1 220 59</cell><cell>555 67</cell><cell></cell><cell></cell></row></table><note>of Tweets and File Size by Month (2008-2013) Tweets (Mil) Size (GB) Tweets (Mil) Size (GB) Tweets (Mil) Size (GB) Tweets (Mil) Size (GB) Tweets (Mil) Size (GB) Tweets (Mil) Size (</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head>Table 5</head><label>5</label><figDesc>Tweet Frequency, Pre-During-Post</figDesc><table><row><cell>Show</cell><cell></cell><cell cols="2">Frequency</cell><cell></cell><cell></cell><cell cols="2">Frequency/Episode</cell><cell></cell><cell></cell><cell>Frequency/Hour</cell><cell></cell></row><row><cell></cell><cell>Pre a</cell><cell>During</cell><cell>Post</cell><cell>Total</cell><cell>Pre</cell><cell>During</cell><cell>Post</cell><cell>Total</cell><cell>Pre</cell><cell cols="2">During Post Total</cell></row><row><cell>2 Broke Girls</cell><cell>7 258</cell><cell>3 071</cell><cell>30 861</cell><cell>41 189</cell><cell>100 8</cell><cell>42 6</cell><cell>428 6</cell><cell>572 1</cell><cell>4 2</cell><cell>85 3 3 0</cell><cell>3 4</cell></row><row><cell>30 Rock</cell><cell>114 258</cell><cell>31 058</cell><cell>423 803</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head></head><label></label><figDesc>Pre" includes all Tweets 24 hours before the show starts. "During" includes Tweets only during the show. "Post" includes Tweets between the end of one episode and the start of the next.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1</cell></row><row><cell>Cougar Town</cell><cell>31 068</cell><cell>7 411</cell><cell>99 986</cell><cell>138 465</cell><cell>349 1</cell><cell>83 3</cell><cell>1 123 4</cell><cell>1 555 8</cell><cell>14 5</cell><cell>166 5 7 8</cell><cell>9 3</cell></row><row><cell>Criminal Minds</cell><cell>97 349</cell><cell>56 446</cell><cell>809 187</cell><cell>962 982</cell><cell>804 5</cell><cell>466 5</cell><cell>6 687 5</cell><cell>7 958 5</cell><cell>33 5</cell><cell>466 5 46 8</cell><cell>47 4</cell></row><row><cell>Desperate Housewives</cell><cell>58 109</cell><cell>29 285</cell><cell>239 505</cell><cell>326 899</cell><cell>575 3</cell><cell>289 9</cell><cell>2 371 3</cell><cell>3 236 6</cell><cell>24 0</cell><cell>289 9 16 6</cell><cell>19 3</cell></row><row><cell>Gary Unmarried</cell><cell>532</cell><cell>67</cell><cell>1 068</cell><cell>1 667</cell><cell>14 4</cell><cell>1 8</cell><cell>28 9</cell><cell>45 0</cell><cell>0 6</cell><cell>3 6 0 2</cell><cell>0 3</cell></row><row><cell>Glee</cell><cell>356 269</cell><cell>109 596</cell><cell>1 708 721</cell><cell cols="8">2 174 587 3 298 8 1 014 8 15 821 5 20 135 1 137 4 1 014 8 110 6 119 9</cell></row><row><cell>Gossip Girl</cell><cell>220 750</cell><cell>70 024</cell><cell>982 357</cell><cell cols="2">1 273 131 2 006 8</cell><cell>636 6</cell><cell cols="2">8 930 5 11 573 9</cell><cell>83 6</cell><cell>636 6 62 5</cell><cell>68 9</cell></row><row><cell>Grey's Anatomy</cell><cell>482 976</cell><cell>870 526</cell><cell>1 067 363</cell><cell cols="3">2 420 866 4 093 0 7 377 3</cell><cell cols="5">9 045 4 20 515 8 170 5 7 377 3 63 3 122 1</cell></row><row><cell>Harry's Law</cell><cell>4 493</cell><cell>2 841</cell><cell>11 994</cell><cell>19 328</cell><cell>132 2</cell><cell>83 6</cell><cell>352 8</cell><cell>568 5</cell><cell>5 5</cell><cell>83 6 2 5</cell><cell>3 4</cell></row><row><cell>Hellcats</cell><cell>10 994</cell><cell>4 985</cell><cell>40 707</cell><cell>56 686</cell><cell>499 7</cell><cell>226 6</cell><cell>1 850 3</cell><cell>2 576 6</cell><cell>20 8</cell><cell>226 6 12 9</cell><cell>15 3</cell></row><row><cell>How I Met Your Mother</cell><cell>101 727</cell><cell>11 224</cell><cell>580 399</cell><cell>693 350</cell><cell>847 7</cell><cell>93 5</cell><cell>4 836 7</cell><cell>5 777 9</cell><cell>35 3</cell><cell>187 1 33 7</cell><cell>34 4</cell></row><row><cell>Lie to Me</cell><cell>2 994</cell><cell>680</cell><cell>14 934</cell><cell>18 608</cell><cell>62 4</cell><cell>14 2</cell><cell>311 1</cell><cell>387 7</cell><cell>2 6</cell><cell>14 2 2 2</cell><cell>2 3</cell></row><row><cell>Mike and Molly</cell><cell>1 589</cell><cell>795</cell><cell>4 070</cell><cell>6 454</cell><cell>17 3</cell><cell>8 6</cell><cell>44 2</cell><cell>70 1</cell><cell>0 7</cell><cell>17 3 0 3</cell><cell>0 4</cell></row><row><cell>NCIS</cell><cell>223 767</cell><cell>311 939</cell><cell>452 242</cell><cell cols="3">987 933 1 849 3 2 577 9</cell><cell>3 737 5</cell><cell>8 164 8</cell><cell cols="2">77 1 2 577 9 26 1</cell><cell>48 6</cell></row><row><cell>Nikita</cell><cell>49 174</cell><cell>8 495</cell><cell>588 896</cell><cell>646 564</cell><cell>673 6</cell><cell>116 4</cell><cell>8 067 1</cell><cell>8 857 0</cell><cell>28 1</cell><cell>116 4 56 4</cell><cell>52 7</cell></row><row><cell>Parks and Recreation</cell><cell>30 637</cell><cell>10 666</cell><cell>97 953</cell><cell>139 256</cell><cell>278 5</cell><cell>97 0</cell><cell>890 5</cell><cell>1 266 0</cell><cell>11 6</cell><cell>193 9 6 2</cell><cell>7 5</cell></row><row><cell>Private Practice</cell><cell>41 628</cell><cell>27 003</cell><cell>133 206</cell><cell>201 836</cell><cell>408 1</cell><cell>264 7</cell><cell>1 305 9</cell><cell>1 978 8</cell><cell>17 0</cell><cell>264 7 9 1</cell><cell>11 8</cell></row><row><cell>Rules of Engagement</cell><cell>4 457</cell><cell>1 235</cell><cell>55 764</cell><cell>61 456</cell><cell>47 9</cell><cell>13 3</cell><cell>599 6</cell><cell>660 8</cell><cell>2 0</cell><cell>26 6 4 2</cell><cell>3 9</cell></row><row><cell>Shark Tank</cell><cell>36 527</cell><cell>14 428</cell><cell>114 773</cell><cell>165 728</cell><cell>392 8</cell><cell>155 1</cell><cell>1 234 1</cell><cell>1 782 0</cell><cell>16 4</cell><cell>155 1 8 6</cell><cell>10 6</cell></row><row><cell>Smallville</cell><cell>23 383</cell><cell>7 551</cell><cell>108 993</cell><cell>139 927</cell><cell>365 4</cell><cell>118 0</cell><cell>1 703 0</cell><cell>2 186 4</cell><cell>15 2</cell><cell>118 0 11 9</cell><cell>13 0</cell></row><row><cell>The Big Bang Theory</cell><cell>556 636</cell><cell>327 452</cell><cell>1 607 036</cell><cell cols="8">2 491 124 4 717 3 2 774 9 13 618 9 21 111 2 196 6 5 550 0 94 9 125 7</cell></row><row><cell>The Vampire Diaries</cell><cell>148 009</cell><cell>42 410</cell><cell>562 743</cell><cell cols="2">753 162 1 333 4</cell><cell>382 1</cell><cell>5 069 8</cell><cell>6 785 2</cell><cell>55 6</cell><cell>382 1 35 5</cell><cell>40 4</cell></row><row><cell>Two and a Half Men</cell><cell>156 894</cell><cell>99 753</cell><cell>471 712</cell><cell cols="2">728 359 1 439 4</cell><cell>915 2</cell><cell>4 327 6</cell><cell>6 682 2</cell><cell cols="2">59 9 1 830 3 30 2</cell><cell>39 8</cell></row><row><cell>Total</cell><cell cols="11">3 454 392 2 797 695 12 278 601 18 530 688 39 939 9 35 372 7 135 648 9 210 961 7 1 664 1 39 878 8 948 1 255 8</cell></row></table><note>a "</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head>Table 6</head><label>6</label><figDesc>Google over time. The numbers on the graph do not represent absolute search volume numbers because the data are normalized and presented on a scale from 0-100. Each point on the graph is divided by the highest point, or 100. For example, on September 21, 2013, the number 35 is relative to the highest point, 100, on September 27.</figDesc><table><row><cell></cell><cell></cell><cell></cell><cell>that are conducted on</cell></row><row><cell cols="2">Tweet Frequency-NFL</cell><cell></cell><cell></cell></row><row><cell>Time</cell><cell>Frequency</cell><cell>Freq/Game</cell><cell>Freq/Hour</cell></row><row><cell>Pre game</cell><cell>1 520 044</cell><cell>3 015 96</cell><cell>125 67</cell></row><row><cell>During game</cell><cell>2 532 638</cell><cell>5 045 10</cell><cell>1 261 27</cell></row><row><cell>Post game</cell><cell>5 402 517</cell><cell>10 783 47</cell><cell>77 02</cell></row><row><cell>Total</cell><cell>9 455 200</cell><cell>18 760 32</cell><cell>111 67</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 7</head><label>7</label><figDesc>Tweet Summary Statistics-32 NFL Teams</figDesc><table><row><cell>Variable</cell><cell>Mean</cell><cell>Median</cell><cell>Std dev</cell><cell>Maximum</cell><cell>Minimum</cell><cell>N</cell></row><row><cell>New_York_Jets</cell><cell>487 15</cell><cell>299</cell><cell>1 062 92</cell><cell>21 350</cell><cell>1</cell><cell>1</cell></row><row><cell>Dallas_Cowboys</cell><cell>412 18</cell><cell>123</cell><cell>1 325 90</cell><cell>20 595</cell><cell>0</cell><cell>1</cell></row><row><cell>New_England_Patriots</cell><cell>335 86</cell><cell>105</cell><cell>1 449 39</cell><cell>41 909</cell><cell>0</cell><cell>1</cell></row><row><cell>Pittsburgh_Steelers</cell><cell>323 05</cell><cell>88</cell><cell>1 521 75</cell><cell>40 416</cell><cell>0</cell><cell>1</cell></row><row><cell>New_Orleans_Saints</cell><cell>304 54</cell><cell>123</cell><cell>1 632 64</cell><cell>51 592</cell><cell>0</cell><cell>1</cell></row><row><cell>Baltimore_Ravens</cell><cell>299 67</cell><cell>70</cell><cell>1 621 66</cell><cell>47 427</cell><cell>0</cell><cell>1</cell></row><row><cell>Philadelphia_Eagles</cell><cell>282 29</cell><cell>105</cell><cell>762 12</cell><cell>8 558</cell><cell>0</cell><cell>1</cell></row><row><cell>Green_Bay_Packers</cell><cell>277 72</cell><cell>70</cell><cell>1 344 21</cell><cell>39 485</cell><cell>0</cell><cell>1</cell></row><row><cell>Chicago_Bears</cell><cell>273 73</cell><cell>123</cell><cell>779 28</cell><cell>18 011</cell><cell>0</cell><cell>1</cell></row><row><cell>San_Francisco_49ers</cell><cell>236 90</cell><cell>70</cell><cell>1 181 30</cell><cell>30 312</cell><cell>0</cell><cell>1</cell></row><row><cell>New_York_Giants</cell><cell>189 97</cell><cell>70</cell><cell>687 34</cell><cell>19 101</cell><cell>0</cell><cell>1</cell></row><row><cell>Washington_Redskins</cell><cell>171 14</cell><cell>70</cell><cell>454 71</cell><cell>5 412</cell><cell>0</cell><cell>1</cell></row><row><cell>Indianapolis_Colts</cell><cell>163 26</cell><cell>35</cell><cell>894 73</cell><cell>25 655</cell><cell>0</cell><cell>1</cell></row><row><cell>Detroit_Lions</cell><cell>161 95</cell><cell>70</cell><cell>440 27</cell><cell>6 467</cell><cell>0</cell><cell>1</cell></row><row><cell>Oakland_Raiders</cell><cell>151 34</cell><cell>70</cell><cell>308 94</cell><cell>3 251</cell><cell>0</cell><cell>1</cell></row><row><cell>Denver_Broncos</cell><cell>143 24</cell><cell>53</cell><cell>463 74</cell><cell>9 120</cell><cell>0</cell><cell>1</cell></row><row><cell>Minnesota_Vikings</cell><cell>131 97</cell><cell>53</cell><cell>547 91</cell><cell>16 043</cell><cell>0</cell><cell>1</cell></row><row><cell>Atlanta_Falcons</cell><cell>128 68</cell><cell>35</cell><cell>509 82</cell><cell>8 628</cell><cell>0</cell><cell>1</cell></row><row><cell>Arizona_Cardinals</cell><cell>127 62</cell><cell>53</cell><cell>364 66</cell><cell>9 014</cell><cell>0</cell><cell>1</cell></row><row><cell>Cleveland_Browns</cell><cell>125 95</cell><cell>70</cell><cell>211 57</cell><cell>2 407</cell><cell>0</cell><cell>1</cell></row><row><cell>Houston_Texans</cell><cell>123 80</cell><cell>35</cell><cell>435 19</cell><cell>6 414</cell><cell>0</cell><cell>1</cell></row><row><cell>Buffalo_Bills</cell><cell>116 78</cell><cell>53</cell><cell>228 05</cell><cell>3 497</cell><cell>0</cell><cell>1</cell></row><row><cell>Kansas_City_Chiefs</cell><cell>101 52</cell><cell>35</cell><cell>250 94</cell><cell>3 901</cell><cell>0</cell><cell>1</cell></row><row><cell>Miami_Dolphins</cell><cell>93 66</cell><cell>53</cell><cell>179 54</cell><cell>2 179</cell><cell>0</cell><cell>1</cell></row><row><cell>Seattle_Seahawks</cell><cell>87 84</cell><cell>35</cell><cell>344 30</cell><cell>8 224</cell><cell>0</cell><cell>1</cell></row><row><cell>Carolina_Panthers</cell><cell>81 94</cell><cell>53</cell><cell>143 11</cell><cell>1 423</cell><cell>0</cell><cell>1</cell></row><row><cell>Cincinnati_Bengals</cell><cell>81 85</cell><cell>35</cell><cell>240 20</cell><cell>4 393</cell><cell>0</cell><cell>1</cell></row><row><cell>St__Louis_Rams</cell><cell>71 84</cell><cell>35</cell><cell>115 69</cell><cell>1 494</cell><cell>0</cell><cell>1</cell></row><row><cell>Tampa_Bay_Buccaneers</cell><cell>70 77</cell><cell>35</cell><cell>104 68</cell><cell>1 125</cell><cell>0</cell><cell>1</cell></row><row><cell>San_Diego_Chargers</cell><cell>68 10</cell><cell>18</cell><cell>215 54</cell><cell>5 711</cell><cell>0</cell><cell>1</cell></row><row><cell>Tennessee_Titans</cell><cell>66 09</cell><cell>35</cell><cell>136 66</cell><cell>1 476</cell><cell>0</cell><cell>1</cell></row><row><cell>Jacksonville_Jaguars</cell><cell>63 89</cell><cell>35</cell><cell>106 47</cell><cell>1 037</cell><cell>0</cell><cell>1</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 9</head><label>9</label><figDesc>Counts for Wikipedia Views, Edits, IMDB Reviews, and Huffington Post Articles The site enables registered users to submit new material and request edits to existing entries.19  The fourth column in Table9describes the number of reviews for each TV series. By contrast to Tweets and Wikipedia views, there are a limited number of IMDB reviews. The show with the most reviews, Breaking Bad, has only 688 posts over more than six years.3.8. The Huffington Post NewsConsumers may also be driven to watch TV series by news articles. Therefore, we collect data from The Huffington Post, a site that offers news, blogs, and The site has extensive traffic and ranks 26th on Alexa as of January 29, 2015. The last column in Table9lists the number of news articles related to each TV series and NFL game. Interestingly, Google Trends, Wikipedia views, IMDB reviews, and Huffington Post news using the example of the fourth season of Breaking Bad in 2011. During that season, there was a new episode every week. Tweets spiked around every show day, 20 and a trail appeared</figDesc><table><row><cell></cell><cell>Wikipedia</cell><cell cols="3">Wikipedia IMDB Huffington</cell></row><row><cell>Show</cell><cell>views</cell><cell>edits</cell><cell cols="2">reviews Post news</cell></row><row><cell>2 Broke Girls</cell><cell>7 072 696</cell><cell>6 282</cell><cell>161</cell><cell>105 000</cell></row><row><cell>30 Rock</cell><cell>13 777 360</cell><cell>1 126</cell><cell>80</cell><cell>657 000</cell></row><row><cell>90210</cell><cell>17 363 009</cell><cell>4 270</cell><cell>84</cell><cell>33 000</cell></row><row><cell>Allen Gregory</cell><cell>912 694</cell><cell>654</cell><cell>48</cell><cell>33 800</cell></row><row><cell>Blue Bloods</cell><cell>3 801 506</cell><cell>822</cell><cell>77</cell><cell>44 300</cell></row><row><cell>Body of Proof</cell><cell>2 912 555</cell><cell>828</cell><cell>40</cell><cell>187 000</cell></row><row><cell>Breaking Bad</cell><cell>41 449 326</cell><cell>4 437</cell><cell>688</cell><cell>229 000</cell></row><row><cell>Charlie's Angels</cell><cell>1 880 872</cell><cell>780</cell><cell>35</cell><cell>41 700</cell></row><row><cell>Cougar Town</cell><cell>6 586 439</cell><cell>1 622</cell><cell>60</cell><cell>15 100</cell></row><row><cell>Criminal Minds</cell><cell>21 460 772</cell><cell>4 752</cell><cell>141</cell><cell>45 400</cell></row><row><cell>Desperate Housewives</cell><cell>21 315 771</cell><cell>11 123</cell><cell>155</cell><cell>261 000</cell></row><row><cell>Gary Unmarried</cell><cell>978 092</cell><cell>742</cell><cell>20</cell><cell>363</cell></row><row><cell>Glee</cell><cell>57 126 905</cell><cell>7 232</cell><cell>158</cell><cell>411 000</cell></row><row><cell>Gossip Girl</cell><cell>18 298 602</cell><cell>7 072</cell><cell>183</cell><cell>380 000</cell></row><row><cell>Grey's Anatomy</cell><cell>31 073 450</cell><cell>9 463</cell><cell>251</cell><cell>489 000</cell></row><row><cell>Harry's Law</cell><cell>1 419 857</cell><cell>654</cell><cell>63</cell><cell>1 360</cell></row><row><cell>Hellcats</cell><cell>3 669 048</cell><cell>1 291</cell><cell>20</cell><cell>656</cell></row><row><cell>How I Met Your Mother</cell><cell>62 167 139</cell><cell>8 190</cell><cell>321</cell><cell>135 000</cell></row><row><cell>Lie to Me</cell><cell>8 458 678</cell><cell>1 631</cell><cell>108</cell><cell>236 000</cell></row><row><cell>Mike and Molly</cell><cell>2 477 749</cell><cell>771</cell><cell>39</cell><cell>332 000</cell></row><row><cell>NCIS</cell><cell>24 884 220</cell><cell>6 381</cell><cell>153</cell><cell>13 300</cell></row><row><cell>Nikita</cell><cell>7 936 616</cell><cell>1 655</cell><cell>77</cell><cell>12 600</cell></row><row><cell>Parks and Recreation</cell><cell>9 458 196</cell><cell>1 882</cell><cell>90</cell><cell>263 000</cell></row><row><cell>Private Practice</cell><cell>6 213 890</cell><cell>1 893</cell><cell>35</cell><cell>84 700</cell></row><row><cell>Rules of Engagement</cell><cell>5 472 316</cell><cell>1 151</cell><cell>37</cell><cell>47 000</cell></row><row><cell>Shark Tank</cell><cell>1 025 637</cell><cell>1 023</cell><cell>10</cell><cell>10 600</cell></row><row><cell>Smallville</cell><cell>14 857 326</cell><cell>8 737</cell><cell>358</cell><cell>974</cell></row><row><cell>The Big Bang Theory</cell><cell>56 785 777</cell><cell>8 864</cell><cell>314</cell><cell>229 000</cell></row><row><cell>The Vampire Diaries</cell><cell>26 545 974</cell><cell>4 919</cell><cell>244</cell><cell>23 100</cell></row><row><cell>Two and a Half Men</cell><cell>30 355 421</cell><cell>7 674</cell><cell>268</cell><cell>499 000</cell></row><row><cell>NFL</cell><cell>10 754 293</cell><cell>10 064</cell><cell></cell><cell>762 000</cell></row></table><note>_(season_8)), we searched through all of the page names that contain the shows' names (for example, A Change of Heart (How I Met Your Mother) or How I Met Your Mother (season 6)) or the keyword NFL (or National Football League). After selecting the relevant pages, we also find the corresponding page edit history using http://tools.wmflabs.org/xtools. Table9summarizes the counts of views and edits for all of the shows. As shown, Wikipedia edits are very limited. This is because only 31,000 people around the world are considered to be active editors for Wikipedia; regular consumers do not edit Wikipedia pages. In the following analysis, we drop the "edits" data and keep only "views." 183.7. IMDB ReviewsConsumers also post reviews on discussion forums such as the IMDB. We choose the IMDB because it has the highest Web traffic ranking (according to Alexa) among all TV-show-related sites. As of January 18, 2015, IMDB had 58 million registered users.a We adjusted the Tweets and Google searches by a proportion to make the three series more comparable with a similar scale on one plot.original content, and which covers entertainment, politics, business, etc.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 10</head><label>10</label><figDesc>MapReduce for Three Tasks</figDesc><table><row><cell></cell><cell></cell><cell>Map</cell><cell></cell><cell></cell></row><row><cell>No.</cell><cell>Task</cell><cell>Key</cell><cell>Value</cell><cell>Reduce</cell></row><row><cell>1</cell><cell>Select relevant</cell><cell>Keyword</cell><cell>1, text</cell><cell>Summation</cell></row><row><cell></cell><cell>tweets/wiki</cell><cell></cell><cell></cell><cell></cell></row><row><cell>2</cell><cell>N-gram frequency</cell><cell>N-gram</cell><cell>1</cell><cell>Summation</cell></row><row><cell></cell><cell>count</cell><cell></cell><cell></cell><cell></cell></row><row><cell>3.1</cell><cell>SSVD-Matrix</cell><cell>Matrix row</cell><cell>Matrix row</cell><cell>Null</cell></row><row><cell></cell><cell>multiplication</cell><cell>index</cell><cell>vector</cell><cell></cell></row><row><cell>3.2</cell><cell>SSVD-</cell><cell>Submatrix</cell><cell>QR matrix</cell><cell>Summation</cell></row><row><cell></cell><cell>Orthogonalization</cell><cell></cell><cell></cell><cell></cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_16"><head>Table 11 Most</head><label>11</label><figDesc>Popular N-Grams in Shows The same logic applies to the names of the other shows.</figDesc><table><row><cell>Show</cell><cell>1st</cell><cell>Count</cell><cell>%</cell><cell>2nd</cell><cell>Count</cell><cell>%</cell><cell>3rd</cell><cell>Count</cell><cell>%</cell><cell>Total</cell></row><row><cell>2 Broke Girls</cell><cell>2 Broke Girls</cell><cell cols="3">21 959 5 0 OfficialKat</cell><cell cols="3">19 199 4 3 Watch</cell><cell cols="2">227 1</cell><cell>442 665</cell></row><row><cell>30 Rock</cell><cell>30 Rock</cell><cell cols="3">568 593 8 0 Watch</cell><cell cols="2">127 239 1 8 Love</cell><cell></cell><cell cols="2">41 667 0</cell><cell>7 148 180</cell></row><row><cell>90210</cell><cell>90210</cell><cell cols="3">893 597 9 3 Watch</cell><cell cols="3">177 318 1 8 Doctor</cell><cell cols="2">61 888 0</cell><cell>9 601 842</cell></row><row><cell>Allen Gregory</cell><cell>Allen Gregory</cell><cell cols="3">8 181 9 2 JonahHill</cell><cell cols="3">2 100 2 4 Watch</cell><cell cols="2">1 713 1</cell><cell>89 161</cell></row><row><cell>Blue Bloods</cell><cell>Blue Bloods</cell><cell cols="3">169 526 8 5 Watch</cell><cell cols="2">21 809 1 1 Love</cell><cell></cell><cell cols="2">14 294 0</cell><cell>1 995 877</cell></row><row><cell>Body of Proof</cell><cell>Body of Proof</cell><cell cols="3">32 658 8 8 Watch</cell><cell cols="3">7 609 2 0 DanaDelany</cell><cell cols="2">3 958 1</cell><cell>372 839</cell></row><row><cell>Breaking Bad</cell><cell>Breaking Bad</cell><cell cols="3">113 950 2 7 aaronpaul</cell><cell cols="3">28 519 0 7 Tonight</cell><cell cols="2">18 407 0</cell><cell>4 145 246</cell></row><row><cell>Charlie's Angels</cell><cell>Charlie's Angels</cell><cell cols="3">15 372 9 4 Watch</cell><cell cols="3">3 379 2 1 Cancel</cell><cell cols="2">1 182 0</cell><cell>162 895</cell></row><row><cell>Cougar Town</cell><cell>Cougar Town</cell><cell cols="3">138 465 8 8 Watch</cell><cell cols="3">28 818 1 8 Show</cell><cell cols="2">14 161 0</cell><cell>1 575 302</cell></row><row><cell>Criminal Minds</cell><cell>Criminal Minds</cell><cell cols="3">962 982 9 4 Watch</cell><cell cols="3">215 756 2 1 Gublernaton</cell><cell cols="2">127 008 1</cell><cell>10 284 082</cell></row><row><cell cols="2">Desperate Housewives Desperate Housewives</cell><cell cols="3">326 899 9 6 Watch</cell><cell cols="3">91 934 2 7 Season</cell><cell cols="2">26 254 0</cell><cell>3 404 224</cell></row><row><cell>Gary Unmarried</cell><cell>Gary Unmarried</cell><cell cols="3">1 664 9 1 Watch</cell><cell cols="3">389 2 1 Funny</cell><cell cols="2">143 0</cell><cell>18 334</cell></row><row><cell>Glee</cell><cell>Glee</cell><cell cols="3">2 174 587 8 7 Watch</cell><cell cols="2">311 489 1 2 Love</cell><cell></cell><cell cols="2">208 418 0</cell><cell>25 074 162</cell></row><row><cell>Gossip Girl</cell><cell>Gossip Girl</cell><cell cols="3">1 273 131 8 4 Watch</cell><cell cols="2">257 260 1 7 Now</cell><cell></cell><cell cols="2">116 795 0</cell><cell>15 177 057</cell></row><row><cell>Grey's Anatomy</cell><cell>Grey's Anatomy</cell><cell cols="3">111 321 2 6 Tonight</cell><cell cols="3">19 369 0 4 Watch</cell><cell cols="2">15 302 0</cell><cell>4 307 147</cell></row><row><cell>Harry's Law</cell><cell>Harry's Law</cell><cell cols="3">19 328 8 6 Watch</cell><cell cols="3">4 130 1 8 Kathy bates</cell><cell cols="2">2 379 1</cell><cell>224 088</cell></row><row><cell>Hellcats</cell><cell>Hellcats</cell><cell cols="3">56 686 9 8 Watch</cell><cell cols="3">10 595 1 8 Ashley tisdale</cell><cell cols="2">7 811 1</cell><cell>577 529</cell></row><row><cell cols="2">How I Met Your Mother How I Met Your Mother</cell><cell cols="3">693 350 8 0 Watch</cell><cell cols="3">139 585 1 6 Neil patrick</cell><cell cols="2">117 773 1</cell><cell>8 625 859</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell cols="2">harris</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Lie to Me</cell><cell>Lie to Me</cell><cell cols="3">18 608 8 7 Tim roth</cell><cell cols="3">6 525 3 1 Watch</cell><cell cols="2">1 844 0</cell><cell>213 067</cell></row><row><cell>Mike and Molly</cell><cell>Mike and Molly</cell><cell cols="3">6 454 9 9 Watch</cell><cell cols="3">2 095 3 2 Checked-in</cell><cell cols="2">891 1</cell><cell>65 037</cell></row><row><cell>NCIS</cell><cell>NCIS</cell><cell cols="3">54 054 2 3 Watch</cell><cell cols="3">8 014 0 3 Tonight</cell><cell cols="2">7 091 0</cell><cell>2 325 168</cell></row><row><cell>Nikita</cell><cell>Nikita</cell><cell cols="2">646 564 9 1 Go</cell><cell></cell><cell cols="2">91 309 1 3 Love</cell><cell></cell><cell cols="2">47 038 0</cell><cell>7 075 657</cell></row><row><cell>Parks and Recreation</cell><cell>Parks and Recreation</cell><cell cols="3">139 256 8 5 Watch</cell><cell cols="3">23 400 1 4 Office</cell><cell cols="2">11 899 0</cell><cell>1 631 277</cell></row><row><cell>Private Practice</cell><cell>Private Practice</cell><cell cols="3">201 836 8 6 Grey's anatomy</cell><cell cols="3">53 815 2 3 Watch</cell><cell cols="2">46 560 2</cell><cell>2 354 062</cell></row><row><cell>Rules of Engagement</cell><cell>Rules of Engagement</cell><cell cols="3">61 456 7 7 David spade</cell><cell cols="2">27 061 3 4 Go</cell><cell></cell><cell cols="2">8 554 1</cell><cell>795 710</cell></row><row><cell>Shark Tank</cell><cell>Shark Tank</cell><cell cols="3">165 728 7 7 Watch</cell><cell cols="3">21 795 1 0 Dragon's den</cell><cell cols="2">3 905 0</cell><cell>2 141 261</cell></row><row><cell>Smallville</cell><cell>Smallville</cell><cell cols="3">139 927 8 5 Watch</cell><cell cols="3">26 197 1 6 Season</cell><cell cols="2">16 833 1</cell><cell>1 651 297</cell></row><row><cell>The Big Bang Theory</cell><cell>Big bang  *</cell><cell cols="3">121 590 2 6 Watch</cell><cell cols="3">16 103 0 3 Tonight</cell><cell cols="2">10 379 0</cell><cell>4 639 872</cell></row><row><cell>The Vampire Diaries</cell><cell>The Vampire Diaries</cell><cell cols="2">753 162 8 3 TV</cell><cell></cell><cell cols="3">255 581 2 8 Watch</cell><cell cols="2">136 691 1</cell><cell>9 025 715</cell></row><row><cell>Two and a Half Men</cell><cell>Two and a Half Men</cell><cell cols="3">32 337 2 3 Watch</cell><cell cols="3">5 043 0 4 Charlie sheen</cell><cell cols="2">3 901 0</cell><cell>1 390 918</cell></row><row><cell>NFL</cell><cell>cowboy</cell><cell cols="2">47 251 0 5 Game</cell><cell></cell><cell cols="3">36 550 0 4 Tonight</cell><cell cols="2">28 432 0</cell><cell>8 603 269</cell></row><row><cell>Total</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>135 138 799</cell></row><row><cell>Note.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>* N-grams: Big, Bang, and Big Bang have the same frequency.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 13 N</head><label>13</label><figDesc></figDesc><table><row><cell>PC1</cell><cell>PC2</cell><cell>PC3</cell><cell>PC4</cell></row><row><cell>Tonight</cell><cell>Bed</cell><cell>Season</cell><cell>Excited</cell></row><row><cell>Can't wait</cell><cell>Home</cell><cell>Start</cell><cell>Finale</cell></row><row><cell>Watch</cell><cell>TV</cell><cell>Premiere</cell><cell>Love</cell></row></table><note>-Grams with Highest Loadings on First Four PCs</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 14</head><label>14</label><figDesc>Variables in the Regression with Descriptions Variable Description Rating_lag Lagged rating, i.e., Nielsen rating for the previous episode of this show Tweets Number of show-related tweets 24/48 hours before the show starts</figDesc><table><row><cell>Google</cell><cell>Number of show-related Google searches (from Google Trend)</cell></row><row><cell></cell><cell>24/48 hours before the show starts</cell></row><row><cell>Wiki</cell><cell>Number of show-related Wikipedia views 24/48 hours before</cell></row><row><cell></cell><cell>the show starts</cell></row><row><cell>IMDB</cell><cell>Number of show-related IMDB reviews 24/48 hours before the</cell></row><row><cell></cell><cell>show starts</cell></row><row><cell>Huffington</cell><cell>Number of show-related Huffington Post news articles 24/48</cell></row><row><cell></cell><cell>hours before the show starts</cell></row><row><cell>Tweet_Pos</cell><cell>Number of show-related positive tweets 24/48 hours before</cell></row><row><cell></cell><cell>the show starts</cell></row><row><cell>Tweet_Neg</cell><cell>Number of show-related negative tweets 24/48 hours before</cell></row><row><cell></cell><cell>the show starts</cell></row><row><cell>Tweet_PC#</cell><cell>#th principal component score for the n-gram matrix derived</cell></row><row><cell></cell><cell>from show-related tweets 24/48 hours before the show</cell></row><row><cell></cell><cell>starts</cell></row><row><cell>Tweet_T#</cell><cell>#th topic model proportion for the n-gram matrix derived from</cell></row><row><cell></cell><cell>show-related tweets 24/48 hours before the show starts</cell></row><row><cell>Premier</cell><cell>Indicator of whether this episode is a season premier</cell></row><row><cell>Finale</cell><cell>Indicator of whether this episode is a season finale</cell></row><row><cell>Age</cell><cell>Total episode number since Season 1 Episode 1</cell></row><row><cell>Winter</cell><cell>Indicator of whether the episode is broadcast in December,</cell></row><row><cell></cell><cell>January or February.</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 15</head><label>15</label><figDesc>Impact of Previous 24 Hours of TGWIH on TV Ratings: TV Series a</figDesc><table><row><cell>24 hr</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head></head><label></label><figDesc>Singh, and Srinivasan: A Structured Analysis of Unstructured Big Data</figDesc><table><row><cell>380</cell><cell>Marketing Science 35(3), pp. 363-388, © 2016 INFORMS</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 15</head><label>15</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head></head><label></label><figDesc>Singh, and Srinivasan: A Structured Analysis of Unstructured Big Data</figDesc><table><row><cell>382</cell><cell>Marketing Science 35(3), pp. 363-388, © 2016 INFORMS</cell></row></table></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 16</head><label>16</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head>Table 17</head><label>17</label><figDesc></figDesc><table /></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_31"><head>Table 22</head><label>22</label><figDesc>Liu, Singh, and Srinivasan: A Structured Analysis of Unstructured Big Data</figDesc><table><row><cell cols="2">Computational Time Comparison</cell><cell></cell></row><row><cell></cell><cell>Cloud (Hadoop) PCA</cell><cell>LDA</cell></row><row><cell>Time (Minutes)</cell><cell>6.2</cell><cell>36.8</cell></row></table></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Although big data processing techniques are only now entering business academic research, these tools are already being widely used by companies such as Facebook, Yahoo!, and Netflix. Although the industry uses a large volume of data for predictions, regrettably the underlying models are rarely revealed. Academics may focus on sophisticated models while industry may rely on simple but effective methods. Practitioners may also value the scalability of the models more than academic researchers in the business arena.4  We thank one of the reviewers for identifying this feature.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="11">http://www.alexa.com/topsites/category/Computers/Internet/ On_the_Web/Online_Communities/Social_Networking. 12 http://blog.gnip.com/tag/gardenhose/.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="13">We thank Brendan O'Connor and Professor Noah Smith from Carnegie Mellon University for providing us with the data.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="14">We also include some variations of the name, such as Breaking_Bad and BreakingBad.15  Hashtags include the names of the teams.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16">http://www.nielsen.com/us/en/press-room/2013/nielsen-laun ches-nielsen-twitter-tv-ratings.html.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="18">We did not report the results with the edits data in Tables15-18and Table20because the performance of "edits" is dominated by the performance of "views." 19 IMDB also features message boards that stimulate regular debates among its authenticated users. However, we cannot access historical discussions before September 2014.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="20">The viewings of popular shows, such as Breaking Bad, can be time deferred, which may reduce the information relevance of Tweets to predict on-air TV ratings. However, we find that Tweets peak during the show time, which suggests that the majority of consumers still watch the shows on air.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="21">To prevent weakening of the Hansen test, we finally chose lags of up to five periods ahead as instruments<ref type="bibr" target="#b0">(Andersen and</ref> Sørensen  1996, Bowsher 2002).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="23">http://alias-i.com/lingpipe/demos/tutorial/sentiment/read -me.html.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="24">We also conducted an analysis for the one-week window. The results are provided in Online Appendix A2 (available as supplemental material at http://dx.doi.org/10.1287/mksc.2015.0972).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="25">The number of episodes of the shows is 2,339. The number of n-grams that are generated from Tweets 24 hours before a show is 28,044,202. For the larger data set of Tweets 48 hours before a show, the number of n-grams is 34,855,764.26  MapReduce developers tout MapReduce for its scalability, fault tolerance, and elasticity. Google uses it to process 20 Pb of data per day.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="29">There is also no second-order serial correlation. The results are not reported here but are available on request.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="30">The shows that have already ended are not included, such as Breaking Bad and Allen Gregory.31  We use the last season of these obscure titles for the prediction.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="32">We thank the anonymous reviewer for emphasizing this point.33 https://gigaom.com/2015/01/21/netflix-is-open-sourcing-tools -for-analyzing-data-in-hadoop/. 34 http://strataconf.com/big-data-conference-ca-2015/public/sche dule/detail/38649.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"> <ref type="bibr">Liu, Singh, and</ref> <p>venue to explore is to disrupt the current Nielsen Rating system and replace it with a real-time measure of audience size/composition based on Twitter or Facebook conversations. Researchers may also want to link TV advertising to online platforms to accurately measure consumer responses to TV ads in real time. We hope that future research will address these issues.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Supplemental Material</head><p>Supplemental material to this paper is available at http://dx .doi.org/10.1287/mksc.2015.0972.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">GMM estimation of a stochastic volatility model: A Monte Carlo study</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">G</forename><surname>Andersen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">E</forename><surname>Sørensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Bus. Econom. Statist</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="328" to="352" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Consistent model and moment selection procedures for GMM estimation with application to dynamic panel data models</title>
		<author>
			<persName><forename type="first">D</forename><forename type="middle">W</forename><surname>Andrews</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Lu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometrics</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="123" to="164" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Deriving the pricing power of product features by mining consumer reviews</title>
		<author>
			<persName><forename type="first">N</forename><surname>Archak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1485" to="1509" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Some tests of specification for panel data: Monte Carlo evidence and an application to employment equations</title>
		<author>
			<persName><forename type="first">M</forename><surname>Arellano</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Bond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Rev. Econom. Stud</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="277" to="297" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Latent Dirichlet allocation</title>
		<author>
			<persName><forename type="first">D</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Machine Learning Res</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Twitter mood predicts the stock market</title>
		<author>
			<persName><forename type="first">J</forename><surname>Bollen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><surname>Mao</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Zeng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Comput. Sci</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="8" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Dynamic panel data models: A guide to micro data methods and practice</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Bond</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Portuguese Econom. J</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="141" to="162" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">On testing overidentifying restrictions in dynamic panel data models</title>
		<author>
			<persName><forename type="first">C</forename><forename type="middle">G</forename><surname>Bowsher</surname></persName>
		</author>
		<ptr target="http://www.bls.gov/news.release/atus.t01.htm" />
	</analytic>
	<monogr>
		<title level="m">Bureau of Labor Statistics (BLS) (2011) American time use survey</title>
				<imprint>
			<date type="published" when="2002" />
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="page" from="211" to="220" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Scree test for the number of factors</title>
		<author>
			<persName><forename type="first">R</forename><surname>Cattell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Multivariate Behavioral Res</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="245" to="276" />
			<date type="published" when="1966" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The differential effects of online word-of-mouth and critics&apos; reviews on pre-release movie evaluation</title>
		<author>
			<persName><forename type="first">A</forename><surname>Chakravarty</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Mazumdar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Interactive Marketing</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="185" to="197" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Online social interactions: A natural experiment on word of mouth versus observational learning</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Q</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Xie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="238" to="254" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">The effect of word of mouth on sales: Online book reviews</title>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">A</forename><surname>Chevalier</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mayzlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="345" to="354" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The effects of online user reviews on movie box office performance: Accounting for sequential rollout and aggregation across local markets</title>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Chintagunta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Gopinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkataraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="944" to="957" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Wikipedia vs. the small screen</title>
		<author>
			<persName><forename type="first">N</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">New York Times</title>
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Yahoo! for Amazon: Sentiment extraction from small talk on the Web</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">R</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1375" to="1388" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Estimating aggregate consumer preferences from online product reviews</title>
		<author>
			<persName><forename type="first">R</forename><surname>Decker</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Trusov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Res. Marketing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="293" to="307" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Research note-Music blogging, online sampling, and the long tail</title>
		<author>
			<persName><forename type="first">S</forename><surname>Dewan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Ramaprasad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Inform. Systems Res</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1056" to="1067" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Does chatter matter? The impact of user-generated content on music sales</title>
		<author>
			<persName><forename type="first">V</forename><surname>Dhar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">A</forename><surname>Chang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Interactive Marketing</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="300" to="307" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">From story line to box office: A new approach for green-lighting movie scripts</title>
		<author>
			<persName><forename type="first">J</forename><surname>Eliashberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">K</forename><surname>Hui</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Z</forename><forename type="middle">J</forename><surname>Zhang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="881" to="893" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Estimating the helpfulness and economic impact of product reviews: Mining text and reviewer characteristics</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans. Knowledge Data Engrg</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1498" to="1512" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Designing ranking systems for hotels on travel search engines by mining user-generated and crowdsourced content</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Li</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="493" to="520" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Opinion mining using econometrics: A case study on reputation systems</title>
		<author>
			<persName><forename type="first">A</forename><surname>Ghose</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Ipeirotis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Sundararajan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 45th Annual Meeting-Assoc</title>
				<meeting>45th Annual Meeting-Assoc</meeting>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="416" to="423" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Using online conversations to study word-of-mouth communication</title>
		<author>
			<persName><forename type="first">D</forename><surname>Godes</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Mayzlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="545" to="560" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Blogs, advertising, and local-market movie box office performance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gopinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">K</forename><surname>Chintagunta</surname></persName>
		</author>
		<author>
			<persName><forename type="first">S</forename><surname>Venkataraman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Sci</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2635" to="2654" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Investigating the relationship between the content of online word of mouth, advertising, and brand performance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Gopinath</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><forename type="middle">S</forename><surname>Thomas</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Krishnamurthi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="241" to="258" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The predictive power of online chatter</title>
		<author>
			<persName><forename type="first">D</forename><surname>Gruhl</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Guha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Kumar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Novak</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Tomkins</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Eleventh ACM SIGKDD Internat. Conf. Knowledge Discovery Data Mining</title>
				<meeting>Eleventh ACM SIGKDD Internat. Conf. Knowledge Discovery Data Mining<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2005" />
			<biblScope unit="page" from="78" to="87" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Randomized methods for computing low-rank approximations of matrices. Unpublished doctoral dissertation</title>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">P</forename><surname>Halko</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2012" />
			<pubPlace>Boulder</pubPlace>
		</imprint>
		<respStmt>
			<orgName>University of Colorado</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Mining and summarizing customer reviews</title>
		<author>
			<persName><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Tenth ACM SIGKDD Internat. Conf. Knowledge Discovery Data Mining</title>
				<meeting>Tenth ACM SIGKDD Internat. Conf. Knowledge Discovery Data Mining<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2004" />
			<biblScope unit="page" from="168" to="177" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Impact of star and movie buzz on motion picture distribution and box office revenue</title>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">V</forename><surname>Karniouchina</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Res. Marketing</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="62" to="74" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">The effect of advertising content on consumer engagement: Evidence from Facebook. Working paper</title>
		<author>
			<persName><forename type="first">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Hosanagar</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">S</forename><surname>Nair</surname></persName>
		</author>
		<author>
			<persName><forename type="first">Gsb</forename><surname>Stanford</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
			<pubPlace>Pittsburgh</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Carnegie Mellon University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Automated marketing research using online customer reviews</title>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">Y</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><forename type="middle">T</forename><surname>Bradlow</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="881" to="894" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Word of mouth for movies: Its dynamics and impact on box office revenue</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="74" to="89" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">ARSA: A sentiment-aware model for predicting sales performance using blogs</title>
		<author>
			<persName><forename type="first">Y</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">An</forename><forename type="middle">A</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName><forename type="first">X</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. 30th Ann. Internat. ACM SIGIR Conf. Res. Development Inform. Retrieval</title>
				<meeting>30th Ann. Internat. ACM SIGIR Conf. Res. Development Inform. Retrieval<address><addrLine>New York</addrLine></address></meeting>
		<imprint>
			<publisher>ACM</publisher>
			<date type="published" when="2007" />
			<biblScope unit="page" from="607" to="614" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Early prediction of movie box office success based on Wikipedia activity big data</title>
		<author>
			<persName><forename type="first">M</forename><surname>Mestyán</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><surname>Yasseri</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Kertész</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">e71226</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Predicting movie sales from blogger sentiment</title>
		<author>
			<persName><forename type="first">G</forename><surname>Mishne</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">S</forename><surname>Glance</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">AAAI Spring Sympos.: Comput. Approaches Analyzing Weblogs</title>
				<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="155" to="158" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">The value of social dynamics in online product ratings forums</title>
		<author>
			<persName><forename type="first">W</forename><forename type="middle">W</forename><surname>Moe</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Trusov</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="444" to="456" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<author>
			<persName><surname>Nielsen</surname></persName>
		</author>
		<ptr target="http://blog.nielsen.com/nielsenwire/wp-content/uploads/2011/01/nielsen-media-fact-sheet-jan-11.pdf" />
		<title level="m">State of the media 2010: U.S. audiences and devices</title>
				<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Study of TV viewers backs Twitter&apos;s claims to be barometer of public mood</title>
		<ptr target="http://bits.blogs.nytimes.com/2015/03/08/twitter-chatter-reveals-what-we-like-to-watch/?_r=0" />
	</analytic>
	<monogr>
		<title level="j">New York Times</title>
		<imprint>
			<date type="published" when="2015-03-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Mine your own business: Market-structure surveillance through text mining</title>
		<author>
			<persName><forename type="first">O</forename><surname>Netzer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Goldenberg</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Fresko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="521" to="543" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Biases in dynamic models with fixed effects. Econometrica</title>
		<author>
			<persName><forename type="first">S</forename><surname>Nickell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econometric Soc</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1417" to="1426" />
			<date type="published" when="1981" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">From tweets to polls: Linking text sentiment to public opinion time series</title>
		<author>
			<persName><forename type="first">B</forename><surname>O'connor</surname></persName>
		</author>
		<author>
			<persName><forename type="first">R</forename><surname>Balasubramanyan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">B</forename><forename type="middle">R</forename><surname>Routledge</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fourth Internat. AAAI Conf. Weblogs Social Media</title>
				<meeting>Fourth Internat. AAAI Conf. Weblogs Social Media</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="122" to="129" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Marketing activity, blogging and sales</title>
		<author>
			<persName><forename type="first">H</forename><surname>Onishi</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Manchanda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Internat. J. Res. Marketing</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="221" to="234" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<author>
			<persName><forename type="first">Singh</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName><surname>Srinivasan</surname></persName>
		</author>
		<title level="m">Structured Analysis of Unstructured Big Data</title>
				<imprint>
			<biblScope unit="page">388</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Marketing Science</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="363" to="388" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Opinion mining and sentiment analysis</title>
		<author>
			<persName><forename type="first">B</forename><surname>Pang</surname></persName>
		</author>
		<author>
			<persName><forename type="first">L</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Foundations Trends Inform. Retrieval</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1-2</biblScope>
			<biblScope unit="page" from="1" to="135" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">You are what you tweet: Analyzing Twitter for public health</title>
		<author>
			<persName><forename type="first">M</forename><forename type="middle">J</forename><surname>Paul</surname></persName>
		</author>
		<author>
			<persName><forename type="first">M</forename><surname>Dredze</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fifth Internat. AAAI Conf. Weblogs Social Media</title>
				<meeting>Fifth Internat. AAAI Conf. Weblogs Social Media</meeting>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="265" to="272" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Beyond likes and tweets: Marketing, online platforms content, and store performance</title>
		<author>
			<persName><forename type="first">H</forename><surname>Pauwels</surname></persName>
		</author>
		<author>
			<persName><forename type="first">E</forename><surname>Stacey</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><surname>Lackman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">MSI Report</note>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Complex dynamics of our economic life on different scales: Insights from search engine query data</title>
		<author>
			<persName><forename type="first">T</forename><surname>Preis</surname></persName>
		</author>
		<author>
			<persName><forename type="first">D</forename><surname>Reith</surname></persName>
		</author>
		<author>
			<persName><forename type="first">H</forename><forename type="middle">E</forename><surname>Stanley</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Trans. Roy. Soc. London A: Math., Physical Engrg. Sci</title>
		<imprint>
			<biblScope unit="volume">368</biblScope>
			<biblScope unit="page" from="5707" to="5719" />
			<date type="published" when="1933" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">How to do xtabond2: An introduction to difference and system GMM in Stata</title>
		<author>
			<persName><forename type="first">D</forename><surname>Roodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stata J</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="86" to="136" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Blogs as predictors of movie success</title>
		<author>
			<persName><forename type="first">S</forename><forename type="middle">E</forename><surname>Sadikov</surname></persName>
		</author>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">G</forename><surname>Parameswaran</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><surname>Venetis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Third Internat. AAAI Conf. Weblogs Social Media</title>
				<meeting>Third Internat. AAAI Conf. Weblogs Social Media</meeting>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="304" to="307" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName><forename type="first">S</forename><surname>Sinha</surname></persName>
		</author>
		<author>
			<persName><forename type="first">C</forename><surname>Dyer</surname></persName>
		</author>
		<author>
			<persName><forename type="first">K</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName><forename type="first">N</forename><forename type="middle">A</forename><surname>Smith</surname></persName>
		</author>
		<title level="m">Predicting the NFL using Twitter</title>
				<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The effects of traditional and social earned media on sales: A study of a microlending marketplace</title>
		<author>
			<persName><forename type="first">A</forename><forename type="middle">T</forename><surname>Stephen</surname></persName>
		</author>
		<author>
			<persName><forename type="first">J</forename><surname>Galak</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Marketing Res</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="624" to="639" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Does chatter really matter? Dynamics of user-generated content and stock performance</title>
		<author>
			<persName><forename type="first">S</forename><surname>Tirunillai</surname></persName>
		</author>
		<author>
			<persName><forename type="first">G</forename><forename type="middle">J</forename><surname>Tellis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Marketing Sci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="198" to="215" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Predicting elections with Twitter: What 140 characters reveal about political sentiment</title>
		<author>
			<persName><forename type="first">A</forename><surname>Tumasjan</surname></persName>
		</author>
		<author>
			<persName><forename type="first">T</forename><forename type="middle">O</forename><surname>Sprenger</surname></persName>
		</author>
		<author>
			<persName><forename type="first">P</forename><forename type="middle">G</forename><surname>Sandner</surname></persName>
		</author>
		<author>
			<persName><forename type="first">I</forename><forename type="middle">M</forename><surname>Welpe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Fourth Internat. AAAI Conf. Weblogs Social Media</title>
				<meeting>Fourth Internat. AAAI Conf. Weblogs Social Media</meeting>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="178" to="185" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
