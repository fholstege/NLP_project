http://pubsonline.informs.org/journal/mksc/

MARKETING SCIENCE
Vol. 36, No. 3, May­June 2017, pp. 453­467 ISSN 0732-2399 (print), ISSN 1526-548X (online)

Robust Dynamic Estimation

Olivier Rubel,a Prasad A. Naika
a Graduate School of Management, University of California Davis, Davis, California 95616 Contact: orubel@ucdavis.edu (OR); panaik@ucdavis.edu (PAN)

Received: November 14, 2014 Revised: September 21, 2015; March 21, 2016; May 6, 2016 Accepted: May 9, 2016 Published Online in Articles in Advance: March 9, 2017
https://doi.org/10.1287/mksc.2016.1010
Copyright: © 2017 INFORMS

Abstract. Managing marketing resources over time requires dynamic model estimation, which necessitates specifying some parametric or nonparametric probability distribution. When the data generating process differs from the assumed distribution, the resulting model is misspecified. To hedge against such a misspecification risk, the extant theory recommends using the sandwich estimator. This approach, however, only corrects the variance of estimated parameters, but not their values. Consequently, the sandwich estimator does not affect any managerial outcomes such as marketing budgeting and allocation decisions. To overcome this drawback, we present the minimax framework that does not necessitate distributional assumptions to estimate dynamic models. Applying minimax control theory, we derive an optimal robust filter, illustrate its application to a unique advertising data set from the Canadian Blood Services, and contribute several novel findings. We discover the compensatory effect: Advertising effectiveness increases and the carryover effect decreases as robustness increases. We also find that the robust filter uniformly outperforms the Kalman filter on the out-of-sample predictions. Furthermore, we uncover the existence of a profit-volatility trade-off, similar to the returns-risk trade-off in finance, whereby the volatility of profit stream decreases at the expense of reduced total profit as robustness increases. Finally, we prove that, unlike for-profit companies, managers of nonprofit organizations should optimally allocate budgets opposite the advertising-to-sales ratio heuristic; that is, advertise more (less) when sales are low (high).

History: Fred Feinberg served as the senior editor and Harald van Heerde served as associate editor for this article.
Supplemental Material: Data and the web appendix are available at https://doi.org/10.1287/ mksc.2016.1010.
Keywords: robust estimation · Kalman filter · optimal control · dynamic games · sandwich estimator · nonprofit marketing

1. Introduction
Brand managers should optimally allocate marketing resources to maximize long-term profit (Gatignon 1993, Mantrala 2002, Shankar 2008, Gupta and Steenburgh 2008). To this end, they seek counsel from marketing analytics companies (e.g., IRI, MarketShare, Kvantum), who analyze the firm's own market data augmented with data from other sources (e.g., Kantar, Nielsen, J.D. Power, etc.), assess the impact of the marketing activities on sales performance, and then recommend optimal budgets and allocations for brand managers to consider when developing marketing plans. For real-world case studies documenting this disciplined practice, see Corstjens and Merrihue (2003), Kumar and Mirchandani (2012), or Nichols (2013). To furnish optimal recommendations, marketing analytics companies use models and methods often invented by academic researchers from various scientific disciplines. For instance, marketing mix models find their roots in the pioneering work of Little (1975), while methods for estimating dynamic models rest on the foundations laid by Fisher's (1922) likelihood principle and Kalman's (1960) filter. In summary, brand

managers make the decisions on marketing budgets and allocations; marketing analytics companies conduct the analyses using existing models and methods to facilitate marketing decisions; and academic researchers invent new models and methods that enable informed decision making and thus improve the practice of marketing.
The optimal allocation of marketing resources over time requires estimation of dynamic models that relate marketing activities (e.g., advertising, price, etc.) to market outcomes (e.g., sales, share, etc.). Existing methods to estimate such dynamic models assume that the forecast errors between the model's predictions and the market data follow some probability distribution, which is typically multivariate normal (e.g., Naik et al. 1998, Vakratsas et al. 2004, Lachaab et al. 2006, Ataman et al. 2008, Bruce 2008, Rubel et al. 2011, van Heerde et al. 2013, Liu and Shankar 2015, Kolsarici and Vakratsas 2015). The data generating process can, however, differ from the assumed probability distribution. The resulting estimated parameters depend on this ex ante assumption of some distribution Fi. Yet what if the distribution was Fj instead? Furthermore,

453

454

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

the probability distributions are infinite and can be represented in the set  {F1, . . . , Fi , . . . , F}, where Fi can be Normal, Gamma, Gaussian Mixture, etc. Because there exists an infinite number of distributions in , it is unreasonable to expect researchers or analysts to estimate parameters for each of the alternative distributions. Hence we propose to develop a new method for estimating dynamic models that does not require the assumption or specification of any probability distribution, parametric or nonparametric.
To elucidate the conceptual idea, let Normal denote the forecast errors resulting under the assumption of a Normal distribution; Gamma under the Gamma distribution; and so on. Then the set  {1, . . . , i , . . . , } contains the forecast errors arising from the corresponding distributions in . Because the proposed method does not assume any specific distribution, the forecast errors arising from all of the distributions must be accounted for when estimating model parameters. To accommodate all of the distributions, we consider the largest possible errors  max{Normal, Gamma, Gaussian Mixture, . . . , i , . . . , }. Consequently, regardless of any specific distribution, we conservatively estimate parameters under the worst case scenario stemming from the largest possible number of errors. As a result, the estimated parameters are robust to any distribution in the set  of all possible distributions. To summarize, robustness is a conceptual property pertaining to the possibility set , while conservatism operationalizes robustness via the worst case scenario.
We formalize the notion of worst case scenarios via the minimax principle (Wald 1950). To understand this principle, let L(, ) denote a loss function such as the sum of squared errors, where  denotes the model parameters and  are the forecast errors. In the extant literature, one assumes that  follows some probability distribution (typically Normal), then evaluates the expected loss L() [L(, )], and finally minimizes it with respect to  to obtain the parameter estimates ^. By contrast, the proposed method eschews the distributional assumption on , minimizes the loss function L(, ) with respect to  and maximizes it with respect to , and thus obtains the parameter estimates ^. Formally, we solve the minimax problem

min max L(, )





to obtain the (best) parameter estimates ^ under the largest errors  (worst case). In the context of
dynamic models, this minimax problem transcends to
a multi-period game. Applying minimax control the-
ory (see, e.g., Baar and Bernhard 1995), we solve this
dynamic game to obtain the best parameter estimates {^ t: t 1, . . . , N } under the largest possible errors {t: t 1, . . . , N}.

We present the results in Propositions 1 and 2. Specifically, Proposition 1 furnishes t for every period t without making any distributional assumptions. Proposition 2 offers ^ t recursively over time t, and depends on a scalar parameter , which specifies the degree of conservatism (or robustness): The smaller the , the more conservative (or robust) the estimation. Interestingly, we show that the robust recursions of ^ t converge to the standard Kalman filter recursions as  tends to infinity. In other words, we show that the Kalman filter estimation is the least conservative. As  decreases, the proposed robust filter becomes more conservative, which means it places more weight on the observed data than the Kalman filter, thereby accommodating a broader range of scenarios.
In summary, the proposed robust filter not only relaxes the necessity of specifying distributions of any kind but also facilitates the robust estimation of timevarying dynamic linear models, which cover broad classes such as the vector auto regression models (e.g., Lütkepohl 2005), ARIMA models (e.g., Brockwell and Davis 1996), time-varying parameter models (e.g., Koop and Korobilis 2010), dynamic regression (e.g., Biyalogorsky and Naik 2003), dynamic factor models (e.g., Bruce et al. 2012) or hierarchical linear models (e.g., Raudenbush and Bryk 2002), to mention a few examples. Thus, for such a broad class of dynamic models, the proposed approach strives to improve the practice of marketing by circumventing the risk of model misspecification. When models are misspecified, the forecast errors contain information, which the proposed robust filter incorporates to learn about the true state by placing more weight on the observed data than the normal Kalman filter.
We apply the proposed dynamic robust estimation to a unique data set from the Canadian Blood Services (CBS), which presents three years of weekly advertising and blood collection across all five provinces of English-speaking Canada (i.e., without Québec). Our analysis reveals that, as conservatism increases, the effectiveness of advertising increases, whereas the carryover effect decreases. This compensatory effect generalizes across all of the provinces. This result arises because the proposed filter places greater weight on more recent data. Furthermore, we compare the dynamic robust estimation with the Kalman filter estimation, with and without White's (1980) correction for robust inferences via the sandwich estimator. We also provide diagnostic tests to determine when to use which method, i.e., robust filter, Kalman filter, robust filter with White's correction, or Kalman filter with White's correction, so that researchers and analysts can use the appropriate method in their empirical contexts. Finally, we derive the optimal budget and allocation strategies for nonprofit organizations whose objective differs from profit-maximization. We prove that, unlike

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

455

for-profit companies, they should spend the marketing budget opposite the advertising-to-sales ratio heuristic, i.e., advertise more (less) when sales are low (high).
The rest of the paper proceeds as follows. Section 3 describes the framework for robust estimation; Section 4 derives the robust filter; Section 5 applies the robust filter to blood donation data and provides an empirical comparison with the Kalman filter and White's correction; Section 6 furnishes the optimal budget and allocation strategies. Section 7 presents concluding comments. We begin with a review of the extant literature on model misspecification.
2. Literature Review
Model misspecification arises when the actual data generating process differs from the assumed probability distribution. Starting with Eicker (1963), this issue has been studied in statistics (see, e.g., Eicker 1967, Huber 1967, Hinkley 1977) and led to an approach known as heteroskedasticity-consistent estimation (White 1980, 1982). In this approach, the standard errors of the estimated parameters are "corrected" to hedge misspecification risk by modifying the inference conducted via the likelihood theory. For misspecified models, White (1980) shows that the inverse of the Fisher information matrix does not yield a consistent variance-covariance matrix, thus resulting in incorrect statistical inferences. To conduct robust inferences, White (1980) proposes the sandwich estimator, which uses not only the inverse of the Fisher information matrix but also the gradients of the log-likelihood function; Equation (22) in Section 4 presents the formula for computational purposes.
In the context of dynamic models, we estimate parameters by computing the likelihood function using the

Kalman filter recursions, and conduct statistical inferences, i.e., significance of the estimated parameters, with or without the sandwich estimator. For example, see Naik et al. (1998) for the Kalman filter estimation without White's correction, and Naik et al. (2008) for robust inferences via the sandwich estimator. Panel A in Figure 1 presents the Kalman filter estimation without White's correction; Panel B in Figure 1 augments it with White's correction for robust inferences.
The primary drawback of White's correction (i.e., the sandwich estimator) is that it does not correct the values of the estimated parameters; it only corrects for their variance. Consequently, managerial decisions would not change whether one uses the sandwich estimator. Consider, for example, estimating a dynamic sales response model with and without White's correction. Would the estimated level of optimal budget or the optimal allocation to marketing activities change? No, because these quantities are functions of the model parameters, whose estimated values remain the same; only their standard errors change due to White's correction. Hence the recommended budget and its allocation to marketing activities remain unaltered.
To overcome this drawback, we develop a method to "correct" the parameter estimator itself. In doing so, the proposed method also corrects for the variance of the estimated parameters. Recall that Panels A and B in Figure 1 require prespecifying a probability distribution, which we aim to relax. To this end, in Panel C of Figure 1, the proposed method, which we call the robust filter, makes no distributional assumptions for the error terms in dynamic linear models.
Because the robust filter provides different parameter estimates than those obtained from Panels A and B

Figure 1. Robust Estimation and Inferences
No Panel A Kalman filter

Robust inferences? Yes
Panel B White's correction

No

1. Nonrobust parameter estimates

2. Nonrobust inferences

3. Nonrobust budget

4. Nonrobust allocation

1. Nonrobust parameter estimates 2. Robust inferences 3. Nonrobust budget 4. Nonrobust allocation

Robust estimation?

Panel C Robust filter

Yes

1. Robust parameter estimates

2. Robust inferences

3. Conservative budget

4. Conservative allocation

Panel D Combined approach
1. Robust parameter estimates 2. Double robust inferences 3. Conservative budget 4. Conservative allocation

456

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

in Figure 1, managerial outcomes such as the budget and allocation change as do their standard errors. In other words, the robust filter yields the robust estimates and robust inferences. Finally, by applying the sandwich estimator together with the dynamic robust estimation, we achieve "double" robustification for inferences, as shown in Panel D of Figure 1.
In summary, the extant literature investigates robustification through the lens of statistical outcomes such as inference, but it cannot affect any managerial outcomes; managerial decisions do not change with or without the sandwich estimator. How else should managers then safeguard against misspecified models? To address this question, we next present the minimax framework to robustify parameter estimation.

3. A Framework for Robust Dynamic Estimation
Consider the dynamic linear model (e.g., Harvey 1989, West and Harrison 1997, Shumway and Stoffer 2011) given by the observation equation

yt Zt t + vt ,

(1)

where yt is the n × 1 vector of observed dependent variables, t is the m × 1 vector of unobserved state variables, Zt is the n × m link matrix, and vt is the n × 1

vector of error terms that follow a multivariate nor-

mal distribution N(0, Ht). Furthermore, the state vector t dynamically evolves over time via the transition

equation

t+1 Tt t + dt + t ,

(2)

where Tt is the m × m transition matrix, dt is the m × 1 drift vector, and the error terms t follow an
m-dimensional multivariate normal distribution

N(0, Qt). Because the system matrices {Zt , Tt , dt , Ht , Qt } can be time-varying, Equations (1) and (2) encapsulate

many classes such as the vector auto regression models

(e.g., Lütkepohl 2005), ARIMA models (e.g., Brockwell

and Davis 1996), time-varying parameter models (e.g.,

Koop and Korobilis 2010), dynamic regression (e.g.,

Biyalogorsky and Naik 2003), dynamic factor models

(e.g., Bruce et al. 2012) or hierarchical linear models

(e.g., Raudenbush and Bryk 2002), to mention a few

examples. Section D in the web appendix explains how

these models are special cases of Equations (1) and (2).

In Equations (1) and (2), the state vector t is un-

observed; hence, we seek the estimator ^ t of the

unobserved state t by minimizing

N t1

t - ^ t

2

assuming that the error terms (vt , t) follow multi-

variate normal distributions. In other words, we min-

imize the expected sum of squared errors, L()

[

N t1

t - ^ t

2], to find the best estimator ^

{^ t:

t 1, . . . , N }, which is given by the Kalman filter

recursions (see, e.g., Appendix B in Naik et al. 1998).

Here we have used the notation x 2 x x and, more

generally,

x

2 A

x Ax for any vector x and a con-

formable positive definite matrix A. The loss func-

tion L() can be viewed as the expected loss L()

[L(, v, )], where the expectation operator [ · ] inte-

grates out (v, ) using the assumed distributions of

the error terms. This operation explains why statistical

estimation requires the assumption of some probability

distribution for (v, ).

To not assume any probability distributions for

(v, ), we invoke the minimax principle, due to Wald

(1950), and replace (v, ) by their worst case (i.e.,

largest) disturbances. Specifically, we seek the estima-

tor ^

{^ t: t

1, . . . , N } by minimizing

N t1

t - ^ t

2

with respect to ^ t, as before, but subject to the maxi-

mization of the sum of squared disturbances,

N -1

D(v, )

t0

t

+ 2
Q-t 1

v2 t Ht-1

+

0 - ^ 0

, 2
P0-1

where (0, P0, ^0) denote the initial state, its uncertainty, and its estimate, respectively. In other words, we replace the integration operation [ · ] by the maximization operation so as to eschew the distributional assumptions. Thus, in the robust estimation framework, we make no distributional assumptions for the error terms because the minimax principle optimizes over the unobserved states and the unknown errors.
To construct a joint objective function, we combine the loss functions L() and D(v, ) in the performance index

L(t, vt, t)

N t1

t - ^ t 2

0 - ^ 0

+ 2
P0-1

N-1(
t0

t

+ 2
Q-t 1

vt

. 2)
Ht-1

(3)

For further details on this performance index, see
Banavar (1992), Theodor and Shaked (1994), Baar and
Bernhard (1995) or Simon (2006). In Equation (3), all
individual terms on the right-hand side (RHS) are
quadratic forms and hence positive, so zero is the least value that L( · ) attains. We search for all of the finite sequences of {(^ t , t): t 1, . . . , N } such that the performance index is smaller than some positive constant , i.e., the feasible solutions satisfy L(t, vt, t) < .
The parameter  embodies conservatism in designing the optimal state estimator ^. To understand this idea, consider the scenario when  is small. Then, ceteris paribus, the optimal  must be sufficiently large to satisfy L(t , vt , t) < . The large  in turn perturbs the state t substantially due to Equation (2). By contrast, when  is large, even small values of  can satisfy L(t , vt , t) < . The small  in turn marginally perturbs the state t due to Equation (2). In the extreme, when  tends to infinity, the disturbances 

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

457

are the smallest, leading to the least conservative scenario. Hence, as  decreases, the estimation becomes
more conservative (or robust) by accommodating wide perturbations to the unobserved state t.
Given any level of conservatism , what are the best trajectories of the state estimator ^ {^ t: t 1, . . . , N } and the disturbance sequences (v, ) {(vt, t): t 0, . . . , N - 1}? To find them, we need to solve the minimax
problem

(^ t

,

v

 t

,

t

)

arg min max L(t , vt , t) < ,

(4)

t (vt , t )

subject to Equations (1) and (2) and without distributional assumptions on (vt , t).
Equation (4) induces a dynamic game, "dynamic"
because Equation (2) evolves over time, and "game"
because one can evoke the metaphor of two fictitious
players, the so-called statistician and Nature, engaged
in a competitive game in which the statistician seeks to estimate the unobserved state t, while Nature injects disturbances (vt , t) to obscure the state and thus impede the statistician. Formally, the statistician chooses ^ t  (-, ) to minimize L(t , vt , t), and Nature chooses the disturbances (vt, t)  (-, ) to maximize L(t , vt , t). Because t perturbs the future evolution of t (via Equation (2)), the statistician foresees this perturbed path and incorporates its effect in determining the best estimator {^ t }. Likewise, Nature foresees the statistician's best response over time {^ t } when determining her best response {(vt, t)} such that neither of them have incentives to deviate, thereby attaining the equilibrium strategies {(^ t , vt, t): t 1, . . . , N}.
In summary, the minimax estimation framework
reveals three insights, i.e., no distributional assumptions are necessary to estimate the unknown state t in dynamic linear models; the parameter  embodies conservatism (small   more conservative); the optimal state estimator ^ t is the least conservative when   .

4. Deriving the Robust Filter
Here we solve the dynamic game in Equation (4) to derive the method for robust dynamic estimation. We first obtain the optimal disturbances in Proposition 1, then present the robust filter in Proposition 2, and finally discuss parameter estimation and inference.
4.1. Optimal Disturbances To derive the disturbances without making distributional assumptions, we apply minimax control theory

(see, e.g., Zames 1981, Baar and Bernhard 1995). Using (3), we first re-express L(t , vt , t) <  as follows:

N

J(t, t)

t - ^ t 2

t 1 N-1

-

t

(
0

t

+ 2
Q-t 1

yt - Zt t

2)
Ht-1

+

0 - ^ 0

2 P0-1

,

(5)

where we substituted vt yt - Zt t from Equation (1). Equation (5) expresses the loss function for the statisti-
cian and Nature. The first term on its RHS reflects the
loss a statistician incurs in estimating the unobserved
state, while the second term in the square parentheses
captures Nature's impedance via ({t }, 0). The resulting game is zero-sum. To see this point,
let J(t , t) J1 -J2, where J1 J(t , t) denotes the statistician's payoff function, and J2 -J(t , t) represents Nature's payoff function. Consequently J1 + J2 J(t , t) + (-J(t , t)) 0 for every (t , t), not just at the equlibrium solutions, because of the common
objective function J(t , t) in Equation (5) for both players. Also, the value of the game

J J(t , t) min max J(t , t)

t

t

is not zero at equilibrium. Next, to dynamically optimize J(t , t), we apply
Pontryagin's maximum principle (see, e.g., Sethi and Thompson 2000). To this end, we re-express the state dynamics in Equation (2) as follows:

t t+1 - t dt - (I - Tt )t + t .

(6)

Then, using (5) for a given t, we formulate the Hamiltonian function

t

t - ^ t 2 - 

t

+ 2

Q

-1 t

yt - Zt

2 Ht-1

+ µt+1 dt - (I - Tt )t + t ,

(7)

where we have adjoined the RHS of Equation (6) using the m × 1 vector of costate variables, µt+1. The Hamiltonian t decomposes the dynamic optimization problem arg max J(t , t) in (4) into instantaneous static optimization problems in (7). Then we connect the optimized solutions over time using the evolution of costate variables prescribed by Pontryagin's maximum principle (see, e.g., Sethi and Thompson 2000).
Equation (7) has the following interpretation. The first term on the RHS represents the loss in forecast accuracy; the second term accounts for the adverse impact due to the shocks; and the third term captures the long-term impact due to fluctuations in the true state. The larger the costate, the larger the impact of state fluctuations on forecast accuracy. In other words,

458

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

the costate variables quantify the difficulty in improving the forecast accuracy due to the fluctuating states.
Based on Pontryagin's maximum principle, the firstorder conditions (FOCs) are given by

t t

0 and µt

-

t t

,

(8)

where µt µt+1 - µt. Differentiating t, we get

 t/t

-((t

Q

-1 t

t

)/t

)

+

µt+1

-2t Qt-1

+ µt+1. Setting the last expression to zero, we get

2t Qt-1 µt+1, which yields the optimal disturbances

t Qt t+1 ,

(9)

where we have re-expressed the costate variables as t+1 µt+1/(2).
Using Equation (8) we next obtain the costate dynamics. Specifically, µt - t/t -2(t - ^ t) + 2(yt - Zt t) Ht-1(-Zt) + µt+1(I - Tt). Dividing by 2, replacing µt/(2) by t, and taking the transpose, we get t+1 - t -(t - ^ t )/ - Zt Ht-1(yt - Zt t ) + t+1 - Tt t+1. Hence the costate vector evolves as follows:
t Tt t+1 + (t - ^ t )/ + Zt Ht-1(yt - Zt t ). (10)

Collecting (9) and (10), we obtain the following proposition.

Proposition 1. The vector of optimal disturbances is

given by

t Qt t+1 ,

where the costate vector evolves according to

t Tt t+1 + (t - ^ t )/ + Zt Ht-1(yt - Zt t ),

starting backwards from the terminal N 0 for t {N - 1, . . . , 1, 0}.
Equations (9) and (10) provide a mechanism to generate the sequence of optimal disturbances without requiring distributional assumptions. The costate vector is driven by the forward dependence (Tt t+1), the state estimation error (t - ^ t), and the measurement noise (yt - Zt t). As  decreases, the magnitude of the costate vector increases and so does the size of the worst case disturbances t. Incorporating these disturbances in the state vector, we next derive the optimal state estimator ^ t.

4.2. Robust Filter

At initial t 0, we maximize J(0, 0) in Equation (5) subject to the constraint in Equation (2). Specifically,

we maximize µ00 -(0

the Lagrangian l(0) - 0 - - ^ t) P0-1(0 - ^ t) + µ00 to get

^ t

2 P0-1

l/0

+

-2(0 - ^ t) P0-1 + µ0. Setting the last equality to zero,

we get 0 ^0 + P00, where 0 µ0/(2). We next

use this relationship between the true and estimated

states for t  1, i.e., t ^ t + Pt t. Substituting it and the disturbances t Qt t+1 from Proposition 1 in the state Equation (2), we get

^ t+1 + Pt+1t+1 dt + Tt ^ t + Tt Pt t + Qt t+1. (11)

Similarly, we substitute t ^ t + Pt t in the costate Equation (10) to obtain

t

T

t+1

+

Pt t/

+

Zt

H

-1 t

(

yt

-

Zt (^ t

+

Pt t)).

(12)

Then, collecting all of the t terms in (12) to its lefthand side and taking the inverse, we get

t

I - Pt / + Zt Ht-1Zt Pt -1

· Tt t+1 + Zt Ht-1(yt - Zt ^ t ) .

(13)

Next, we substitute t from (13) in (11), collect the terms for t+1, and apply Lagrange's method of unde-
termined coefficients to observe that

^ t+1 dt + Tt ^ t + Tt Pt I - Pt / + Zt Ht-1Zt Pt -1

· Zt Ht-1(yt - Zt ^ t ),

(14)

and

Pt+1 Tt Pt I - Pt / + Zt Ht-1Zt Pt -1Tt + Qt . (15)

Collecting (14) and (15), we state the following proposition.

Proposition 2. The optimal state estimator ^ t is given recursively for t 1, . . . , N by

^ t+1 dt + Tt ^ t + Tt Kt (yt - Zt ^ t ),

(16)

where

Kt Pt (I - Pt / + Zt Ht-1Zt Pt )-1Zt Ht-1, and (17)

Pt+1 Tt Pt (I - Pt / + Zt Ht-1Zt Pt )-1Tt + Qt .

(18)

Equations (16) through (18) provide the optimal
recursions to update the state estimate ^ t+1 based on ^ t. This update is proportional to the estimation error
(yt - Zt ^ t). The proportionality depends on the gain matrix Kt. The gain matrix should satisfy the condition that the matrix (I - Pt/ + Zt Ht-1Zt Pt) is positive definite to ensure optimality (i.e., the second-order
conditions).
The subtraction of Pt/ in (17) optimally expands the gain matrix Kt. To see this clearly in (17), observe that as  decreases, the matrix Pt/ increases, so (-Pt/) decreases, which in turn increases (I - Pt/ + Zt Ht-1Zt Pt)-1 due to the inverse operation, and hence Kt increases. Consequently, a larger Kt places greater weight on the current market data (yt - Zt ^ t). Thus, a more robust filter overweighs the recent past,
making it relatively more "present-oriented." Similar
reasoning shows that Pt+1() in (18) increases as 

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

decreases. As a result, a more robust filter also accommodates a wider range of perturbations to the unobserved states t.
In Section B of the web appendix, we prove the robust filter converges to the Kalman filter as   . Specifically, we show that the gain matrices, the covariance matrices, and the state estimators of the standard Kalman filter and the proposed robust filter are asymptotically equivalent. Furthermore, the robust filter becomes less conservative as  increases and so it is the least conservative filter at   . Thus, the Kalman filter is not only nested but also the least conservative filter.

4.3. Robust Parameter Estimation and Inference
The time-varying system matrices {Zt , Tt , dt , Ht , Qt } in Equations (1) and (2) depend on the p × 1 vector of model parameters . To estimate , as in the Kalman
filter estimation, we maximize the criterion

S()

N

-1 2

ln(det(Ft ()))

+(

t
yt

-1

Zt ^ t())

Ft ()-1(yt

-

Zt

^ t())

,

(19)

where Ft() Zt Pt()Zt + Ht(). More precisely, for a given level of conservatism , we obtain the robust parameter estimates

^ arg max S().

(20)

To conduct robust inference, we extract the square root of the diagonal of the negative inverse of the Hessian of S() to obtain the vector of robust standard errors

se(^) Sqrt(Diag(-G^ -1)),

(21)

where the p × p Hessian matrix G^ (2S()/  )| ^ is evaluated at the estimated parameter values.
In summary, we derived the optimal disturbances in Equation (9) without making any distributional assumptions; Equations (16) through (18) provide the robust filter recursions; Equation (20) yields the robust parameter estimates; and Equation (21) enables robust inference. These equations, together, complete the proposed approach for robust dynamic estimation shown in Panel C of Figure 1.
To complete the approach mentioned in Panel D of Figure 1, we "correct" the standard errors obtained from Equation (21) via White (1980). Specifically, for each observation t, we first numerically compute the gradient S()/ , which is a 1 × p vector. Next, we stack all of the gradients row-wise to create the N × p matrix A and thus create the matrix M A A of dimension p × p. Then, we obtain the vector of double-robust standard errors

se(^) Sqrt(Diag(G-1 MG-1)).

(22)

459

Note that the robust parameter estimates ^ (from Equation (20)) remain the same in both standard error estimators (i.e., Equations (21) or (22)). Hence doublerobustification affects only the inference, and does not alter the managerial outcomes based on Equation (20).

4.4. When To Use Which Method? Should researchers or analysts always pursue robust estimation and inferences? Not necessarily. The answer depends on whether the residuals exhibit nonnormality and whether we suspect misspecification. To this end, we suggest using the Jarque­Bera test to ascertain normality and White's test to discover heteroskedasticity or misspecification.
The Jarque­Bera test statistic is given by

T1 (N - p)(S2 + 0.25(C - 3)2)/6,

(23)

where the sample skewness

S the sample kurtosis

N t

1(rt

-

r¯)3

N t

1(rt

-

r¯)2

3/2
,

C

N t

1(rt

-

r¯)4

N t

1(rt

-

r¯)2

2
,

and (rt , r¯) denotes the individual residuals and their average. The null hypothesis is that the residuals are normally distributed (i.e., neither skewness nor kurtosis). The statistic T1 follows 2 with two degrees of freedom, which yields the p-values at the 95% confidence level.
To conduct the White's (1980) test, researchers or analysts should run an auxiliary regression with the dependent variable as the squared residuals, and the regressors being the constant plus the linear, quadratic, and cross-product terms of the variables in the original model. Then the White (1980) test statistic is given by

T2 NR2,

(24)

where R2 denotes the unadjusted fit of the auxiliary
regression. The null hypothesis is that neither het-
eroskedasticity nor misspecification exists. The statistic T2 follows k2 with k degrees of freedom, which equals the number of regressors excluding the con-
stant, and it yields the p-values at the 95% confidence
level.
If T1 holds, i.e., one fails to reject the null, then the residuals are deemed normal; if T2 holds, then neither heteroskedasticity nor misspecification exists. Accord-
ingly, researchers or analysts run the Kalman filter and
then apply T1 and T2 to the residuals from Panel A. If T1 and T2 hold, they stay in Panel A. There is no need for robust estimation or robust inferences. If T1 holds but

460

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

not T2, they go to Panel B and apply the sandwich estimator as in Equation (22), but using the gradient and Hessian matrices obtained from the Kalman filter (for details, see Naik et al. 2008). If T1 does not hold, they go to Panel C and run the robust filter. Then they apply T2 to the residuals obtained from the robust filter. If T2 holds, they stay in Panel C. If not, they go to Panel D and the sandwich estimator given in Equation (22) is applied. In general, this road map guides researchers and analysts to discover for themselves whether they should implement the results from robust estimation and inferences in their particular empirical contexts. Next, we apply the robust dynamic estimation to blood advertising by Canadian Blood Services.
5. Empirical Application
5.1. Blood Marketing Over a hundred million blood donations are collected worldwide every year. Blood donors give blood without compensation and without knowing who the donees are. Thus, blood donations epitomize altruism, which blood collection agencies elicit through advertising. Yet advertising for blood differs from brand advertising. Unlike conventional marketing, profit considerations do not arise for blood collection agencies since there are no market prices or profit margins involved. Moreover, collection agencies do not advertise to maximize donations but to bring blood collections close to targets since blood cannot be stored for long periods.
The literature on blood donations is sparse. A recent study by Aravindakshan et al. (2014) investigates how online media generates blood donations for a small community blood bank. By contrast, we study advertising by CBS, a large national blood collection agency serving English-speaking Canada.
For historical perspective, recall that the government of Premier Jean Chrétien established the CBS because, during the 1980s, over 30,000 people received tainted blood products due to the negligence of the Canadian Red Cross in performing the necessary tests to detect HIV and Hepatitis C. In response, the Royal Commission, headed by Justice Horace Krever, investigated this nationwide public calamity. Based on the commission's report (Krever 1998), the Canadian government banned the Red Cross from collecting blood. Red Cross blood collection was replaced by the CBS (see www.blood.ca) for collecting and supplying blood in Canada, except Québec. In this new system, Canadian Provinces and Territories provide funding to CBS, which delivers blood products to hospitals free of charge without consideration of the market prices or profit margins. As a state monopoly, CBS does not face competition for blood collection in any of its five provinces, i.e., Alberta, the Atlantic Provinces, British Columbia, Ontario, and the other Prairies. Moreover,

based on the Krever Commission, CBS cannot import blood from outside these five provinces, and the hospitals cannot receive blood products from other sources.

5.2. Data Description CBS deploys marketing communications to elicit altruistic behaviors from donors. Consistent with its motto, It's in you to give, CBS advertises to motivate people to give blood by using mass communications via radio advertisements and personal communications via phone calls. We collected weekly data on pints of blood collected, radio gross rating points (GRPs), and the number of phone calls for each of the five provinces from April 2010 through March 2013. Thus, we observed the entire blood collection in Englishspeaking Canada for 156 weeks. Table T1 in the web appendix (see Section A) summarizes the descriptive statistics.

5.3. Blood Collection Dynamics

Let yt denote the actual blood collected at time t, bt denote the mean blood levels, and vt represent the disturbance such that



yt bt + hvt ,

(25)

where h measures the impact of the disturbances vt. The mean blood level evolves over time as follows:







bt+1 1 u1t + 2 u2t + bt + qt ,

(26)

where (u1t , u2t) denotes the weekly radio GRPs and the number of phone calls, (1, 2) correspond to their effectiveness,  represents the carryover effect, and q measures the impact of the disturbance t. In robust estimation, the disturbances (vt , t) are conceptually viewed as Nature's perturbations that are strategically
set rather than randomly drawn (as in the nonrobust Kalman filter estimation). Consequently, ( h, q)
are interpreted as the impact of marginal changes in (vt , t) on the observation and state variables (y, b), respectively. Formally, h y/ and q b/. Thus, they represent the impacts of disturbances (, ) on (y, b), respectively.
Equations (25) and (26) can be cast into the dynamic
linear model in (1) and (2), respectively. To see this equivalence, note that Zt 1, t bt, Ht h, Tt , dt 1 u1t + 2 u2t, and Qt q. We observe (yt , u1t , u2t) for t 1, . . . , N 156 weeks. We must estimate the parameter vector  (1, 2, , h, q) of dimension p 5. We use 104 observations for estimation and hold out 52
observations for validation. We next apply the four
methods mentioned in Panels A­D of Figure 1. For
details of Panels A and B, see Naik et al. (1998, 2008),
respectively. For details of Panels C and D, see Sec-
tions 4.2 and 4.3.

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

461

5.4. Scale for Conservatism Here we create a scale such that conservatism increases as  increases rather than as  decreases (i.e., reverse the orientation). We first estimate the Kalman filter to obtain the parameter estimates and the maximized value S  in Equation (19). Then we apply the robust filter to estimate the model for various values of , and select that value of , which we denote by ^min, for which the difference -2(S - S ) just equals 12, 0.05 3.84. In words, we conceptually seek that robust filter that is statistically no worse than the Kalman filter. For Alberta, Atlantic, British Columbia, Ontario, and the Prairies, we find ^min (4,000, 3,000, 3,000, 50,000, 4,000), respectively. Next, we increase  in increments of 1,000 up to a large value (which occurs at 103,000 in our application) such that the parameter estimates from the robust filter converge to those obtained from the Kalman filter. Finally, we create a scale  exp(-( - ^min)/^min) such that conservatism increases as  increases (i.e., reverse the orientation with respect to ). In this scale,  and  map one-to-one with  0 corresponding to the least conservative filter and  1 to the most conservative filter.
5.5. Parameter Estimates We estimated 500 models for various  and 5 provinces. Table 1 reports the parameter estimates and t-values across the four approaches in Figure 1. Panels A and B of Table 1 present the parameter estimates and their t-values from the Kalman filter without and with White's correction, respectively. The estimated parameter values in Panels A and B do not change; only the t-values differ because the sandwich estimator alters the standard errors to hedge misspecification risk.
By contrast, Panel C of Table 1 displays the results from the proposed robust filter. Recall that the robust filter uses the optimal disturbances derived in Proposition 1, eschewing probabilistic assumptions for the

random errors. Consequently, the estimated parameter values obtained via the Equation (20) for the robust filter (Panel C) differ from those obtained via the Kalman filter (Panel A). This outcome is the consequence of parametric robustification, which places a greater weight on current market data compared to the Kalman filter (i.e., present-orientedness of the robust filter). In addition, the standard errors from Equation (21) for the robust filter (Panel C) differ from those obtained via the Kalman filter (Panel A). Thus, we obtain the robust estimates and robust inferences.
To achieve "double-robust" inferences, we use the sandwich estimator in Equation (22). The parameter values in Panels C and D do not change since both are obtained via Equation (20). Only the t-values differ because Equation (21) yields the standard errors for the robust filter, whereas Equation (22) yields the standard errors from the sandwich estimator. However, double robustification in Panel D alters the parameter estimates (relative to Panel B) and their significance (relative to Panels A­C).
Substantively, the results show that the carryover effects are significant in all provinces except Atlantic and they appear bi-modal with values clustered in the neighborhoods of 0.5 and 0.9. We also learn that radio advertising is statistically significant in all provinces, except Atlantic where phone calls generate blood donations. Phone call communications are statistically significant in all provinces, except British Columbia where radio advertising generates blood donations. Moreover, heterogeneity exists across provinces. The effectiveness of radio advertising estimated with the robust filter ranges from 0.06 to 1.23 with a median of 0.83. Similarly, the phone call effectiveness ranges from 0.23 to 1.47 with a median of 0.88.
5.6. Compensatory Effect Figure 2 presents the effect of conservatism on the carryover effect, radio effectiveness, and phone call effectiveness for Alberta. As conservatism increases, we

Table 1. Parameter Estimates (t-Values)

Provinces

Radio ^1

Calls ^2

Panel A. Kalman filter

Alberta Atlantic B.C. Ontario Prairies

0.90 (2.15) 0.06 (0.29) 0.66 (2.72) 1.05 (1.73) 0.78 (2.31)

0.44 (2.17) 1.33 (6.08) 0.20 (1.60) 0.71 (2.65) 0.98 (4.79)
Panel C. Robust filter

Alberta Atlantic B.C. Ontario Prairies

1.07 (2.44) 0.06 (0.32) 0.72 (2.87) 1.23 (1.97) 0.82 (2.42)

0.61 (2.91) 1.47 (8.58) 0.23 (1.73) 0.88 (3.19) 1.21 (6.63)

Carryover ^
0.88 (18.23) 0.28 (1.43) 0.93 (29.43) 0.87 (17.76) 0.62 (6.49)
0.83 (15.63) 0.15 (0.82) 0.91 (26.88) 0.83 (15.79) 0.51 (13.87)

Radio ^1

Calls ^2

Carryover ^

Panel B. White's correction

0.90 (2.30) 0.06 (0.29) 0.66 (2.91) 1.05 (1.85) 0.78 (2.50)

0.44 (2.21) 1.33 (4.72) 0.20 (1.62) 0.71 (2.35) 0.98 (3.95)

0.88 (19.20) 0.28 (1.05) 0.93 (27.07) 0.87 (15.13) 0.62 (5.24)

Panel D. Combined approach

1.07 (2.47) 0.06 (0.31) 0.72 (2.96) 1.23 (2.08) 0.82 (2.57)

0.61 (2.77) 1.47 (6.79) 0.23 (1.63) 0.88 (2.54) 1.21 (5.50)

0.83 (15.45) 0.15 (0.60) 0.91 (23.68) 0.83 (12.31) 0.51 (4.27)

462

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

Figure 2. (Color online) Compensatory Effect of Conservatism

Alberta

1.1

0.88

1.0

Radio effectiveness

0.9

0.87

0.8 0.86

0.7

0.85 0.6

Calls effectiveness

0.5

0.84

0.4

0

0.2

0.4

0.6

0.8

1.0

Alberta

Carryover effect

0.2

0.4

0.6

0.8

1.0

observe that the estimated effectiveness of radio advertising increases; the estimated effectiveness of phone calls also increases; whereas the estimated carryover effect decreases. These findings generalize across all five provinces.
These results reveal the compensatory effect between marketing effectiveness and the carryover effect as conservatism increases. That is, marketing effectiveness and the carryover effect move in the opposite direction. Thus, conservatism induces managers to rely more on the present and less on the past. We attribute this finding to the present-orientedness of the robust filter whose gain matrix places greater weight on the current data, thereby increasing short-term effectiveness and decreasing long-term carryover effect.
5.7. Marketing Elasticities To compare the relative performance of CBS' marketing instruments, we compute the elasticities for radio advertising and personal phone calls. Specifically, for each province, we draw 100,000 realizations from the distribution of estimated parameter values, which takes into account the associated parametric uncertainty and their cross-correlations via the full variance-covariance matrix. We obtain the median elasticities and their statistical significance based on the 2.5th and 97.5th percentiles.
Radio advertising elasticities for Alberta, Atlantic, British Columbia, Ontario, and the Prairies are (0.09, 0.002, 0.16, 0.07, 0.03), respectively. All of the elasticities, except Atlantic, are statistically significant. Substantial heterogeneity exists across provinces, ranging from negligible in Atlantic to 0.16 in British Columbia. To provide a perspective, consider the meta-analysis by Sethuraman et al. (2011) based on the extant advertising literature. They present elasticities for television, print, and aggregate advertising, but no elasticity for

radio advertising is reported in their meta-analysis, indicating its scant availability in the extant literature. Furthermore, studies in the meta-analysis focus on industries such as pharmaceutical, durable goods, food, nonfood, and services, where consumers receive tangible benefits from the advertised brand. By contrast, blood donors do not receive tangible benefits. Despite these differences, it is remarkable that the median elasticity of radio advertising for blood is 0.07, which is comparable to the median advertising elasticity of 0.10 (ibid, p. 468). Thus, our work augments this scant literature by contributing the elasticities of radio advertising.
To complement mass advertising on radio, CBS also uses its National Contact Center to make phone calls, which constitute one-on-one personal communications. The elasticities of personal communications for Alberta, Atlantic, British Columbia, Ontario, and the Prairies are (0.33, 0.27, 0.27, 0.35, 0.29), respectively. All of the elasticities, except for British Columbia, are statistically significant. Unlike radio advertising, much heterogeneity does not exist across provinces, with the elasticities ranging from 0.27 to 0.35. To provide a perspective, consider the meta-analysis by Albers et al. (2010) based on the extant literature on personal selling. Over 50% of their studies cover the pharmaceutical industry (e.g., sales force communication to physicians) and about 25% pertain to military recruiting efforts. No elasticity for personal communications of nonprofit organizations is reported in their meta-analysis, again indicating scant availability in the extant literature. Despite this difference, it is remarkable that the mean elasticity for phone call communications for blood donations is 0.29, which is comparable to the mean elasticity for personal selling of 0.31 (ibid, p. 840). Thus, we further augment the scant literature by contributing the elasticities of phone call communications.

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

463

5.8. Was Robustification Necessary? We answer this question based on the road map given in Section 4.4. Specifically, we trace the diagnostic path in our empirical context, starting with Kalman filter residuals in Panel A of Figure 1, applying the Jarque­Bera test, and obtaining T1 0.707 (p-value 0.001), and thus rejecting the normality assumption. Because T1 does not hold, we go to Panel C of Figure 1, conduct robust dynamic estimation, apply White's test to the residuals from the robust filter, obtain the test statistic T2 123.88 (p-value 0.000), and thus reject homoscedasticity and no misspecification. Because T2 does not hold, we go to Panel D of Figure 1 and apply the sandwich estimator to achieve double robustification of inferences. Hence, our market data support use of the combined approach in Panel D for robust parameter estimation and doubly robust inferences.
5.9. Fit vs. Forecasts Trade-off Robustification induces a trade-off between in-sample fit and out-of-sample forecasts. To understand this, we use 104 observations to fit the model and hold out 52 observations to assess predictive accuracy. Table 2 reports the results. Panel A shows that the Kalman filter better fits the sample data (i.e., larger log-likelihood values) for all five provinces. By contrast, Panel B shows that the robust filter uniformly outperforms the Kalman filter on the out-of-sample predictions across the three metrics, i.e., mean squared error (MSE), mean absolute percentage error (MAPE), and mean absolute deviation (MAD), in all five provinces. This finding suggests that the out-of-sample data degrade the Kalman filter's performance much more than the robust filter's performance. The intuition is as follows.

Table 2. Fit vs. Forecasts Trade-off

Panel A: In-sample fit

Log-likelihood

Provinces

Kalman filter

Robust filter

Alberta Atlantic B.C. Ontario Prairies

-464.77 -450.07 -418.30 -580.75 -471.32

-466.68 -450.66 -419.77 -582.67 -472.89

Panel B: Out-of-sample prediction

MSE

MAPE (%)

MAD

Kalman Robust Kalman Robust Kalman Robust Provinces filter filter filter filter filter filter

Alberta

846.1 532.5 3.9

Atlantic 1,752.1 1,632.9 8.6

B.C.

501.2 394.9 3.7

Ontario 9,636.7 6,791.1 4.5

Prairies 1,193.3 893.8 6.7

3.1

22.1 17.4

8.3

32.2 31.2

3.3

18.3 16.4

3.8

70.3 59.5

5.8

27.5 24.0

In the estimation sample, the Kalman filter performs better than the robust filter because, by construction, the latter sacrifices up to 3.84 points on the 2-scale to eschew distributional assumptions; its benefit accrues in the holdout sample when the data generation process departs from normality or the assumed model is misspecified.

6. Dynamic Multimedia Allocation Under Conservatism
Given the robust estimation results, we tackle the budget allocation problem of the large public health agency whose objective differs from profit-maximization. Specifically, we seek insights into how managers should determine the optimal marketing budget and optimally allocate it to radio advertising and phone call communications. We investigate these issues next.
CBS manages each province independently and sets the collection targets. A deviation from the targets is costly because blood levels below the target create shortages, whereas levels above it generate waste (e.g., Brodheim and Prastacos 1979, Prastacos 1984). Because the cost of excess or shortage is asymmetric, we use the LINEX function (Varian 1975, Zellner 1986),

g(b, ) e-a(b-) + a(b - ) - 1,

(27)

where (b, ) are the actual and target blood levels and a > 0 controls the magnitude of asymmetry. In Equation (27), g( · ) represents the cost that exponentially increases as the shortage increases (i.e., b -  become more negative) due to the first term on the RHS; the cost grows linearly when the excess blood level increases (i.e., b -  become more positive) due to the second term on the RHS; the third term ensures that the cost is zero when b .
CBS allocates its marketing budget B(t) to radio advertising and phone calls to drive blood collections. To minimize the total cost of excess and shortage plus the marketing budget B(t), we specify the objective function

f (u1, u2) 



e-t e-a(b-) + a(b - ) - 1 + B(t) dt , (28)

0

where  is the discount rate, and the blood collection evolves according to







db 1 u1 + 2 u2 - b dt + q dW. (29)

Equation (29) is an equivalent continuous-time version
of the discrete-time blood dynamics in Equation (26). Comparing the two equations, we note that dW t dt denotes the increment of a standard Brownian motion,  1- , and u1(t) and u2(t) are the radio GRPs and the

464

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

number of phone calls. The marketing budget equals
B(t) c1u1(t) + c2u2(t), where c1 and c2 are the costs per GRP and phone call, respectively.
We want to identify the optimal strategies (u1 , u2 ) that minimize the total expected cost in Equation (28). To this
end, we define the value function

V(b) min(u1, u2) f (u1, u2) ,
which satisfies the Hamilton­Jacobi­Bellman (HJB) equation

V(b)

min [e-a(b-) + a(b - ) - 1 + B(t)]

(u1, u2)





+ Vb(1 u1 + 2 u2 - b) + qVbb/2 , (30)

where Vb V/b and Vbb 2V/b2. Equation (30) has three terms on its RHS. The first
term [e-a(b-) + a(b - ) - 1 + B(t)] represents the direct cost incurred every period. The second term, Vb(1 u1 + 2 u2 - b), consists of two parts, i.e., (i)the expected incremental blood collected [db/dt] 1 u1 + 2 u2 - b due to the marketing activities (u1, u2) and (ii) the valuation Vb of a pint of incremental blood. Thus, Vb(1 u1 + 2 u2 - b) adds the indirect contribution to the value function. The third term, qVbb/2, accounts for the dynamic uncertainty in blood collection, Var[db/dt].
Equation (30) is a second-order partial differential
equation (PDE). To solve this PDE, we first differenti-
ate its RHS with respect to (u1, u2) to obtain the FOCs and then substitute them back into (30) to eliminate
the minimization operator. Because blood collection
operates close to the target, we also expand g(b, ) by
the Taylor series around  and use Lagrange's method
of undetermined coefficients to fully characterize the
value function as follows:

V(b) A2(b - )2/2 + A1(b - ) + A0,

(31)

where the coefficients (A0, A1, A2) depend on the model parameters:

A2 A1 and A0

2 +  -

(

+ 2)2 + 2a2(21/c1 21/c1 + 22/c2

+

22

/c2

)

,

2(-( + 2) + ( + 2)2 + 2a2(21/c1 + 22/c2))

(21/c1 + 22/c2)( + ( + 2)2 + 2a2(21/c1 + 22/c2))

3(21/c1 + 22/c2)(A1 - A2)2 4

+

qA2

+

(2A1 + 2

(a2

-

A2 ))

.

Note that A1 is always positive and that A2 is always negative. Having analytically solved the PDE in (30), we present the optimal marketing strategies in Proposition 3.

6.1. Optimal Marketing Resource Allocations Proposition 3. The optimal marketing strategies are given by

ui

(K0i - K1i(b - ))2 if b < b~ ,

0

otherwise,

(32)

for i (1, 2), where

K0i

A1 i 2ci

> 0,

K1i

- A2i 2ci

> 0,

and b~ denotes the buffer level corresponding to the zero optimal marketing spends.

Equation (32) has the following properties. First, they are feedback (or closed-loop) strategies as a function of the state variable b. Second, they exhibit nonlinear state dependence due to (b - )2. Last, they operate so as to restore the target level .
To understand this last point, consider what happens when blood collection exceeds the target, i.e., b > . Because (b - ) > 0, optimal advertising should be reduced per (32) as b increases, which in turn suppresses the rate of blood collection due to Equation (29). On the other hand, when blood collection falls below the target, i.e., b < , optimal advertising should be increased because (b - ) < 0 in Equation (32), which in turn boosts the blood collection rate due to (29) and thus restores collection levels closer to the target. This mechanism to advertise more (less) when the state variable is small (large) is the opposite of the advertisingto-sales ratio heuristic, which recommends spending more (less) when sales are high (low), as used by forprofit companies (see, e.g., Farris et al. 1998).

6.2. Buffer Levels

Should forward-looking managers stop advertising

when the collection reaches the target or continue

advertising beyond the target? Proposition 3 shows

that optimal responds to

athdevebrutiffsienrglesvtoepl sb~when(1u+i

0, which cor). This buffer

level always exceeds the target because





-

+ (2 + )2 + 4(21/c1 + 22/c2) 2(21/c1 + 22/c2 + (r + ))

>

0.

Hence, forward-looking managers should not stop advertising even if they reach the target collections. Why? Because if they were to stop advertising at the target, the expected collection levels may soon fall below the target due to Equation (29), thus creating shortages. Anticipating this impending shortfall and responding to prevent it, the manager must continue to advertise to build a healthy buffer.
To provide further guidance on how much buffer level is "healthy," we empirically evaluate the optimal

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

465

buffer levels by taking 10,000 draws from the distribution of estimated parameters along with asymmetry parameter a 1 and the costs c1 $16 and c2 $2.2 obtained from the CBS' marketing team and  5% per annum discount rate. Results show that the optimal buffer level should be 44% larger than the actual target in Alberta; 77% larger in Atlantic; 43% larger in British Columbia; 33% larger in Ontario; and 65% larger in the Prairies. On average, CBS should maintain a 36% buffer over their collection targets.
6.3. Budget and Allocation How does the pursuit of conservatism affect the marketing budget? To answer this question, we evaluate Equation (32) for the optimal radio GRPs and phone calls in each of the five provinces. Table 3 reports the average weekly optimal marketing budget in each province. The optimal conservative and nonconservative budgets are about the same in the Prairies. However, the optimal conservative budget exceeds the nonconservative budget in Alberta by 7.8%, in British Columbia by 2.5%, and in Ontario by 4.6%. By contrast, the optimal conservative budget is below the nonconservative budget in Atlantic by 5%. Across the five provinces, the total conservative budget exceeds the nonconservative budget by 3.7%. Yet the optimal conservative budget is 54.4% below the actual budget; this shows that CBS overspends on marketing.
Besides overspending, how do they allocate the budget to radio versus phone advertising? For each province, Table 4 presents the optimal budget allocation to radio advertising as a ratio of the total optimal budget, i.e., c1u1 /B. The optimal allocation to

Table 3. Optimal Weekly Budgets

Alberta Atlantic B.C. Ontario Prairies Total

Kalman filter ( 0) ($)
10,662 7,493 8,152 72,327 8,372 107,006

Robust filter ( 1) ($)
11,493 7,121 8,355 75,651 8,346 110,966

radio advertising varies substantially across provinces from 0% to 56% with a median of 21%. Because the remaining budget is allocated to phone calls, the phone calls get (72%, 100%, 44%, 79%, 95%) in Alberta, Atlantic, British Columbia, Ontario, and the Prairies, respectively.
The median phone call allocation of 79% compared to radio advertising at 21% comports with their relative elasticities. Specifically, our estimation results (see Section 5.7) show that phone calls (radio advertising) elasticity is 0.29 (0.07). That is, personal phone calls are four times more effective than radio advertising. However, the heuristic of allocating budgets proportional to the relative elasticities does not uniformly apply to all provinces. For example, this heuristic would allocate 37% to radio advertising in British Columbia, whereas the optimal allocation recommends 56% (via Equation (32)), thereby resulting in a sub-optimal under-allocation to radio advertising.
6.4. Profit vs. Volatility Trade-off Robustification induces another trade-off: The total profit reduces, but so does its volatility. Conservatism influences the long-term profit level and its variability differentially. For this insight, we compute the expectation of the value function for various levels of conservatism. We represent the value function as the negative of the total cost function and interpret it as the longterm profit. That is, we evaluate and plot ((V) 0 - (V) )/E(V) 0 for different values of  from zero to unity. This scaled expectation measures the percentage profit reduction as a function of conservatism. Similarly, we compute the variance of the value function V(b), i.e., (var(V) 0 - var(V) )/var(V) 0. This scaled variance quantifies the percentage volatility reduction as a
Figure 3. (Color online) Impact of Conservatism on Profit and Its Variance
50 % drop in the volatility of the value function
40

Table 4. Optimal Radio Allocationa

30

Kalman filter ( 0) (%)

Robust filter

( 1) (%)

20

Alberta

37

Atlantic

0

B.C.

60

Ontario

22

Prairies

8

Total

24

28

0

56

10

21

5

22

aThe remaining budget is allocated to phone call communications.

% drop in the expectation of the value function

0.2

0.4

0.6

0.8

1.0

466

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

Table 5. Optimal Robustness


Alberta Atlantic B.C. Ontario Prairies

 0.003
0.520 0.000 0.999 0.999 0.001

 0.03
1.000 0.000 1.000 1.000 0.169

 0.3
1.000 0.521 1.000 1.000 1.000

function of conservatism. Figure 3 presents the results for the Alberta province. It reveals that, as conservatism increases, the profit reduction increases above 10% at  1, but the volatility reduction increases more sharply, beyond 50% at  1. The plots for other provinces (not shown for brevity) are qualitatively similar. This profit-volatility trade-off is reminiscent of the returns-risk trade-off in finance; for example, a more conservative investor can add more bonds to the portfolio and thus reduce returns as well as volatility. To determine optimal conservatism,1 we combine profit and volatility to formulate U() (V) -  var(V), where  denotes the risk aversion coefficient, and thus obtain  arg max01 U(). We apply NMaximize in Mathematica 10.1 and report  for various values of  in Table 5. For example, when risk aversion is small  0.003, managers should be least robust in Atlantic and the Prairies, moderately robust in Alberta, and most robust in British Columbia and Ontario.
7. Conclusions
Optimal budgeting and allocation of marketing resources over time require estimation of dynamic models (see, e.g., Gatignon 1993, Mantrala 2002, Shankar 2008, Gupta and Steenburgh 2008). Virtually all estimation methods assume that error terms follow the Normal distribution or some other probability distribution, parametric or nonparametric. When the data generation process differs from the assumed probability distribution, model misspecification arises. The extant literature recognizes the seriousness of this misspecification problem and recommends using the sandwich estimator (White 1980) to "correct" the statistical inferences. However, although the sandwich estimator affects statistical outcomes such as inference, it does not alter the managerial actions of budgeting and allocation because the estimated parameters remain unchanged, with or without this correction. Consequently, despite White's (1980) sandwich estimator, managers continue to risk misallocating marketing resources in the presence of misspecification. This was our motivation to develop a method for robust dynamic estimation. We apply minimax control theory to derive the robust filter for a general time-varying multivariate dynamic linear model without making any distributional assumptions. Specifically, we first

derive the optimal disturbances in Proposition 1 via Pontryagin's Maximum Principle. Then, using the optimal disturbances, we derive the robust filter recursions in Proposition 2. The robust filter safeguards against the misspecification risk inherent in making distributional assumptions. Furthermore, it reveals two new insights, i.e., (i) the robust gain matrix optimally enhances the weight on observed data compared to the Kalman filter, and (ii) the robust filter nests the Kalman filter as   . In other words, the Kalman filter is the least conservative in the family of conservative filters indexed by .
Applying the proposed method in the context of blood donation marketing, we find that the estimated effectiveness of marketing activities increases and the carryover effect decreases as conservatism increases. This compensatory effect generalizes across the five English-speaking Canadian provinces. We also uncover the novel finding that personal (i.e., phone call) communications are four times more effective than mass (i.e., radio) advertising. In Proposition 3, we further prove that nonprofit organizations should optimally advertise more (less) when sales are low (high), which is the opposite of the advertising-to-sales ratio heuristic used by for-profit companies. Finally, we find that robustification improves out-of-sample predictions and induces a profit-volatility trade-off.
We close by noting how to use the robust dynamic estimation. Operationally, users should make two small changes: (1) Replace the Kalman gain matrix with the new robust gain matrix in (17); and (2) Replace the prior covariance matrix with the new robust covariance matrix in (18). Specifically, replace the usual Kalman gain matrix K~ t Pt-Zt(Zt Pt-Zt + Ht)-1 with the robust gain matrix Kt Pt(I - Pt/ + Zt Ht-1Zt Pt)-1Zt Ht-1. Similarly, replace the usual prior covariance in period (t + 1) with Pt+1 Tt Pt(I - Pt/ + Zt Ht-1Zt Pt)-1Tt + Qt. Both the robust gain and covariance matrices involve subtraction of the matrix (Pt/), which is computationally simple. This small, but important, change yields the robust filter in Panel C. It optimally inflates the gain and covariance matrices (since the subtraction is inside an inverse operation) and places a greater weight on the market data (i.e., induces present-orientedness), thus accommodating more scenarios to consider when making decisions. Users can then perform the tests T1 and T2 to decide which method and results to use in their empirical contexts.
Acknowledgments The authors thank seminar participants at École Polytechnique Fédérale de Lausanne, McGill University, Rutgers University, Tsinghua University, the University of California Davis Statistics Department, University of Alberta, University of California, Irvine, University of Michigan, and University of South Carolina for their helpful suggestions. The

Rubel and Naik: Robust Dynamic Estimation Marketing Science, 2017, vol. 36, no. 3, pp. 453­467, © 2017 INFORMS

467

authors also gratefully acknowledge the support of the Canadian Blood Services for providing the data and insights into blood donation marketing.
Endnote
1 We thank the area editor for this suggestion.
References
Albers S, Mantrala MK, Sridhar S (2010) Personal selling elasticities: A meta-analysis. J. Marketing Res. 47(5):840­853.
Aravindakshan A, Rubel O, Rutz O (2014) Managing blood donations with marketing. Marketing Sci. 34(2):269­280.
Ataman MB, Mela CF, van Heerde HJ (2008) Building brands. Marketing Sci. 27(6):1036­1054.
Banavar RN (1992) Linear dynamic estimation. Unpublished doctoral dissertation, University of Texas, Austin.
Baar T, Bernhard P (1995) H-Optimal Control and Related Minimax Design Problems: A Dynamic Game Approach (Birkhäuser, Boston).
Biyalogorsky E, Naik PA (2003) Clicks and mortar: The effect of online activities and offline sales. Marketing Lett. 14(1):21­32.
Brockwell PJ, Davis RA (1996) Introduction to Time Series and Forecasting (Springer, New York).
Brodheim E, Prastacos GP (1979) The Long Island blood distribution system as a prototype for provincial blood management. Interfaces 9(5):3­20.
Bruce N (2008) Pooling and dynamic forgetting effects in multitheme advertising: Tracking the advertising sales relationship with particle filters. Marketing Sci. 27(4):659­673.
Bruce NI, Peters K, Naik PA (2012) Discovering how advertising grows sales and builds brands. J. Marketing Res. 49(6):793­806.
Corstjens M, Merrihue J (2003) Optimal marketing. Harvard Bus. Rev. 81(10):114­121.
Eicker F (1963) Asymptotic normality and consistency of the least squares estimator for families of linear regression. Ann. Math. Statist. 34(2):447­456.
Eicker F (1967) Limit theorems for regression with unequal and dependent errors. Le Cam LM, Neyman J, eds. Proc. Fifth Berkeley Sympos. Math. Statist. Probab. (University of California Press, Berkeley, CA), 59­82.
Farris P, Shames ER, Reibstein DJ (1998) Advertising Budgeting: A Report from the Field (American Association of Advertising Agencies, New York).
Fisher RA (1922) On the mathematical foundations of theoretical statistics. Philos. Trans. Roy. Soc. A 222:309­368.
Gatignon H (1993) Marketing mix models. Eliashberg J, Lilien GL, eds. Handbooks in Operations Research and Management Science, Marketing, Vol. 5 (North-Holland, Amsterdam), 697­732.
Gupta S, Steenburgh TJ (2008) Allocating marketing resources. Kerin RA, O'Regan R, eds. Marketing Mix Decisions: New Perspectives and Practices (American Marketing Association Publication, Chicago), 3­37.
Harvey AC (1989) Forecasting Structural Time Series Models and the Kalman Filter (Cambridge Universtity Press, Cambridge, UK).
Hinkley DV (1977) Jacknifing in unbalanced situations. Technometrics 19(3):285­292.
Huber PJ (1967) The behavior of maximum likelihood estimates under nonstandard conditions. Le Cam LM, Neyman J, eds. Proc. Fifth Berkeley Sympos. Math. Statist. Probab. (University of California Press, Berkeley, CA), 221­233.
Kalman RE (1960) A new approach to linear filtering and prediction problems. J. Basic Engrg. 82(March):35­45.
Kolsarici C, Vakratsas D (2015) Correcting for misspecification in parameter dynamics to improve forecast accuracy with adaptively estimated models. Management Sci. 61(10):2495­2513.
Koop G, Korobilis D (2010) Bayesian multivariate time series methods for empirical macroeconomics. Foundations Trends Econometrics 3(4):267­358.

Krever H (1998) Commission of Inquiry on the Blood System in Canada. Minister of Supply and Services, Ottawa, Ontario, Canada. http://publications.gc.ca/collections/Collection/CP32-62 -3-1997-1E.pdf.
Kumar V, Mirchandani R (2012) Increasing the ROI of social media marketing. MIT Sloan Rev. 54(1):55­61.
Lachaab M, Ansari A, Jedidi K, Trabelsi A (2006) Modeling preference evolution in discrete choice models: A Bayesian state-space approach. Quant. Marketing Econom. 4(1):57­81.
Little JDC (1975) BRANDAID: A marketing-mix model, Part 1: Structure and Part 2: Implementation, calibration and case study. Oper. Res. 23(4):628­673.
Liu Y, Shankar V (2015) The dynamic impact of product-harm crises on brand equity and advertising effectiveness: An empirical analysis of the automobile industry. Management Sci. 61(10):2514­2535.
Lütkepohl H (2005) New Introduction to Multiple Time Series Analysis (Springer, Berlin).
Mantrala M (2002) Allocating marketing resources. Weitz BA, Wesley R, eds. Handbook of Marketing (Sage, London), 409­435.
Naik PA, Mantrala MK, Sawyer AG (1998) Planning media schedules in the presence of dynamic advertising quality. Marketing Sci. 17(3):214­235.
Naik PA, Prasad A, Sethi SP (2008) Building brand awareness in dynamic oligopoly markets. Management Sci. 54(1):129­138.
Nichols W (2013) Advertising analytics 2.0. Harvard Bus. Rev. 91(3):60­68.
Prastacos G (1984) Blood inventory management: An overview of theory and practice. Management Sci. 30(7):777­800.
Raudenbush SW, Bryk AS (2002) Hierarchical Linear Models: Applications and Data Analysis Methods, 2nd ed. (Sage, Thousand Oaks, CA).
Rubel O, Naik PA, Srinivasan S (2011) Optimal advertising when envisioning a product-harm crisis. Marketing Sci. 40(6): 1048­1065.
Sethi SP, Thompson GI (2000) Optimal Control Theory: Applications to Management Science and Economics (Springer, New York).
Sethuraman R, Tellis GT, Briesch RA (2011) How well does advertising work? Generalizations from meta-analysis of brand advertising elasticities. J. Marketing Res. 48(3):457­471.
Shankar V (2008) Strategic allocation of marketing resources: Methods and insights. Kerin RA, O'Regan R, eds. Marketing Mix Decisions: New Perspectives and Practices (American Marketing Association, Chicago), 154­183.
Shumway RH, Stoffer DS (2011) Time Series Analysis and Its Applications. With R Examples (Springer-Verlag, New York).
Simon D (2006) Optimal State Estimation: Kalman, H-infinity, and Nonlinear Approaches (John Wiley and Sons, Hoboken, NJ).
Theodor Y, Shaked U (1994) Game theory approach to H-optimal discrete-time fixed-point and fixed-lag smoothing. IEEE Trans. Automatic Control 30(9):1944­1948.
Vakratsas D, Feinberg FM, Bass FM, Kalyanaram G (2004) The shape of advertising response function revisited: A model of dynamic probabilistic thresholds. Marketing Sci. 23(1):109­119.
van Heerde HP, Gsenberg GJ, Dekimple MG, Steenkamp JB (2013) Price and advertising effectiveness over the business cycle. J. Marketing Res. 50(2):177­193.
Varian H (1975) A Bayesian approach to real estate assessment. Feinberg SE, Zellner A, eds. Studies in Bayesian Econometrics and Statistics in Honor of L.J. Savage (North-Holland, Amsterdam), 195­208.
Wald A (1950) Statistical Decision Functions (John Wiley, New York). West M, Harrison J (1997) Bayesian Forecasting and Dynamic Models
(Springer-Verlag, New York). White H (1980) A heteroskedasticity-consistent covariance matrix
estimator and a direct test for heteroskedasticity. Econometrica 48(4):817­838. White H (1982) Maximum likelihood estimation of misspecified models. Econometrica 50(1):1­25. Zames G (1981) Feedback and optimal sensitivity: Model reference transformations, multiplicative seminorms, and approximate inverses. IEEE Trans. Automatic Control 26(2):301­320. Zellner A (1986) Bayesian estimation and prediction using asymmetric loss functions. J. Amer. Statist. Assoc. 81(394):446­451.

