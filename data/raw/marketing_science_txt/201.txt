http://pubsonline.informs.org/journal/mksc/

MARKETING SCIENCE
Vol. 36, No. 4, July­August 2017, pp. 542­564 ISSN 0732-2399 (print), ISSN 1526-548X (online)

Optimizing Click-Through in Online Rankings with Endogenous Search Refinement

Babur De los Santos,a Sergei Koulayevb
a John E. Walker Department of Economics, Clemson University, Clemson, South Carolina 29634; b Consumer Financial Protection Bureau, Washington, DC 20552 Contact: babur@clemson.edu (BDlS); sergei.koulayev@gmail.com (SK)

Received: June 19, 2013 Revised: December 30, 2014; April 7, 2016; July 14, 2016 Accepted: September 5, 2016 Published Online in Articles in Advance: June 15, 2017
https://doi.org/10.1287/mksc.2017.1036
Copyright: © 2017 INFORMS

Abstract. Consumers engage in costly searches to evaluate the increasing number of product options available from online retailers. Presenting the best alternatives at the beginning reduces search costs associated with a consumer finding the right product. We use rich data on consumer click-stream behavior from a major web-based hotel comparison platform to estimate a model of search and click. We propose a method of determining the ranking of search results that maximizes consumers' click-through rates (CTRs) based on partial information available to the platform at the time of the consumer request, its assessment of consumers' preferences, and the expected consumer type based on request parameters from the current visit. Our method has two distinct advantages. First, we endogenize a consumer response to the ranking using search refinement tools, such as sorting and filtering of product options. Accounting for these search refinement actions is important since the ranking and consumer search actions together shape the consideration set from which clicks are made. Second, rankings are targeted to anonymous consumers by relating price sensitivity to request parameters, such as the length of stay, number of guests, and day of the week of the stay. We find that predicted CTRs under our proposed ranking are almost double those of the platform's default ranking.

History: K. Sudhir served as the editor-in-chief and Jean-Pierre Dubé served as associate editor for this article.
Supplemental Material: Data and the online appendix are available at https://doi.org/10.1287/ mksc.2017.1036.
Keywords: consumer search · website design · search refinement · targeting · clickstream analysis · website morphing · customization · Internet marketing · sorting · filtering

1. Introduction
In the past decade, Internet commerce has achieved significant advances in the reach and complexity of recommendation systems that shape consumer choices in almost all areas of commerce. Consumers search for product information in online search engine results to evaluate a wide range of products, such as electronics, books, mortgages, hotel rooms, and flights. Although the problem of optimal recommendation is not new (salespeople have long struggled with choosing which product to endorse to a consumer) the majority of consumer information generated online has revolutionized the way firms collect and analyze consumer data, customize product choices, and target product recommendations (see, e.g., Ansari and Mela 2003).
At the core of product recommendations is the challenge of matching a set of products to a set of consumers whose tastes are heterogeneous and often unobserved. The accuracy of the match depends on how firms leverage available information to infer consumer preferences. For example, Amazon makes recommendations in diverse product categories by exploiting product correlations present in other consumers' transaction

histories. Although potential buyers' preferences for a new product are unobservable, modern recommendation systems are typically based on the notion that preferences for various products are similar across the set of consumers who bought or rated other products in a similar way. This is the underlying assumption of collaborative filtering and other hybrid methodologies, including those presented by Anderson et al. (2003), Basilico and Hofmann (2004), Huang et al. (2004), Melville et al. (2002), Vozalis and Margaritis (2004), Yu et al. (2003), and Moon and Russell (2008).
Unfortunately, the collaborative approach is infeasible in the case of anonymous consumers, for whom the platform has no knowledge of past choices, but who comprise a substantial share of all platform visitors. Generally, recommendations for such visitors can be made using distributional information about unobserved tastes, which is inferred from past choices made by other users. One such example is the website morphing literature that enables a website to learn the latent cognitive style of a consumer and morph the content or the "look and feel" of a website to maximize click-through rates (CTRs) or serve the most effective banner advertising (Hauser et al. 2009, Urban et al.

542

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

543

2014). An alternative to collaborative methods for recommendation rankings is utility-based discrete choice models (for instance those presented by Ansari et al. 2000, Schaupp and Bélanger 2005, Burke 2000; for an overview, see Ricci et al. 2011).
This paper proposes a utility-based model in which consumers' search actions and clicks are jointly determined. Based on this model, we propose a method of determining a targeted ranking that maximizes consumers' CTRs based on partial information available to the platform at the time of the request. By considering search actions and clicks together, we follow the recent literature that incorporates search into discrete choice models of consumer demand. Notably, Kim et al. (2010) use aggregate consumer search data from Amazon to estimate demand models of durable products. Other papers, such as De los Santos (2017), Ghose et al. (2014), and Koulayev (2014), incorporate search activity at the consumer level.
Our model explicitly accounts for the endogeneity of consumers' search refinement actions, such as sorting and filtering, as well as the diverse ways in which consumers combine these tools to navigate search results. Accounting for search actions is important because the composition of consideration sets is a result of a twoway interaction between product rankings and consumer search. On one hand, the use of search refinement tools alters the presentation of results in a way that is independent of the ranking, often undermining its impact on consumer choice. On the other hand, the ranking itself changes the way consumers search, an effect that must be taken into account when evaluating an alternative means of ranking.
Our proposed ranking maximizes the predicted CTR by manipulating displays in a way that anticipates the kinds of hotels that a consumer would find through her own search actions. Intuitively, a superior ranking attempts to strike a balance between two goals, i.e., helping the user save on search costs by presenting relevant results earlier and stimulating exploration. Suppose we expect that a consumer will sort results by increasing price and then advance to the pages of modestly priced hotels. What would be the optimal composition of the initial display before the sorting action? It would include some lower-priced hotels so as to preempt the user's own search action and perhaps motivate her to explore other types of hotels. It would also include some higher quality, higher priced hotels to diversify the user's choice set in case she decides to continue with price sorting. Thus, the key element of our model is a structural link between current display contents and the consumer decision on whether to continue searching and which search tools to use. In our application, we use click-stream data from a major online travel platform to show the validity of this modeling approach. The link between past displays

and future search actions has also been explored by Montgomery et al. (2004), who use a dynamic probit model to show that search actions exhibit a strong "memory" where the types of products that have been recently viewed by the consumer may predict her next search action. In a closely related paper, Chen and Yao (2016) demonstrate that search refinement tools complement the default ranking, encouraging more search and higher CTRs. The main difference between the two studies is the notion of search: While Chen and Yao (2016) consider the click itself as a search action, we abstract from the click-related uncertainty and focus on modeling the search refinement actions. In a related paper, Fradkin (2017) analyzes consumer search behavior in the peer-to-peer lodging rental platform Airbnb, including the use of search refinement strategies.
In addition, we present a targeted recommendation ranking that maximizes the CTR using product and other information about a consumer available to the platform at the time of the search request. This approach is similar to the website morphing literature, but instead of learning about consumer's cognitive styles, the main objective is to learn about consumers' preferences. In our application, consumers are anonymous to the online platform but relevant observable information is available in the current consumer visit. In particular, we show that the request parameters affect a consumer's outside option and are a primary source of information about consumer preferences, especially informing us of their price sensitivity. For instance, a search request for a hotel room on an online travel platform, which includes the date of the stay and the number of guests, reveals that the consumer is more likely to be a business traveler if the stay is on a weekday, if the room request is for single occupancy, and if the request was made fewer (versus more) days in advance of the stay. This allows us to optimally serve a consumer with a ranking that maximizes the CTR.
An important consideration is unobserved consumer preferences. We propose that a significant portion of heterogeneity can be inferred from the request parameters. After controlling for request parameters, there remains a significant unobserved component in consumer tastes. Using past clicks and search choices made by other consumers, we infer the shape of the distribution of that component, which we then use in the construction of a targeted ranking.
The closest work to this paper is by Ghose et al. (2012), who incorporate user-generated content (e.g., online hotel reviews) into a recommendation ranking. Our approach differs in that we explicitly account for a consumer's search refinement actions in the construction of the ranking and the targeted methodology based on available consumer information.
We compare the performance of optimal ranking from the search and click random coefficients model with various alternative rankings, including the default

544

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

ranking implemented by the platform. The ranking based on the search and click model leads to an almost two-fold increase in CTR compared to the default ranking. Additionally, we compare performance of the optimal ranking to different discrete choice specifications (in terms of clicks) that do not endogenize consumer search. By doing so, the optimal ranking increases the CTR by 4% to 5% compared to a utility-based ranking from a static discrete choice model. This is a nontrivial gain for a web platform with millions of visitors per month. The search and click model not only provides a better fit in terms of search actions and clicks but also provides a better fit in terms of clicks conditional on observed search behavior. The search model can better explain clicks because it uses inequalities imposed by search decisions to update expectations about the distribution of consumer tastes. Intuitively, our targeted ranking places preferred alternatives higher in the search results. This leads to an increase in CTR not only because it saves consumers the effort of evaluating inferior alternatives but also because of the well known phenomenon that consumers are more likely to click on higher ranked positions (e.g., Lohse 1997, Joachims et al. 2005).
The rest of the paper is organized as follows. Section 2 presents a theoretical model of search and click, followed by a discussion of our modeling assumptions. Section 3 outlines our approach to estimating the model from the data, including construction of the likelihood function and its simulation. Section 4 formally defines the problem of optimal ranking, presents our solution to the issue of dimensionality involved in this problem, and concludes with a simple two product example. Section 5 presents the data, discusses identification and our solution to the problem of price endogeneity, and concludes with estimation results. Section 6 presents evaluations of alternative ranking methods. Section 7 concludes with managerial implications. Our findings highlight the practical and methodological relevance of utility-based discrete choice models that help to optimize CTRs by creating a more relevant ranking of highly differentiated products to users of online platforms.
2. A Model of Consumer Search and Click
In this section, we present a model of consumer choice where search and click decisions are jointly determined. A consumer searches for a hotel room on an online travel platform by initiating a request that includes the city, dates of stay, and number of guests. The platform responds with a display of hotel alternatives that satisfy the consumer's request and are ranked according to the platform's recommendation system. After observing the first page of ranked results, the consumer can browse the pages of additional hotel options, sort the results by some hotel characteristic (such as price, distance to city center, star rating, etc.) or

filter the results according to one or more parameters of these characteristics.
We model the interaction between the attractiveness of the current display to the consumer and the consumer's choice of how to search and which hotels to click. The consumer's decision to use these search tools (including browsing, sorting, and filtering) is endogenous, as it is affected by the ranking and the consumer's preferences. Use of these tools may produce a different set of results for each consumer. Therefore, the consumer's search session is a sequence of search actions and the corresponding hotel displays that result from those actions. On each resulting display, the consumer may click on any hotel to reveal additional information about that option.
The model shares the same cost-benefit trade-off as the Weitzman (1979) model, i.e., a consumer will perform the next search action only if the expected gains of the search exceeds the search cost. However, there are two main departures from the Weitzman model. First, at every step the consumer in our model has multiple options on how to search, each offering a distinct distribution of the gains from search. Second, even if we fix a particular search strategy (as in Weitzman), in our case the distribution of gains from search is changing across every search attempt. Hence the reservation values are nonstationary as they change with each search action. The latter property allows us to rationalize recalling behavior, that is, instances where a consumer returns to a previously found alternative; the Weitzman sequential model cannot explain this.
2.1. Click Model Let i index consumers, j index hotels, and t 1, . . . , Ti index displays that a consumer observes during a search process of length Ti. A display is a ranked set of hotels, denoted by Dti. Taking this display as given, we first consider a model that predicts which hotel(s) on the current display will be clicked. Then, we examine consumers' choice of search actions.
The attractiveness of a hotel j  Dti for consumer i is measured by click utility uij. In general, because the consumer has limited information about a hotel at the click stage, this click utility is not the actual utility from staying at the hotel. Rather, uij can be interpreted as an expected utility, which will be refined after the consumer clicks through and finds additional information on the hotel's details page.
Even though consumers observe many hotels during their search, only a few are clicked. The relative rarity of hotel clicks indicates that clicks are costly (for example, due to the cost of processing information on the landing page). Structural models of costly clicks, such as those cited in Ghose et al. (2012), imply that a click is made only if the utility of the clicked hotel exceeds a certain consumer-specific threshold. In our

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

545

model, we capture this effect in reduced form by introducing an outside option, the ui0, so that a hotel is clicked only if its value exceeds this threshold. We further assume that at most one click per page can be made; this assumption simplifies computations. The data show that fewer than 2% of displays have more than one click per display, making this a reasonable assumption.
Together, our assumptions imply that a hotel j  Dti is clicked if and only if it is the best hotel on the page and its value exceeds the outside option

uij > ui0,

(1)

uij  uik ,  k  Dti.

(2)

Clicks depend on past search actions to the extent that past searches lead to the discovery of the clicked hotel. Clicks also affect future search actions by providing a fallback option, or status quo, as an alternative to future searches. Specifically, the current period's status quo is defined as

u

 ti



max{ u i j

|

j



{0},

D1i

,

.

.

.

,

Dti

}.

(3)

In other words, it is the utility of the best hotel found so far, including the value of the outside option. As we observe clicks, we also observe the identity of the best hotel across periods.

2.2. Choosing a Search Action
After display Dti is observed, the consumer contemplates the next search action. There are three major
categories of search actions, i.e., browsing through
pages of search results, sorting the results according to
certain product attributes (such as price or distance),
and filtering results according to a consumer-supplied
parameter over a product attribute. Within sorting and
filtering, there are parameters that can be fine-tuned,
resulting in dozens of search refinement options avail-
able in each period. Let Ati denote the choice set of search tools available to consumer i after display Dti is observed, and let a  Ati be an element of this set.
The choice of a particular search action ati  Ati will produce the next set of results, D(t+1)i. However, the effect of a given search action on search results will
also depend on the combination of search actions used
in previous periods. These past search actions can be
summarized by what we call a "search state," Sti S(a1i , a2i , . . . , a(t-1)i). The current period's search state is the specification of sorting and filtering parameters
that are applied in the current period. When making a choice ati  Ati, the consumer takes the search state as given.
For example, after an initial consumer request and
an automatic search action, a1i, is performed by the platform, suppose the consumer refines the search by

sequentially sorting by price and distance to the city, and filtering the last set of results

a1i {"default sorting"}, a2i {"sort by price"}, a3i {"sort by distance to city center"}, a4i {"filter price between $200 and $300"}.

After these search actions, the search state in period 5

is such that results are sorted by distance to city center,

and only hotels priced between $200 and $300 per night

are shown. The sorting actions in periods t 1, 2 are

not part of the search state because they were undone

by the sorting by distance action in period 3. If the

consumer now decides to change the price filter, she

knows that the results will still be sorted by distance.

If she decides to sort by price, then she knows that

only hotels in the [200, 300] range will be shown, not

necessarily the cheapest hotels.

In addition to the consumer's search action and the

search state, the third determinant of the next period's

display is the condition of the market, such as hotel

availability and prices. This last factor introduces ran-

domness into the contents of the next display: If the

consumer was aware of the full set of market conditions

there would be no need for a search. Consumer beliefs

about the contents of the next page following the choice

of search action ati in a search state Sti are denoted by the probability distribution H(D(t+1)i | ati , Sti).
Each search action is costly, and each consumer

incurs a search cost, ci, for each action, which is drawn from a common probability distribution. The benefit of

a search action is the possibility of improvement over

the

current

best

utility,

u

 ti

.

To

compute

the

expected

benefit of search, we translate consumer beliefs over

sets of hotels, H(D(t+1)i | ati , Sti), into beliefs over a single dimensional parameter, i.e., maximum utility

among hotels on the next page, u~(t+1)i max{uij | j  D(t+1)i }. Denote this belief as Fi(u~ | ati , Sti). Note that
while belief H is common across all consumers who are

in the same search state, the belief Fi also depends on preferences and will vary with unobserved consumer

type. In Section 3.2 we discuss how beliefs H and Fi might be approximated using the available data.

The search choice is a two-stage decision: A con-

sumer decides which search action to use and whether

to continue the search. The first part is decided by eval-

uating the expected gain associated with each available

search action, a  Ati,

 +

Gtai

(u

 ti

)

max(u~

-

u

 ti

,

0)

d

Fi

[u~

|

a

,

Sti

],

(4)

-

and choosing the action that delivers the highest improvement. The consumer continues searching if and only if the payoff from the best tool exceeds search cost

Gtai

(u

 ti

)

>

ci ,

(5)

Gtai

(u

 ti

)



Gti(a, uti),

 a  Ati.

546

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

An alternative way to present this choice is by using the concept of reservation utility for each search action, defined as

 +

r¯tai (c i ):

(u~ - r¯) dFi[u~ | a, Sti] ci ,  a  Ati . (6)

r

By definition, reservation utility is the expected gain

from a search such that a consumer is indifferent be-

tween searching and not searching. Clearly, for any

alternative action, a , we have r¯tai(ci) > r¯tai (ci) if and only

if

Gtai (uti

)

>

Gtai

(u

 ti

).

We assume that the reservation utility may vary

across consumers via an alternative specific i.i.d. ex-

treme value type 1 shock, ij. The reservation utility can be expressed as

rtai(ci) r¯tai(ci) + ij .

(7)

This shock incorporates possible differences among consumers as to the distribution of search results; hence we allow for heterogeneity in consumers' beliefs about Fi(u). On the empirical side, we find this assumption necessary to rationalize the observed choices of search actions by consumers. The difficulty of rationalizing discrete choices in a dynamic context is a well known problem, first documented by Rust (1987). In our context, this problem arises because the number of search alternatives in the consumer choice sets is much larger than the number of dimensions by which these alternatives differ (that is, the mean and variance of search results).
Similar to (5), the consumer will optimally choose the search action with the highest reservation utility provided that it exceeds the value of the status quo

rati ti



rtai ,

 a  Ati , t

2, . . . , T - 1,

(8)

rati ti



u

 ti

,

(9)

where ati is the choice actually made by consumer i in period t. A consumer will stop searching if all reserva-
tion utilities fall below the status quo

rtai



u

 ti

,

 a  Ati , t

T.

(10)

Inequalities (1), (2), (8), and (9) describe how consumers make search and click decisions in our model. These inequalities can be integrated out, with respect to quantities that are unobserved to the researcher, to obtain the main outcome of interest, i.e., the probability that a random visitor would make a click. For managers of the search aggregator, the model outlined above provides a structural link between the ranking and the click probability. This can be exploited to evaluate counterfactual rankings.

2.3. Discussion In our case, the search aggregator provides consumers with flexible search tools (e.g., sorting and filtering)

to help them navigate through hundreds of hotel (and airline) options. The fact that a consumer can use any of these search refinement tools in any combination increases the number of consumer search strategies. A structural approach to modeling the full set of potential search strategies is infeasible. To overcome this hurdle, we adopt a one-step lookahead approach where the consumer is building her search strategy step by step: At each subsequent page, she decides which search tool to use next. In this way, she only considers the immediate gains from searching, but does not consider the option value given by the possibility of continuing to search after the next set of results. Therefore, the reservation value in (6) is an approximation of the true continuation value of choosing a particular search action. We offer two rationales for this assumption.
First, the goal of our study requires a credible simulation of the effects of a recommendation ranking on consumer search. To this end, our model must rationalize a wide variety of search actions that are observed in the data. We achieve this by using an approximate solution to the choice of search strategy by structurally modeling only the dominant search strategies (similar to Koulayev 2014).
Second, this is a reasonable approximation if a consumer who considers only immediate benefits of search may fail to take action in situations where the benefits are negative but the option value of searching further outweighs that loss. An example is browsing after price sorting: A consumer may not be interested in the cheapest hotel available but must take a costly action (price sorting) for a chance to consider other options by browsing the price-sorted alternatives. Fortunately, our data includes the time a consumer spent on a page, which helps in evaluating the incidence of such errors. The amount of time spent indicates that a consumer would spend very little time on results in which she is not interested. In our data, we observe 1,282 search sessions where consumers browse alternatives after price sorting. Specifically, we find that in only 3% of search-action pairs did consumers spend fewer than 10 seconds on the first page of price-sorted results, and more than 15 seconds on the second page. By contrast, in 16% of search-action pairs consumers spent more than 15 seconds on the first page and fewer than 10 seconds on the second page. In the remaining observations, consumers spent similar amounts of time on both pages.
Another type of error that our approximation may introduce is in the choice of search action, as in (5). A consumer from our model may fail to choose a search action with less immediate benefit but higher option value than other search tools: differences in option values among search options matter, although the technological features of this platform suggest that these differences are probably negligible. This is because almost

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

547

all search actions are available for use at any point during the search, so that a particular search choice in the current period does not represent a commitment to a particular search path in the future. Because the set of future search opportunities does not vary with the selected search action, the option values may not vary a great deal.

3. Empirical Specification
3.1. Click Utility A consumer's choice is represented by a click on one of the hotels and indicates that the clicked hotel is more attractive than other hotels on the same display. This revealed preference approach to clicks is corroborated by previous studies, such as Joachims et al. (2005) and Brynjolfsson and Smith (2000), who compared click choices to actual purchases and found that clicks provide a reasonable proxy for the preferences of an average consumer.
The model of click utility is

uij ipij + iXj + iLij + ij.

(11)

Parameter i measures a consumer's price sensitivity; i is a vector of tastes for a set of nonprice characteristics, Xj, that can be observed on the display, i.e., brand, star rating, neighborhood, and distance to city center. The parameter i measures the effect of the hotel's position in the display, Lij, on the probability of clicking. Figure 1 shows that, on average, consumers are more
likely to click on hotels at higher positions. We interpret i Lij as being related to the cost of within-page search rather than being part of inherent consumer utility that is attributable to hotel characteristics, i pij + i Xj. Although this distinction is not important for predic-
tion of clicks, it will be important for the recommendation ranking. Last, ij are i.i.d. type I extreme value error terms that represent a consumer's idiosyncratic
preference for a particular hotel.
The utility of the outside option is given by

ui0 0 + 1Ri + i0,

(12)

where Ri is a vector of parameters of request submitted by consumer i. These include the number of peo-
ple staying in the room, dates of search, and dates of

Figure 1. (Color online) Clicks by Page Reached and Position





.UMBEROFCLICKS                                                            

















0OSITIONANDPAGE

Notes. The figure shows a breakdown of clicks by position and page where the click occurred. There are 15 results per page. The figure is truncated to the first four pages of results.

548

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

stay. From this information we derive whether the trip includes a weekend, the number of days of the stay, and advance purchase length. For example, a consumer who is searching further in advance might have a higher value for the outside option due to the possibility of searching later, or they may have less flexible plans.
Taste heterogeneity in our model arises due to differences in parameters of request, as well as unobserved heterogeneity

i 0 + 1Ri + ~i ,

(13)

ln(-i) 0 + 1Ri + ~ i ,

(14)

where 0 is the vector of baseline tastes, 1 is the matrix of interaction terms, and ~i  N(0, ) are consumerspecific deviations from the mean. The parameter i is a consumer-specific price coefficient, which includes
interaction terms with parameters of request, and ln(~ i)  N(0, ).

3.2. Approximation of Beliefs
Before taking a costly search action, a consumer formulates a belief about the contents of the next page that she would observe in the next period, denoted as H(D(t+1)i | a, S), where a is the search action and S is the search state. In the estimation, we approximate H with an empirical distribution of pages that were actually observed by consumers who took action a in state S. In our application, we construct beliefs for action-state pairs (a, S) for which we have at least 50 observations. Because we cannot construct adequate approximations of consumer beliefs that will explain search actions made in rarely observed search states, these search actions are omitted. Furthermore, even in popular search states, some actions are rarely chosen; we remove these actions from the set of alternatives, Ati, when modeling search choice in period t. The latter restriction is the primary reason that Ati varies across t and i. Altogether, our model can rationalize 56.4% of observed uses of search actions, and 97.2% of search sessions.

3.3. Likelihood Function
We seek the probability that inequalities related to clicking decisions, (1) and (2), and inequalities related to search decisions, (8) and (9), are satisfied. That probability is an integral over consumer level unobservables, i.e., search cost ci, tastes i , i, product specific shocks ij, and search action specific shocks, ij. To ease notation, we omit consumer index i for the remainder of this section.
We perform integration in two steps. First, we derive the analytic likelihood function, conditional on the vector of utilities of clicked hotels and consumer traits, i.e., tastes , , search cost c, and the value of the outside option, u0. That is, we integrate over productspecific shocks ij for nonclicked hotels (which make

up the majority of unobserved quantities) and search
choice specific shocks tai. The likelihood for decisions in period t is

Lt (u j(1), . . . , u j(t) | , , c)

jDt , j j(t)

exp(rtat ) aAt exp(rta )

×

F(u j(t)

-

µij)

1(t <T )

× 1 - F ut - ln

exp(rta )

aAt

1(t T)

×

F

u

 t

-

ln

exp(rta )

,

aAt

(15)

where j(t) is the index of the clicked hotel in period t (with jt 0 if no click is made); uj(t) is the utility of the clicked hotel; ut max{u j(1), . . . , u j(t)} is the utility of the best alternative so far while in period t (i.e., over hotels observed in periods D1, . . . , Dt); at is the search action chosen in period t after observing Dt; rtat is the reservation value of that search action; At is the choice set of search actions available. Finally, F is the cumulative distribution function (CDF) of the extreme value type 1 random variable. The expression (15) is intuitive. The logit term at the beginning of the first line corresponds to the choice of the search action; F(uj(t) - µij) captures the probability that the clicked hotel in a period has a higher utility than nonclicked hotels. On the second line, the term when t < T captures the decision to continue searching, i.e., the probability that searching is more profitable than stopping. Finally, for the last period considered in the search session, t T, the term captures the condition under which search is no longer optimal.
Second, we obtain the unconditional likelihood by numerically integrating over unobserved quantities, (u j(1), . . . , u j(T), , , c)

(j(1), . . . , j(T))

1I I i1

T

Lt

(u

i j(1)

,

.

.

.

,

u

i j(t)

|



i

,



i

,

c

i

)

,

t1

(16)

where i stands for a simulated consumer obtained by independently drawing unobserved consumer-specific taste parameters and search costs. We use 50 Halton draws to perform numeric integration. Search cost draws are made from a log-normal distribution whose parameters are estimated.
Next we show how to use the estimates from this model to obtain the optimal ranking.

4. A Platform's Problem of Optimal Ranking
The optimal ranking system we derive is designed to maximize the expected CTR for the organic set of

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

549

search results. Although this does not coincide with the more general goal of profit maximization, click maximization is an important input. Specifically, a ranking that maximizes CTR may serve as a starting point that can be readily modified to satisfy various external factors, such as click fees that vary across products, presence of sponsored results, etc. Furthermore, a revealed preference approach to clicks implies that click maximization amounts to maximization of consumer satisfaction. That in itself is an important long-term goal of a search platform, often separate from the short-term goal of profit maximization, which could deviate from maximizing consumer satisfaction if there are incentives to place hotels higher in the rankings. Indeed, search platforms today earn most of their revenues through clearly marked sponsored offerings, bypassing the need to distort organic search results.
We use a discrete choice approach to manage expected CTR on a search platform. After a consumer compares the attractiveness of the options observed during the search session, the click is an outcome of optimal consumer choice. The insight of our approach is to select a candidate ranking and use model predictions to calculate the probability that a random consumer will make at least one click. The discrete choice model creates a link between a candidate ranking and a click through the assumption that a click is the result of optimal consumer choice. By changing the presentation of results in a display, a candidate ranking affects the probability that the consumer's most preferred hotel will be discovered and therefore clicked. The model offers a straightforward way to evaluate multiple counterfactuals without the need to run costly real time experiments on the platform.
Unobserved heterogeneity is a major challenge for obtaining an optimal ranking. It is particularly acute for search aggregators, where the majority of consumers are partially anonymous, as they are not registered (or do not sign in). Generally, there are two dimensions of unobserved heterogeneity. The first is unobserved tastes for hotel attributes, i.e., location, quality, and price. Of course, it is possible to ignore the unobserved component and simply offer a ranking that targets an average consumer, but this results in a loss of efficiency, as we will demonstrate in Section 6. The second dimension of heterogeneity, which is less often mentioned in the literature, is related to the consumer's search preferences, which are also unobserved since the ranking must be created and presented to the consumer immediately after the search request is made and before any search actions are observed. Because consumers' search actions after presentation of the initial default ranking will distort (or even eliminate) the effects of the recommended ranking, a model of optimal ranking should anticipate how a consumer will

continue searching after the initial display. The opposite is also true: The search, itself, is affected by ranking. For instance, if a consumer finds an attractive option on the initial display, she may decide to stop searching earlier, thus eliminating the potential for future clicks. The model of consumer search and click presented above addresses both dimensions of consumer heterogeneity.
In the rest of this section we formally state the problem of optimal ranking in a setting where a consumer's search actions might interfere with the effectiveness of the ranking. Then we present simplified examples to build intuition on how and why our proposed ranking method outperforms alternative rankings.
4.1. Recommendation Ranking The objective of the recommendation ranking is to manipulate displays of hotels observed by the consumer, Dt for t 1, . . . , T, in a way that maximizes the expected CTR. A consumer sees the initial display, D1, which consists of the top 15 hotels ranked by the platform's default recommendation system. Beyond D1, the effect of the ranking on the display composition is influenced by use of filtering and sorting actions. Sorting hotels by some dimension, such as price, eliminates the effect of the ranking on affected displays. Filtering preserves the ranking but reduces the set of hotels that can be recommended. Therefore, the impact of a recommendation ranking is most pronounced among passive consumers, who only evaluate the default ranking and do not use sorting or filtering.
The interference of consumer search actions with recommendation rankings means that unobserved future search actions have to be integrated out to compute the correct measure of expected CTR. To achieve accuracy in the integration problem, the model must differentiate between a wide array of search alternatives available to the consumer at every step. As argued above, a model that focuses on a few dominant search strategies will make inaccurate predictions among the long tail of consumers who use rare search strategies. In our model, we achieve wide coverage of a search strategy space by allowing the consumer to reoptimize after every display.
Let r (r1, . . . , rN ) be the candidate ranking for the current consumer (we abstract from index i to simplify notation), and a~ {a~1, . . . , a~T } be a potential search path, where the "" sign indicates the counterfactual nature of a~. The likelihood function (16) provides a probability that a consumer will click on hotels indexed ( j(1), . . . , j(T)) conditional on a search path a (and resulting displays D1, . . . , DT). Integrating out the unobserved search path, we obtain the unconditional CTR
Pr(j(1), . . . , j(T) | r, P, R)
a~( j(1), . . . , j(T) | a~, D1(a~, r), . . . , DT(a~, r)). (17)

550

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

This equation shows that the CTR function depends on three observed factors:
1. Ranking system, r (r1, . . . , rN ). 2. Current price vector, P (p1, . . . , pN ). 3. Parameters of request, R. Equation (17) is used to select candidate rankings r that maximize the expected CTR rate on a particular set of hotels, (j(1), . . . , j(T)). For instance, we may want to maximize the click rate on hotels that give the highest revenue to the platform (such as click fees). If the goal is to maximize the aggregate CTR, then we compute the unconditional CTR over the search length. The maximization problem becomes

E[CTR (r, P, R)]

T¯

Pr(j(1), . . . , j(T) | r, P, R)  max . (18)

T1

r

Solving this optimization problem by brute force is infeasible as there are N! potential rankings, where N is the total number of hotels. We must reduce the dimensionality of the set of alternative rankings by introducing a discrete set of unobserved consumer types.

4.2. Consumer Types and Targeted Rankings

The unobserved consumer-level heterogeneity (in

tastes) in our model is represented by two parameters,

price sensitivity i and tastes for nonprice attributes, i (see (13) and (14)). Unobserved product level shocks
are integrated out as seen from (15). Both parame-

ters are estimated as continuous distributions; once we

obtain the estimates, we discretize them onto a grid of

predefined points. The price sensitivity parameter is

defined as ln(-i) 0 + 1Ri + ~ i, where ~ i  N(0, ).

With an estimated value of , we obtain a set of quan-

tiles, {10 The grid

,{..10.,,.. 0G. ,+1}0G,+w1}hliecahdscotovearsfin9i9t%e seotf

the density. of consumer

types: A consumer i is said to be of type g(i) if his draw

of ~ i belongs to an interval (0g , 0g+1), with probabil-

ity g obtained using the estimated density of ~ i. The

price sensitivity of a type g consumer is approximated

as the midpoint of this interval. A similar exercise can

be done for the joint distribution of i, but for the sake of simplicity and clarity of exposition we abstract

from the unobserved heterogeneity in this parameter

when constructing the ranking. That is, we use its mean

value, E[i] 0 + 1Ri. As a result of these transformations, we replace the

actual mean utility of consumer i

µij ipij + iXj

(19)

with its approximation

µ^ ij g(i)pij + E[i] X j .

(20)

The advantage of the approximation is that now consumer tastes for hotel characteristics are summarized

by just two parameters, g(i) and Ri. In other words, if we knew these parameters for a new incoming consumer to the platform, we could obtain a vector of mean utilities µ^ i1, . . . , µ^ iN for that consumer. Once mean utilities are known, the click-maximizing ranking is simply to sort hotels by decreasing mean utility. Note that the hotel's position in the display, Lij, enters the mean utilities because we interpret its effect as being related to the within-page search cost, rather than an inherent part of consumer preferences.
As a consumer's type, g(i), is unobserved, it is not possible to directly offer an optimal ranking to each consumer. Instead, our objective is to "guess" the type of the current consumer in a way that maximizes the expected click rate, where the expectation is taken across unobserved types. With this approach, a generally intractable problem (18) is reduced to a discrete optimization problem

E[CTR (rg~ , P, R)]

T¯

g Pr j(1), . . . , j(T) | rg~ , P, R, g

g

T1

 max, g~ (21)

where rg~ is a ranked set of mean utilities corresponding to "guessed" type g~. The outer sum represents an integration of CTR over unobserved consumer type, g, which may differ from the "guessed" type.
Solving (21) is computationally fast as the rankings corresponding to each consumer type (e.g., combinations of g, R) can be obtained before a consumer arrives at the platform. Notably, the click probabilities for each ranking are also obtained before a consumer arrives. At the consumer's request, only a lookup operator and a few linear transformations are required. This ensures speed and scalability of computations, which are critical properties of the recommendation system.

4.3. An Illustration Next we provide two examples that illustrate two key issues that an optimal ranking must address, i.e., heterogeneity in unobserved tastes and differences in ranking when consumers use sorting and filtering tools. Three questions may arise: If we do not know the consumer type, can we simply target the average type, or perhaps the most popular type? What is the role of search actions? How does prediction of future search actions affect our choice of ranking?
The examples allow us to develop intuition as to why and how a ranking that targets a median consumer will not achieve the same results as a targeted ranking based on distributional parameters. Intuitively, if the platform has any reason to believe that hotel A will have a higher click rate than hotel B by the current consumer, it will maximize the overall click rate by placing hotel A on the first page, instead of hotel B. We relate

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

551

the click rate to observable hotel characteristics, which
implies that hotels with a higher mean utility are more
likely to be clicked.
Consider the next set-up to be a simplified version of
the search environment faced by consumers. Suppose
there are two products, characterized by price-quality combinations (pj , vj), j 1, 2. Product 2 is of higher quality than product 1 (i.e., v2 > v1) but it is also more expensive (p2 > p1). Product utilities are uij i pj + vj + ij. Consumers can be of two types, which are unobserved, with type 1 being more price sensitive: 1 < 2. It follows that if the price of the high quality product is not too high, price sensitive consumers
prefer the higher quality product. Finally, suppose the share of type 1 consumers in the population is , and the share of type 2 consumers is 1 - .
Upon arrival at the website, all consumers observe
the first display, which contains one product that was
ranked highest by the recommendation system. To find
the second product, they need to search. With probability , a consumer will continue searching to dis-
cover the second-ranked product, and with probability 1-  she will not search. Depending on her search deci-
sion, a consumer may have only one or two products
in her choice set. With only one product, the click rate of a consumer with  a1, 2 for option j is the logit formula

Cj()

1

exp(pj + + exp(pj

vj) +v

j

)

,

j

1, 2.

The expected click rate for such a consumer is C¯ j Cj(1) + (1 - )Cj(2). If both products are found, the
click rate is higher at

C12()

1

exp(p1 + + exp(p1

v1) + + v1)

exp(p2 + + exp(p2

v2) + v2)

.

Similarly, the expected click rate among those with two products is C¯ 12 C12(1) + (1 - )C12(2). Next we examine the properties of optimal ranking in this
set-up.

4.3.1. Comparison of Rankings Under Random and Average Tastes. Given that consumer types are unobserved, it is unclear a priori how such information could be incorporated into a ranking and why such a strategy may be better than a ranking based on average tastes. The following discussion provides two reasons. First, the click rate of the average type does not equal the expected click rate across types since the expected click rate is a nonlinear function of consumer type (in our case, the price sensitivity parameter). Second, price changes between the product options affect the CTR differently across types. We show that depending on the relative price levels, the discrepancy from the average type ranking and the optimal ranking can vary between zero and some substantial value. There

is simple economic intuition behind both effects, which we illustrate below.
With only two products (one per page), the choice of ranking is between {1, 2} and {2, 1}. Let the probability of continuing the search be . Click rates under these alternative rankings are

CTR (1, 2) (1 - )C¯ 1 + C¯ 12,

(22)

CTR (2, 1) (1 - )C¯ 2 + C¯ 12.

(23)

With probability 1 - , the consumer observes only the top-ranked product; with probability , both products are discovered. The ranking {1, 2} is optimal if it leads to a higher expected CTR

(1 - )C¯ 1 + C¯ 12 > (1 - )C¯ 2 + C¯ 12,

or simply

C¯ 1 > C¯ 2.

(24)

Now consider a ranking that targets preferences of the
average consumer, whose price sensitivity is ¯ 1 + (1 - )2. It is straightforward to show that the ranking {1, 2} is optimal if

C1(¯) > C2(¯),

(25)

or simply

¯ p1 + v1 > ¯ p2 + v2.

In other words, targeting the average consumer type amounts to sorting results by declining average utility.
The ranking rules (24) and (25) will generally be different as the click rate is a nonlinear function of unobserved parameter , so that C¯ 1 C1(¯). However, the magnitude of the discrepancy will vary with product prices, in absolute and relative terms. To illustrate this point, Figure 2(a) plots ranking rules (24) and (25) in the space of product prices, p1, p2 for parameters v1 10, v2 20, 1 -2, 2 -1, and  0.6. For each rule, there exists a boundary such that for each price point (p1, p2) above the boundary, the low quality product (product 1) should be placed on top. For instance, at point B both rules will place the expensive product on top. The shaded area is where the recommendations of ranking rules (24) and (25) disagree. In the area with point A, the ranking that targets average tastes will place the high quality item (product 2) in the top position while the consumer-targeting ranking favors the cheaper product. In the area with point C, the opposite is true.
The disagreement between the average and randomtaste targeting is because the expected CTR under any ranking is comprised of clicks made by consumers who belong to various unobserved types. The contribution of a particular consumer type is determined by its population share (which does not change with prices) and its type-specific expected CTR (which does change

Price of the high quality product 4.07 4.23 4.39 4.56 4.72 4.88 5.04 5.20 5.36 5.53 5.69 5.85 6.01 6.17 6.33 6.49 6.66 6.82 6.98 7.14 7.30 7.46 7.63 7.79 7.95 8.11 8.27 8.43 8.60 8.76 8.92
Price of the high quality product 6.00 6.04 6.08 6.12 6.16 6.20 6.24 6.28 6.32 6.36 6.40 6.44 6.48 6.53 6.57 6.61 6.65 6.69 6.73 6.77 6.81 6.85 6.89 6.93 6.97 7.01 7.05 7.09 7.13 7.17 7.21 7.25 7.29

552

Figure 2. Two Product Ranking Examples
(a) No search
20

18

16

C

14
B 12
A

10 Low quality product on top:
8 Random tastes model

6

Average tastes model

4

Price of the low quality product

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

18.00 17.00 16.00 15.00 14.00 13.00 12.00 11.00 10.00
9.00 8.00

(b) Price search
B A Random tastes--Price search Random dates--No price search Price of the low quality product

with prices). As prices change, so do relative contributions of consumer types, and the optimal ranking must be adjusted accordingly. For instance, if prices of both products are high, as in point C, the contribution of the price-sensitive type becomes so small that it is optimal to target the high type, even though they are less prevalent in the population. The ranking that targets the average type does not detect these shifts in expected CTR composition and can make erroneous recommendations (as in point C, where it continues to place the cheaper product on top). The resulting click losses can be quite large, depending on price levels.
4.3.2. Ranking Under Search Refinement. Limited consumer search is the primary reason for the need for recommendation systems. Consumers are very different in their use of search tools. Some do not search at all, while others use filtering and sorting tools to explore additional options in the results. Chen and Yao (2016) find that consumers use these search refinement tools disproportionately if they are uninformed of the default ranking rule. As a result, the same ranking will have a different impact on consumers who search differently.
An ideal recommendation system will choose the contents of the first page in a way that complements future search results. For consumers who sort by ascending price, one might show more expensive hotels on the first page, thus increasing the diversity of their choice sets. Unfortunately, individual search actions are unobserved at the time when a ranking is to be made. Instead, we observe search actions made by past consumers and their frequencies, much in the same way as we infer consumer types and their probabilities. Such distributional information can be a valuable input into the ranking method.
Returning to our basic set-up, suppose that with probability Rec the consumer will search the default

recommended options and discover the second-ranked hotel; with probability Price the consumer will sort by price and discover the cheapest hotel. Depending on the ranking method, these strategies may lead to different choice sets. The expected CTR under the ranking {1, 2} is
CTR (1, 2) (1 - Rec - Price)C¯ 1 + RecC¯ 12 + PriceC¯ 1. (26)
The first part of the equation is the expected CTR by consumers who did not search (hence their choice set consists only of hotel 1). The last two terms are the expected CTR by those who searched default results and found both hotels. Finally, there are consumers who sorted by price and did not find any new results as the cheaper product was already on the first page. The CTR under {2, 1} ranking is similarly obtained. Taking the difference, we obtain
CTR (1, 2) - CTR (2, 1) (1 - Rec - Price)(C¯ 1 - C¯ 2) - Price(C¯ 12 - C¯ 1). (27)
If C¯ 1 > C¯ 2 in the absence of price sorting, it would be optimal to place that product on top (as in the previous example). In that case, the expected click rate by nonsearchers will increase by (1 - Rec - Price)(C¯ 1 - C¯ 2). However, with an option of price sorting, there is also a negative effect: Consumers who search by price will decrease by Price(C¯ 12 - C¯ 1).
Figure 2(b) illustrates this trade-off by comparing the optimal ranking rule (27) with a ranking that ignores the presence of the price sorting tool. We set Rec 0.5 and Price 0.2, in addition to the same parameters as in Figure 2(a): v1 10, v2 20, 1 -2, 2 -1, and  0.6. At point A, both rules prescribe placing the higher quality product on top because it is not

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

553

too expensive for consumers. The dotted area corresponds to product prices when the prescriptions of the two rules diverge. At point B, the optimal ranking rule (27) still places the higher quality product on top, while the simpler rule dictates that this product is now too expensive and should be downgraded because now C¯ 1 > C¯ 2. If a share of consumers always discovers inexpensive products by price sorting, the optimal rule leads to higher prominence of the pricier product. Another less obvious factor is that some consumers will erroneously use the price sorting tool and may not find their preferred high quality product if it is not placed on top.
5. Empirical Analysis
5.1. Data The data consist of consumer search histories for hotel rooms on a major web-based hotel comparison platform. A search history starts with a search request. The request includes the city, dates of stay, number of people, and number of rooms. Following the request, the website presents the consumer with an ordering of hotels in the city with available rooms that satisfy the request parameters. The hotel options are organized in pages with 15 hotels per page, displaying the hotel name and price, as well as various nonprice characteristics such as star rating, neighborhood, distance to city center, and proximity to airports. All consumers are presented with an initial display of results upon submitting the search request.
After obtaining the default set of results, consumers can click on a hotel on that page, continue to the next page of results, or use other search refinement actions (such as sorting or filtering results based on hotel characteristics). In our data, we observe all hotel listings displayed as a result of the consumer's search request and all subsequent sorting or filtering actions. We also observe which hotel the consumer clicked as part of

their search process. About half of the searchers who click do so only once, in which case this is the end of the search session. If more than one click is made on a page, we consider the last click as the hotel that is the closest match to the consumer's preferences among the searched hotels. Alternatively, the consumer can leave the website without clicking.
The platform is an online search aggregator that compiles and presents hotel information from other travel websites, but does not offer hotel bookings. After clicking on a hotel option, the consumer is redirected to another website where a booking can be made. A potential limitation of the data is that we do not observe whether two search sessions were conducted by the same person (a session is the set of search requests within 24 hours of each other). Therefore, we conduct our analysis as if every search was made by a unique individual. Below we discuss these issues in greater length.
The sample contains 23,959 unique search sessions for Chicago by consumers who searched the platform between May 1­May 31, 2007. There were 148 Chicago hotels available for online booking during that period. A search typically returns 130 to 140 hotel options, depending on availability. This abundance of lodging options creates a nontrivial search problem for a consumer. Hotels in the Chicago market include those in the city of Chicago, satellite towns (Evanston, Skokie, etc.), as well as those close to airports (i.e., O'Hare and Midway). There are also various neighborhoods within the city center. These geographical parameters are observed by consumers during their search.
Table 1 summarizes our data. On average, consumers in our sample search for a hotel room 33.5 days in advance of their stay, 60% stay over a weekend, and the average number of guests is 1.84. The hotels in the data set show significant price variation, $16 to $1,500, with an average of $230. This reflects cross-sectional and temporal variations in prices. The variation in contents

Table 1. Descriptive Statistics
Request parameters Advance search (days) Weekend stay Number of people Length of stay (days)
Across hotels First page location (% of obs) Price (100s of dollars) Clicked price (100s of dollars) CTR (%)
Across consumers Any click Click on the first page Size of choice set (no. of hotels)

Mean
33.50 0.60 1.84 2.44
30.64 2.30 2.00 1.11
0.33 0.17 30.00

Median
21.00 1.00 2.00 2.00
22.18 2.00 1.75 0.80
0 0 26.00

Std. dev.
36.63 0.49 0.97 1.65
28.33 1.27 1.17 0.94
0.47 0.38 21.11

Min.
1.00 0.00 1.00 1.00
0.00 0.16 0.26 0.00
0 0 10.00

Max.
364.00 1.00 8.00
30.00
98.35 15.00 14.41 5.82
1 1 135.00

Obs.
23,959 23,959 23,959 23,959
148 721,848
8,007 148
23,959 23,959 23,959

554

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

Table 2. Breakdown of Consumers by Search and Click Actions

Search category
Browse default rankings 1 page 2 pages 3 pages More than 3 pages
Use sorting or filtering tools 2 pages or more
Total

% of sample
40.8 6.7 4.4 5.7
42.4 100

% of total clicks
36.3 6.7 4.2 4.8
48.0 100

of the first page of results can be summarized by the percentage of observations in which a given hotel appeared on the first page. In the sample, an average hotel appears on the first page about 30% of the time, with substantial heterogeneity: Some hotels never appear on the first page, while others appear in half of all searches.
In the sample, 33% of the search requests ended in a click. Of these clicks, more than half took place on the first page. An individual hotel's CTR ranges between 1.1% and 5.8%. Prices of hotels that received a click are lower. There is a considerable variation in search behavior among consumers, which takes the form of a long tail on hotel choices. An average consumer observes two pages of results (30 hotels). Table 2 presents the breakdown of the different consumers' search refinement strategies in the sample. We find that 40.8% of consumers never continue their search; they only observe the first page of results. Another 16.8% of visitors continue browsing past the first page of the

hotel listings. Among all consumers, 42.4% choose a search refinement action, and represent 48% of clicks.
Figure 1 illustrates the extent of within-page search. Although we do not directly observe this search, indirect evidence can be obtained from the distribution of clicks across hotel position (ranging from 1 to 15 on the page of results). Of all clicks on the first page, 22% went to the hotel in position 1, by contrast to 11% to position 2, and 3% to the last position on the page. A similar pattern exists for other pages: Overall, 19% of the clicks were for a hotel at the top of any page.
Table 3 provides evidence of the importance of accounting for the endogeneity of search refinement actions; this validates our modeling approach. The table summarizes hotel characteristics of the first display based on the consumer's decision on whether to click or continue searching and which search tool to use after observing the initial display. The first column shows that consumers are more likely to click on displays with lower prices and choose a search strategy when prices of hotels within the first display are higher on average. For instance, average prices for hotels when consumers click are $265 compared with when consumers browse another page of results ($284), filter by distance ($288), filter by price ($282), filter by stars ($294), sort by distance ($271) or sort by price ($268). The second column shows that consumers sort or filter by distance when the price dispersion of the first display is larger and sort by price when the price dispersion is lower. The third column shows that consumers are more likely to click when the average price-star ratio is relatively lower and perform a search action when the ratio is higher. The one exception is sorting

Table 3. Search Actions and Hotel Characteristics of First Display

Action No further search
Click on a hotel No click
Search action Browsing a page Filter by distance Filter by price Filter by stars Sort by distance Sort by price

Average price
265.01 (4.52)
270.2 (2.27)
284.61 (2.22)
288.66 (4.97)
282.13 (4.26)
294.39 (9.93)
271.74 (7.03)
268.95 (3.18)

Price dispersion
86.59 (2.67) 82.44 (1.23)
88.83 (1.25) 94.4 (2.82) 86.7 (2.24) 79.67 (4.16) 95.89 (3.87) 78.41 (1.72)

Average star
rating
3.19 (0.02) 3.2 (0.01)
3.23 (0.01) 3.21 (0.02) 3.21 (0.01) 3.28 (0.04) 3.13 (0.02) 3.21 (0.01)

Average price-star
ratio
84.18 (1.3) 85.93 (0.65)
89.44 (0.65) 90.81 (1.42) 89.16 (1.18) 90.08 (2.33) 87.61 (2.06) 85.62 (0.92)

Within 1 mile from city center

Share of hotels

Average price

0.46 (0.01) 0.48 (0.01)
0.49 (0.01) 0.44 (0.01) 0.49 (0.01) 0.48 (0.02) 0.39 (0.02) 0.52 (0.01)

366.66 (8.34)
355.18 (3.89)
374.45 (3.98)
397.08 (8.82)
369.12 (7.23)
383.07 (12.69) 395.7 (12.28) 334.87
(4.95)

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

555

by price. The relationship between the contents of the first display and a consumer's next decision is stronger when we focus on hotels within one mile of the city center.
5.2. Identification Utility parameters. The browsing and clicking data provide rich sources of variation that can be used to identify consumer preferences for observable hotel characteristics, as well as the distribution of unobserved heterogeneity. These sources are changing hotel prices, composition of choice sets, and positions of hotels within the display. In our data, no two consumers observed the same vector of hotel prices or had the same composition of choice set. In other words, every click we observe was made in a different choice context than the next click. This facilitates identification because we can fix a subset of hotel characteristics (such as neighborhood and quality rating) and still find variation in other parameters (such as price or brand). Because we directly observe the choice sets (e.g., sets of hotels displayed on the screen), we improve the precision of estimates by avoiding ad-hoc assumptions as to the distribution of choice sets.
Price sensitivity. Price endogeneity is a serious concern in the context of brand choice (see Villas-Boas and Winer 1999 and Chintagunta et al. 2005). In our context, identification of the effect of prices on clicks represents a particular challenge because price is the only timevarying characteristic of a hotel that can be correlated with changes in unobserved hotel quality over time. For instance, a hotel could be near a sports event; this is a positive demand shock that drives up demand and price. In our application, we are concerned that biased estimates of the price coefficient may alter ranking simulations in a way that is hard to predict.
To overcome this problem, we use the feature of our data where we observe not only the price of the clicked product but also prices of other products in the choice set that were not chosen. As a result, we have multiple price observations for a product within a market. This is in contrast to typical transaction data where the number of price observations is the same as the number of markets where the product is observed. Of course, additional price observations would not help if there were no variations. In fact, we find plenty of variation in hotel prices online, to the extent that two people searching for the same hotel, on the same date, for the same future dates of stay, may be exposed to different prices. These two features of the data, i.e., frequent price changes and the fact that we observe them at the consumer level, allow us to construct proper controls for price endogeneity.
We begin by defining narrow consumer segments to reduce the variation in unobserved product attributes within a segment. Consumers who belong to the same

segment are allowed to have idiosyncratic taste shocks. A segment consists of a hotel and includes consumers who searched within a day around a date of search and a date of arrival. For instance, a segment for the Hilton Chicago with a May 15, 2007 date of search, and a July 20, 2007 date of arrival, includes consumers who searched between May 14­May 16 for an arrival date between July 19­July 21.
We then construct a predicted hotel price for each consumer segment using a price regression on a data set of 721,848 price observations for 148 Chicago hotels that are observed by consumers in our search model. Using a set of fixed effects for 28,219 unique consumer segments, we obtain an R2 of 86%; the remaining 14% of observed price variation is "experimental" (with a standard deviation of $47).
Finally, we include the predicted price, along with the actual price, in the utility model. The predicted price serves as a control function (Petrin and Train 2010). Conditional on the predicted price, the variation in the observed price is uncorrelated with unobserved demand shocks, hence the estimates are consistent. Intuitively, the effect of price on demand is identified from the joint variation of price and demand (e.g., clicks) within a narrowly defined consumer segment.
Position effects. The position of a hotel within a display has an important effect on the probability of a click because of the human tendency to read results from top to bottom. However, if the page is sorted by a default ranking, which is based on some measure of hotel popularity, the position may also reflect unobserved hotel quality; for this reason there may be a spurious correlation with the CTR.
Our approach to position endogeneity is again to construct a control function. In addition to hotel and time fixed effects, we include lagged click rates on the hotel as a regressor in the price model: Past click rate was likely an input into the ranking system used by the platform in 2007. Note also that 48% of clicks (Table 2) come from pages sorted not by default sorting but instead are sorted according to a hotel attribute (price, distance to city center, etc.). After controlling for that hotel attribute (as we do in the click model), the remaining variation in hotel positions on such pages should be exogenous to consumer preferences. This helps alleviate concerns about the endogeneity of position effects. Furthermore, we attempt to study the properties of the default ranking (see the online appendix). We find that relative hotel rankings are not strongly related to reasonable economic predictors (price, parameters of request, etc.); this suggests a lot of randomness in the default rankings themselves.
Search costs. The main challenge in identifying search costs is to separate them from preferences in their effect on search decisions. As we observe search actions and clicks, we use an exclusion restriction where

556

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

preferences affect both, but search costs affect only search actions. The joint variation in clicks and choice sets allows us to pin down a distribution of preferences; based on that, observations of search intensities uncover the search cost distribution. Specifically, because our data is in the form of conditional search decisions (i.e., search actions coupled with preceding displays of results), the search cost distribution is identified (Koulayev 2014). The idea is that consumers who were presented with better hotel deals on the first page will search less frequently than those who were not. The predicted difference between search intensities in the two groups is regulated by the parameters of the search cost distribution.
We estimate the parameters by fitting the predicted search intensities to actual search intensities. The identifying assumption is that the contents of the first page, or other displays preceding a search action, are not correlated with unobserved consumer preferences. The contents of the initial display are not chosen by the consumer; therefore, it is likely that differences in displays between two observationally equivalent consumers (i.e., same parameters of request) are random. Note that we do not assume that the first display is random (as it is chosen by the recommendation system), only that differences in the contents are random. The contents of subsequent displays are, in part, a result of consumer choice, and so are correlated with unobserved tastes. We model that correlation in a structural way. When we model clicks on a price-sorted page, it is based on the fact that the consumer who chooses price sorting is potentially more price sensitive than the average consumer. Therefore, our identifying assumption is that differences in page contents will be random based on the search action that creates the page. This is a much weaker assumption than unconditional randomness.
5.3. Estimation Results In this section, we present estimates of the search and click model under different specifications, i.e., (1) logistic regression, (2) logit model with constant tastes, (3) logit model with random tastes, and (4) search and click model. The main distinction is that the first three model specifications explain clicks by taking search actions as given, while the search and click model explains search actions and clicks as dependent variables. The difference between logit models with constant and random tastes is the presence of unobserved heterogeneity in coefficients of hotel attributes.
Table 4 presents the utility parameter estimates of these four discrete choice models. In every specification, we include a rich set of interactions between consumer level observables, such as advance purchase, duration of stay, weekend stay, number of travelers,

and price and nonprice hotel characteristics. The logistic and logit models with random tastes present similar results. Specifically, the least price sensitive consumers search two weeks in advance and include a Saturday night stay, while (perhaps contrary to expectations) the closer the arrival date, the more price sensitive the demand. This implies that request parameters include valuable information about consumer preferences that should be used by ranking systems. Estimates of the price coefficient interactions of the random tastes model are larger than the constant taste model, which explains the positive mean price coefficient. The extent of unobserved heterogeneity is substantial: For example, the logit model with random tastes estimates the standard deviation of log-price coefficient at 0.81, which is 1.4 times the mean of that parameter.
Table 4 also shows that the estimates of the price sensitivity from the search and click model are substantially different from those obtained in logit models. This is because elasticity estimates might be biased when search information is ignored and only click information is used to characterize choice. Intuitively, when consumers are allowed to face exogenously chosen alternatives, estimates will attribute the choice of pricier alternatives to price sensitivity instead of to an optimal decision to stop engaging in costly search. An interesting finding that supports this notion is the sign reversal of the coefficient for consumers who search less than two weeks in advance, indicating that consumers are significantly less price sensitive when facing time or deadline constraints.
Table 5 compares coefficient estimates from the search model with and without endogeneity controls. The coefficient on the control function (predicted price) is positive and significant, as expected. With independent variable (IV) controls, the median price coefficient is larger in magnitude (e.g., demand is more sensitive) but the difference is small, about 12%. Accordingly, we find that price endogeneity does not produce qualitatively different results in terms of relative performance of various ranking methods.
Finally, the estimated distribution of search costs, in dollars, is presented in Table 6, with a median search cost of $16.25, and a substantial amount of heterogeneity, i.e., between $10 at the lower end and $40 at the higher end.
5.4. Model Fit To test the fit of the search and click model, which accounts for search in addition to click choices, we augment the nonsearch models with empirical frequencies of search actions. This enables us to construct the likelihood of the observed searches and clicks and compare it to the likelihood of the full search model. Specifically, we multiply the likelihoods by an estimate of search action probabilities using the frequency of each

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

557

Table 4. Estimates of Discrete Choice Models of Hotel Choice

Search model

Logit model random tastes

Logit model constant tastes

Logistic regression

Distribution of the price coefficient E(ln()) SD(ln())
Interactions of price with Saturday night stay One guest Within 2 weeks of stay Within 3 days of stay
Non-price hotel characteristics Position effect (in $) Distance to city center Random effect std. dev. Distance to O'Hare Random effect std. dev.
Outside option and request interactions Saturday night stay One guest Within 2 weeks of stay Within 3 days of stay
Endogeneity controls Price control Position control
Other nonprice hotel characteristics Star rating dummies Random effect std. dev. Neighborhood dummies Random effect std. dev. Request interact Month dummies
Log-likelihood Log-likelihood: Search and click Log-likelihood: Click Number of observations

0.03 (0.01) 0.66 (0.38)
-0.27 (0.18) -0.34 (0.21) -1.10 (0.08)
0.17 (0.10)
-35.15 (0.07) -0.05 (0.01)
0.21 (0.13) 0.40 (0.28) 0.09 (0.03)
0.38 (0.20) 0.69 (0.33) 0.86 (0.45) 0.10 (0.08)
0.08 (0.01) -0.13 (0.02)
Yes Yes Yes Yes Yes Yes -137,032 -137,032 -19,118 21,366

0.59 (0.32) 0.81 (0.34)
-0.27 (0.14) -0.35 (0.13) -0.46 (0.19)
0.19 (0.18)
-7.76 (0.05) -0.26 (0.21)
0.27 (0.17) 0.68 (0.15) 0.20 (0.12)
0.44 (0.22) 0.97 (0.39) 0.72 (0.17) -0.13 (0.12)
Yes Yes Yes Yes Yes Yes -42,277 -173,957 -20,222 21,366

-0.21 (0.11)
-0.16 (0.07) -0.06 (0.12) -0.17 (0.12)
0.21 (0.15)
-18.51 (0.08) -0.25 (0.16)
0.44 (0.25)
0.19 (0.18) 0.31 (0.15) 0.17 (0.12) -0.22 (0.18)
Yes
Yes
Yes Yes -42,918 -174,598 -21,311 21,366

-0.35 (0.11)
-0.16 (0.10) -0.03 (0.02) -0.24 (0.10)
0.21 (0.15)
-24.12 (0.09) -0.28 (0.13)
0.34 (0.12)
0.15 (0.16) 0.15 (0.14) 0.12 (0.14) -0.22 (0.15)
Yes
Yes
Yes Yes -45,578 -177,258 -21,899 21,366

Notes. This table presents estimates of utility parameters for various discrete choice models (see Section 3.1). The search model sees hotel clicks and search actions as dependent variables; the other three models explain hotel clicks only. The random effects, if included, take a normal distribution (and log-normal for price coefficient). Advance search is defined as the number of days between the date of search and the date of arrival. Default categories for request parameters are no Saturday night stay, more than one guest, more than two weeks advance search, and more than two days stay. Standard errors are in parentheses.

search action in the data. This has an effect of adding a constant to the log-likelihood (LL). Table 4 presents the comparison of the LL of the different models. A chi-square test of the LL differences indicates that the search and click model significantly outperforms any of the nonsearch models. Similarly, the resulting differences in LL between the search model and the click only models are large and statistically significant at any standard level of confidence.
An alternative is to compare the performance of the search and click models to the other specifications with regard to their abilities to predict clicks. We obtain the likelihood of observed clicks for each of the alternative models, where search decisions are integrated out. In the search model, we sum the probabilities of the

joint search and click decisions across potential search paths to estimate the LL of only click decisions. In the other specifications, we obtain a weighted average of click probabilities, where weights are the sample frequencies of search paths. The resulting LL of the click, LL (click), is shown in Table 4. A natural benchmark for these values is the unconditional likelihood obtained from the average click rate observed in the data (which is 35%). This can be interpreted as the probability that a randomly chosen consumer will click at least once. Taking the logarithm of 35% and multiplying by the number of observations, we obtain LL (click) -22,777. In all logit models, the LL (click) is higher than this benchmark, as these models use a set of covariates to explain clicks. The search model has the highest value

558

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

Table 5. Controls for Endogeneity

Search model with IV controls

Search model without
IV controls

Distribution of the price coefficient

E(ln(-))

0.03 (0.01)

SD(ln(-))

0.66 (0.38)

Interactions of price with Saturday night stay One guest Within 2 weeks of stay Within 3 days of stay

-0.27 (0.18) -0.34 (0.21) -1.10 (0.08)
0.17 (0.10)

Non-price hotel characteristics Position effect (in $) Distance to city center Random effect std. dev. Distance to O'Hare Random effect std. dev.

-35.15 (0.07) -0.05 (0.01)
0.21 (0.13) 0.40 (0.28) 0.09 (0.03)

Outside option and request interactions

Saturday night stay

0.38 (0.20)

One guest

0.69 (0.33)

Within 2 weeks of stay

0.86 (0.45)

Within 3 days of stay

0.10 (0.08)

Endogeneity controls Price control Position control

0.08 (0.01) -0.13 (0.02)

Other nonprice hotel characteristics

Star rating dummies

Yes

Random effect std. dev.

Yes

Neighborhood dummies

Yes

Random effect std. dev.

Yes

Interactions with requests

Yes

Month dummies

Yes

Log-likelihood Number of observations

-137,032 21,366

0.03 (0.01) 0.50 (0.35)
-0.41 (0.15) -0.60 (0.18) -0.85 (0.25)
0.07 (0.11)
-31.25 (0.03) 0.04 (0.01) 0.19 (0.12) 0.52 (0.21) 0.15 (0.11)
0.51 (0.18) 0.74 (0.18) 0.64 (0.38) 0.21 (0.03)
Yes Yes Yes Yes Yes Yes -137,426 21,366

Note. This table presents a comparison of estimates of the search model with and without controls for endogeneity of price and position.

LL (click) -19,118. One explanation for this is that the search model is using inequalities imposed by search decisions to update expectations of the distribution of consumer tastes. In this way, the search model brings in an additional source of information relative to static discrete choice models.

Table 6. Search Cost Distribution

Decile
1 2 3 4 5 6 7 8 9

Search costs ($)
8.35 10.89 12.47 14.83 16.25 19.33 34.08 40.53 55.23

5.5. Estimates of Consumer Types

In this section, we illustrate targeting that relates re-

quest parameters to consumers' heterogenous price

sensitivities. However, this targeting can be extended

to a richer set of consumer characteristics.

First, we construct 40 consumer types by discretiz-

ing the distribution of unobserved heterogeneity, cor-

responding to different values of the parameter 0i, which stands for the unobserved component of price

sensitivity (see Equation (14)). These values represent

the grid points over the interval containing 99% of the

probability mass of 0i. For an economic interpretation, we obtain a marginal effect of price for each type

defined by the percentage point change in the expected

CTR following a 1% increase in prices of all hotels. Fig-

ure 3(a) plots the resulting density of marginal effects:

The median is around -1%, with a substantial amount

of heterogeneity around the median.

As discussed previously, the observable consumer-

level heterogeneity in our sample consists of the pa-

rameters of request, Ri , and a vector of prices, Pi. For
ceaovnnedrsyetrauccohctmpaborsinasniabtklieeodnunloiosftb(soRefir,hvPoeidt)etlosyb,psdeeernv0goe,tdgedinb1yt,h.ve. e. s,ca4tom0r, pwrligee, where each ranking is optimal based on the underlying unobserved type. For every ranking rig, we simulate counterfactual choice sets that would have been real-

ized under this ranking. For every simulated choice

set, we compute an expected CTR using the model's

estimates. A ranking that delivers the highest CTR cor-

responds

to

a

certain

"guessed"

consumer

type

g

 i

g(Ri , Pi), called the "best guess," which is the solution

to the platform's optimization problem. The notation

g(Ri , Pi) implies that the "best guess" will vary with

prices and parameters of request.

Repeating the procedure for every observation, we

obtain a sample distribution of "best guesses," gi, i 1, . . . , M, shown in Figure 3(b). The median type is

most frequently chosen as the "best guess," but only

in 30% of the cases. In the remaining 70%, types other

than the median are optimal for targeting through a

customized ranking. In other words, in the majority of

cases, a simple targeting of a median consumer leads

to a suboptimal ranking.

A further insight is obtained from Figure 4, which

illustrates the effect of request parameters on the opti-

mal group type to which a consumer is assigned.

The figure shows the distribution of optimal "guesses"

among consumers with different request parameters.

Figure 4(a) shows two hypothetical requests: Guest 1

books less than a week in advance and stays one night

over a weekend. Guest 2 books more than a week

in advance and stays three or more nights with no

weekend stay. These two hypothetical guests represent

the two extremes of the price sensitivity distribution.

The distribution of optimal group types differs greatly

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

Figure 3. Marginal Effects and Consumer Type

(a) Price marginal effects and consumer type

0.1

20

559
(b) Sample frequency of "best guesses"

Price marginal effect Price marginal effect

0

15

­ 0.1

10

­ 0.2

5

­ 0.3

0

­5

­4

­3

­2

­1

0

­ 0.3

­ 0.2

­ 0.1

0

0.1

Price

Frequency (percentage)

0

10

20

30

40

Group

0

10

20

30

40

Group

among them. Another example is presented in Figure 4(b), which shows the typical business and leisure guests. The business guest travels alone, stays three or more nights, and does not stay over a weekend. The typical leisure guest books a room for two adults, spends one night, and includes a weekend stay. The figure shows that the most likely ranking of the typical business guest is the one for group 15; the ranking for the typical leisure guest is the ranking for group 17.
6. Evaluation of Alternative Rankings
In this section, we further explore the validity of our estimates by evaluating different recommendation

rankings. The preferred method to evaluate the performance of a ranking method is through a randomized field experiment. In the absence of such an opportunity, we use the structural model of search and click to compare rankings. To the extent that the model adequately reflects the data and is identified, the model's predictions can inform us about the relative performance of alternative ranking methods. These results can be used to find a better selection of recommendation rankings to evaluate during field experiments, which are costly to implement.
We evaluate recommendation rankings at different ends of the recommendation spectrum, from a simple popularity ranking to our proposed ranking

Figure 4. Sample Frequencies of "Best Guess" by Request Parameters

(a) Two consumers with extreme price elasticities

(b) Two typical consumers

0.3 Guest 1 Guest 2
0.2

0.25 Typical guest: Business Leisure
0.20
0.15

Percentage Percentage

0.10 0.1
0.05

0 10 11 12 13 14 15 16 17 18 19
Optimal group type

0 10 11 12 13 14 15 16 17 18 19
Optimal group type

Notes. The figure shows the distribution of optimal "guesses" among consumers with different request parameters. In Figure 4(a), guest 1 represents all consumers booking less than a week in advance and staying one night over a weekend; guest 2 represents consumers staying three or more nights, booking more than a week in advance, with no weekend stay. In Figure 4(b), the typical business guest travels alone, stays three or more nights, and does not include a weekend stay. The typical leisure guest consists of two adults, spending one night, and includes a weekend stay.

560

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

that maximizes the CTR in a fully structural model of search and click. In particular, we separate the importance of accounting for different aspects of the model, i.e., unobserved taste heterogeneity, endogeneity of search decisions to ranking, and targeting using parameters of requests. Using our model of search and click, we evaluate the relative contributions of these factors to the performance of a ranking. This helps managers make better design choices.
Next, we construct two performance measures of a ranking generated by this model. The first measure is the expected click rate, predicted by the model of search and click. Because the first measure is modelbased, it properly accounts for unequal click likelihoods and endogenous search response. The second measure is the average rank of hotels that were clicked. As the second measure is model-free, it represents an external validation of the model-based results; for the same reason, the results of both metrics are not necessarily the same and hence can be viewed as complementary.
6.1. CTR Comparisons To estimate the CTR for different rankings, we proceed in three steps. In the first step, we use estimates of the full model of search and click to construct a ranking that maximizes the predicted CTR in that model. The CTR is computed as the expected click rate integrated over future search action paths and future clicks (see Equation (21)).
In the second step, we build several simpler models that do not account for choice factors such as request parameters, random tastes, and endogenous search decisions. For each model, we construct a ranking that maximizes CTR as predicted by that model, just as a practitioner would. We then use the full model to compute the "actual" CTR for each alternative ranking. Because the full search and click model yields the maximum CTR, any alternative ranking would necessarily

result in a lower CTR than the fully optimal ranking derived in the first step.
Last, we simulate popularity and price sort rankings, which are two of the most commonly used. A popularity ranking is the hotel's click rate over the last two weeks, measured as the ratio of clicks to the number of displays (impressions). The price sort ranking is simply a ranking of hotels by increasing price.
Table 7 presents the CTRs for the alternative rankings. The CTRs are obtained over a random sample of 1,016 ranking scenarios, which are combinations of parameters of request and hotel prices available at the time of the request. For a ranking, the CTR will generally vary across the considered scenarios. For instance, in periods when hotel prices are higher, the CTR is lower. For this reason, we present the deciles of the CTR distribution across these scenarios. The table shows that the ordering of the alternative ranking is still consistent across deciles of the distribution. The default ranking is the platform ranking we observe in the data, reconstructed from search histories where a consumer has browsed at least four pages of defaultsorted results. The default ranking is the worst performer of all, with a CTR of 26.5%. The simulated popularity ranking, with a mean CTR of 32.7%, is better, as is the price sorting, with a CTR of 34.3%. The modelbased rankings bring further improvements, i.e., 41.9% for a constant coefficients logit model, and finally 43.6% mean CTR for the logit model with random tastes. The search model CTR is 46.4%, which represents an almost two-fold improvement over the default ranking.
These absolute values of CTR provide a sense of the impact of changes in the ranking model. For a modest sized search platform with 1 million visitors a month, a 1% improvement in CTR brings 10,000 extra clicks. However, the actual CTR outcomes of a ranking will vary with market conditions (such as prices and availability), as can be seen from deciles of CTRs across scenarios. Table 8 presents a useful comparison of the

Table 7. CTR Distribution Under Alternative Rankings

Default ranking

Simulated rankings

Popularity

Price

Logistic regression

Model-based rankings

Logit constant

Logit random

Search and click

Decile

1

2

3

4

5

6

7

8

9

Mean

0.203 0.225 0.240 0.255 0.266 0.278 0.291 0.305 0.324
0.265

0.275 0.292 0.304 0.315 0.327 0.337 0.349 0.363 0.382
0.327

0.274 0.294 0.312 0.330 0.346 0.358 0.375 0.390 0.408
0.343

0.374 0.386 0.397 0.406 0.416 0.426 0.436 0.446 0.459
0.416

0.376 0.388 0.399 0.409 0.420 0.430 0.438 0.449 0.464
0.419

0.393 0.406 0.417 0.426 0.435 0.444 0.455 0.464 0.479
0.436

0.420 0.434 0.445 0.454 0.464 0.474 0.484 0.495 0.509
0.464

Notes. The table presents the distribution of absolute expected CTRs under alternative ranking scenarios. Logit constant is the logit discrete choice model of click with constant coefficients; logit random has random coefficients, i.e., unobserved tastes for hotel attributes.

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

561

Table 8. CTR Comparison Under Alternative Rankings

Ranking

Mean CTR (1)

Ratio of CTR relative to search and click (2)

CTR diff. from popularity ranking
(3)

Ratio of CTR diff. relative to search and click (4)

Default

0.265

0.57

Simulated rankings

Popularity

0.327

0.70

Price

0.343

0.73

Model-based rankings

Logistic regression

0.416

0.89

Logit constant coefficients

0.419

0.90

Logit random coefficients

0.436

0.94

Search and click

0.464

1

-0.062
0.000 0.016
0.089 0.092 0.109 0.137

-0.45
0 0.11
0.65 0.67 0.79 1

Notes. The table shows absolute expected CTRs under alternative ranking scenarios. Logit constant is the logit discrete choice model of click with constant coefficients; logit random has random coefficients, i.e., unobserved tastes for hotel attributes. The calculations in column (2) are the ratio of the mean CTR of each ranking to the search and click ranking. For instance, the mean CTR of logit with constant coefficients is 0.419 and the mean CTR of the search and click ranking is 0.464, hence the ratio is 0.419/0.464 90.4%. In column (3), the ranking gain over the popularity ranking can be measured as the difference from popularity rankings. Because the popularity ranking mean CTR is 0.327, the gain of the logit with constant coefficients is 0.419 - 0.327 0.092, while the difference of the search and click model is 0.464 - 0.327 0.137. The relative gain achieved by the search and click model can be measured as the ratio of these two differences: 0.092/0.137 67.4%.

gain of each ranking relative to the search and click model.
The first column of Table 8 shows the mean CTR of each ranking. The second column shows the ratio of each CTR to the CTR of the search and click model, which achieves the largest CTR of 46.4%. The CTR of the default ranking is 57% of the CTR from the search and click model. Because the exact algorithm of the default ranking is unknown, we cannot definitively state the reasons behind the poor performance of the default ranking. As the default ranking cannot be reproduced, we use the popularity ranking as the lowest benchmark for comparison of the CTR gains. The simulated rankings perform better than the default ranking: The popularity and price rankings are 70% and 73%, respectively, of the CTR of the search and click ranking. The CTRs of model-based rankings improve with their flexibility: The logistic model achieves 89% of the gains from the search and click model, and the random coefficients logit model achieves 94% of the gains from the search model.
A natural comparison is the performance of simpler alternative rankings relative to the search and click ranking. Because the algorithm of the default ranking is proprietary, we use the popularity ranking as a benchmark. The click improvement of the search and click model relative to the popularity ranking is 0.464 - 0.327 0.137 or 13.7%. The differences of each ranking relative to the popularity ranking are presented in the third column of Table 8. The fourth column shows the ratio of each click gain from the third column relative to the gain of the search and click model (0.137). The click gain from a constant coefficient logit model represents (0.419 - 0.327)/(0.464 - 0.327) 67.4% of this maximum improvement. The constant coefficient logit model uses sorting of hotels by average utility, and

implements targeting based on observed tastes (in our case, parameters of request), but does not take into account unobserved heterogeneity or search preferences. The random coefficient logit model includes targeting on unobserved tastes, and achieves 79.3% of the maximum, which translates into an additional 0.436 - 0.419 0.017 or 1.7%. Finally, accounting for search response to ranking (as done by the search model) brings an additional 2.8% (0.464 - 0.436 0.028).
A platform would not only be interested in the average CTR but also in the performance of a ranking in the worst and best case scenarios. Figure 5 illustrates these distributional differences between the rankings. In Figure 5(b) we plot CTRs from two logit models and find that, although modal CTRs differ only slightly, the random coefficient logit model significantly outperforms the constant coefficient version in the upper and lower tails (for instance, the low click rate of 0.3­0.35 is almost eliminated under the "random logit" model). Figure 5(c) shows that the gain in CTR by the search model over the "random logit" is mostly a shift of the distribution to the right. Part of the distributional impact comes from targeting based on observed and unobserved consumer types, which we explore below.
6.2. Rank of Clicked Hotel Comparisons An external validation of our approach can be obtained using model-free metrics. One such metric is the average rank of hotels that were clicked under different rankings, which is common in recommender systems design (see Ricci et al. 2011). The idea behind it is straightforward: A superior recommendation system should help the consumer find her preferred product earlier in the search process. This metric, however, has several drawbacks. First, it says nothing about the click

562

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

Figure 5. Distributions of CTRs Under Alternative Rankings

(a) Simulated rankings

10 Ranking:

Default

8

Popularity

Price

6

4

(b) Ranking from click models

Ranking:

10

Default

Logit constant coeff.

Logit random coeff. 8

6

4

2

2

0 0.1

0.2

0.3

0.4

Click-through rates

0

0.5

0.1

0.2

0.3

0.4

0.5

Click-through rates

(c) Ranking from search and click model

Ranking:

10

Default

Logit random coeff.

Search and click

8

6

4

2

0

0.1

0.2

0.3

0.4

0.5

0.6

Click-through rates

rate, which is of ultimate interest for a platform manager. Second, all observed clicks are treated equally, while in fact the attractiveness of some clicked hotels may be higher than others. Finally, no account is made for a possible response of search activity to ranking. For these reasons, the average rank of clicked results should be considered a complementary measure to our main results.
There are two distinct ways in which our proposed ranking method may lead to better CTRs than the default ranking. The most important effect comes from changes in the composition of choice sets, i.e., the types of hotels displayed to consumers. Hotels neglected by the default ranking are introduced for consumers' consideration, and less relevant options are moved out of the consideration set. The other effect is reordering hotels on the page of results: By placing better alternatives closer to the top of the page, we improve the quality of the choice set, even without changing its

contents. This is particularly true for the first page of results, as it is observed by all consumers.
Table 9 presents a breakdown of clicks across pages of results sorted by an optimal recommendation ranking based on the search and click model. Under this optimal ranking, 43.8% of clicked hotels would have been observed on the first page by the consumer. By contrast, only 23% of clicked hotels were actually found

Table 9. Distribution of Clicks by Page

Page
First Second Third Fourth Fifth Other pages
Total

Search and click ranking (%)
43.8 20.9 13.3 9.5 5.7 6.9
100

Default ranking (%)
23.0 18.2 22.9 15.5 9.8 10.7
100

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

563

on the first page in our data (generated by the default ranking). This is a substantial improvement, in line with a large predicted gain in CTR that we found in our model-based results.
7. Conclusions
This paper proposes a search and click model that endogenizes consumers' search refinement actions, along with an optimal ranking for online platforms. Additionally, the paper derives a methodology to target individuals with rankings by exploiting the relationship between the parameters of requests available to the platform and the expected consumer price sensitivity.
Note that the structural approach allows us to link a choice with the different consideration sets observed by the consumer as part of her search process. This modeling approach also allows for search and click prediction under alternative rankings and changing market conditions (availability and prices). This is difficult to achieve with reduced-form approaches to clicks, such as simple popularity rankings, or more generally, machine-learning algorithms. Formally, click maximization is achieved by improving the expected values of choice sets presented to consumers. The optimal ranking is computed for every individual consumer request, while conditioning on the set of currently available products and their prices. In this way, the proposed algorithm uses the technological capacities of a search platform, i.e., its ability to collect information and manipulate displays in real time.
Counterfactual ranking comparisons demonstrate the poor performance of the default ranking used by the platform even when compared with simple popularity and price sort rankings. The largest gains of performance, as measured by CTRs, are derived from a simple discrete choice model based on hotel characteristics. Further CTR gains are obtained by models that jointly explain search and click and by an optimized ordering of hotel results tailored to individual consumers.
This paper has important managerial implications. Online platforms offer consumers the ability to analyze and compare product attributes for a large set of distinct alternative products. Incorporating consumer search choice models that allow for heterogeneous tastes and endogenous search refinement allows firms to more precisely present consumers with preferred alternatives. In addition to increased profitability through higher CTRs, reducing search frictions will likely increase consumer satisfaction, as well as retention and return rates.
Acknowledgments A previous version of the paper was circulated under the title: Optimizing Click-through in Online Rankings for Partially Anonymous Consumers. The authors thank Lura Forcum, Elisabeth Honka, Ali Hortaçsu, Joowon Kim, Matths Wildenbeest, and participants in the Industrial

Organization Society sessions at the Allied Social Sciences Association annual meeting, the 4th Workshop of Consumer Search and Switching, and seminar participants at the University of Iowa, the University of Arizona, and the University of Texas at San Antonio for helpful comments. Special thanks to Emilia Simeonova for encouragement and support. The views expressed are those of the authors and do not necessarily reflect those of the Consumer Financial Protection Bureau or the United States.
References
Anderson M, Ball M, Boley H, Greene S, Howse N, Lemire D, McGrath S (2003) RACOFI: A rule-applying collaborative filtering system. Proc. IEEE/WIC COLA'03, NRC 46507, Halifax, Nova Scotia, Canada.
Ansari A, Mela CF (2003) E-customization. J. Marketing Res. 40(2): 131­145.
Ansari A, Essegaier S, Kohli R (2000) Internet recommendation systems. J. Marketing Res. 37(3):363­375.
Basilico J, Hofmann T (2004) Unifying collaborative and contentbased filtering. Proc. Twenty-first Internat. Conf. Machine Learning (ACM, New York), 65­72.
Brynjolfsson E, Smith M (2000) Frictionless commerce? A comparison of Internet and conventional retailers. Management Sci. 46(4):563­585.
Burke R (2000) Knowledge-based recommender systems. Encyclopedia of Library and Information Science, Vol. 69 (Marcel Dekker, New York), 180­200.
Chen Y, Yao S (2016) Sequential search with refinement: Model and application with click-stream data. Management Sci. ePub ahead of print September 28, http://dx.doi.org/10.1287/ mnsc.2016.2557.
Chintagunta P, Dubé J-P, Goh KY (2005) Beyond the endogeneity bias: The effect of unmeasured brand characteristics on household-level brand choice models. Management Sci. 51(5): 832­849.
De los Santos B (2017) Consumer search on the Internet. Working paper, Clemson University, Clemson, SC.
Fradkin A (2017) Search, matching, and the role of digital marketplace design in enabling trade: Evidence from Airbnb. Working paper, Massachusetts Institute of Technology, Cambridge.
Ghose A, Ipeirotis P, Li B (2012) Designing ranking systems for hotels on travel search engines by mining user-generated and crowdsourced content. Marketing Sci. 31(3):492­520.
Ghose A, Ipeirotis PG, Li B (2014) Examining the impact of ranking on consumer behavior and search engine revenue. Management Sci. 60(7):1632­1654.
Hauser JR, Urban GL, Liberali G, Braun M (2009) Website morphing. Marketing Sci. 28(2):202­223.
Huang Z, Zeng DD, Chen H (2004) A unified recommendation framework based on probabilistic relational models. Fourteenth Annual Workshop Inform. Tech. Systems (WITS), 8­13.
Joachims T, Granka L, Pan B, Hembrooke H, Gay G (2005) Accurately interpreting clickthrough data as implicit feedback. Proc. 28th Annual Internat. ACM SIGIR Conf. Res. Development Inform. Retrieval (ACM, New York), 154­161.
Kim JB, Albuquerque P, Bronnenberg BJ (2010) Online demand under limited consumer search. Marketing Sci. 29(6):1001­1023.
Koulayev S (2014) Search for differentiated products: Identification and estimation. RAND J. Econom. 45(3):553­575.
Lohse G (1997) Consumer eye movement patterns on Yellow Pages advertising. J. Advertising 26(1):61­73.
Melville P, Mooney RJ, Nagarajan R (2002) Content-boosted collaborative filtering for improved recommendations. Eighteenth Natl. Conf. Artificial Intelligence, 187­192.
Montgomery AL, Li S, Srinivasan K, Liechty JC (2004) Modeling online browsing and path analysis using clickstream data. Marketing Sci. 23(4):579­595.

564

De los Santos and Koulayev: Optimizing Click-Through in Online Rankings Marketing Science, 2017, vol. 36, no. 4, pp. 542­564, © 2017 INFORMS

Moon S, Russell GJ (2008) Predicting product purchase from inferred customer similarity: An autologistic model approach. Management Sci. 54(1):71­82.
Petrin A, Train K (2010) A control function approach to endogeneity in consumer choice models. J. Marketing Res. 47(1):3­13.
Ricci F, Rokach L, Shapira B, Kantor PB, eds. (2011) Recommender Systems Handbook (Springer, New York).
Rust J (1987) Optimal replacement of GMC bus engines: An empirical model of Harold Zurcher. Econometrica 55(5):999­1033.
Schaupp LC, Bélanger F (2005) A conjoint analysis of online consumer satisfaction. J. Electronic Commerce Res. 6(2):95­111.
Urban GL, Liberali G, MacDonald E, Bordley R, Hauser JR (2014) Morphing banner advertising. Marketing Sci. 33(1): 27­46.

Villas-Boas JM, Winer RS (1999) Endogeneity in brand choice models. Management Sci. 45(10):1324­1338.
Vozalis M, Margaritis KG (2004) Unison-CF: A multiple-component, adaptive collaborative filtering system. De Bra PME, Nejdl W, eds. Adaptive Hypermedia and Adaptive Web-Based Systems, Lecture Notes Comput. Sci., Vol. 3137 (Springer-Verlag, Berlin Heidelberg), 255­264.
Weitzman M (1979) Optimal search for the best alternative. Econometrica 47(3):641­654.
Yu K, Schwaighofer A, Tresp V, Ma WY, Zhang HJ (2003) Collaborative ensemble learning: Combining collaborative and content-based information filtering via hierarchical Bayes. Uncertainty Artificial Intelligence: Proc. 19th Conf. (UAI-2003) (Morgan Kaufmann, San Francisco), 616­623.

