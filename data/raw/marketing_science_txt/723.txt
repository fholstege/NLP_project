Vol. 27, No. 5, September­October 2008, pp. 922­931 issn 0732-2399 eissn 1526-548X 08 2705 0922

informs ®
doi 10.1287/mksc.1070.0327 © 2008 INFORMS

Research Note
Competitive Brand Salience
Ralf van der Lans
Rotterdam School of Management, Erasmus University, Rotterdam, The Netherlands, rlans@rsm.nl
Rik Pieters
Tilburg University, Tilburg, The Netherlands, pieters@uvt.nl
Michel Wedel
Robert H. Smith School of Business, University of Maryland, College Park, Maryland 20742, mwedel@rhsmith.umd.edu
Brand salience--the extent to which a brand visually stands out from its competitors--is vital in competing on the shelf, yet is not easy to achieve in practice. This study proposes a methodology to determine the competitive salience of brands, based on a model of visual search and eye-movement recordings collected during a brand search experiment. We estimate brand salience at the point of purchase, based on perceptual features (color, luminance, edges) and how these are influenced by consumers' search goals. We show that the salience of brands has a pervasive effect on search performance, and is determined by two key components: The bottom-up component is due to in-store activity and package design. The top-down component is due to out-of-store marketing activities such as advertising. We show that about one-third of salience on the shelf is due to out-of-store and two-thirds due to in-store marketing. The proposed methodology for competitive salience analysis exposes the optimal visual differentiation level of a brand versus its competitors, and of each SKU versus the other SKUs of the same brand. The model of the visual search process and methodology for competitive salience analysis enable diagnostic analyses of the current levels of visual differentiation of brands and SKUs at the point of purchase, and provide directions for increasing these.
Key words: search goals; eye movements; Hidden Markov; brand salience; visual attention History: This paper was received on September 13, 2005, and was with the authors 17 months for 2 revisions;
processed by Greg Allenby. Published online in Articles in Advance May 23, 2008.

1. Introduction
Competitive clutter at the point of purchase is intense, due to stock-keeping unit (SKU) proliferation, brand extensions, me-too products, private labels, and copycats. As a consequence, searching brands on supermarket shelves is a daily challenge for consumers. Clutter causes consumers to accidentally pick up the wrong brands or not find their favorite brand at all. Therefore, manufacturers and retailers try to make the SKUs of their brands visually salient among competitors through improved package design and advertising. They seek an optimal level of differentiation of their brands and SKUs by balancing the visual salience of each SKU relative to competitors with a unique identity of the entire line of SKUs. At the same time, they need to obey established codes about the visual appearance of the category. To support this management task, the visual salience of SKUs and brands needs to be assessed, but how to accomplish this is far from obvious: there is no academic literature addressing this problem, but related literatures exist on variety perceptions of assortments (Broniarczyk et al. 1998, Herpen and Pieters 2002, Hoch et al. 1999)

and on the overlap within product portfolios (Aribarg and Arora 2007).
We intend to fill this gap and afford a detailed analysis of visual competition between brands based on the few seconds that consumers search for them on the shelf. Using eye-movement data collected in a brand search experiment, we develop a model of brand search and, based on this, a methodology to assess the competitive salience of brands, establish its effects on search performance, and show how to improve it through marketing. We begin with a description of the data.
2. Brand Search Experiment
During a computer-mediated brand search task for laundry detergents, eye movements were collected for a random sample of 109 regular consumers in the Netherlands (47 males and 62 females, between 16 and 55 years of age). Participants were individually seated behind 21-inch LCD computer screens (1 024 × 1 280) on which a shelf with six brands of laundry detergent was shown--four brands with three SKUs each and two brands with two SKUs each (16 SKUs in total). Multiple replications (facings) of SKUs were

922

van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience

Marketing Science 27(5), pp. 922­931, © 2008 INFORMS

923

present to mimic regular shelves at the point of purchase. Participants were randomly assigned to one of five conditions of a one-factorial between-subjects design in which they searched for one out of five different brands, respectively, Witte Reus Tablets, Omo Tablets, Persil Tablets, Sunil Tablets, and Dixan Tablets. In all cases, the search goal was directed at a specific SKU of a brand (the tablet SKU). The sixth brand, Ariel, is the market leader and serves as a baseline. Placement of the brands in the display was rotated across conditions and consumers to eliminate possible location effects, with the same number of facings in all conditions. Participants had a maximum of 10 seconds to find the target brand, and indicated having found the target brand by touching it on the touch-sensitive LCD screen, after which the brand search task ended. Eye movements, and latency and accuracy of search were recorded. For the details about eye tracking, we refer to Wedel and Pieters (2000). Figure A1 in the appendix provides an example of a scan-path across the shelf for one participant.
3. Brand Search: Theory and Model
3.1. Brand Search Theory In brand search, consumers try to find a target brand among distracters in a visual display, which is guided by eye movements. During eye fixations, information is extracted from small regions in the display, and during eye saccades attention is redirected rapidly to other potentially informative regions (Findlay 2005). Bottom-up effects--visual characteristics of the shelf--and top-down effects--the consumers' search goals--influence brand search. Basic perceptual features affect search bottom-up: color, luminance, and edges (Wolfe and Horowitz 2004). Brand search is easy when the target brand is dissimilar from all distracters on a single feature and when all distracters are similar on that feature (Duncan and Humphreys 1992). In that case, the target brand pops out and is found almost instantly, as when searching for the Heinz green ketchup among its uniformly red competitors. Brand search on retail shelves is difficult when targets share features with distracters and the distracters are heterogeneous among themselves, which is common. This creates spatial uncertainty: i.e., where in the display candidates are located, and identity uncertainty, i.e., what the identity of a located candidate is: target brand or distracter. During search, the visual brain likely alternates between a fast but less accurate "where" (localization) state to reduce spatial uncertainty and a slower but more accurate what (identification) state to reduce identity uncertainty (Niebur and Koch 1998).
A salience map guides eye movements during the where state. It is a topographic map, represented physically in the visual brain, that captures the visual

importance (salience) of all locations in the display (Niebur and Koch 1998, Thompson 2005). A location that contrasts with its surroundings on a perceptual feature is visually salient. The salience map is thought to be a weighted combination of the perceptual features at each location in the display. It enables individuals to search efficiently by shifting their focus of attention successively to display locations of decreasing salience, until the candidate is found.
The salience map is also influenced top down by the search goal. This occurs because the search goal selectively enhances presumably diagnostic and suppresses presumably nondiagnostic features of the target brand (Lee and Mumford 2003). For example, in a search for ketchup, the color red will be enhanced and candidate brands with this color will become more salient. Such enhancement and suppression due to search goals is effortful and may be limited to one or two features only, mostly colors (Wolfe and Horowitz 2004, Wolfe et al. 1990). The total salience that guides eye movements during search is the sum of bottomup salience due to the brand's perceptual features, and top-down salience due to the goal-based selective enhancement and suppression of these features (Yantis and Egeth 1999). Because bottom-up salience is determined by perceptual features of the visual display, it is independent of the search goal. A brand with large bottom-up salience, such as the Heinz green ketchup, will attract attention no matter what an individual's search goal is.
Eye movements in the where state are also guided by systematic search strategies (Monk 1984, Ponsoda et al. 1995). These strategies are based on the layout of the display, in particular the horizontal organization of product shelves in supermarkets. Horizontal eyemovement patterns (left-right and right-left) appear to prevail in target search (Gilchrist and Harvey 2006). Whereas eye movements guided by the salience map are mostly disorderly when salient display regions are nonadjacent, eye movements guided by systematic search strategies are orderly. The where state is characterized by longer saccades between brands.
Once a candidate brand is fixated, the brain switches to the what state to reduce uncertainty about the candidate's identity. This typically requires repeated fixations on the candidate, with small saccades between consecutive fixations. Search terminates when the consumer has sufficient evidence that the candidate is the target brand.
3.2. Operationalization of Variables We define the independent variables used in the model indexed by k = 1 K, for consumers c = 1 C, and eye fixations i = 1 Ic for each consumer c. These variables are derived from the image of the display and defined for each pixel u v

van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience

924

Marketing Science 27(5), pp. 922­931, © 2008 INFORMS

in it, where u = 1 1 024 and v = 1 1 280. These

variables correspond to the basic features processed

by the visual brain.

The first set of independent variables scik u v indexed by k  KM covers the constant and the perceptual features, i.e., colors, luminance, and edges,

contributing to the salience map. Colors were derived

from the RGB values of each pixel (the values range

from 0 to 255), using standard imaging software, with

luminance derived as Sluminance = 0 299R + 0 587G + 0 114B (Shapiro and Stockman 2001). Because colors

are collinear with luminance, we coded red, green,

and blue as dummy values (0/1) for each pixel. Edges

are extracted from the image using standard imag-

ing procedures that compute edges as the gradients

of luminance (Marr 1982). Whereas edges at various

levels of detail are available, we retained the edges

that determine for each pixel to which brand (multi-

ple SKUs) and to which SKU it belonged. We define

a dummy variable (0/1) for each pixel u v indi-

cating whether it belongs to a specific brand, and a

dummy variable indicating whether the pixel belongs

to a specific SKU. The region from which the eye

extracts information is larger than the exact pixel on

which it fixates and can be approximated by a bivari-

ate normal distribution (Motter and Holsapple 2001,

Pomplun et al. 2000). We therefore spatially smooth

the image data for each of the perceptual features by

a two-dimensional Normal kernel, using a bandwidth

of 2 degrees, which is the visual angle covered by the

fovea (Findlay 2005). We use the smoothed values of

these dummy variables at each pixel location u v .

The second set of independent variables scik i-1 u v , indexed by k  KS, contains two dummy variables reflecting left-right and right-left zigzag sys-

tematic search strategies, respectively. For example,

the left-right strategy is specified through dummy

scik i-1 u v = 1 for all new locations u v to the right of the previous fixation point i - 1 u v and 0

for all others.

The third set of independent variables scik i-1 u v , indexed by k  KT , contains two dummies reflecting refixation strategies on the same, SKU and SKUs of

the same brand, respectively, which variables charac-

terize the identification state. For example, a refixa-

tion on the same SKU is specified through a dummy

variable scik i-1 u v = 1 for all locations u v that pertain to the same SKU as the SKU in location u v

on fixation i - 1.

Thus, the data that are used as input for the model

consist of

C c=1

Ic

rows,

where

each

row

ic

specifies

the

location of fixation i for consumer c, along with the val-

ues of the K = 9 independent variables for all 1,310,720

(1 024 × 1 280) pixels of the display. The first set of

independent variables that defines the constant term,

colors, luminance, and edges is constant across fixa-

tions of a consumer, but differs between consumers because of the randomization of the shelf positions. The variables in the second and third sets, defining the systematic and refixation strategies, vary between consumers and fixations. Next to the fixation locations, for each consumer search accuracy (0/1) and latency (seconds) are used as dependent variables.

3.3. The Brand Search Model We develop a brand search model that extends the Hidden Markov Models (HMM) by Liechty et al. (2003) and van der Lans et al. (2007). Liechty et al. (2003) used an HMM to describe eye movements during free viewing of print ads. The present model goes beyond that study by including (a) the effects of image features, (b) systematic search strategies on eye movements, and (c) the use of the exact fixation locations on pixels rather than on a coarse spatial grid. We extend van der Lans et al. (2007) by (a) separating topdown from bottom-up salience, which is enabled by our combination of experimental design with a hierarchical Bayes formulation, and (b) integrating search accuracy and latency in the HMM model. Together, this makes it possible to comprehensively assess competitive brand salience and its effects on search performance, for which neither of these two previous approaches allows. In the appendix the scan path of one participant is used to illustrate how the model explains eye movements.

3.3.1. Eye Movements. The model describes, for

consumer c = 1 C, the location of a fixation as a

choice among all pixels D1 × D2 = 1 024 × 1 280 of the display. Thus, the location of every fixation i is a

choice of one out of all pixels. Each fixation is either

generated in the localization state (j = 1) or in the

identification state (j = 2). Switching between these

two attention states is represented by an HMM, with

probabilities j j (Liechty et al. 2003). We let j u v · be the probability that the next fixation is in loca-

tion u v  D1 D2 , given that this fixation is generated in attention state j. In the localization state

(j = 1), j=1 u v · is based on the salience map and systematic search strategies. In the identification

state (j = 2), j=2 u v · represents the probability of refixating on the previously fixated SKU or brand.

We thus have S = 2 systematic strategies (left-right

and right-left zigzag) and T = 2 (SKU surface and

brand surface) refixation strategies. The dimensions

of the scik = scik u v and scik i-1 = scik i-1 u v are D1 × D2 .
The fixation probabilities j u v jc sci are a function of these variables with consumer and state-

specific weights,

ci, with

sci =

scik

K k=1

a collection

of K D1 × D2 matrices. These weights are assumed

to have a normal distribution to account for hetero-

geneity, jc  N j j , with a diagonal covariance

van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience

Marketing Science 27(5), pp. 922­931, © 2008 INFORMS

925

matrix j . A square-root link function is used for j · . This ensures that j ·  0, which is appealing because it describes probabilities on a two-dimensional sur-
face, and makes the computation of fixation probabil-
ities feasible (van der Lans et al. 2007):

u v jc sci

  = 

Salience map

scik u v jck
kKM Systematic strategy

+

scik i-1 u v jck

kKS

scik i-1 u v
kKT

2 jck

2
Rjci
Rjci

j =1 j =2

(1)

Repeated fixation

where Rj=1 c i = uD1 vD2 s kKM KS cik i-1 u v

and Rj=2 c i =

uD1 vD2 kKT scik i-1 u v

jck 2, jck 2.

To ensure that the expression in (1) is a probability

across all pixels, we normalize by Rjci for all states j, consumers c, and fixations i. Because of this, one

parameter in each attention state is not identified and

we restrict the constant in the localization state, and

the SKU refixation strategy in the identification state

to be equal to 1.1

The probability of a sequence of fixations of a consumer c, yceye = yceiye , with yci the location of the ith fixation in pixel coordinates, is written as an HMM:

P yceye c

sc

2

2 nc

= ···

y eye
ji-1 ji ji ci

jic sci u v

(2)

j2=1 jnc =1 i=2

where sc =

sci

nc i=1

.

For

identification

purposes,

the

first

fixation is assumed to be in the localization state, i.e.,

j1 = 1. Furthermore, Equation (2) does not include the probability of the first fixation (i = 1). At or before

this fixation the visual brain is believed to rapidly

segment the search display and extract perceptual fea-

tures from it to build the salience map (Itti and Koch

2001, Koch and Ullman 1985). Therefore, the first fix-

ation is used to initialize the transition probabilities

of the refixation and systematic strategies, and is not

affected by them.

In the experiment, there are g = 1 G groups of

consumers, each with a different search goal. Each

of the G = 5 goals affects the salience map differ-

ently, which makes it possible to assess the compet-

itive salience of brands and SKUs. Search goals are

1 We normalized for each consumer c, the perceptual features, and surfaces, such that the sum of their squared values across all display locations equals 1, so that the estimates of are comparable across variables.

thought to impose a hierarchical prior on the weights

of the individual perceptual features in the salience

map (Lee and Mumford 2003). For example, if search-

ing for a brand that is remembered to be mostly blue,

the color blue will receive higher top-down weight.

To capture this, we specify a normal prior distribu-

tion c1  N + g j for the salience weights, c1k,

k  KM . We specify

G g=1

g = 0, so that the mean for

group g equals + g, and consists of an overall

effect , and an effect of the specific search goal g.

Our interpretation of these parameters is based on

the assumption that the effect of each feature that is

common across the five search goals is the (mean)

bottom-up effect of the display. That is, the effect that

the color red, for example, has on the eye-movement

pattern under each of the search goals is what we

designate as its bottom-up effect. Differences in salience

weights between the five search goals are interpreted

as their (mean) top-down effects. That is, if red receives

a different weight when searching for brand A than

it does when searching for brand B, then we believe

this to be induced by the search goals for these two

brands. The diagonal covariance matrix j captures heterogeneity in the salience weights across individ-

uals. Thus, individuals have different weights for

the basic features, and have different salience maps,

and these maps are influenced hierarchically by the

(mean) bottom-up and top-down g effects.

3.3.2. Search Performance. As an integral component of the model, we allow search performance to be influenced by three aspects of the eye-movement model: fr c , r = 1 3. These are not fixed independent variables, but are functions of the eyemovement model parameters:

1 f1

1c = target
Display

kKM scik u v 1ck 2 du dv kKM scik u v 1ck 2 du dv

captures the relative salience of the target brand in the localization state (higher salience indicates lower spatial uncertainty), where the integral is approximated as a sum over all pixels u v in the target brand.
2. f2 cj  iBTc I zc i = 2 is the total time in the identification state when attending to the target brand (attending longer to the target in the identification state should lead to more accurate decisions), where zci  1 2 is a latent variable (computed in the Gibbs sampler) that indicates the state from which fixation i of consumer c is generated, and BTc are the fixations on the target.
3. f3 cj  iBDc I zc i = 2 is the relative time in the identification state when attending to distracter brands (shorter duration indicates lower identity uncertainty), where BDc are the fixations on all nontarget brands.

van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience

926

Marketing Science 27(5), pp. 922­931, © 2008 INFORMS

For each consumer c, search accuracy ycacc and the log of search time yctime indicate search performance. For search accuracy we use a probit formulation, and

define the continuous latent normal variable

acc c

that

is positive for ycacc = 1 and negative otherwise, which

leads to

yctime

time acc

perf

acc

c

c







 N 

time 0

+

r

acc 0

+

rtime fr

acc r

fr

c 
c

perf 

(3)

r

where

time r

and

acc r

represent

the

coefficients

for

log

search time and accuracy, respectively, and perf is a

full covariance matrix.

3.4. Estimation and Inference The model is estimated with an Markov chain Monte Carlo (MCMC) algorithm2 with auxiliary variables (Damien et al. 1999) to estimate c. We follow Robert et al. (1993) to estimate the HMM, and a Metropolis Hastings step (Chib and Hamilton 2000) to estimate perf, using 25,000 draws, thinned 1 in 10, with a burn-in of 25,000 iterations. In synthetic data analyses the parameters are recovered well. We compare several alternative models based on the log marginal density, computed using Chib (1995). We compute the hold-out Mean Absolute Deviation (MAD) and hitrate for search latency and accuracy, for a random sample of one-third of the participants, by considering ycacc and yctime missing for these participants and sampling them from their predictive distributions within the MCMC algorithm. We compare models with and without systematic search, identification, and effects of search goals.

4. Findings
The data contain 1,762 fixations on the display during the search task. Average brand search time was 3.82 seconds (SD = 2 02), and did not vary much across the tasks. Of the 109 consumers, 88% correctly located the target brand. Most failures (9%) were due to incorrectly locating brands.
4.1. Model Comparisons Six different models are compared using the logmarginal density (LMD): a single-state model with salience only, a single-state model with salience and systematic search, and a two-state model with salience, systematic search in the localization state,

2 A Technical Appendix presenting the details of the MCMC algorithm can be downloaded from the Marketing Science website at http://mktsci.pubs.informs.org.

and an identification state, each with and without effects of search goals. Model fit improves when systematic search is added (LMD = -22 223) to the one-state salience-only model (LMD = -22 290). Adding the identification state improves fit substantially (LMD = -20 782). Whereas adding the effects of search goals to the one-state salience-only model decreases fit (LMD = -22 443), adding effects of search goals results in an improvement in fit once systematic search (LMD = -22 066) and the identification state are accounted for (LMD = -20 722). These model comparisons support the full two-state model with goal effects on salience, and strategic search; it explains search performance very well and better than the five competing models. The hold-out MAD of predicted search time and the Hit Rate (HR) for search accuracy are 1.79 sec and 81%, respectively, for the full model. Models without search goals (MAD: 1.82 sec, and HR: 80%), and especially without the identification state (MAD: 1.97 sec, HR: 81%) predict search performance significantly worse, and our model improves over the other three benchmark models, as well.
4.2. Parameter Estimates Table 1 shows the posterior means of the parameters. Reducing identity uncertainty is somewhat more important than reducing location uncertainty: the limiting probabilities of the Hidden Markov Chain reveal that consumers spent 32% of the time in the localization state and 68% of the time in the identification state. Consumers are highly likely to refixate the last fixated brand in the latter state; 90% of the consumers terminated search in that state, presumably after having identified the target brand. Saccade lengths are on average 3.4 times larger in the localization state (posterior median 332.0 pixels) than in the identification state (97.2 pixels), which provides evidence of the qualitatively different attention processes that guide eye movements in these two states (Bullier et al. 1996, Thompson 2005).
Table 1 shows that salience guides attention in the localization state. All individuals have positive posterior median salience weights for blue, and there is substantial heterogeneity. The positive weight of luminance indicates that attention is directed to the brighter locations in the display. Systematic search strategies guided attention strongly as well, independent of salience. In fact, there is a stronger tendency to use the left-right zigzag strategy (posterior median: 0.446) than the right-left zigzag strategy (posterior median: 0.359); consumer heterogeneity in these effects is fairly small. These results are obtained across rotated search displays, and thus are not due to specific positions of brands and SKUs. More salient brands are indeed found faster (posterior median: -0 090) and more accurately (posterior

van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience

Marketing Science 27(5), pp. 922­931, © 2008 INFORMS

927

Table 1 Attention Guidance During Target Search and Its Effects on Search Performance Medians of the Posterior Distributions of Parameters

Eye movements

Bottom-up

Top-down

Search performancea

Parameters

Mean

Witte Reus

Omo

Persil

Sunil

Dixan

log(time)

Accuracy

Own transitions Identification Localization
Identification: Refixation Targetb Nontargetsc
Localization: Salience Blue Green Red Luminance
Systematic search Left-right zigzag Right-left zigzag
Covariance log(time) Accuracy

0 720 0 406
1 090
0 122 0 015 0 022 0 091
0 446 0 359

-0 178 -0 132 -0 203
-0 103

0 028 -0 149
0 130 0 315

-0 051 0 273 0 007
-0 025

0 077 0 041 -0 075 -0 141

0 124 -0 029
0 144 -0 022

0 056 0 822
-0 090

0 178 0 054

90% posterior confidence interval does not contain 0, 95% posterior confidence interval does not contain 0. aWe included a constant and brand dummies to control for brand specific search performance effects; salience multiplied by 100. bNumber of identification fixations on SKUs of target brand. cProportion of fixation frequency on SKUs of competitive brands in identification state. dVariance of search accuracy set to one for identification.

0 391 -4 144
2 705
0 054 1d

median: 2.705). Furthermore, consumers who direct

more identification fixations to the target are more

accurate at the expense of longer search times. The

correlation between search time and accuracy is posi-

tive but low and positive, which reflects an accuracy-

effort trade-off.

Figure 1 shows the mean bottom-up and top-down

salience maps for two brands (C and E). Note that the

maps are derived from the localization state, and that

systematic search patterns in the localization state and

repeated fixations on the target brand in the identifi-

cation state do not play a role in their construction.

The maps are computed as BU u v = u v k 2, and TD u v = kKM scik u v

kKM
k+

scik
gk

·
2

- kKM scik u v k 2, for the bottom-up and top-

down components, respectively, and are evaluated at

the posterior medians of the parameters in question.

The figure reveals the dramatic effects of search goal

effects on the salience maps.

Figure 2 presents for each of the five target brands

the salience per pixel and the proportion of this due to

the display, u v target BU u v , and the search goal, u v target TD u v . The search targets are highly
salient, as revealed in comparison to the average

salience per pixel across the image (normalized to

equal 1), shown as a horizontal line on the graph.

There are important differences in brand salience. For

instance, whereas brand B (Omo) and brand D (Sunil) are equally salient, the salience of brand B is more due to its visual image (73%) than is the case for brand D (56%). Search goals account for about onethird of salience. This suggests roughly a 1 to 2 ratio in the effectiveness of strategies to influence salience through out-of-store versus in-store marketing activities, respectively.
Figure 2 suggests avenues for building salience through in-store visual marketing. For example, Brand A (Witte Reus) is relatively salient when it is the search target, but its low bottom-up salience suggests that, when it is not on the consumers' shopping list, the visual features of this brand are insufficient to have the brand make eye contact. The estimated bottom-up weights of perceptual features suggest how to improve this, however. The brand may, for example, increase the amount of blue in its package, because that color is already present in its package and blue contributes most to its salience.
Figure 2 also provides input for out-of-store activities such as advertising. For example, brand C (Persil) has a relatively small lift of its salience when it is the target of search. Its diagnostic color is green and there is much heterogeneity in the salience weight of that color. Apparently, its green packaging does not facilitate pop-out on the shelf, which is perhaps

van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience

928

Marketing Science 27(5), pp. 922­931, © 2008 INFORMS

Figure 1

Illustration of Display (Bottom-Up) and Search Goal (Top-Down) Effects on the Salience Map

Target brand C (Persil)

Target brand E (Dixan)

Top-down salience

Top-down salience

Saliency

Saliency

Total salience

Total salience

Saliency

Saliency

Bottom-up salience

Saliency

Dixan

Ariel

Persil

Witte Reus Sunil

Omo

Figure 2

Sources of Brand Salience: Display (Bottom-Up) and Search Goal (Top-Down)

2.5

Bottom-up Top-down

Average salience

Salience

2.0

1.5
37% 1.0

0.5

63%

27% 73%

34% 66%

44% 56%

39% 61%

0 Brand A Brand B
Witte Reus Omo

Brand C Persil

Brand D Sunil

Brand E Dixan

Note. Salience is rescaled per pixel for comparability. The line in the histogram represents the average salience (set equal to 1) on the search display, i.e., corresponding to a flat noninformative salience map.

due to confusion with the green packaging of the market leader, Ariel. But, even worse, consumers do not appear to have strong memory for the visual image of brand C. Advertising should strengthen the association between the brand and its green color to make the brand easier to find when it is on consumers' shopping lists.
5. Analysis of Competitive Brand Salience
The estimation of salience and its decomposition into top-down and bottom-up components makes it possible to analyze the competitive salience of brands. Such an analysis reveals visual strengths and weaknesses of brands and their SKUs at the point of purchase. On a continuum of completely similar to completely dissimilar, both brands and their SKUs need to attain an optimum visual differentiation level.

van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience

Marketing Science 27(5), pp. 922­931, © 2008 INFORMS

929

When brand differentiation is optimal, a brand becomes more salient to consumers that search for it, while at the same time the salience of all competing brands is suppressed. All five brands in our experiment became more salient when they were the search target. Although none of the brands suppressed salience of all competing brands as would be desirable, brand differentiation was closest to optimal for brand D (Sunil). When this brand was the target, the salience of three competing brands was reduced significantly. Brand C (Persil), on the other hand, appears to be underdifferentiated. When it was the search target, the three SKUs of the market leader (Ariel) became more salient as well, and even more so than brand C itself (see Table 2). To improve its visual competitiveness, this brand's visual image needs to become more strongly differentiated from the market leader. Some visual features are shared by all brands in a product category, such as the color red for tomato ketchup. A brand that is overdifferentiated on such category codes could experience adverse effects. This did not occur in the current empirical analysis, but would manifest itself when all or many competing brands gain more in salience than the target brand, which becomes hard to find.
When SKU differentiation is optimal, a SKU that is searched for and the other SKUs of the same brand become more salient, but the latter less strongly so. Two of the five brands exhibited a close-to-optimal pattern, namely, brands B (Omo) and D (Sunil). However, some of the SKUs of brands A (Witte Reus) and E (Dixan) appear to be overdifferentiated. Specifically, two SKUs of brand A (Color Reus and Witte

Table 2 Analysis of Competitive Brand Salience

Target brands during search

Competitive salience effects

A1

B1 C1 D1 E1

Witte Reus Omo Persil Sunil Dixan

A 1 Witte Reus tablets 2 Color Reus 3 Witte Reus Vloeibaar
B 1 Omo tablets 2 Omo color
C 1 Persil tablets 2 Persil color 3 Persil gel
D 1 Sunil tablets 2 Sunil color
E 1 Dixan tablets 2 Dixan Megaperls 3 Dixan gel
F 1 Ariel essential 2 Ariel color 3 Ariel hygiene

4 12 -0 57
0 03
-8 05 -1 10
-1 61 -0 15
0 79
-0 98 1 14
-3 98 -0 89
0 82
-1 13 -1 39 -1 04

1 61 -3 24 -1 31 -2 57 0 27 -0 80 -0 60 1 49 1 21 -0 35 -0 65 -0 32

7 16 -3 34 -1 12 5 41 4 84 -1 89 -3 04 -0 46

0 85 0 44 -1 21

2 77 -1 81 -1 35 0 67 -0 79 -0 75 2 53 0 59 -0 95

-4 56 -2 13 5 53 2 78 -3 19 -0 60 3 31 -0 02

-0 31 -3 07 -0 16 -0 92 -0 63 -0 28

0 25 5 57 0 29 1 26 0 79 -0 01

-2 59 -2 09 -1 07

7 22 -0 29 -1 69 6 49 -0 40 -1 53 2 06 -0 11 -0 18

Note. Median parameter estimates (multiplied by 100) are presented. Estimates in bold are from 0.025­0.975 credible intervals not covering 0.

Reus Vloeibaar) do not become more salient when the Tablets-SKU of that brand is the search target. The same holds for the SKU of brand E (Dixan Gel). To achieve an optimal level of differentiation, the SKUs of these brands need to increase the similarity of their visual features. When SKUs are underdifferentiated the salience of the other SKUs of the brand in question are increased at least as much as the salience of the target SKU, and the SKUs may be too hard to distinguish. Brand C (Persil) exhibits this pattern: the salience of the Gel-SKU is enhanced equally as that of the target Tablets-SKU. To achieve an optimal differentiation level, this brand needs to differentiate the visual features of its SKUs better.
6. Conclusion
Competition on the shelves of supermarkets is intense, and most of that competition is visual. Retailers and manufacturers aim to make their brands stand out to enable consumers to find them quickly, or to pick them up serendipitously on impulse. However, how to make brands salient at the point of purchase is not obvious, and that is an issue with which brand managers and retailers grapple. They seek to make their brands and SKUs more salient than those of their competitors, while obeying established norms about the visual appearance of the category. Both in-store (packaging) and out-of store (advertising) marketing efforts are applied to that end.
Our study reveals that about one-third of salience on the shelf is due to out-of-store and two-thirds due to in-store marketing. This underlines that the integration of advertising with packaging strategies should be a key concern (Keller and Lehmann 2006). The relatively small top-down influences on salience that we found for some brands in our study may well be attributable to a lack of integration of packaging and advertising strategies for some brands.
We have shown that the salience of brands has a pervasive effect on search performance, but it appears that consumers use only one or two basic features simultaneously when trying to find a brand rapidly and accurately. This has important implications for package design, and for advertising that aims to increase brand salience on the shelf. Such advertising would need to establish strong associations in memory with a limited number of unique features.
We have proposed a methodology for competitive brand salience analysis and a framework to guide thinking about competitive salience by exposing the optimal visual differentiation level, of a brand versus competitors, and of each SKU versus the other SKUs of the same brand. Our model of the visual search process, captured through eye tracking, helps to identify current levels of visual differentiation of

van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience

930

Marketing Science 27(5), pp. 922­931, © 2008 INFORMS

brands and SKUs at the point of purchase and enables diagnostic analysis of competitive salience. Naturally, underdifferentiation of brands leads to brand confusion and reduces market share. But overdifferentiating brand packaging from the category comes with risks as well, because brands that differ too much from the category codes may not be found easily. Visual differentiation of SKUs should play a role in managing product line length and in decisions of product line extensions. Visual underdifferentiation may affect consumers' preference for the brand (Hui 2004) and lead to cannibalization. Overdifferentiation of SKUs may diminish unique brand associations and erode brand equity.
Future research could investigate how such factors as the number, facings, and arrangements of brands and SKUs on the shelf affect salience and search. Extending the present analysis to other visual marketing stimuli, including brand logos and ads and to dynamic contexts, including web pages and TV commercials, are other avenues for future research.
Acknowledgments The authors thank the editor, area editor, and the reviewers for their helpful comments. The authors also thank Dominique Claessens of Verify International for the eyetracking database.
Appendix We use the scan path of one participant in Figure A1 to illustrate how the model explains the eye movements. This scan

path is of Participant 3 searching for brand E (Dixan Tablets; fourth SKU at the top shelf). It consists of 12 fixations, each next fixation shown in a separate panel of the figure, starting at the top-left and ending at the bottom-right panel. The (estimated median) attention state is shown for each fixation (j = 1: location, j = 2: identification). Also shown are for each SKU, the fixation probabilities given the attention state. These probabilities are obtained by integrating the pixel-by-pixel fixation probabilities, j u v · as computed from the individual-specific parameter estimates of the model, over the area of the SKU on the shelf (note that these probabilities do not need to sum to one across SKUs, since fixations may fall outside of any of the brand facings on the shelf). Figure A1 shows that switching between localization and identification causes the predicted probabilities of the location of a next fixation to change continuously at every fixation.
At the first fixation (Panel 1, top left), the consumer is in the localization state (j = 1). Eye movements at this first fixation are entirely driven by the salience map. The target (SKU4) has a probability of 0.145 of being fixated, which is caused by Participant 3's large salience weights for blue and red. The first fixation lands on SKU3. This individual has a strong tendency to use a left-right zigzag strategy, which makes subsequent fixations to the right of SKU3 more likely. This causes the probability that the second fixation is the target to jump to 0.328. Nevertheless, due to the stochasticity in the process, the second fixation (Panel 2) in fact falls on SKU7. At the third and fourth fixations (Panels 3­4) the participant is in the identification state (j = 2). The probability to refixate on the same SKU7 then jumps to 0.778, but the probability to fixate on the target (SKU4) drops to 0.

Figure A1. Illustration of the Observed Eye-Movement Pattern for One Participant

i = 1: 0 ­180 ms. j = 1

2.5% 25% 2.6% 14.5% 4.2% 0.8%

4.7% 3.8%

3.7% 1.8%

0.8%

0.5%

10.2% 4.7% 4.3% 18.8%

i = 2: 180­380 ms. j = 1

2.5% 12.2% 3.9% 32.8% 3.7% 0.4%

2.6% 2.1% 0.5%2.2% 1.0% 0.3%

5.6%

2.6% 2.4%

10.3%

i = 3: 380­600 ms. j = 2

i = 4: 600­900 ms. j = 2

0.0%

0.1% 0.0% 0.0% 0.0%

0.0%

77.8%

11.5% 1.3% 0.1%

0.0% 0.0%

0.0% 0.1% 0.0%

0.0%

0.1% 0.0% 0.0%

0.0% 0.0% 0.0%

77.8%

11.5% 0.1% 0.0%

1.3%

0.0%

0.0% 0.1% 0.0%

0.0%

i = 5: 900 ­1,120 ms. j = 1

i = 6: 1,120­1,340 ms. j = 1

i = 7: 1,340­1,580 ms. j = 2

i = 8: 1,580 ­1,740 ms. j = 1

1.4% 1.4% 1.5%

8.0% 2.3% 0.4%

1.6% 1.5% 1.5%

8.3%

2.4% 0.4%

4.6%

13.6% 1.2% 2.1%

1.0% 0.3%

16.8%

3.4% 0.5%

2.1%

1.0%

0.3%

27.6% 3.8% 2.4% 10.5%

7.5%

20.1% 3.1%

10.9%

0.0% 0.0% 0.0%

0.0%

0.0% 0.0%

0.0% 0.0%

0.0% 0.0%0.1%

0.0% 0.0%

1.0%

60.7%

37.4%

1.9% 1.9% 2.0%

11.0%

3.2% 0.6%

3.5% 7.7%

2.9%

3.0% 1.4%

0.7%

0.4%

4.3% 20.6 %

16.5%

i = 9: 1,740 ­2,460 ms. j = 2

i = 10: 2,460­2,540 ms. j = 2

i = 11: 2,540­2,720 ms. j = 2

i = 12: 2,720­2,920 ms. j = 2

0.0% 0.0% 0.4%

32.0%

49.5% 5.2%

0.0% 0.0% 0.4%

32.0%

49.5% 5.2%

0.0% 0.0% 1.7%

80.0%

9.3% 1.3%

0.0% 0.0% 1.7%

80.0% 9.3% 1.3%

0.0% 0.0% 0.0% 0.0% 0.0% 0.0%

0.0%

0.0% 0.0% 0.0%

0.0% 0.0%

0.0% 0.0% 0.0%0.1% 0.0% 0.0%

0.0%

0.0% 0.0%0.1% 0.0% 0.0%

0.0% 0.0% 0.0% 0.0%

0.0% 0.0% 0.0% 0.0%

0.0% 0.0%

0.0% 0.0%

0.0%

0.0%

0.0% 0.0%

Note. An observed eye-movement pattern consisting of 12 eye fixations of a consumer searching for Dixan Tablets (4th SKU at the top shelf), starting at the top-left panel (i = 1 - symbol ), and ending at the bottom-right panel (i = 12 - symbol ). Predicted posterior probabilities of fixation per SKU are shown.

van der Lans, Pieters, and Wedel: Research Note: Competitive Brand Salience

Marketing Science 27(5), pp. 922­931, © 2008 INFORMS

931

Apparently, the identification process does not result in a match, and search continues.
At Fixation 5 the probability of fixating the target is 0.080, but the probability of fixating SKU13 increases to 0.276, because, similar to the target, that brand has much blue and red. The fifth fixation thus lands on SKU13. At Fixations 5 and 6 (Panels 5 and 6), the individual's use of the left-right zigzag strategy is apparent as the eyes move along the shelf to the right. At Fixation 7 (Panel 7), the individual is again in the identification state and examines the other SKU of the previously inspected brand Omo. Fixation 8 (Panel 8) lands on the target brand, but on SKU5 rather than on target SKU4. The consumer is in the identification state (j = 2) for the next four fixations. Fixations 10 to 12 are on the target SKU4, which has a fixation probability of 0.800. This results in accurate target identification, in 2,920 milliseconds.
References
Aribarg, A., N. Arora. 2008. Inter-brand variant overlap: Impact on brand preference and portfolio profit. Marketing Sci. 27(3).
Broniarczyk, S. M., W. D. Hoyer, L. McAlister. 1998. Consumers' perceptions of the assortment offered in a grocery category: The impact of item reduction. J. Marketing Res. 35 166­176.
Bullier, J., J. D. Schall, A. Morel. 1996. Functional streams in Occipito-Frontal connections in the monkey. Behav. Brain Res. 76 89­97.
Chib, S. 1995. Marginal likelihood from the Gibbs output. J. Amer. Statist. Assoc. 90(432) 1313­1321.
Chib, S., B. H. Hamilton. 2000. Bayesian analysis of cross-section and clustered data treatment models. J. Econometrics 97 25­50.
Damien, P., J. Wakefield, S. Walker. 1999. Gibbs sampling for Bayesian non-conjugate and hierarchical models by using auxiliary variables. J. Roy. Statist. Soc.: Ser. B 61 331­344.
Duncan, J., G. W. Humphreys. 1992. Beyond the search surface: Visual search and attentional engagement. J. Experiment. Psych.: Human Perception Performance 18(2) 578­588.
Findlay, J. M. 2005. Covert attention and saccadic eye movements. L. Itti, G. Rees, J. K. Tsotsos, eds. Neurobiology of Attention. Elsevier Academic Press, Amsterdam, 114­116.
Gilchrist, I. D., M. Harvey. 2006. Evidence for a systematic component within scan paths in visual search. Visual Cognition 14(4­8) 704­715.
Herpen, E. van, R. Pieters. 2002. The variety of an assortment: An extension to the attribute-based approach. Marketing Sci. 21(3) 331­341.
Hoch, S. J., E. T. Bradlow, B. Wansink. 1999. The variety of an assortment. Marketing Sci. 18(4) 527­546.
Hui, K.-L. 2004. Product variety under brand influence: An empirical investigation of personal computer demand. Management Sci. 50(5) 686­700.
Itti, L., C. Koch. 2001. Computational modelling of visual attention. Nature Rev. Neuroscience 2(3) 194­203.

Keller, K. L., D. R. Lehmann. 2006. Brands and branding: Research findings and future priorities. Marketing Sci. 25(6) 740­759.
Koch, C., S. Ullman. 1985. Shifts in selective visual attention: Towards the underlying neural circuitry. Human Neurobiology 4 219­227.
Lee, T. S., D. Mumford. 2003. Hierarchical Bayesian inference in the visual cortex. J. Optical Soc. America 20(7) 1434­1448.
Liechty, J., R. Pieters, M. Wedel. 2003. Global and local covert visual attention: Evidence from a Bayesian Hidden Markov model. Psychometrika 68(4) 519­541.
Marr, D. 1982. Vision: A Computation Investigation into the Human Representation and Processing of Visual Information. W. H. Freeman and Company, San Francisco.
Monk, T. H. 1984. Search. J. S. Warm, ed. Sustained Attention in Human Performance. Wiley, New York, 293­321.
Motter, B. C., J. W. Holsapple. 2001. Separating attention from chance in active visual search. J. Braun, C. Koch, J. L. Davis, eds. Visual Attention and Cortical Circuits. MIT Press, Cambridge, MA, 159­175.
Niebur, E., C. Koch. 1998. Computational architectures for attention. R. Parasuraman, ed. The Attentive Brain. MIT Press, Cambridge, MA, 163­186.
Pomplun, M., E. M. Reingold, J. Shen, D. E. Williams. 2000. The area activation model of saccadic selectivity in visual search. L. R. Gleitman, A. K. Joshi, eds. Proc. Twenty Second Annual Conference Cognitive Science Society, Philadelphia, 543­548.
Ponsoda, V., D. Scott, J. M. Findlay. 1995. A probability vector and transition matrix analysis of eye movements during visual search. Acta Psychologica 88 167­185.
Robert, C. P., G. Celeux, J. Diebolt. 1993. Bayesian estimation of Hidden Markov chains: A stochastic implementation. Statist. Probab. Lett. 16 77­83.
Shapiro, L. G., G. C. Stockman. 2001. Computer Vision. Prentice Hall, Upper Saddle River, NJ.
Thompson, K. G. 2005. Dissociation of selection from saccade programming. L. Itti, G. Rees, J. K. Tsotsos, eds. Neurobiology of Attention. Elsevier, San Diego, 124­129.
van der Lans, R., R. Pieters, M. Wedel. 2008. Eye-movement analysis of search effectiveness. J. Amer. Statist. Assoc. Forthcoming.
Wedel, M., R. Pieters. 2000. Eye fixations on advertisements and memory for brands: A model and findings. Marketing Sci. 19 297­312.
Wolfe, J. M., T. S. Horowitz. 2004. What attributes guide the deployment of visual attention and how do they do it? Nature Rev. Neuroscience 5(June) 1­7.
Wolfe, J. M., K. P. Yu, M. I. Stewart, A. D. Shorter, S. R. FriedmanHill, K. R. Cave. 1990. Limitations on the parallel guidance of visual search: Color × color and orientation × orientation conjunctions. J. Experiment. Psych.: Human Perception Performance 16(4) 879­892.
Yantis, S., H. E. Egeth. 1999. On the distinction between visual salience and stimulus-driven attentional capture. J. Experiment. Psych.: Human Perception Performance 25(3) 661­676.

