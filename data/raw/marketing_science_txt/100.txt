http://pubsonline.informs.org/journal/mksc/

MARKETING SCIENCE
Vol. 38, No. 3, May­June 2019, pp. 417­441 ISSN 0732-2399 (print), ISSN 1526-548X (online)

Recommending Products When Consumers Learn Their Preference Weights

Daria Dzyabura,a,b John R. Hauserc
a New Economic School, Moscow, Russia 121353; b Stern School of Business, New York University, New York, New York 10012; c MIT Sloan School of Management, Massachusetts Institute of Technology, Cambridge, Massachusetts 02142 Contact: ddzyabur@stern.nyu.edu, http://orcid.org/0000-0003-0729-2379 (DD); hauser@mit.edu,
http://orcid.org/0000-0001-8510-8640 (JRH)

Received: March 22, 2016 Revised: October 31, 2017; April 24, 2018 Accepted: May 1, 2018 Published Online in Articles in Advance: May 22, 2019
https://doi.org/10.1287/mksc.2018.1144
Copyright: © 2019 INFORMS

Abstract. Consumers often learn the weights they ascribe to product attributes ("preference weights") as they search. For example, after test driving cars, a consumer might find that he or she undervalued trunk space and overvalued sunroofs. Preference-weight learning makes optimal search complex because each time a product is searched, updated preference weights affect the expected utility of all products and the value of subsequent optimal search. Product recommendations, which take preference-weight learning into account, help consumers search. We motivate a model in which consumers learn (update) their preference weights. When consumers learn preference weights, it may not be optimal to recommend the product with the highest option value, as in most search models, or the product most likely to be chosen, as in traditional recommendation systems. Recommendations are improved if consumers are encouraged to search products with diverse attribute levels, products that are undervalued, or products for which recommendation-system priors differ from consumers' priors. Synthetic data experiments demonstrate that proposed recommendation systems outperform benchmark recommendation systems, especially when consumers are novices and when recommendation systems have good priors. We demonstrate empirically that consumers learn preference weights during search, that recommendation systems can predict changes, and that a proposed recommendation system encourages learning.

History: K. Sudhir served as the senior editor and Peter Fader served as associate editor for this article. Supplemental Material: The data files and online appendix are available at https://doi.org/10.1287/
mksc.2018.1144.
Keywords: recommendation systems · learned preferences · multiattribute utility · consumer search

1. Introduction
Our basic premises are that (1) in some product categories consumers learn their preference weights by searching products and (2) many recommendation systems can anticipate a consumer's (true) preference weights better than novice consumers. (By "preference weights," we refer to the weights that a consumer places on an attribute level in an additive multiattribute utility function.) We argue that premise (1) changes a consumer's optimal search path and that premises (1) and (2) change the recommendation that a recommendation system should make.
1.1. Motivation of Premise (1): PreferenceWeight Learning
Consider Candace and Dave, who were moving to a new city. They wanted a condominium with two bedrooms, two bathrooms, a good school district, hardwood floors, an island kitchen, adequate lighting, proximity to work, and a full-service concierge. They had full access to Multiple Listing Service (MLS) listings and could search attributes of condominiums easily but sought a real

estate agent's recommendations. Based on an agent's recommendation, they visited one condominium that had a playground across the street. Seeing the playground, Candace and Dave realized how convenient this feature would be for them. Although they always valued playgrounds, they had not previously considered proximity to playgrounds to be an important decision criterion for a home. Their preference weight for playgrounds was substantially larger after seeing the condominium near a playground than before. As they decided what to search further, playground proximity was weighted more heavily. Playground proximity influenced their selection of condominiums to search and their choice of which condominium to buy.
Preference-weight learning applies broadly, for example, to a high school student learning about what to value in undergraduate research programs during college search, consumers learning about new features as they search for new automobiles, first-time parents learning how nannies affect their lifestyle, and even many singles dating and searching for partners. See Cook (2012), Finkel et al. (2012), and Sheehy (2013) for

417

418

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

further examples. The common thread in all these examples is that novice consumers, the kind most likely to seek recommendations, revised their preference weights after carefully evaluating products, services, or people during costly search. Consumers updated prior beliefs about preference weights after search and used the updated preference weights for subsequent search and for choice at the end of search. Preference-weight learning appears common even in information-rich environments in which consumers have easy access to attribute levels for most products in the market.
Premise (1) is different from the vast literature in marketing on search with Bayesian learning because consumers learn their preference weights during search rather than simply learning the utility of products, services, or people. This difference is important because learned (or updated) preference weights affect the relative utility of every product that has (or doesn't have) the corresponding attribute level. In contrast, in most analytical models, when consumers learn product utilities by searching, the learning affects primarily the utility of the product that is searched.
1.2. Motivation for Premise (2): RecommendationSystem Knowledge
In our vignette, Candice and Dave received a recommendation from a real estate agent. The agent was sufficiently experienced to know that a young couple with small children would value playground proximity and observed that Candice and Dave were not putting sufficient weight on it. The agent had a better understanding of Candice and Dave's true preferences than did Candice and Dave at the start of the search. This phenomenon is common. For example, Rogers (2013, p. F4) suggests, "Often people don't know what they want . . . You may think you want X, but if you're shown Y, you may love Y better than you ever loved X . . . Even (or especially) in these days of consumer online access, some of an agent's value lies in her being able to offer a buyer a choice different from his preconception." College counselors help high school students learn what to value in colleges, childcare agencies help new parents learn what to value in nannies, and automotive websites help consumers learn what to value in new automobile purchases. A recommender often has knowledge of the attribute levels of products on the market and also knowledge of how attribute levels influenced consumers' purchases in the past. This knowledge translates to insight on the trade-offs consumers make among attribute levels. Good recommenders use this knowledge to guide future consumers' search.
Depending on the availability of information on product attributes, a recommender's value lies in helping the consumer learn product attributes and/or helping the consumer learn preference weights or both. Attribute-level search is well studied. We focus

on preference-weight learning recognizing that many recommenders do both.
Existing automated recommendation systems value the ability to accurately predict preferred products. Machine-learning methods, such as collaborative filters, content-based filters, and Bayesian-update systems, learn preference weights from past users and apply them to new users (reviewed in Section 2). When preference weights are relatively homogeneous or when preference weights can be tied to observable characteristics, recommendation systems can efficiently learn consumers' true preference weights. Although automated recommendation systems use the knowledge of consumers' preference weights to make recommendations, we know of no automated recommendation system that recommends products that help consumers learn their own preferences.
1.3. Product Categories for Which PreferenceWeight Learning Is Likely to Be Relevant
We expect preference-weight learning to be relevant in product or service categories in which the product or service is multiattributed, infrequently purchased, costly to experience without purchase or extensive search, and sufficiently valuable to justify extensive and costly search. The set of categories includes real estate, colleges, automobiles, childcare, mates, vacations, furniture, sailboats, and even high-cost industrial equipment. Henceforth, we use "product" to refer to all relevant categories. In these categories, consumers routinely seek advice from human recommenders and/or automated recommendation systems. Anecdotes abound to suggest that human recommenders take preference-weight learning into account in these categories. We hope to extend that capability to automated recommendation systems.
1.4. Overview of Model and Results We assume that the consumer learns (updates) beliefs about the preference weights for attribute levels after searching a product with the corresponding attribute levels. Search is costly, and a purchase, if any, occurs at the end of search. The benefit the consumer derives from purchase, if any, is based on the consumer's true utility, which the consumer experiences from purchase and consumption. In searching optimally, the consumer weighs the vision of this anticipated utility (possibly discounted) against anticipated search cost. To focus on preference-weight learning, we assume that the information about attribute levels of all products is available at low cost from sources such as the Multiple Listing Service (real estate), Kelly Blue Book (automobiles), or popular press ratings (colleges).
We demonstrate that existing search-theory solutions may not be optimal when preference weights are learned, even when the consumer searches without a

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

419

recommendation. For example, it is not always best to search products with high option values. We next introduce a recommendation system and argue that the typical criterion used to evaluate recommendation systems, highest predicted utility, does not always identify recommendations that maximize a consumer's net utility when preference weights are learned. Instead, a knowledgeable recommendation system should recommend products with diverse attributes (thus providing a theoretical explanation for recent trends) and/or recommend products that are undervalued by the consumer. Such products are effective recommendations even if the products have a low probability of being the chosen product because the recommendations make the consumer's subsequent search more efficient. We use numerical examples to illustrate how benevolent recommendation systems can direct the consumer to the optimal-net-utility choice. We also illustrate nonbenevolent recommendation systems that lead consumers to profitable products that may not be best for the consumer. Our arguments and examples suggest practical preference-weight-learning recommendation systems. We test the proposed recommendation systems (and a standard benchmark) with synthetic data and explore when each system is most advantageous. We close the paper with an empirical test to demonstrate that our premises are reasonable and that a proposed recommendation system helps consumers learn preference weights better than either the standard benchmark recommendation system or allowing consumers to choose without a recommendation.
2. Related Literature
We build on two pieces of related literature: the recommendation-systems literature, mostly from computer science, and the sequential-search literature, mostly from economics and marketing.
2.1 Literature on Recommendation Systems Traditionally, the primary goal of a (top-N) recommendation system is to recommend N items that maximize a user's utility (Adomavicius and Tuzhilin 2005). Typically, the recommendation system observes a utility surrogate, a rating or a rank, for some users and some items and attempts to extrapolate the surrogate to all users and items. As a result, most recommendation systems are evaluated on the accuracy of that extrapolation (Herlocker et al. 2004, McNee et al. 2006, Zhang and Hurley 2008, Liu et al. 2010, Vargas and Castells 2011). This focus was most notable in the $1M Netflix Challenge that began in 2006 and finished in 2009. The Netflix Challenge sought the recommendation-system algorithm that best predicted held-out user ratings. Successful recommendation systems focus on similarities among

users (collaborative filters), similarities among items (content-based filters), attribute-based utility models, or hybrids to recommend products with high expected utility (Urban and Hauser 2004, Adomavicius and Tuzhilin 2005, Moon and Russell 2008, Jacobs et al. 2016). Although some recommendation systems attempt to match attribute-based utility, attributes are typically defined with taxonomies, such as genre (Ansari et al. 2000). A related literature in marketing uses attribute-level preferences to predict whether consumers will choose a recommended product (Ha¨ubl and Trifts 2000, Ying et al. 2006, De Bruyn et al. 2008, Chung and Rao 2012, Ghose et al. 2012, Lu et al. 2016). Although both the recommendation-systems literature and the marketing literature demonstrate that recommendation systems can learn consumer preference weights well, many authors have criticized the focus on predictive accuracy as, in practice, providing recommendations that are too similar to previously purchased items, for example, recommending the same author after a book is purchased (McNee et al. 2006, Zhang and Hurley 2008, Fleder and Hosanagar 2009), or too obvious, for example, recommending bread, milk, eggs, and bananas to all grocery store shoppers (Herlocker et al. 2004).
In response, researchers have proposed algorithms, and metrics to evaluate those algorithms, that include goals that complement predictive accuracy (Herlocker et al. 2004, Bodapati 2008). New algorithms avoid recommending items that the consumer would have bought without a recommendation. They augment predictive accuracy with diversity, novelty, and serendipity (Ziegler et al. 2005, Celma and Herrera 2008, Ge et al. 2010, Zhou et al. 2010, Castells et al. 2011, Vargas and Castells 2011, Adamopoulos and Tuzhilin 2014). Diverse items are items that are not similar to one another; novel items are items the consumer would not have chosen without a recommendation; serendipitous items are items that are unexpected, relevant, and useful. To achieve these goals, recommendation systems penalize recommendations that are similar to "accurate" recommendations or recommend products from the "long tail." Product attributes, when used, are used to define product similarity metrics. Diversity, novelty, and serendipity are based on products, not the levels of attributes of the products. We augment this literature by studying how a recommendation system might incorporate preference-weight learning when making recommendations. Our results challenge the traditional recommendation-system focus on products that are likely to be chosen or likely to have high utility. By contrast, our analyses provide a theoretical explanation for why diversity, novelty, and serendipity work better in practice than pure predictive accuracy. We suggest modifications to recommendation systems that are based on a reinterpretation of

420

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

these concepts and highlight when such modifications benefit consumers.
2.2. Literature on Sequential Search Papers in marketing and economics recognize the importance of the consumer's search for information and have studied it empirically and theoretically. For example, Kim et al. (2010) use Amazon's view-rank data to infer consumer preferences for observed attributes of camcorders. Consumers know these attribute levels without search, but consumers search to resolve the unobserved utility of the products (error term). Bronnenberg et al. (2016) study observed online search and find that search is over a relatively small region of attribute space that declines with subsequent search. The final choice is rarely the first item searched. Hong and Shum (2006), Seiler (2013), Honka (2014), and Chen and Yao (2016) analyze search-path data to infer price distributions and/or search costs. Although a few authors consider nonsequential search, Bronnenberg et al. (2016) report strong evidence to support sequential search.
Much of this literature is based on theory derived by Weitzman (1979), who studied search over products whose utilities are independently distributed. Weitzman derives the optimal search strategy for this model, which is based on an option value index--the upper tail of the utility distribution. The optimal strategy is to search the products with the highest indices as long as they are above the reservation value. See extensions by Bikhchandani and Sharma (1996) and Adam (2001). Branco et al. (2012) focus on the optimal search for multiple attributes of a single product. The optimal strategy in this setting is also index-based: the consumer searches as long as utility is bounded between purchase and not-purchase thresholds. Ke et al. (2016) extend the model to derive appropriate bounds for two products.
Our analyses are consistent with this literature in the sense that the consumer's optimal search path is the solution to a dynamic program (a Bellman equation). However, we modify the recursion to allow consumers to update their preference weights for attributes as they search. Because products share attribute levels, the optimal search strategy is no longer indexable (e.g., Weitzman's solution). High option value or high variance in product utility matters less; strategies to learn preference weights efficiently matter more.
Finally, our model of preference-weight learning is consistent with examples of preference-weight learning in the marketing-science literature. Greenleaf and Lehmann (1995) demonstrate that consumers delay purchases to learn preference weights, and She and MacDonald (2013) show that "trigger features" cause consumers to update preference weights. Hauser et al. (2014a) show that as consumers become more expert, their preference weights stabilize. Predictions, even one to three weeks later, improve. Dzyabura et al. (2019)

and Dzyabura and Jagabathula (2018) demonstrate that preference weights change when consumers evaluate physical products rather than their online descriptions. Most of these changes persist if consumers go back to the online channel after evaluating physical products, which is consistent with learning preference weights.

3. Model of Consumer Search with
Preference-Weight Learning
To model preference-weight learning, we decompose product utilities into components corresponding to product attribute levels and allow consumers to learn their preference weights for attribute levels as they search products. We start by defining the utility of a product and then present the model of search.

3.1. Consumer Utility Is Defined on Attributes Levels
Let j 1, . . . , J index products and i 1, . . . , I index attributes. For ease of exposition, we begin with binary attributes such that a product either has or does not have an attribute. When it is clear in context, we refer to binary attributes simply as "attributes." Later, in Section 4.1.2, when we discuss multilevel attributes, we introduce terminology to distinguish attribute levels from attributes. Let xij 1 if product j has binary attribute i, and let xij 0 otherwise. Let xj be the binary vector that describes product j.
Let uj be the utility of product j, and let wi be the relative preference weight that the consumer places on attribute i such that

I

uj u(xj)

wixij.

(1)

i1

Let w [w1, . . .wI] be the vector of preference weights for all the attributes. The consumer has a prior belief about the values of wi. The prior probability density for the consumer's prior beliefs is denoted by fi0(wi) for each attribute i. This belief can be updated when the consumer observes a product with attribute i. We assume the prior distributions (and any updated distributions) are independent over i.
To focus on preference-weight learning, we assume that consumers know, or can search at negligible cost, whether a product has an attribute. That is, we assume that they know xj. This simplification is not unrealistic. Zillow, Trulia, and MLS provide attribute levels of new homes; U.S. News & World Report and Business Week provide attribute levels for colleges; Autotrader, Edmunds, and Kelly Blue Book provide attribute levels for automobiles; and travel websites, dating websites, and Amazon provide attribute levels for other products. We focus on situations in which attribute levels are easy to observe, but more costly search is necessary for consumers to experience attributes and learn their preference

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

421

weights. We revisit this assumption and the assumption of discrete attribute levels in Section 9.2.

3.2. Consumers Learn Preference Weights

During Search

Consumers engage in sequential search, searching

one product at a time. Searching represents sufficient

effort by a consumer to examine and evaluate product j,

for example, by test-driving a car, visiting a condo-

minium for sale, visiting a college, or interviewing a

caregiver. The cost of searching a product is c > 0. There
is a true value of wi, which we label wri (r for "revealed"). During search, the consumer updates beliefs about wi toward wri . For infrequently purchased products (as in Section 1.3), the consumer fully learns the consumer's

preference weights when consuming the chosen

product; thus, the utility the consumer ultimately gets

is computed according to wri , that is,

I i

1wri xij.

Let t index sequential searches, and let st be the tth

product search. Whenever xtij 1, the consumer re-

ceives a signal about the true value of the consumer's

preference weight. This signal takes the form of a probability density function g(wri |wi, st j) for the true value wri . Using Bayes theorem, the consumer's evaluation during search of product j enables the consumer to update beliefs about wi. If xtij 0, the consumer cannot update beliefs about wi. Let Ft ( j st) {i : xtij 1}; then the consumer's belief distribution about preference

weight i after the tth search is

fit+1(wi)  fit+1(wi|wr, st j)

 fit(wi)

for all i  Ft ( j),





g(wri |wi, st g (wri |wi, st

j)fit(wi) j)fit(wi)dwi

for all i  Ft ( j).

(2)

We refer to fit(wi) as the prior beliefs before the tth search and fit+1(wi) as the posterior beliefs after the tth search. Equation (2) allows the Bayesian updating to remain general. For the numeric examples and synthetic data experiments, we make a functional assumption--we use normally distributed priors leading to normally distributed posteriors. The online appendix summarizes the formulas.
As t increases, we expect the mean of fit(wi) to approach wri and the variance to approach zero. The rate at which the posterior beliefs converge can vary. For example, one of our colleagues was dead set against swimming pools when searching for vacation homes in a beach community, but when she saw the perfect swimming pool layout for her children, she immediately updated her preference weights and bought the house. Another colleague searched three homes in a community before he fully updated his preference weight for a

neighborhood-owned swimming pool. We explore differences in the rate at which preferences are updated in our numerical examples and synthetic data experiments.

3.3. Optimal Search
If no recommendations are made, the consumer searches sequentially and optimally. If recommendations are made, the consumer searches all recommended products, updates the preferences, and searches optimally thereafter. The consumer is forward looking; therefore, the consumer solves a dynamic programming recursion to select the next product to search or to stop and purchase. The state is the set of products already searched St, and the beliefs prior to search are f t(w). When prior distributions are independent over i, and when an observation of an attribute only updates preference weights for that attribute, posterior beliefs are independent over attributes. Probabilistic independence implies f t(w) i 1 to I fit(wi).
If J(St, f t) is the continuation value, the Bellman equation for search without recommendations recognizes that this value is the maximum over choosing the outside option denoted by U*, choosing the maximum utility product without searching based on f t, or continuing to search. The value of continuing to search is the maximum over all unsearched products taking into account that preferences will be updated through further search (if further search is optimal). Expectations are based on f t, which is the consumer's belief about the preference weights when the search decision is made. The resulting Bellman equation is

J(St, f t)

max

U*, max
j 1 to J

E[i

1to Iwixij| f t],

max -c + E J St  {k}, f t+1| f t ,
kSt
(3)

where   1 represents the discount factor. A key part of this optimization problem, relative to the searchtheory literature, is that the belief distribution f t is part of the state space and is defined over product at-
tributes (rather than products). Naturally, Equation (3) could be extended to include uncertainty over the xj's for research to marry preference-weight learning to
attribute-level search.

3.4. Recommendations
We model product recommendations as follows. A "recommendation" is a single product that is recommended to the consumer at a given time. We assume that the consumer follows that recommendation and searches the recommended product. A human recommender might be a real estate agent offering to show the home buyer a particular property or a childcare agency

422

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

scheduling interviews for parents with potential caregivers. We are particularly interested in automated recommendation systems. After searching the recommended product, the consumer continues to search optimally given the consumer's beliefs, according to Equation (3).
For simplicity, we prefer to make the assumption that the consumer searches the recommended product, but the assumption also can be motivated with an assumed utility bonus (Ubonus > 0) to represent a belief by the consumer that the recommender knows something about the recommended product (not known to the consumer). The consumer trusts that, for some reason to be revealed during search, consumption utility is increased by the utility bonus. In other words, the consumer believes that the expected utility of recommended product  is E[i 1 to Iwixil| f t] + Ubonus. If the bonus is sufficient but not so large that the consumer purchases product  without searching, then it is optimal for the consumer to search the recommended product. At the end of search, knowledge gained by searching overwhelms any ephemeral utility bonus. The consumer's consumption utility is based on wr.
3.5. Preference-Weight Learning vs. AttributeLevel Learning
Equation (3) is reminiscent of the Bellman equations used in classical models of optimal sequential search but with key differences. For example, Equation (3) shares Weitzman's (1979, p. 643) assumption that "the sum of search costs is paid during search, whereas the maximum reward is collected after search has been terminated." However, unlike in Weitzman's (1979) model, the updates in Equation (3) do not necessarily reveal the value of the searched product with a single observation. Slower learning is assumed in learning models, such as in Chick and Frazier (2012), when, each time the consumer searches, the consumer observes a random draw from a distribution rather than the true parameter value. More critically, in search models, such as Weitzman (1979), and search with learning models, such as Chick and Frazier (2012), product utilities are independent. Independence is often assumed in search models because independence enables relatively simple search policies called "index policies." With an index policy for search, the optimal search strategy continues until the revealed product (or attribute) exceeds an index determined by a simpler Bellman equation. Index strategies break the curse of dimensionality. When independence during search is lost because of preference-weight learning, we know of no optimal or near-optimal index strategies.
Index strategies are also important for a different, but related, set of dynamic programs: multiarmed bandit problems. Multiarmed bandit problems share the property of search with learning problems that

multiple alternatives are each described by reward distributions, but multiarmed bandit problems differ because rewards can be obtained in each period rather than only at the end of search. The consumer decides which alternative ("arm") to try by balancing immediate rewards versus the long-term benefits from learning about the reward distribution to choose better in the future. The consumer sequentially tries alternatives, but unlike search problems, the consumer receives a potential payoff every time an arm is pulled rather than only receiving the reward from the chosen product (or outside option) at the end of search. When the alternatives are independent, Gittins (1979) demonstrated that the optimal policy is to choose the alternative with the largest index. Whittle (1988) extended index policies to restless bandits with which the value of the nonchosen alternatives can change independently. Many bandit problems have been shown to be indexable (Gittins et al. 2011), including the partially observable Markov processes in website and banner morphing (Hauser et al. 2009). When there is a switching cost between arms, the bandit is said to have "memory," and multiple indices might be required (Jun 2004). In some cases, structured interdependence is allowed, and greedy policies perform near optimally (Mersereau et al. 2009). In the marketing literature, multiarmed bandit models have been used to model consumer purchases in consumer packaged goods categories (Lin et al. 2014), to optimize advertising creative (Schwartz et al. 2017), and in revenue management for optimal pricing (Misra et al. 2017). Research on multiarmed bandits is extensive and ongoing. In time, concepts from this literature might provide new insights into search models with preference-weight learning.
The very nature of preference-weight learning induces interdependence among product utilities: every time a preference weight is updated, the utilities of all products with the corresponding attribute level, including those already searched, can change. Index policies are unlikely to be optimal. We know of no simplifying policy that provides an optimal solution for Equation (3), nor for recommendations that influence a consumer who bases optimal search on Equation (3). Even in simple two-product, two-attribute markets, relationships to determine the optimal policy are complex. The curse of dimensionality applies. (See the appendix, which illustrates Equation (3) with and without a recommendation system.)
Interdependence and the curse of dimensionality require that realistic recommendation systems rely on heuristic policies. For example, if all attribute combinations were feasible in a product space with 10 attributes at six levels each, a single recommendation would require that we evaluate almost 60 million candidate recommendations. This number would grow

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

423

to more than three quadrillion pairwise recommendations for a top-two recommendation system (which recommends two products sequentially). Without any special structure, the memory requirement of the dynamic program in Equation (3) grows exponentially with the size of the problem. It is no surprise that applied recommendation systems rely on heuristics. To be consistent with applications and with the recommendationsystems literature, we explore recommendation-system modifications that are likely to be feasible in applied situations. These modifications are necessarily heuristic. We develop potential heuristics by examining the structure of consumer search and the implied recommendation policies.
4. Insights About Search and Recommendation
Equation (3) implies that the consumer must make trade-offs among search costs and the reward to purchasing without search versus the knowledge gained from further search and improved rewards that come from a later purchase. Equation (3) becomes even more challenging when a recommendation system is introduced. The complexities, because of the interdependence imposed by preference-weight learning, require that we seek qualitative insights toward potential heuristic modifications to recommendation systems. This section provides insights; Section 7 develops and tests recommendation systems that implement modifications based on the insights.
4.1. Recommendation-System Beliefs
A key component of the Candice and Dave condominium vignette was that the agent had beliefs about Candice and Dave's preference weights and that these beliefs were better (closer to the true preferences) than Candice and Dave's initial beliefs. Let f rec(wi) be the recommendation system's beliefs about the consumer's preference weights. For some attributes, the recommendation system's priors may match the consumer's priors ( firec fit), but for other attributes, the recommendation system may believe that the consumer's beliefs are not accurate ( firec  fit). In this notation, we do not require that the recommendation system know the consumer's true beliefs wri perfectly. The recommendation system's beliefs may be a probability distribution. However, if the recommendation system is to be valuable, f rec(w) should, in some sense, be closer to wr than is f t(w). We quantify "closer" as follows. (We assume that the recommendation system cannot credibly inform the consumer of its beliefs about the consumer's preference weights; it must do so implicitly by recommending products to the consumer.)
By assumption, if the recommendation system recommends product j at time t, then st j. The key

difference between the recommendation system and the consumer is that the recommendation system expects the first (or first few) updates to be based on f rec. When the number of potential recommendations is small, as in the example in the appendix, the optimal recommendation can be found by exhaustive enumeration. When the number of products is more typical, we must rely on heuristic policies.
4.2. Aspect Diversity 4.2.1. Consumer Search in a Full-Factorial Product Space. Consider first a full-factorial product space in which, for I binary attributes, all 2I possible combinations of attribute levels are available as products. In Equation (3), the search costs are product based, not attribute based; thus, searching a product j with xij 1 for I attributes is no more costly than searching products with xij 1 for only one attribute. By contrast, if the consumer were to search the product with I attributes present, the consumer would gain more information than the consumer would by searching a product with one attribute present. (The consumer can still decide to purchase the one-attribute-present product. Unlike bandit problems, there is no immediate reward during search. Search produces knowledge to improve net consumption utility after a product or the outside option is chosen.) If the optimal solution at t 1 were for the consumer to search a product, then the best product to search is the product j with all I attributes present xij 1 for all i. The insight has intuitive appeal. Real estate agents often recommend that consumers search homes outside their price range to experience and learn about as many attributes as possible, such as proximity to playgrounds, swimming pools, full-service concierge, island kitchens, and media rooms. Automobile dealers often maintain test-drive cars with many "options." (For interested readers, a formal proof in a two-product, two-attribute product space is available from the authors.)
4.2.2. Full-Factorial Product Spaces Are Rare, Especially with Multilevel Attributes. The value of searching a fully attributed product to learn (update) preference weights raises a conundrum. It seems obvious that the consumer should always begin by searching the product with all I attributes present--no recommendations are needed. But recommendation systems are popular and highly researched. The answer to the conundrum is simple. In most realistic cases, fullfactorial product spaces are not available. Highly featured cars are priced high and may be outside the consumer's price range, leading to "sticker shock." Many possible attributes describe homes--a fully attributed property is exceedingly rare. The same can be said for caregivers, colleges, jobs, furniture, and dating opportunities.

424

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

Recommendations are particularly valuable in product spaces with multilevel attributes in which, by definition, a fully attributed alternative is not available: a vehicle cannot simultaneously be a sedan, a coupe, a station wagon, a crossover, a minivan, an SUV, and a truck. Henceforth, to avoid confusion, we follow Tversky (1972) and refer to a binary attribute level as an "aspect." A multilevel attribute is then a collection of aspects with the constraint that exactly one of the aspects in an attribute has xij 1.

4.2.3. Aspect Diversity. Despite the sparsity of fullfactorial product spaces, the insights about fully attributed products are useful. When consumers learn preference weights, it is valuable to search a product that has a diverse set of aspects. This insight is related to recent recommendation-system trends toward diverse, novel, or serendipitous products and may provide a partial theoretical explanation for those trends. However, aspect diversity is subtly different because it focuses on learning about preferences for aspects rather than for the products themselves.
Recommendation systems provide value by recommending products that improve the consumer's search, resulting in a higher terminal utility net of search costs relative to what the consumer would have searched without them. Thus, it is valuable to recommend products with aspects that have a high true preference weight but which the consumer would not otherwise have searched. This value comes into Equation (3) primarily in the continuation value J(St  {k}, f t+1| f rec). If product k has aspects the consumer would not have otherwise searched, the recommendation helps the consumer to make better subsequent search decisions and, ultimately, identify a higher utility product (net of search costs) to purchase and consume. We call a recommendation-system modification that implements this modification, "aspect diversity." There are many ways to implement an aspectdiversity heuristic. We have found that it is effective to modify the standard recommendation-system criterion (maximize expected utility based on f rec) to include a penalty for recommending aspects the consumer would otherwise have searched. If s*t indicates the product the consumer would have searched without a recommendation, then the aspect diversity criterion becomes

xrec

arg max E[i
j 1 to J

1to Iwixij| f rec] - i

1 to Ixis*t xij.

(4)

The parameter  determines how much emphasis the recommendation system places on diverse aspects. When  0, the recommendation system recommends the maximum-expected-utility product; when   , the recommendation focuses primarily on diversity.

As is typical in recommendation-system applications,  is a tuning parameter that is best chosen by experience or experimentation.
4.3. Recommendation Systems That Use Information About Expected Preference Weights
Equations (2) and (3) rely on the consumer's priors f t, the recommendation system's priors f rec, and the signal distribution g(wri |wi, st j). In theory, recommendations might depend on the full distributions. For example, recommendations may vary depending on the rate at which the consumer learns preference weights. However, full distributions ( f t, f rec, and g) might be hard for the recommendation system to observe; the recommendation system might be much better at observing or predicting the mean of the distributions. For such cases, we begin with recommendationsystem modifications that rely only on the expected values of the preference weights and later consider recommendation-system modifications based on the full distributions.
4.3.1. Conceptual Example. Consider three condominiums that are similar on all attributes except playground proximity, type of kitchen (traditional, open-concept, island), and type of service (live-in superintendent, full-service concierge). Suppose that Candice and Dave's prior beliefs are such that they do not value playground proximity and prefer an island kitchen in a building with a full-service concierge. Suppose that the recommendation system believes that Candice and Dave undervalue playground proximity and correctly value an island kitchen but overvalue a fullservice concierge. Finally, suppose that the condominium stock in Candice and Dave's target market is limited--not all combinations of playground proximity, kitchens, and service are available. Intuitively, the recommendation that would lead to the largest shift in Candice and Dave's beliefs about their preference weights is a condominium, if available, that has playground proximity but a live-in superintendent. By improving Candice and Dave's understanding of their preference weights, the recommendation may lead them to purchase and consume a condominium with playground proximity. Candice and Dave may learn to forego a full-service concierge and allocate their limited budget to other high-valued aspects. (If nothing else, condo fees are less with a live-in superintendent than with a full-service concierge.)
4.3.2. Undervalued Products. The intuitive recommendation in the condominium example is based on both components of Equation (3), E[i 1 to Iwixij| f rec] and J(St  {k}, f t+1| f rec). By recommending a condominium near a playground, the recommendation system improves the

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

425

expected reward because E[wppxpp,j| f rec] > E[wppxpp,j| f t] for playground proximity (pp). It does so by shifting the priors toward a high-valued attribute level that the consumer currently undervalues. If the mean of f rec is closer to wr than the mean of f t, then the expected purchase and consumption utility is also improved. The continuation value comes into play because Candice and Dave can search more effectively for the next condominium when further search is optimal. They can do so because their objective function better matches their true utility (J(St  {k}, f t+1| f rec) increases). The recommendation is a good recommendation if these gains are greater than the search cost c.
The suggested modification to a recommendation system is to recommend undervalued products, and "undervalued" implies that the expected utility based on the recommendation system's beliefs is higher than the expected utility based on the consumer's priors; that is, E[i 1 to Iwixij| f rec] > E[i 1 to Iwixij| f t]. We implement the heuristic by identifying the products for which the difference between the recommendations system's beliefs about the consumer's expected utility and the consumer's beliefs about the expected utility is maximized
xrec arg max E[i 1 to Iwixij| f rec] - E[i 1 to Iwixij| f t].
j 1 to J
(5)
We call a recommendation system that implements this modification "undervalued products."
4.4. Differences in the Distributions of f rec and f t In some cases, the recommendation system might be able to measure the variance (or the full distributions) of f rec and f t. If so, we might improve recommendations by allowing the recommendation system to use its knowledge of the preference-weight belief distributions and the signal, not just the means of the distributions. For example, a recommendation system might favor recommending products with aspects for which preference weights are updated more rapidly (less posterior variance) or products with aspects for which the recommendation system has tighter beliefs. We propose two such recommendation-system heuristics.
4.4.1. Option Value Discrepancy. We draw insight from search theory and focus on the option values for the attribute levels of a searched product. However, unlike in optimal search models, we take both f rec and f t into account. Because option values are easiest to understand for multilevel attributes, we temporarily modify our notation to accommodate multilevel attributes. In particular, let xij 1 if product j has

attribute i at level . We define wi similarly. Then we implement the heuristic as follows:

I



xrec arg max

widf rec(wi)

j 1 to J i 1  : xij 1 w*i


- widf t(wi) , (6)
w*i

where w*i is the highest expected value over  of wi. (To make Equation (6) feasible, we use the expected value for w*i rather than integrate over all possible outcomes.) We call a recommendation system that im-
plements this modification "option value discrepancy."

4.4.2. Kullback­Liebler. We might also attempt to
quantify the difference between the two distributions f rec and f t and use the quantified difference.
A formal measure of distance between two distributions is the Kullback­Liebler divergence from f t to f rec, DKL( f t f rec). Kullback­Liebler divergence measures the nonsymmetric difference between two prob-
ability distributions. If a larger divergence between the
two distributions leads to the most learning, then,
returning to the xij notation, a heuristic based on this concept is the following in which DKL,j is the Kullback­ Liebler divergence for product j:

xrec arg max

DKL,j( fit firec).

(7)

j 1 to J i :xij 1

We call a recommendation system that imple-

ments this modification "Kullback­Liebler." We pro-

vide more specific formulae in Section 7, in which we make distributional assumptions about f rec and f t.

5. Preference-Weight Learning Criteria
Preference-weight learning introduces new twists to existing literatures in recommendation systems and search theory. In particular, the modifications in Section 4 are based on criteria that differ from the typical criteria in the recommendation-systems literature and in the search-theory literature. In this section, we explore those differences.

5.1. Compared with Typical RecommendationSystem Criteria
In the recommendation-systems and marketing-science literatures, most recommendation systems are evaluated on their ability to predict the products that consumers will choose. This is a reasonable criterion when the consumer knows the consumer's preference weights because, in such cases, the goal is to recommend the product that will deliver maximum purchase and consumption utility. This criterion will not maximize

426

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

purchase and consumption utility when consumers learn preference weights.
Consider the condominium example. If the recommendation system were to recommend the condominium that maximizes expected utility based on f t, then Candice and Dave would choose a condominium without playground proximity in a full-service building. Candice and Dave would never know what they missed. Our example in Section 4.3.1 also implies that the best recommendation may not be the product Candice and Dave are most likely to choose. Instead, the best recommendation might be a condominium that the recommendation system believes Candice and Dave will never buy. Searching a condominium with a less desired kitchen but with playground proximity and their true preferred level of service might be the most efficient way for Candice and Dave to learn their preference weights for playground proximity and level of service. After updating their preference weights, Candice and Dave are more likely to search the product that maximizes the purchase and consumption utility net of search costs. The trends of product diversity, novelty, and serendipity can be interpreted as improving the continuation value in Equation (3) because consumers learn their preference weights.
5.2. Compared with Typical Search-Theory Criteria Because most search-theory analyses assume independence among products, efficient optimal policies are based on indices (e.g., Weitzman 1979, Branco et al. 2012). Although the details vary, the indices tend to favor the upper tail of the probability distribution of product utility rather than the expected value of the product utility or the expected value of a level of the attribute. Upper-tail criteria (indices) represent the option value from the searched product (choose it, continue to search, or choose an already searched product). The option value represents the expected gain in utility if the product turns out to have higher utility than the current best option. If the expected utilities of two products are equal, these criteria favor products with high variance in utility distributions (if the distributions are from the same distributional family).
These criteria do not necessarily apply when consumers learn their preference weights in part because of the interdependence in Equation (3). Assume that Candice and Dave are now sure that their preference weight for playground proximity wplayground is high, but they don't know how high. They have decided on an open-concept kitchen and a live-in superintendent but are now considering whether they want a condominium with an eat-in kitchen, a media room, or both. (Attribute level weights are net of added price.) There are three types of condominiums left to search:

1. {playground proximity = good, media room = yes, kitchen = not eat-in}
2. {playground proximity = good, media room = no, kitchen = eat-in}
3. {playground proximity = bad, media room = yes, kitchen = eat-in}
Candice and Dave do not know whether they prefer a media room or an eat-in kitchen, but they know that having both has less preference weight than playground proximity, that is, wplayground > wmedia + weat-in kitchen. Candice and Dave may choose to search condominiums in type 3 to resolve their preference weights for media rooms and eat-in kitchens even though the option values of both type 1 and 2 condominiums are higher. After resolving the uncertainty by evaluating type 3 condominiums, they can then choose a condominium of either type 1 or type 2. Their actual decision, and the decision on whether to continue to search, depends on the preference-weight distributions, the search costs, and the discount rate. We argue in Section 5.3 that prior preference-weight distributions exist such that the best strategy is to search type 3 condominiums and that such distributions are reasonable.
The Candice and Dave example provides a counterexample to maximizing the option value of the searched products. The optimal product to search, a condominium of type 3, has no option value if Pr(wplayground > wmedia + weat-in kitchen) 1 because a condominium of type 3 would never have the highest utility. It also provides a counterexample to maximizing the option value of preference-weight distributions. The option value of the weight on playground proximity can be higher than the option value for the weights on the other attributes, but resolving playground-proximity uncertainty does not change Candice and Dave's decision. The key mathematical insight is that, for preferenceweight learning, the continuation value in Equation (3) is not separable in either products (j) or attributes (i) if the product space is not full factorial (if all 2I products are not available). Resolving uncertainty by updating f t to f t+1 occurs for all aspects in the searched products, which, in turn, affects the option values of all products searched and to be searched.
The Candice and Dave vignette illustrates search without a recommendation. It is easy to embellish the vignette for recommendations. If f rec f t, the best recommendation remains type 3 condominiums. But suppose that f rec is such that the recommendation system believes that Candice and Dave undervalue eat-in kitchens; then the motivation for recommending a search of type 3 condominiums is even stronger.
5.3. Formal Demonstration of Intuition
Sections 5.1 and 5.2 provide intuitive examples to illustrate that neither the consumer's optimal search nor the best recommendations are based on the

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

427

traditional criteria. It remains to demonstrate that we can actually choose f t and/or f rec such that traditional criteria do not apply. The appendix contains two formal proofs for a product space with three aspects. The first formalization addresses optimal search when there is no recommendation system. The second formalization adds a recommendation system. Together the two results formalize the intuition from Sections 5.1 and 5.2. Because we need only establish the existence of consumer search and recommendation systems for which standard criteria do not apply, the formalizations allow the consumer to update beliefs fully with a single observation of an aspect.
Specifically, the appendix establishes that the criteria for the optimal search without a recommendation and for the optimal recommendation under preferenceweight learning:
· Differ from typical criteria in recommendation systems.
 The best recommendation may not be the product with the highest expected utility.
 The best recommendation may be a product that the consumer is unlikely to choose.
· Differ from typical criteria in optimal search.  The best product to search (recommend) may
not be the product with the highest option value.  The best product to search (recommend) may
not have the largest variance in utility. The formal demonstrations tell us what the recom-
mendation should not do. In Section 4, we proposed three criteria for new recommendation systems:
· Modification 1: Recommend products with diverse aspects.
· Modification 2: Recommend products with undervalued expectations (E[ f rec] versus E[ f t]).
· Modification 3: Recommend products to move the consumer's priors closer to the recommendation system's priors.
The suggested modifications are consistent with and provide a marketing-science explanation for recent trends in the recommendation-systems literature (diversity, novelty, and serendipity). However, preference-weight learning suggests that diversity should be with respect to aspects, novelty should be based on not-yet-searched aspects, and serendipity should focus on products with aspects that are undervalued.
6. Recommendations When Consumers Learn Preference Weights
Before we test the proposed recommendation-system modifications, we gain insight by exploring how recommendations influence the consumer's search path.
6.1. Structure of the Synthetic Data We examine a product space defined by three six-level attributes. The 18 (18 3 × 6) aspects in our product

space are sufficient to illustrate interesting phenomena but not so complex as to make calculating postrecommendation search infeasible. With three six-level attributes, 6 × 6 × 6 216 feasible products exist in the product space. Let Lk denote the set of aspects that correspond to levels of attribute k.
The consumer's prior beliefs fi0 for all aspects i are normally distributed and independent over aspects. We denote the means and standard deviations of the aspect-based normal distributions by w¯ i and i such that fi0 1(w¯ 0i , 0i ). The signal obtained about the preference weight by searching a product with the corresponding aspect is also normally distributed g 1(wri , si ). These assumptions imply that the posterior distributions, updated from product search, are normally distributed fit 1(w¯ ti, ti). The formulas for the posterior distributions are standard and given in the online appendix. The posterior mean is a convex combination of the prior mean and the true mean. For ease of notation, we assume both the consumer and the recommender system know the preference weight for a base level (aspect) of each attribute. We set the preference weight of the base level to zero. (For example, such assumptions are necessary for identification iwn¯ c0h, oic0e,-baansdedwcor najoreingt aivneanlysinis.)thTeheosnpliencieficapvapleunedsioxf. Patterns similar to those discussed in this section emerge for a wide range of parameter values and numbers of attributes.
To simplify the search problem, we assume that all 216 products are available. We call such product spaces "fully crossed" to distinguish them from the much larger full-factorial aspect spaces. In a fully crossed product space, the maximum-utility product is the product with the maximum-preference-weight level for each attribute. In a fully crossed product space, the search problem can be broken down by attribute. Returning to the multilevel attribute notation introduced in Section 4.4, for each attribute i, the consumer searches the product that maximizes (over levels) the option value of searching level  in each attribute i, w*i widf t(wi), where w*i was defined in Section 4.4. Because the product space is fully crossed, there exists a product that has attributes at the maximizing levels. (Note that these option values apply attribute by attribute and only in a fully crossed product space. This does not contradict the option value result in Section 5.3.)
The attribute-level maximization policy is heuristic rather than optimal because the lower limit of the integral is based on expected values rather than a full (infeasible) solution to the Bellman equation. The attribute-level maximization heuristic approaches optimality as the signal variances (si )2 approach zero. The attribute-level maximization heuristic outperforms other known heuristics, such as that by Chick and

428

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

Frazier (2012), which is optimized for search with attribute-level learning among independent products. (Details available from the authors.)
In this section, we evaluate the impact of a single recommendation for each consumer. A single recommendation is sufficient to affect the consumer's search path and illustrate the phenomena made possible by preference-weight learning. We allow multiple recommendations when we test the proposed recommendation-system modifications in Section 7.
6.2. Comparison of Recommended and Chosen Products
We evaluate recommendations of each of the 216 possible products. We assume that Ubonus is such that the consumer searches the recommended product and then continues searching (near) optimally. At the (endogenous) end of search, the consumer either chooses a product or the outside option. We summarize the results in Figures 1 and 2.
The vertical axis of Figure 1 plots the consumer's net payoff: the utility of the chosen product minus the incurred search costs. The horizontal axis of Figure 1 represents the true utility of the recommended product (based on wr). The consumer learns (updates) f 1 after searching the recommended product and, perhaps, continuing to search. In Figure 1, all recommendations lead the consumer to purchase one of three products, as indicated by the horizontal clusters. The net utility of the chosen product differs slightly because search costs differ. (Three products are not a general

result. Different parameter values give different numbers of postsearch products.)
We first examine the product recommendation in Figure 1 that is represented by the diamond ( ). In this case, the recommendation system recommended the highest-utility product, and the consumer chose that product but ultimately did so after incurring more search costs than would have been incurred for other recommendations. This suggests that even if a recommendation system has perfect knowledge of consumer utility, the highest-utility product may not be the best recommendation if the consumer has to learn the consumer's own preferences. The recommendation indicated by a triangle ( ) also leads the consumer to the highest-utility product but does so by recommending a much lower-utility product. After receiving this recommendation ( ), the consumer learns efficiently that some attributes are more important and some are less important than previously thought.
The recommendation indicated by a square ( ) is interesting. For such recommendations, the consumer is satisfied with the recommended product and has no incentive to search further. Such recommendations by nonbenevolent recommenders (or poorly designed recommendation systems) exploit the consumer's nai¨iveté and lead the consumer to purchase a product that is not the highest true utility. The consumer would not update the priors sufficiently and never learn of better-than-expected-utility products but would be satisfied with the chosen product at the time

Figure 1. Net Utility of Product Chosen After Search vs. Utility of Recommended Products

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

429

Figure 2. Net Utility of Product Chosen After Search vs. Recommendation System's Beliefs About the Utility of the Recommended Product

of purchase. The consumer might even thank the recommendation system for a recommendation. For example, a nonbenevolent real estate agent might have incentives to recommend the agent's own listing to obtain both seller and buyer commissions (Ansari et al. 2000). Similarly, and with similar concerns, short-term gains might be tempting if paid advertising supported a recommendation system. The other interesting feature about the recommendation denoted by a square ( ) is that other recommendations ( ) exist with lower initial utility that lead to higher postsearch utility.
Recommendations, such as indicated by a circle ( ), lead the consumer to choose low-utility products. After following such recommendations, the consumer, acting optimally based on priors, updates some of the preference weights but never updates preference weights sufficiently to find the highestutility product. Postsearch, the consumer believes falsely that the consumer has found the product that has the highest utility. Despite the opportunity loss, the consumer might be satisfied. Without a recommendation and without search, the consumer in this example would have chosen the product the consumer believes would maximize utility. The consumer would have expected to receive utility of 11.4 from this purchase but, on consumption, would only have received utility of 9.4. Had the consumer searched without a recommendation and chosen optimally after searching this product, the consumer would have received utility of 10.7, basically in the middle tier of products that could have been recommended.

Figure 2 provides a different perspective based on the same set of candidate recommendations. Figure 2 compares net postsearch utility to recommendationsystem beliefs. In this illustration, the mean of the recommendation-system beliefs f rec is a convex function of the mean of the consumer's prior beliefs f 0 and the consumer's true beliefs f (wr). As anticipated by Section 5 and as represented by a hexagon ( ), a recommended product, thought by the recommendation system to be the highest-utility product, does not lead the consumer to the highest-utility product. After receiving that recommendation ( ), the consumer, acting optimally based on priors, would not search sufficiently to find the true highest-net-utility product. A recommendation system would have served the consumer better had it recommended the product indicated by a diamond ( ) or even the product indicated by a triangle ( ). In the latter case ( ), the recommendation itself would not have been a high-utility product, but the recommendation would have caused the consumer to update beliefs and continue searching until the highest-net-utility product was found.
In Figures 1 and 2, the utilities of the recommended products and the net utilities of the chosen products are correlated ( 0.43,  0.28, respectively), but the relationship is well below 1.0. Preference-weight learning drives the lack of perfect correlation. Detailed examination of the search path reinforces the insights obtained from Section 4: the best recommendations are those that encourage the consumer to search products that reveal diverse aspects and undervalued aspects. Figure 2 reinforces the insight

430

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

that good recommendations provide valuable information. Figures 1 and 2 allow the consumer to be surprised either positively (preference weight higher than priors) or negatively (preference weight lower than priors). Both forms of preference-weight learning are valuable to consumers.
7. Preference-Weight-Learning Recommendation-System Evaluations
To explore whether the modifications suggested in Section 4 improve recommendation-system performance, we expand the analyses of Section 6 to 5,000 consumers in multiple experimental conditions. Because the value of preference-weight learning depends on differences in f rec and f t, our experimental conditions vary with respect to the quality of consumers' priors (na¨iveté), the quality of the recommendation system's priors (recommendation-system knowledge), and the rate at which consumers update their preference weights. By design, consumers learn their preference weights as they search products. Our synthetic-data experiments are proof-of-concept experiments: we examine whether the recommendationsystem modifications improve recommendationsystem performance when consumers learn their preferences. We complement these synthetic-data experiments with an empirical demonstration in Section 8.
We expect preference-weight learning to be particularly relevant for na¨ive consumers who are new to a product category. Na¨iveté is more likely for infrequent purchases, such as automobiles, housing, college choice, and nannies. Na¨iveté is also more likely for consumers who feel they need recommendations. Because the preference-weight-learning modifications use more complete knowledge about f rec and f t than do typical recommendation-system benchmarks, we expect the incremental value of the preference-weightlearning modifications to generally increase with recommendation-system knowledge. The exception is low recommendation-system knowledge when we expect that no recommendation system does well. We expect that faster updating should favor the preference-weight-learning modifications.
7.1. Product Space and True Consumer Utilities We simulate a product space of three six-level attributes using the same structure that we used in Section 6. We consider recommendation systems that recommend two products sequentially. For each experimental condition and for each of 5,000 consumers in that experimental condition, we draw true aspect preference weights from a mixture of two normal distributions: one with a low mean to represent unimportant aspects and one with a high mean to represent important aspects. The consumer's prior beliefs are normally

distributed and independent over aspects and depend on na¨iveté, as described in Section 7.2. The variances of the consumers' priors (vi in the online appendix) are drawn independently and identically distributed from an exponential distribution. The specific values of the parameters of the preference-weight distributions are given in the online appendix. For readers wishing to explore other parameter values, other recommendationsystem modifications, or other combinations of na¨iveté, recommendation-system knowledge, or the rate of updating, the software is available from the authors.
7.2. Characteristics Varied in the Synthetic Data Experiments
7.2.1. Consumer Na¨iveté. For each consumer, we set the prior means equal to the true means for a fraction of the aspects. For the remaining aspects, we redraw the prior means randomly. A consumer is more na¨ive (less expert) if a larger fraction of the consumer's prior beliefs are redrawn randomly. We vary this fraction ( in the online appendix). An expert has na¨iveté equal to zero, and a novice has na¨iveté equal to one.
7.2.2. Recommendation-System Knowledge. For some aspects, we set the recommendation system's priors to the consumer's priors (probability Pc). For the remaining aspects, we set the mean of the recommendation system's priors to the true partworths with probability Prec, and we set the recommendation system's priors randomly with probability 1 - Prec. Larger Prec implies greater recommendation-system knowledge. We maintain the Pc parameter to recognize that, even with Prec 1, recommendation systems are unlikely to ever know the true preference weights perfectly. The variances of the recommendation-system priors are constant for all consumers. (In theory, we can manipulate recommendation-system knowledge by manipulating the means, the variances, or both. Exploratory simulations suggest that it is sufficient to manipulate the means.)
There are a number of well-established methods by which recommendation systems learn consumers' priors and consumers' true preferences. Collaborative filters, content-based filters, and statistical model­based systems, as reviewed in Section 2, are just a few examples. Methods for such firm-side learning are well established in theory and in practice, but research on improvements continues. In a related context, Hauser et al. (2014b) illustrate that, in automated systems, firm-side learning about the best "morph" can be decoupled from learning about consumers' cognitive styles. (The analogy is recommendation policy  morph and consumer beliefs  cognitive style. The mathematical structure, while related, is not identical.) Recommendation-system knowledge is likely to

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

431

be greater if consumers are more homogeneous, if consumers' priors can be measured directly, if true preferences can be estimated as a function of observable characteristics of the consumer, or if the recommender system has access to more data. (Manipulating the heterogeneity of the environment provides an alternative method to manipulate recommendation-system knowledge. Results are similar.)

7.3.5. Kullback­Liebler. The Kullback­Liebler modification compares the Kullback­Liebler divergence for every aspect in product j and recommends the product for which the divergence is largest (Equation (7)). When the consumer's prior beliefs and the recommendation system's beliefs are normally distributed, the Kullback­Liebler divergence DKL,j for each product j is given by Equation (8):

7.2.3. Rate of Updating. The rate at which the consumer converges to the true utility parameters depends on the variance of the signal, (si )2 in the online appendix. We vary this parameter in our experiments. In some experimental conditions, consumers update their priors rapidly (low signal variance), and in other experimental conditions, consumers update their priors slowly (high signal variance).
7.3. Preference-Weight-Learning Recommendation Systems and Benchmark
We test four recommendation-system modifications that implement the insights and equations from Section 4. We compare these modifications to the typical benchmark recommendation system. The basic concepts are reviewed here. Recommendation system priors are firec 1 (w¯ ri ec, ri ec).
7.3.1. Maximum-Expected-Utility Benchmark. The maximum-expected-utility recommendation system recommends products that it expects will give the consumer the highest utility (based on f rec).
7.3.2. Aspect Diversity. The aspect-diversity modification modifies the benchmark recommendation system by subtracting a penalty proportional to the number of aspects in common with the product the consumer would have searched without a recommendation [Equation (4)].
7.3.3. Undervalued Products. The undervalued-products modification compares the consumer's mean prior beliefs f t to the recommendation system's mean beliefs f rec and maximizes the difference in expect utility [Equation (5)]. Preliminary experiments suggest that we improve recommendations for this modification when make the recommendation less sensitive to small variations. When the variation is below a threshold, it is likely the consumer has learned the consumer's preferences; we revert to the benchmark.
7.3.4. Option-Value Discrepancy. The option-value discrepancy modification recommends products for which the attribute-based option values as calculated by the recommendation system are larger than the attribute-based option values as calculated by the consumer [Equation (6)]. Preliminary experiments suggest a threshold does not improve this modification.

DKL,j( f t f rec)

1 2

i :xij 1

ti ri ec

2

+

(w¯ ri ec - w¯ ti )2 (ri ec)2

+

2

ln

ri ec ti

-

1

.

(8)

7.4. Results of the Synthetic Data Experiments We vary consumer na¨iveté and recommendationsystem knowledge in 10 equal steps each from 0.1 to 1.0 for each level of signal variance and for each of five recommendation systems. In each of the experimental conditions, each of 10,000 consumers receives two sequential recommendations. The consumer searches the first recommended product and updates preference weights. The consumer then searches the second recommended product. The consumer either purchases a product or continues to search (near) optimally until the optimal stopping rule is reached. Performance is the difference between net utility achieved by a consumer who searches the product recommended by the recommendation-system modification and the net utility the consumer would have achieved without a recommendation. Net utility is the true utility of the chosen product, if any, minus the incurred search costs.
To visualize the patterns that emerge from the synthetic data experiments, we plot performance of the system while varying one parameter and holding two other experimental variables constant. Because consumer preference weights are redrawn for each of the 10,000 consumers, we subtract from net utility the utility of the product the consumer would have chosen without a recommendation. Because we are interested in performance relative to the benchmark (maximum expected value recommendations), we subtract benchmark performance from the performance of each recommendation system in our plots. (The performance of the benchmark, relative to no recommendation, is plotted in the online appendix. As expected, the benchmark performance increases for both consumer na¨iveté and recommendation system knowledge.)
Figure 3 plots relative performance versus consumer na¨iveté holding recommendation-system knowledge constant; Figure 4 plots relative performance versus recommendation-system knowledge holding consumer na¨iveté constant. Each figure contains a plot for

432

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

Figure 3. Improvement in Net Utility as a Function of the Consumer's Na¨iveté

slow consumer updating (high signal variance) and for fast consumer updating (low signal variance). We chose intermediate values for the experimental variable that is held constant: na¨iveté = 0.6 and recommendationsystem knowledge = 0.6. Figures 3 and 4 illustrate how naiveté and recommendation system knowledge affect relative performance as a function of consumer na¨iveté, recommendation-system knowledge, and the rate of updating.
Figures 3 and 4 suggest that aspect diversity, undervalued-products, and option-value discrepancy improve recommendations relative to the improvement achieved by the recommendation-system benchmark. We did not plot the performance of Kullback­ Liebler to keep Figures 3 and 4 readable. Although Kullback­Liebler takes the full distributions of f rec and f t into account rather than just their means, its complexity appears to be a handicap. It does not perform as well as the simpler recommendation systems.

The performance of the Kullback­Liebler recommendation system is available from the authors.
Diverse aspects does better than the recommendationsystem benchmark over the entire range of naiveté. Undervalued-products and option-value discrepancy do extremely well for highly na¨ive consumers but are slightly counterproductive relative to the benchmark for expert consumers. The latter is not surprising. There is little value to exploration of preference weights when consumers already know their preference weights. Furthermore, when consumers know their preference weights, they are more likely than the tested recommendation system to choose the best product to search. Overall, the best recommendation system for na¨ive consumers is undervalued products. The best recommendation for expert consumers is diverse aspects, although it does not do much better than the benchmark. The proposed recommendation systems do slightly better when consumers update their

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

433

Figure 4. Improvement in Net Utility as a Function of Recommendation System Knowledge

preference weights rapidly; however, the relative improvement is slight, and the pattern is similar to that of the slow-updating case.
When we vary recommendation-system knowledge holding consumer na¨iveté constant at an intermediate value (0.6), all the proposed recommendation systems beat the benchmark. Undervalued products tends to be best except for very high recommendation-system knowledge. Once again, the algorithms do slightly better when consumers update their preference weights rapidly.

do well over most of the ranges, and the performance appears to be robust with respect to the rate of updating. With refinement and tuning, we expect the relative performances of all the modifications to improve further. For example, we might test a heuristic that combines the best features of the undervaluedproducts and the aspect diversity modifications, or we might tune either or both modifications. We might modify Kullback­Liebler to be more robust. For readers wishing to explore refinements, software is available from the authors.

7.5. Summary of Synthetic Data Experiments
Figures 3 and 4 demonstrate that situations exist in which recommendation-system modifications based on preference-weight learning improve the consumer's net utility more than the typical recommendationsystem benchmark. (Improvement is relative to no recommendation.) All three proposed modifications

8. Empirical Demonstration
We began Section 1 with premises that (1) consumers learn preference weights while searching products and (2) recommendation systems can anticipate consumers' (true) preference weights. Based on these premises, we proposed recommendation systems that take preference-weight learning into account. Synthetic

434

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

Figure 5. (Color online) Basic Design of the Empirical Demonstration

data suggest that undervalued products shows promise relative to a benchmark recommendation system, maximum expected utility, and relative to allowing consumers to choose without a recommendation. (For the remainder of this section, for simplicity, we call the three methods to search products "undervalued," "max expected," and "choice," respectively.) In this section, we describe an empirical study in which we demonstrate that the two premises are reasonable and that undervalued helps consumers learn preference weights better than either max expected or choice.
8.1. Context of the Empirical Demonstration We consider a product space of five bicycles and six attributes. We created rich realistic descriptions of the five bicycles that, when studied by consumers, simulate product search. The bicycles vary on five of the six attributes of gel seat, folding ability, hydraulic brakes, nighttime visibility, and a low bar for stepthrough access. These attributes were chosen based on discussions with potential bicycle customers and a review of the bicycles available on the market. If a bicycle had the attribute, the rich realistic descriptions highlighted the attribute and its benefits in text and pictures. By design, none of the rich realistic descriptions mentioned the sixth attribute, variety of colors. With only five bicycles, the product space was not full factorial. There was no obviously dominant search strategy.
To encourage respondents to search and evaluate the bicycles seriously, respondents were asked to provide ratings and qualitative comments about any bicycles that they evaluated. Following standard procedures, before any analyses, we eliminated respondents who answered too fast, answered the same for all questions, or provided nonsense qualitative answers (13 respondents were eliminated). The sample was drawn from Amazon Mechanical Turk.

Respondents received the standard honorarium for completing the tasks.
8.2. Basic Design Figure 5 summarizes the study design. In the first stage, prior to providing recommendations or allowing the respondent to choose which bicycle to search, we collected data and trained a model by which the recommendation system can predict consumers' true preference weight distribution f rec(w) (left side of Figure 5). Next, respondents were assigned randomly to one of three experimental cells: choice (92 respondents), undervalued (110 respondents), or max expected (106 respondents) (right side of Figure 5). The choice cell acts as a control: if assigned to choice, respondents chose which bicycle to search based on attribute-level summaries. If a respondent was assigned to undervalued or max expected, the recommendation system chose the bicycle for the respondent to search based on the algorithms in Section 7.3. Respondents who received a recommendation then searched the recommended bicycle. In all three cells, respondents first stated their prior preference weights w0, searched a bicycle (viewed a rich realistic description), rated their likelihood of purchase, and then stated their preference weights w1 again. Preference weights were measured with a 10-point scale on which the most important attribute is given a 10. Likelihood of purchase was measured with a three-point scale. The study was pretested with 37 respondents to ensure that the respondent tasks were clear and relevant.
8.3. Training a Predictive Model for f rec(w) To train f rec(w), we measure respondents' preference weights after they have searched all available bicycles (training data). We also measure consumer characteristics, such as age, gender, where they live (urban, suburban, rural, other), and how they plan to use

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

435

the bicycle. Using linear regression, we predict wr E[w| f rec] as a function of these variables and the respondents' prior preference weights w0. The last variable accounts for heterogeneity in preference weights that is not tied to the observed characteristics. The predictive model is trained on 93 respondents. These respondents did not participate in the consumer search on the right side of Figure 5. In practice, a recommendation system's underlying predictive model would be based on tens of thousands of respondents (or more); hence, our empirical demonstration is conservative.
8.4. Results of the Empirical Demonstration 8.4.1. Manipulation Checks. We first check whether the recommendation systems recommended bicycles that were different between recommendation systems and different from bicycles that respondents chose to search on their own. The distributions of bicycles differ among the three experimental cells (2 117.8, d.f . 8, p < 0.01); undervalued differs from max expected (2 24.0, d.f . 4, p < 0.01) and from choice (2 77.9, d.f . 4, p < 0.01). The attribute "variety of colors" serves as a control attribute: we do not anticipate that its preference weight would change after search. It did not: w1i - w0i = 0.12, 0.12, and 0.07 for undervalued, max expected, and choice, respectively, and no differences were statistically significant from zero nor statistically different between pairs of experimental cells. Finally, we expect undervalued to sacrifice the overall expected consumption utility of the recommended bicycle relative to max expected (and relative to choice) but hope the sacrifice is not substantial. Our surrogate for expected consumption utility is the stated likelihood of purchase. The average values were 2.2, 2.3, and 2.3 for undervalued, max expected, and choice, respectively; no differences were statistically significant between pairs of experimental cells. The data pass the manipulation checks: respondents in each of the three experimental cells chose or were recommended different bicycles, the preference weights for the control attribute did not change, and the surrogate for expected consumption utility behaved as anticipated.
8.4.2. Change in Preference Weights. We test the first premise by comparing preference weights before and after search using root-mean-square-change (RMSC) and the sum over all attributes. Additionally, we test whether undervalued is better at helping consumers to learn preference weights. Specifically, we test whether preference weights change more for undervalued than for the other two experimental cells. Changes are as predicted: RMSC = 0.81, 0.39, and 0.46, and the sum over attributes is 1.69, 0.20, and 0.53, respectively, for undervalued, max expected,

and choice. Sums are significantly different from zero for undervalued and choice (p's < 0.05). The change in the undervalued experimental cell is significantly larger than the change in either max expected or choice for both RMSC and for the sum of changes (p's < 0.05), but the change in max expected is not significantly different than that in choice (p 0.34). On an attribute-by-attribute basis, the average preference weights (other than for the control attribute) increase significantly or marginally significantly when respondents search bicycles recommended by undervalued (p's < 0.05 for gel seat, folding ability, and a low bar; p's < 0.10 for hydraulic brakes and nighttime visibility). These changes are larger than for those in the other two experimental cells. No attribute-level preference weights change significantly for max expected, and only hydraulic brakes increase significantly for choice (p 0.03). Qualitative comments were consistent, for example, "I changed the folding ability up to 10. I think I really want that in my next bike."
Thus, the data demonstrate that (1) product search can cause preference weights to change (at least for undervalued) and (2) searching undervalued recommendations causes preference weights to change more than searching benchmark recommendations (max expected) or searching without a recommendation (choice).
8.4.3. Moving Preference Weights Toward Their True Values. Empirically, we cannot observe wr, but we can observe E[w| f rec]. To evaluate preference-weight learning, we compare the observed preference-weight change w1 - w0 with the predicted preference-weight change E[w| f rec] - w0. (We compare differences with control for heterogeneity in the w0.) We expect the two differences to move in the same direction if (1) the search changes preference weights and (2) the predictive model is reasonable. We test the movement with regressions (for each attribute and each experiment cell) in which the observed change is a function of the predicted change. We focus on directional movement, recognizing that the predictive models are based on simple regressions using training data for four variables from 93 respondents. Typical commercial recommendation systems might be based on hundreds of variables, tens of thousands of respondents, and state-of-the-art machine-learning methods. Users of commercial recommendation systems would likely search more products than the one recommended product in our tests.
For the undervalued experimental cell, the regression coefficient is significant for gel seat, folding ability, and hydraulic brakes (p's < 0.05) and marginally significant for low bar (p < 0.10). All coefficients are positive. For the max expected experimental cell,

436

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

all coefficients are positive, but none are significant. For the choice experimental cell, the gel seat coefficient is positive and significant (p < 0.05), and the low bar coefficient is positive and marginally significant (p < 0.10). The coefficient is negative but not significant for visibility. Thus, when respondents search bicycles recommended by undervalued, their preference weights move in the direction that is predicted for the true preference weights. This movement is greater than the movement when respondents search benchmark recommendations (max expected) or when respondents search on their own (choice).
To summarize, the empirical demonstration is consistent with both premises (consumers can learn preference weights, and a recommendation system can predict that learning). The empirical demonstration also suggests that a proposed recommendation system leads to greater preference-weight learning than either a benchmark recommendation system or search without recommendations. We consider this empirical demonstration a proof of concept that we hope will be refined in subsequent tests.
9. Summary and Discussion
9.1. Summary When consumers update their preference weights as they search, the optimal search strategy becomes more complex because interdependence among products is introduced by preference-weight learning. Whenever a preference weight is updated, the update changes the utilities of all searched products and the expected utilities of all products yet to be searched. Optimal policies in classic search models, such as the policy derived in Weitzman (1979), are no longer optimal. When we introduce a recommendation system, the policies by which the optimal recommendations should be chosen are even more complex. In contrast to traditional recommendation-systems literature but consistent with recent developments with respect to diversity, novelty, and serendipity, preference-weight learning suggests that recommendation systems should not be evaluated solely on accuracy (probability of choice or expected utility of the recommended product).
Despite the complexity, we gain insight about effective recommendation systems for consumers who learn their preference weights by using intuition and examining the Bellman equation. These insights suggest modifications to recommendation systems: recommend products with diverse aspects, recommend products that the consumer undervalues, and recommend products most likely to update the consumer's

prior beliefs. Recommendation systems based on these modifications perform well in synthetic data experiments, especially for na¨ive consumers and when recommendation systems can predict consumers' preference weights. The proposed recommendation systems perform well as long as they are not too complex.
We demonstrate empirically that consumers update their preference weights from searching even a single rich realistic description of a bicycle. Preference-weight learning is greater when consumers search a bicycle recommended by one of the proposed recommendation systems--greater than search based on a benchmark recommendation system or search without a recommendation. Furthermore, the actual change in preference weights moves as predicted, especially when consumers search products recommended by the proposed recommendation system.
9.2. Generality We expect the insights from the numerical examples, the synthetic data experiments, and the empirical demonstration to scale to larger product spaces. The proposed modifications are stylized proof-of-concept recommendation systems; we expect more sophisticated modifications to achieve even greater improvements, especially when tuned to specific settings. Our formal model assumes that consumers know attribute levels. Relaxing this abstraction greatly complicates the model but does not change the insight that preferenceweight learning affects search. Preference-weight learning and attribute-level learning are complementary phenomena.
We assumed that attributes are described by discrete levels (aspects). We did not restrict the attributes to be horizontal (type of kitchen) or vertical (livein superintendent versus full-service concierge), although we did assume that learning about one aspect does not affect the priors with respect to another aspect. Continuous attributes, such as the square footage in a condominium or the proximity to a playground, can be handled in one of two ways--both are common for typical preference-weight measurement methods, such as conjoint analysis. Either we discretize the continuous attribute or assume a parametric form (linear, quadratic, logarithmic) for the preference function. Discretized attributes are handled with no modification. For parametric preferences, we need to specify updating rules. For example, the consumer's preferences might be linearly increasing in square footage. The consumer updates that linear weight in a matter analogous to the updating rules in Equation (2).

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

437

9.3. Future Research
The analyses in this paper demonstrate that preferenceweight learning can have a major impact on the study of consumer search and on the design of recommendation systems. Further avenues of research are promising. Researchers might explore interdependence among preference weights for aspects and model how learning about one aspect informs preference weights about another aspect. Interdependence is especially interesting for discretized vertical attributes. Recommendation systems might be developed that identify the consumer's relative na¨iveté and change algorithms depending on that na¨iveté. Ensembles of recommendation systems might do well. We focused on situations in which consumers have ready access to attribute-level information. Combining preference-weight learning and attributelevel search is a complex and interesting challenge.
In Section 6, nonbenevolent recommendation systems influenced outcomes to the benefit of the recommendation system yet left the consumer satisfied. Such recommendation systems could prove interesting. We assumed that forward-looking consumers solve Equation (3). An alternative interpretation is that heuristic solutions to Equation (3) approximate consumer search. For example, Lin et al. (2014) illustrate situations in which consumers use a cognitively simple learning strategy that approximates a complex dynamic program.
We focused on benevolent recommendation systems that maximize consumers' net purchase and consumption utility. One justification for an assumption that the consumer searched recommended products is the utility bonus. It is possible that the utility bonus is not sufficient: the consumer might decline searching further if the expected utility of the recommended product is too low. This phenomenon might hamper the recommendation system's reputation and provide incentives to the recommendation system to avoid low-expected-utility recommendations even when such recommendations are in the best interests of the consumer. Such situations are worth studying.
Our examples and references from the marketingscience literature motivate preference-weight learning. Research on the underlying mechanism could improve insight. There are rich literatures in both recommendation systems and in marketing about firm-side learning of preference weights. When such algorithms are coupled with the modifications suggested in this paper, we expect that recommendations to consumers will improve.
Finally, our empirical demonstration was a proof of concept. Experiments might explore recommendations in other product categories with more attributes, in situations in which commercial prediction algorithms are used, for more extensive search, or with endogenous stopping rules.

Appendix. Formal Demonstrations
A.1. Consumer Search Criteria When consumers learn their preference weights, there exist product spaces in which the consumer, searching optimally without a recommendation, may use search criteria that differ from the typical criteria in either search-theory or recommendation systems. In particular, unlike typical criteria in search theory, the consumer may choose to search a product that does not have the highest option value (highest variance). Unlike typical recommendation-systems criteria, the consumer may choose to search a product that does not have the highest expected utility. The product may even have a low or zero probability of being chosen.
Proof. The formal analysis is based on binary attributes. However, to show the result, we need at least three binary attributes and not a full-factorial product space. Thus, we consider a product space of x1 (0, 0, 0), x2 (1, 0, 0), x3 (0, 1, 0), x4 (0, 0, 1), x5 (1, 1, 0), x6 (1, 0, 1), and x7 (0, 1, 1). In a proof available from the authors and as illustrated in Section 4, we demonstrate that the consumer will prefer searching those products that reveal two attributes, x5, x6, or x7, rather than those products that reveal only one attribute.
Because this result is an existence proof, we need only show an example. (We actually show a class of examples.) For our example, we assume zero signal variance such that the posterior distributions are (wri ) when the consumer searches a product with xij 1. We consider distributions for the consumer's prior beliefs in which the consumer prior beliefs assure that wr1, wr2, wr3  0 and min{wr3}  max{wr1, wr2}. Our result is not limited to such distributions, but such distributions suffice. There are many distributions that satisfy these properties. For example, the conditions hold for uniformly distributed beliefs wi ~ 8[ai, bi], with parameters a1, a2  0 and a3  max[b1, b2]. The assumption of nonnegative true importances simplifies the tree of conditions in the dynamic program and ensures that the consumer weakly prefers x5 to x1, x2, and x3; weakly prefers x6 to x1, x2, and x4; and weakly prefers x7 to x1, x3, and x4. We need only consider a product space of x5, x6, and x7. These are really the most interesting products for our purposes. The outside option is U* u(x1) 0.
We first consider searching on x5. With min{wr3}  max{wr1, wr2}, the consumer would never choose x5 but may consider searching x5 to learn wr1 and wr2 efficiently. We assume that   1 is sufficiently large to justify search. After searching x5, the consumer will either choose the outside option, one of x5, x6, and x7, or searchx6 or x7, and perhaps if the consumer searches, the consumer will continue thereafter. Using Equation (3) in the text, we obtain

J({5}, f 0) max{0, max{wr1 + wr2, wr1 + w¯ 3, wr2 + w¯ 3},

max{
k 6,7

-

c

+

Ew3

[

J

({5,

k},

f

1

|

f

0

)]}}.

(A.1)

With min{wr3}  max{wr1, wr2}, there is no value to searching to reveal wr3 because knowing wr3 does not change the consumer's decision. Using wr1, wr2, wr3  0, we eliminate the outside option as a choice. Using min{wr3}  max{wr1, wr2}, we

438

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

eliminate x5 as a choice. Hence, we obtain the cost of searching x5 as
-c + Ew1,w2 [ J({5}, f 0)] -c + Ew1,w2[max{max{wr1 + w¯ 3, wr2 + w¯ 3}, -c + 0}] -c + Ew1,w2[max{w1, w2}] + w¯ 3.
(A.2)
The last step uses the consumer's prior beliefs to compute expected values for the wri 's that are revealed by search.
We now consider searching on x6. Using similar reasoning to Equation (A.1), we obtain

J({6}, f 0) max{0, max{wr1 + w¯ 2, wr1 + wr3, w¯ 2 + wr3}, max{-c + E[J({6, k}, f 1| f 0)]}}.
k 5,7

(A.3)

We first examine the value of further search. Searching either x5 or x7 reveals wr2, so the consumer is indifferent between searching x5 or x7. We replace the value of further search by the value of searching one of the two products. As
in the case of searching x5, further search beyond x6 and x5 or x6 and x7 has no value. Thus, we have, if the consumer were to choose to search,

-c + Ew2 [ J({5, 6}, f 1)]

-c + Ew2 [ J({6, 7}, f 1)] -c + Ew2[max{wr1 + wr3, w2 + wr3}] -c + Ew2[max{wr1, w2}] + wr3.
(A.4)

If, after searching only x6, the consumer were to choose without search, then wr1 and wr3 are revealed, but the consumer expects w¯ 2 if x5 or x7 is chosen. Recall that the outside option and x5 are dominated if consumer beliefs follow the example class of distributions. Thus, the value of choosing without
search, that is, the second internal max in Equation (A.3), is
given by the following:

max{wr1 + w¯ 2, wr1 + wr3, w¯ 2 + wr3} max{wr1, w¯ 2} + wr3. (A.5)
Putting it all together and factoring out wr3, we obtain J({6}, f 0) max{max{wr1, w¯ 2}, - c + Ew2[max{wr1, w2}]} + wr3.
(A.6)

And the value of searching x6 is

-c + Ew1,w3 [ J({6}, f 0)]

-c + Ew1[max{max{wr1, w¯ 2}, -c + Ew2[max{wr1, w2}]}] + w¯ 3 -c + Ew1[max{wr1, w¯ 2, -c + Ew2[max{wr1, w2}]}] + w¯ 3.
(A.7)

Suppose that wr1  w¯ 2. Then, for all wr1, max{wr1, w¯ 2, -c + Ew2[max{wr1, w2}]}  Ew2[max{wr1, w2}] for sufficiently large   1. This is true because, for the last internal max, max{wr1, w2}  wr1. (It is certainly true for  1.) Hence, Ew1[max{wr1, w¯ 2, -c + Ew2[max{wr1, w2}]}|wr1  w¯ 2] Ew1,w2[max{w1, w2}| wr1  w¯ 2]. Suppose that wr1 < w¯ 2. Then, for all wr1, max{wr1, w¯ 2, -c + Ew2[max{wr1, w2}]}  Ew2[max{wr1, w2}]. This is true because w¯ 2  Ew2[max{wr1, w2}] for sufficiently large   1. Thus, Ew1[max{wr1, w¯ 2, -c + Ew2[max{wr1, w2}]}|wr1 < w¯ 2]  Ew1,w2[max{w1, w2}|wr1 < w¯ 2] for sufficiently large   1.

Putting these expressions together establishes that Ew1[max{wr1, w¯ 2, -c + Ew2[max{wr1,w2}]}]  Ew1,w2[max{w1,w2}]. Comparing Equation (A.7) with Equation (A.2), we have the result that -c + Ew1,w3 [ J({6}, f 0)]  -c + Ew1,w2 [ J({5}, f 0)].
We have demonstrated that the consumer prefers to search x5 rather than x6. The consumer's preference for searching x5 rather than x7 follows by symmetry. We have also demonstrated that, after the first product is searched,
the consumer does not search further. Finally, we can easily
show that the consumer will choose to search whenever -c + Ew1,w2[max{w1, w2}]  max{w¯ 1, w¯ 2}. This must hold for some c and for sufficiently large   1. By design, all possible
realized values of w3 are greater than any possible realized value of either w1 or w2; hence, both the expected utility and the option value of u(x6) and u(x7) dominate the expected utility and option value of u(x5). By option value, we mean that E[u(x5)|u(x5)  U*] < E[u(x6)|u(x6)  U*] E[u(x7)| u(x7)  U*]. We have nowhere restricted the variances of prior beliefs. The result holds even if the variance of w3 is greater than the variance of w1 and the variance of w2. Finally, all possible realized values of w3 are greater than any possible realized value of either w1 or w2, and the consumer will never choose x5 after searching x5. This completes the proof.

A.2. Recommendation System Criteria. For recommendation systems that take preference-weight learning into account, the optimal product to recommend may not satisfy the typical criterion that it be the highest expected utility (most likely to be chosen). The product might even have a low or zero probability of being chosen. Furthermore, the product may not have the largest option value as might be expected from optimal search theory.

Proof. This result is also based on binary attributes. We

consider a three-product product space: x1 (0, 0), x2 (1, 0), and x3 (0, 1). Because this result is an existence proof, we

need only show an example. We begin by deriving general

conditions and then show that there exists a class of examples

that satisfy the general conditions.

We first examine the consumer's optimal search path in

the absence of a recommendation. The consumer makes

decisions based on the consumer's prior beliefs and

revealed values. We are particularly interested in the case in

which one of the attributes is undervalued by the consumer

but but

not



 0

by the recommendation system:  0w2df20(w2) < c, w2df2rec(w2) > c. The other attribute is not undervalued:

f1rec(w1)

f10(w1)

and



 0

w1df10

(w1

)



 0

w1

df1rec

(w1

)

>

c.

We

are interested in the case in which the consumer searches (at least) x2, so we further assume that  0w1df10(w1) -c > w¯ 1. For simplicity, we set the utility of the outside option to the

utility of choosing x1 (0, 0) such that U* u(x1) 0.

We evaluate whether the consumer searches x2. The

expected value of searching x2 is



E [ J({x2}, f 1)] max 0, w¯ 1, - c + 

w2df20(w2) .

max{0,wr1 }

(A.8)

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

439

Recognizing

that



 max{0,wr1

}

w2

df20

(w2

)





 0

w2

df20

(w2

)

<

c

for   1, the consumer will not search x3 after x2; hence,

E [J({x2}, f 1)] max{0, w¯ 1}. Furthermore, because  0 w1 ·

df10(w1) - c > w¯ 1, E [ J({x2}, f 1)] - c > w¯ 1; hence, the con-

sumer prefers to search x2 rather than simply choose x2.

The expected value of searching x3 is



E [ J({x3}, f 1)] max 0, w¯ 2, -c + 

w1df10(w1)

max{0,w¯ 2}

 max{0, w¯ 2}


w2df20(w2) < c,
0

(A.9)

which implies that the consumer will not choose to search x3 (without a recommendation). Putting these together, if no
recommendations are made, the consumer would search x2 and then either purchase x2 if wr1  0 or accept the outside option, U* 0, if wr1 < 0. The expected payoff based on the consumer's beliefs is given in Equation (A.10). Because f1rec(w1) f10(w1), this is also the recommendation system's belief about what the consumer will achieve without any
recommendation.

E [ J(Ø, f 0)| f rec]

-c +  -c + 


w1df10(w1)
0
w1df1rec(w1).
0

(A.10)

We now analyze the cases in which the recommendation

system recommends a product, x2 or x3, and the consumer follows that recommendation. We assume the consumer

acts optimally after the recommendation. (We later con-

sider what would happen if the recommendation system

could recommend both products.) We seek to establish a

case in which the recommendation system recommends

even

though



0 w2df1rec(w2) < 

 0

w1

df1rec(w1).

x3

We first consider the expected payoff if the recommen-

dation system recommends x2 only. If x2 is the recom-

mendation, then the consumer does not deviate from the

optimal path that the consumer would have chosen without

a recommendation. Define J({x2}rec, f 1) as the continuation value given that the consumer searched x2 because of a

recommendation. Then



E [ J({x2}rec, f 1)| f rec] -c + 

w1df1rec(w1).

0

(A.11)

We now consider the expected payoff if the recom-

mendation system recommends x3. After searching the

recommended product, the consumer may stop and pur-

chase x3, take the outside option (U* remaining product, x2. [Our condition

0), or search the that  0 w1df10(w1) -

c > w¯ 1 ensures that the consumer will not purchase x2

without searching. It's easy to show that Equation (A.12)

does not change that.] From the consumer's perspective,



E [ J({x3}rec, f 1| f 0)] max 0, w¯ 2, -c + 

w1df10(w1) .

max{0,w¯ 2}

(A.12)

The

consumer

will

search

x2

if



 max{0,w¯ 2

}

w1

df10

>

c

+

w¯ 2.

We are interested in the recommendation system's expec-

tation of this payoff, or E [ J({x3}rec, f 1)| f rec]. This value de-

pends on whether the consumer would choose to search x2

after searching x3. Define w~ 2 to be the maximum observed

value of wr2 for which it would be optimal for the consumer

to search



 w~ 2

w1df10

and does

x2 after x3. This value is defined implicitly by

c not

+ w~ 2. If wr2 > w~ 2, the search x2 because wr2

consumer purchases x3

>

-c

+



 w~ 2

w1

df10

(w1

).

To compute the expected value, we consider three regions

for the outcome of the x3 search. Each outcome corresponds

to a different action by the consumer after searching x3. These regions are wr2  0, 0 < wr2  w~ 2, and wr2 > w~ 2. Note that w~ 2 is defined by f 0, but we compute expectations based on the

recommendation system's beliefs f rec.

Case 1. search x2

wafr2ter0x. 3Ibnectahuissereg 0iown1,

the consumer expects to df10(w1) > c. After searching

x2, there are no products left to search; the consumer

purchases x2 if wr1 > 0 and takes the outside good if wr1  0. In

this region, the recommendation believes



-c + E [ J({x3}rec, f 1)|wr2  0, f rec] -(1 + )c +  w1df1rec(w1).

0

(A.13)

Case 2. 0 < wr2  w~ 2. In this region, by the definition of w~ 2, the consumer expects to search x2 after x3, after which there
are no products left to search. The net expected payoff to the consumer is -(1 + )c +  max{0, wr1, wr2} according to the recommendation system's beliefs.

Case 3. w~ 2 < wr2. In this region, by the definition of w~ 2, the

c-ocn+sum~we2 wr c1hdof10o(swe1s)x3

and does

-c

+



 wr2

not search w1df10(w1)

x2. But, and wr2

because wr2 > > 0, we know

E [ J({x3}rec, f 1| f rec)]



max 0, wr2, -c + 

w1df10(w1)

max{0,wr2 }



 -c + 

w1df10(w1).

max{0,wr2 }

(A.14)

Thus, the net payoff in Case 3 is at least as large as that

which the consumer would obtain by searching x2 after x3, thus, the next payoff is at least as large as -(1 + )c +

 max{0, wr1, wr2}. By combining Cases 2 and 3, which occur

according to the recommendation system's beliefs with prob-

ability Pr(w2 > 0)



 0

w2df2rec

(w2

),

we

obtain

a

lower

bound

on the recommendation system's beliefs for Cases 1­3 as

-(1 + )c +  max{0, wr1, wr2}: -c + E [ J({x3}rec, f 1)| f rec]

0



 -(1 + )c + 

w1 df1rec (w1 )df2rec (w2 )

w2 - w1 0

0

+

w2 df1rec (w1 )df2rec (w2 )

w2 0 w1 -



+

w1 df1rec (w1 )df2rec (w2 )

w2 0 w1 w2



w2

+

w2 df1rec (w1 )df2rec (w2 ).

w2 0 w1 0

(A.15)

440

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

Note that we would also obtain the right-hand side of Equation (A.15) if the recommendation system were to recommend both x2 and x3. Thus, we have shown that recommending x3 alone weakly dominates recommending both products for sufficiently large   1. We now rearrange the limits of integration to obtain

-c + E [ J({x3}rec, f 1)| f rec]





 -(1 + )c + 

w1df1rec(w1)df2rec(w2)

w2 - w1 0

0

+

w2 df1rec (w1 )df2rec (w2 )

w2 0 w1 -



w2

+

(w2 - w1)df1rec(w1)df2rec(w2)

w2 0 w1 0

0

 E [ J(Ø, f 0)| f rec] - c + 

w2 df1rec (w1 )df2rec (w2 )

w2 0 w1 -



w2

+

(w2 - w1)df1rec(w1)df2rec(w2).

w2 0 w1 0

(A.16)

Equation (A.16) is a general condition for when the rec-

ommendation system will recommend x3 to the consumer.

All that remains to complete the proof is to establish at least

one example in which the last two integrals in Equation (A.16)

exceed c. We can do this for many distributions. We do it for

at least one.

We consider uniform distributions, all of which have the zero

mean: f10(w1) f1rec(w1) 8[-b1, b1], f2rec(w2) 8[ - b1, b1], and f20(w2) 8[-b2, b2], where  < 1 ensures that the option

value of x3 is less than the option value of x2 and the variance

tohfa0ut(wx13d)fi010s(wlwe21sd)sf20t(hwa2n)0 t<whc1edvfw1arericit(ahwn1c)be>2o<cf

u(x2). 4c/.
and

If  1, we ensure

We ensure that




0 w2

df2rec

(w2

)

>

c

with b1 > 4c/. The value of the next-to-last integral is

b1/8, and the value of the last integral is 2b1/24. Thus,

for any positive  < 1, the result holds as long as 2b1/24

+b1/8 > c/. Because  < 1, we have that 2 < . Thus, we

require only that 2b1 > 6c/. This condition and the con-

dition b1 > 4c/ are satisfied for many values of  and

b1. For example, if  1/2, then it is sufficient that

b1 > 24c/. Prob{choose x3}

1 4

+

 8

<

1 2

-

 8

Prob{choose x2}

for all  < 1. Finally, replacing the support of w2 with

f rec(w2) 8[ -b1 - , b1 - ], condition (A.16) becomes

-c/ + (b1 - )2/8b1 + (b1 - )3/24b21 > 0. We choose > 0

so that Erec[8(x3)] < Erec[u(x2)]. With 1/2, b1 3, and c/

0.1, setting 0.05 suffices. This completes the proof.

References
Adam K (2001) Learning while searching for the best alternative. J. Econom. Theory 101(1):252­280.
Adamopoulos P, Tuzhilin A (2014) On unexpectedness in recommender systems: or how to better expect the unexpected. ACM Trans. Intelligent Systems Tech. 5(4):54:1­32.
Adomavicius G, Tuzhilin A (2005) Toward the next generation of recommender systems: A survey of the state-of-the-art and possible extensions. IEEE Trans. Knowledge Data Engrg. 17(6):734­749.
Ansari A, Essegaier S, Kohli R (2000) Internet recommendation systems. J. Marketing Res. 37(3):363­376.

Bikhchandani S, Sharma S (1996) Optimal search with learning. J. Econom. Dynam. Control 20(1):333­359.
Bodapati A (2008) Recommendation systems with purchase data. J. Marketing Res. 45(1):77­93.
Branco F, Sun M, Villas-Boas JM (2012) Optimal search for product information. Management Sci. 58(11):2037­2056.
Bronnenberg BJ, Kim J, Mela CF (2016) Zooming in on choice: How do consumers search for cameras online? Marketing Sci. 35(5): 693­712.
Castells P, Vargas S, Wang J (2011) Novelty and diversity metrics for recommender systems: choice, discovery and relevance. Macdonald C, Wang J, Clarke C, eds. Proc. Internat. Workshop Diversity Document Retrieval, Dublin, Ireland.
Celma O` , Herrera P (2008) A new approach to evaluating novel recommendations. Proc. 2008 ACM Conf. Recommender Systems (ACM, New York), 179­186.
Chen Y, Yao S (2016) Sequential search with refinement: Model and application with clickstream data. Management Sci. 63(12): 4345­4365.
Chick SE, Frazier P (2012) Sequential sampling with economics of selection procedures. Management Sci. 58(3):550­569.
Chung J, Rao VR (2012) A general consumer preference model for experience products: Application to internet recommendation services. J. Marketing Res. 49(3):289­305.
Cook J (2012) MiniDates schedules real-life (legitimately) blind dates for you. TechCrunch (May 30), https://techcrunch.com/2012/ 05/30/minidates-schedules-real-life-legitimately-blind-dates-for -you/.
De Bruyn A, Liechty JC, Huizingh EKRE, Lilien GL (2008) Offering online recommendations with minimum customer input through conjoint-based decision aids. Marketing Sci. 27(3):443­460.
Dzyabura D, Jagabathula S (2018) Offline assortment optimization in the presence of an online channel. Management Sci. 64(6): 2767­2786.
Dzyabura D, Jagabathula S, Muller E (2019) Accounting for discrepancies between online and offline product evaluations. Marketing Sci. 38(1):88­106.
Finkel EJ, Eastwick PW, Karney BR, Reis HT, Sprecher S (2012) Online dating: A critical analysis from the perspective of psychological science. Psych. Sci. Public Interest 13(1):3­66.
Fleder D, Hosanagar K (2009) Blockbuster culture's next rise or fall: The impact of recommender systems on sales diversity. Management Sci. 55(5):697­712.
Ge M, Delgado-Battenfeld C, Jannach D (2010) Beyond accuracy: Evaluating recommender systems by coverage and serendipity. Proc. 2008 ACM Conf. Recommender Systems (ACM, New York), 257­260.
Ghose A, Ipeirotis PG, Li B (2012) Designing ranking systems for hotels on travel search engines by mining user-generated and crowdsourced content. Marketing Sci. 31(3):493­520.
Gittins JC (1979) Bandit processes and dynamic allocation indices. J. Roy. Statist. Soc. Ser. B (Methodological) 41(2):148­177.
Gittins JC, Glazebrook K, Weber R (2011) Multi-armed Bandit Allocation Indices (John Wiley & Sons, London).
Greenleaf EA, Lehmann DR (1995) Reasons for substantial delay in consumer decision making. J. Consumer Res. 22(2):186­199.
Ha¨ubl G, Trifts V (2000) Consumer decision making in online shopping environments: The effects of interactive decision aids. Marketing Sci. 19(1):4­21.
Hauser JR, Dong S, Ding M (2014a) Self-reflection and articulated consumer preferences. J. Product Innovation Management 31(1):17­32.
Hauser JR, Liberali G, Urban GL (2014b) Website morphing 2.0: Switching costs, partial exposure, random exit, and when to morph. Management Sci. 60(6):1594­1616.
Hauser JR, Urban GL, Liberali G, Braun M (2009) Website morphing. Marketing Sci. 28(2):202­224.

Dzyabura and Hauser: Recommending Products When Consumers Learn Their Preferences Marketing Science, 2019, vol. 38, no. 3, pp. 417­441, © 2019 INFORMS

441

Herlocker J, Konstan J, Terveen L, Riedl J (2004) Evaluating collaborative filtering recommender systems. ACM Trans. Inform. Systems 22(1):5­53.
Hong H, Shum M (2006) Using price distributions to estimate search costs. RAND J. Econom. 37(2):257­275.
Honka E (2014) Quantifying search and switching costs in the US auto insurance industry. RAND J. Econom. 45(4):847­884.
Jacobs BJD, Donkers B, Fok D (2016) Model-based purchase predictions for large assortments. Marketing Sci. 35(3):389­404.
Jun T (2004) A survey on the bandit problem with switching costs. Economist 152(4):513­541.
Ke TT, Shen Z-JM, Villas-Boas, JM (2016) Search for information on multiple products. Management Sci. 62(12):3576­3603.
Kim JB, Albuquerque P, Bronnenberg BJ (2010) Online demand under limited consumer search. Marketing Sci. 29(6):1001­1023.
Lin S, Zhang J, Hauser JR (2014) Learning from experience, simply. Marketing Sci. 34(1):1­19.
Liu NN, Zhao M, Xiang E, Yang Q (2010) Online evolutionary collaborative filtering. Proc. 4th ACM Conf. Recommender Systems (ACM, New York), 95­102.
Lu S, Xiao L, Ding M (2016) A video-based automated recommender (VAR) system for garments. Marketing Sci. 35(3):484­510.
McNee S, Riedl J, Konstan J (2006) Accurate is not always good: How accuracy metrics have hurt recommender systems. Extended Abstracts on ACM Human Factors in Computing Systems (ACM, New York), 1097­1101.
Mersereau AJ, Rusmevichientong P, Tsitsiklis JN (2009) A structured multiarmed bandit problem and the greedy policy. IEEE Trans. Automatic Control 54(12):2787­2802.
Misra K, Schwartz EM, Abernethy J (2017) Dynamic online pricing with incomplete information using multi-armed bandit experiments. Working paper, University of Michigan, Ann Arbor.
Moon S, Russell GL (2008) Predicting product purchase from inferred customer similarity: An autologistic model approach. Management Sci. 54(1):71­82.

Rogers A (2013) After you read the listings, your agent reads you. New York Times (March 26), F4.
Schwartz EM, Bradlow ET, Fader PS (2017) Customer acquisition via display advertising using multi-armed bandit experiments. Marketing Sci. 36(4):500­522.
Seiler S (2013) The impact of search costs on consumer behavior: A dynamic approach. Quant. Marketing Econom. 11(2):155­203.
She J, MacDonald EF (2013) Trigger features on prototypes increase preference for sustainability. Proc. 25th ASME Internat. Conf. Design Theory Methodology, Portland, OR.
Sheehy K (2013) Study: High school grads choosing wrong college majors. U.S. News World Rep. (November 11). http://www .usnews.com/education/blogs/high-school-notes/2013/11/11/ study-high-school-grads-choosing-wrong-college-majors.
Tversky A (1972) Elimination by aspects: A theory of choice. Psych. Rev. 79(4):281­299.
Urban GL, Hauser JR (2004) `Listening-in' to find and explore new combinations of customer needs. J. Marketing 68(2):72­87.
Vargas S, Castells P (2011) Rank and relevance in novelty and diversity metrics for recommender systems. Proc. 5th ACM Conf. Recommender Systems (ACM, New York), 109­116.
Weitzman ML (1979) Optimal search for the best alternative. Econometrica 47(3):641­654.
Whittle P (1988) Restless bandits: Activity allocation in a changing world. J. Appl. Probab. 25(A):287­298.
Ying Y, Feinberg F, Wedel M (2006) Leveraging missing ratings to improve online recommendation systems. J. Marketing Res. 43(3): 355­365.
Zhang M, Hurley N (2008) Avoiding monotony: Improving the diversity of recommendation lists. Proc. 2008 ACM Conf. Recommender Systems (ACM, New York), 123­130.
Zhou T, Kuscsik Z, Liu J-G, Medo M, Wakeling JR, Zhang Y-C (2010) Solving the apparent diversity-accuracy dilemma of recommender systems. Proc. Natl. Acad. Sci. 107(10):4511­4515.
Ziegler C-N, McNee SM, Konstan JA, Lausen G (2005) Improving recommendation lists through topic diversification. ACM Proc. 14th Internat. Conf. World Wide Web (ACM, New York), 22­32.

