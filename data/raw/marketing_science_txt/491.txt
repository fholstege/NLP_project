CELEBRATING 30 YEARS
Vol. 30, No. 5, September­October 2011, pp. 866­880 issn 0732-2399 eissn 1526-548X 11 3005 0866

http://dx.doi.org/10.1287/mksc.1110.0654 © 2011 INFORMS

New Perspectives on Customer "Death" Using a Generalization of the Pareto/NBD Model

Kinshuk Jerath
Tepper School of Business, Carnegie Mellon University, Pittsburgh, Pennsylvania 15213, kinshuk@cmu.edu
Peter S. Fader
The Wharton School of the University of Pennsylvania, Philadelphia, Pennsylvania 19104, faderp@wharton.upenn.edu
Bruce G. S. Hardie
London Business School, London NW1 4SA, United Kingdom, bhardie@london.edu
Several researchers have proposed models of buyer behavior in noncontractual settings that assume that customers are "alive" for some period of time and then become permanently inactive. The best-known such model is the Pareto/NBD, which assumes that customer attrition (dropout or "death") can occur at any point in calendar time. A recent alternative model, the BG/NBD, assumes that customer attrition follows a Bernoulli "coin-flipping" process that occurs in "transaction time" (i.e., after every purchase occasion). Although the modification results in a model that is much easier to implement, it means that heavy buyers have more opportunities to "die."
In this paper, we develop a model with a discrete-time dropout process tied to calendar time. Specifically, we assume that every customer periodically "flips a coin" to determine whether she "drops out" or continues as a customer. For the component of purchasing while alive, we maintain the assumptions of the Pareto/NBD and BG/NBD models. This periodic death opportunity (PDO) model allows us to take a closer look at how assumptions about customer death influence model fit and various metrics typically used by managers to characterize a cohort of customers. When the time period after which each customer makes her dropout decision (which we call period length) is very small, we show analytically that the PDO model reduces to the Pareto/NBD. When the period length is longer than the calibration period, the dropout process is "shut off," and the PDO model collapses to the negative binomial distribution (NBD) model. By systematically varying the period length between these limits, we can explore the full spectrum of models between the "continuous-time-death" Pareto/NBD and the naïve "no-death" NBD.
In covering this spectrum, the PDO model performs at least as well as either of these models; our empirical analysis demonstrates the superior performance of the PDO model on two data sets. We also show that the different models provide significantly different estimates of both purchasing-related and death-related metrics for both data sets, and these differences can be quite dramatic for the death-related metrics. As more researchers and managers make managerial judgments that directly relate to the death process, we assert that the model employed to generate these metrics should be chosen carefully.
Key words: customer-base analysis; Pareto/NBD; BG/NBD; customer attrition History: Received: February 9, 2011; accepted: March 16, 2011; Steve Shugan served as the acting editor-in-chief
for this article. Published online in Articles in Advance June 6, 2011.

1. Introduction
As marketing researchers become more sophisticated in building models of customer behavior, they begin to scrutinize, test, and improve upon underlying assumptions of their models that were originally taken for granted. Within the domain of noncontractual customer-firm relationships, the assumptions made about the timing and nature of customer "death" (i.e., unobserved and unobservable dropout) are ripe for such improvements. For years, the gold standard for such models has been the Pareto/NBD (Schmittlein et al. 1987), which was the first to capture and exploit a customer death process in such a setting.

Applications of the model (e.g., Fader et al. 2005b, Reinartz and Kumar 2000, Schmittlein and Peterson 1994) have utilized the Pareto/NBD dropout process (namely, an exponential timing process with gammadistributed heterogeneity across customers) without questioning it or testing alternative mechanisms.
The first paper to raise such questions was Fader et al. (2005a), which replaced the continuous-time gamma-exponential process operating in "calendar time" with a beta-geometric process operating in "transaction time" (i.e., the customer can only die immediately after a transaction). The resulting model, called the BG/NBD, was viewed as a "quick and

866

Jerath, Fader, and Hardie: New Perspectives on Customer "Death" Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

867

easy" alternative to the Pareto/NBD, because it offers a much more straightforward parameter estimation process with no substantial loss in the model's fit and forecasting capabilities. Beyond these computational benefits and aggregate indicators of overall model performance, however, not much attention was paid to the death process itself.
In this paper we propose and carefully investigate a new process for customer death in the noncontractual setting. The resulting model is a generalization of the Pareto/NBD and offers new insights about the death process. This new framework, called the periodic death opportunity (PDO) model, assumes that customers act in accordance with the discrete "coinflipping" story associated with the geometric process, but these "coin flips" arise at periodic intervals in calendar time instead of transaction time (as in the BG/NBD model).
The differences in the assumed customer death process associated with these "buy-till-you-die" models of buyer behavior in noncontractual settings are illustrated in Figure 1. The first dimension on which they differ is whether the customer can "die" at any point in time (continuous) or only at discrete points in time. A second dimension appears when death occurs at discrete points in time: whether these points are discrete points in calendar time or are on a different timescale defined by the point in time at which transactions occurred. In all cases, it is assumed that opportunities for transactions (while alive) occur in continuous time; this is implicit in the use of the NBD to characterize buying behavior while alive.1
The PDO model allows us to take a closer look at how assumptions about customer death influence model fit as well as managerial inferences and diagnostics that emerge from the model. By varying the length of the time interval after which each customer makes her dropout decision, which we call the period length, we effectively vary the customer dropout dynamics. When the period length is very large, the dropout component is "shut off," and our model becomes the standard "no-death" negative binomial distribution (NBD) model (Ehrenberg 1959, Morrison and Schmittlein 1988). At the other extreme, when the period length tends to zero, our discrete-time dropout process converges into the continuous-time dropout process of the Pareto/NBD; we prove this convergence analytically. For intermediate values of period
1 When the opportunities for transactions occur in discrete time (e.g., the NBD is replaced by the beta-binomial (BB) model), the "Continuous time" row in Figure 1 collapses into the "Discrete time" row (as time is discretized), and the distinction between "Calendar time" and "Transaction time" disappears (because they become one and the same timescale). Thus all three models collapse to the BG/BB model (Fader et al. 2010) when transactions can only occur at discrete points in time.

Figure 1

Classifying Differences in Assumed Customer Death Processes

Continuous time
Opportunities for death
Discrete time

BG/NBD

Pareto/NBD PDO

Transaction

Calendar

time

time

Time measure

length, we can explore the full continuum of models that lie between these two extremes.
We find in our empirical analysis that the PDO model works better than both the NBD and the Pareto/NBD models for intermediate values of the period length, both in the calibration samples and longitudinal holdout periods. Hence, the PDO model acts as a unifying framework between the widely used Pareto/NBD and NBD models. We also find that the PDO model produces different estimates of some key managerial quantities compared to the alternative models. For instance, for both the data sets that we analyze, the PDO model predicts that the average customer in the cohort purchases slower while alive but lives longer, compared to the Pareto/NBD model.
We also compare the PDO model to the BG/NBD model and find that customer-death-related inferences are vastly different for the BG/NBD model. Recent research has focused on using death estimates obtained from buy-till-you-die models to augment managerial decisions regarding customer retention programs (Gopinath et al. 2009; Reinartz and Kumar 2000, 2003; Schweidel and Knox 2010; Wübben and Wangenheim 2008). Our results show that different models can lead to very different conclusions about customer death. In light of this, we assert that the model employed to generate these metrics should be chosen carefully, and the PDO model offers a rich framework for this analysis.
In the next section, we formally develop the PDO model. In §3, we carry out an empirical analysis in which the performance of the proposed model is compared to that of the Pareto/NBD, BG/NBD, and NBD models on two data sets--one using transactions from an online retailer of music CDs and the other using transactions from a grocery store. In §4, we extend the basic model to allow for heterogeneity in the period

Jerath, Fader, and Hardie: New Perspectives on Customer "Death"

868

Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

length parameter and estimate this new model on both data sets. Finally, we conclude with a recap of the model, a brief discussion of its limitations, and some suggestions for related future research opportunities.

2. Model Development
The PDO model is based on the following six assumptions.
Assumption 1. A customer's relationship with a specific firm can be characterized as first being alive for some period of time, then becoming permanently inactive (dead).
Assumption 2. While alive, the number of transactions made by a customer follows a Poisson process with mean . (This is equivalent to assuming that the interpurchase times are independent and identically distributed exponential with rate .)
Assumption 3. Heterogeneity in transaction rates across customers follows a gamma distribution with shape parameter r and scale parameter :

r r-1e-

fr=

r

(1)

Assumption 4. Let the random variable denote the

unobserved time at which the customer dies. We model

the death process by assuming that every units of time

(where time starts at zero), the customer can drop out with

probability . (This implies that the customer can drop

out at 2

t/ in the interval 0 t , where ·

denotes the "floor" function.) Therefore, the probability that

the customer has died by time t is

P t

= 1 - 1 - t/

and the mean lifetime of the customer is E

= /.

We refer to as the period length parameter and assume

that it is the same for all customers. (We relax this assump-

tion in §4.)

Assumption 5. Heterogeneity in follows a beta distribution with probability density function (pdf )

f

ab=

a-1 1 - Ba b

b-1

(2)

Assumption 6. The transaction rate and the dropout probability vary independently across customers.
Note that the first three assumptions are identical to the corresponding assumptions of the Pareto/NBD model; the difference lies in the assumptions regarding the nature of the death process.
It follows from Assumptions 4 and 5 that the mean lifetime of a randomly chosen customer is

E

ab

a+b-1 = a-1

(3)

and the probability that she died by t is

P t a b

=

1-

B

a

b B

+ a

t/ b

(4)

The Pareto/NBD assumes that individual lifetimes follow an exponential distribution (in place of Assumption 4) and that heterogeneity in the underlying death rate follows a gamma distribution with shape parameter s and scale parameter (in place of Assumption 5). This implies that, for a randomly chosen customer,

E s = s - 1 and

(5)

s

P t s =1- +t

(6)

On the face of it, these two models for the under-

lying death process seem quite different: in the PDO

model a customer can die only at fixed points in time,

whereas in the Pareto/NBD model a customer can die

at any point in time. However, one can see that as

(in the PDO model) becomes smaller and smaller,

the points in time when a customer can die come

closer and closer. Extending this argument, as we let

approach zero, the customer can die at any point of

time. The geometric "discrete" process then becomes

an exponential "continuous" process. (We could think

of the customers as continually flipping their coins to

decide whether to drop out or not.) We can begin to

see how the PDO model nests the Pareto/NBD as a

special case.

Consider a customer who made x transactions in

the interval 0 T , with the transactions occurring

at t1 t2

tx; by definition, tx = 0 when x = 0. We

define K1 = tx/ and K2 = T / . Since tx is the time

of the last recorded transaction, the customer must

have been alive at time K1 , which implies that the customer definitely survived the first K1 opportunities to die. Because the customer was observed until

time T , K2 is the total number of opportunities the customer had to die (out of which she surely did

not die in the first K1 opportunities). The meanings of, and relationships between, K1 and K2 will become clearer in the derivation below.

When K1 = K2, we have

0

t1 ×

tx T
...×

2

K1

(K2 + 1)

K2

The fact that a purchase occurred at tx implies the customer must have been alive at K1 , which occurs with probability 1 - K1 . Since K1 = K2, the customer

Jerath, Fader, and Hardie: New Perspectives on Customer "Death" Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

869

must still be alive at T . Given the model assumptions, the likelihood function for this case is

L

t1

tx T

= e- t1 e- t2-t1 · · · e e - tx-tx-1 - T -tx 1 - K2

= xe- T 1 - K2

When K1 < K2, we have

0

t1

tx

×

×

2

K1 (K1 + 1)

T K2 (K2 + 1)

As before, the fact that a purchase occurred at tx implies the customer must have been alive at K1 . There are, however, a number of possible explanations for the lack of purchasing in the remaining interval tx T :
· The customer died at K1 + 1 , having made no purchase in the interval tx K1 + 1 , with likelihood function
xe- K1+1 1 - K1
· The customer died at K1 + 2 , having made no purchase in the interval tx K1 + 2 , with likelihood function
xe- K1+2 1 - K1+1
· The customer died at K1 + 3 · The customer died at K2 , having made no purchase in the interval tx K2 , with likelihood function
xe- K2 1 - K2-1

· The customer did not die at K2 and made no purchase in the interval tx T , with likelihood function
xe- T 1 - K2

Note that in both cases (K1 = K2, K1 < K2), information on when each of the x transactions occurred is not

required; we can replace t1

tx T with (x tx T ). In

other words, tx and x are sufficient summaries of a

customer's transaction history. (Using direct market-

ing terminology, tx is recency and x is frequency.2) Combining these two cases, we see that the

individual-level likelihood function is

L

x tx T

= xe- T 1 -

T/
+ T / > tx/

T / - tx /

·

xe- tx/ +j 1 - tx/ +j-1 (7)

j =1

2 If x = 0, then tx = 0. Note that this measure of recency differs from that normally used by the direct marketing community, who measure recency as the time from the last observed transaction to the end of the observation period (i.e., T - tx).

Taking the expectation of (7) over the distributions of and , (1) and (2), results in the following expression for the likelihood function for a randomly chosen customer with purchase history (x tx T ):

Lr a b

1

=

L

00

r+x r

=

r

x tx T

x tx T f r f

1 r+x B a b + T /

+T

Ba b

abd d + T / > tx/

T / - tx /
·
j =1

1

r +x

+ tx/ + j

B a + 1 b + tx/ + j - 1

·

Ba b

(8)

The five model parameters (r a b and ) can be estimated via the method of maximum likelihood in the following manner. Suppose we have a sample of I customers, where customer i had xi transactions in the interval 0 Ti , with the last transaction occurring at txi . The sample log-likelihood function is given by
I
LL r a b = ln L r a b xi txi Ti (9)
i=1
We find the maximum of this function using a line search for coupled with standard optimization methods for the other four parameters.
In Appendix A, we show that as  0, (8) becomes the likelihood function associated with the Pareto/ NBD model. As  , T / = 0 and T / > tx/ = 0, in which case (8) collapses to

r+x r r

1

r +x

+T

which is simply the timing-model analog of the basic NBD model (Gupta and Morrison 1991). (Strictly speaking, the PDO model collapses to the NBD whenever > max Ti i = 1 I .)
Following Schmittlein et al. (1987), three quantities of managerial interest in a customer-base analysis exercise are as follows.
· The expected number of transactions in a time interval of length t is given by

EXt r a b

rt B a b + t/

=

Ba b

r +

t/

B j

a+1

b+j -1

j =1

Ba b

(10)

(This quantity is central to computing the expected transaction volume for the whole customer base over time.)

Jerath, Fader, and Hardie: New Perspectives on Customer "Death"

870

Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

· The probability that a customer with observed behavior x tx T is still alive at time T is given by

P >T r

r +x

=

r

a b x tx T

r

1

r +x

+T

B a b+ T/ · Ba b

L r a b x tx T (11)

· The expected number of transactions in the interval T T + t for a customer with observed behavior x tx T is given by

E X T T +t r a b x tx T

=L r

1

r+x+1 r

a b x tx T ×

r

B a b+ T +t /

·

Bab

t

1

r +x+1

+T

T +t / - T / B a+1 b + T / +j -1

+
j =1

Bab

· T / +j -T

(12)

(See Appendix B for the associated derivations.)

3. Empirical Analysis
We now examine the performance of the PDO model using the CDNOW data set used in Fader et al. (2005a, b) and a grocery purchase data set used in Batislam et al. (2007) (henceforth, the Grocery data set).

3.1. The CDNOW Data Set

This data set tracks 2,357 individuals who made their

first-ever purchases at the CDNOW website in the

first 12 weeks of 1997 and records their repeat pur-

chasing through June 1998. The first 39 weeks of

data are used for model calibration; the remaining

39 weeks of data are used as longitudinal holdout for

model validation. Fitting the Pareto/NBD model to

these data yields a log-likelihood of -9,595.0; fitting

the NBD model yields a log-likelihood of -9,763.7.

Clearly, the Pareto/NBD model does much better

than the NBD model while using only two extra

parameters (likelihood ratio test

2 2

=

337

4,

p

<

0

001).

Our focus, however, is on the performance of the PDO

model. Is its fit bounded between these Pareto/NBD

and NBD limits, or does it provide a superior fit to

the data?

Varying from 0.01 weeks to 40 weeks (in incre-

ments of 0.001), we find the maximum likelihood esti-

mates of the remaining four model parameters by

maximizing the log-likelihood function given in (9).

The corresponding values of the log-likelihood func-

tion are plotted in Figure 2. This figure shows that the

log-likelihood function is discontinuous in at multi-

ple values of .3 These discontinuities occur as a result

of the discrete nature of the floor functions in (8),

which have as an argument. At certain values of , a

very small increase in causes a large discrete change

in the values of the floor functions (i.e., for a very

small increase in , the value of the floor function can

decrease by one for several cohort members), which

leads to a discontinuity in the sample log-likelihood

function in (9). (More specifically, this occurs when tx is a multiple of .) Despite the presence of disconti-

nuities in the sample log-likelihood function, the fol-

lowing patterns are clearly discernible.

When is very small ( = 0 01 weeks, LL =

-9,595.3), the fit of the PDO model is almost exactly

the same as that of the Pareto/NBD. As increases

from 0.01, the log-likelihood increases from the

Pareto/NBD limit to a maximum value of -9,585.6

at = 3 001, then starts declining toward the much

lower value associated with the NBD.4 As soon as

> 6 weeks, the fit of the PDO model is strictly worse

than that of the Pareto/NBD. When is large (>39

weeks in this empirical setting), the PDO model yields

the same log-likelihood as that of the NBD model.

The PDO model (with = 3 001) provides a sig-

nificant improvement in calibration-period model fit

over the Pareto/NBD (likelihood ratio test

2 1

=

18

8,

p < 0 001). The parameter estimates of the best-fitting

PDO model and the Pareto/NBD model are reported

in Table 1.5 6

To illustrate more clearly the relationship between

the Pareto/NBD, the NBD, and the PDO models with

various values of , we present the parameter esti-

mates and other summary statistics for these models

3 We thank Albert Bemmaor and Nicolas Glady for bringing this point to our attention.
4 We could use an adaptive line search that switches to a finer incremental in the region of the maximum value of . For example, if we switch to an increment of 1e-06 in the region of = 3 001, we find that the optimal value of is 3.000001 with an associated log-likelihood of -9,585.3. (There is no change in the other parameter estimates to two decimal places and no change in any derived quantities of managerial interest, such as forecasts of repeat sales.) This implies the "truly" optimal value of is 3 + , where  0+. For the sake of simplicity, we stay with the nonadaptive line search with an increment of 0.001 for the analyses presented in this paper.
5 Note that the log-likelihood function for the PDO model is discontinuous around = 3 001 (where it attains its maximum). The standard errors that we report here are obtained by local smoothing of this function in the neighborhood of = 3 001 (Barnett 1966, Daniels 1961). Specifically, we report the values provided by the fmincon function in Matlab, which uses quadratic local smoothing. Other methods, such as bootstrap or jackknife, may also be used to obtain standard errors.
6 The NBD parameter estimates are r^ = 0 38 and ^ = 12 07.

Jerath, Fader, and Hardie: New Perspectives on Customer "Death" Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

871

Figure 2

Plot of the PDO Model Log-Likelihood for the CDNOW Data Set as a Function of the Period Length Parameter

­9,550

­9,585

Log-likelihood Log-likelihood

­9,600 ­9,650 ­9,700 ­9,750

­9,595 ­9,605 ­9,615

­9,800 0

­9,625

10

20

30

40

0

2

4

6

8

10

Note. The right-hand plot presents a "zoomed-in" view for small values of .

in Table 2. Note how the parameters of the PDO model tend toward those of the Pareto/NBD model as  0 (a  s, b  ). This is in accordance with the pattern predicted theoretically in Appendix A.
Beyond the raw parameter estimates, we also see an interesting range of values for two summary statistics of the underlying behavioral characteristics--namely, the mean transaction rate and the median lifetime.

Table 1

Parameter Estimates and Standard Errors for the PDO and Pareto/NBD Models for the CDNOW Data Set

PDO

Pareto/NBD

Estimate

Std. error

Estimate

Std. error

r

0.52

10.40

a

0.43

b

2.61

3.001

s

LL

-9,585.6

0 008 0 008 0 015 0 002 0 002

0.55 10.58
0.61 11.67 -9,595.0

0 026 0 632
0 025 0 307

Table 2

Estimation Results for the CDNOW Data Set for the Pareto/NBD Model = 0 , the NBD Model  and the PDO Model for Various Values of

Transaction

Death

r

aa

ba

LL

E

Median( )

(0) 0 55 10 58 0 61 11 67 -9 595 0 0 052 25 0

0.010 0 55 10 58 0 61 1 167 41 -9 595 3 0 052 25 0

0.100 0 55 10 57 0 60 115 29 -9 595 5 0 052 25 0

1.001 0 54 10 50 0 56 10 90 -9 589 7 0 051 26 5

2.001 0 52 10 16 0 53 5 20 -9 588 3 0 051 26 5

3.001 0 52 10 40 0 43 2 61 -9 585 6 0 050 27 8

4.001 0 50 10 45 0 42 2 02 -9 594 3 0 048 29 8

5.001 0 48 11 26 0 46 2 03 -9 599 2 0 043 30 8

10.001 0 45 10 49 0 26 0 62 -9 620 0 0 043 45 0

20.001 0 40 11 18 0 63 1 51 -9 703 5 0 036 53 8

( ) 0 39 12 07 --

-- -9 763 7 0 032

--

as and in the case of the Pareto/NBD model ( = 0).

First, comparing the two extreme models, we expect that under the Pareto/NBD, we would have shorter lifetimes and therefore higher average transaction rates when compared with the NBD. Pursuing this logic further, it follows that increases in would be associated with declining average transaction rates and increasing median lifetimes. What is not known, however, is how quickly these statistics will change with and whether the rates of change are similar or different when we compare them. The data in Table 2 confirm the expected directional changes for these two statistics as a function of , but they also reveal some differences. As rises from 0 (i.e., Pareto/NBD model) to 3.001, the mean transaction rate falls by about 5%, but the median lifetime rises by about 10%. These differences are not dramatic, but they suggest that the estimated death rates, rather than the mean transaction rates, are more sensitive to changes in .
Because the reduction in transaction rate is smaller than the increase in lifetime, the best-fitting PDO model generates a slightly higher estimate of total repeat sales over time than that produced by the Pareto/NBD model. But is this good or bad? As rises from 0 (i.e., Pareto/NBD model) to 3.001, the mean transaction rate falls by about 5%, but the median lifetime rises by about 10%. To examine this we create total repeat sales forecasts for each of the specifications reported in Table 2. In Table 3 we report the mean absolute percentage error (MAPE) numbers for both cumulative total repeat sales and weekly total repeat sales over weeks 40­78.
Looking at the cumulative MAPE numbers, we see that all of the PDO models with a finite period length forecast the cumulative sales trajectory extremely well; it is hard to discern meaningful differences in a plot of these curves. In contrast, when we look at errors on an incremental (week-by-week) basis, there are greater deviations (as would be expected). Overall, however, there is strong empirical support for

Jerath, Fader, and Hardie: New Perspectives on Customer "Death"

872

Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

Table 3
(0) 0.010 0.100 1.001 2.001 3.001 4.001 5.001 10.001 20.001 ()

Measures of Model Forecasting Performance for the Pareto/NBD Model = 0 , the NBD Model  and the PDO Model (for Various Values of )

MAPE (Weeks 40­78)

Cumulative (%)

Weekly (%)

1 35 1 35 1 34 1 14 1 09 0 85 0 85 0 88 0 70 0 92 10 37

20 89 20 89 20 53 20 13 19 81 19 06 19 06 19 33 19 18 19 25 36 22

the performance of the PDO model (particularly with = 3 001) as a worthy alternative to the Pareto/NBD. Do these results prove that customers are actually
"flipping their coins" every three weeks? Of course not; however, they do suggest that there is room for improvement in modeling the death process beyond the starting point established by the Pareto/NBD, and they provide some reasonable evidence to support the general idea of the discrete-time "story" being told here. The consistency of these results and their superiority to a very strong benchmark (represented by the Pareto/NBD) are hard to deny.
3.2. The Grocery Data Set Batislam et al. (2007) used a data set covering 5,479 individuals at a Turkish grocery store who made their first-ever purchases between August 2001 and October 2001, recording their repeat purchasing through April 2003. For every individual, we have data on the recency and frequency of repeat purchasing and the length of time for which this individual was observed. To make our study consistent with that of Batislam et al. (2007), we use the first 78 weeks for calibration and the last 13 weeks as longitudinal holdout for model validation.
Fitting the Pareto/NBD model to these data yields a log-likelihood of -67,925.8, and fitting the NBD model yields -71,000.5. Fitting the PDO models by varying from 0.01 weeks to 80 weeks, we confirm the pattern we observed for the CDNOW data set-- when is very small (i.e., = 0 01 weeks), the fit of the PDO model is identical to that of the Pareto/NBD; when is large (>78 weeks in this empirical setting), the PDO model yields the same log-likelihood as that of the NBD model. The values of the log-likelihood function as varies from 0.01 to 10 weeks are plotted in Figure 3. (This is the equivalent of the "zoomedin" right-hand plot in Figure 2.) Note that, as in the

Figure 3

Plot of the PDO Model Log-Likelihood for the Grocery Data Set as a Function of the Period Length Parameter

­ 67,700

­ 67,800

­ 67,900

Log-likelihood

­ 68,000

­ 68,100

­ 68,200

­ 68,300

­ 68,400

0

2

4

6

8

10

case of the CDNOW data set, the log-likelihood func-

tion for the Grocery data set is discontinuous at mul-

tiple values of . The maximum log-likelihood value

is achieved when = 1 001 and is -67,757.3. Com-

pared with the Pareto/NBD model, this is a highly

significant improvement in model fit at the cost of

just one additional parameter (likelihood ratio test

2 1

=

337,

p

<

0

001).

In

Table

4,

we

present

the

param-

eter estimates of the best-fitting PDO model and the

Pareto/NBD model.7

As expected, we also observe exactly the same pat-

terns as in Table 2 for the parameter estimates, mean

underlying transaction rates, and median lifetimes for

the different PDO models as varies, and we observe

the same qualitative relationships between these mod-

els and the Pareto/NBD model. For instance, for the

best-fitting PDO model, the mean underlying trans-

action rate is 0 11 per week and the median life-

time is 45 2 weeks; for the Pareto/NBD model, the

mean underlying transaction rate is the same (0 11 per

week) and the median lifetime is smaller (41 8 weeks).

Furthermore, for the 13-week holdout period also, we

observe similar patterns as in Table 3. For the PDO

( = 1 001) model, the cumulative MAPE is 0 9% and

the weekly MAPE is 3 6%; for the Pareto/NBD model,

the cumulative MAPE is 0 5% and the weekly MAPE

is 3 7%.

To summarize, the best-fitting PDO model per-

forms significantly better than the Pareto/NBD model

in terms of in-sample fit for the Grocery data set,

and we observe similar relationships between the

Pareto/NBD, NBD, and various PDO models in this

data set as we did in the CDNOW data set.

3.3. Comparison with the BG/NBD Model A natural question that arises is, what about the original BG/NBD model (with "coin flips" tied to transactions instead of occurring periodically in calendar

7 The NBD parameter estimates are r^ = 0 31 and ^ = 4 86.

Jerath, Fader, and Hardie: New Perspectives on Customer "Death" Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

873

Table 4

Parameter Estimates and Standard Errors for the PDO and Pareto/NBD Models for the Grocery Data Set

PDO

Pareto/NBD

Estimate

Std. error

Estimate

Std. error

r

0 46

4 38

a

0 62

b

22 19

1 001

s

LL

-67,757.3

0 001 0 019 0 004 0 011 0 000

0 48 4 38
0 57 17 64 -67,925.8

0 001 0 014
0 002 0 031

time)? The answer is quite interesting. In terms of insample fit, the BG/NBD performs at least as well as all of the PDO models for the CDNOW data set; its log-likelihood value of -9,582.4, as reported in Fader et al. (2005a), is slightly better than that of the PDO model with = 3 001 (and therefore substantially better than that of the regular Pareto/NBD). However, for the Grocery data set, the BG/NBD model (LL = -68 007 0) significantly underperforms both the PDO model and the Pareto/NBD model.8 In terms of out-of-sample performance on the summary statistics shown in Table 3, the BG/NBD consistently performs slightly worse than the PDO model--for the CDNOW data set, the BG/NBD model's cumulative MAPE is 2.6% and weekly MAPE is 19.4% (both slightly worse), and for the Grocery data set, the BG/NBD model's cumulative MAPE is 8.8% (much worse) and weekly MAPE is 4.0% (slightly worse). Overall, these fit statistics offer mixed evidence about the superiority of the PDO model vis-à-vis the BG/NBD, and none of it is particularly dramatic.
Further insight into the three models can be obtained by comparing interferences we may draw concerning underlying buyer behavior. In particular, we compare the estimates for the mean transaction rate and the median lifetime with uncertainty in the maximum-likelihood (ML) estimates taken into account.9
Figure 4 plots the estimates for the mean transaction rate with uncertainty in the ML estimates taken into account. For both data sets, there are notable differences in the mean purchasing rates; a randomly
8 The BG/NBD model parameter estimates, along with the standard errors in parentheses, are r^ = 0 24 0 013 , ^ = 4 41 0 366 , a^ = 0 79 0 189 , and b^ = 2 43 0 695 for the CDNOW data set; and r^ = 0 28 0 004 , ^ = 2 34 0 008 , a^ = 0 40 0 022 , and b^ = 2 09 0 178 for the Grocery data set.
9 To account for uncertainty in the estimates, we take 1,000 draws of the relevant parameters from a multivariate normal distribution, where the means are the ML estimates of the relevant parameters and the covariance matrix is given by the inverse of the Hessian (to account for the correlations between parameter estimates).

Figure 4
500 400

Expected (Latent) Transaction Rate for a Randomly Chosen Customer for the CDNOW and Grocery Data Sets, Accounting for Uncertainty in the ML Estimates, for the Best-Fitting PDO, Pareto/NBD and BG/NBD Models
(a) CDNOW
PDO Pareto/NBD BG/NBD

f (E())

300

200

100

f (E())

0 0.040
1,400 1,200 1,000
800 600 400 200
0 0.100

0.045

0.050

0.055 E ()

0.060

(b) Grocery

0.065 0.070
PDO Pareto/NBD BG/NBD

0.105

0.110 E()

0.115

0.120

chosen customer purchases slower (while alive) under the PDO model compared to the Pareto/NBD model and purchases slower (while alive) under the Pareto/NBD model compared to the BG/NBD model. (We note that the estimates for these quantities are sharper for the Grocery data set than the CDNOW data set because in the former we have data for almost twice the number of individuals compared with the latter.)
Noting that the BG/NBD model probability of a randomly chosen customer having died by t is given by

r

t

P  t = 1 - + t 2F1 r b a + b + t

(13)

where 2F1 · is the Gaussian hypergeometric function, we can compute the median lifetime for all three models with uncertainty in the ML estimates taken into account--see Figure 5 for the associated plots.
In both empirical settings, there is a slight (but systematic) difference in the median lifetimes as implied by the PDO and Pareto/NBD models, with the PDO model predicting that a randomly chosen customer in the cohort lives longer; however, the results for the

Jerath, Fader, and Hardie: New Perspectives on Customer "Death"

874

Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

Figure 5

Median (Latent) Lifetime for a Randomly Chosen Customer for the CDNOW and Grocery Data Sets, Accounting for Uncertainty in the ML Estimates, for the Best-Fitting PDO, Pareto/NBD, and BG/NBD Models

0.25 PDO Pareto/NBD
0.20

(a) CDNOW 0.0035

BG/NBD

0.0025

0.15

0.10

0.0015

f (Median())

f (Median())

0.05

0.00

10

15

20

25

30

35

40

Median()

0.0005
0 200

(b) Grocery

1.4

PDO

0.004

Pareto/NBD 1.2

0.003 1.0

f (Median())

0.8 0.002
0.6

0.4 0.001
0.2

0.0

0

40

42

44

46

48

400

Median()

400

600

800

Median()

1,000

BG/NBD

600

800

1,000

Median()

1,200

f (Median())

BG/NBD model cast a dubious light on its validity-- even when its overall fit is superior. Specifically, we note that, for both data sets, the median lifetimes as implied by the BG/NBD are so vastly different than those of the two former models that they cannot be plotted on the same scale.
Compared with the Pareto/NBD model, the PDO model predicts (in these empirical settings) that a randomly chosen customer in the cohort lives longer but purchases slower while alive. Under the BG/NBD model, a randomly chosen customer not only lives much longer but also purchases at a slightly higher rate. How do we reconcile this with the finding that the BG/NBD underestimates cumulative repeat sales when compared to the Pareto/NBD model (Batislam et al. 2007, Fader et al. 2005a)? In contrast to the cumulative death probability for the PDO and Pareto/NBD models, (4) and (6), respectively, the cumulative death probability for the BG/NBD model,

(13), is a function of the parameters of the distribution that characterizes heterogeneity in buying rate while alive. This follows from the fact that death can only follow a purchase. Although the mean of the gamma heterogeneity distribution is highest for the BG/NBD model for both data sets, it is also the most heterogwehniecohuesq(uaaslsin1d/icarte).dTbhyisthpeoocloeoffficciuesnttomofervsarwiaittihona, very low buying rate means that their opportunities for death occur very infrequently, which results in very long (unobserved) lifetimes.
These questionable results for the BG/NBD highlight the practical implications of the death process associated with the class of buy-till-you-die models; assessing measures of model fit is not sufficient to judge the suitability of a model for inferential purposes. As more researchers and managers make managerial judgments that directly relate to the death process (Gopinath et al. 2009; Reinartz

Jerath, Fader, and Hardie: New Perspectives on Customer "Death" Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

875

and Kumar 2000, 2003; Schweidel and Knox 2010; Wübben and Wangenheim 2008), the theoretical benefits of the PDO framework become much more tangible. The BG/NBD has no direct connection to the Pareto/NBD, and there is no way to equate the parameters across these different specifications. These conceptual benefits help demonstrate the value of the PDO framework, especially for researchers with a focal interest in the nature of the death process.

4. Heterogeneity in
In the previous sections, we have treated the parameter as homogeneous for all customers; in reality, however, the nature of the period length is likely to vary across them. In this section, we allow for heterogeneity in . Specifically, we assume that varies across customers according to a gamma distribution with pdf

m m-1e-

f m=

m

(14)

(Using other heterogeneity distributions, such as a log-normal distribution or a normal distribution truncated below at zero, yields similar results.)
Under this specification, the individual-level process is the same as before, and the likelihood function for a randomly chosen customer is obtained by taking the expectation of (8) over the distribution of , i.e., evaluating the integral

Lr a b f m d
0
As this does not have an algebraic solution, we turn to Markov chain Monte Carlo (MCMC) methods for estimating this heterogeneous PDO (henceforth HPDO) model; see Appendix C for details.
We estimate the HPDO model on both data sets. Our inferences are based on 50,000 iterations, following a burn-in of 20,000 iterations. The resulting

Table 5

Parameter Estimates for the HPDO Model for the CDNOW and Grocery Data Sets

CDNOW

Grocery

Posterior mean

95% interval

Posterior mean

95% interval

r

0 41

11 74

a

0 20

b

2 75

m

1 47

0 12

0 408 0 413 11 647 11 833 0 194 0 206 2 648 2 852 1 463 1 478 0 118 0 123

0 35 4 55 0 54 10 54 1 42 0 21

0 349 0 351 4 529 4 571 0 535 0 545 10 354 10 726 1 416 1 424 0 207 0 214

parameter estimates after the Markov chains converge are presented in Table 5. (The associated logmarginal density numbers, calculated using the harmonic mean of the likelihoods across iterations (see Newton and Raftery 1994), are -8,577.1 and -63,746.2 for the CDNOW and Grocery data sets, respectively.)
Figure 6 shows the distribution of for both data sets. Clearly, there is significant heterogeneity in
in both data sets. Note that the expected value of is larger for the CDNOW data set compared with the Grocery data set; this is in line with the value of for the best-fitting PDO model (i.e., without heterogeneity in ) being larger for the CDNOW data set compared to the Grocery data set. However, although the HPDO model offers new insights into the dropout process and a large improvement in in-sample fit, it performs slightly worse in terms of out-of-sample predictions than the PDO models without heterogeneity in . For the CDNOW data set, for weeks 40­78, the cumulative MAPE is 1 92% and the weekly MAPE is 20 55%. For the Grocery data set, for weeks 78­91, the cumulative MAPE is 1 5% and the weekly MAPE is 8 1%. Furthermore, using simulated data for various "HPDO worlds," we found that the HPDO model is unable to do a satisfactory job of recovering the true individual-level period lengths, which we conjecture is because the individual-level likelihood function has floor functions that make it discontinuous in . Similar simulations for the basic PDO model

Figure 6

Histogram of Posterior Draws of Across Customers from One Iteration After Convergence for the CDNOW Data Set (Left) and the Grocery Data Set (Right)

150

450

100

300

Frequency Frequency

50

150

0

0

10

20

30

40

50

0

0

10

20

30

40

50

Jerath, Fader, and Hardie: New Perspectives on Customer "Death"

876

Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

covering a wide variety of purchasing characteristics in the cohorts show that, in contrast to the HPDO model, it is able to recover its original parameters with good accuracy in spite of the discontinuity issues that we discussed in §3. (In the case of the basic PDO model, we are able to conduct a line search to find the optimal value of for the cohort.) For these reasons, the simpler PDO model may be the preferred alternative. Nevertheless, we believe that the HPDO model is a worthwhile extension to consider and might offer value to future researchers, particularly if they want to test hypotheses about how the nature of the dropout process varies across customers (perhaps related to customer characteristics or contextual factors).
5. Discussion and Conclusions
We have proposed the PDO model as a new way to better understand and capture the death process associated with buy-till-you-die type models that are frequently used to model customer buying behavior in noncontractual settings. We demonstrated (both analytically and empirically) that the PDO model nests both the Pareto/NBD and the traditional nodeath NBD as special cases, and we found strong evidence that customers behave as if their death process is somewhere in between these two extremes. Because the PDO model has a more flexible death process, it widens the scope of what we can infer about the nature of the customer dropout process when compared to the Pareto/NBD model. Because the purchase process is estimated jointly with the death process, we can also expect to see differences in inferences for the quantities related to the purchase process. In accordance with these insights, we found that the PDO model can indeed offer different estimates for some important characteristics of purchase and death dynamics in a cohort--for instance, for both the data sets that we analyzed, we found that the average customer lives longer but purchases slower in the PDO model than in the Pareto/NBD model.
Although this paper questions (and improves upon) one aspect of the original Pareto/NBD paradigm, it does not necessarily mean that the Pareto/NBD itself is obsolete and should be avoided. We continue to encourage using the Pareto/NBD model when the manager's primary goal is forecasting purchases, as opposed to a principal focus on the death process, per se. Although in our data sets the best-fitting PDO models (and the HPDO model) offer consistent and significant improvements in the calibration sample, the improvements in predictions for the holdout period are not especially dramatic. On the other hand, when inferences about customer dropout are central to the manager's goals, the PDO framework deserves her attention.

This paper has focused on the underlying structure of the death process in the buy-till-you-die models of buyer behavior in noncontractual settings, as illustrated in Figure 1. All the models assume that an individual customer's unobserved (and unobservable) lifetime is characterized by a memoryless process (i.e., an exponential or geometric distribution) and that buying behavior while alive can be characterized by the Poisson distribution coupled with gamma heterogeneity (i.e., the NBD). Staying within the buytill-you-die paradigm, there are obvious extensions. We can replace the memoryless lifetime distribution (associated with any of the three cells in Figure 1) with one that exhibits some form of duration dependence. For instance, if we find that the Pareto/NBD is underpredicting repeat sales or overpredicting the number of zero repeat buyers, or both, we could replace the exponential lifetime distribution with a Weibull (or some other distribution with a more flexible hazard function that has the ability to "slow down" the death process). We can also relax the assumption of a memoryless interpurchase distribution associated with the NBD. For example, the NBD can be replaced by the CNBD (Chatfield and Goodhardt 1973, Schmittlein and Morrison 1983), as in Platzer's (2008) CBG/CNBD-k model and the work of Schweidel and Knox (2010).
The emergence of simulation-based estimation methods for the Pareto/NBD model (Abe 2009, Ma and Liu 2007, Singh et al. 2009) means that it is now much easier for the researcher to tinker with the basic "building blocks" of the model, i.e., the ability to utilize other probability distributions instead of those used by the early researchers in this area. Although this kind of flexibility seems like a welcome addition to the modeler's toolkit, it may create an overly complex model that lacks a meaningful "as-if" story. We feel that a more reflective approach to extending the model, such as stepping back and questioning the implicit assumption that "death can occur at any time," may result in better performance (particularly in a holdout period) as well as improved diagnostics (such as the nature of the death process).
A logical extension of our hierarchical Bayesian estimation procedure for the HPDO model would be the use of covariates to help explain how the death process varies across customers. Several researchers have explored such extensions to the Pareto/NBD model using time-invariant covariates (e.g., Abe 2009, Fader and Hardie 2007) and time-varying covariates (e.g., Schweidel and Knox 2010). This could help managers manage customer attrition in an effective manner. These issues, however, go beyond the PDO model proposed here (and may not offer substantial benefits to justify their additional complexity). Before rushing ahead with these potential improvements, we

Jerath, Fader, and Hardie: New Perspectives on Customer "Death" Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

877

encourage researchers to contemplate the basic PDO model and take advantage of its desirable theoretical properties.

Acknowledgments The authors thank Emine Batislam, Meltem Denizel, and Alpay Filiztekin for making the Grocery data set available and Albert Bemmaor, Nicolas Glady, and Marcel Goic´ for helpful discussions. The first author acknowledges the support of the i-Lab at Carnegie Mellon University, the second author acknowledges the support of the Wharton Customer Analytics Initiative, and the third author acknowledges the support of the London Business School Centre for Marketing.

Appendix A. The Pareto/NBD as a Limiting Case In this section we show that the PDO model likelihood function approaches that of the Pareto/NBD model as  0.
The individual-level likelihood function for the Pareto/ NBD model is (Fader and Hardie 2005):

x

x+1

L

x tx T =

e- + tx +

e- + T

+

+

Assuming heterogeneity in and is distributed gamma with parameters (r ) and (s ), respectively, it follows that the likelihood function for a randomly chosen customer is found by solving

Lr s
=
00

x tx T
x
e- + tx +

x+1

+

e- + T f r f s d d (A1)

+

Our proof is based on showing that

1

lim

L

0 0 0

x tx T f r f a b d d

is identical to (A1) (i.e., lim 0 L r a b  L r s ). This proof will make use of the following results:

lim 1 - 0

T / = e- T

(A2)

e lim

- 1-

0

=+

(A3)

lim s + /

0

/

s

s

=

(A4)

(We note that (A2) is a standard result, (A3) results from the application of L'Hôpital's rule, and (A4) follows from Abramowitz and Stegun 1972, Equation 6.1.46.)
Noting that

T / - tx / j =1

x e- tx / +j

1 - tx/ +j-1

= x e- tx/ +1 = x e- tx/ +1

1-

T / - tx / -1

tx /

e- 1 -

l

l=0

1 - tx/ 1 - e- 1 -

T / - tx /

1 - e- 1 -

x e- tx /

1 - tx/

xe- T /

1- T/

=

e - 1-

-

e - 1-

we can rewrite the individual-level likelihood function (7) as

L

x tx T

= xe- T 1 -

T/
+ T / > tx /

x e- tx /

1 - tx/

e - 1-

xe- T /

1- T/

-

e - 1-

Let = , which implies d = d . (When = 0 = 0; similarly, when = 1 = 1/ .) Also let a = s and b = / . It follows that PDO likelihood function for a randomly chosen customer, L r a b , can be written as

Lr s

1/

=

L

00

×

s-1 1 -

= 1 + T / > tx/

x tx T f r

/ -1 s + / s/
2- 3

dd (A5)

where

1/

1=

0

0

s+ ·s

xe- T /
f /

s s-1 1 - r dd

T / + / -1

1/

2=

0

0

xe- tx/ s s 1 - e - 1-

tx / + / -1

·

s+ / s/

f

r

dd

1/

3=

0

0

xe- T / s s 1 - e - 1-

·

s+ / f s/

r

dd

T / + / -1

(Note that the only difference between sus T .)
We now take the limit of (A5) as T / > tx/ = 1 as  0, we have

2 and 3 is tx ver 0. Noting that

lim L r s 0

= lim 0

1

+

lim 0

2

-

lim 0

3

(A6)

Noting tx/ (A2)­(A4),

tx/ and T /

T / as  0, and using

lim 0

1

= lim 0

0

1/
xe- T s s-1 1 -
0

·

s+ s

/ /

f

r

dd

T / + / -1

=
0

lim 0 1/

lim

0

0

xe- T s s-1 1 -

T / + / -1

·

s+ / s/

f

r

dd

=
00

x e- T s s-1e- s

+T
f

r

dd

=

xe- + T f r f s d d

00

(A7)

Jerath, Fader, and Hardie: New Perspectives on Customer "Death"

878

Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

and

lim 0

2

=

lim 0

0

1/ 0

xe- tx/ s s 1 - e - 1-

tx / + / -1

·

s+ / s/

f

r

dd

=
0

lim 0 1/

lim

0

0

xe- tx/ s s 1 - e - 1-

tx / + / -1

·

s+ / f s/

r

dd

x e- tx s s e- +tx

= 00 +

s

f r dd

x e- + tx

=

f r f s dd

00

+

(A8)

It follows that

x e- + T

lim 0

3= 0

0

f r f s dd +

(A9)

Substituting (A7)­(A9) in (A6) and simplifying gives us

lim L r s 0
=
00
·f r

x

x+1

e- + tx +

e- + T

+

+

f s dd

which is exactly the integral for the Pareto/NBD likelihood function, (A1). Q.E.D.
This proof establishes the equivalence between the likelihoods of observing the same data under the PDO model when  0 and the Pareto/NBD. We use this fact somewhat liberally to "prove" that the two models are equivalent under this special condition (  0). (Using a similar procedure and the same substitutions, it is easy to show that all the expressions for the PDO model--e.g., (10)­(12)--are identical to those of the Pareto/NBD as  0.)

Appendix B. Derivations of Key Results

Derivation of (10). Let the random variable X t denote

the number of transactions occurring in the interval 0 t .

Conditional on , it follows from the assumption of Poisson

purchasing that E X t is simply t if the customer is active

at t, if the customer dies at , 2 if the customer dies

at 2 , 3 if the customer dies at 3 , and t/ if the

customer dies at t/ . Multiplying these quantities by the

probability that the customer dies at 2

gives us

EXt

= t 1-

t/
+

t/
1 - j-1
j =1

Taking the expectation of this over the distributions of and , (1) and (2), gives us the expression in (10).
Derivation of (11). The probability that a customer with purchase history x tx T is alive at time T is simply the probability that she was alive at K2 . Referring back to our derivation of the individual-level likelihood function, (7), the application of the Bayes' theorem gives us

P >T

x

tx

T

xe- T =L

1- x

T/
tx T

(B1)

(We note that if tx/ = T / (i.e., K1 = K2), P > T x tx T = 1.)
By Bayes' theorem, the joint posterior distribution of
and is given by

f

r a b x tx T

L =

x tx T f r f a b

(B2)

L r a b x tx T

Taking the expectation of (B1) over this joint posterior distribution gives us (11).
Derivation of (12). Let the random variable X T T + t denote the number of purchases made in the interval T T + t . We are interested in computing the conditional expectation E X T T + t x tx T , the expected number of purchases in the interval T T + t for a customer with purchase history (x tx T ).
Let us assume the customer is alive at T (i.e., > T ). Conditional on , it follows from the assumption of Poisson purchasing that the expected number of purchases in T T + t is simply t if the customer is active at T + t,
T / + 1 - T if the customer dies at T / + 1 , T / + 2 - T if the customer dies at T / + 2 , ... , and T + t / - T if the customer dies at T + t / . Multiplying these quantities by the probability that the customer dies at T / + 1 , T / + 2 , ... , gives us

E X T T +t

>T

= t 1 - T +t / - T /

T +t / - T /
+
j =1

T / + j - T 1 - j-1 (B3)

Taking the expectation of the product of (B1) and (B3) over the joint posterior distribution of and , (B2), gives us (12).

Appendix C. MCMC Procedure for the

HPDO Model

Customer i with period length i makes her dropout deci-

sion at i 2 i 3 i

Whether the customer dropped out

or not and, if so, when she dropped out, is unobserved. To

aid with the model estimation, we generate these unobserv-

ables using data augmentation (Tanner and Wong 1987).

Specifically, we use the indicator variable Zi (with the real-

ization zi) to denote whether the customer died between

txi and Ti: if the customer is still alive at Ti, Zi = 1; if the

customer died at i i, where i  txi / i + 1

Ti/ i ,

Zi = 0.

Recalling the logic of the derivation of (7), the likelihood

function of Zi = 1, and

customer i is

xi i

e-

i

ii

i 1-

given by

xi i

e-

i Ti

1-

i

Ti / i

if

i i-1 if Zi = 0 (and the customer

died at i i). Therefore,

L i i i xi txi Ti zi i

= e 1 - xi - i ziTi+ 1-zi i i 1-zi

i

i

zi Ti / i + 1-zi i -1 i

The parameters of the heterogeneity distributions for ,
, and specified earlier act as priors for i, i, and i, respectively. Hence, i  gamma(r ), i  beta(a b), and i  gamma(m ). We derive expressions for the conditional densities of the relevant individual-level parameters in the
following manner.

Jerath, Fader, and Hardie: New Perspectives on Customer "Death" Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

879

· The conditional posterior distribution of i is propor-

tional to L i i i xi turn is proportional to

trx+i xiT-i1
i

zi e-

i

i ×f i
+zi Ti + 1-zi

r , which in i i . Therefore,

ir

i xi Ti zi i

 gamma r + xi - 1

+ ziTi + 1 - zi i i

(C1)

· The conditional posterior distribution of i is propor-

tional to L i i i xi txi in turn is proportional to

Ti zi i

a-zi i

1-

× f i a b , which . i b-1+zi Ti / i + 1-zi i -1

Therefore,

i a b i Ti zi i  beta a + 1 - zi b + zi Ti/ i + 1 - zi

i -1

(C2)

· The conditional posterior distribution of i is proportional to L i i i xi txi Ti zi i × f i m , which gives us

f im

i Ti zi i

 e 1 - m-1 - i+ i ziTi+ 1-zi i i i

zi Ti / i + 1-zi i -1 i

(C3)

We can sample from this distribution using MetropolisHastings methods.
· Recalling (B1),

P Zi = 1

i i itxi Ti =

1+

1 Ti / i > txi / i

2

where

(C4)

1 = e- iTi 1 - i Ti/ i

and

Ti / i - txi / i

2=

e- i txi / i +j i i 1 - i txi / i +j-1

j =1

Note that if Ti/ i = txi / i , customer i is definitely alive

at Ti because she did not get a chance to flip her death

coin after her last purchase (which occurred at txi ); as such,

P Zi = 1 · = 1.

· If Zi = 0, then we also generate an integer i 

txi / i + 1

Ti/ i , where txi < i i < Ti is the point in

time at which customer i died. Assuming a (discrete) uni-

form prior on i,

P i = i i i i txi Ti  e- i i i i 1 - i i-1

(C5)

The joint conditional posterior distributions of the population-level parameters are given by

I

fr

 f i r frf

i=1

(C6)

fab

I
 f i a b f af b
i=1

(C7)

fm

I
 f im
i=1

f mf

(C8)

where , , and denote the current vectors of the individual-level parameters. We use fully diffuse hyperpriors for r, , a, b, m, and . (Although these parameters are only allowed to take on positive values, in our case this is

not a problem because the two data sets we use have a large number of individuals in them; i.e., while sampling from the posterior distribution, the data likelihood strongly dominates the prior specification.) Metropolis-Hastings methods are used to sample the pairs r , a b and m .
The resulting MCMC procedure used in the estimation is as follows:

1. Set initial values for r a b m and , as well as for

i i i zi and i  i = 1

I.

2. Iterate until convergence:

(a) For each customer i, sample i, i, and i using (C1), (C2), and (C3), respectively.
(b) For each customer i, generate zi using (C4). If zi = 0, generate i using (C5). (This is the data augmentation step.)
(c) Sample the pairs r , a b , and m using (C6),
(C7), and (C8), respectively.

References
Abe, M. 2009. "Counting your customers" one by one: A hierarchical Bayes extension to the Pareto/NBD model. Marketing Sci. 28(3) 541­553.
Abramowitz, M., I. A. Stegun, eds. 1972. Handbook of Mathematical Functions. Dover Publications, New York.
Barnett, V. D. 1966. Evaluation of the maximum-likelihood estimator where the likelihood equation has multiple roots. Biometrika 53(1/2) 151­165.
Batislam, E. P., M. Denizel, A. Filiztekin. 2007. Empirical validation and comparison of models for customer base analysis. Internat. J. Res. Marketing 24(3) 201­209.
Chatfield, C., G. J. Goodhardt. 1973. A consumer purchasing model with Erlang inter-purchase times. J. Amer. Statist. Assoc. 68(344) 828­835.
Daniels, H. E. 1961. The asymptotic efficiency of a maximum likelihood estimator. Proc. 4th Berkeley Sympos. Math. Statist. Probab., Vol. 1. University of California Press, Berkeley, 151­163.
Ehrenberg, A. S. C. 1959. The pattern of consumer purchases. Appl. Statist. 8(1) 26­41.
Fader, P. S., B. G. S. Hardie. 2005. A note on deriving the Pareto/NBD model and related expressions. Retrieved April 10, 2010, http://brucehardie.com/notes/009/.
Fader, P. S., B. G. S. Hardie. 2007. Incorporating time-invariant covariates into the Pareto/NBD and BG/NBD models. Retrieved April 10, 2010, http://brucehardie.com/notes/019/.
Fader, P. S., B. G. S. Hardie, K. L. Lee. 2005a. "Counting your customers" the easy way: An alternative to the Pareto/NBD model. Marketing Sci. 24(2) 275­284.
Fader, P. S., B. G. S. Hardie, K. L. Lee. 2005b. RFM and CLV: Using iso-value curves for customer base analysis. J. Marketing Res. 42(4) 415­430.
Fader, P. S., B. G. S. Hardie, J. Shang. 2010. Customer-base analysis in a discrete-time noncontractual setting. Marketing Sci. 29(6) 1086­1108.
Gopinath, S., R. Blattberg, E. Malthouse. 2009. Are revived customers as good as new? Working paper, Northwestern University, Evanston, IL. http://ssrn.com/abstract=1356851.
Gupta, S., D. G. Morrison. 1991. Estimating heterogeneity in consumers' purchase rates. Marketing Sci. 10(3) 264­269.
Ma, S.-H., J.-L. Liu. 2007. The MCMC approach for solving the Pareto/NBD model and possible extensions. Proc. 3rd Internat. Conf. Natural Comput. (ICNC 2007), IEEE Computer Society, Washington, DC, 505­512.

Jerath, Fader, and Hardie: New Perspectives on Customer "Death"

880

Marketing Science 30(5), pp. 866­880, © 2011 INFORMS

Morrison, D. G., D. C. Schmittlein. 1988. Generalizing the NBD model for customer purchases: What are the implications and is it worth the effort? J. Bus. Econom. Statist. 6(2) 145­159.
Newton, M. A., A. E. Raftery. 1994. Approximate Bayesian inference with the weighted likelihood bootstrap. J. Roy. Statist. Soc. Ser. B 56(1) 3­48.
Platzer, M. 2008. Stochastic models of noncontractual consumer relationships. Master's thesis, Vienna University of Economics and Business Administration, Vienna.
Reinartz, W., J. V. Kumar. 2000. On the profitability of long-life customers in a noncontractual setting: An empirical investigation and implications for marketing. J. Marketing 64(4) 17­35.
Reinartz, W. J., V. Kumar. 2003. The impact of customer relationship characteristics on profitable lifetime duration. J. Marketing 67(1) 77­99.
Schmittlein, D. C., D. G. Morrison. 1983. Prediction of future random events with the condensed negative binomial distribution. J. Amer. Statist. Assoc. 78(382) 449­456.

Schmittlein, D. C., R. A. Peterson. 1994. Customer base analysis: An industrial purchase process application. Marketing Sci. 13(1) 41­67.
Schmittlein, D. C., D. G. Morrison, R. Colombo. 1987. Counting your customers: Who are they and what will they do next? Management Sci. 33(1) 1­24.
Schweidel, D. A., G. Knox. 2010. Incorporating strategic direct marketing activity into "buy 'til you die" models. Working paper, University of Wisconsin­Madison, Madison. http://ssrn .com/abstract=1670060.
Singh, S. S., S. Borle, D. C. Jain. 2009. A generalized framework for estimating customer lifetime value when customer lifetimes are not observed. Quant. Marketing Econom. 7(2) 181­205.
Tanner, M. A., W. H. Wong. 1987. The calculation of posterior distributions by data augmentation. J. Amer. Statist. Assoc. 82(398) 528­540.
Wübben, M., F. v. Wangenheim. 2008. Instant customer base analysis: Managerial heuristics often "get it right." J. Marketing 72(3) 82­93.

