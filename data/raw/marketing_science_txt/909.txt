Vol. 24, No. 2, Spring 2005, pp. 285­293 issn 0732-2399 eissn 1526-548X 05 2402 0285

informs ®
doi 10.1287/mksc.1040.0088 © 2005 INFORMS

Dynamic Models Incorporating Individual Heterogeneity: Utility Evolution in Conjoint Analysis

John C. Liechty
Marketing Department of Statistics Department, Smeal College of Business, 701 M BAB, Pennsylvania State University, University Park, Pennsylvania 16802, jcl112@psu.edu
Duncan K. H. Fong
Marketing Department and Statistics Department, Smeal College of Business, 707 G BAB, Pennsylvania State University, University Park, Pennsylvania 16802, i2v@psu.edu
Wayne S. DeSarbo
Marketing Department, Smeal College of Business, 701 D BAB, University Park, Pennsylvania 16802, desarbows@aol.com
It has been shown in the behavioral decision making, marketing research, and psychometric literature that the structure underlying preferences can change during the administration of repeated measurements (e.g., conjoint analysis) and data collection because of effects from learning, fatigue, boredom, and so on. In this research note, we propose a new class of hierarchical dynamic Bayesian models for capturing such dynamic effects in conjoint applications, which extend the standard hierarchical Bayesian random effects and existing dynamic Bayesian models by allowing for individual-level heterogeneity around an aggregate dynamic trend. Using simulated conjoint data, we explore the performance of these new dynamic models, incorporating individual-level heterogeneity across a number of possible types of dynamic effects, and demonstrate the derived benefits versus static models. In addition, we introduce the idea of an unbiased dynamic estimate, and demonstrate that using a counterbalanced design is important from an estimation perspective when parameter dynamics are present.
Key words: heterogeneity; empirical utility functions; dynamic models; Bayesian analysis; conjoint analysis; unbiased dynamic estimates
History: This paper was received November 9, 2001, and was with the authors 21 months for 3 revisions; processed by Michel Wedel.

1. Introduction
One of the standard assumptions in conjoint analysis is that a consumer's utilities remain constant during the course of the conjoint study, an assumption that underlies most normative theories of value maximization (e.g., von Neumann and Morgenstern 1947), which assume that individuals have a global set of utilities that is revealed when elicited. There are a number of reasons why this assumption may not hold in practice. Research of human decision making and judgment strongly suggest that preferences are constructed as opposed to being revealed (see Payne et al. 1992, Slovic 1995), implying that individuals may engage in simplification strategies or they may be learning about their preferences during the course of a preference study. Evolution of preferences may also come about because of fatigue and boredom (e.g., Bijmolt and Wedel 1995) or because individuals adjust to the range of possible levels that are revealed during the course of the study (e.g., Hsee et al. 1999).

The manifestation of these phenomenon has been demonstrated in the revealed/stated preference analysis (conjoint measurement) literature (cf. Luce and Tukey 1964), where there is mention of a "burn-in" period during which subjects evolve a systematic approach to providing preference judgments as they examine attributes and attribute levels (Huber et al. 1992). More significantly, Johnson and Orme (1996) have noticed significant shifts in attribute weights during the course of a single survey for such revealed/stated preference studies. DeSarbo et al. (2004) have documented regime shifts in such conjoint preference/utility functions when estimated during the course of the experiment. DeSarbo et al. (2005) have documented such dynamic effects in fullprofile conjoint analysis, involving a student apartment application using a counterbalanced design with ordinary least squares and empirical Bayes models.
There is evidence that dynamics because of learning effects may be influenced by the initial profile seen by a participant, e.g., studies on order of entry effects

285

Liechty, Fong, and DeSarbo: Dynamic Models Incorporating Individual Heterogeneity

286

Marketing Science 24(2), pp. 285­293, © 2005 INFORMS

(cf. Kardes and Kalyanaram 1992) and initial choices (cf. Muthukrishnan and Kardes 2001) suggest that an initial product profile may provide an anchor for subsequent profiles. The standard approach to reduce or eliminate these types of crossover effects is to counterbalance the experimental design (see Keppel 1991). One of the simplest counterbalance arrangements is a cyclic one, where the set of profiles from a design are rotated for different groups of participants (e.g., participants in group 1 rate profiles 1 2 3 T , participants in group 2 rate profiles T , 1 2 T - 1, and so on). In addition to helping reduce order effects, we demonstrate that counterbalancing plays an important role in obtaining estimates that recover the average of underlying aggregate dynamic preference, which may exist independent of the profile order. While design issues are not the main focus of this paper, we remark that Toubia et al. (2003) have recently proposed and tested new adaptive question design and estimation algorithms for partial-profile conjoint analysis.
A number of dynamic models have been proposed in the marketing literature, e.g., Vakratsas et al. (2004). Some studies and the resulting models address aggregate market behavior (see Wildt and Winer 1983, Dekimpe and Hanssens 1995, Bronnenberg et al. 2000), and others look at market behavior by considering individual-level consumer purchases (see Guadagni and Little 1983, Meyer and Sathi 1985, Allenby and Lenk 1994, Erdem 1996, Paap and Franses 2000). Models of aggregate market behavior explicitly consider heterogeneity across time, but do not typically consider individual-level utilities. Individual-level models are designed to uncover persistence in utility functions with respect to brand (Guadagni and Little 1983) and other marketing mix variables, e.g., Paap and Franses (2000) consider a multinomial probit model, which can distinguish between short-term and long-term effects of different marketing mix variables. Such individual-level models use current and lagged marketing mix information and lagged utility and/or purchase information to uncover persistence effects. They are different from the models proposed here, which allow for both individual and time-specific part-worth utilities, and are well suited for investigating potential part-worth evolution during conjoint studies.
We consider extensions of two different classes of dynamic models: (1) models that are a function of time and (2) dynamic linear models. These models are extended to allow for part-worth utilities that display heterogeneity across both time and individuals. The basic hierarchical Bayesian models assume that heterogeneity exists across individuals, but not across time (e.g., Lenk et al. 1996). Alternatively, dynamic models such as Bayesian dynamic linear

models assume that heterogeneity exists across time but not across individuals (e.g., West and Harrison 1997). The purpose of this research note is threefold: (1) to introduce two new classes of Bayesian dynamic models that accommodate heterogeneity both across time and across individuals; (2) to investigate the diagnostic power of these models for different potential sources of evolution that may occur during a conjoint study; and (3) to demonstrate that counterbalancing the design used in a conjoint study is essential if utility dynamics exist, which are independent of order in which the profiles are shown to the participants.
We proceed with our description of the models and our investigation into their performance in the following manner. We introduce and discuss our newly proposed models in §2. In §3, we report the results of a simulation conjoint study, where we investigate the performance of these models using synthetic data sets that assume different types of dynamics; we also discuss the importance of using a counterbalanced design when dynamics are present. In §4, we conclude and discuss future research in this area.

2. Dynamic Bayesian Models

Incorporating Individual

Heterogeneity

We propose two different classes of dynamic mod-

els that can be used to model rating-based conjoint

data; both classes contain the standard hierarchical

Bayesian random effects model as a special case (e.g.,

Lenk et al. 1996). The hierarchical Bayesian random

effects model assumes that the likelihood function for

a rating yit, given by the ith individual for the tth

product profile Xit, i = 1 n and t = 1 T , is as

follows:

yit = ¯ + i Xit + it

(1)

where

it =d N 0

2 i

,

N

represents

the

normal

dis-

tribution and =d means equal in distribution. The

prior distributions for the individual part-worth devi-

ations are given by i =d N 0 and we assume

conjugate priors for -1

and P identity

amreatsrpixe,ci=fieadn,d

¯

=d =d

WNish=art

n I,

P , where where I is

are specified, and

-2 i

n the =d

Gamma Shape Scale , where Shape and Scale are spec-

ified. Both classes of models that we introduce build

on the standard random effects model by allowing the

aggregate part-worth to vary with respect to time or

yit =

¯ t

+

i Xit +

it

(2)

where we assume the same priors as in the random

effects model with the exception of the prior for the

aggregate part-worth

¯ t

.

The

first

class

of

models

(which we denote as dynamic functional form models)

Liechty, Fong, and DeSarbo: Dynamic Models Incorporating Individual Heterogeneity

Marketing Science 24(2), pp. 285­293, © 2005 INFORMS

287

assumes that the aggregate part-worths follow a functional form with respect to time. The second class of models (which we denote as dynamic linear random effects models) extends the dynamic linear model framework of West and Harrison (1997) by allowing an aggregate part-worth vector to follow a system equation as in a dynamic linear model.
The dynamic functional form models assume that the aggregate part-worth vector follows a quadratic function of time or

¯ t

=

¯0 +

¯ 1

t

+

¯ 2

t2

(3)

where

that

=
j

¯ j

=

N

=
j

jI ,

= 0 (this choice

j = 0 1 2; we have is insignificant if j

assumed is large).

Clearly when 1 = 2 = 0, the quadratic model reduces

to the standard random effects model. To avoid mul-

ticollinearity problems, we rescale and center time

(t = t/T - 1/2 when applying this quadratic model.

Further, if we assume that = 0, then individ-

ual heterogeneity is removed and one is left with

an aggregate, quadratic model with respect to time.

Regardless of whether individual-level heterogeneity

is included, the quadratic model contains the linear

model as a special case (by setting 2 = 0 and can act as an approximation of a more complicated functional

forms (e.g., an exponential model). Given this frame-

work, there is obviously a broad range of functional

form models that could be considered.

For the dynamic linear random effects model, we

assume that the aggregate part-worth dynamics are

given by the system equation

¯ t

=

G

¯ t-1

+

wt

(4)

where wt =d N 0 , -1 =d Wishart n P , n , and

P

are specified, and

¯ 1

=d

N

A1

B1

, we assume that

A1 = 0.

Our major departure from the approach of West

and Harrison (1997) is regarding the treatment of the

matrix G. Because of difficulties in estimation, they

assume that G is known. We assume that G is a ran-

dom diagonal matrix, where the diagonal elements

(indexed by j are normally distributed around 1 or

Gjj =d N 1 2

(5)

where 2 is specified. With respect to interpretation,

if the posterior estimate of Gjj is greater than 1, this implies that, on average, the jth mean part-worth is

becoming more important across time; and, if it is less

than 1 but still positive, then, on average, the mean

part-worth becomes less important across time.

In general, as the matrix G is diagonal, Equation (4)

implies that

¯ t

follows a vector autoregressive pro-

cess of order 1. When 2 = 0, G becomes an identity

matrix and

¯ t

follows a random walk process. If G is

an identity matrix and the variance-covariance matrix of wt is zero, then the model will simplify to the standard random effects model. Finally, if we assume that
= 0, then individual heterogeneity is removed, and one is left with the standard dynamic linear model.
For the sake of completeness, the full conditional densities for the two proposed dynamic models are given in Appendix A. All of these models that we present have standard full conditional densities and are estimated using a Markov chain Monte Carlo (MCMC) algorithm based on the Gibbs sampler (see Gilks et al. 1996 for a general discussion of MCMC methods).
3. The Conjoint Simulation Study
We assessed the performance of the proposed models on synthetic data that were generated from three different potential cognitive processing dynamics: fatigue, learning, and rule simplification. For each of the scenarios, we generated synthetic parameters and data for 108 individuals, where each individual rated 27 profiles (the first 24 profiles were used for calibration and the last 3 were used for holdout validation). To mimic a conjoint setting, we generated a common set of profiles using a 210 fractional factorial design, where each profile consisted of 10 dummy variables and an intercept. In each scenario, every individual had a true part-worth, i, which was perturbed during the course of the study to generate individual and time-specific part-worth values. For the fatigue scenario, we assume that the individual-level partworths used to generate ratings were centered around an individual's true part-worth but had a variance, which was initially small and then increased toward the end of the sequence of profiles. This dynamic mirrors the type of behavior that one would expect from a burn-in scenario, where the variance is large for the initial profiles and then decreases across time. For the learning scenario, the individual-level part-worth used to generate the ratings converges at roughly an exponential rate to the true part-worth and then is centered around the individual's true part-worth with a relatively small variance. The rule simplification scenario reflects a strategy where respondents suddenly determine that an attribute is no longer relevant to their utility function; the part-worth used to generate the ratings is initially centered around the individual's true part-worth with a small variance, and then at a random time the part-worth is centered around zero and has a larger variance that quickly decreases. We used a random scheme to determine whether a part-worth was no longer relevant and, hence, set to zero at some point during the conjoint study, where the probability of being set to zero depended on how close the part-worth was to zero.

Liechty, Fong, and DeSarbo: Dynamic Models Incorporating Individual Heterogeneity

288

Marketing Science 24(2), pp. 285­293, © 2005 INFORMS

This type of sudden change dynamic could also be related to a structural change in the part-worth where an individual suddenly realizes that the range for some of the attribute levels is different than they initially anticipated, resulting in a sudden change in some of the part-worth values. A detailed description of the algorithms used to generate these synthetic data is given in a separate technical appendix (see http://mktsci.pubs.informs.org).
For each scenario, we generated two sets of synthetic data using the same parameters but different counterbalancing approaches. The first data set did not have any counterbalancing (all of the individuals "saw" the profiles in the same order) and the second data set used a cyclic counterbalancing approach (individuals were divided into 27 groups and each group "saw" the profiles in the same order, but with a different initial profile). To clarify, for the cyclic counterbalancing, group 1 "rated" the profiles 1 2 3 27, group two "rated" the profiles 2 3 27 1, and so on. Synthetic ratings were obtained by adding a normal error to the utility resulting from the part-worths and profile.

3.1. Unbiased Dynamic Estimates and

Counterbalancing

To illustrate the impact of counterbalancing from the

perspective of estimation, we briefly need to ini-

tially discuss maximum likelihood estimates (MLE).

This discussion allows us to highlight the origin of

problems that can arise when using static Bayesian

models with vague prior specifications and dynamic

Bayesian models to analyze data from an experi-

mental design that is not counterbalanced. Typically,

a good experimental design and estimation scheme

result in an unbiased estimate, under the assump-

tion that the model parameters are static or constant

across time. If this assumption is in doubt, then it is

reasonable to add a criterion for a good design by

requiring that the unbiased estimate based on that

design is an unbiased dynamic estimate or an estimate

that, on average, equals the average of the underly-

ing dynamic utility. To illustrate, ¯tXit + it and it =d N 0 2 . If

assume

¯ t

=

¯

that yit for all

= t,

then the standard aggregate MLE is an unbiased esti-

mate or E

^¯ MLE

= ¯. However, if

¯ t

are different for

each time t, then there is no guarantee that the stan-

dard aggregate MLE is an unbiased dynamic estimate

or that

E

^¯ MLE

=1 T

t

¯ t

Figure 1 illustrates the difference between the MLE

for noncounterbalanced and counterbalanced data,

by graphically comparing the MLE estimates to the

average--at each point in time--of the actual param-

eter values that were used to generate the synthetic

data; as the learning and rule simplification tend to have similar results, we restricted our attention in this illustration to the fatigue and learning scenarios.
Clearly, as highlighted by the learning scenario estimates, if dynamics are present and counterbalancing is not used, static estimates like the aggregate MLE can be entirely different from the average dynamic. This occurs because the noncounterbalanced design systematically excludes part of the dynamic or weights parts of the dynamic inappropriately. Introducing a simple cyclic counterbalancing approach corrects this by ensuring that every part of the dynamic is evenly represented in the data (see Appendix B for a formal proof that counterbalanced designs will result in unbiased dynamic estimates).
3.2. Conjoint Simulation Results Analyzing the simulation data using the static Bayesian random effects model and the dynamic Bayesian models introduced in §2 yields several interesting results. First, based on our model choice criteria, we find that for these synthetic data sets, accounting for individual-level heterogeneity is relatively more important than accounting for dynamics. Second, we find that when we use noncounterbalanced data, estimates from the static random effects model behave in a fashion similar to the aggregate MLE and they are not representative of the average dynamic; this problem does not tend to occur with counterbalanced data.
Before discussing these results in more details, we describe the study and model choice tools that were used to discriminate between models. We analyzed both the noncounterbalanced and the counterbalanced data sets for all of the scenarios, using a range of Bayesian models: assuming that there was no heterogeneity across time or individuals (the aggregate static model), assuming that there was heterogeneity across individuals but not across time (the static random effects model), assuming that there was heterogeneity across time but not across individuals (aggregate quadratic and aggregate dynamic linear models), and assuming that there was heterogeneity across both individuals and time (random effects quadratic and dynamic linear models). We considered a range of prior values and found that the dynamic models performed best when data dependent priors were used for the dynamic portion of the model, and vague or noninformative priors were used for the remaining model parameters (see Appendix A for exact prior values).
We used log marginal probability and holdout prediction root mean square error (RMSE) to determine model performance, where log marginal probabilities were calculated using the estimation method

Liechty, Fong, and DeSarbo: Dynamic Models Incorporating Individual Heterogeneity

Marketing Science 24(2), pp. 285­293, © 2005 INFORMS

289

Figure 1

MLE Parameter Estimates and Average Parameter Values Fatigue Scenario

7.6

Average Parameter Values

MLE Using Noncounterbalanced Data

MLE Using Counterbalanced Data

7.4

7.2

7.0

0
7 6

5

10

15

20

25

Learning Scenario
Average Parameter Values MLE Using Noncounterbalanced Data MLE Using Counterbalanced Data

5

4

3

0

5

10

15

20

25

Note. The graphs above report estimates and actual values for variable 4, using the noncounterbalanced and counterbalanced data sets from the fatigue and learning scenarios.

provided by Newton and Raftery (1994). We calculated the RMSE for the holdout portion of the data set (the last three observations for each individual) for each sweep of the MCMC sampler resulting in a posterior mean and standard deviation of the holdout RMSE. For the static models, we used the individuallevel parameter value at each sweep of the MCMC sampler to forecast out of sample observations; for the dynamic models, we generated parameter values for the holdout portion of the data set based on the current set of parameters and the model dynamics at each sweep of the MCMC sampler to forecast out of sample data. To assess parameter recovery, we compared the average of the actual parameter value at each point in time with the posterior mean estimate of the average parameter value at each point in time, and then calculated the RMSE between these actual and estimated parameter values.

For all of the synthetic data sets, including heterogeneity across individuals appears to contribute the most to performance improvements in terms of the model choice criteria (see Table 1). In terms of holdout predictions, the quadratic random effects model is comparable to the static random effects model for all of the scenarios and clearly outperforms the latter for the learning scenario. When participants learn during the course of the study and a counterbalancing design is employed, the quadratic and dynamic linear random effects models are comparable in terms of holdout predictions and they are much better than the other models.
The dynamic linear random effects model gives the lowest log marginal probability for every scenario studied in this paper, but it does not always gives the best holdout predictions. This may be indicative of unreliable parameter estimates from the dynamic

Liechty, Fong, and DeSarbo: Dynamic Models Incorporating Individual Heterogeneity

290

Marketing Science 24(2), pp. 285­293, © 2005 INFORMS

Table 1 Predictive Performance of Dynamic and Static Models for Three Synthetic Data Sets: Fatigue, Learning, and Simplification

Noncounterbalanced data sets (profiles were not rotated)

Aggregate models

Random effects models

Data set

Model choice criteria

Static

Quadratic

Dynamic linear

Static

Quadratic

Dynamic linear

Fatigue Learning Simplification

Log marginal probability Holdout RMSE
Log marginal probability Holdout RMSE
Log marginal probability Holdout RMSE

-7 249 27 6 00 0 01
-7 605 12 9 70 0 14
-7 636 63 5 66 0 03

-7 245 71 6 03 0 05
-7 028 12 5 78 0 31
-7 620 37 5 72 0 10

-7 233 61 6 35 0 32
-6 999 77 5 46 0 74
-7 607 27 5 92 0 28

-6 698 29 5 76 0 08
-7 122 61 9 84 0 13
-6 503 89 4 10 0 10

-6 686 5 5 79 0 09
-5 452 91 4 26 0 30
-6 422 53 4 20 0 15

-6 668 27 6 66 0 64
-5 410 44 8 07 0 89
-6 404 18 4 50 0 38

Counterbalanced data sets (profiles were rotated)

Aggregate models

Random effects models

Data set

Model choice criteria

Static

Quadratic

Dynamic linear

Static

Quadratic

Dynamic linear

Fatigue Learning Simplification

Log marginal probability Holdout RMSE
Log marginal probability Holdout RMSE
Log marginal probability Holdout RMSE

-7 257 68 6 15 0 02
-8 021 65 6 68 0 08
-7 757 54 5 48 0 03

-7 257 37 6 20 0 04
-7 106 91 4 64 0 07
-7 720 44 5 35 0 04

-7 112 53 6 29 0 06
-6 902 83 4 76 0 10
-7 606 42 5 37 0 02

-6 697 5 6 13 0 10
-7 193 42 6 42 0 14
-6 551 26 3 81 0 11

-6 697 43 6 18 0 10
-5 436 4 2 96 0 10
-6 437 19 3 68 0 11

-6 482 92 6 19 0 11
-5 107 87 2 99 0 16
-6 220 5 3 90 0 19

Note. Criteria: log marginal probability and RMSE of holdout in back data posterior mean (std).

linear random effects model and it suggests that the predictive RMSE may be a more dependable model choice diagnostic.
As demonstrated by the parameter RMSE given in Table 2, using counterbalanced data typically results in comparable or better recovery of the true aggregate parameter dynamics when compared with using noncounterbalanced data.1
In general, we found that when analyzing noncounterbalanced data, the quadratic random effects model gives estimates that are somewhat stable and that are usually, but not always, close to the average dynamic.2 The dynamic linear random effects model does not perform well with noncounterbalanced data; the parameter estimates are very unstable and the MCMC algorithm takes much longer to converge. Convergence diagnostics indicated that the static and dynamic models considered here converged relatively quickly, within one or two thousand iterations, for all data sets, with the exception of the dynamic linear random effects model with noncounterbalanced data,
1 There are a few instances that this is not the case--for example involving the fatigue data and the static and quadratic random effects models--that is because of random variations in the simulated data.
2 As pointed out by a reviewer, the performance of these models in terms of parameter recovery depends on the number of ratings in the data set; the larger the data set, the better the parameter recovery. However, it is important to realize that based on our investigation, similar size counterbalanced data sets tend to result in much better parameter recovery than noncounterbalanced data sets.

which appears to have not converged after more than 8,000 iterations of the MCMC algorithm. In contrast, the simpler quadratic random effects model appears to be able to use its strong functional form assumptions to bridge the gap in missing information, resulting in better estimates for noncounterbalanced data.
4. Discussion
To investigate preference changes during the course of a conjoint study, it is essential to have statistical models that capture dynamics and accommodate individual heterogeneity. The dynamic Bayesian models introduced in this paper accommodate heterogeneity both across time and across individuals. These models offer researchers tools that can be used in assessing the quality of the inference that can be derived from an analysis of their conjoint data.
In addition, we find theoretical and empirical support for using an experimental design that is counterbalanced. The consumer behavior literature supports using counterbalancing to ensure that crossover effects do not create or drive preference dynamics. We demonstrate that, even if preference dynamics are independent of the order of the profiles, it is essential to use a counterbalanced design. If a counterbalanced design is not used and dynamics exist, then static models can fail to capture the average of the dynamics, and dynamic models can give relatively poor estimates, however, these problems are eliminated when a counterbalanced design is used.

Liechty, Fong, and DeSarbo: Dynamic Models Incorporating Individual Heterogeneity

Marketing Science 24(2), pp. 285­293, © 2005 INFORMS

291

Table 2 Parameter Recovery of Dynamic and Static Models for Three Synthetic Data Sets: Fatigue, Learning, and Simplification

Aggregate models

Random effects models

Data set

Type of data set

Static

Quadratic

Dynamic linear

Static

Quadratic

Dynamic linear

Fatigue Learning Simplification

Noncounterbalanced Counterbalanced
Noncounterbalanced Counterbalanced
Noncounterbalanced Counterbalanced

1 578 1 577
2 752 1 859
1 990 1 951

1 581 1 582
1 811 1 451
1 935 1 899

1 914 1 767
1 528 1 546
2 383 2 071

1 433 1 469
2 848 2 364
1 539 1 476

1 440 1 473
2 022 1 853
1 454 1 398

2 174 1 639
3 420 1 850
2 049 1 554

Note. Parameter RMSE based on actual average parameter values and posterior mean estimates.

From our simple conjoint simulation study, we find that for noncounterbalanced data, the static Bayesian random effects model estimates behave in a fashion similar to the aggregate MLE and they are not representative of the average dynamic; this problem does not occur with counterbalanced data. We also find that the dynamic models, particularly the quadratic models, result in estimates that are much closer to the average dynamic when noncounterbalanced data are used, but that these estimates do not always represent the dynamics properly; again, these problems do not occur when counterbalanced data are used. Based on our model choice criteria, we find that accounting for individual-level heterogeneity is relatively more important than accounting for the dynamics employed in our modest simulation. Finally, we find that predictive RMSE is a more reliable model choice diagnostic when compared with the log marginal probability.
There are, of course, a number of limitations with respect to this simulation study. First, the empirical results are based on our synthetic conjoint data sets and may change for real conjoint data sets. Second, the models that we introduce do not accommodate potential evolution in the variance of the error term, which could be another important source of dynamics. In addition, they do not offer a way for investigating whether the change in one part-worth impacts the dynamics of other part-worths. Obviously, these dynamic models could be extended to accommodate these types of complex dynamics. For example, the dynamic linear random effects model could be modified so that the updating matrix G in the system equation is a full matrix, which would allow for changes in one part-worth to impact the dynamics of other part-worths; these types of extensions are the subject of future research. Finally, several applications with real conjoint data sets are necessary to examine in detail the exact nature of dynamics in actual conjoint settings. In this same line of thought, extensions of these models to choice-based conjoint analysis, adaptive conjoint analysis, hybrid conjoint analysis, and so on would also prove beneficial.

Appendix A. Full Conditional Densities and Prior Values

Full Conditional Densities Some of the full conditional densities for both the quadratic and dynamic linear models are identical given ¯t. We present these full conditional densities first, and then the unique full conditional densities for the quadratic model, followed by the unique full conditional densities for the dynamic linear model. The common full conditional densities are given by

2 ii

¯ t

D

=d N

1
2

xit xit +

it

-1 -1

1
2

xit

yit -

¯ t

xit

it

1 2 xit xit +
it

-1 -1

(A.1)

-2

i

i

¯ t

D

=d Gamma

T 2

+

Shape

t yit -

¯t + 2

i

xit 2 + Scale

(A.2)

and

-1 i =d Wishart n + N P +

ii

i

(A.3)

where D represents all of the data. The unique full conditional densities for the quadratic
model are given by

¯ 0

2¯ ¯
i 12

iD

=d N

1
2

xit xit

+

1I

-1

it i

0

·

1 2 xit yit -

¯ 1

t

+

¯2t2 +

i

xit

it i

1
2

xit xit

+

0I

-1

it i

¯ 1

2¯ ¯
i 02

iD

=d N

1
2

t2

xit xit

+

1I

-1

it i

·

1 2 xit t yit -

¯0 + ¯2t2 +

i

xit

it i

1
2

t2

xit xit

+

1I

-1

it i

1

(A.4) (A.5)

Liechty, Fong, and DeSarbo: Dynamic Models Incorporating Individual Heterogeneity

292

Marketing Science 24(2), pp. 285­293, © 2005 INFORMS

¯ 2

2¯ ¯
i 01

iD

=d N

1
2

t4

xit xit

+

1I

-1

it i

2

·

1
2

xit

t2

yit -

¯ 0

+

¯ 1

t

+

i

xit

it i

1
2

t

4

xit xit

+

1I

-1

it i

2

(A.6)

The unique full conditional densities for the dynamic linear model are given by

¯ 1

2 i

G

¯
i2

D

=d N

n1 2 xi1xi1 + G
i=1 i

-1
-1G + B1-1

·

n

1
2

xi1

yi1 -

ix1 + G

-1

¯ 2

+

B1-1 A1

i=1 i

n1 2 xi1xi1 + G
i=1 i

-1
-1G + B1-1

(A.7)

¯ t

2 i

G

¯¯
i t-1 t+1

D

=d N

n1 2 xit xit + G
i=1 i

-1G +

-1 -1

·

n

1
2

xit

yit -

ixit + G

-1

¯ t+1

+

-1 G

¯ t-1

i=1 i

n1 2 xit xit + G
i=1 i

-1G +

-1 -1

for T > t  2 (A.8)

¯T

2 i

G

i ¯T -1

D

=d N

n1 2 xiT xiT +
i=1 i

-1 -1

·

n

1
2

xiT

yiT -

ixiT +

-1 G

¯ T -1

i=1 i

n1 2 xiT xiT +
i=1 i

-1 -1

(A.9)

-1

G

¯ t

D

=d Wishart n + T

T
P + ¯t - G ¯t-1
t=2

¯ t

-

G

¯ t-1

(A.10)

and

diag G ¯t D

=d N

T
¯¯ t-1 t-1 t=2

%

-1 +

1
2

Ip

-1

T

·

¯ t-1

%

t=2

-1 ¯ t

+

1 2 diag Ip

T
¯¯ t-1 t-1 t=2

%

-1 +

1
2

Ip

-1

(A.11)

where diag is a vector comprised of the diagonal elements of a matrix, and % is the binary operator for element-byelement matrix multiplication (i.e., A % B ij = Aij Bij ).

Prior Values Although a range of hyperparameter values were considered, the following values were used in the models reported in this study. Results for the static models were very robust to the prior specifications, while the results for the dynamic models were sensitive to the hyperparameters that contributed to the dynamics. Some of the hyperparameters are common across all models; we will first specify the common hyperparameters and then give the hyperparameters for the dynamic models: Shape = 1, Scale = 0 1, n = COV + 1, P = 0 1I, where COV is the number of covariate and I is the identity matrix. For the quadratic model, the variance of the intercept was set to a large value but the variance of the linear and quadratic terms were small: 0 = 1 000, 1 = 1, and 2 = 0 1. For the dynamic linear random effects models, we used n = 10, P = 100, B1 = 0 1I , and 2 = 0 1.

Appendix B. Proof of Unbiased Dynamic Estimates Definition. Counterbalanced Experimental Designs.
Let x = x1 xT be an experimental design. A counterbalance of this design is achieved by assigning the same number of participants to T groups, where each element of x is applied to at least one of the groups during every trial of the experiment.

Lemma. Let 1

T represent dynamics from a statisti-

cal model. Let x be an experimental design with T trials and

be an unbiased estimate of E = when t = for all t. If x is a counterbalanced experimental design, then will be an

unbiased dynamic estimate.

Proof. If E = when t = for all t, then

E

=

T t=1

wt

t,

where

wt

may

depend

on

the

design

and

T t=1

wt

= 1.

If

x

is

counterbalanced,

then

E

=1 T E T j=1

Gj

=1 T T t=1

t w1 + · · · + wT

=1 T T t=1

t

References
Allenby, G., P. Lenk. 1994. Modeling household purchase behavior with logistic normal regression. J. Amer. Statist. Association 89 1218­1231.
Bijmolt, T., M. Wedel. 1995. The effects of alternative methods of collecting similarity data for multidimensional scaling. Internat. J. Res. Marketing 12 363­371.
Bronnenberg, B., V. Mahajan, W. Vanhonacker. 2000. The emergence of new repeat-purchase categories: The interplay of market share and retailer distribution. J. Marketing Res. 37 16­21.
Dekimpe, M., D. Hanssens. 1995. The persistence of marketing effects on sales. Marketing Sci. 14 1­21.
DeSarbo, W., D. Lehmann, F. Hollman. 2004. Modeling dynamic effects in repeated measures experiments involving preference/choice: An illustration involving stated preference analysis. Appl. Psych. Measurement 28 186­209.
DeSarbo, W., D. K. H. Fong, J. Liechty, J. C. Copland. 2005. Evolutionary preference/utility functions: A dynamic perspective. Psychometrika. Forthcoming.

Liechty, Fong, and DeSarbo: Dynamic Models Incorporating Individual Heterogeneity

Marketing Science 24(2), pp. 285­293, © 2005 INFORMS

293

Erdem, T. 1996. A dynamic analysis of market structure based on panel data. Marketing Sci. 14 359­378.
Gilks, W., S. Richardson, D. Spiegelhalter. 1996. Markov Chain Monte Carlo in Practice. Chapman & Hall, New York.
Guadagni, P., J. Little. 1983. A logit model of brand choice calibrated on scanner data. Marketing Sci. 2 203­238.
Hsee, C., G. Loewenstein, S. Blount, M. Bazerman. 1999. Preference reversals between joint and separate evaluations of options: A review and theoretical analysis. Psych. Bull. 125(5) 576­590.
Huber, J., D. Wittink, R. Johnson, R. Miller. 1992. Learning effects in preference tasks: Choice-based versus standard conjoint. Sawtooth Software Conference Proceedings. Sawtooth Software, Inc., Sequim, WA.
Johnson, R., B. Orme. 1996. How many questions should you ask in choice-based conjoint studies. Technical report, Sawtooth Software, Inc., Sequim, WA.
Kardes, F., G. Kalyanaram. 1992. Order-of-entry effects on consumer memory of judgment: An information integration perspective. J. Marketing Res. 29 343­357.
Keppel, G. 1991. Design and Analysis: A Researcher's Handbook, ed. 3. Prentice-Hall, Englewood Cliffs, NJ.
Lenk, P., W. DeSarbo, P. Green, M. Young. 1996. Hierarchical Bayes conjoint analysis: Recovery of part-worth heterogeneity from incomplete designs in conjoint analysis. Marketing Sci. 15 173­191.
Luce, D., J. Tukey. 1964. Simultaneous conjoint measurement: A new type of fundamental measurement. J. Math. Psych. 1 1­27.

Meyer, R., A. Sathi. 1985. A multiattribute model of consumer choice during product learning. Marketing Sci. 4 41­61.
Muthukrishnan, A. V., F. Kardes. 2001. Persistent preferences for product attributes: The effects of the initial choice context and uninformative experience. J. Consumer Res. 28 89­104.
Newton, M., A. Raftery. 1994. Approximate Bayesian inference by the weighted likelihood bootstrap (with discussion). J. Roy. Statist. Soc. Ser. B 56 3­48.
Paap, R., P. Franses. 2000. A dynamic multinomial probit model for brand choice with different long-run and short-run effects of marketing-mix variables. J. Appl. Econometrics 15 717­744.
Payne, J., J. Bettman, E. Johnson. 1992. Behavioral decision research: A constructive processing perspective. Ann. Rev. Psych. 43 87­131.
Slovic, P. 1995. The construction of preference. Amer. Psych. 50 364­371.
Toubia, O., D. I. Simester, J. R. Hauser, E. Dahan. 2003. Fast polyhedral adaptive conjoint estimation. Marketing Sci. 22(3) 273­303.
Vakratsas, D., F. M. Feinberg, F. M. Bass, G. Kalyanaram. 2004. The shape of advertising response functions revisited: A model of dynamic probabilistic thresholds. Marketing Sci. 23(1) 109­119.
von Neumann, J., O. Morgenstern. 1947. Theory of Games and Economic Behavior. Princeton University Press, Princeton, NJ.
West, M., J. Harrison. 1997. Bayesian Forecasting and Dynamic Models, ed. 2. Springer-Verlag, New York.
Wildt, A., R. Winer. 1983. Modeling and estimation in changing market environments. J. Bus. 56 365­388.

