http://pubsonline.informs.org/journal/mksc/

MARKETING SCIENCE
Vol. 37, No. 5, September­October 2018, pp. 838­851 ISSN 0732-2399 (print), ISSN 1526-548X (online)

Preaching to the Choir: The Chasm Between Top-Ranked Reviewers, Mainstream Customers, and Product Sales

Elham Yazdani,a Shyam Gopinath,b Steve Carsona
a David Eccles School of Business, University of Utah, Salt Lake City, Utah 84112; b Kelley School of Business, Indiana University, Bloomington, Indiana 47405 Contact: elham.yazdani@eccles.utah.edu (EY); shgopi@iu.edu, http://orcid.org/0000-0002-1955-7920 (SG); steve.carson@eccles.utah.edu (SC)

Received: May 8, 2016 Revised: June 19, 2017; January 7, 2018; March 15, 2018 Accepted: March 16, 2018 Published Online in Articles in Advance: August 22, 2018
https://doi.org/10.1287/mksc.2018.1101
Copyright: © 2018 INFORMS

Abstract. The main objective in this paper is to study the effect of reviews by top- and bottom-ranked reviewers on product sales. We use designated market area sales data for 182 new music albums released over an approximately three-month period along with user review data from Amazon.com. Our estimation accounts for confounding factors in the effects of online word-of-mouth measures via the use of instrumental variables. There are several key insights. Overall, we find that bottom-ranked reviewers have a greater effect on sales than top-ranked reviewers. Top-ranked reviewers can be opinion leaders, but their influence is largely limited to special cases like very new products or products with high variance in existing reviews. Additional analysis reveals that the differences in the influence of top- and bottom-ranked reviewers is driven by both what they write (content) and who they are (identity). The results are robust across multiple product categories (music and cameras) and multiple dependent variables (sales and sales rank).

History: K. Sudhir served as the editor-in-chief and Catherine Tucker served as the associate editor for this article.
Supplemental Material: Data are available at https://doi.org/10.1287/mksc.2018.1101.

Keywords: social media · online word-of-mouth · reviews · music · cameras · endogeneity · instrumental variables

Introduction
For managers to appropriately target influencers online, they must first understand how the opinions expressed by different groups affect product sales. Opinion leaders are typically defined as consumers who generate a high volume of influential word-ofmouth (WOM). Since influence is rarely measured directly, marketers trying to identify key influencers usually look for users who generate a high volume of content along with feedback from other users such as helpfulness ratings, followers, or subscribers that serve as a proxy for influence. Websites such as Amazon.com assist in the identification of such individuals through reviewer rankings that reward prolific reviewers for their contributions to the community while also signaling their status to other users. The algorithms used to rank reviewers on Amazon.com and other e-commerce sites are proprietary; however, they are generally recognized to account for the volume of reviews posted by a user in addition to factors such as the recency of reviews.
If the logic behind such reviewer rankings is correct, top-ranked reviewers should be particularly influential on product sales. While the influence of top-ranked reviewers is often assumed by marketers when assembling an influencer network, it is an open question as to whether they actually influence product sales

more than other reviewers. To gain insight into this issue, we study the review and sales activity for all 182 new music albums released between January 21, 2014, and April 15, 2014, on Amazon.com, the leading seller of music albums. We take review data from Amazon. com and relate this to Designated Market Area (DMA)level sales data from Nielsen.
Music albums were selected since they are an experience good for which online reviews should be particularly relevant and for which both review content and source are important factors to consider when processing reviews. Sales of music albums are known to peak shortly after release. Therefore, the data set is constructed to examine review activity during the critical first two months so that early influences on consumption can be observed. As robustness checks, we relate product reviews to sales rank on Amazon.com and repeat this analysis in the camera category. Cameras are a very different type of product, the sales of which are driven much more by the technical aspects of the product and for which it is more difficult for consumers to sample the product in a meaningful way prior to purchase.
In our analysis, we show that top-ranked reviewers can be opinion leaders, in the sense that their reviews have a strong directional influence on product sales, but their influence is largely limited to special cases like

838

Yazdani, Gopinath, and Carson: Preaching to the Choir: The Link Between Reviewer Ranking and Product Sales Marketing Science, 2018, vol. 37, no. 5, pp. 838­851, © 2018 INFORMS

839

very new products or products with high variance in existing reviews. In contrast, bottom-ranked reviewers have a much greater influence on sales in general. This divergence is explained by the identity of the reviewer (i.e., the reviewer ranking itself) and by the contrast in review content between top- and bottom-ranked reviewers. Our analysis demonstrates that top-ranked reviewers write reviews that are longer, more formal, and with more punctuation, but that are less social and less affective when compared with reviews written by bottom-ranked reviewers. These differences substantially alter the effect of reviews from the two groups on product sales. The effect of each group is further moderated by content of existing reviews for the product. Overall, the results show that marketers should be extremely cautious in using reviewer rankings alone as a measure of opinion leadership or as a basis for establishing an influencer network.1
The remainder of this paper is organized as follows. First, we briefly review the literature on online WOM and social influences on product sales. We then discuss reasons why top-ranked reviewers may or may not have a stronger influence on sales than bottom-ranked reviewers. Then, we describe our data, models, and results. This is followed by a discussion of the implications for marketers.
Related Literature
Past research on online WOM has focused primarily on examining the effects of user-generated content such as reviews on product sales and stock performance. In contrast, only a handful of studies have considered source effects related to the characteristics of the reviewer or contextual factors that might alter the effect of reviews from different sources, as we focus on in the current study.
Online Word-of-Mouth The three most commonly used measures of online WOM are volume, valence, and variance (Dellarocas and Narayan 2006). Volume and valence are typically measured by the number of reviews and the average review rating for a product, respectively. Variance has been measured either by statistical dispersion (Clemons et al. 2006, Moe and Trusov 2011, Sun 2012) or entropy (Godes and Mayzlin 2004).
Existing studies have generally shown a positive relationship between the valence of customer reviews and product sales (Chen and Xie 2008, Chevalier and Mayzlin 2006, Dellarocas et al. 2007, Ho-Dac et al. 2013). Evidence on the relationship between volume and sales has been more mixed (Duan et al. 2008, Chintagunta et al. 2010), although both valence and volume have been successfully linked to increased stock performance (Luo 2007, Tirunillai and Tellis

2012). Results for variance have been less consistent, in part because of the complex ways in which variance may affect sales (Clemons et al. 2006, Sun 2012).
Source Effects and Opinion Leadership Some reviews will be more influential than others due to both the content of the review and its source. It is important for marketers to identify the opinion leaders responsible for such reviews. There are a number of different characteristics of opinion leaders that have been identified in the literature to distinguish them from opinion seekers (Katz and Lazarsfeld 1955, King and Summers 1970, Bloch and Richins 1983).
Goldenberg et al. (2006) identify opinion leaders as having high product expertise and well-developed social connections. Chan and Misra (1990) define opinion leaders as highly involved individuals with higher product knowledge and more exposure to others. Feder and Savastano (2006) define opinion leaders as individuals with more access to information who have high status, expertise, and knowledge about the product. Susarla et al. (2012) view opinion leaders as early adopters who share their experiences with others. They show that opinion leaders defined in this manner have a high importance in the early stages of the new product diffusion process. Iyengar et al. (2011) define opinion leaders as heavy product users. In a commentary on this study, Godes (2011) finds different characteristics for opinion leaders based on how they are identified. He concludes that heavy users, who have a larger effect than average users, might have higher status or greater product involvement. While the precise definitions vary, these studies jointly link the influence of an individual with their knowledge of the product as well as their status or position in the community, as indicated by factors such as reviewer ranking.
Top- and Bottom-Ranked Reviewers For products like music and cameras, preferences vary considerably across reviewers, as does knowledge of the product category. Hence, consumers of reviews must evaluate the source to assess their motivation and qualifications as well as the extent to which they value the same features or benefits the particular consumer does. Given a limited amount of information and time, consumers will employ heuristics when evaluating the source of the review such as considering reviewer rankings, the style of the review, or the similarity between the source and receiver.
In making this evaluation, there is evidence that reviewers can be grouped into identifiable categories with similar behavior on the basis of the content of their reviews. Gilbert and Karahalios (2010) mine data from 100,000 Amazon.com reviews of 200 best-selling products and identify "professional" and "amateur" reviewers. Amateurs are defined as reviewers with similar

840

Yazdani, Gopinath, and Carson: Preaching to the Choir: The Link Between Reviewer Ranking and Product Sales Marketing Science, 2018, vol. 37, no. 5, pp. 838­851, © 2018 INFORMS

review content to earlier reviews. In contrast, professionals have followers and different motivations than amateurs. The authors demonstrate that it is important for professionals to build up their reputation in the community. Pinch and Kesler (2011) similarly conclude in their study of the top 1,000 Amazon.com reviewers that these reviewers try to promote their ranking and that Amazon.com actively helps top-ranked reviewers connect with each other.
Top- and bottom-ranked reviewers differ in a number of ways that may affect the ability of each group to influence the opinions and actions of other consumers. First, there are differences in the content of reviews posted by top-ranked reviewers in comparison with bottom-ranked reviewers. According to Pinch and Kesler (2011), top-ranked reviewers write in a more formal and professional manner, and their reviews tend to be longer than those of typical reviewers. These two groups of reviewers may also differ on other key dimensions (e.g., social, affective) we investigate that can substantially alter the effect of their reviews on product sales.
Second, there is the reviewer identity itself. Every reviewer on Amazon.com receives a reviewer ranking that is displayed in their profile. The top 1,000 reviewers are identified by badges. Further information about a reviewer's ranking can be found by clicking through to view their profile, where this information is prominently displayed. For reviewers without a badge, this is the only way to see their ranking. The identity component is important, since top-ranked reviewers possess a general credibility and trustworthiness engendered by their status and reputation that is transmitted by the website through the signal of their reviewer ranking (Cheung et al. 2009). In contrast, bottom-ranked reviewers lack such credibility, independent of the content of their review.
This difference in credibility suggests that the effect of each group of reviewers on sales is likely to change in two scenarios. First, when a product is new, there is a higher level of uncertainty about it, which makes signals of credibility more important. In addition, the potential buyer needs to read through only a small set of reviews, which makes it relatively easy to attend to reviewer ranking. As the product ages, the number of reviews increases, making it a more daunting task to keep track of each reviewer's ranking. Together, these factors suggest that top-ranked reviewers will be more influential for newly released products due to their general credibility and the ease with which they can be identified.
Second, when there is a lack of consensus (i.e., high variance) among existing product reviews, consumers will look for heuristics to sort through the conflicting evidence. Top-ranked reviewer status can again act as a signal of credibility to which consumers may turn. Bottom-ranked reviewers will have less influence in this circumstance, since they lack such a signal of credibility.

However, when reviews are more consistent, the valence associated with bottom-ranked reviewers should become more influential because of their similarity (homophily) to the broader market. In other words, the identity and style of reviews by top-ranked reviewers marks them as different from the typical reviewer, which may diminish the effect of their opinion on the typical consumer.
Research Contributions To the best of our knowledge, this is the first study that parses out the effect of review summary measures (volume, valence, and variance), the effect of review content, and the effect of review source on product sales. Specifically, this research adds to the growing subdomain of online WOM on the following fronts. First, we do not restrict our analysis to top-ranked reviewers. We study the influence of both top- and bottom-ranked reviewers on product sales, recognizing the potential effect of the latter. Second, we analyze the role of product age and review consensus in moderating the influence of these two reviewer groups. Product age is defined as the time since product introduction. Variance in the ratings of reviews is used to capture (the inverse of) review consensus. Third, we investigate the role of review content along multiple dimensions--word count, social, affective, informal, and punctuation. This content analysis provides us with valuable information that clearly differentiates a typical review written by a top-ranked reviewer from a typical review written by a bottom-ranked reviewer. Fourth, we study whether each group's effect changes as a function of the cumulative content measures of existing reviews. Finally, on the methodological side, we use an instrumental variable approach to address potential endogeneity issues with the key online WOM measures.
Data Description
In the United States, the music industry generates more than $15 billion in annual revenue. The data set for this study consists of all 182 music albums in audio format released over a roughly three-month period from January 21, 2014, to April 15, 2014. We obtained the official release date for each album from Metacritic (http://www.metacritic.com). Music albums, similar to other entertainment products (e.g., movies), experience fast sales drops after their initial release. We therefore focus our analysis on the two-month period immediately after album release.
We collected data from Amazon (http://www .amazon.com) for 60 days following the date of release for each music album. Specifically, we collected data on Amazon's sales price (PRICE), the number of reviews, and the number of stars each reviewer assigned. The average number of stars assigned by reviewers is captured on a scale from one to five, with five being the best. For each review, we collected the reviewer's rank and the

Yazdani, Gopinath, and Carson: Preaching to the Choir: The Link Between Reviewer Ranking and Product Sales Marketing Science, 2018, vol. 37, no. 5, pp. 838­851, © 2018 INFORMS

841

number of people who found the review helpful. We also collected the full content of each review since one of our main goals is to study the role of review content and whether it is the content or identity associated with top- and bottom-ranked reviewers that sets them apart.
Cumulative volume (VOLCUM), cumulative valence (VALCUM), and cumulative variance (VARCUM) are, respectively, the total number of posted reviews, the average rating of all posted reviews, and the variance of all posted reviews for a product through a given day. Consistent with prior research (e.g., Gopinath et al. 2013, Chintagunta et al. 2010), we assume that all of the reviews posted until, but not including, period t impact sales in period t. Top-ranked review valence ( VALCUM_TOPRANK) is calculated as the average of the ratings from reviewers with a top 1,000 Amazon ranking. Bottom-ranked review valence (VALCUM_BOTMRANK) is the average of ratings from reviewers with a non­top 1,000 Amazon ranking.
Since a reviewer's ranking is dynamic (i.e., it can change after he or she posts a review), we track daily changes in Amazon's ranking for each reviewer. That is, the same review will be associated with a different Amazon reviewer ranking as this updates dynamically over time to reflect the perspective of a reader encountering the review on that day. We control for the average reviewer ranking across all reviews for a product at a given time with the variable average reviewer rank (RANK). This also updates dynamically each period because of the posting of new reviews for the product and/or a change in the Amazon reviewer rankings associated with the current set of reviewers.
In our main analysis, we use DMA-level sales data for each music album from Nielsen. These data capture DMA-level sales across all online and offline channels. We also conduct additional analysis using Amazon. com sales rank in two product categories, music and cameras. Variable definitions and summary statistics are given in Table 1.
Empirical Analysis
We proceed with the analysis as follows. First, we present models that help us understand the effects of the valence of top- and bottom-ranked reviewers on product sales. Second, we test the robustness of our results with Amazon.com sales rank data and in the second product category. We then examine the role of review content versus reviewer identity. Finally, we investigate the moderating role of product age and review variance on the influence of each reviewer group. In all models, we use a log-log specification.
Does Reviewer Ranking Moderate the Effect of Review Valence on Sales? Reviewer ranking can be seen as a measure of a reviewer's global network position, which is one of the

factors that has been shown to determine influence in an online social network (Katona et al. 2011). Reviewers with better rankings are perceived to have more central network positions and more credibility in the sense that their reviews are more trustworthy because they have a reputation to protect. Cialdini (2000) and Cheung et al. (2009) provide evidence that the reputation of a recommendation source is important in determining its influence. In addition, a large number of articles support the theory that source credibility increases the chance that a receiver will accept a persuasive message (Fishbein and Ajzen 1975, McGuire 1969). Guadagno and Cialdini (2003) summarize studies in this area and conclude that social status is even more important in an online setting than in face-to-face communication.
However, there are also factors that may decrease the effect of top-ranked reviewers on sales. At a general level, consumers know that certain top reviewers are given free products to review through Amazon Vine and similar programs. Manufacturers also distribute products to top reviewers directly in return for reviews. This can create a dent in the credibility of top-ranked reviewers. In addition, the sheer volume of reviews produced by many top-ranked reviewers across categories can call into question the extent to which they have developed indepth knowledge of a specific product category.
Finally, there are differences in the content between top- and bottom-ranked reviewers. According to Pinch and Kesler (2011), reviewers with better rankings are more likely to be good writers. However, the effect of a well-written review on potential buyers and sales is an open question since it may also signal the group membership of the reviewer and how they differ from the typical reviewer or consumer.
Model and Results. We use album sales as the dependent variable. We do not invert the reviewer ranking. Thus, a lower numerical reviewer ranking indicates a more "top-ranked" reviewer. Sales is modeled as a function of the product's price, the age of the product since launch, and the cumulative volume, cumulative valence, and cumulative variance of its reviews. We also control for the helpfulness of reviews.
To examine the main relationship of interest in the initial analysis, we include the average reviewer rank for the reviews of the product as well as the interaction between this variable and cumulative valence. The interaction term allows us to investigate how the ranking profile of reviewers responsible for a product's reviews affects the influence of cumulative valence on the sales of the product. Cumulative valence is expected to be positively associated with sales. Therefore, if top-ranked reviewers are less influential on sales than bottom-ranked reviewers, this will be reflected in a positive interaction between average reviewer rank and cumulative valence, recalling that a larger numerical

842

Yazdani, Gopinath, and Carson: Preaching to the Choir: The Link Between Reviewer Ranking and Product Sales Marketing Science, 2018, vol. 37, no. 5, pp. 838­851, © 2018 INFORMS

Table 1. Descriptive Statistics

Variable

Definition

Mean Standard deviation Minimum Maximum

DMA_SALESijt SALESRANKit PRICEit AGEit VOLCUMit VALCUMit VARCUMit RANKit VALCUM_TOPRANKit

DMA-level sales for album i in market j at time t Sales rank for album i at time t Price for album i in time t Age of album i at time t Total number of reviews for album i at time t Average of ratings for album i at time t One plus the variance of ratings for album i at time t Average of reviewer rankings for album i at time t Average of top 1,000­ranked reviewers' ratings for
album i at time t

VALCUM_BOTMRANKit Average of non­top 1,000­ranked reviewers' ratings for album i at time t

HELPFULit WORD COUNTit PUNCTUATIONit

Average of helpfulness votes for album i at time t Number of words in the reviews for album i at time t Punctuation characters in the reviews for album i at
time t

AFFECTIVEit

Net of both the positive and negative emotions (such as anxiety, anger, and sadness) for album i at time t

SOCIALit

Words capturing the degree of being involved in social process with family, friends, etc. for album i at time t

INFORMALit

Words capturing the degree of using informal language, such as swear, first-person singular words, and short

words for album i at time t

AFRICAN-AMERICANj CAUCASIAN j YOUNG j

Percentage of African-Americans in market j Percentage of Caucasians in market j Percentage of population less than 34 years old in
market j

No. of observations

51.71966 10,707 10.9476 29.6066 24.6383 4.5345 1.7535 4,778,003 4.3396
4.5172
1.8403 122.2086 18.6208
8.0409
7.6941
0.9245
0.0984 0.8121 0.3733

315.7125 36,116 1.6646 16.6813 29.1256 0.3531 0.6709 2,395,745 0.9394
0.9382
1.4322 67.9952 3.9622
2.0776
1.9368
0.6373

1 1 6.99 5 2 2 1 2,611.929 1

50,650 887,885 17.99
61 231 5 6.3333 1.48e+07 5

1

5

0 19 3.45

10.6667 749
80.1467

1.235 19.05

1.04

21.2517

0.03

8.1

0.0846 0.1207 0.0289

0.00809 0.4463 0.2896

52,510

0.4651 0.9794 0.4861

reviewer ranking indicates a more bottom-ranked reviewer. We have the following model specification:

log(SALESijt)

i + 1 log(VOLCUMit-1) + 2 log(VALCUMit-1) + 3 log(VARCUMit-1) + 1 log(VALCUMit-1) × log(RANKit-1) +  log(j) +  log(Xit) + ijt,
(1)

where j (AFRICAN - AMERICANj, CAUCASIANj, YOUNGj) is a vector controlling for the demographic variables of DMA j, and Xit (PRICEit, AGEit, RANKit-1,
HELPFULit-1).

Endogeneity. Endogeneity is a potential issue when investigating the influence of different measures of online WOM. The general concern is that unobserved factors associated with the product or the environment in a given period can create a correlation between the regressors and the error structure, biasing OLS estimates. The use of product fixed effects ( i) in our models removes the effect of time-invariant unobserved product-specific characteristics. However, time-variant characteristics such as offline WOM, television advertisements, or radio play are not removed through fixed-effect estimation and may affect both review activity and sales in a given period. The lag

structure of the models provides a degree of protection, but this is typically incomplete.
Prior studies in this area have used both limited information (e.g., Chintagunta et al. 2010, Gopinath et al. 2013) and full information (e.g., Duan et al. 2008) approaches to deal with this challenge. In this research, we correct for endogeneity in the estimation by using instrumental variables (IV). The intuition behind any choice of instruments is to have variables that are correlated with the online WOM measures but uncorrelated with the unobservable in Equation (1).
As the IV for VOLCUM, we use the number of days during the time period that the amount of precipitation was greater than the median. Gopinath et al. (2013) use a similar instrument. The idea is that people are more likely to stay indoors on rainy/snowy days and spend more time writing reviews. The identifying assumption is that, conditional on album characteristics, market characteristics, etc., covariation between the volume of reviews and the number of bad weather days is due to the supply of time for writing reviews and not due to unobserved demand factors.
For VALCUM, we use as the IV the average cumulative rating each reviewer has posted for products in categories other than music. The intuition is that such an IV shows the positive/negative tendency of a specific reviewer, which influences his/her rating for the focal product but does not directly influence the focal product's sales.

Yazdani, Gopinath, and Carson: Preaching to the Choir: The Link Between Reviewer Ranking and Product Sales Marketing Science, 2018, vol. 37, no. 5, pp. 838­851, © 2018 INFORMS

843

Table 2. First-Stage Estimates for VOLCUM, VALCUM, and VARCUM

First-stage estimates for endogenous variables

Variable

DV = VOLCUMa

DV = VALCUMa

INSTRUMENT for VOLCUM INSTRUMENT for VALCUM INSTRUMENT for VARCUM PRICE AGE RANK HELPFUL AFRICAN-AMERICAN CAUCASIAN YOUNG No. of observations Within R2 Product fixed effects

0.0456*** (0.0051) 0.3465*** (0.0659) 0.1634*** (0.0201) 0.3369*** (0.0266) 0.4454*** (0.0026) 0.0738*** (0.0039) ­0.1196*** (0.0093) 0.0002 (0.0021) ­0.0012 (0.0198) ­0.0062 (0.0195)
52,510 0.9621
Yes

­0.0092*** (0.0010) 0.0690*** (0.0113) ­0.0708*** (0.0047) ­0.0478*** (0.0043) ­0.0032*** (0.0005) 0.0055*** (0.0007) 0.0221*** (0.0012) 0.0000 (0.0004) 0.0001 (0.0032) 0.0010 (0.0056)
52,510 0.9381
Yes

Note. Fixed effects are not reported. aThe DVs are the volume, valence, and variance measures for the online reviews.
***p < 0.01.

DV = VARCUMa
­0.00538 (0.0042) ­0.8929*** (0.0650) 0.1339*** (0.0169) ­0.0666*** (0.0209) 0.0201*** (0.0045) 0.0189*** (0.0034) ­0.0355*** (0.0098) 0.0002 (0.0011) 0.0016 (0.0076) ­0.0005 (0.0200)
52,510 0.8818
Yes

Thus, the covariation between the valence of reviews and the instrument can be attributed to factors other than the unobservable characteristics of the music album. This is our identifying assumption.
Using similar logic, for VARCUM, we use the variance of the cumulative ratings each reviewer has posted for products in categories other than music. One would expect the variance in reviewer rating tendencies for other product categories to be positively related to the variance in reviewer ratings for the music category. The identifying assumption is similar to that for the valence instrument.
We present the first-stage results of the regressions of the endogenous variables on the instruments, exogenous variables, and fixed effects in Table 2. As can be seen, each endogenous variable is significantly and directionally impacted by its corresponding IV.
The second-stage estimation of Model 1 using these IVs is shown in Table 3. There is considerable difference in the coefficients of the endogenous variables in the two columns. This highlights the importance of controlling for endogeneity. The key result is that there is a significant positive coefficient for the interaction term, which indicates that top-ranked reviewers are less influential on sales than bottom-ranked reviewers. That is, the valence of reviews has a stronger association with sales to the extent that the reviews are coming from non­highly ranked reviewers. The control variables all

influence sales as expected. PRICE and AGE affect sales negatively, while HELPFULNESS has a positive influence on sales. The three demographic variables also have significant effects on sales.
We next estimate a second model in which reviewers are categorized into top-ranked reviewers (top 1,000 reviewers) and bottom-ranked reviewers (non­top 1,000 reviewers), as defined earlier, to allow for more precise insights into the differences between these groups of reviewers. The econometric specification to tease out the effects of the valence of topranked ( VALCUM_TOPRANK) and bottom-ranked (VALCUM_BOTMRANK) reviewers is as follows:
log(SALESijt) i + 1 log(VOLCUMit-1) + 2 log(VARCUMit-1) + 1 log(VALCUM TOPRANKit-1) + 2 log(VALCUM BOTMRANKit-1) +  log(j) +  log(VALCUM TOPRANKit-1) × log(j) +  log(VALCUM BOTMRANKit-1) × log(j) +  log(Xit) + ijt.
(2)
For the endogeneity correction of the volume and variance measures, we use the same IVs as before. As IVs

844

Yazdani, Gopinath, and Carson: Preaching to the Choir: The Link Between Reviewer Ranking and Product Sales Marketing Science, 2018, vol. 37, no. 5, pp. 838­851, © 2018 INFORMS

Table 3. Does Reviewer Ranking Moderate the Effect of Review Valence on Sales?

Model 1, DV = log(SALES)a

Variable

No endogeneity correction

PRICE AGE RANK HELPFUL VOLCUM VARCUM VALCUM RANK * VALCUM AFRICAN-AMERICAN CAUCASIAN YOUNG No. of observations Within R2 Product fixed effects

­0.2590*** (0.0754) ­0.9153*** (0.0487) ­0.0832 (0.108) 0.1803*** (0.0237) 0.0242 (0.0341) 0.0606** (0.0290) -2.2578*** (0.9034) 0.1264** (0.0685) ­0.1099*** (0.0099) ­0.2604*** (0.0841) 1.1509*** (0.0571)
52,510 0.5649
Yes

Note. Fixed effects are not reported. aThe DV is the market (DMA)-level sales. **p < 0.05; ***p < 0.01.

With endogeneity correction
­0.2434*** (0.0996) -1.0118*** (0.0431) ­0.6791*** (0.2043) 0.2120*** (0.0341) ­0.0147 (0.0703) 3.3345*** (0.7213) -2.8027** (1.3020) 0.3630*** (0.0921) ­0.0176** (0.0081) ­0.6539*** (0.0639) 1.3872*** (0.08920)
52,510 0.6137
Yes

for VALCUM_TOPRANK and VALCUM_BOTMRANK, similar to the IV for VALCUM, we use the average cumulative rating each reviewer (top ranked or bottom ranked) has posted for products in categories other than music. Thus, the first-stage equation is similar to Model 1 but has two IVs for VALCUM_TOPRANK and VALCUM_BOTMRANK instead of the single instrument for VALCUM. The firststage results are shown in Table 4. As we see, each endogenous variable is significantly impacted by the corresponding IV.
The results for Model 2 are shown in Table 5. The same key effect that was uncovered in Model 1 is evidenced in Model 2. The valence associated with bottom-ranked reviewers has a much stronger effect on sales than the valence of top-ranked reviewers.
What Is the Effect of Top- and Bottom-Ranked Reviewers on Amazon Sales Rank? As a robustness check of the results in Table 5, we estimate the effect of the two groups on Amazon.com sales rank, which has been used as a proxy for sales in previous research. To further check the generalizability of our results, we also collect sales rank, price, and review data for a random sample of cameras over the same period as our music data set. We do not invert

the sales rank. Thus, a negative coefficient implies a positive effect on sales. The model is specified as follows:
log(SALES RANKit) i + 1 log(VOLCUMit-1) + 2 log(VARCUMit-1) + 1 log(VALCUM TOPRANKit-1) + 2 log(VALCUM BOTMRANKit-1) + (WEEK DAY DUMMIESt) +  log(Xit) + ijt.
(3)
The results of Model 3 are shown in Table 6. In both product categories, we see a significant negative coefficient for VALCUM_BOTMRANK but an insignificant coefficient for VALCUM_TOPRANK, which means that ratings provided by bottom-ranked reviewers matter more than ratings from top-ranked reviewers.
Why Are Bottom-Ranked Reviewers More Influential than Top-Ranked Reviewers on Sales? In this section, we investigate why the two reviewer groups have different effects on sales. This could arise due to (1) content differences (i.e., potential consumers are more strongly influenced by the bottom-ranked

Yazdani, Gopinath, and Carson: Preaching to the Choir: The Link Between Reviewer Ranking and Product Sales Marketing Science, 2018, vol. 37, no. 5, pp. 838­851, © 2018 INFORMS

845

Table 4. First-Stage Estimates for VOLCUM, VALCUM_TOPRANK, VALCUM_BOTMRANK, and VARCUM

First-stage estimates for endogenous variables

Variable

DV = VOLCUMa DV = VALCUM_TOPRANKa DV = VALCUM_BOTMRANKa DV = VARCUMa

log(Instrument for VOLCUM)
log(Instrument for VALCUM_TOPRANK)
log(Instrument for VALCUM_BOTMRANK)
log(Instrument for VARCUM)
PRICE
AGE
RANK
HELPFUL
AFRICAN-AMERICAN
CAUCASIAN
YOUNG
No. of observations Within R2 Product fixed effects

0.0208*** (0.0063) 0.1404*** (0.0471) 0.07057 (0.0628) 0.1396*** (0.0195) 0.3077*** (0.0305) 0.4632*** (0.0032) 0.0551*** (0.0043) ­0.0969*** (0.0108) ­0.0001 (0.0031) ­0.0034 (0.0120) ­0.0088 (0.0230)
52,510 0.9537
Yes

0.0152** (0.0095) 0.2777*** (0.0606) ­0.0795 (0.0956) ­0.1163*** (0.0259) ­0.4704*** (0.0455) ­0.1381*** (0.0050) 0.0357*** (0.0049) 0.0016 (0.0106) ­0.0003 (0.0042) ­0.0027 (0.0230) ­0.0001 (0.0341)
52,510 0.8332
Yes

­0.0737*** (0.0171) ­0.2933*** (0.0971) 1.4817*** (0.2724) ­0.0174 (0.0447) ­0.6178*** (0.0514) ­0.3172*** (0.0079) 0.0675*** (0.0072) 0.0729*** (0.0165) ­0.0016 (0.0057) ­0.0029 (0.0241) 0.0195 (0.0399)
52,510 0.8386
Yes

­0.0037 (0.0049) ­0.2479*** (0.0415) ­0.6756*** (0.0773) 0.0350*** (0.0107) 0.2272*** (0.0271) 0.0110*** (0.0024) 0.0012 (0.0031) ­0.0209*** (0.0058) 0.0002 (0.0010) 0.0022 (0.0071) 0.0004 (0.0104)
52,510 0.9204
Yes

Note. Fixed effects are not reported. aThe DVs are the volume, valence of top-ranked reviewers, valence of bottom-ranked reviewers, and variance measures for the online reviews. **p < 0.05; ***p < 0.01.

group's review content), (2) identity differences (i.e., the ranking label of a top-ranked reviewer has a negative connotation associated with it (e.g., it might be assumed that highly ranked reviewers can be biased because they receive free gifts from sellers)), or (3) both (i.e., the differences we observe are the result of both content and identity differences). This investigation adds to the literature on summary measures (i.e., valence, volume, and variance) by teasing out the separate effects of the summary measures, content measures, and reviewer identity.
To do so, we use the Linguistic Inquiry and Word Count (LIWC) tool (http://liwc.wpen gine.com) to score each review on five key dimensions: word count, affective, social, informal, and punctuation. There is a high correlation between the LIWC categorization procedure and that of human coders (Pennebaker et al. 2007). This methodology has been used in different contexts, such as online blogs (Cohn et al. 2004) and online instant messaging (Slatcher and Pennebaker 2006). It has recently been used in marketing to analyze newspaper articles (Humphreys 2010, Berger and Milkman 2012) and Amazon.com online reviews (Ludwig et al. 2013).
WORD COUNT captures the numbers of words in a review. Godes and Mayzlin (2004) find that the

average length of discussions about a TV show has a negative but insignificant effect on its rating. Our context is different in that Godes and Mayzlin focus on message board discussions featuring threads with typically multiple responses from each user. However, for reviews, it is more of a one-way form of communication in which length could be more valuable.
The AFFECTIVE dimension measures the extent of both positive and negative emotional content in the review. Gopinath et al. (2014) find that emotion oriented keywords have a significant effect on purchasing behavior. However, they do not disentangle the effects of online WOM summary measures and content measures. In addition, their social media source is message boards (similar to Godes and Mayzlin) and not product reviews. Examples of affective words in a text are "nice" and anxiety/anger/sadness related words such as "worried, hate, or crying."
Next we include the SOCIAL measure. LIWC uses a methodology based on several studies (e.g., Cegala 1989, Giles and Coupland 1991) to identify linguistic correlates of social involvement. Cegala (1989) found that more involved couples use more certainty words, more verbal immediacy, and plural pronouns. Giles and Coupland (1991) developed communication accommodation theory. According to this theory, individuals use

846

Yazdani, Gopinath, and Carson: Preaching to the Choir: The Link Between Reviewer Ranking and Product Sales Marketing Science, 2018, vol. 37, no. 5, pp. 838­851, © 2018 INFORMS

Table 5. Impact of Top- and Bottom-Ranked Reviewers on Sales

Variable PRICE
AGE
RANK
HELPFUL
VOLCUM
VARCUM
VALCUM_TOPRANK
VALCUM_BOTMRANK
AFRICAN-AMERICAN
CAUCASIAN
YOUNG
VALCUM_TOPRANK * AFRICANAMERICAN
VALCUM_TOPRANK * CAUCASIAN
VALCUM_TOPRANK * YOUNG
VALCUM_ BOTMRANK * AFRICANAMERICAN
VALCUM_ BOTMRANK * CAUCASIAN
VALCUM_ BOTMRANK * YOUNG
No. of observations Within R2 Product fixed effects Note. Fixed effects are not reported.
aThe DV is the market (DMA)-level sales. **p < 0.05; ***p < 0.01.

Model 2
DV = log(SALES)a
­0.7715*** (0.1043) -1.0485*** (0.0291) 0.1151*** (0.0253) 0.1815*** (0.0331) 0.0812*** (0.0311) 0.0577** (0.0281) 0.0861 (0.2621) 1.243*** (0.2131) ­0.2169*** (0.0721) -1.6117*** (0.5150) -1.3344*** (0.4510) ­0.0199 (0.0223) 0.1127 (0.1322) 0.2119** (0.0915) 0.1396** (0.0578) 0.6346*** (0.2030) 0.8076*** (0.3149)
52,510 0.6187
Yes

language to negotiate the social distance between themselves and their partners (Pennebaker et al. 2003). Examples of social words in a text include words related to family/friends/female/male.
Expert writers, unlike novice writers, present their views in a more professional manner. We include two measures (INFORMAL and PUNCTUATION) to capture this aspect of review content. INFORMAL measures the degree to which informal language is used, whereas PUNCTUATION captures the total number of punctuation characters in the review. The informal measure is based on early work on code switching, referring to the automatic changes in language, accent, dialect, etc. in social interactions (e.g., Brown and Gilman 1960). Brown and Levinson (1987) developed politeness theory to

study how individuals try to maintain their public face. Biber (1988) found that personal conversations are more informal. Pennebaker and King (1999) identified immediacy, including present tense verbs, first-person singular, and short words as the most significant factors indicating informality. Examples of informal words in a text are words related to swear words/ netspeak/assent/nonfluencies/filler, such as "damn, btw, OK, hm, and Imean."
We return to our main data set on DMA-level sales for the music category and specify the following model to uncover the role of review content and identity:

log(SALESijt) i + 5 log(VOLCUMit-1) + 6 log(VARCUMit-1) + 1 log(VALCUM TOPRANKit-1) + 2 log(VALCUM BOTMRANKit-1) +  log(j)
+  log(VALCUM TOPRANKit-1) × log(j)
+  log(VALCUM BOTMRANKit-1) × log(j)
+  log(CONTENTit) + µ log(VALCUM TOPRANKit-1) × log(CONTENTit) +  log(VALCUM BOTMRANKit-1) × log(CONTENTit) + 3 log(AGEit) × log(VALCUM TOPRANKit-1) + 4 log(AGEit) ×log(VALCUM BOTMRANKit-1) + 5 log(VARCUMit-1) × log(VALCUM TOPRANKit-1) + 6 log(VARCUMit-1) × log(VALCUM BOTMRANKit-1) +  log(Xit) + ijt,
(4)
where

CONTENTit

(WORDCOUNTit, AFFECTIVEit, SOCIALit, INFORMALit, PUCTUATIONit).

This specification includes main effects of the content variables as well as their interactions with the two reviewer groups. It also includes interactions between the valence measures of each reviewer group and product age and review variance. We discuss these results in the next section.
For ease of interpretation given the large number of interactions, we first stratify each variable that is interacted with one of the two valences (VALCUM_TOPRANK or VALCUM_BOTMRANK) and then create the interaction. The interacted variables in our data are continuous measures, so we create corresponding dummy variables. For example, YOUNG = 1 if the proportion of young

Yazdani, Gopinath, and Carson: Preaching to the Choir: The Link Between Reviewer Ranking and Product Sales Marketing Science, 2018, vol. 37, no. 5, pp. 838­851, © 2018 INFORMS

847

Table 6. Impact of Top- and Bottom-Ranked Reviewers on Amazon Sales Rank

Model 3

Variable

Product category:
music
(DV = log(SALES RANKING))a

Product category:
cameras
(DV = log(SALES RANKING))a

PRICE AGE RANK HELPFUL VOLCUM VARCUM VALCUM_TOPRANK VALCUM_BOTMRANK TUESDAY WEDNESDAY THURSDAY FRIDAY SATURDAY SUNDAY No. of observations Within R2 Product fixed effects

1.2030*** (0.2579) 1.0016*** (0.0216) ­0.1434** (0.0550) ­0.5540*** (0.0831) ­0.0310** (0.0098) ­0.3079** (0.1600) ­0.6040 (0.9912) -1.6141** (0.6521) -0.0741** (0.0390) -0.0752** (0.0392) -0.1041** (0.0398) -0.1825*** (0.0411) -0.2188*** (0.0452) -0.1857*** (0.0411)
2,092 0.5069
Yes

2.9806*** (0.2037) -0.0303 (0.0911) 0.1436 (0.2076) 0.0819 (0.1351) 0.1426 (0.1530) 0.0904* (0.0457) 0.0658 (0.0731) -0.5738*** (0.1835) 0.0783** (0.0398) 0.0284 (0.0435) 0.0105 (0.0389) 0.0434 (0.0389) 0.0620* (0.0409) 0.0572* (0.0409)
1,444 0.2682
Yes

Note. Fixed effects are not reported. aThe DV is the Amazon sales ranking; negative coefficients indicate
greater sales. *p < 0.1; **p < 0.05; ***p < 0.01.

individuals in a market is greater than the median across all markets. We implement analogous median splits for all the demographic and content variables as well as cumulative review variance and product age. Next, we interact these dummy variables with the top- and bottom-ranked valence measures. As a result, the coefficients for the interaction terms represent simple shifts in the elasticity between the relevant valence measure and product sales when the corresponding dummy variable takes on a value of one. We show the estimation results in Table 7.
The key takeaways center around the content measures. We find that sales are positively influenced by reviews that are less verbose and more informal (i.e., more informal language and less punctuation), and that have more social and affective content. In addition, several of the interaction effects between the content

and reviewer ranking valence measures are significant. This suggests that the influence of a review is driven by both what is written ( content) and who writes it ( identity).
Next, we explore whether there are clear differences in the content of reviews by top- and bottom-ranked reviewers that might explain their differential effects. Table 8 shows the average scores for the content dimensions of the two groups of reviewers. The last column shows the percentage change in the review content of the bottom-ranked group with the review content of the top-ranked group acting as the reference. The numbers reveal interesting insights. The reviews of bottom-ranked reviewers tend to be less verbose, more informal, more social, and more affective. This is the type of review that has a strong effect on sales as identified above. This provides considerable insight as to why bottom-ranked reviewers have a bigger effect on sales than top-ranked reviewers. Moreover, the differences between the two groups are statistically significant for all content dimensions except the punctuation dimension. Table 8 also reveals that the two groups are very similar to each other in terms of the valence of their reviews and when they review the product.
How Do Product Age and Lack of Review Consensus Moderate the Effect of Top- and Bottom-Ranked Reviewers? Research on the role of product age in an online WOM context has been fairly limited. For example, Liu (2006) finds that the effect of online WOM decreases as the number of days since product introduction increases. In a customer lifetime value context, Villanueva et al. (2008) find that individuals acquired through WOM have greater long-term value than individuals acquired through traditional firm marketing. We add to this literature and the broader product diffusion literature by investigating how product age affects the influence of reviews by top- and bottom-ranked reviewers. As described above, we anticipate that the identity component of reviewer ranking will be more readily accessible for newer products and that the uncertainty associated with newer products will place greater value on the trustworthiness signal associated with top-ranked reviewers. Hence, top-ranked reviewers are expected to have a stronger effect earlier in the product life cycle.
Turning to consensus, when reviews have high variance (i.e., lack consensus), consumers must find a way to sort through the conflicting opinions. As discussed above, the signaling literature suggests that consumers will seek out indications of credibility in situations marked by high uncertainty (Heil and Robertson 1991, Wernerfelt 1988). One way to do this is to put more stock in the opinions expressed by

848

Yazdani, Gopinath, and Carson: Preaching to the Choir: The Link Between Reviewer Ranking and Product Sales Marketing Science, 2018, vol. 37, no. 5, pp. 838­851, © 2018 INFORMS

Table 7. Impact of Review Content, Lack of Review Consensus, and Product Age on Sales

Variable PRICE AGE RANK HELPFUL VOLCUM VARCUM VALCUM_TOPRANK VALCUM_BOTMRANK AFRICAN-AMERICAN CAUCASIAN YOUNG VALCUM_TOPRANK * AFRICAN-
AMERICAN VALCUM_TOPRANK * CAUCASIAN VALCUM_TOPRANK * YOUNG VALCUM_ BOTMRANK * AFRICAN-
AMERICAN VALCUM_ BOTMRANK * CAUCASIAN VALCUM_ BOTMRANK * YOUNG WORD COUNT SOCIAL AFFECT INFORMAL PUNCTUATION VALCUM_TOPRANK * WORD COUNT VALCUM_TOPRANK * SOCIAL VALCUM_TOPRANK * AFFECT VALCUM_TOPRANK * INFORMAL VALCUM_TOPRANK * PUNCTUATION VALCUM_ BOTMRANK * WORD COUNT VALCUM_ BOTMRANK * SOCIAL

Model 4
DV = log(SALES)a
-0.5236** (0.1131) -1.0599*** (0.1456) 0.0490*** (0.0161) 0.0980*** (0.0346) ­0.0715 (1.0123) 0.0997*** (0.0291) 0.0891 (0.0903) 2.9567*** (0.5105) 0.0388 (0.0997) ­0.2143** (0.0990) ­0.0181** (0.0083) ­0.0208 (0.0367) 0.0520 (0.0510) 0.0311** (0.0171) 0.0328** (0.0195) ­0.0592 (0.0711) 0.0398*** (0.0136) ­0.8645*** (0.3650) 1.6905*** (0.6801) 3.9765*** (0.6716) 1.2956*** (0.4052) ­0.6104*** (0.1843) ­0.0465 (0.0590) ­0.1844*** (0.0465) ­0.1849** (0.0877) 0.0382 (0.0565) 0.1470 (0.1541) 0.3457** (0.1603) ­0.5078** (0.2300)

Table 7. (Continued)
Variable VALCUM_ BOTMRANK * AFFECT VALCUM_ BOTMRANK * INFORMAL VALCUM_ BOTMRANK * PUNCTUATION VARCUM * VALCUM_TOPRANK VARCUM * VALCUM_BOTMRANK AGE * VALCUM_TOPRANK AGE * VALCUM_BOTMRANK No. of observations Within R2 Product fixed effects Note. Fixed effects are not reported.
aThe DV is the market (DMA)-level sales. *p < 0.1; **p < 0.05; ***p < 0.01.

Model 4
DV = log(SALES)a
-1.7834 (1.5641) ­0.6718*** (0.2234) 0.3533*** (0.0899) 0.5908* (0.2700) -1.0378*** (0.4802) ­0.2345*** (0.0462) 0.4132*** (0.0811)
52,510 0.5871
Yes

top-ranked reviewers since they possess a level of trustworthiness tied to the maintenance of their reputations. In contrast, when reviews exhibit lower variance, the heterophily between top-ranked reviewers and most ordinary customers suggests that the valence associated with reviews from bottomranked reviewers will become more influential on product sales.
The results for age and review variance also appear in Table 7. There are two key takeaways. First, we see that the effect of top-ranked reviewers on sales decreases as the age of the product increases, whereas the effect of bottom-ranked reviewers grows over time. Next, we find that the effect of bottom-ranked reviewers on sales becomes weaker as variance increases, but the effect of top-ranked reviews increases, suggesting that the top-ranked reviewers are more important when there is a lack of review consensus.
Discussion and Conclusions
The results of the study support the opinion leadership role of top-ranked reviewers, but only in certain circumstances where the general credibility engendered by their ranking is most salient and relevant--for very new products and for products with high review variance. In more typical situations, bottomranked reviewers have a stronger influence on product sales.
One of the main factors limiting the effect of topranked reviewers is the style of their reviews. Topranked reviewers write longer, more formal, and less social and affective reviews, all factors that limit their

Yazdani, Gopinath, and Carson: Preaching to the Choir: The Link Between Reviewer Ranking and Product Sales Marketing Science, 2018, vol. 37, no. 5, pp. 838­851, © 2018 INFORMS

849

Table 8. Top-Ranked Reviewer vs. Bottom-Ranked Reviewer

Content dimension/WOM measure

Top 1,000­ranked reviewer

Bottom-ranked reviewer, with ranking greater than 1,000

WORD COUNT PUNCTUATION AFFECT SOCIAL INFORMAL VALENCE REVIEW_ORDER

333.77 19.15 6.15 6.56 0.47 4.47 29.47

93.91* 18.35 8.48* 8.17* 0.86* 4.52 28.96

aTop-ranked reviewer content/WOM measure is the reference category. *Statistically different at the 5% level for two reviewer groups.

Percentage change in content/WOM measure for bottom-ranked reviewera (%)
-71.86 -4.18 37.89 24.54 82.98
1.11 -1.73

influence. However, the reaction to top-ranked reviewers is also driven by their identity. This suggests that firms can attempt to control the identity effect via policies that influence reviewer ranking awareness while controlling the content effect via policies that influence the content characteristics of reviews.
The results uncovered in this study add considerable insight into the role of top-ranked reviewers (and prolific reviewers in general) beyond the findings currently available in the literature. While these reviewers generate a large volume of WOM and for this reason would seem to be inherently attractive to marketers, their actual influence on sales is much more complex. Our findings extend the work of Chen and Xie (2008), who find no influence of reviewers with a top 1,000 badge on Amazon.com. We similarly find a limited influence of top-ranked reviewers, although we extend their study by (1) finding an opinion leadership role for top-ranked reviewers for very new products and products that lack consensus in current reviews and (2) identifying a much stronger leadership role for ordinary reviewers who are typically cast as followers. These findings suggest that marketers should be extremely cautious if trying to use reviewer rankings alone as a measure of opinion leadership outside of the immediate postlaunch period.
Importantly, the limited effect of top-ranked reviewers on sales calls into question two justifications for focusing marketing efforts on this group: (1) that they are heavy users of the product, or (2) that there is a high enough level of contagion within the group to make up for the limited influence across groups to more mainstream consumers. (1) is unlikely to be true for the vast majority of products sold on large diversified sites like Amazon.com or discussed on highly diversified platforms (e.g., Twitter) since reviewer ranking (or post count, followers, etc.) is based on activities across many product categories or outside the context of purchasing entirely. It may hold to a greater extent on more narrowly focused e-commerce sites or specialized discussion forums. Thus, the context in which top reviewers or top contributors are identified matters.

A detailed examination of the within-group contagion suggested in (2) is beyond the scope of this research, but much more likely to be true. For example, Godes and Mayzlin (2009) explain the influence of prolific reviewers among loyal consumers of a brand by noting the stronger ties among loyal consumers, whereas nonloyal consumers lack such connections. However, the typically low effect on sales that we observe implies that the top-ranked reviewer group is either too limited in size or exhibits too great a level of heterophily with mainstream consumers to justify a marketing focus based on within-group contagion, except in the special cases identified above.
Overall, the results of this study highlight the limitations of simply focusing on reviewers or consumers with strong ties to each other that is prominent in the literature. Bottom-ranked reviewers probably do not possess strong ties amongst themselves as a group but are nevertheless more influential on sales. Our results in this regard are consistent with Katona et al. (2011) who suggest that it is better to focus on groups with more (rather than stronger) connections because they have a greater general influence. An alternative interpretation in our context is that the strong ties among bottom-ranked reviewers are harder to observe. For example, unobserved ties may be present among connoisseurs of the product category. However, in either case, a focus on topranked reviewers as easily identifiable opinion leaders would appear to be severely limited, given the generally smaller effect of reviews from this group on sales.
Limitations and Future Research There are a number of opportunities for future research that emerge from this study. First, the main product category in the present study is a low risk one with hedonic motivations for purchase. Although music is a $15 billion industry and similar to other large industries like movies and video games, it has a unique set of characteristics. As a robustness check we examined the camera category, since this category is more

850

Yazdani, Gopinath, and Carson: Preaching to the Choir: The Link Between Reviewer Ranking and Product Sales Marketing Science, 2018, vol. 37, no. 5, pp. 838­851, © 2018 INFORMS

risky, a more utilitarian good, a durable good, and a higher-involvement product, and showed that the main results hold. Nevertheless, it would be beneficial to examine the relationships of interest in other product categories.
It would also be informative to examine the extent to which top- and bottom-ranked reviewers are transmitting their own opinions or restating the opinions of a very small group of opinion leaders. This can be used as a measure to divide opinion leaders into two groups of initiators and imitators and explore which group has more influence.
Moreover, it would be worthwhile to examine the influence of top- and bottom-ranked reviewers during the prelaunch period, since we showed different effects for very new products. Crowdfunding sites feature discussion among users and measurable outcomes and would thus seem well suited to such an investigation.
Finally, the question about how to incentivize influential disseminators is intriguing. After identifying a target, a firm should determine how to encourage them to "spread the word" about the brand. A careful analysis of the effect of different incentive programs based on the number of referrals made in their social network as well as the content of the reviews generated would be a potentially fruitful endeavor.
Nowadays, consumers can easily share their product experiences via the Internet. Online communities and influencer networks can play an important role in increasing firm profitability, especially if managed properly. Our findings help marketers understand why some reviewers are more impactful than others. In particular, our results show that it is important for a firm to identify, address, and motivate influential WOM disseminators rather than rely on sitewide rankings.
Endnote
1 The risk associated with an overreliance on top rated reviewers is nicely captured by this comment from a consumer on Reddit: "There's a guy who is a top 500 reviewer on Amazon who reviews audio gear--among other things. I'm pretty experienced in audio and can firmly say that the dude has minimal knowledge of what he's talking about and mostly spouts popular rhetoric. He's exposed heavily whenever he reviews audio things out of his `experience' level. . .This guy does 4-5 lengthy audio reviews a month which is not only absurd, but it's damn near impossible to put out an informed opinion on something that often. I'd say 2 weeks is about the minimum you'd have to have headphones to fully understand their technical abilities" (https://www.reddit.com/r/Frugal/comments/ 45tg81/how_do_i_become_one_of_those_amazon_product).
References
Berger J, Milkman KL (2012) What makes online content viral? J. Marketing Res. 49(2):192­205.
Biber D (1988) Variation Across Speech and Writing (Cambridge University Press, Cambridge, UK).

Bloch PH, Richins ML (1983) A theoretical model for the study of product importance perceptions. J. Marketing 47(3):69­81.
Brown R, Gilman A (1960) The pronouns of power and solidarity. Sebeok TA, ed. Style in Language (MIT Press, Boston), 253­276.
Brown P, Levinson SC (1987) Politeness: Some Universals in Language Usage (Cambridge University Press, Cambridge, UK).
Cegala DJ (1989) A study of selected linguistic components of involvement in interaction. Western J. Speech Comm. 53(3):311­326.
Chan KK, Misra S (1990) Characteristics of the opinion leader: A new dimension. J. Advertising 19(3):53­60.
Chen Y, Xie J (2008) Online consumer reviews: Word-of-mouth as a new element of marketing communication mix. Marketing Sci. 54(3):477­491.
Cheung ME, Luo C, Sia CL, Chen H (2009) Credibility of electronic word-of-mouth: Informational and normative determinants of on-line consumer recommendations. Internat. J. Electronic Commerce 13(4):9­38.
Chevalier JA, Mayzlin D (2006) The effect of word of mouth on sales: Online book reviews. J. Marketing Res. 43(3):345­354.
Chintagunta PK, Gopinath S, Venkataraman S (2010) The effects of online user reviews on movie box office performance: Accounting for sequential rollout and aggregation across local markets. Marketing Sci. 29(5):944­957.
Cialdini RB (2000) Influence: Science and Practice, 4th ed. (HarperCollins, New York).
Clemons EK, Gao GG, Hitt LM (2006) When online reviews meet hyperdifferentiation: A study of the craft beer industry. J. Management Inform. Systems 23(2):149­171.
Cohn MA, Mehl MR, Pennebaker JW (2004) Linguistic markers of psychological change surrounding September 11, 2001. Psych. Sci. 15(10):687­693.
Dellarocas C, Zhang X, Awad N (2007) Exploring the value of online product reviews in forecasting sales: The case of motion pictures. J. Interactive Marketing 21(4):23­45.
Dellarocas C, Narayan R (2006) A statistical measure of a population's propensity to engage in post-purchase online word-ofmouth. Statist. Sci. 21(2):277­285.
Duan W, Gu B, Whinston AB (2008) The dynamics of online word-ofmouth and product sales: An empirical investigation of the movie industry. J. Retailing 84(2):233­242.
Feder G, Savastano S (2006) The role of opinion leaders in the diffusion of new knowledge: The case of integrated pest management. World Development 34(7):1287­1300.
Fishbein M, Ajzen I (1975) Belief, Attitude, Intention, and Behavior: An Introduction to Theory and Research (Addison-Wesley, Boston).
Gilbert E, Karahalios K (2010) Understanding deja reviewers. Proc. 2010 ACM Conf. on Computer Supported Cooperative Work, (ACM, New York), 225­228.
Giles H, Coupland N (1991) Language: Contexts and Consequences (Brooks/Cole, Pacific Grove, CA).
Godes D (2011) Commentary: Invited comment on "Opinion leadership and social contagion in new product diffusion." Marketing Sci. 30(2):224­229.
Godes D, Mayzlin D (2004) Using online conversations to study word-of-mouth communication. Marketing Sci. 23(4):545­560.
Godes D, Mayzlin D (2009) Firm-created word-of-mouth communication: Evidence from a field test. Marketing Sci. 28(4):721­739.
Goldenberg J, Lehmann DR, Shidlovski D, Barak MM (2006). The role of expert vs. social opinion leaders in new product adoption. Working paper, Marketing Science Institute, Cambridge, MA.
Gopinath S, Chintagunta PK, Venkataraman S (2013) Blogs, advertising, and local-market movie box office performance. Management Sci. 59(12):2635­2654.
Gopinath S, Thomas JS, Krishnamurthi L (2014) Investigating the relationship between the content of online word of mouth, advertising, and brand performance. Marketing Sci. 33(2): 241­258.

Yazdani, Gopinath, and Carson: Preaching to the Choir: The Link Between Reviewer Ranking and Product Sales Marketing Science, 2018, vol. 37, no. 5, pp. 838­851, © 2018 INFORMS

851

Guadagno RE, Cialdini RB (2003) Online persuasion and compliance: Social influence on the Internet and beyond. AmichaiHamburger Y, ed. The Social Net: The Social Psychology of the Internet (Oxford University Press, Oxford, UK), 91­113.
Heil O, Robertson TS (1991) Toward a theory of competitive market signaling: A research agenda. J. Strategic Management 12(6):403­418.
Ho-Dac NN, Carson SJ, Moore WL (2013) The effects of positive and negative online customer reviews: Do brand strength and category maturity matter? J. Marketing 77(6):37­53.
Humphreys A (2010) Megamarketing: The creation of markets as a social process. J. Marketing 74(2):1­19.
Iyengar R, Van den Bulte C, Valente TW (2011) Opinion leadership and social contagion in new product diffusion. Marketing Sci. 30(2):195­212.
Katona Z, Zubcsek PP, Sarvary M (2011) Network effects and personal influences: The diffusion of an online social network. J. Marketing Res. 48(3):425­443.
Katz E, Lazarsfeld P (1955) Personal Influence (Free Press, New York). King CW, Summers JO (1970) Overlap of opinion leadership across
consumer product categories. J. Marketing Res. 7(1):43­50. Liu Y (2006) Word of mouth for movies: Its dynamics and impact on
box office revenue. J. Marketing 70(3):74­89. Ludwig S, de Ruyter K, Friedman M, Bruggen EC, Wetzels M, Pfann
G (2013) More than words: The influence of affective content and linguistic style matches in online reviews on conversion rates. J. Marketing 77(1):87­103. Luo X (2007) Consumer negative voice and firm-idiosyncratic stock returns. J. Marketing 71(3):75­88. McGuire WJ (1969) Handbook of Social Psychology, Vol. 3 (AddisonWesley, Reading, MA).

Moe WW, Trusov M (2011) The value of social dynamics in online product ratings forums. J. Marketing Res. 48(3):444­456.
Pennebaker JW, Booth RJ, Francis ME (2007) Linguistic Inquiry and Word Count (LIWC): LIWC2007 (Lawrence Erlbaum Associates, Mahwah, CT).
Pennebaker JW, King LA (1999) Linguistic styles: Language use as an individual difference. J. Personality Soc. Psych. 77(6):1296­1312.
Pennebaker JW, Mehl MR, Niederhoffer KG (2003) Psychological aspects of natural language use: Our words, our selves. Annual Rev. Psych. 54:547­577.
Pinch T, Kesler F (2011) How Aunt Ammy gets her free lunch: A study of the top-thousand customer reviewers at Amazon.com. Working paper, http://Truthinadvertising.org.
Slatcher RB, Pennebaker JW (2006) How do I love thee? Let me count the words: The social effects of expressive writing. Psych. Sci. 17(8):660­664.
Sun M (2012) How does the variance of product ratings matter? Management Sci. 58(4):696­707.
Susarla A, Oh JH, Tan Y (2012) Social networks and the diffusion of user-generated content: Evidence from YouTube. Inform. Systems Res. 23(1):23­41.
Tirunillai S, Tellis GJ (2012) Does chatter really matter? Dynamics of user-generated content and stock performance. Marketing Sci. 31(2):198­215.
Villanueva J, Yoo S, Hanssens DM (2008) The impact of marketinginduced vs. word-of-mouth customer acquisition on customer equity growth. J. Marketing 45(1):48­59.
Wernerfelt B (1988) Umbrella branding as a signal of new product quality: An example of signaling by posting a bond. RAND J. Econom. 19(3):458­466.

