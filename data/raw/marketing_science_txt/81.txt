http://pubsonline.informs.org/journal/mksc

MARKETING SCIENCE
Vol. 38, No. 5, September­October 2019, pp. 793­811 ISSN 0732-2399 (print), ISSN 1526-548X (online)

Advertising Strategy in the Presence of Reviews: An Empirical Analysis

Brett Hollenbeck,a Sridhar Moorthy,b Davide Proserpioc
a Anderson School of Management, University of California Los Angeles, Los Angeles, California 90095; b Rotman School of Management, University of Toronto, Toronto, Ontario M5S 3E6, Canada; c Marshall School of Business, University of Southern California, Los Angeles, California 90089 Contact: brett.hollenbeck@anderson.ucla.edu, http://orcid.org/0000-0001-9848-9366 (BH); moorthy@rotman.utoronto.ca,
http://orcid.org/0000-0001-5251-9961 (SM); proserpi@marshall.usc.edu, http://orcid.org/0000-0002-9271-067X (DP)

Received: November 23, 2017 Revised: November 23, 2018; March 14, 2019 Accepted: April 19, 2019 Published Online in Articles in Advance: September 10, 2019
https://doi.org/10.1287/mksc.2019.1180
Copyright: © 2019 INFORMS

Abstract. We study the relationship between online reviews and advertising spending in the hotel industry. Combining a data set of TripAdvisor reviews with other data sets describing these hotels' advertising expenditures, we show, first, that online ratings have a causal demand-side effect on ad spending. Second, this effect is negative: hotels with higher ratings spend less on advertising than hotels with lower ratings. This suggests that hotels treat TripAdvisor ratings and advertising spending as substitutes, not complements. Third, the relationship is stronger for independent hotels than for chains, and stronger in less differentiated markets than in more differentiated markets. The former suggests that a strong brand name continues to provide some immunity to reviews and the latter that the advertising response is stronger when ratings are more likely to be pivotal. Finally, we show that the relationship between online ratings and advertising has strengthened over time, just as TripAdvisor has become more popular, implying that firms respond to online reviews if and only if consumers respond to them.

History: K. Sudhir served as the editor-in-chief and David Godes served as associate editor for this article.
Funding: B. Hollenbeck was supported by the Morrison Center for Marketing and Data Analytics, and S. Moorthy was supported by the Social Sciences and Humanities Research Council of Canada.
Supplemental Material: Data and the online appendix are available at https://doi.org/10.1287/ mksc.2019.1180.

Keywords: advertising · online reviews · TripAdvisor · hotels

1. Introduction
Over the last 15 years, one of the major developments in the consumer's shopping environment has been the growth and proliferation of online review platforms such as TripAdvisor and Yelp, providing independent quality information on experience goods. According to the Pew Research Center, in 2016, 82% of U.S. adults read online reviews occasionally or regularly before purchasing a product for the first time; 40% did so almost always.1 The ready availability of experiential information from past users and professional reviewers is a potentially significant demand shock affecting firms in many industries. Effectively, experience goods have become search goods. This raises many questions, among them, how does this change in the consumer's information environment affect the advertising strategy of firms? Do they target the informed consumer or the uninformed consumer? What is the relationship, if any, between the information on quality revealed in online reviews and firms' advertising spending decisions, and how has this changed over time as online review platforms have become

more popular? In this paper, we report on these questions in the context of the hotel industry.
The theoretical relation between product quality and advertising spending is complex. This is because there are multiple forces pulling in different directions: (i) Nelson's (1970, 1974) "signaling effect," which argues for a positive relation between advertising spending and quality because only firms with high quality products would be willing to invest in advertising; (ii) supply-side effects, which arise as soon as advertising has a direct demand-enhancing role, such as raising awareness, and these tend to be negative if marginal production costs are increasing in quality and/or capacity constraints more likely to bind at higher quality levels (Zhao 2000; Horstmann and Moorthy 2003; Bagwell 2007, p. 1777); (iii) demandside effects, which arise whenever at least some consumers are informed about quality before purchase, and these can be positive (Archibald et al. 1983, Lei 2015, Linnemer 2002) or negative (Horstmann and Moorthy 2003, Chen and Xie 2005); (iv) interactions between the two, which can lead to a net positive or

793

794

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

negative effect (Schmalensee 1978, Horstmann and Moorthy 2003); and, finally, (v) strategic interactions in prices and advertising among firms, which can lead to strategic complementarity or strategic substitutability effects (Chen and Xie 2005, Lei 2015).
Perhaps reflecting these difficulties, past empirical studies have failed to show a consistent advertising spending­quality relationship. For instance, Rotfeld and Rotzoll (1976), looking at 12 convenience-goods categories, find a positive correlation between advertising and quality (as reported in Consumer Reports and Consumers Bulletin) among all brands--advertising and nonadvertising--but not within the subset of brands that advertise. Caves and Greene's (1996) more comprehensive study of nearly 200 categories reports median correlations around zero.
Online data from review platforms such as TripAdvisor present a unique opportunity to get a clearer picture of the multiple forces at work. They allow us to identify a causal effect of perceived quality on advertising spending and to label it as a demand-side effect. Both accomplishments stem from the same feature of the data: TripAdvisor rounds up or down the average ratings of reviewers to the nearest whole or half ratings (on a 5-star scale) and displays only those rounded ratings to users. What the consumer sees are these whole and half ratings--1, 1.5, . . . , 4.5, 5 stars-- not the average ratings underlying them.2 This has two effects: (i) it creates a dissociation between perceived quality (displayed ratings) and "actual quality" (average ratings; see Figure 1), and (ii) it provides us with a ready-made regression-discontinuity design (RDD) to identify a causal effect. By focusing on the random, discrete variation in perceived quality around the discontinuities--when the average rating changes from, say, 3.24 (displayed rating, 3) to 3.25 (displayed rating, 3.5)--and measuring the effect of this variation on advertising spending, we identify a causal effect of perceived quality on advertising spending.3 Furthermore, this is self-evidently a demand-side effect: whereas "large variations" in average ratings can have both demand- and cost-side effects on advertising spending,4 small, local variations that produce "big" variations in displayed ratings can be plausibly characterized only as demand-side effects.5
The hotel industry is an ideal setting to study the relationship between online reviews and advertising for several reasons. First, it was one of the earliest adopters of online reviews. A large corpus of reviews has accumulated, showing good variation both in the cross section and in the time series. Second, because hotels are experience goods and serve people who live in many, widely dispersed locations, online word of mouth is comparatively more important than offline word of mouth. Finally, the industry is large and important in its own right. Hotels generated $196

Figure 1. (Color online) How Perceived Quality Varies with Actual Quality at TripAdvisor
billion in sales and employed 2 million individuals in 2012 according to the U.S. Economic Census. The industry also spent $2.1 billion on advertising in 2015 (Powell and Quinby 2015). Therefore, even apart from what we learn about the relationship between advertising and quality, the hotel industry is of some interest purely as a case study.
Our empirical analysis is based on four data sets, one comprising TripAdvisor hotel reviews, two others containing detailed information on the advertising strategies of the hotels featured in those reviews, and the fourth describing various characteristics of the hotels. The review data set contains all U.S. hotels listed on TripAdvisor between 2002 and 2015, and the advertising data sets include information about hotels' monthly advertising spends, disaggregated by media--TV, newspapers, magazines, radio, outdoor, and internet display and search advertising (the last of these, only for independent hotels). Collecting and matching these data sets allows us to conduct the first time-series, cross-sectional study of the empirical relationship between online ratings and firms' advertising strategies. This is noteworthy because our data are not just a sample of a particular market in a particular period of time, but rather the entire experience of an industry over virtually the entire time online reviews have existed.
Our main results are the following: First, total ad spending by hotels in our measured media has fallen slightly from 2002 to 2015. The fall is quite sharp in traditional advertising--print and television, mainly-- but this is largely offset by the growth in internet

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

795

search and display advertising. Extrapolating from the last observation, because our advertising data do not cover several media that came into existence only after 2002--for example, social media, mobile advertising, and online video--overall ad spending by hotels has probably increased over this 14-year period.
Second, we find a distinct inverse-U-shaped relationship between hotels' average ratings and ad spending, both in traditional media and in online advertising. This is consistent with previous studies in the literature that have also documented a crosssectional inverse-U relationship between quality and advertising spending (Horstmann and Moorthy 2003). However, our most important and novel result is the negative causal relationship we observe between displayed TripAdvisor ratings and advertising spending. Hotels with higher displayed ratings spend less than hotels with lower displayed ratings around the TripAdvisor rounding thresholds. This effect is observed in all the traditional media as well as in internet display and search advertising. Furthermore, it operates both at the extensive margin (decision to advertise) as well as at the intensive margin (advertising level given advertising). Together, these results suggest a substitution relationship between online ratings and advertising spending: hotels with "good" ratings treat their ratings as a substitute for advertising spending, whereas hotels with relatively poor ratings treat advertising as a substitute for their ratings. Effectively, hotels with higher ratings are targeting the informed consumer who gets her information from TripAdvisor, whereas hotels with lower ratings are targeting the uninformed consumer via advertising.
Two factors moderate the substitution relationship: First, the relationship is stronger for independent hotels than for chains, consistent with prior research showing that online reviews have larger effects on independent hotels' sales than on chain hotels' sales (Hollenbeck 2018). Apparently, a strong brand name continues to provide some immunity to reviews, as has been found in other contexts as well, such as movies (Dhar and Moorthy 2017). Second, when we examine how the ratings­advertising relationship operates in different markets, we find that less differentiated markets, that is, markets with hotels' ratings tightly bunched together, show a stronger relationship, suggesting that ratings have a bigger effect on ad spending when they are more likely to be pivotal.
Finally, comparing the relationship between online ratings and advertising spending in the early years of TripAdvisor (2002­2005) to what it became in later years (2012­2015), we find that the relationship has strengthened. During this period, review platforms have become more popular, and the proportion of informed consumers has almost certainly grown.

Apparently, when this proportion was small, both highand low-quality hotels probably found it optimal to ignore this consumer and target the uninformed consumer instead. Now, however, the informed segment is too large to ignore, and this, perhaps in conjunction with capacity constraints, causes the advertising strategies of the high- and low-quality hotels to separate (Horstmann and Moorthy 2003, Lei 2015). Ultimately, the basic message is that firms will respond to their online ratings if and only if consumers do.
2. Background
As noted earlier, survey evidence shows that a large number of people consult online reviews before making purchase decisions. Consistent with this, a number of empirical studies show that online reviews affect sales. This includes those by Anderson and Magruder (2012) and Luca (2016), who, using the same RDD strategy we follow, find that higher-rated restaurants enjoy higher sales than lower-rated restaurants. The demand-side literature also includes Chevalier and Mayzlin (2006) and Sun (2012) for books, Jin and Kato (2006) and Cabral and Hortaçsu (2010) for eBay auctions, and Lewis and Zervas (2016) for hotels. Luca (2016) shows, in addition, that the demand effect of online reviews is particularly strong for independent restaurants (compared with chain restaurants). In a similar vein, Hollenbeck (2018) shows that online reviews have significantly reduced the revenue premium enjoyed by hotel chains over independent hotels.
In contrast to this large literature showing the effect of online reviews on demand, there is relatively little work on how online reviews affect firms' actions. This is an important lacuna: not only is the effect of online reviews on firm behavior interesting in its own right, it also has implications for the literature on consumer response. If firms change their pricing, advertising, or other actions when their ratings change, prior work documenting an effect of ratings on sales might actually be documenting the combined effect of ratings and firm response.6 One setting where firms' responses to ratings has been studied is eBay, but even here, the focus has been on price responses only (Melnik and Alm 2002, Houser and Wooders 2006, Resnick et al. 2006). Arguably, eBay auctions are unique in several respects, not the least being that sellers on the platform tend to be small and online only. One non-eBay paper is by Lewis and Zervas (2016), who use TripAdvisor data to show that hotel prices increase in response to online ratings. Lei (2017) analyzes Yelp restaurant ratings data from 2014 using methodology similar to ours and finds, like us, that displayed ratings have a negative effect on advertising spending in the cross section.

796

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

On the theoretical side, we have the studies by Chen and Xie (2005, 2008) and Lei (2015). The first is a duopoly model with horizontal and vertical differentiation, the second is a monopoly matching model in two dimensions, and the third is a duopoly model with vertical differentiation. In the first, reviews are assumed to provide accurate information about product quality, whereas advertising can mislead those who do not read reviews. In the second, reviews provide information comprehensively (i.e., on both product dimensions) but may or may not be accurate, whereas advertising-supplied information is accurate but may or may not be comprehensive. In the third, reviews provide unbiased signals of underlying quality, and advertising creates awareness and directs advertising-sensitive consumers to reviews. The central concern of the two papers by Chen and Xie (2005, 2008) is what happens to advertising strategy as reviews become available; that is, they focus on a time-series prediction. By contrast, Lei's (2015) paper focuses on cross-sectional variation in advertising strategy between a "high-quality" firm and a "lowquality" firm. The main result of the first paper is that when reviews can be incorporated into ads but the horizontal differentiation is so strong that prices do not change when reviews are published, then both the low-quality and the high-quality firm reduce their advertising expenditures. The second paper argues that information provided in ads may increase or decrease as reviews become available. Finally, the third paper shows that many kinds of equilibria are possible--neither firm advertising, only the firm with better (worse) reviews advertising, and both firms advertising (advertising is assumed to be a binary decision).
As noted in the introduction, the present work is also related to the large empirical literature relating advertising spending to product quality. As far as we know, none of this work has used online ratings as a measure of quality--the typical study predates the internet era (Rotfeld and Rotzoll 1976, Caves and Greene 1996, Moorthy and Zhao 2000, Horstmann and Moorthy 2003). Furthermore, these studies are correlational, not causal. As such, they are unable to separate the cost-side effects of quality from its demand-side effects. Our regression discontinuity design allows us to identify a causal effect, and because the variation we exploit is a "local" variation in average ratings, we can be confident that what we are finding is a demand-side effect, and not a cost-side effect.
3. Data
To study the effect of online ratings on hotels' advertising spending empirically, we examine data from four sources: TripAdvisor, Kantar Media, SpyFu, and STR.

3.1. TripAdvisor
We begin with TripAdvisor because our unit of analysis is a hotel property reviewed on TripAdvisor in the 2002­2015 period.7
Launched in 2000, TripAdvisor is now one of the most popular review platforms on the internet.8 In an average month, it has about 350 million unique visitors worldwide.9 In addition, TripAdvisor's ratings are widely displayed on other travel search platforms such as Hotels.com, Orbitz, Travelocity, and Expedia.com. As of May 2016, TripAdvisor had over 500 million customer reviews on over 6 million accommodations, restaurants, and attractions.
We created a script to search and scrape all data on TripAdvisor for accommodation properties (hotels, bed-and-breakfasts, inns) located in the United States. This yielded reviews on 91,783 hotel properties; 82,589 of these had at least one review in the January 2002­ December 2015 period. The total number of timestamped reviews is 13,947,126.
3.2. Kantar Media
Advertising spending data from Kantar Media (and its previous incarnations, TNS Media Intelligence, and LNA) have been the basis of a number of studies in the literature (e.g., Caves and Greene 1996, Shum 2004, Kim and McAlister 2011, Honka et al. 2017). Our Kantar data set covers all the traditional advertising media--TV, radio, magazines, newspapers, and outdoor--plus internet display advertising.10 Missing are several newer media: search advertising, social media advertising, mobile advertising, email advertising, and online video advertising. (The first of these we partially remedy with data from SpuFu, discussed below.) Kantar's methodology is essentially a bottomup approach, combining direct monitoring of ads and information supplied by media outlets.
Monthly advertising expenditures, by media, are available for each hotel brand and "product," brand being a higher-level aggregation than product. Generally, a product refers to a specific hotel property, but more generally it refers to a specific "advertised product." For example, for Best Western Hotels, the brand is "Best Western Hotels," and there are over 100 advertised products, including "Best Western Hotels: Bethlehem PA," "Best Western Hotels: Online," and "Best Western Hotels & Minnesota State Tourism: Combo."11 Brand ad expenditure is the sum of all product ad expenditures under the brand. We obtained monthly advertising expenditures for 16,852 brand­product pairs in the 2002­2015 period. From this data set, we remove products containing the term "Combo" because such products include advertising spending on two or more brand­product pairs. This leaves us with 15,973 distinct brand­ product pairs.

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

797

3.3. SpyFu SpyFu is a company that tracks online search advertising; it provided us our online search advertising data. The company's methodology is to search millions of keywords on Google, Bing, and Yahoo and record the URLs these searches return, along with their positions in paid (and organic) listings. From this raw material, they obtain estimates of monthly search advertising spending by each URL using Google's Keyword Planner tool.12 Their reach is extensive and includes even very specific keywords such as "Dockside Inn Fort Pierce" or "hotel New Brunswick." The chief limitation of these data is that only independent hotels' search advertising spending can be examined; chain hotels' property-specific search ad spending numbers cannot be obtained because SpyFu does not provide ad spending estimates at the subURL level.13
To use the SpyFu data, we proceeded as follows. First, from TripAdvisor, we obtained each property's homepage URL.14 This yielded about 31,000 URLs, out of which 10,398 were for independent hotels. Then, using the SpyFu API, we obtained search advertising spending information for all the independent hotels for which SpyFu had this information. This procedure yielded monthly search advertising spending data on 9,718 independent hotels.
3.4. STR Finally, from STR, a company that tracks the hotel industry, we obtain (1) a list of all the hotel chains in the United States, along with the number of properties in each chain; (2) basic census data for a large fraction of U.S. hotel properties, including hotel name, location, price category, class, ownership, and capacity, among others;15 and (3) a panel of hotel prices (average daily rates (ADRs)) at the hotel-year-month level for a subset of hotels in the STR census--the ones that chose to report such information to STR.
3.5. Matching the Data Sets The first step in using these four data sets is to match them up, starting with our unit of analysis, a TripAdvisorreviewed hotel.
3.5.1. Matching Kantar with TripAdvisor. This match poses the biggest challenge because, whereas TripAdvisor provides detailed information--exact name and address--for each hotel, Kantar's ad spending numbers are organized by brand­product, a much less precise hotel designation. For chain hotels, especially, this is a serious problem because we do not want to conflate chain-wide advertising (which is unlikely to react to property-specific reviews) with propertyspecific advertising.

To perform this match at scale, we use the following algorithm:
1. Perform a Google search for each Kantar brand­ product and examine the URLs of the top 10 search results.
2. Identify the subset of those URLs that correspond to a TripAdvisor hotel URL.
3. Extract the TripAdvisor hotel ID(s) of those URL(s).
4. If the TripAdvisor hotel ID extracted is unique, the algorithm returns the pair (TripAdvisor ID, Kantar brand­product ID) as a possible match; if the TripAdvisor hotel ID extracted is not unique, then we cannot match this Kantar brand­product, so we do not consider the advertising numbers associated with it. By this process, we identified 10,470 Kantar brand­ products matched uniquely to specific TripAdvisor properties.
5. Compute a similarity score between the Kantar brand­product name and the TripAdvisor hotel name and retain only those matches that show "high similarity."
Finally, we manually checked the output of the algorithm for correctness.
This algorithm ends up matching 6,312 Kantar brand­products with 5,666 TripAdvisor hotel properties, which is 40% of the total Kantar sample. The large attrition is due to the fact that the full Kantar sample contains many brand­products that are not uniquely matchable to specific TripAdvisor properties.16 Out of the 5,666 TripAdvisor hotel properties correctly matched, 5,563 received a review before the year 2016; in total, these 5,563 hotels had 3,308,450 reviews, or about 594 reviews per hotel.
Using these matches, we proceeded to construct a monthly panel of hotel ratings and advertising spending. The final data set contains 762,233 hotelyear-month observations for 5,563 TripAdvisor hotels (4,020 independent, 1,543 chains) that were reviewed between January 2002 and December 2015. Most of the analysis we present below is based on this data set.
3.5.2. Adding STR Information. We augment the above data set with information from the STR census. Matching hotels between TripAdvisor and STR is a much easier task because both data sets contain hotel names and complete addresses. This matching yields 3,996 hotels (about 72% of 5,563). Out of these 3,996 hotels, STR provided us with financial information (prices) for 2,810 hotels.
3.5.3. Adding SpyFu Advertising Spending. Out of the 9,718 independent hotels for which we have SpyFu data, 3,520 can be linked through the TripAdvisor hotel ID to the 4,020 independent hotels in the

798

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

Figure 2. Comparing Average Advertising Spending by Media for All Hotels in the Full Kantar Sample and the Matched Sample

0.14 in both the full and matched samples, and the fraction of chain hotels is 0.27 in the full sample and 0.26 in the matched sample. These results reassure us that our matched sample is quite similar to the full Kantar sample.

Kantar­TripAdvisor matched data set. For these 3,520 independent hotels, then, we have a substantially complete advertising profile: advertising spending in all the traditional media as well as advertising spending in internet display and internet search.
Besides this more comprehensive data set, we also created a supplementary data set to focus on search advertising specifically. This data set contains TripAdvisor ratings and search ad spending information for 9,008 independent hotels over 10 years (from 2006 to 2015), a total of 439,506 hotel-year-month observations. We use this second data set to check whether the search advertising results obtained on the smaller Kantar-matched data set generalize to the larger data set as well.
3.6. Checks for Matching Bias and Selection We compare the matched data set to the full Kantar data set to see whether our matching process produced any systematic distortions. First, we compare the average advertising spending levels in the different media (internet display, outdoor, print, radio, and TV) in the matched and full Kantar samples in Figure 2. In general, although ad spending in each medium is smaller in the matched sample than in the full Kantar sample, the distribution is quite similar: outdoor and print are the media where hotels spend the most, and internet display, radio, and TV are the media where they spend less. Second, we compare the hotel class distributions for hotel chains in the matched and full Kantar samples in Figure 3.17 These distributions are also similar. Finally, we compare the two samples on average fraction of months with positive advertising and fraction of chains. The average fraction of months with positive advertising is

4. Descriptive Evidence
In this section, we describe the general patterns in the ratings and advertising data, starting in Table 1 with a comparison of summary statistics between 2002 (the start of our data) and 2015 (the end of our data). Comparing these two time periods shows how user ratings and advertising spending have changed over a 14-year period.
First, both average hotel rating and number of reviews have increased over time. Ratings increased by about 0.2 stars, whereas the number of reviews grew exponentially from about 2 reviews per hotel in 2002 to over 550 per hotel in 2015. Second, spending on traditional media decreased over the same period. Average monthly spending per property in the traditional media--print, radio, TV, and outdoor--decreased by about 56% from 2002 to 2015, from about $2,000/ month in 2002 to about $850/month in 2015.18 This decrease was particularly pronounced for print advertising, followed by outdoor and TV advertising spending; see Figure 4. The decrease in ad spending in traditional media is offset, however, by a large increase in online advertising. Internet display advertising shows a steep increase of about 116%, and search advertising (by independent hotels) shows an even steeper increase, from essentially zero in 2002--our data do not begin until 2006--to about $1,150 per month by 2015.19
Figure 5 shows monthly average advertising spending in the Kantar sample by different types of hotels:
Figure 3. Comparing STR Class Distribution for Hotel Chains in the Full Kantar Sample and the Matched Sample

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

799

Table 1. Summary Statistics

2002

2015

Hotels

2,805

Fraction of months with advertising

0.18

Fraction of hotels reviewed

0.25

Ratings and reviews

Avg hotel rating

3.89

Avg reviews per hotel

1.71

Average monthly advertising expenditure per hotel ($)

Internet display

73

Print

1,576

Outdoor

202

Radio

30

Television

40

Total (Kantar Media) Internet searcha

1,921 1,326

5,446 0.12 1.00
4.08 558.07
162 526 94 35 33 849 1,153

Note. Average (Avg) hotel rating and average reviews per hotel are based on end-of-year numbers.
aAs noted earlier, our internet search advertising data are only for independent hotels, and they do not begin until 2006. Therefore, the first column, in this case, refers to the year 2006. Comparing the numbers in this row to the more detailed picture presented in Figure 4, we see that the decline in internet search advertising from 2006 to 2015 is largely spurious.

Finally, the relationship between advertising spending (in the Kantar Media) and TripAdvisor ratings is plotted in Figure 6 for two time periods, the years 2002­2005 and the years 2012­2015. Comparing the two panels, the relationship between ratings and ad spending is very noisy in the early years, whereas it coalesces into a fairly well-defined inverted-U shape in the later years. A similar pattern is evident for search advertising by independent hotels in Figure 7. (In both figures, even in the later years, there is a lot of noise at the low ratings end, reflecting the small sample sizes there.) Because review platforms' influence has steadily increased over the years (Lewis and Zervas 2016), this suggests that hotels started reacting to TripAdvisor reviews only after consumers started responding to them.20 And once they start doing so, an inverted-U relationship between ad spending and average ratings emerges. This relationship is reminiscent of previous results in the literature such as Horstmann and Moorthy (2003), and suggests the multiple forces at work. What starts out as a complementarity relationship ends up as a substitutability relationship.

different hotel classes and independent versus chain hotels. Luxury hotels advertise the most, spending almost as much as all the other hotel tiers combined; they also decline the most. Comparing chains to independent hotels, ad spending, excluding internet search, decreased more for the former. Figures 1 and 2 in Online Appendix B shows that if search advertising is included, total ad spending does not fall as much.

5. Empirical Framework
We estimate a causal effect of online ratings on advertising spending by using a RDD. As noted in the introduction, the RDD exploits the rounding rule TripAdvisor uses to convert average ratings into displayed ratings. Specifically, TripAdvisor's displayed ratings are the average ratings of reviewers rounded to the nearest half or full star. Thus, for example, a hotel with an average rating of 3.74 is shown as a

Figure 4. (Color online) Average Year-Month Ad Spending by Media Channel

Notes. Each black line represents a linear fit and the grey shade the 95% confidence interval. Note that internet search advertising covers independent hotels only.

800

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

Figure 5. Year-Over-Year Average Monthly Ad Spending in the Kantar Media by Hotel Class and Hotel Type (Independent vs. Chain)

Note. Internet search advertising and advertising in several other digital media are not included.

3.5-star hotel, whereas a hotel with an average rating of 3.75 stars is shown as a 4-star hotel. If we assume that average ratings are an unbiased estimate of the true quality of a hotel, but subject to sampling variation, then this rounding mechanism creates discrete, random variations in perceived quality around the rounding thresholds that is effectively independent of a hotel's true quality (see Figure 1). To the extent hotels' marginal costs depend on quality, they depend on true quality, not the small sampling variations in average ratings around the rounding thresholds. Therefore, any variation in a firm's advertising level that correlates with average ratings around those rounding thresholds represents a causal demand-side effect of perceived quality, not a cost-side effect stemming from variations in true quality.

5.1. RDD Specification We estimate the following specification:
log Ad Spendingit 1Above Thresholdit + 2Avg Ratingsit (1) + 3Above Thresholdit × Avg Ratingsit + i + t + it.
Here, t refers to the beginning of a month. Thus, AvgRatingsit is the average rating of hotel i at the beginning of month t. The dependent variable, however, aggregates ad spending over the subsequent six months, that is, log Ad Spendingit is the logarithm of total advertising spending by hotel i in the period [t, t + 6 months]. We do this aggregation because (i) ads are purchased before they are delivered, and

Figure 6. Relationship Between Advertising Spending (Kantar Media) and Hotel Ratings: 2002­2005 vs. 2012­2015

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

801

Figure 7. Relationship Between Search Advertising Spending and Hotel Ratings: 2006­2009 vs. 2012­2015 (Independent Hotels Only, Kantar-Matched SpyFu Data)

the lead-time between purchase and delivery, we conjecture, might be anywhere from 0 to 6 months, depending on the ad medium, and (ii) aggregating over six months reduces noise in the variable.21
AboveThresholdit, whose coefficient is the main object of interest, is an indicator of whether the average rating of hotel i at time t falls above the rounding threshold or below it. The inclusion of separate slopes for average ratings above and below the threshold allows for a more flexible specification; it increases our confidence that 1 actually represents the difference in advertising spending between hotels that differ by a half star in their displayed ratings. All specifications include year-month fixed effects, t, and brand fixed effects,22 i.
To estimate Equation (1), we made two important design choices with respect to the RDD. First, taking advantage of the large data set available to us, we limited attention to hotels that are within 0.05 stars of each rounding threshold--a very small bandwidth for a RDD. Second, to reduce sampling variance in the average ratings, we limit all our analyses to hotels with 20 or more reviews. In Section 7, we discuss additional tests to check for the robustness of our estimates to different functional forms, bandwidths, and different aggregation windows of the dependent variable.
5.2. Identification Tests Our RDD regression's identification of a causal effect relies on the assumptions that (i) expected advertising spending given average rating, as a function of

average rating, is continuous around the rounding thresholds, both under the "treatment"(displayed rating is "high") and not under the treatment (displayed rating is "low"), and (ii) hotels do not select into the treatment based on the anticipated advertising effect.23
As McCrary (2008) observed, the latter assumption can fail if hotels can manipulate their average ratings around the rounding thresholds. To check for such a violation, McCrary (2008) proposed a simple test based on continuity of the density of the "running variable" around the rounding thresholds. Intuitively, if there is upward manipulation of ratings, we should see relatively few firms with average ratings just below the thresholds and a clump of firms with average ratings just above the thresholds, and if there is downward manipulation of ratings--say, because of competitors' actions--then we should see the opposite. As Figure 8 shows, however, the density of average ratings in our data is essentially continuous, uniform in fact, with neither bumps nor dips, above or below the rounding thresholds.24 The visual evidence is confirmed by a formal McCrary (2008) test in Table 2; the RD regression with the density of average ratings as the dependent variable shows an insignificant coefficient for Above Threshold.
Another category of identification tests is based on the idea, formalized in Lee (2008), that if the assignment of hotels to just above the rounding threshold and just below the rounding threshold is random, then the baseline characteristics of the hotels--characteristics that are determined prior to the realization of the average

802

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

Figure 8. McCrary (2008) Test: Distribution of Average Ratings Near Rounding Thresholds

rating--should have the same distribution just above and below the thresholds. In Table 3, we see just this: hotels just above the threshold do not differ systematically from those just below the threshold on a variety of characteristics--including price, which is arguably not a predetermined characteristic.
Finally, in Online Appendix C, we provide several additional tests for ratings manipulation based on various correlates of manipulated reviews identified in the past literature (Anderson and Magruder 2012, Mayzlin et al. 2014, Luca and Zervas 2016, Proserpio and Zervas 2017). These include things like number of five-star reviews, reviewers with few versus many reviews, independent hotels managed by large versus small owners, and reviews with and without managerial responses. None of these variables show discontinuities around the rounding thresholds.
Collectively, then, we do not see any evidence that the identifications assumptions of RDD are being violated here. This does not mean, of course, that there are no hotel-manipulated reviews in our data. Rather, what it means is that, notwithstanding any

Table 2. McCrary (2008) Test

(1)

Above Threshold
Avg Ratings
Above Threshold × Avg Ratings
Year-month fixed effects Brand fixed effects N R2

0.001 (0.001)
-0.030 (0.029)
0.038 (0.047)
Yes Yes 251 0.54

Notes. The dependent variable is density of average ratings, computed on a bin size of 0.0004 stars. Pooled RDD with a bandwidth of 0.05 stars. Only hotels with 20 or more reviews included. Robust standard errors are in parentheses.

manipulation, hotels do not seem to have precise control over their average ratings around the rounding thresholds. As Lee and Lemieux (2010) emphasized, precise control is the issue:
If individuals--even while having some influence--are unable to precisely manipulate the assignment variable, a consequence of this is that variation in treatment near the threshold is randomized as though from a randomized experiment. (p. 283; italics original)
With average ratings, the problem of precise control is compounded by the fact that while a hotel may try to raise its ratings by writing fake positive reviews, its competitors are probably trying to do just the opposite by writing fake negative reviews. Ultimately, what moves average ratings in this scenario is the consumer's honest opinion, reflecting her actual experiences with the hotel's quality.

6. Results
6.1. How Online Ratings Affect
Advertising Spending
We start our analysis by presenting visual evidence that hotels' total ad spending is sensitive to their average ratings around the rounding thresholds. In Figure 9, we show the relationship between average ratings at time t and logarithm of total advertising spending in the period [t, t + 6 months] at different rounding thresholds: 3.25, 3.75, 4.25, and 4.75.25 There are clear gaps in the intercepts at thresholds 3.25, 4.25, and 4.75, and a less clear one at threshold 3.75. Recall that crossing a threshold increases the displayed rating by half a star. Thus, Figure 9 shows that for all but the 3.75 threshold, the discrete increase in displayed ratings around the rounding thresholds results in a reduction in the amount of advertising spending.

Table 3. Randomization Check: Comparison of Hotel Characteristics Above and Below the Threshold

Hotel is part of a chain Hotel rooms Number of reviews Hotel class Hotel location Hotel has meeting space Hotel brand Hotel price

Below 0.38
197.70 259.50
4.01 4.42 0.79 18.60 164.60

Above 0.38
195.40 258.10
4.01 4.41 0.79 18.50 165.70

Difference (SE)
0.002 (0.004) 2.34 (1.96) 1.34 (3.43) -0.004 (0.01) 0.01 (0.01) 0.0009 (0.003) 0.06 (0.23) -1.16 (0.96)

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

803

Figure 9. Relationship Between Total Advertising Spending and TripAdvisor Average Ratings at Various Rounding Thresholds

Note. CI, Confidence interval.
Table 4 presents detailed RDD estimates for the visual evidence. The coefficient of interest, AboveThresholdit, is negative for all thresholds and statistically significant for all except the 3.75 threshold. These results suggest that hotels above the threshold spend, on average,

between 6% and 15% less on advertising than hotels below the thresholds.
Because of the consistent negative effects of displayed ratings on advertising spending across thresholds, in all subsequent analyses, we pool the thresholds

Table 4. How TripAdvisor Ratings Affect Total Ad Spending: RDD Estimates

3.25

3.75

4.25

4.75

Above Threshold
Avg Ratings
Above Threshold × Avg Ratings
Year-month fixed effects Brand fixed effects N R2

-0.156*** (0.044)
3.409** (1.090)
0.896 (1.479)
Yes Yes 10,825 0.085

-0.028 (0.032)
1.269 (0.806)
-1.814 (1.060)
Yes Yes 22,113 0.11

-0.062* (0.029)
-0.704 (0.736)
3.463*** (0.978)
Yes Yes 24,824 0.12

-0.108** (0.042)
2.657* (1.072)
-3.448* (1.382)
Yes Yes 10,215 0.10

Notes. The dependent variable in each column is log of ad spending in the following six months. All columns use a bandwidth of 0.05 stars around the rounding cutoff in the column header. Only firms with 20 or more reviews are included. Robust standard errors are in parentheses.
*p < 0.05; **p < 0.01; ***p < 0.001.

804

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

Table 5. Ad Spending Effects by Hotel Type

All hotels

Chains

Independent

Independent (including search ads)

Above Threshold
Avg Ratings
Above Threshold × Avg Ratings
Year-month fixed effects Brand fixed effects N R2

-0.070*** (0.018)
1.035* (0.445)
0.655 (0.591)
Yes Yes 67,977 0.079

-0.024 (0.029)
0.572 (0.737)
0.517 (0.982)
Yes Yes 22,546 0.21

-0.088*** (0.022)
1.173* (0.556)
0.789 (0.738)
Yes No 45,431 0.012

-0.229* (0.099)
1.839 (2.428)
2.621 (3.315)
Yes No 22,455 0.18

Notes. The dependent variable is log of ad spending in the following six months for the hotels covered by the column heading. The first three columns do not include search advertising. All columns use a pooled RDD with a bandwidth of 0.05 stars. Only firms with 20 or more reviews are included. Robust
standard errors are in parentheses. *p < 0.05; ***p < 0.001.

together. The first column of Table 5 repeats the Table 4 analysis on the pooled sample. The results suggest that an extra half star in TripAdvisor's displayed ratings causes hotels to spend about 7% less on advertising. In Online Appendix A, we show that these results obtain both at the extensive margin (decision to advertise) as well as at the intensive margin (advertising spending given decision to advertise).
6.2. Effects by Media Next, we look at how the effect of ratings on ad spending varies across advertising media. We use the same specification as before, but the dependent variable now is log of ad spending within a particular ad medium. Results are presented in Table 6. As the table shows, our earlier finding with total ad spending is replicated within each media as well. Search advertising is by far the most responsive, followed by print,

internet display, outdoor, and TV; radio is the least responsive.
6.3. Hotel Type Effects In this section, we explore whether the ratings­ad spending relationship varies by whether the hotel is independent or part of a chain. Table 5 presents the results, with the second and third columns excluding spending on search ads, whereas the fourth column shows results for independent hotels with search ad spending included in total ad spending.26 We observe that the relationship for chains is negative, but not statistically significant, whereas for independent hotels it is both negative and significant. The latter is also economically meaningful: a half-star increase in TripAdvisor ratings reduces independent hotels' ad spending by about 9%. Although the coefficients for chain hotels and independent hotels are not

Table 6. Ad Spending Effects by Media Type

Internet display Internet search Outdoor Print Radio TV

Above Threshold
Avg. Ratings
Above Threshold × Avg Ratings
Year-month fixed effects Brand fixed effects N R2

-0.027*** (0.008)
0.313 (0.195)
0.156 (0.256)
Yes Yes 67,977 0.029

-0.206* (0.102)
2.335 (2.509)
1.707 (3.421)
Yes No 22,455 0.19

-0.017* (0.007)
0.437* (0.175)
-0.074 (0.239)
Yes Yes 67,977 0.026

-0.039* (0.015)
0.703 (0.389)
0.262 (0.517)
Yes Yes 67,977 0.094

-0.009* (0.004)
0.071 (0.097)
0.230 (0.130)
Yes Yes 67,977 0.055

-0.011* (0.005)
0.168 (0.120)
-0.161 (0.155)
Yes Yes 67,977 0.023

Notes. The dependent variable is log of ad spending in the following six months in particular media. All columns use a pooled RDD with a bandwidth of 0.05 stars. Only hotels with 20 or more reviews are considered. Robust standard errors are in parentheses. Internet search contains only observations for independent hotels.
*p < 0.05; ***p < 0.001.

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

805

Table 7. How Ad Spending Effects Vary by Chain Size and Hotel Class

Fewer than 90 properties

More than 90 properties

Nonluxury

Luxury

Nonluxury

Luxury

Above Threshold
Avg Ratings
Above Threshold × Avg Ratings
Year-month fixed effects Brand fixed effects N R2

-0.194* (0.093)
0.080 (2.527)
-1.640 (3.243)
Yes Yes 2,110 0.26

-0.125 (0.122)
0.372 (3.119)
6.465 (4.291)
Yes Yes 2,898 0.27

-0.007 (0.031)
0.090 (0.788)
0.550 (1.047)
Yes Yes 12,900 0.084

-0.068 (0.072)
6.961*** (1.751)
-7.188** (2.359)
Yes Yes 4,638 0.20

Notes. The dependent variable in each column is log of search ad spending in the following six months. Only hotels with 20 or more reviews are included. Chain size and luxury class come from STR. Robust standard errors are in parentheses.
*p < 0.05; **p < 0.01; ***p< 0.001.

statistically different from one another, these results suggest that the ad response of independent hotels drives much of the overall result. Finally, in the fourth, when we repeat the analysis for independent hotels including search ad spending, we find an even stronger result.
Why might independent hotels be more responsive to their ratings than chain hotels? We conjecture that this is because the chains' national branding insulates them from reviews--both on the positive side and on the negative side. When demand is less sensitive to reviews, hotels have less reason to respond.
We next test how the effect varies within chains, based on size and quality-tier differences. We separately estimate the RDD for small (fewer than 90 properties) and large (more than 90 properties) chains, and distinguish between luxury and nonluxury chains (as classified by STR). (Ninety properties is approximately the 25th percentile of chain size in our data.) Table 7 shows a significant relationship only for small nonluxury chains, suggesting that brand strength may be a function not only of size, but also prominence. Luxury chains such as Ritz-Carlton or W, though small, might still be prominent enough to insulate them from reviews.
6.4. Market Effects In this section, we examine how the degree of differentiation in a market affects the relationship between ratings and ad spending. We use the STR definition of market as a metropolitan statistical area and operationalize differentiation by computing the standard deviation of average ratings in each market each year. Our hypothesis is that in markets with low standard deviation of average ratings, the boost in displayed ratings that comes from average ratings crossing the rounding threshold from left to

right might be more pivotal. In such markets, then, we should see a bigger ad response than in markets where average ratings are already well differentiated to begin with.
Table 8 shows the results of this analysis. Comparing markets with above-the-median differentiation and markets with below-the-median differentiation, we find that ratings have a stronger negative effect on ad spending in less differentiated markets than in more differentiated markets.

6.5. Early vs. Late Effects In Figure 6, we saw that the ratings­advertising relationship in 2002­2005 was mostly noise, whereas in 2012­2015, a well-defined inverted-U relationship was present. We hypothesize that this difference is driven by the growing influence of TripAdvisor among consumers. In the early years of our data set, it is likely

Table 8. Ad Spending Effects by Market Competitiveness

High ratings SD Low ratings SD

Above Threshold
Avg Ratings
Above Threshold × Avg Ratings
Year-month fixed effects Brand fixed effects N R2

-0.028 (0.024)
-0.599 (0.632)
2.664** (0.823)
Yes Yes 36,558 0.091

-0.108*** (0.025)
2.807*** (0.624)
-1.668* (0.849)
Yes Yes 31,419 0.084

Notes. The left (right) column refers to markets where the standard deviation (SD) of average ratings is higher (lower) than the median standard deviation. The dependent variable in each column is log of ad spending in the following six months. All columns use a pooled RDD with a bandwidth of 0.05 stars. Only firms with 20 or more reviews are included. Robust standard errors are in parentheses.
*p < 0.05; **p < 0.01; ***p < 0.001.

806

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

Table 9. Effect of TripAdvisor Ratings on Ad Spending, Early vs. Late

2002­2005

2012­2015

Above Threshold
Avg Ratings
Above Threshold × Avg Ratings
Year-month fixed effects Brand fixed effects N R2

-0.121 (0.141)
4.705 (3.283)
-0.703 (4.572)
Yes Yes 2,191 0.18

-0.106*** (0.024)
1.124 (0.602)
0.522 (0.804)
Yes Yes 34,496 0.066

Notes. The dependent variable is log of ad spending in the following six months during the period of the column heading. All columns use a pooled RDD with a bandwidth of 0.05 stars. Only firms with 20 or more reviews are included. Robust standard errors are in parentheses.
***p < 0.001.

that few people visited TripAdvisor to read reviews and make buying decisions based on them. However, by 2015, reviews and review platforms such as TripAdvisor had become extremely popular and many consumers were using them to make buying decisions. (As we noted in Endnote 8, by November 2016, TripAdvisor was among the top 50 sites in the entire internet.) Hotels that did not feel any need to respond to their ratings when consumers were not paying attention surely had to respond once consumers started paying attention.
We test this hypothesis in Table 9, where two regressions are reported, one based on 2002­2005 data and another based on 2012­2015 data. We find that in the 2002­2005 period, although the point estimate of the ratings effect is large, the coefficient is not statistically significant because of the large amount of noise in the data. During the 2012­2015 period,

Table 10. Placebo Test: Local Variation in Average Ratings Without Variation in Displayed Ratings

All firms

Above Threshold
Avg Ratings
Above Threshold × Avg Ratings
Year-month fixed effects Brand fixed effects N R2

-0.015 (0.018)
-0.308 (0.448)
0.439 (0.617)
Yes Yes 69,971 0.097

Notes. The dependent variable in each column is the log of ad spending over the next six months. All columns use a pooled RDD around placebo cutoffs (3.1, 3.6, 4.1, and 4.6 stars) with a bandwidth of 0.05 stars. Only firms with 20 or more reviews are included. Robust standard errors are in parentheses.

Table 11. How TripAdvisor Average Ratings Affect Ad Spending, Controlling for Hotel Prices

(1)

(2)

Above Threshold
Avg Ratings
Above Threshold × Avg Ratings
log Hotel Price
Year-month fixed effects Brand fixed effects N R2

-0.076** (0.027) 1.841** (0.671) 0.068 (0.893)
Yes Yes 36,412 0.12

-0.072** (0.026)
1.572* (0.667)
0.281 (0.889)
0.368*** (0.020)
Yes Yes 36,412 0.13

Notes. The dependent variable is log of ad spending in the following six months for the hotels covered by the column heading. All columns use a pooled RDD with a bandwidth of 0.05 stars. Only firms for which we obtained ADRs and with 20 or more reviews are included. Robust standard errors are in parentheses.
*p < 0.05; **p < 0.01; ***p < 0.001.

however, the relationship between ratings and advertising becomes highly significant. In fact, as expected, the negative relationship in the later period is even stronger than in our earlier regression when we aggregated across all periods (Table 6, first column).

7. Robustness of Results
In this section, we examine the robustness of our results to placebo thresholds that do not involve any variation in displayed ratings, inclusion of hotel prices as a control, alternative formulations of the RDD: quadratic polynomial functional form, alternative bandwidths, and alternative aggregation windows for advertising spending.

7.1. Placebo Test In order to test whether variation in displayed ratings is necessary for the advertising effect, we estimate the RDD on placebo thresholds, that is, thresholds around which local variation in average ratings does not produce any variation in displayed ratings. The results are in Table 10. The placebo thresholds we chose were 3.1, 3.6, 4.1, and 4.6. The coefficient of interest, Above Threshold, is quite close to zero and statistically insignificant, implying that without a change in displayed ratings there is no effect of local variation in average ratings. In other words, variation in displayed ratings appears to be necessary for a local average-ratings variation to have an advertising effect (see Endnote 5).
7.2. Controlling for Hotel Prices Theoretically, one may argue that because both prices and advertising affect demand,27 hotels may respond to variations in displayed ratings both by adjusting

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

807

Table 12. Quadratic Specification

(1)

Above Threshold
Avg Ratings
Above Threshold × Avg Ratings
Avg Ratings2
Above Threshold × Avg Ratings2
Year-month fixed effects Brand fixed effects N R2

-0.081** (0.027)
0.670 (1.916)
2.941 (2.395)
-6.882 (34.556)
-32.068 (44.864)
Yes Yes 67,977 0.079

Notes. The dependent variable is log of ad spending over the next six months. All columns use pooled RDDs with a bandwidth of 0.05 stars. Only firms with 20 or more reviews are included. Robust standard errors are in parentheses.
**p < 0.01.

advertising spending as well as by adjusting price. Although a test of whether prices also adjust to displayed ratings is beyond the scope of this paper, we can include price as a covariate in our regressions to see whether it makes a difference. Along these lines, we reestimate Equation (1) on a subset of hotels for which we have ADRs (see Section 3). The results are in Table 11. In the first column, hotel prices are not included; in the second column, they are. First, we notice that the results on the subset of hotels for which we have hotel prices are similar to those obtained under the full sample (see Table 8, first column). Second, when we insert the logarithm of ADR as a control, the coefficient remains negative, statistically significant, and similar in magnitude to that reported in the first column, suggesting that our results are not affected by the inclusion of hotel prices.

7.3. Quadratic Polynomial Estimator
Here we test whether our results are sensitive to changing from our previous linear specification to a quadratic polynomial specification. We add to Equation (1) a quadratic term for the average ratings variable and interact it with the Above Threshold dummy to allow for a separate effect of the quadratic term above and below the discontinuity. The specification thus becomes

log Ad Spendingit

1Above Thresholdit + 2Avg Ratingsit

+ 3Avg Ratings2it

(2)

+ 4Above Thresholdit × Avg Ratingsit

+ 5Above Thresholdit × Avg Ratings2it + i

+ t + it.

Table 13. Sensitivity Analysis: Different Bandwidths

Bandwidth

0.025

0.05

0.075

Above Threshold
Avg Ratings
Above Threshold × Avg Ratings
Year-month fixed effects Brand fixed effects N R2

-0.107*** (0.026)
3.953** (1.367)
-1.604 (1.723)
Yes Yes 33,523 0.074

-0.070*** (0.018)
1.035* (0.445)
0.655 (0.591)
Yes Yes 67,977 0.079

-0.032* (0.015)
0.661** (0.247)
-0.586 (0.330)
Yes Yes 100,292 0.085

Notes. The dependent variable is log of ad spending over the next six months. Only firms with 20 or more reviews are included. Robust standard errors are in parentheses.
*p < 0.05; **p < 0.01; ***p < 0.001.

The results are in Table 12 are qualitatively similar to our earlier results with a linear specification.

7.4. Alternative Bandwidths We test the sensitivity of our RDD to alternative bandwidths. We test three different bandwidths--0.025, 0.5, and 0.075--in Table 13. The coefficient of interest, Above Threshold, is statistically significant for every bandwidth tested; however, the effects are larger for the smaller bandwidths.
7.5. Alternative Aggregation Windows for Advertising Spending
Recall that we aggregate advertising spending over the six months following our rating measurement. As we explained in Section 5.1, the motivation for this choice is twofold: (i) ads are often purchased far ahead of when they are delivered, and (ii) we wanted to reduce noise in the variable.
Table 14 shows that our results are robust to different aggregation windows. The first column shows our baseline specification using a time window of [t, t + 6]; the second column shows the results using a shorter window of [t, t + 3]; the third column shows "next month" spending; and, finally, the fourth column shows the results for a forward-looking window of [t + 3, t + 6]. In each case, we find a negative and significant effect.

8. Discussion
What we have shown is that local variations in average ratings that trigger relatively big variations in displayed ratings (perceived quality) have a causal demand-side effect on advertising spending by hotels. The reason it can only be a demand-side effect is that the average rating variation driving the response is confined to a small neighborhood of the rounding

808

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

Table 14. Results with Different Time Windows for Advertising Spending

log next 6 months log next 3 months log next 1 month log next 3­6 months

Above Threshold
Avg Ratings
Above Threshold × Avg Ratings
Year-month fixed effects
Brand fixed effects N R2

-0.070*** (0.018) 1.035* (0.445) 0.655 (0.591)
Yes
Yes 67,977 0.079

-0.056*** (0.014) 0.813* (0.348) 0.700 (0.462)
Yes
Yes 70,793 0.066

-0.032*** (0.009) 0.364 (0.230) 0.497 (0.305)
Yes
Yes 72,650 0.046

-0.060*** (0.015) 1.021** (0.393) 0.203 (0.521)
Yes
Yes 67,977 0.071

Notes. The dependent variable is log of ad spending summed over the aggregation window in the column heading. All columns use a pooled RDD with a bandwidth of 0.05 stars. Only firms with 20 or more reviews are included. Robust standard errors are in parentheses.
*p < 0.05; **p < 0.01; ***p < 0.001.

thresholds, more plausible as a sampling variation in reviews than as an actual variation in quality. Once variation in actual quality is off the table, the cost-side motivation disappears.
The nature of the demand-side effect is, of course, our most interesting result. We observe that hotels with high perceived quality--those just to the right of a rounding threshold--spend less on advertising than hotels with low perceived quality, those just to the left of the rounding threshold. Why might this be so? We can only speculate, but extrapolating from past theoretical models that have appeared in the literature, such as Horstmann and Moorthy (2003) and Lei (2015), a plausible explanation might be that hotels with a high perceived quality are targeting a different consumer segment than hotels with a low perceived quality. In particular, the former might be targeting the "informed" consumer who gets her information from TripAdvisor's displayed ratings, whereas the latter might be targeting the "uninformed" consumer who gets her information from advertising. Whereas the former's targeting choice might be deemed opportunistic, the latter's targeting choice is arguably born out of necessity: consumers visiting the TripAdvisor site are unlikely to choose a hotel with lower ratings over a hotel with higher ratings, ceteris paribus.
For the hotel with high perceived quality, then, a lower ad spending level is justified because (a) advertising will not be very productive on informed consumers, and (b) why spend money on advertising when online ratings can do the work for free? On the other hand, precisely because it will be hard to persuade informed consumers, the hotel with low perceived quality must target the uninformed consumer with advertising.
The remaining question to be resolved is why the hotel with high perceived quality does not also go after the uninformed segment, for if it were to do

so, perhaps we would not see a difference in their advertising strategies. The answer to this must await a fully worked out theoretical model, but one possibility is "price dilution." Because uninformed consumers hold "average quality" beliefs, the highperceived-quality hotel will not be able to charge high prices by pursuing this segment. In other words, pursuing the uninformed segment has the opportunity cost of foregoing the high prices that would otherwise be possible. The fact that the negative relationship between perceived quality and advertising spending has become apparent only in the more recent years of our data, as the proportion of informed consumers has presumably risen, lends credence to this argument. The presence of capacity constraints only makes it stronger.
Is the substitution effect between online ratings and advertising likely to be a universal feature of all industries? We conjecture not. In fact, we know, based on Dhar and Moorthy (2017), that the result does not hold in the movie category. There, in the subcategory of limited-release movies, advertising complements critics' reviews. The reasons for the difference may have to do with a number of things that differentiate the movie industry from the hotel industry: (a) all movies, regardless of reviews, are priced the same; (b) movies can incorporate critics' ratings in advertising copy; and (c) movies, unlike hotels, do not face capacity constraints.
9. Conclusion
This paper has examined the relationship between online ratings and advertising spending in the hotel industry using a 14-year panel of TripAdvisor hotel reviews matched to advertising data from Kantar Media and SpyFu. Our results suggest that hotels' displayed ratings have a causal, demand-side effect on their advertising spending decisions. Hotels with higher

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

809

ratings spend less on advertising than hotels with lower ratings. The effect is robust, seen both in aggregate advertising spending and in individual media spending, at the intensive margin as well as at the extensive margin. In short, the evidence is strong that hotels with "high" displayed ratings seem to be treating their ratings as a substitute for advertising, whereas hotels with "low" displayed ratings seem to be treating advertising as a substitute for their ratings. It is as if the former are targeting the informed consumer and the latter are targeting the uninformed consumer.
Beneath the broad substitution relationship, there are several interesting nuances. Independent hotels respond to their ratings, but chains generally do not--except small nonluxury chains. This suggests to us that having a strong, well-known brand continues to provide some immunity to reviews. We also find that hotels in less differentiated markets are more responsive to their online ratings than hotels in more differentiated markets, suggesting that firms are more motivated to respond when ratings are more likely to be pivotal. Finally, in the time series, we see hotels becoming more responsive to their ratings over time, in step with the rising popularity of TripAdvisor. This tells us that it is not the presence of reviews per se that triggers a firm reaction, but rather the recognition that consumers are responding to them.
Our empirical analysis, based on regression-discontinuity designs, would not be possible without the exogenous discontinuities built into TripAdvisor's displayed ratings system. However, this is also a limitation. Although we can say with confidence that online ratings substitute for advertising ratings in the neighborhood of the discontinuities, we cannot say what happens causally, away from those discontinuities. (Our placebo test in Section 7 suggests, however, that nothing much happens if displayed ratings do not change.) Nor can we say whether large-scale changes in average ratings have only demand-side effects, or cost-side effects also. Finally, our results are likely sensitive to the particular institutional context of TripAdvisor ratings, in so far as TripAdvisor does not allow hotels to use their TripAdvisor ratings in advertising copy. In other contexts, this might be different. For example, in the movie industry, critics' ratings are routinely featured in advertising copy. Perhaps for this reason, Dhar and Moorthy (2017) report a positive relationship between critics' ratings and ad spending for limitedrelease movies.
Acknowledgments The authors thank Judith Chevalier; Pedro Gardete; Tobias Klein; Jason Roos; Navdeep Sahni; Ken Wilbur; and audiences at the 2017 Quantitative Marketing and Economics Conference; 2017 NYU Conference on Digital, Mobile Marketing, and Social Media Analytics; 2018 ISMS Marketing Science

Conference; 2018 National Bureau of Economic Research Economics of Digitization Conference; 2018 Bass Frontiers of Research in Marketing Science Conference; 2018 ACM Conference on Economics and Computation; and 2018 Economics of Advertising Workshop for their helpful comments.
Endnotes
1 See http://www.pewinternet.org/2016/12/19/online-reviews/. 2 A particularly motivated consumer could go to the raw data-- reviewers' actual ratings--and calculate the averages for herself, but we conjecture that most consumers will not do that. Our empirical analysis relies on the assumption that consumers do not know the average ratings but hotels do. 3 For other applications of regression-discontinuity designs using user reviews, see Anderson and Magruder (2012), Luca (2016), and Lei (2017). 4 In the hotel industry, arguably, most costs are fixed. So even largescale average rating variation probably is not accompanied by significant marginal cost variation. 5 Small variations in average ratings away from the discontinuity thresholds, say, from 3.48 to 3.49, can also have a demand-side effect on advertising spending, but by a more circuitous route. Although displayed rating is constant for this variation, consumers may still respond because TripAdvisor ranks the 3.49-rated hotel higher than the 3.48-rated hotel. 6 We thank an anonymous referee for this insight. 7 For independent hotels, "hotel property" and "hotel" mean the same thing; for chain hotels, they do not. However, for ease of writing, we will sometimes abbreviate "hotel property" to "hotel" in what follows. As we will discuss shortly, because TripAdvisor ratings are available at the individual property level, whereas advertising spending numbers are not necessarily so, part of our challenge is how to associate the right spending with the right property. 8 Indeed, it is one of the most visited websites on the internet (see http://www.comscore.com/Insights/Rankings/Revised-Top-50-Digital -Media-Properties-for-October-and-November-2016). 9 See https://www.tripadvisor.nl/pages/factsheet.html. 10 To be more specific, 18 media categories are identified: network TV, spot TV, Spanish language network TV, cable TV, syndication, magazines, Sunday magazines, local magazines, Hispanic magazines, business-to-business magazines, national newspapers, newspapers, Hispanic newspapers, network radio, national spot radio, local radio, U.S. internet display, and outdoor. 11 As this example indicates, "product" may indicate a specific property, but it may also indicate a type of ad, as well as an advertising partnership. 12 This tool provides, for every keyword, the average traffic, cost per thousand impressions, and cost per click of the average search ad. 13 For instance, the Hyatt Regency in Princeton, New Jersey, uses the URL https://www.hyatt.com/en-US/hotel/new-jersey/hyatt -regency-princeton/princ, and the Hyatt Regency in Buffalo, New York, uses the URL https://www.hyatt.com/en-US/hotel/new-york/ hyatt-regency-buffalo-hotel-and-conference-center/buffa. SpyFu does not report separate spending numbers for these URLs; instead, it aggregates "all Hyatt spending" into www.hyatt.com. 14 For most hotels, TripAdvisor provides a link to the hotel homepage, if one exists. 15 The STR hotel census contains information on about 63,502 properties, which is about 69% of the properties listed on TripAdvisor. 16 The reason is, even if our algorithm returns a unique TripAdvisor ID at Step 4, that match may not be a "correct" match. This is why we

810

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

need Step 5 followed by a further manual check at the end. Google's search results may be "wrong" because (i) the Kantar brand­product we searched for did not have a TripAdvisor page, and Google returned a TripAdvisor URL for a hotel with a similar name; (ii) the hotel we searched for is closed, and Google returned the TripAdvisor URL of the hotel currently open in a similar location; and (iii) the name of the hotel on the TripAdvisor page is different enough from the Kantar brand­product name that the match is discarded even though it is correct. For example, our algorithm, for the Kantar brand­product "28th Street Hotel," returned as a potential match the hotel "Hampton Inn & Suites Grand Rapids Airport/28th St"; however, we rejected this match in Step 5 because the two names were not similar enough. For another Kantar brand­product, "Calabasas Inn," the algorithm returned as a potential match "Good Nite Inn--Calabasas," which again we discarded in Step 5. (It turns out that the original Calabasas Inn closed and was reincarnated as The Hilton Garden Inn Calabasas.) For these reasons, there is a 40% attrition in going from Step 4 to Step 5 of the algorithm. 17 This comparison is possible only for chain hotels because we are able to identify chain name and class for the whole Kantar sample using a list of U.S. chains and their classes obtained from STR. 18 These are nominal spending numbers, not inflation-adjusted numbers. If we were to plot the latter, the decrease would be even steeper. 19 One can conjecture that ad spending in the newer media that our data do not capture, namely, social media, online video, email, and mobile, also shows an increase, so overall ad spending has probably increased from 2002 to 2015. 20 Indeed, Lewis and Zervas's (2016) work shows that the relationship between ratings and hotel revenue became significant only in 2006, after which it steadily increased from year to year. 21 Ideally, one would observe when ad spending decisions are made and relate those decisions directly to the average and displayed ratings prevailing at the time. However, we do not observe when ad decisions are made, only when advertising money is spent. Aggregating ad spending over the subsequent six months may therefore be seen as introducing measurement error in the dependent variable, which only makes it harder to find a ratings­ad spending effect. 22 Whereas chain hotels are identified by their individual brands-- Marriott, Hilton, etc.--independent hotels are collectively branded as "independent." 23 For a formal discussion of the identification assumptions underlying RDD, see Hahn et al. (2001). 24 Although round numbers such as the rounding thresholds are more common, they are not more common than other round numbers, such as 4.15 and 4.35. Note that uniform density is not the requirement, continuity is. For an example of a nonuniform density that is still continuous, see Lee and Lemieux (2010, figure 16). 25 For average ratings below 3 stars, there are not enough observations to estimate an effect of being above or below the threshold. Fewer than 5% of hotels had an average rating below 3 stars in 2015. 26 As we noted in Section 3, internet search data are available only for independent hotels, and that too, only starting 2006. 27 Luca's (2016) results showing ratings affecting restaurant revenue is suggestive of a price effect.
References
Anderson M, Magruder J (2012) Learning from the crowd: Regression discontinuity estimates of the effects of an online review database. Econom. J. 122(563):957­989.
Archibald RB, HaulmanCA, Moody Jr CE (1983) Quality, price, advertising, and published quality ratings. J. Consumer Res. 9(4): 347­356.

Bagwell K (2007) The economic analysis of advertising. Armstrong M, Porter R, eds. Handbook of Industrial Organization, vol. 3 (Elsevier, Amsterdam), 1701­1844.
Cabral L, Hortaçsu A (2010) The dynamics of seller reputation: Evidence from eBay. J. Indust. Econom. 58(1):54­78.
Caves RE, Greene DP (1996) Brands' quality levels, prices, and advertising outlays: empirical evidence on signals and information costs. Internat. J. Indust. Organ. 14(1):29­52.
Chen Y, Xie J (2005) Third-party product review and firm marketing strategy. Marketing Sci. 24(2):218­240.
Chen Y, Xie J (2008) Online consumer review: Word-of-mouth as a new element of marketing communication mix. Management Sci. 54(3):477­491.
Chevalier JA, Mayzlin D (2006) The effect of word of mouth on sales: Online book reviews. J. Marketing Res. 43(3):345­354.
Dhar T, Moorthy S (2017) On the marketing of experience goods: the case of movies. Presentation, 39th Annual ISMS Marketing Science Conference, June 9, University of Southern California, Los Angeles.
Hahn J, Todd P, Van der Klaauw W (2001) Identification and estimation of treatment effects with a regression-discontinuity design. Econometrica 69(1):201­209.
Hollenbeck B (2018) Online reputation mechanisms and the decreasing value of chain affiliation. J. Marketing Res. 55(5)636­654.
Honka E, Hortaçsu A, Vitorino MA (2017) Advertising, consumer awareness, and choice: Evidence from the US banking industry. RAND J. Econom. 48(3):611­646.
Horstmann IJ, Moorthy S (2003) Advertising spending and quality for services: The role of capacity. Quant. Marketing Econom. 1(3): 337­365.
Houser D, Wooders J (2006) Reputation in auctions: Theory, and evidence from eBay. J. Econom. Management Strategy 15(2):353­369.
Jin GZ, Kato A (2006) Price, quality, and reputation: Evidence from an online field experiment. RAND J. Econom. 37(4):983­1004.
Kim MC, McAlister LM (2011) Stock market reaction to unexpected growth in marketing expenditure: Negative for sales force, contingent on spending level for advertising. J. Marketing 75(4): 68­85.
Lee DS (2008) Randomized experiments from non-random selection in US house elections. J. Econometrics 142(2):675­697.
Lee DS, Lemieux T (2010) Regression discontinuity designs in economics. J. Econom. Literature 48(2):281­355.
Lei Y (2015) How do firms advertise when customer reviews are available? Working Paper, Boston University, Boston.
Lei Y (2017) Local restaurants' advertising response to a better online rating. Working Paper, Peking University, Beijing.
Lewis G, Zervas G (2016) The welfare impact of consumer reviews: A case study of the hotel industry. Working Paper, Boston University, Boston.
Linnemer L (2002) Price and advertising as signals of quality when some consumers are informed. Internat. J. Indust. Organ. 20(7): 931­947.
Luca M (2016) Reviews, reputation, and revenue: The case of Yelp.com. Working Paper, Harvard Business School, Boston.
Luca M, Zervas G (2016) Fake it till you make it: Reputation, competition, and Yelp review fraud. Management Sci. 62(12):3412­ 3427.
Mayzlin D, Dover Y, Chevalier J (2014) Promotional reviews: An empirical investigation of online review manipulation. Amer. Econom. Rev. 104(8):2421­2455.
McCrary J (2008) Manipulation of the running variable in the regression discontinuity design: A density test. J. Econometrics 142(2):698­714.
Melnik MI, Alm J (2002) Does a seller's ecommerce reputation matter? evidence from eBay auctions. J. Indust. Econom. 50(3):337­349.
Moorthy S, Zhao H (2000) Advertising spending and perceived quality. Marketing Lett. 11(3):221­233.

Hollenbeck, Moorthy, and Proserpio: Online Reviews and Advertising Strategy Marketing Science, 2019, vol. 38, no. 5, pp. 793­811, © 2019 INFORMS

811

Nelson P (1970) Information and consumer behavior. J. Political Econom. 78(2):311­329.
Nelson P (1974) Advertising as information. J. Political Econom. 82(4): 729­754.
Powell T, Quinby D (2015) The U.S. travel advertising marketplace: Industry sizing and trends 2015. Report, Phocuswright Market Research, Sherman, CT.
Proserpio D, Zervas G (2017) Online reputation management: Estimating the impact of management responses on consumer reviews. Marketing Sci. 6(5):645­665.
Resnick P, Zeckhauser R, Swanson J, Lockwood K (2006) The value of reputation on eBay: A controlled experiment. Experiment. Econom. 9(2):79­101.

Rotfeld HJ, Rotzoll KB (1976) Advertising and product quality: are heavily advertised products better? J. Consumer Affairs 10(1): 33­47.
Schmalensee R (1978) A model of advertising and product quality. J. Political Econom. 86(3):485­503.
Shum M (2004) Does advertising overcome brand loyalty? Evidence from the breakfast-cereals market. J. Econom. Management Strategy 13(2):241­272.
Sun M (2012) How does the variance of product ratings matter? Management Sci. 58(4):696­707.
Zhao H (2000) Raising awareness and signaling quality to uninformed consumers: A price-advertising model. Marketing Sci. 19(4):390­396.

