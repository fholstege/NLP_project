Vol. 34, No. 1, January­February 2015, pp. 116­133 ISSN 0732-2399 (print) ISSN 1526-548X (online)

http://dx.doi.org/10.1287/mksc.2014.0877 © 2015 INFORMS

Consumer Dynamic Usage Allocation and Learning Under Multipart Tariffs

Arun Gopalakrishnan, Raghuram Iyengar, Robert J. Meyer
The Wharton School, University of Pennsylvania, Philadelphia, Pennsylvania 19104 {agop@wharton.upenn.edu, riyengar@wharton.upenn.edu, meyerr@wharton.upenn.edu}
Multipart tariffs are widely favored within service industries as an efficient means of mapping prices to differential levels of consumer demand. Whether they benefit consumers, however, is far less clear as they pose individuals with a potentially difficult task of dynamically allocating usage over the course of each billing cycle. In this paper we explore this welfare issue by examining the ability of individuals to optimally allocate consumption over time in a stylized cellular-phone usage task for which there exists a known optimal dynamic utilization policy. Actual call behavior over time is modeled using a dynamic choice model that allows decision makers to both discount the future (be myopic) and be subject to random errors when making call decisions. Our analysis provides a "half empty, half full" view of intuitive optimality. Participants rapidly learn to exhibit farsightedness, yet learning is incomplete with some level of allocation errors persisting even after repeated experience. We also find evidence for an asymmetric effect in which participants who are exogenously switched from a low (high) to high (low) allowance plan make more (fewer) errors in the new plan. The effect persists even when participants make their own plan choices. Finally, interventions that provide usage information to help participants eradicate errors have limited effectiveness.
Keywords: multipart tariffs; dynamic allocation; consumer learning; dynamic decision making; intertemporal discounting
History: Received: September 25, 2012; accepted: July 31, 2014; Preyas Desai served as the editor-in-chief and Teck Ho served as associate editor for this article. Published online in Articles in Advance October 20, 2014.

1. Introduction
The multipart tariff is one of the most widely used approaches to pricing in service industries such as cellular phones, electricity distribution, vehicle leasing, retail banking, and online retailing. By charging consumers different prices for different levels of consumption, multipart tariffs have the advantage of allowing firms both to price discriminate among consumers who have different levels of demand and fairly allocate limited capacity to those who need it the most (Bagh and Bhargava 2013, Oren et al. 1985). Whether such pricing mechanisms offer comparable welfare benefits for consumers, however, is far less clear.
The primary source of concern is that multipart tariffs potentially complicate otherwise simple decisions about service utilization and tariff choice. Under a typical pay-per-use plan, for example, a consumer who wishes to decide whether to consume a unit of a service (such as place a phone call) simply needs to assess whether the marginal utility of usage exceeds its marginal cost. Under multipart plans, however, the decision is rendered more complex by the need to also consider how consumption in the present may affect the marginal cost of future consumption. If consumers

find it difficult to make present-future consumption trade-offs, or lose track of accumulated usage under a given plan (e.g., Grubb and Osborne 2013), multipart tariffs could distort consumption patterns in a way that departs from what would be optimal for the consumer in the long term. An example would be cellphone consumers who too quickly use up their "free minutes" (the monthly allowance), exposing them to otherwise avoidable overage charges (which represent an increase in marginal cost) later in the month.
How pervasive are such consumer errors within the context of multipart tariffs? The empirical evidence, based largely on aggregate (typically monthly) usage, is somewhat mixed. Bar-Gill and Stone (2009), for example, find that cell-phone consumers are often poor judges of the calling plans that best match their actual usage. In their work, consumers exceeded their call allowance 17% of the time (by an average of 33%), and those who did not exceed it used, on average, just 47% of their call allowance. Likewise, Ascarza et al. (2012) report that consumers increase usage when switching from two-part (fixed access fee and pay-per-use rate) to three-part tariffs (fixed access fee, usage allowance, and overage rate), an inflation they attribute to a biased tendency to increase usage when

116

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

117

consumption within the usage allowance is perceived as "free." Finally, Lambrecht and Skiera (2006), Lambrecht et al. (2007), Goettler and Clay (2011), and Ater and Landsman (2013) all offer suggestive evidence that consumers themselves sense the difficulties of making usage decisions under multipart tariffs, with many preferring flat-rate plans to multipart tariffs even when total ex post cost is higher.
Two sets of factors limit the strength of conclusions about optimality that can be drawn from data on aggregate usage. First, because such data do not reveal the full set of beliefs held by consumers when they were making decisions­such as their expectations of future usage, consumption utility, and temporal planning horizon­it is impossible to draw strong conclusions about the optimality of these decisions. For example, a consumer who is observed incurring overage charges might well have been behaving optimally if she was strategically responding to an unexpected surge in consumption opportunities providing high utility. Second, as noted by Miravete (2003), even if consumers do err when choosing plans and/or making consumption decisions, such mistakes may be transient, diminishing over time as consumers become more skilled in forecasting their usage patterns and disciplining consumption during a billing cycle.
The purpose of this paper is to take a first step toward empirically assessing the ability of individuals to make optimal usage decisions under multipart pricing schemes. We do so by studying how consumers make call-by-call usage allocation decisions under three-part tariffs in a controlled laboratory task for which there is a known optimal policy for consumption over time. In this task, participants make a series of decisions about whether to accept or reject a series of incoming phone calls that have a known stochastic arrival rate. As in natural settings, when calls arrive, participants observe the utility of the call (simulating caller ID), decide whether to accept each call, and can terminate calls. Participants play for a monetary incentive with the goal of maximizing the total net utility of their phone usage decisions over a time horizon.
We emerge from the work with four key findings. First, we show how participants' call-acceptance decisions in the task can be captured by a heterogeneous dynamic utility model that assumes that they are forward looking when making call-acceptance decisions, but subject to both differential rates of temporal discounting and random errors in usage. Estimates of the structural parameters of the model suggest that although participants quickly learn to avoid myopia (excessive discounting) when making decisions in the task, random errors are more persistent, which forms

the main source of departures from optimality among experienced users. Second, although aggregate performance improves relative to normative benchmarks with game experience, this convergence is incomplete and displays several sustained departures from optimality. Among these is a tendency for behavior to be "noisier" as the free allowance is increased in the three-part tariff, and participants who are exogenously switched from a low (high) to high (low) allowance plan make more (fewer) errors in the new plan. Third, this asymmetry persists even when allowing participants to self-select into plans. Finally, interventions such as providing subjects with full information about talk time usage and/or creating an alert when reaching 80% of free allowance has almost no effect on performance, suggesting that inattention to usage is unlikely to be a major driver of errors.
The remainder of this paper is organized as follows. In §2, we describe the general form of the decision task faced by participants in our laboratory setting, and develop a dynamic choice model of consumer decision making that incorporates temporal discounting, random errors, learning, and heterogeneity. In §3, we explain our design choices and describe the experimental setting in which we collect data. In §4, we report the findings from four studies based on our experimental paradigm along with robustness checks. We conclude in §5 with a discussion of the work's implications for researchers and regulators.
2. Theory and Model Development
2.1. Overview In this paper we study how individuals solve a series of cell-phone calling tasks that have the following structure:
A consumer i faces a series of incoming calls in game g (out of a total of G games) and must decide whether to accept or decline each opportunity. The costs of calls are governed by a three-part-tariff (TPT) plan ig in which the consumer pays a fixed up-front fee Fig for the first W¯ ig seconds of "free" talk time, with overage charges of cig units per second. Upon receiving a call at time t the consumer first observes its marginal utility per second uigt, which is an independent and identically distributed (i.i.d.) draw from a known distribution h uigt . If she accepts the call it lasts for up to L seconds. Once a call is accepted, the consumer can terminate the call at any time or accept another incoming call whose utility can be observed even while an accepted call is in progress. Time is discrete, and calls arrive as a Bernoulli process with a fixed, known, probability p in each second. The consumer's goal is to make a series of accept, switch, or reject decisions

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

118

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

that maximize total net call utility over a finite time horizon of T seconds.
Although abstract in form, this stylized task captures many of the common features of real-world calling problems. As in natural settings the consumer must decide how best to utilize "free" talk time under a budget that mimics monthly billing cycles, she faces potential overage charges that can exceed the average unit time cost (fixed fee divided by "free" talk time), the likely utility of an incoming call is known (e.g., the consumer is assumed to have "caller ID"), call duration is under the control of the consumer, and she has the ability to switch to a new incoming call while on a current call. Likewise, because the task will be played repeatedly, there are opportunities to learn, and the consumer faces the possibility of plan changes that she must adapt to. That said, we do not accommodate all features of real-world calling in order to retain a form that yields a clear optimal policy. We do not, for example, allow subjects to make outgoing calls, allow for rollover of unused call allowance, or distinguish between off-peak and on-peak usage, and every call's duration has the same upper bound. In the discussion we address the degree to which the current findings might be expected to generalize to a broader range of dynamic consumption problems.
2.2. Normative Theory and Empirical Model In this section we describe how call acceptance decisions would be made by a rational decision maker who seeks to maximize net call utility over a finite time horizon. Because one of our central research goals is to examine how actual acceptance decisions compare to this optimal benchmark, the model allows for two behavioral features that might change over games as participants gain task experience: intertemporal discounting, or the tendency to give more weight to the value of calls that are immediately at hand versus those that may lie in the future, and timevarying random response errors. Following Salisbury and Feinberg (2010), these errors reflect unobserved drivers of utility that lie outside the rational policy, such as momentary lapses of attention and transient errors that arise from making decisions via nonnormative heuristics.
In §2.2.1 we first describe how a utility-maximizing consumer would solve our focal decision problem given that she discounts future utilities absent random choice errors, and we then extend this model in §2.2.2 to allow for such errors. In §2.2.3 we discuss the form of the model that we estimate empirically, which includes heterogeneity in discounting and error propensities.

2.2.1. The Optimal Policy Without Random Choice
Errors. Consider the optimal policy for consumer i
who wishes to maximize utility over a discounted
finite time horizon in game g with discount fac-
tor ig under a TPT plan ig (with fixed fee Fig, "free" allowance W¯ ig, and per-second overage charge cig by making a series of decisions { igt}. The consumer is assumed to be intertemporally risk neutral in assessing the expected total utility of future calls.1 Note that
the discount factor is allowed to be consumer-specific
and game-specific. Let t  1 2 T } be the decision
times within game g, where T is the total number of
seconds. Assume that in each second there is a con-
stant probability p of an arriving call with strictly pos-
itive and stochastic utility uigt with p.d.f. h uigt . For notational convenience, we set uigt = 0 to represent the event of no call arriving at time t (which occurs
with probability 1 - p , yielding the mixed probability
distribution f uigt = 1 - p · I uigt = 0 + p · h uigt · I uigt > 0 .
At time t, a consumer derives current-period utility
K uigt uigt Digt wigt igt from new call acceptance ( igt = 1) or existing call continuation ( igt = 0) and obtains zero utility from termination or rejection of a
call ( igt = -1). As shown in Figure 1, the space of call decisions igt uigt uigt depends on available new and existing calls and period utility is a function of uigt, the value of an incoming call (could be 0 if none);
uigt, the value of an ongoing call (could be 0 if none); Digt, the number of seconds remaining on an existing call; and wigt, the number of free seconds (or talk time) used.
The consumer's expected utility is given by

T

E

t-1 ig

·

K

uigt

uigt

Digt

wigt

t=1

igt  igt uigt uigt

and can be formulated as a dynamic programming
problem as shown in Equation (1), where Vigt uigt uigtDigt wigt igt is the conditional value function and

V¯ig t+1 uig t+1 Dig t+1 wig t+1  Euig t+1 max Vig t+1 uig t+1 uig t+1
ig t+1
Dig t+1 wig t+1 ig t+1

is the expected continuation value conditional on future state parameters. State variables include uigt

1 In our experimental work we will examine whether observed departures from optimality might accrue because of risk aversion among consumers. We impose intertemporal risk neutrality here both for model identification and to make the analysis consistent with prior dynamic consumer utility models, which also make the same assumption (e.g., Erdem and Keane 1996).

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

119

Figure 1 (Color online) Current Period Utility K as a Function of State Variables and Decision

uigt > 0

Yes

No

uigt > 0

Yes

No

uigt > 0

Yes

No

igt  {1, 0, ­1}

igt  {1, ­1}

igt  {0, ­1}

igt  {­1}

K{uigt, uigt, Digt, Wigt, igt) =

[uigt ­ cigI(wigt  Wig)]I (uigt > 0), igt = 1 [uigt ­ cigI(wigt  Wig)]I(uigt > 0) I (Digt > 0), igt = 0
0, igt = ­1

Note. For a respondent i, game g, and time t, uigt is the value of an incoming call, uigt is the value of an ongoing call, Digt is the number of seconds remaining on an existing call, wigt is talk time used, and igt denotes the decision being new call acceptance ( igt = 1), existing call continuation ( igt = 0), or termination or rejection of a call ( igt = -1).

uigt Digt, and wigt but only uigt is unknown prior to the start of time t

Vigt uigt uigt Digt wigt igt

 

uigt - cig I

wigt  W¯ ig



   

+ ig V¯ig t+1 uigt L - 1 wigt + 1



  

·I uigt>0

igt= 1



= uigt - cigI wigt  W¯ ig

(1)

   

+ ig V¯ig t+1 uigt Digt - 1 wigt + 1



   

·I uigt>0 I Digt>0

igt= 0



 ig V¯ig t+1 0 0 wigt igt= -1

In Web Appendix A (available as supplemental material at http://dx.doi.org/10.1287/mksc.2014.0877), we lay out formal propositions that characterize the properties of the above value function and the optimal call-acceptance policy that follows from solving this dynamic program. Most have a strong intuitive flavor. For example, if the consumer has an incoming call but no existing call at time t uigt > 0 uigt = 0 , the optimal decision of whether to accept ( igt = 1 or reject ( igt = -1 the call involves a trade-off between immediate call utility (less any overage charge) and its associated opportunity cost: the difference in expected future utility from saving this unit of talk time for future consumption and taking the call. Once a call is accepted, a rational consumer then needs to decide how long to stay on it. In the absence of another incoming call, the optimal call continuation decision has a similar intuition to call acceptance. A rational consumer might, however, choose to switch calls if a new competing one arrives. In this situation three decisions are possible ( igt = 1 0 -1 ): continue the current call, take the new call, or terminate the current call without taking the new one. In this case the consumer would compute the same trade-off between

present utility and future opportunity costs as above, but here via two steps, first deciding which of the two calls offers the higher level of long-run utility, and then deciding whether the better of the two is worth continuing or taking (which could cause both calls to be rejected).

2.2.2. Introducing Random Choice Errors. It is

unlikely, of course, that consumers would always

trade-off utility and costs in an optimal manner. Even

if they understood the optimal policy, its application

may occasionally be disrupted by lapses of atten-

tion or transient mood effects that are unobserved

by the analyst. Likewise, in the course of learning

how best to accept calls, consumers might randomly

try out a mix of heuristic policies that sometimes

lead them to accept calls they should decline and

sometimes reject those that should be accepted. To

capture the effect of such errors in the decisions

of consumer i in game g, we introduce a time-

varying additive i.i.d. extreme value type I shock term

igt igt with scale parameter ig in the model formulation (Rust 1987, Salisbury and Feinberg 2010)

such that the consumer chooses the decision

 igt

=

arg max igt Vigt uigt uigt Digt wigt igt + igt igt . We

nonparametrically capture learning that may reduce

transient errors across games by allowing ig to be game specific.

In the extreme case, as ig  0, a consumer's actions are perfectly characterized by the optimal policy for

her given discount factor ig. On the other hand, a larger ig indicates a noisy policy that deviates with increasing probability from what is optimal given the

consumer's ig (cf. McKelvey and Palfrey 1995). As ig  , consumer i makes completely random deci-
sions in game g. The expected continuation value

V¯ig t+1 uig t+1 Dig t+1 wig t+1  Euig t+1 V¯ig t+1 uig t+1 uig t+1 Dig t+1 wig t+1 is now a function of ex ante

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

120

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

value function V¯ig t+1 uig t+1 uig t+1 Dig t+1 wig t+1 , which requires integrating over a vector of future

shock terms ig t+1, unknown to both the consumer and researcher. Note that current-period error

terms igt are assumed known to the consumer at time t and only realized for igt  igt uigt uigt . However, the researcher only knows the distribution of

these shocks and must integrate over them to arrive at

the probability of making decision igt. Given that the error terms are distributed extreme

value type I, closed-form solutions are available for

conditional choice probabilities and the ex ante value

function (Arcidiacono and Ellickson 2011, Rust 1987)

as shown in Equations (2) and (3), respectively. Here,

the term

max igt

=

arg max

igt

Pr

igt

uigt uigt Digt wigt ,

and is the Euler-Mascheroni constant

Pr igt uigt uigt Digt wigt

exp Vigt uigt uigt Digt wigt igt / ig = m igt uigt uigt exp Vigt uigt uigt Digt wigt m / ig

(2)

V¯igt uigt uigt Digt wigt

= -ln Pr

max igt

uigt

uigt

Digt

wigt

+ Vigt uigt

uigt

Digt

wigt

max igt

+

ig

(3)

The ex ante value function can be interpreted as

the value function for the decision with the highest

probability of being chosen plus an upside coming

from possible shocks that may make other decisions

more attractive. The term involving does not affect

conditional choice probabilities. As noted before, in

the limiting case of ig  0, the ex ante value function becomes equivalent to the conditional value function

given

max igt

as

the

decision

rule

becomes

deterministic

(i.e., Pr

max igt

uigt uigt Digt wigt  1).

Given a vector of observed consumer deci-

sions Yig ig1 ig2

igT and call arrivals Xig 

uig1 uig2

uigT for each game, we can construct

the likelihood function for consumer i over G games

using the standard assumption of conditional inde-

pendence of the temporal error terms (e.g., Rust 1987)

as shown below

G
p Yig ig ig Xig ig
g=1

GT

=

Pr igt uigt uigt Digt wigt

(4)

g=1 t=1

State variables at each decision node can be con-
structed from Xig and Yig. The data therefore constitute discrete choices made at different values of state
parameters. An important point to note is that Xig is independent of Yig by design--arriving calls have nothing to do with the decisions the consumer made
in the past.

2.2.3. Model Identification and Heterogeneity. Our dynamic choice model has two parameters to capture decision making by consumer i in game g: an intertemporal discount factor ( ig) and error scale parameter ( ig). The scale parameter is usually set to a constant (e.g., Arcidiacono and Ellickson 2011) to estimate the slopes of a latent utility function. Since call utilities are assumed known to both the consumer and researcher (we provide them in the experimental task), the slope for current period utility is essentially fixed to a value of 1, which allows us to estimate ig.2 We also assume that state transition probabilities are known to both the consumer and researcher (since they are explicitly provided in the experimental task) unlike models estimated on field data (e.g., Erdem and Keane 1996), which allows us to pin down the discount factor based on observed choices across a large variation of state parameters at different points in game time (cf. Dubé et al. 2013) as it is the only unknown driving the systematic portion of conditional choice probabilities in Equation (2).
The estimation of individual- and game-specific parameters will, however, be challenging because of sampling variation in call arrivals such that some games' data may be less informative than others for a particular pair of parameters (see Web Appendix E). To circumvent this issue of data sparseness and address heterogeneity across consumers as well, we propose a latent class framework in which the model parameters for each segment are allowed to vary across games nonparametrically (Kamakura and Russell 1989).3 Note that an important substantive benefit of allowing for multiple segments with game-specific parameters is that it will capture heterogeneity in learning within the subject pool--for example, some segments may learn to become optimal quickly, whereas others may not despite repeated experience. Further, our nonparametric specification (which nests the case of allowing a linear trend over games for each parameter) of how the segment level parameters (the discount factor and scale parameter) vary over the six games imposes no a priori restriction on the direction and speed of learning, which is important since patterns may not be monotonic. The likelihood function
2 As long as the slope for one term in the period utility function is fixed, the scale parameter is identified along with slopes of other terms. We exploit this in one of our robustness checks in which we estimate curvature in the per-period utility.
3 We assume homogeneity within a segment, consistent with typical latent class models. Although there may be heterogeneity even within a latent class, since the objective of this paper is to characterize the overall effects of three-part tariffs on learning and usage, we do not introduce further heterogeneity into the model. Further, several individual-level posterior distributions closely resemble the "segment average" given the sparseness of information in data from any given person-game.

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

121

for a data set of N subjects playing G games each is as follows:

NS

G

p is

p Yig gs gs Xig ig

(5)

i=1 s=1

g=1

where p i  s is the probability that subject i belongs to segment s and p Yig gs gs Xig ig the likelihood function for a person-game formed using conditional choice probabilities with segment level parameters (Equation (2)). Note that a homogenous model would have 12 parameters (two game-specific parameters by six games), a two-segment model would have 25 parameters (including the probability of segment membership), and so forth.

3. Empirical Setting
In this section we describe our experimental design, starting with the selection of task parameters and the associated normative predictions in §3.1. In §3, we provide an overview of the experimental method and studies that we ran.
3.1. Design Considerations and Normative Predictions
One of the major challenges in designing the experiment was to choose task parameters (e.g., the free allowance W¯ , the overage cost per second c, the time horizon T , and the probability distribution of call events f u ) that would allow us to efficiently identify the parameters of the empirical model described above while minimizing the task burden on participants.
For example, while it would be desirable to observe a large number of call choices made in different contexts from each participant, pilot work suggested that participants became fatigued when the task lasted longer than 25­30 minutes. We also found that participants typically took twice the amount of time as the number of game-time seconds across all games to complete the task (including the time for decision making whenever a call arrives). As a result, we determined that six games with T = 120 seconds would provide a sufficiently large number of games to assess learning and adaptation to plan changes, while also providing a long enough time horizon to create sufficient present/future trade-offs.
Given T = 120, it was important to choose an allowance W¯ that was neither too high nor too low in order to facilitate identification of individuals' intertemporal discount rates. In particular, to identify these rates we had to choose W¯ such that participants faced consequential trade-offs in most periods of the game when deciding whether to accept a call now versus saving the talk time for future calls. Based on pilot work we found that allowances of 20 seconds (onesixth the total time) and 40 seconds (one-third) captured scenarios that were perceived by participants

as reflecting sparse and ample free-talk time budgets, where opportunity costs were more and less salient, respectively. We also chose maximum call length L = 8 to allow for the real-world feature of call termination (which requires L > 1) and potentially multiple opportunities to switch to other calls (in this case, up to seven opportunities since at most one call can arrive per second in our task). Though the fixed fee was sunk, we choose values of $80 ($20) for the plan with a 40-second (20-second) allowance to ensure task realism and set the expected surplus under both plans for a consumer who does not discount future call values ( = 1) to be roughly equal.
The choices for the distribution of call arrivals f u and overage rates c were crucial in determining the call acceptance threshold. We chose f u = 0 = 0 8 so that the average probability of a call arriving was 0.2, with an expected number of 24 calls in a 120-second time horizon, providing a reasonable number of decision opportunities to participants within a game. A higher f u = 0 decreased the likelihood of overage by rendering call opportunities too sparse.
For participants to make trade-offs about present and future call consumption, the overage charge should exceed some of the call values. We chose three call values (low: uL = $0 25, medium: uM = $0 75, and high: uH = $6), which arrive with known probabilities (f uL = 0 1 f uM = 0 05 f uH = 0 05) and set the overage charge c to $4 (falling between uL and uH ).4 The large value differential between the high- and medium-valued calls simplified the consumer's decision calculus while allowing for efficient recovery of our model parameters.
In Figures 2 and 3, we present the optimal policies for when to accept low-valued (uL and mediumvalued (uM calls under the above set of plan and game characteristics, for both a consumer who does not discount future call values ( = 1 and one who is more myopic. High-valued (uH calls should always be accepted regardless of temporal discounting.
From Figures 2(a) and 2(b), the higher the amount of free allowance consumed, the more judicious a consumer should be in taking low-valued calls (solid line) and medium-valued calls (dotted line). These lower-valued calls can be accepted earlier under a plan with a larger allowance since there is a larger pool of "free" seconds before the consumer starts approaching the overage phase. As the prospect of overage nears, both types of calls should generally be avoided. Under discounting for the 40-second allowance plan (Figures 3(a) and 3(b)) consumers would accept lower-valued calls much sooner than
4 A c that is too low makes overage essentially inconsequential, whereas a c that is too high would preclude some calls from ever being rational to accept.

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

122

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

Figure 2

Earliest Time (in Seconds) for a Consumer Following the Optimal Policy to Accept Call with Given Utility Under Each Plan When (a) = 1 W¯ = 40, (b) = 1 W¯ = 20

A

"ETAOFPLANWITHSECONDALLOWANCE



Figure 3

Earliest Time (in Seconds) for a Consumer Following the Optimal Policy to Accept Call with Given Utility Under Each Plan When (a) = 0 95 W¯ = 40, (b) = 0 90 W¯ = 40

A

"ETAOFPLANWITHSECONDALLOWANCE



%ARLIESTTIMETOACCEPTCONTINUECALL

%ARLIESTTIMETOACCEPTCONTINUECALL











 









#ALLALLOWANCEUSED

B 

"ETAOFPLANWITHSECONDALLOWANCE

%ARLIESTTIMETOACCEPTCONTINUECALL























#ALLALLOWANCEUSED

Note. Low-value call decisions are represented by the solid line while medium-value call decisions are represented by the dotted line.

a consumer who does not discount future call values ( = 1), and then shift to a higher acceptance threshold as the overage phase approaches. The timing of these inflection points varies by discount factor; a more myopic consumer will continue accepting lower-valued calls for a longer period of time before applying more stringent standards. Note that a low-valued call becomes unattractive more quickly than a medium-valued call with increasing usage. The intuition is similar for the 20-second allowance plan. Plan and game characteristics other than the ones we chose can also lead to meaningful differences in optimal policies that can be exploited for estimating structural parameters. An interesting direction for future research is to understand the boundary conditions of how these characteristics interact with consumer behavioral patterns.











 









#ALLALLOWANCEUSED

B 

"ETAOFPLANWITHSECONDALLOWANCE

%ARLIESTTIMETOACCEPTCONTINUECALL























#ALLALLOWANCEUSED

Notes. Low-value call decisions are represented by the solid line and

medium-value call decisions are represented by the dotted line. Note that it is never optimal to accept low- or medium-valued calls once the call allowance

is fully used up in our experimental design.

3.2. Overview of Method and Studies Each of the experimental studies described below has a similar structure. In all cases participants first played a 30-second practice game to familiarize themselves with the task and interface, and then proceeded to play six games for compensation. After each game, the net utility was displayed to the participant, breaking down the total value of calls consumed less fixed and overage costs. For incentive compatibility, we informed participants that all amounts shown above were in game dollars and revealed the exchange rate to convert net accumulated game dollars over the six games to a bonus payment in U.S. dollars (over and above a show-up fee). The show-up fee and exchange

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

123

rate varied depending on the platform we used to run each study. Web Appendix B contains illustrative call arrival patterns and decisions and how these help identify model parameters. In Web Appendix C, we include the full set of instructions to participants as they undertook the task.
The overall experiment comprised four main studies and several follow-up studies that allowed us to examine call behavior under different plan characteristics. In study 1, we examine consumer learning as a function of plan allowance by exposing each subject to one of two TPT plans for six games. In study 2, we examine consumer learning and adaptation to imposed plan change by exposing each subject to one TPT plan for three games and the other for the remaining three games. In study 3, we replicate the structure of study 2 but allow for initial plan choice and the option to switch after three games, as a test of whether self-selection impacts within-game behavior. In study 4, we examine the effect of risk attitude on intertemporal discounting. Two follow-up studies then tested the robustness of the earlier findings to manipulations that might act to improve the efficiency of call decisions: (1) providing a pop-up alert when subjects use up 80% of their free allowance, and (2) providing the alert and a visible real-time counter of talk time used. Additional follow-up studies tested for sunk cost effects arising from the fixed fee of the TPT and curvature in current period utility. For each study, we present model-free evidence of how subjects performed as a function of experience and/or plan changes using the natural benchmark of a consumer who does not discount future call values with no random errors in decision making.
We also present model estimates obtained by running an MCMC algorithm that is detailed in Web Appendix D. In addition to typical model selection criteria such as log marginal likelihood (Newton and Raftery 1994) and DIC (Spiegelhalter et al. 2002) for determining the appropriate number of latent classes, we also considered segment size for model selection. We find that a two-segment model considerably improves fit over a homogeneous model, as there appear to be two highly heterogeneous subgroups in the data. Additional segments continue to subdivide one of these subgroups to better fit the data but do not add new diagnostic insights (see Web Appendix F for fit statistics for a range of models with up to four latent classes and various nested cases) and in some instances result in segment sizes that are too small for robust parameter recovery (see Web Appendix E). To permit intuitive and robust like-for-like comparisons across studies and conditions, we present results for all studies using a two-segment latent class model.

4. Results
4.1. Study 1--Learning Under the Same Plan
4.1.1. Motivation and Procedure. The purpose of this study is to quantify how consumer temporal discounting and random response errors change with game experience as a function of tariff allowance. Consumers might be expected to consider a larger planning horizon (consistent with a higher discount factor) and reduce the propensity for random errors as they receive feedback from bills. In particular, it has been widely noted that "as-if" optimality often arises by the recurrent application of simple trial-anderror (reinforcement) learning rules based on repeating behaviors that yield positive outcomes (low bills and high utility) and avoiding those that do not (e.g., Meyer and Hutchinson 2001, Kunreuther et al. 2009, Young 2009). But whether and with what speed reinforcement rules will allow calling behavior to converge to optimality in this task is unclear. A potential barrier is the noisy nature of feedback that cellphone customers receive; if one ends a game facing overage charges and wants to learn from this experience, one has to imagine the counterfactual policy that would have yielded lower charges but still provided high levels of call utility.
In this study, participants were 125 members of a subject pool of a large northeastern university. All studies were run in a computer lab. Subjects were paid $10 to participate and could earn a bonus (typically between $0 and $2.50) based on an exchange rate of US$1 for every 400 game dollars). Upon being seated participants first read the overall task instructions and were randomly allocated to a plan with an allowance of either 20 seconds (55 subjects) or 40 seconds (70 subjects). Participants then made decisions under this plan for all six games. We used a predefined criterion of task comprehension (accepting 33% or fewer of high-value calls across six games implies lack of task understanding) to screen out subjects not meeting this criterion.5 After screening, there remain 44 subjects in the 20-second condition and 63 subjects in the 40-second condition.6 The exact experimental instructions used and screen shots of the game are provided in Web Appendix C.
4.1.2. Findings: Overall Performance. In Table 1, we show descriptive statistics for number of call arrivals by type and how many were accepted on average across the six games in each condition. As expected, most high-value calls are accepted. A
5 The qualitative features of the aggregate descriptive statistics do not change with the exclusion of these subjects.
6 A two-sample test of proportions shows that the proportions of subjects screened out in each condition are not statistically different (p-value = 0 11).

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

124

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

Table 1

Descriptive Statistics for Study 1--the Values Shown Are Averages Across the Six Games Played by Each Participant, with Across-Participant Standard Deviations in Parentheses

Statistics across participants over the set of six games

Expected call 20-second plan 40-second plan

arrivals

allowance

allowance

Total calls

144

145 (12)

Total low- and

108

110 (12)

medium-valued calls

Number of accepted

N/A

16 (17)

low- and medium-

valued calls

Total high-valued calls

36

35 (6)

Number of accepted

N/A

32 (7)

high value calls

145 (11) 107 (10)
23 (15)
38 (6) 35 (8)

smaller number of low- and medium-value calls (lumped together) are accepted, though there is high variance across subjects.7
In Figures 4 and 5 we plot how participants' call-acceptance decisions corresponded to those prescribed by a fully optimal ( = 1) error-free policy in the 20-second and 40-second plans, respectively.
The figures plot the incidences of three types of potential decision errors: failing to correctly accept a new call, failing to correctly continue an existing call, or failing to correctly reject a call. In Figures 4(a) and 5(a) we see that participants were quite skilled at accepting calls that they should (which would usually be any high-value call) almost from the start, and this achievement increased with play experience. In the first game for the 40-second allowance condition, for example, participants correctly accepted 81% of all optimal calls, and this increased to 92% by the sixth game. In addition, as shown in Figures 4(b) and 5(b), participants were even more skilled at knowing when to continue calls that should be continued; across all games in both plan conditions participants exhibited normative continuation behavior in 99% of all accepted calls.
In contrast, participants were far less skilled at knowing when to decline the low- and medium-value calls that should be rejected (especially early on in a game). As shown in Figure 4(c) (Figure 5(c)) for the 20-second (40-second) allowance condition, participants successfully rejected or terminated only 17% (14%) of all calls that should have been declined, including both new and ongoing ones in game one. With experience decision-making abilities increased, but learning was far from complete, with 62% (53%)
7 Most subjects exceed their free allowance since high-value calls continue to arrive in the overage phase and are worth more than overage cost. In our setting therefore, exceeding overage is not a diagnostic statistic.

of correct rejections and terminations for the 20second (40-second) plan condition in game six. Participants in aggregate seem to do worse in the larger allowance plan even after experience.
4.1.3. Model Results. Although the descriptive results show that participants were able to learn to adopt more efficient call-acceptance policies with experience in the task (albeit to a limit), they are silent on the source of the learning; specifically, whether it might have been due to participants being more farsighted as the task went on, or becoming more consistent in the application of an otherwise farsighted policy. We can explore this by examining the acrossgame properties of the two key parameters of our two-segment behavioral-structural model that we fit to participants' behavior in the task: implied discount rates and scale parameters. In Figures 6 and 7 we plot the posterior mean and 95% posterior interval of the parameters obtained from our MCMC implementation.
Figure 6 shows the game-by-game variation for the model parameters for the two segments (that we label as "error-prone" and "learner," respectively) for the W = 20 plan. The across-game variation of the parameters for the error-prone segment does not show any trend, whereas that for the learner segment clearly shows a pattern. For the latter, the discount parameter (which determines the level of farsightedness) increases over games, whereas the scale parameter (which determines the level of errors) decreases over games. We test for consumer learning by examining whether the difference between two structural parameters in adjacent games includes 0 in the 95% posterior interval, as shown in Table 2 for the scale parameter of the learner segment.
The improvements are not statistically significant beyond game five. The pattern in Figure 6 and Table 2 are both indicative of consumer learning--consumers in the learner segment are becoming more farsighted and are reducing their errors. The learner segment constitutes 84% of the subjects (with the posterior probability of segment membership practically 100% indicating clear separation into latent classes). In Figure 7, we show that the larger allowance plan (W = 40) also features a learner segment (segment 2, 67% of the subjects). Notably, the scale parameter ( ) under the larger allowance plan is significantly larger than that under the smaller allowance plan for each of the games except the first one (for the learner segment), suggesting that subjects learn to reduce errors to a greater extent in the smaller allowance plan.
Note that under both plans, a residual amount of error remains after six games of experience even in the learner segment, since some subjects do not learn to eliminate errors. Though even the error-prone segment learns to reduce errors, residual error variance is

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

125

Figure 4 (Color online) Study 1 (20-Second Allowance)

(a) 100

Do consumers take the calls they ought to?

% of optimal accept decisions

80

60

40

1

2

3

4

5

6

Game

(b)

Do consumers stick with existing calls optimally?

% of optimal continue decisions

100

95

90

85

80

1

2

3

4

5

6

Game

(c)

Do consumers reject calls optimally?

% of optimal reject decisions

100 New and ongoing calls

60

New low-value call ($0.25)

New medium-value call ($0.75)

20

New high-value call ($6)

0

1

2

3

4

5

6

Game

Notes. Most of the calls that should be accepted are high-value ones, hence the overall trajectory is virtually identical to the high-value call acceptance trajectory (graph a). Subjects learn to reject new low- and medium-value calls with experience but performance asymptotes after three games (graph c). The overall call

rejection trajectory is lower than for new call rejection since this includes incorrect continuation of ongoing calls that should be rejected.

Figure 5 (Color online) Study 1 (40-Second Allowance)

(a)

Do consumers take the calls they ought to?

(b)

Do consumers stick with existing calls optimally?

% of optimal continue decisions

% of optimal accept decisions

100

100

80

95

90

60

85

40

80

1

2

3

4

5

6

Game

1

2

3

4

5

6

Game

(c)

Do consumers reject calls optimally?

% of optimal reject decisions

100 New and ongoing calls

60

New low-value call ($0.25)

New medium-value call ($0.75)

20

New high-value call ($6)

0

1

2

3

4

5

6

Game

Note. Similar to Figure 4, learning to reject new low- and medium-value calls asymptotes after three to four games.

Table 2

Study 1--95% Posterior Interval for Difference in Learner Segment's Error Scale Parameter Between Game Pairs

Conditions (imposed)

2L - 1L

3L - 2L

4L - 3L

5L - 4L

6L - 5L

Study 1, 20-second allowance ( - 6 2 -4 5) (-1 7 -0 9) (-0 7 -0 3) (-0 3 0 1) Study 1, 40-second allowance (-2 0 -0 0) (-2 4 -1 3) (-1 0 -0 0) (-0 8 -0 1)
Note. Learning is indicated if the posterior interval excludes nonnegative values (in bold).

(-0 3 0 0) (-0 4 0 1)

significantly higher than the learner segment in both conditions. Further, consumer learning does not continue beyond game five (see Table 2).
4.2. Study 2--Imposed Plan Change
4.2.1. Motivation and Procedure. In natural settings consumers are often faced with changes in

plans, either because of voluntary choices or policy changes imposed by their service provider. There is anecdotal evidence that plan changes have at least a short-term effect in degrading the efficiency of calling decisions, because heuristic policies learned under the previous regime may have little applicability to the new one. For example, consider a consumer who has

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

126

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

Figure 6

Study 1: Posterior Means and 95% Credible Interval of Parameters by Segment and Game for Study 1's 20-Second Allowance Plan

"Error prone segment" beta

"Error prone segment" log(lambda)

log(lambda_ g1)

Beta_ g1

0.9

0.7

0.5

1

2

3

4

5

6

Game

8 6 4 2 0

1

2

3

4

5

6

Game

"Learner segment" beta 1.00

"Learner segment" log(lambda) 4

log(lambda_ g2)

Beta_ g2

3

2 0.85
1

0

0.70

­1

1

2

3

4

5

6

1

2

3

4

5

6

Game

Game

Notes. Note that intervals are wider for large values of log(lambda) and low values of beta, since identification from the data is more challenging for such values. Each graph has a different y-axis range to emphasize variations of interest. Learners improve mostly in the first three games.

Figure 7

Study 1: Posterior Means and 95% Credible Interval of Parameters by Segment and Game for Study 1's 40-Second Allowance Plan

"Error prone segment" beta

"Error prone segment" log(lambda)

log(lambda_ g1)

Beta_ g1

0.9

0.7

0.5

1

2

3

4

5

6

Game

8 6 4 2 0

1

2

3

4

5

6

Game

"Learner segment" beta

"Learner segment" log(lambda)

log(lambda_ g2)

1.00

4

3

Beta_ g2

0.85

2

1

0

0.70

­1

1

2

3

4

5

6

Game

1

2

3

4

5

6

Game

Note. Each graph has a different y-axis range to emphasize variations of interest. Learners improve mostly in the first three games.

become skilled at making call decisions under a plan with a low free allowance who then transitions to a plan with a larger allowance. If the consumer exhibits rule carryover (e.g., Restle 1962), she would, at least for a while, maintain higher standards for call quality as if she were in a low-allowance regime, to avoid incurring overage charges for which there was little real risk. On the other hand, work by Lichtenstein and Fischhoff (1977) and Alba and Hutchinson (2000) suggest that we might see the opposite bias by virtue of what they term the "hard-easy" effect: the larger allowance plan is objectively a harder regime since it involves a larger set of policies to ponder over prior to overage, yet the consumer may misconstrue the regime as one where heuristics that insure vigilance

are no longer required, resulting in lower standards for the quality of accepted calls. The hard-easy effect would predict worse (better) performance when transitioning to a higher (lower) allowance plan whereas the rule carryover effect's predictions would be in the opposite direction.
The purpose of this study is to examine consumer learning and adaptation to imposed plan change by exposing each subject to one TPT plan for three games and the other for the remaining three games. Participants were 156 members of a subject pool recruited on Amazon Mechanical Turk, an online platform for running tasks, which offers access to a stable and diverse subject pool (Mason and Suri 2012). We put in place the following requirements for subjects to qualify for

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

127

our study: a historical task approval rate greater than or equal to 95%, at least 50 tasks approved to date, and based in the United States. Subjects who qualified could see our task posted and undertake it by clicking on the URL that led to our web-based study (ran on Mozilla Firefox browser). Subjects were paid $3 to participate and could earn a bonus (typically between $0­$1) based on an exchange rate of US$1 for every 1,000 game dollars.
Subjects were randomly assigned to start with a 40second allowance TPT plan (cell 1) or a 20-second allowance TPT plan (cell 2), and experienced an imposed change to the other plan after three games. From the original pool, 47 were screened out based on a predefined criterion of task comprehension (accepting 33% or fewer of all high value calls across the six games). Of the remaining 109 subjects, 43 were in cell 1 and 66 were in cell 2.8
4.2.2. Findings: Overall Performance. Similar to study 1, participants were skilled in correctly continuing calls once taken with an average of 98% accuracy across all games in both conditions. We plot the relative incidence of call acceptance and rejection decision errors for cell 1 and cell 2 (Figure 8). Participants accept on average 80% of the calls they should rationally take (Figures 8(a) and 8(c)) across six games in both cells, and although there is learning in the first two games, we see little evidence of a disruptive effect of plan change on this error type.
In contrast, we observe a tangible and asymmetric effect of plan changes on the kind of decision errors that were most prominent in study 1: correct rejections of low- and medium-value calls. Participants who first became familiar with a large plan allowance and then were switched to a smaller plan allowance improved decision accuracy after the plan change (Figure 8(b)). In contrast, participants who first became familiar with a small plan allowance and were then switched to a larger plan allowance performed worse after the plan change, and only partially recovered from this deterioration by game six (Figure 8(d)). As can be seen in Figure 8(d), increased acceptance of mediumvalue calls that should be rejected drives much of the deterioration.
4.2.3. Model Results. The results suggest that, similar to study 1, there are two very different types of subjects. Subjects in the error-prone segment are erratic in their temporal discounting and exhibit a large amount of randomness. Learner subjects, who represent over 60% of the subjects in both cells, exhibit a learning pattern. The latent classes clearly distinguish learners from error-prone subjects as evidenced
8 A two-sample test of proportions shows that the proportions of subjects screened out in each condition are not statistically different (p-value = 0 18).

by the virtually 100% posterior probability of each subject belonging to one of the segments. To examine how the task-change effects were manifested in the structural parameters of the behavioral model, in Figure 9(a) we plot the estimates for the scenario in which participants in the learner segment started with a 40-second allowance and were then switched to a 20-second allowance.
Subjects in the learner segment (63% of subjects) become more farsighted from game one to game two and from game two to game three. The learning effect is much more pronounced from game one to game two for the discount parameter ( ). However, learning asymptotes after game three, and does not seem affected by plan change. For the scale parameter ( ), learning is significant between games two and three, and games three and four (see Table 3). This reduction in errors when switched to the lower allowance plan largely explains the aggregate effect in Figure 9(a).
For the case where participants started with a 20second allowance and were then switched to a 40second allowance, we again see evidence of two different segments; 60.7% of subjects consist of learners who quickly learn to become farsighted while reducing noisy deviations within the first three games (Figure 9(b)). We find that even these learners become noisier when shifted to the higher allowance plan (starting from game four), but recover after some experience in the new plan. Thus there is clear asymmetry in the learning behavior across the two experimental conditions for subjects in the learner segment, in the direction suggested by the hard-easy effect.
4.3. Study 3--Performance Under Volitional Plan Choice
4.3.1. Motivation and Procedure. One potential limitation of the findings of incomplete learning in study 1 and the asymmetric effect of plan switches in study 2 is that both were uncovered in settings where plans were exogenously imposed on decision makers. In natural settings, consumers can self-select into the plans that best fit their own needs and decision skills. Hence, if participants are aware of their differential abilities to make efficient calling decisions under different plan types, we might expect both higher achievement overall and the asymmetric biases observed in studies 1 and 2 to vanish--or at least be mollified--under plan choice.
To test this, we recruited a new panel of 140 participants from Amazon Mechanical Turk, using the same recruitment criteria as study 2. In this new study, participants were initially offered a choice of a 40-second allowance plan at a fixed fee of $80 or a 20-second allowance plan at a fixed fee of $20, after playing a practice game. Participants were given the opportunity to change plans after three games. The fixed

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

128

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

Figure 8

(Color online) Study 2: Cell 1 (40-Second Allowance for First Three Games, 20-Second Allowance for Last Three Games) and Cell 2 (20-Second Allowance for First Three Games, 40-Second Allowance for Last Three Games)

% of optimal accept decisions

(a) Cell 1--Do consumers take the calls they ought to? 100

80

60

40

1

2

3

4

5

6

Game

% of optimal reject decisions

(b) Cell 1--Do consumers reject calls optimally? 100

60

20 0

1

2

3

4

5

6

Game

% of optimal accept decisions

(c) Cell 2--Do consumers take the calls they ought to? 100

80

60

40

1

2

3

4

5

6

Game

% of optimal reject decisions

(d) Cell 2--Do consumers reject calls optimally? 100

60

20 0

1

2

3

4

5

6

Game

New and ongoing calls

New low-value call ($0.25)

New medium-value call ($0.75)

New high-value call ($6)

Notes. Subjects correctly reject more low- and medium-value calls after transitioning to the lower allowance plan. Subjects correctly reject fewer medium-value calls after transitioning to the higher allowance plan.

Figure 9

(Color online) Study 2: Posterior Means and 95% Credible Interval of Parameters for Learner Segment by Game for (a) Study 2's Imposed 40- to 20-Second Plan Transition, and (b) Study 2's Imposed 20- to 40-Second Plan Transition

A TOSECONDPLANTRANSITION

h,EARNERSEGMENTvBETA

h,EARNERSEGMENTvLOGLAMBDA





LOGLAMBDA? g

"ETA? g











n

























'AME

'AME

B TOSECONDPLANTRANSITION

h,EARNERSEGMENTvBETA

h,EARNERSEGMENTvLOGLAMBDA





LOGLAMBDA? g

"ETA? g























'AME

Note. The dotted vertical line demarcates the plan transition point.

n













'AME

Table 3

Study 2­95% Posterior Interval for Difference in Learner Segment's Error Scale Parameter Between Game Pairs

Conditions (imposed)

2L - 1L

3L - 2L

4L - 3L

5L - 4L

6L - 5L

Study 2, low to high allowance (-5 2 -2 9) (-0 7 -0 2) (0 1 0 6) Study 2, high to low allowance (-1 4 0 1) (-1 9 -0 9) (-1 1 -0 4)

(-0 5 0 0) (-0 3 0 1) (-0 3 0 1) (-0 3 0 1)

Notes. Learning or deterioration is indicated if the posterior interval excludes zero (in bold). The shaded cells indicate transition because of plan change.

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

129

fees were chosen such that the expected surplus for a consumer who does not discount future call values is about the same across the two plans. From the original pool, 33 were screened out based on a predefined criterion of task comprehension (accepting 33% or fewer of all high-value calls across the six games). Of the remaining 107 subjects, 29 started in the 40second allowance plan and 78 started in the 20-second allowance plan. Twelve out of 29 subjects starting in the 40-second plan switched to the 20-second plan after three games, whereas 32 out of 78 starting in the 20-second plan switched to the 40-second plan after three games.
4.3.2. Findings: Overall Performance. In Figure 10 we plot the key measure of performance-- percentage of calls that were incorrectly pursued when in fact optimal to reject--for each of the four possible plan-choice combinations: those who started with the 40-second plan and stayed with it (N = 17), those who stayed with the 40 and switched to a 20 (N = 12), those who started with the 20-second plan and stayed (N = 46), and those who started with a 20 and switched to a more generous plan (N = 32). The other performance measures (correct acceptance and continuance of calls) were similar to the corresponding imposed plan conditions in studies 1 and 2.
By comparing the panels of Figure 10 with those from studies 1 and 2 (Figures 4, 5, and 8) we see an immediate answer to the question of whether having free choice helped: it did not. Similar to study 1, those who stuck to the same plan throughout displayed steady learning (Figures 10(a) and 10(b)). Likewise, the self-selection data show an asymmetric effect of learning for those who switched plans. As shown in Figure 10(c), switchers from the higher to lower plan allowance learn at a gentle rate (the solid line) while correct rejection of low- and medium-valued calls improves mildly. In contrast, switchers from the lower to higher plan allowance perform worse (solid line in Figure 10(d)), which is especially driven by increased usage allocation to medium-valued calls.
4.3.3. Model Results. For the cases where participants switched plans--either from 40 to 20 seconds or 20 to 40 seconds--we find that learning appears to come more from participants reducing response errors ( ) than from overcoming myopia ( ), in line with the earlier studies. We find that participants significantly improve learning after choosing a lower allowance, whereas those choosing a higher allowance plan regress to some extent9 as shown in Table 4.
9 Though we observe an increase in when participants choose a higher allowance plan, the effect is not significant perhaps because of the lower sample size resulting from self-selection in this condition.

4.4. Study 4--Effect of Risk Attitude on Discounting
Note that in our task there is no uncertainty in current period utility. There is, however, uncertainty in the distribution of future payoffs, which raises the possibility that our estimates of time discounting may also be capturing individual differences in risk aversion. Specifically, respondents may appear to be giving more weight to immediate (and certain) call values less because they are myopic and more because they prefer certain over uncertain call values. To test this we recruited a sample (N = 41) of participants to perform the 40-second calling task described in study 1, and also took measures of their risk attitudes using the lottery task described by Holt and Laury (2002). Details of the lottery task are in Web Appendix G. We test whether this risk measure (Ri) moderates each individual's discount factor ( ig) by incorporating it as a covariate in our structural model and allowing slopes ( s) to be latent class-specific (i.e.,
ig = function gs s Ri . The mean raw risk aversion score of the 41 participants was 6.22 (the risk-neutral score is 4) indicating that subjects on average tended toward being risk averse in line with Holt and Laury (2002). We subtract four from the raw score to yield the risk attitude covariate (higher than zero indicates risk aversion, less than zero indicates risk seeking). We find that the error-prone segment has a risk attitude slope that is not statistically different from zero, whereas the learner segment has a slope that is positive (0.11) whose 95% posterior interval excludes zero. The result suggests individuals who are more risk averse as measured by the Holt and Laury (2002) task were, surprisingly, also more forward looking in our simulation task. Whether this result might generalize to other settings is uncertain, as there have been relatively few prior attempts to examine the relationship between risk and intertemporal discounting (e.g., Andersen et al. 2008, Coble and Lusk 2010). As the learning curves for discounting and random error propensities remain similar to those in study 1, this result suggests that our model is capturing intertemporal preference effects that go beyond the effects of relative risk aversion, which appear empirically small.
4.5. Robustness Checks In this section, we describe additional studies and analyses that test the robustness of our findings from the main set of studies. First, decision errors might be reduced if participants were given more information about their usage of time in the task--something the Federal Communications Commission has negotiated with telecom companies to implement (Jiang 2013). To test usage-awareness effects, we modified the 40second plan condition of study 1 such that participants were provided with either a pop-up alert when

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

130

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

Figure 10

(Color online) Study 3: Call Rejection Performance for All Four Self-Selected Cells That Participants Could End Up in, Based on Their First and Second Plan Choice

A !LWAYSCHOSESECPLANCALLREJECTIONPERFORMANCE 

B !LWAYSCHOSESECPLANCALLREJECTIONPERFORMANCE 

OFOPTIMAL REJECTDECISIONS

OFOPTIMAL REJECTDECISIONS





 













'AME

 













'AME

OFOPTIMAL REJECTDECISIONS

C 3WITCHEDFROMTOSECPLANCALLREJECTIONPERFORMANCE 

D 3WITCHEDFROMTOSECPLANCALLREJECTIONPERFORMANCE 

OFOPTIMAL REJECTDECISIONS





 













'AME

 













'AME

.EWANDONGOINGCALLS

.EWLOWVALUECALL

.EWMEDIUMVALUECALL

Table 4

Study 1--95% Posterior Interval for Difference in Learner Segment's Error Scale Parameter Between Game Pairs

Conditions (self-selected)

2L - 1L

3L - 2L

4L - 3L

5L - 4L

6L - 5L

Study 3, Low to high allowance (-2 4 -0 9) (-1 0 -0 4) (-0 0 0 6) (-0 3 0 3) (-0 5 0 0) Study 3, High to low allowance (-3 7 -1 1) (-0 8 0 5) (-1 6 -0 7) (-0 4 0 3) (-0 4 0 3)
Notes. Learning or deterioration is indicated if the posterior interval excludes zero (in bold). The shaded cells indicate transition due to plan change.

they used up 80% of their free allowance (call alert study), or an alert and visible real-time counter of talk time used (usage display study). Participants learned more quickly early on to achieve a higher correct call rejection percentage of 29% (35%) in the first three games of the call alert (usage display) study as compared to the study 1 40-second plan condition (23% average over first three games). However, participants achieve approximately the same performance in the final three games (original study: 49%, call alert study: 46%, usage display study: 47%) indicating that these interventions do not lift overall performance after participants build task experience.
Second, we reduced the size of the fixed fee (from $80 to $20) in the 40-second plan condition of study 1 to understand if the larger up-front fee of the 40second plan relative to the 20-second plan may be driving our results, since participants may be driven by a need to use as many seconds as possible to justify the larger fixed fee (a sunk cost effect akin to Arkes and Blumer 1985). The reduced fixed-fee study causes a slight lift in correct call rejection performance (58% average in final three games) but does not markedly change the learning curve compared to the corresponding study 1 condition.

Finally, we tested for curvature effects in current period utility using study 1 data by running a model that included a quadratic net current utility (call value less any cost) term and allowed the slope for the quadratic term to vary by latent class membership.10 We find that the slope coefficient is very close to the lower bound of zero for both segments and the DIC for this model is worse than the original model for the 40-second plan (17,210 versus 17,200), reflecting that the two additional curvature slope parameters did not improve fit. This result makes sense in our setting where call utilities are explicitly given to subjects (hence no uncertainty in current period utility), who have an incentive proportional to maximizing net utility.
5. Discussion
The purpose of this paper was to investigate the ability of individuals to make optimal call-usage decisions under multipart pricing schemes. Our findings
10 We restrict this slope to be between zero and an upper bound computed to ensure that the resulting utility function is concave and increasing. The slope is identified because we set the slope of the linear net utility term to 1.

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

131

are based on data drawn from a series of controlled laboratory experiments in which participants made a series of decisions whether to accept simulated incoming phone calls in a setting for which there was a known optimal usage policy. Although the laboratory environment lacked the ecological realism that would have come from studying call behavior in the field (e.g., Grubb 2009), it had the advantage of allowing us to draw strong inferences about intuitive optimality that would be otherwise difficult to achieve. For example, by providing participants with the distribution of arriving calls we were able to tease apart variance in usage behavior that accrued to varying rational expectations about future calls and how participants traded off the present versus future value of those calls.
One of our major findings was that mean usage behavior approached that which would be optimal under different plans given repeated experience, as evidenced by increasing farsightedness and reduced errors in responses over time. However, we also found learning to be incomplete, with participants still making the error of incorrectly accepting too many lowervalued calls despite multiple rounds of experience. The experiments also revealed an asymmetric bias in achievement when participants were forcibly switched between plans that varied in the amount of free talk time. Specifically, transitioning from a large to small allowance plan accelerated learning whereas the converse resulted in regression. The direction of this asymmetric effect is in line with the hard-easy effect (Lichtenstein and Fischhoff 1977) rather than a uniform tendency to carry over polices learned in one context to another (Restle 1962). Perhaps most surprisingly, these results proved to be robust to such manipulations as allowing participants to choose their own plans, providing warnings when their free talk time was almost used up, and by making talk time visible, as well as to risk preferences. We also find systematic evidence for a small but highly error-prone segment whose learning asymptotes at much higher levels of error variance compared to the "learners."
In line with past research that has investigated how plan characteristics impact consumption (e.g., Ascarza et al. 2012, Leider and Sahin 2014) we find that increasing free allowance results in overconsumption of lower-valued calls that ought to be rejected. Our work suggests this is due to increased errors under plans with large "free" allowances, rather than a utility bias for "free" minutes or suboptimal threshold policies. Other work has considered how consumers' inattention to past usage may impact their future consumption under multipart tariffs (e.g., Grubb 2014, Grubb and Osborne 2013, Jiang 2013). For instance, Jiang (2013) and Grubb and Osborne (2013) cite evidence of a lack of bunching at points when the free

Table 5

Lift in Average Bonus for Learner Segment by Using Error-Free Optimal Policy with No Discounting of Future Call Values for Study 1

Game 1 Game 2 Game 3 Game 4 Game 5 Game 6

20-second allowance (%) 254 42 20

76

4

40-second allowance (%) 195 54 20 12 9

5

allowance is used up and attribute this to consumer inattention to usage. Interestingly, we find little evidence that inattention drives suboptimal usage allocation in our experimental setting. Consumers accept too many lower-valued calls and deplete their free allowance, therefore resulting in overage when they take the higher-valued calls that they should rationally accept.
Subjects in the "learner" segment who did not largely eliminate errors fell prey to a flat maximum around the objective function as shown in Table 5, as the lift from eliminating game six errors is about 5% for study 1 conditions. Cognitive miserliness can explain this result as additional effort to improve performance has diminishing payoffs for learner subjects. Yet, error-prone subjects could have substantially improved earnings relative to learners by updating their decision-making strategies with game feedback. In study 1, subjects in the 20-second (40-second) plan allowance who were classified as error-prone earned an average bonus of $0.27 ($0.60) compared to an average of $1.57 ($1.69) for those in the learner segment. One possibility is that these subjects simply could not exercise the discipline needed to avoid lower-valued calls--these types of consumers may be especially prone to incurring overage charges and racking up higher monthly bills (whether it comes as a shock or not).
Although observed in a laboratory setting, we suggest that the findings may aid recent attempts to inform telecom regulators (such as the Federal Communications Commission) seeking to enhance consumer welfare under multipart tariffs (e.g., Grubb and Osborne 2013, Jiang 2013). To date, most actions that have been introduced to help consumers avoid "bill shock" have been based on the assumption that usage errors accrue primarily because of usage inattention. If true, providing consumers with more complete information about usage (such as limit alerts) should allow them to properly balance short-term and long-term costs when making usage decisions. One of the key findings of our work, however, is such interventions may be less successful than widely presumed; the usage biases we observed were robust to usage-limit alerts and posting elapsed usage. The reason is that the errors we observed were not primarily caused by inattention, but rather by participants being overly myopic when first exposed to a plan and then making too many errors later--two sources not

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

132

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

remedied by making them more informed about time. Knowing this, it might be more useful to communicate projected usage costs in the future rather than how much talk time has been used. Likewise, our data also show that consumers cannot be counted on to be aware of their own biases and choose the plans to which they are cognitively best suited, as allowing free choice of plans also did little to mitigate the pattern of errors.
But although there may be no simple fix either for usage or plan choice errors, the positive message here is that, with experience, these errors diminish; hence, in some cases the best consumer healing tool may just be time itself. In other cases where errors may not diminish quickly (such as for the error-prone segment), more detailed interventions may be needed. For instance, providing a planning tool that projects usage and overage costs at the current run rate may draw more attention to the future consequences of current decisions. Tools such as intelligent virtual assistants (e.g., Siri in the Apple iOS system) may be able to learn user preferences and biases over time and provide recommendations when it may help the user.
One of the limitations of our work is that our data were drawn from behavior in an experimental task that simplified the real-world problem of cell-phone usage. In our setting, participants were not tempted to make outgoing calls, call value and duration were known upon arrival and uncorrelated, and there was no data usage of the phone. Given these simplifications, the view of consumer optimality that we offered may, if anything, be an optimistic one relative to that which we might observe in a more complex task setting. In field settings, consumers may have significantly lower attention because of the longer time span of the billing cycle and distractions because of other activities. Further, the distribution of call utilities is likely much more complex than the design choices we implemented, which can slow down learning. As a result, the value of alerts and other interventions in the field may have benefits beyond what we demonstrate in our experiments.
Future experimental work can probe the boundaries of the biases uncovered here by changing the task design. On one hand, task difficulty could be increased by providing a larger set of call values (and probabilities), extending the calling task over a longer time period, and adding more distractions to mimic real-world task attention spans, all of which would be expected to exacerbate decision errors. On the other hand, learning effects may be stronger if participants played a larger set of games--though they would almost certainly need breaks during the task to avoid mental depletion.
In this same light, researchers can explore the effects uncovered in this paper using field data by

combining data sources, whether through consumer "call diaries," recalled distribution of calls on a suitable importance scale, or by exploiting natural variation in the data. Using either natural experiments (e.g., Yao et al. 2012), or imposing exclusion restrictions to separate current and future payoffs (e.g., Chung et al. 2014) can help pin down discount rates, which are essential to understand temporal usage trade-offs, along with patterns of learning and error variance. Akin to Dubé et al. (2013), our approach demonstrates that experiments can help with identification of structural parameters that are challenging to recover using field data. Augmenting field data with experimental data could yield further insights on consumer primitives.
We hope that our work in the cell-phone consumption context encourages future research in several other related domains such as diet management (e.g., Guthrie et al. 1995), consumption of goods using credit cards (e.g., Gross and Souleles 2002), the use of banking products (e.g., Stango and Zinman 2009), and health insurance (e.g., Aron-Dine et al. 2012). Understanding what assumptions typically used in empirical models hold in terms of underlying dynamic usage behavior can better aid both researchers and practitioners in their attempts to better anticipate the consequences of policy actions on consumer behavior and welfare.
Supplemental Material Supplemental material to this paper is available at http://dx .doi.org/10.1287/mksc.2014.0877.
Acknowledgments The authors thank Alessandro Arlotto, Eric Bradlow, Jeffrey Cai, Yupeng Chen, Pete Fader, Lynn Selhat, Christophe Van den Bulte, Qin Zhang, seminar participants at the 2012 Wharton Marketing Lunch Seminar series, Cornell University, and University of Washington Marketing Camp, and session participants at the 2012 INFORMS Marketing Science, 2013 University of Texas at Dallas and 2013 Theory & Practice in Marketing conferences for their helpful comments. The authors thank Amanda Gulick, Tony Kutovoy, Robert Botto, and Rich Fritzson for data collection assistance and support. The authors thank the Marketing Science review team for their thoughtful comments throughout the review process. The first author acknowledges the generous support of the Russell Ackoff Doctoral Student Fellowship and the Wharton Risk Management and Decision Processes Center for this research. This work was supported by an Amazon Web Services in Education Grant. The order of authorship is alphabetical.
References
Alba JW, Hutchinson JW (2000) Knowledge calibration: What consumers know and what they think they know. J. Consumer Res. 27(2):123­156.
Andersen S, Harrison GW, Lau MI, Rutström EE (2008) Eliciting risk and time preferences. Econometrica 76(3):583­618.

Gopalakrishnan, Iyengar, and Meyer: Consumer Dynamic Usage Allocation and Learning

Marketing Science 34(1), pp. 116­133, © 2015 INFORMS

133

Arcidiacono P, Ellickson PB (2011) Practical methods for estimation of dynamic discrete choice models. Annu. Rev. Econom. 3(1): 363­394.
Arkes HR, Blumer C (1985) The psychology of sunk cost. Organ. Behav. Human Decision Processes 35(1):124­140.
Aron-Dine A, Einav L, Finkelstein A, Cullen MR (2012) Moral hazard in health insurance: How important is forward looking behavior? NBER Working Paper 17802.
Ascarza E, Lambrecht A, Vilcassim N (2012) When talk is "free": The effect of tariff structure on usage under two- and threepart tariffs. J. Marketing Res. 49(6):882­899.
Ater I, Landsman V (2013) Do customers learn from experience? Evidence from retail banking. Management Sci. 59(9):2019­2035.
Bagh A, Bhargava HK (2013) How to price discriminate when tariff size matters. Marketing Sci. 32(1):111­126.
Bar-Gill O, Stone R (2009) Mobile misperceptions. Harv. JL Tech. 23(1):49­118.
Chung DJ, Steenburgh T, Sudhir K (2014) Do bonuses enhance sales productivity? A dynamic structural analysis of bonus-based compensation plans. Marketing Sci. 33(2):165­187.
Coble KH, Lusk JL (2010) At the nexus of risk and time preferences: An experimental investigation. J. Risk Uncertainty 41(1): 67­79.
Dubé J-P, Hitsch GJ, Jindal P (2013) The joint identification of utility and discount functions from stated choice data: An application to durable goods adoption. Quant. Marketing Econom. Forthcoming.
Erdem T, Keane MP (1996) Decision making under uncertainty: Capturing dynamic brand choice processes in turbulent consumer goods markets. Marketing Sci. 15(1):1­20.
Goettler RL, Clay K (2011) Tariff choice with consumer learning and switching costs. J. Marketing Res. 48(4):633­652.
Gross DB, Souleles NS (2002) Do liquidity constraints and interest rates matter for consumer behavior? Evidence from credit card data. Quart. J. Econom. 117(1):149­185.
Grubb MD (2009) Selling to overconfident consumers. Amer. Econom. Rev. 99(5):1770­1807.
Grubb MD (2014) Consumer inattention and bill-shock regulation. Rev. Econom. Stud. Forthcoming.
Grubb MD, Osborne M (2013) Cellular service demand: Biased beliefs, learning, and bill shock. Amer. Econom. Rev. Forthcoming.
Guthrie JF, Fox JJ, Cleveland LE, Welsh S (1995) Who uses nutrition labeling, and what effects does label use have on diet quality? J. Nutrition Ed. 27(4):163­172.
Holt CA, Laury SK (2002) Risk aversion and incentive effects. Amer. Econom. Rev. 92(5):1644­1655.
Jiang L (2013) The welfare effects of "bill shock" regulation in mobile telecommunications markets. Working paper, Sauder School of Business, University of British Columbia, Vancouver.

Kamakura WA, Russell GJ (1989) A probabilistic choice model for market segmentation and elasticity structure. J. Marketing Res. 26(4):379­390.
Kunreuther H, Silvasi G, Bradlow ET, Small D (2009) Bayesian analysis of deterministic and stochastic prisoner's dilemma games. Judgment Decision Making 4(5):363­384.
Lambrecht A, Skiera B (2006) Paying too much and being happy about it: Existence, causes and consequences of tariff-choice biases. J. Marketing Res. 43(2):212­223.
Lambrecht A, Seim K, Skiera B (2007) Does uncertainty matter? Consumer behavior under three-part tariffs. Marketing Sci. 26(5):698­710.
Leider S, Sahin O (2014) Contracts, biases and consumption of access services. Management Sci. 60(9):2198­2222.
Lichtenstein S, Fischhoff B (1977) Do those who know more also know more about how much they know? Organ. Behav. Human Performance 20(2):159­183.
Mason W, Suri S (2012) Conducting behavioral research on Amazon's Mechanical Turk. Behav. Res. Methods 44(1):1­23.
McKelvey RD, Palfrey TR (1995) Quantal response equilibria for normal form games. Games Econom. Behav. 10(1):6­38.
Meyer RJ, Hutchinson JW (2001) Bumbling geniuses: The power of everyday reasoning in multi-stage decision making. Wharton on Making Decisions (John Wiley & Sons, New York).
Miravete EJ (2003) Choosing the wrong calling plan? Ignorance and learning. Amer. Econom. Rev. 93(1):297­310.
Newton MA, Raftery AE (1994) Approximate Bayesian inference with the weighted likelihood bootstrap. J. Roy. Statist. Soc.: Ser. B 56(1):3­48.
Oren S, Smith S, Wilson R (1985) Capacity pricing. Econometrica 53(3):545­566.
Restle F (1962) The selection of strategies in cue learning. Psych. Rev. 69(4):329­343.
Rust J (1987) Optimal replacement of GMC bus engines: An empirical model of Harold Zurcher. Econometrica 55(5):999­1033.
Salisbury L, Feinberg F (2010) Alleviating the constant stochastic variance assumption in decision research: Theory, measurement, and experimental test. Marketing Sci. 29(1):1­17.
Spiegelhalter DJ, Best NG, Carlin BP, Van Der Linde A (2002) Bayesian measures of model complexity and fit. J. Royal Statist. Soc.: Ser. B 64(4):583­639.
Stango V, Zinman J (2009) What do consumers really pay on their checking and credit card accounts? Explicit, implicit, and avoidable costs. Amer. Econom. Rev. 99(2):424­429.
Yao S, Mela CF, Chiang J, Chen Y (2012) Determining consumers' discount rates with field studies. J. Marketing Res. 49(6): 822­841.
Young PH (2009) Learning by trial and error. Games Econom. Behav. 65(2):626­643.

