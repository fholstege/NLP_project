Vol. 35, No. 5, September­October 2016, pp. 810­826 ISSN 0732-2399 (print) ISSN 1526-548X (online)

http://dx.doi.org/10.1287/mksc.2015.0973 © 2016 INFORMS

Try It, You'll Like It--Or Will You? The Perils of Early Free-Trial Promotions for
High-Tech Service Adoption

Bram Foubert
Department of Marketing and Supply Chain Management, School of Business and Economics, Maastricht University, 6200 MD Maastricht, Netherlands, b.foubert@maastrichtuniversity.nl
Els Gijsbrechts
Department of Marketing, Tilburg School of Economics and Management, Tilburg University, 5000 LE Tilburg, Netherlands, e.gijsbrechts@uvt.nl
The proliferation of free trials for high-tech services calls for a careful study of their effectiveness, and the drivers thereof. On one hand, free trials can generate new paying subscribers by allowing consumers to become acquainted with the service free of charge. On the other hand, a disappointing trial experience might alienate potential customers, when they decide not to adopt the system and are lost for good. This dilemma is particularly worrisome in early periods, when service quality has not been "tried and tested" in the field, and breakdowns occur. We accommodate these phenomena in a model of consumers' free-trial and regular adoption decisions. Among other effects, it incorporates usage- and word-of-mouth-based learning about quality in a setting where quality itself is evolving. Consumers are forward-looking in that they account for changes in quality and anticipate uncertainty reduction due to trial usage. We estimate our model and run simulations on the basis of a rich and unique data set that incorporates customers' trial subscription, adoption, and usage behavior for an interactive digital television service. The results underscore that free trials constitute a double-edged sword, and that timing and consumers' usage intensity during the trial are key to the effectiveness of these promotions. Implications for managers are also discussed.
Data, as supplemental material, are available at http://dx.doi.org/10.1287/mksc.2015.0973.
Keywords: free-trial promotions; adoption behavior; high-tech consumer services; contractual services; learning; promotion effectiveness; promotion timing; usage
History: Received: May 8, 2013; accepted: September 13, 2015; Preyas Desai served as the editor-in-chief and Puneet Manchanda served as associate editor for this article. Published online in Articles in Advance May 31, 2016.

1. Introduction
With the rise of high-tech consumer services involving contractual arrangements, free-trial promotions have gained widespread acceptance, becoming the rule rather than the exception. Examples particularly abound for software packages (e.g., antivirus software), communication (e.g., telephone, Internet), and entertainment services (e.g., interactive television). Free-trial promotions offer consumers free access to a full-fledged or restricted version of the service for a limited period. A popular example is the online movie rental service Netflix, which heavily advertises its two- or four-week free-trial offer (Chatterjee et al. 2009). After the trial, consumers can opt out or do nothing and automatically become paying subscribers.
Despite their pervasive presence, free-trial promotions are not well understood. Netflix boasts a trialto-adoption conversion rate of approximately 90% (Chatterjee et al. 2009), but many post-trial adopters might have adopted anyway, even without the trial.

Moreover, the 10% of nonadopters could include people who would have signed a regular contract in the absence of a free trial but decided not to adopt after having tried the system at a moment that service quality was subpar. This concern is particularly relevant for high-tech services, whose quality may change over time due to fluctuations in technical service performance (e.g., Zhang and Niu 2014). Yet, surprisingly little research considers how the timing of a free trial and consumers' usage intensity during the trial might affect adoption of high-tech consumer service contracts.
Although scarce compared with the vast research on price promotion, studies of free-trial and sample promotions offer some valuable insights. Early research indicates that samples exert lasting effects on sales (Heiman et al. 2001). Bawa and Shoemaker (2004) identify different phenomena underlying a sample's sales impact. A sample may initially cannibalize regular brand purchases from consumers who would have been willing to buy the product. However, after the

810

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

811

promotion, the brand likely benefits from accelerated purchases (by consumers who adopt sooner than they would have without the sample) and market expansion (buyers who would not have adopted the product without the sample). Existing research also addresses why consumers are more likely to adopt after a sample or trial promotion. Halbheer et al. (2014) analytically show that the effectiveness of a (permanent) free trial for information goods depends on the trial's impact on the valence of consumers' quality beliefs;1 Marks and Kamins (1988) find that samples reduce belief uncertainty. Apart from these direct effects, a trial can also indirectly influence adoption through word of mouth (WOM). People who have tried a product may initiate brand-related conversations and alter other consumers' beliefs. The more people engage in WOM, the more effective sampling becomes (Jain et al. 1995).
These findings are insightful, but the unique characteristics of our focal setting, i.e., contractual high-tech services, suggest some important differences. First, the quality of high-tech consumer services is not stationary but fluctuates over time (e.g., Zhang and Niu 2014), such that the valence of the trial experience and the trial's WOM effects depend on when the promotion is offered. While quality fluctuations are intrinsic to services in general, they are particularly common in high-tech service settings. In pursuit of early-mover advantages, high-tech service companies may trade off quality to speed up market entry and lock in a substantial number of customers. As a result, quality may be subpar and breakdowns may occur especially early in the service's life cycle. Extant sampling and free-trial literature suggests that allowing consumers to try a product or service at least does not reduce the number of adopters; that is, even if it does not help, it will not hurt (e.g., Bawa and Shoemaker 2004, Heiman et al. 2001, Jain et al. 1995). By contrast, we expect that if the service's quality is insufficient, the trial could lead to a substantial loss of customers who, absent the possibility to first try the service, would have entered into a paid long-term contract.
Second, a free service trial does not involve a fixed consumption amount but rather a fixed consumption period. Experience accumulation and learning thus is not fixed across triers but depends on their usage intensity. Most sampling studies consider consumer packaged goods, for which sample acceptance and consumption largely coincide (e.g., Bawa and Shoemaker 2004). The few studies that consider trials of durable products, services or information goods ignore the effects of usage
1 In a related context, Pauwels and Weiss (2008) examine the implications when an online content provider moves from "free to fee." These investigations differ from our setting in not only the focal context but also the studied instruments (permanent pricing instead of temporary promotional offers).

on trial performance (e.g., Halbheer et al. 2014, Jain et al. 1995, Pauwels and Weiss 2008). Yet, understanding the impact of usage is essential in these settings: It helps managers assess the likely outcome of an ongoing trial promotion and may urge them to take action if usage rates appear too low.
Third, a trial for a high-tech service may trigger specific decision dynamics. For one, whereas current research addresses settings in which conversion of triers into paying customers occurs on an opt-in basis, users of a temporary service trial typically must explicitly opt out if they prefer not to adopt the paid service. As a result, trial users may adopt just to avoid the hassle of opting out. Furthermore, for subscribers to become acquainted with the system, a high-tech service trial usually covers a sufficiently long period; consequently, consumers may get used to the trial's zero price and become less willing to adopt the paid service.
In this paper, we examine how free-trial promotions for contractual high-tech consumer services influence adoption. We focus on adoption (rather than repurchase) decisions because they are typically associated with higher risk and lower product knowledge, and are critical to the success of new products (Ho et al. 2012). We present a framework for the trial mechanisms and develop a model for a consumer's free-trial subscription and paid adoption decisions. Our model accommodates consumers' quality learning from trial usage, WOM, advertising, and direct marketing, in a context in which service quality itself evolves over time. Consumers are forward-looking in that they account for quality changes and anticipate uncertainty reduction due to trial usage. We estimate our model on a unique data set, incorporating customers' trial subscription, adoption, and usage behavior for an interactive digital television (IDTV) service. The interactive TV and video-on-demand market has evolved into a multibillion-dollar industry that spurs the interest of academics (e.g., Nam et al. 2010). Our findings generate important managerial insights. First, we assess the effects of a free trial on consumers' adoption behavior and compare the trial's learning effects with those of advertising and direct marketing. Second, we demonstrate that ill-timed free trials may actually reduce the number of adopters. Third, we shed light on the appropriate timing of free-trial promotions and the role of consumers' usage intensity during the trial.
Below, we first develop our conceptual framework. Next, we elaborate on the study context and available data. We then present the model specification and estimation results, and simulate the performance implications of alternative free-trial scenarios. We conclude with a discussion of academic and managerial implications, limitations, and future research.

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

812

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

2. Conceptual Framework
Figure 1 depicts the processes that govern a consumer's decision to adopt a new high-tech service. In the absence of a free-trial promotion, the consumer's propensity to adopt depends on marketing communication and WOM (Manchanda et al. 2008): Advertising or direct marketing, and contacts with current adopters, enable the consumer to learn about the service's quality (see the solid lines in Figure 1). A temporary free trial influences adoption in two ways (dashed lines in Figure 1), i.e., directly, by allowing the consumer to try the service and learn through own usage, and indirectly, because trial subscribers may spread WOM.
Whether a free trial increases the number of adopters depends on the extent to which it generates new subscribers who would not have adopted without the trial. However, as we will argue in this section, the free trial's effectiveness also rests on its ability to avoid losing customers who would have adopted in the absence of a trial promotion. Figure 2 presents the free trial's impact on adoption as the difference between the number of adopters gained and the number of

adopters lost. Below, we discuss the components of Figure 2 and link them to the mechanisms in Figure 1.
2.1. Adopters Gained in Response to Trial Promotion
In Figure 2, the gray- and black-striped boxes refer to adopters gained after own trial usage and adopters gained just due to WOM, respectively.
Adopters gained after own trial usage. A free trial may appeal to consumers who otherwise would not subscribe for several reasons (see Figure 1). First, it allows them to start using the service without paying any setup or periodic fees. Second, by contrast with a paid subscription, which involves a long-term commitment (e.g., a one-year software license), a free trial permits the consumer to end the relationship with the seller sooner, without penalty. Though some consumers may prefer a long-term contract for reasons of precommitment or convenience (Wertenbroch 1998), most consumers value the possibility to reconsider their subscription at a later time when they have experienced the service and have become more certain about its quality. That is, the trial provides a so-called option

Figure 1 Consumers' Decision Process in the Presence of a Free-Trial Promotion

Marketing communication

Wordofmouth

Nonadoption

Free-trial subscription
No periodic or setup fees: + Option premium: + Smart-shopper feelings: +

Figure 2 Impact of a Free-Trial Promotion on Adoption: A Decomposition Adopters gained

Paid adoption
No setup fee: + Inertia premium/No installation effort: + Reference price effect: ­ Learning through usage: +­
Adopters lost

Free-trial
impact on =
adoption

After own trial usage
­

After own trial usage

Due to wordofmouth

Due to wordofmouth

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

813

premium (Sriram et al. 2015). Finally, in addition to their purely rational benefits, the trial's free nature and its option premium may trigger smart-shopper feelings, in which consumers derive pleasure just from receiving a deal (Bicen and Madhavaram 2013).
After completing the free trial, consumers may be more likely to become paying adopters (see Figure 1). First, free triers pay no setup fee because the service is already in place. Second, continuation of the subscription does not require any installation effort; rather, not acting and continuing to use the service implies a reduction of effort, a so-called inertia premium (Su 2009). Third, and most crucially, triers can learn about the service's quality through own experience, which may improve their perceived service benefits. Learning reduces uncertainty, which has a positive effect on (risk-averse) consumers' appraisal of the service. In addition, learning from trial usage can generate more favorable quality beliefs than those based on external quality signals alone. For example, consumers may doubt the credibility of advertising and direct marketing and therefore discount (possibly more than is justified) quality signals obtained via these marketing channels (Mehta et al. 2008).
Adopters gained due to WOM. A free trial may also generate new adopters in an indirect way (Ghose and Han 2011). As Figure 1 indicates, triers and adoptersafter-trial may engage in WOM communication, such that current nonusers learn more about the service's actual quality (Jain et al. 1995, Manchanda et al. 2008, Nam et al. 2010). Quality signals obtained through WOM help nonusers reduce their quality uncertainty and may lead to more favorable quality beliefs than the less trusted marketing signals.
2.2. Adopters Lost in Response to Trial Promotion In the context of high-tech contractual services, free trials can also have negative effects on consumers' adoption decisions. That is, some consumers who would have adopted a long-term contract in the absence of a trial promotion might refrain from adopting after trial usage or due to WOM. In Figure 2, we use the gray- and black-colored boxes to indicate these consumer groups.
Adopters lost after own trial usage. A free trial may attract people who willingly would have adopted the paid service in the absence of the trial. This creates important risks. First, as noted in Figure 1, the free trial may reduce reference prices (Pauwels and Weiss 2008), such that the fees that come with regular adoption loom larger after a free trial. Second, trial usage enables the consumer to learn and become more certain about the service's quality, but the net impact of such learning is not necessarily positive (Sriram et al. 2015). When the consumer has a negative trial experience, the resulting quality beliefs may be less favorable than those formed (only) on the basis of advertising and direct marketing signals, even when she discounts

marketing information. This holds particularly for hightech services, whose actual performance is evolving and which may suffer from technical malfunctions, especially early in the service life cycle. The consumer may insufficiently account for the temporary nature of these deficiencies and take the bad experience as a signal of the service's long-run quality. As a result consumers who would otherwise have accepted a regular subscription may renege after a free trial.
Adopters lost due to WOM. Negative trial experiences may be shared with others such that consumers who do not use the trial also learn about the service's deficiencies. These WOM signals make consumers more certain about the service's quality, but also decrease the valence of their quality beliefs. As a result, they may decide not to subscribe to the service, which they would have adopted without the trial.
In summary, the final impact of the free trial rides on the dual mechanism of attracting consumers who otherwise would not have subscribed to the service, and minimizing the losses of consumers who otherwise would have adopted. A crucial determinant of the relative sizes of these consumer groups is consumers' learning process in the presence of a trial: What consumers (directly or indirectly) learn from the trial may differ from what they learn from marketing, and may change over time. We incorporate these aspects in our adoption decision model.
3. Data
3.1. Study Context We use data from a large West European telecom firm that offers telephone, Internet, and TV services and operates in a single country. The data cover consumers' adoption behavior and the company's marketing efforts for DSL-based IDTV during the first two years after the service's launch. In the country and period of study, the company has a market share of 31% in the digital TV market, and is the only provider of IDTV via DSL.2 To allow modeling of consumers' adoption decisions, our data also include customers who never subscribed to IDTV and only use the company's other services.
To use the IDTV service, customers must install a DSL modem and a set-top box that decodes the digital signal. The service grants access to a wide selection of television channels in digital quality, an electronic program guide, program background information, and video-on-demand, which includes movies, shows, and newscasts. (Because the studied provider does not produce TV content, user interaction during live TV programs was virtually nonexistent.) New IDTV
2 Its main competitor (with a market share of 40%) and the smaller remaining players in the digital TV market (with a total market share of 29%) operate through satellite or cable.

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

814

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

customers sign a 12-month contract with automatic renewal. They pay a one-time installation fee and a monthly flat rate for the basic channel package and set-top box.
In an attempt to accelerate adoption, the company made intensive use of free-trial promotions: Between months 10 and 19 of our two-year observation period, every interested consumer could subscribe to a threemonth free trial of the basic IDTV offer, without any purchase obligation. After the trial, customers could cancel the contract and return the set-top box to one of the operator's many shops or else do nothing and become regular paying users. The contract of consumers who did not cancel after a free trial was automatically converted into a paid one such that the next nine months were considered part of a regular contract.
3.2. Data Set From our initial set of more than 170,000 consumers, we deleted those who did not technically qualify to receive the IDTV signal (e.g., because they did not have a sufficiently fast DSL Internet connection from the focal company) or for whom relevant information was lacking. We randomly selected 15,000 customers, of whom 10,000 were used for estimation and 5,000 for out-of-sample validation. Because our sample consists of consumers who were customers of the company before the launch of the IDTV service (i.e., they had the required Internet connection), we also can identify nonadopters.
For each consumer, we have information about whether and in which month she subscribed to the free trial or adopted the paid IDTV service. Furthermore, our data set contains information about the four sources through which consumers learn about service quality: direct marketing, advertising, service usage, and WOM. Direct marketing and advertising are captured by the monthly number of direct marketing contacts per consumer (phone, email or regular mail) and monthly per capita advertising expenditures, respectively.3 For usage, we used the monthly number of channel zaps by each subscriber.4 Finally, for our WOM measure, we take into account that geographically close neighbors are more likely to interact
3 Because the company's communication management is based on the country's administrative regions, the advertising information is region-specific. Yet the ad spending differences between regions are negligible. The other marketing instruments also barely differ across regions: TV channel bundles are largely the same and price and sales promotion strategies are identical.
4 This usage measure ensures that the subscriber was actually watching TV. Set-top box operating times, as an alternative, involve active and passive (i.e., "background noise") use. In addition, IDTV subscribers could leave their set-top box on when their TV set was switched off. Information about set-top box operating times is available only for a limited period. During this period, the correlation between zaps and operating times was 0.67.

(Manchanda et al. 2008, Nam et al. 2010), and compute the distance-weighted number of current IDTV users surrounding each consumer i in month t. Specifically, we compute j=i uj t-1 / 1 + Dij , where uj t-1 is a dummy variable indicating whether consumer j was using the service at the end of the previous month, and Dij is the distance in kilometers between the centroids of the census blocks (i.e., geographic units of 213 households on average) of consumers i and j (e.g., Gauri et al. 2009).5 To reduce the scale of our WOM measure, we divide it by 1,000, without loss of generality. Several other variables served as controls; we discuss them further when we introduce them into the model in Section 4. In Table 1, we report descriptive statistics for all explanatory variables.
Table 1 also presents some descriptives on free-trial usage and paid adoption behavior. Of the customers in our calibration set, 20.74% adopted the paid IDTV service at some point during the observation period. Of all customers who took advantage of the free trial, 60.56% became paying IDTV users, compared to only 13.58% of those who did not accept the free trial. Although these figures suggest that a free trial stimulates paid adoption, they should be interpreted with caution. First, many adopters-after-trial would have adopted even without the trial promotion. Second, the percentages in Table 1 may mask substantial heterogeneity in consumers' response to free trials. Third, these figures do not address the dynamic nature of the trial's effect on adoption. As service quality evolves over time, the outcome of a consumer's learning process, whether through own service usage during the trial or through interactions with current IDTV users, may vary. To cleanly identify the impact of free-trial promotions on a consumer's adoption decision, we need to estimate a model that incorporates these factors.
4. Model Development
4.1. General Model Structure We propose a discrete-choice framework in which the consumer, at the end of every month, chooses whether to accept the free trial, adopt the paid offer (possibly after first having used a trial) or not subscribe at all. This framework essentially corresponds to a discrete hazard-rate structure with time-dependent variables (e.g., Manchanda et al. 2008), and accounts for duration dependence in a rich way. First, we disentangle consumers' learning processes preceding adoption: Every month consumers revise their service quality beliefs on the basis of signals from direct marketing,
5 We divide by 1 + Dij , rather than Dij , to avoid division by zero when consumers i and j belong to the same census block (e.g., Gauri et al. 2009). To increase the reliability of our WOM measure, consumers j involve those within and outside our calibration data set.

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

815

Table 1 Descriptive Statistics

Adoption among free triers and other consumers

Adopters of the paid service

N

(% of N)

Complete sample Free triers Other consumers

10 000 1 524 8 476

2 074 (20.74%) 923 (60.56%)
1 151 (13.58%)

Explanatory variables

Mean

Total variance

Consumer variance

Time variance

Advertising (E per capita) Direct marketing (contacts) Usage during subscription months (00zaps) Word of mouth (distance-weighted number
of surrounding users, 000s) Onsite repair interventions (% of customers) Discount (00E) Age (years, at start of observation period) Annual income (000E, average of census block) Household size (members) Relationship length (years since DSL adoption) Advertising main competitor (E per capita) Trend (months since launch)

0 202 0 206 1 572 0 342
3 437 2 105 48 516 25 453 3 111 2 215 0 072 11 96

0 033 0 370 2 604 0 134
2 081 0 588 133 676 35 180 2 055 1 516 0 008 46 430

0 001 0 077 1 753 0 035
0 085 0 007 133 676 35 180 2 055 1 516 0 004 2 079

0 032 0 293 0 852 0 099
1 996 0 581 0 000 0 000 0 000 0 000 0 003 44 351

advertising, usage during a trial, and WOM, in the course of which they adjust for possible signal biases (Mehta et al. 2008). Second, consumers account for future quality changes and, when confronted with a free-trial offer, anticipate the learning benefits from the trial experience. Thus, as time passes and the decision window shifts forward, consumers' assessment of the future service benefits change.
A few remarks about the availability of consumers' choice alternatives over time are appropriate. First, the free-trial option was only available from months 10 to 19. Second, if a consumer accepts the free trial, the next nontrivial decision comes only at the end of the trial period, when she chooses whether to become a paying user. Third, in the period during which the free trial was available, the company continued offering regular paid subscriptions, typically at a reduced price (e.g., a discount on the installation or monthly fee).6 Fourth, in line with our data, consumers who decide not to adopt the paid offer after a trial will not reconsider the service during the remainder of the observation period.7 Figure 3 provides an illustra-
6 Promotional offers could not be accumulated: Consumers had to choose the free trial or the discounted paid adoption. Even when the free trial's cost savings outstripped those of the discounted regular offer, some consumers chose the regular offer, likely for reasons of precommitment or convenience (Wertenbroch 1998).
7 Our data set does not contain a single consumer that opted out after a free trial and later subscribed again to a trial or the paid offer. This is not surprising: In opt-out-based free trials such as those considered here, a consumer's decision not to adopt the paid service tends to be a deliberate choice that she will not easily revise (see Sriram et al. 2015).

tion. In the beginning, the consumer can only choose between adopting the paid service or not adopting; in this example, the consumer does not adopt. Even during the free-trial campaign (starting in month 10), the consumer does not subscribe until month 14, when she accepts the free-trial offer. The last decision occurs three months later, upon the trial's expiration, when she chooses to adopt the paid offer.

4.2. Discrete-Choice Model We use a multinomial logit (MNL) structure to model the probabilities that, in a specific month, the consumer subscribes to the free-trial offer or the regular paid service (possibly after a trial), given that she did not do so before. We write consumer i's utility in month t for the free-trial (UiFt and regular offer (UiRt as follows:

UiFt = ViFt +

F it

=

0 i

+

F i

-E

exp

-ri qiFt

+

DISC i

DISCFit

+

UR i

URit

+XiFt

X
i+

F it

(1)

UiRt = ViRt +

R
it =

0i -E exp -riqiRt

+

DISC i

DISCRit

+

FE i

FEit

+X

R it

X i

+

R it

(2)

We start by discussing the free trial's utility (Equation (1)). First, -E exp -riqiFt represents the expected service benefits obtained by subscribing to the free
trial. In line with previous studies (e.g., Narayanan and
Manchanda 2009), we capture these expected benefits
through the expected value of an exponential function of qiFt, which is the consumer's stochastic belief about service quality during the free trial. For positive val-
ues of the risk-aversion coefficient ri, the exponential function (including the negative sign in front of it) is

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

816

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

Figure 3

Illustration of a Consumer's Varying Choice Set

Month since launch

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17

No subscription X X X X X X X X X X X X X

Paid service

X

Free trial

XXX

: Available option : Unavailable option X: Chosen option

concave, such that the consumer is risk-averse with respect to uncertainty in qiFt. To ensure that ri is positive, we write ri = exp ri , where ri can take any value. Assuming that qiFt follows the normal distribution N q¯iFt siFt , we can write (see Erdem et al. 2005)

- E exp -riqiFt = - exp -ri q¯iFt-ri siFt 2/2

(3)

where -ri siFt 2/2 is a penalty for quality uncertainty. As we will explain in Sections 4.3 and 4.4, the consumer

derives her quality belief qiFt by learning from quality signals obtained through advertising, direct marketing,

and WOM.

Second, to account for the monetary benefits of the

free trial (see Figure 1), we include DISCFit, the sum of all waived installation, activation, and monthly

subscription fees over the three trial months. Note that

its coefficient,

DISC i

,

is

also

identified

by

the

occur-

rence of price promotions for the regular offer (see

Equation (2)).

Third, URit is the anticipated utility due to a betterinformed adoption decision after the free trial. More

precisely, it captures the consumer's anticipated reduc-

tion in uncertainty about the service's quality, given

her expected usage intensity during the trial (Ching

et al. 2011). The greater URit, the more the consumer appreciates the opportunity to make the actual adop-

tion decision only after having tried the service. As

such, this component captures the fluctuations in the

free trial's option premium. We discuss the derivation

of URit in Section 4.4. Any remaining utility shifts are

captured by the coefficient

F i

.

Indeed,

smart-shopper

feelings may further boost the free trial's utility (see

Figure 1).

After a free trial, consumers may consider adopting

the paid offer. In Equation (2), two components capture

the effect of a consumer's free-trial experience. First, we

include -E exp -riqiRt , the expected service benefits of the paid offer, where qiRt  N q¯iRt siRt is the consumer's stochastic belief about service quality during a regular

subscription. Unlike qiFt, qiRt is not only based on marketing and WOM signals but also incorporates usage

signals if the consumer first subscribed to a trial (see Figure 1). In line with Equation (3), we can write

- E exp -riqiRt = - exp -ri q¯iRt -ri siRt 2/2

(4)

Second, we add FEit, a dummy that equals 1 when the consumer has completed a free trial. We thus

account for the fixed-effect change in the utility of the

paid offer after a trial, due to the absence of a setup fee,

the inertia premium, and reference price effects (see

Figure 1). The sign and magnitude of the coefficient

FE i

reveal the net impact of these different mechanisms.

Finally, XiFt and XiRt are row vectors of offer-, con-

sumer-, and month-specific control variables;

X i

is

a

vector of coefficients; and

F it

and

R it

are

extreme-value

distributed error terms, such that we obtain an MNL

form for the probability that consumer i subscribes to

offer y y = F R in month t:

Piyt

=

zFit

· exp

zyit · exp Viyt ViFt +zRit · exp

ViRt

+1

(5)

The probability of nonsubscription N , in turn, is given by

PiNt = zFit · exp

ViFt

1 +zRit · exp

ViRt

+1

(6)

The indicators zFit and zRit serve to "deactivate" an offer that is not available to the consumer. For example, after
a trial, the consumer can only choose between the paid offer and the no-purchase option, such that zFit = 0 and zRit = 1 (see Figure 3).

4.3. Consumer Learning About Ultimate Match Quality
At the core of our model is a consumer learning process (Erdem et al. 2005, Narayanan and Manchanda 2009). Specifically, the consumer tries to infer the ultimate match quality i, which is the extent to which the service offers the consumer's sought-after features in the absence of any service deficiencies, that is, after initial technical malfunctions have been resolved. Below, we discuss this learning process in detail. In Section 4.4, we explain

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

817

how it enables the consumer to derive her beliefs

qiFt and qiRt about quality during the trial and regular subscription, and the anticipated uncertainty reduction

URit (see Equations (1) and (2)). Quality information sources. In line with substantial

empirical research on learning (e.g., Erdem et al. 2005,

Narayanan and Manchanda 2009), consumers update

their beliefs about i in a Bayesian fashion. They take into account quality signals from four sources of infor-

mation: (1) advertising, (2) direct marketing, (3) own

usage of the service during the trial, and (4) WOM

(Erdem et al. 2005). The corresponding normal signal

distributions are N

A i

A ,N

A i

D ,N

U it

U , and

N

U it

W . While each of the four sources has its own

standard deviation (and thus perceived information

precision, see, e.g., Narayanan et al. 2005), advertising

and direct marketing have the same mean quality

signal

A i

(i.e.,

the

advertised

match

quality);

usage

and WOM share the (time-variant) mean quality signal

U it

(i.e.,

the

real

match

quality

in

the

current

period)

(Ghose and Han 2011).

Signal bias. In line with Mehta et al. (2008), these

four sources do not necessarily provide unbiased signals

of the ultimate match quality i. First, advertisements and direct marketing contacts often engage in puffery

and overstate the service's quality (Xu and Wyer 2010).

In other words,

A i

may

be

greater

than

i. We capture

this by writing

A i

as

A
i = i+

(7)

where is the bias in the advertising and direct mar-

keting signals.

Second, especially in the early stages of the service's

life cycle, the service may still suffer from technical

problems, such that the actual quality delivered,

U it

,

may be below the ultimate match quality, i. We thus

write

U it

as

follows:

U it

=

i+

· interventt

(8)

where · interventt represents the deviation from the ultimate quality, i.e., the "bias" in the usage and WOM

signals. The variable interventt refers to the number of onsite repair interventions by a field technician in

month t, expressed as a percentage of the total number

of customers in that month.8 Including interventt helps

us to identify the fluctuations in

U it

.

It

captures

the

service's technical evolution and tends to decrease over

time, varying between 6.0% and 1.6%. We expect to

be negative: A high value for interventt is an indication of a low current match quality.

8 interventt does not include customers' requests for remote assistance. Typically, such requests can be attributed to customers' initial inability to operate the system and therefore are themselves subject to consumer learning. Our measure is free of such learning mechanisms and thus offers a good indicator of the service's objective performance.

Signal correction. Consistent with Mehta et al. (2008),

the consumer is aware of possible biases and holds

beliefs about the degree of distortion, which enable

her to correct the quality signals. As in Mehta et al.

(2008), we assume that these beliefs about signal bias,

themselves, are not subject to learning. The consumer's

belief about the advertising and direct-marketing bias, ,

is represented by d, which follows the normal distribu-

tion N d¯ sd . In addition, the consumer holds beliefs

about · interventt, i.e., the extent to which the real

match quality

U it

deviates

from

the

ultimate

match

quality i in a given month t. Because the consumer

does not observe interventt, she assumes the deviation

to decrease linearly over time. Specifically, the con-

sumer believes the difference between real and ultimate

match quality equals

k · T - t for t  T and

0

for t > T

(9)

The parameter k captures the rate at which, according

to the consumer, the technical deficiencies decrease; k is

stochastic and follows the normal distribution N k¯ sk ,

where k¯ is expected to be negative. The parameter T

represents the number of months it takes for the system

to start functioning optimally (i.e., without deficien-

cies). To keep estimation tractable, we assume that the

consumer's belief about T is deterministic. Note that

Expression (9) can also be written as k · max 0 T - t .

Based on her beliefs about the amount of bias, the

consumer corrects the incoming quality signals in an

attempt to obtain an unbiased estimate of i. Specifically, when the consumer receives some advertising

(or direct marketing) signal , she will use the cor-

rected signal  - d. Similarly, when she receives some usage (or WOM) signal # in month t, she will rely

on the corrected signal # - k · max 0 T - t . Given

Equations (7) and (8), the means of the corrected signal

distributions are i + - d¯ for advertising and direct marketing, and i + · interventt-k¯ · max 0 T - t for usage and WOM.

Bayesian updating. Let

iAt ,

D it

,

U it

,

and

W it

be

the

sums of the corrected advertising, direct marketing,

usage, and WOM signals (respectively) that the con-

sumer obtains in month t. If we condition on d and k

(a constraint that we will later relax again), these signal

sums have the following normal distributions:

A it

dN

nAit ·

i+

-d

nAit · A

D it

dN

nDit ·

i+

-d

nDit · D

U it

kN

nUit ·

i+

· interventt

- k · max 0 T - t

nUit · U

W it

kN

nWit ·

i+

· interventt

- k · max 0 T - t

nWit · W

and (10)

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

818

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

where nAit , nDit , nUit , and nWit refer to the numbers of, respectively, advertising, direct marketing, usage, and
WOM signals in month t. The above expressions hold
true because the original, uncorrected, signals follow the normal distributions N i + A , N i + D , N i + · interventt U , and N i + · interventt W . Expressions (10) show that, conditionally on d and k,
the corrected signal sums are independent. If we
assume that consumers' initial belief about i, q0, is normally distributed, then the posterior conditional
belief at any point in time is also normal (Narayanan
and Manchanda 2009): qit d k  N q¯it sit , with

q¯it = si2t

q¯i t-1 si2 t-1 +

A it
A 2+

D it
D 2+

U it
U 2+

W it
W2

(11)

and

sit =

1 si2 t-1 +

nAit A 2+

nDit D 2+

nUit U 2+

nWit
W2

-1/2

(12)

Note that the consumer can use qit d k to derive a conditional belief about the real match quality in some

future period t + , that is, about

U i t+

. Let qitt+

dk

refer to this conditional belief. Given the consumer's

belief about the difference between current and ulti-

mate match quality (see Expression (9)), we obtain

qitt+ d k = qit d k + k · max 0 T - t - , which is normally distributed.

4.4. Derivation of qiFt, qiRt , and URit In our model, consumers are forward-looking in two

ways. First, they account for the fact that match quality

U it

is

evolving.

Specifically,

in

their

adoption

and

trial

subscription decisions, they use their beliefs about the

quality changes to derive beliefs qiFt and qiRt about the average service quality during the free trial and regular

subscription, respectively (see Equations (1) and (2)).

Second, when evaluating the trial offer, consumers

anticipate the uncertainty reduction URit as a result of learning during the trial. Below, we discuss both

elements.

Derivation of qiFt and qiRt . In Web Appendix 1 (available as supplemental material at http://dx.doi.org/10.1287/

mksc.2015.0973), we obtain the unconditional normal

distributions of qiFt and qiRt by averaging the conditional match quality beliefs qitt+ d k across the months t + 1 t + 2 of the free trial and regular subscription,

respectively, and then deriving the unconditional mean

and standard deviation. For the free trial, we find

LF
q¯iFt = E qitt+ d = d¯ k = k¯ /LF and (13)
=1

siFt = si2t + G2it · sd 2 + Hi2t · sk 2 1/2

(14)

The expressions for q¯iRt and siRt are analogous. The expression qitt+ d = d¯, k = k¯ refers to qitt+ d k evaluated

in d¯ and k¯ , LF represents the length in months of the free trial, and Git and Hit are weights that depend, among others, on the numbers of past quality signals and signal variances (see Web Appendix 1 for the full expressions). Equation (14) shows that the uncertainty about the average match quality during the trial, siFt 2, depends not only on the uncertainty about the ultimate match quality, si2t, but also on the uncertainty about signal bias, sd 2 and sk 2 (see Mehta et al. 2008).
Derivation of URit. Following Ching et al. (2011), we model the expected uncertainty reduction as the anticipated decrease in the variance of the consumer's quality belief as a result of service usage.9 More precisely, the consumer evaluates the extent to which usage during the trial will affect siRt+3 2, which is the uncertainty three months from now about the average match quality during a regular subscription starting in t + 4. Thus, the consumer assesses the difference between, on one hand, the anticipated uncertainty in the absence of any usage signals and, on the other hand, the anticipated uncertainty given the consumer's likely usage pattern during the trial. As we explain in Web Appendix 1, to derive this uncertainty reduction, the consumer needs the expected number of advertising, direct marketing, usage, and WOM signals during the next three months, for which she relies on her signal history and consumer characteristics. Finally, to cleanly separate the anticipated uncertainty reduction over time from cross-sectional differences between consumers (which are already captured by the heterogeneous utility intercept), we center each customer's series of uncertainty reduction values around her first-period value. As a result, URit only captures within-consumer cross-time variation in anticipated uncertainty reduction.
Note that the role of URit differs fundamentally from that of siFt which also appears in the free trial's utility function (see Equations (1) and (3)). The parameter siFt captures uncertainty about the average match quality
9 In line with Ching et al. (2011 and 2013), we thus use a "reduced form" approach to capture future benefits, rather than solve the consumer's dynamic programming problem. Not only is the latter approach more complicated and time-consuming, identification may become prohibitive if the value outcomes of the decisions are not directly observed, which is the case in our model, since we only observe choices, not the underlying utilities (Ching et al. 2011). Moreover, the only learning effects that a consumer can truly anticipate are those on belief uncertainty, and not those on the belief's expected value, for which she would need the exact values of the future quality signals (Ching et al. 2011). Hence, one can express the future learning benefits of making a certain choice (in our case, accepting the free trial) as a function of the reduction in uncertainty following that choice compared to the no-purchase option. To test the accuracy of our reduced form, we run a simulation in which we compute the anticipated uncertainty reduction due to trial and compare it with the anticipated benefit of trial in a more structural model. The approach and results are discussed in Web Appendix 2.

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

819

during the free trial, given the quality signals collected until month t. By contrast, URit measures uncertainty reduction, pertains to the average match quality in the months after the trial, and accounts not only for the so-far collected quality signals but also for the anticipated signals in the next three months.
In summary, we build a model in which consumers learn about ultimate match quality (i.e., match quality in the absence of technical deficiencies) from advertising, direct marketing, WOM, and, in case they subscribe to the trial, own service usage. Consumers expect the advertising and direct marketing signals to overstate the service's quality and therefore adjust them downward, relying on their beliefs about puffery in marketing communication. Furthermore, consumers know that the WOM and usage signals may understate the ultimate quality due to temporary technological deficiencies, and correct these signals based on how much they believe the actual quality is still below the ultimate quality. The derived belief about ultimate match quality together with the belief about the speed of technological evolution, enable consumers to make inferences about the average quality during a future (paid or free-trial) contract, which informs their subscription decisions. In addition, when considering a free trial, consumers account for the extent to which the trial will help reduce the uncertainty about average quality.

4.5. Control Variables

Several other factors, represented by XiFt and XiRt in Equations (1) and (2), respectively, directly influence

the utilities of the trial and paid offer. First, we include

advertising and direct marketing in both utility equa-

tions to account for these variables' persuasive role,

in addition to their informative signaling effects on

consumers' quality beliefs (Narayanan et al. 2005).

Second, we account for the fact that, near the end of

our observation period (after the free-trial campaign), a

paid three-month trial option became available, allow-

ing consumers to experience the paid service without

signing a long-term contract. Although our model

already captures learning through usage and WOM,

two additional variables are necessary to accommodate

a paid trial's effects. Specifically, in the trial's utility

function, we include a dummy that equals 1 when the

trial was not free of charge; this dummy's coefficient

replaces

F i

in

Equation

(1).

We

thus

allow

for

any

difference in utility between free and paid trials (e.g.,

due to limited smart-shopper feelings), on top of the utility shift captured by the discount variable DISCFit.
Similarly, in the utility function of the regular contract,

we incorporate a dummy (comparable to FEit that equals 1 when the consumer has completed a paid

trial; the fixed feedback effect of a paid trial may be

higher than that of a free trial because a paid trial is

unlikely to decrease reference prices. We only add these

variables as controls; free trials remain our focus.10 Third, in the utilities of the regular and trial offer, we include monthly advertising expenditures (E per capita) of the main competitor and a linear trend to account for any remaining changes in subscription probability.

4.6. Consumer Heterogeneity

To account for latent consumer heterogeneity, the coef-

ficients

F i

,

Di ISC,

UR i

,

Fi E, and

X i

,

the

transformed

risk-aversion parameter ri (ri = ln ri , and the ulti-

mate match quality

i (and, as a result, also

A i

and

U it

,

see Expressions (7) and (8)) follow normal mixing

distributions with constant population-level means

and standard deviations. The intercept

0 i

is

also

nor-

mally distributed but its mean is a function of several

consumer characteristics

E

0
i=

0+Zi

Z

(15)

where 0 ( Z is a (column vector of) coefficient(s) to be estimated, and Zi is a row vector of (mean-centered) consumer characteristics, including the consumer's age and relationship length (i.e., the duration of the consumer's DSL subscription) at the start of the observation period, average annual income in the consumer's census block, and family size (see also Table 1).
Several of these potential sources of (latent or explained) consumer heterogeneity are shared by the free trial and paid service (see Equations (1) and (2)), such that our model allows for correlation between the offers' utilities (e.g., Train 2009). This is important because consumers who subscribe to the trial offer may already have a greater propensity for paid adoption before the trial, e.g., due to their intrinsic interest in the service. By accounting for such commonalities in the utility of both offers, we avoid bias in the estimated effect of trial usage on paid adoption.

4.7. Identification and Estimation
For identification purposes, we set consumers' initial quality uncertainty s0 to 0.01 (e.g., Narayanan et al. 2005). Furthermore, and d¯ cannot be individually identified: Marketing bias and consumers' subsequent correction always co-occur (see, e.g., Expressions (10)) and neither process can be observed directly (Mehta et al. 2008). We therefore define d = - d, capturing the amount of over- or undercorrection, and estimate the parameters of the corresponding distribution N d¯ sd . This identification problem does not arise for the usage and WOM signals because the bias · interventt and correction k ·max 0 T -t are informed by two separate, observable processes, i.e., the fluctuation in repair

10 The paid trial was available only toward the end of our observation period, so the data set contains very few customers who actually completed such a trial.

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

820

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

Table 2 Comparison of Alternative Model Specifications

No. of

Log

Model

parameters

likelihood

BIC

BM1

24

-15 368 03

31,030.93

BM2

33

-14 726 85

29,859.16

BM3

35

-14 748 42

29,926.87

BM4

37

-14 364 06

29,182.73

FM

40

-14 354 95

29,201.35

Note. The values in bold indicate the best-performing models. aIn thousandths.

AIC
30,784.06 29,519.70 29,566.84 28,802.13 28,789.89

Root mean square errora

In-sample

Out-of-sample

5.385 4.286 4.197 4.461 4.082

5.181 4.180 4.108 4.174 4.035

interventions and the passage of time t, respectively.

Finally, we assume that T , consumers' expected number

of months for the system to become void of technical

deficiencies, is in line with the actual pattern of repairs.

We thus plot interventt against time, and set T equal to the point where the fitted regression line crosses

the time axis (i.e., 29 months after launch). Sensitivity

analysis shows that our results are largely insensitive

to changes in T . Web Appendix 3 presents a more

detailed discussion on identification.

From the researcher's perspective, the parameters

0 i

F i

DISC i

UR i

FE i

X i

ri

i

A it

D it

U it

,

and

W it

are random variables that must be integrated out

for each consumer. We therefore estimate our model

with simulated maximum likelihood, using 100 Halton

draws from the parameters' distributions. The log

likelihood expression is available in Web Appendix 4.

5. Results
To establish validity, we first compare our full model (FM) with four benchmark specifications: (1) a model without quality learning but with a dummy to capture the fixed effect of a preceding free trial (BM1); (2) a learning model in which consumers do not look forward, and the quality signals of all sources are unbiased with the same time-invariant mean (BM2); (3) a model that adds anticipated uncertainty reduction to BM2 (BM3); and (4) a model that adds marketing bias (and bias correction) to BM3 (BM4). Table 2 reports the models' log likelihood, Bayesian information criterion (BIC), and Akaike information criterion (AIC) values, as well as the root mean square error (RMSE) of the predicted monthly hazard rates in the calibration and holdout sample. Except for BIC (which favors BM4), the fit measures support our full model and underscore the importance of accommodating learning, signal bias (correction), and forward-looking. As another validity check, we track the observed trial subscription and post-trial adoption numbers over time, against the predictions of our full model (for which we use consumer-specific parameters, based on a Bayesian update of the population-level parameters, see Train 2009), and find that the model performs quite well (see Figure 4).

Table 3 reports the parameter estimates for our full model. The coefficients of the control variables have face validity. For example, large households have a higher probability to subscribe p < 0 01 , which makes intuitive sense, given the nature of the service. The positive mean coefficients of own advertising p < 0 10 and direct marketing p < 0 01 point to a persuasive role of marketing communication. In what follows, we first discuss the utility parameters that capture the free-trial mechanisms shown in Figure 1. We then focus on the learning process underlying the changes in perceived service benefits. For heterogeneous parameters, we focus on the population means: For most parameters, latent consumer heterogeneity is relatively limited.

5.1. Adoption Decision Mechanisms in the Presence

of a Free Trial

Table 3 shows that, as expected, the discount effect is

positive p < 0 01 . Hence, monetary benefits influence

service adoption and, in the case of a free trial, people

are attracted by the opportunity to use the service for

free. The positive coefficient of uncertainty reduction

p < 0 10 indicates that consumers value the oppor-

tunity to become more certain about service quality

before committing to paid adoption. Interestingly, the

free-trial constant

F i

is also

positive,

and strongly

significant p < 0 01 . Thus, free trials have appeal

Figure 4

Observed and Predicted Free-Trial Subscription and Subsequent Adoption Over Time

Observed free-trial subscribers

300

Predicted free-trial subscribers

Observed adopters after trial

Predicted adopters after trial

200

100

50

0

10

12

14

16

18

20

22

24

Months since launch

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

821

Table 3 Parameter Estimates

Estimate (standard error)

Population mean

Standard dev.

Coefficients of utility functions

Core coefficients

Intercept,

0 i

Constant, 0

6 522 (0.788)

0 001 (0.137)

Age (years, at start of observation period)

-0.015 (0.002)

Average annual income (000E)

-0.009 (0.005)

Household size (members)

0.056 (0.019)

Relationship length (years since DSL adoption)

Free-trial constant,

F i

Discount (E),

DISC i

Risk aversion w.r.t. quality beliefs, ri = exp ri (lognormal)

Uncertainty reduction,

UR i

Fixed effect after free trial,

FE i

Coefficients of remaining control variables

-0.009 (0.022) 7 231 (0.353) 0 004 (0.001) 3 192 (0.956) a 28 821 (16.101) 4 692 (0.166)

0 038 (0.176) 0 001 (0.001) 0 574 (0.187) a 0 215 (0.796) 0 031 (0.235)

Own advertising (E per capita)

0 308 (0.163)

0 077 (0.398)

Direct marketing (contacts)

0 275 (0.032)

0 398 (0.062)

Advertising main competitor (E per capita)

0 194 (0.277)

0 007 (0.637)

Trend (months since launch)

-0 460 (0.031)

0 004 (0.005)

Paid-trial constant

4 089 (0.449)

1 116 (0.395)

Fixed effect after paid trial

6 202 (0.481)

0 459 (1.373)

Parameters of learning process

Consumers' initial expected ultimate match quality, q¯0 Ultimate mean match quality, i Match quality signals' standard deviations

5 195 (1.649)

Std. dev. of advertising signal, A

Std. dev. of direct marketing signal, D

Std. dev. of usage signal, U

Std. dev. of WOM signal, W

Signal bias and bias beliefs

-0.594 (0.176)
0.034 (0.003) 0.023 (0.001) 0.203 (0.007) 0.037 (0.004)

0 005 (0.017)

Mean overcorrection of marketing signals, - d¯ = d¯ Std. dev. of belief about marketing signal bias, sd Real mean match quality fluctuation coefficient,
Mean of belief about real match quality fluctuation, k¯ Std. dev. of belief about real match quality fluctuation, sk

-5.367 (1.690) 0.000 (0.052)
-2.078 (0.649) -0.014 (0.007)
0.023 (0.006)

Log likelihood value: -14,354.947; BIC: 29,201.354; AIC: 28,789.894 2 × (Loglik full model - Loglik homogenous intercepts only): 11,322.066 p < 0 001

aStandard errors are derived from the covariance matrix of the estimated parameters r and r, using the delta method. Significant at the p < 0 01 level; significant at the p < 0 05 level; significant at the p < 0 10 level.

beyond their anticipated monetary and informative

benefits and seem to trigger smart-shopper feelings.11

Together, these effects show that the free-trial offer

convinces otherwise disinterested consumers to start

using the service.

However, it remains to be seen to what extent trial

users are converted to paying adopters. First, the fixed-

effect coefficient

FE i

is

positive

and

significant

p<

0 01 : For free-trial subscribers, any negative reference

price effect thus tends to be more than compensated

by the inertia premium and the absence of setup fees.

Second, this effect may be enhanced or tempered by

11 The paid-trial constant is lower than the free-trial constant p < 0 01 , indicating that, even after controlling for the discount, the paid trial appears less attractive, most likely due to limited smart-shopper feelings. The fixed effect after paid trials is higher, probably because of the absence of reference price effects.

changes in perceived service benefits as a result of quality learning during the trial. Indeed, the riskaversion parameter ri is significant p < 0 01 , such that changes in consumers' quality beliefs due to trial usage affect the attractiveness of the paid contract (see Equation (4)). Note that ri also captures changes in quality beliefs due to learning from WOM. Thus, even if a consumer does not subscribe to the trial, she is indirectly affected by the trial through WOM.
5.2. Learning Process The results in Table 3 also shed light on consumers' learning process. The initial mean belief about ultimate match quality, q¯0 = -0 594, is significantly below the average consumer's true ultimate match quality ¯i = 5 195 p < 0 01 . Based on Equation (12) and the signals' standard deviations in Table 3, we can determine the effectiveness of the various information sources

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

822

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

Figure 5 0.010
0.008

Uncertainty About Ultimate Match Quality Over Time
sit without preceding trial sit after three-month trial

Figure 6 Average Corrected Quality Signals Over Time

4 Average corrected advertising and direct marketing signal

2

Average corrected usage and WOM signal

0

­2 0.006
­4

0.004 4 6 8 10 12 14 16 18 20 22 24
Months since launch

at updating the beliefs and reducing uncertainty. For

instance, a 10% drop in the uncertainty about ultimate

match quality sit (i.e., from its initial value of 0.01 to 0.009) requires 96.687 zaps, compared to 2.649 advertis-

ing signals, 1.195 direct marketing contacts, and 3.164

WOM signals. Viewed against the average monthly

levels of usage (157.154 zaps), advertising (E0.202 per

capita), direct marketing (0.206 contacts), and WOM

(0.342), this suggests that consumers' own experiences

are by far the most informative quality signals. In

line with insights from cognitive psychology, firm

communications are less informative than own usage

(Hoch 2002). The WOM signals' relatively low infor-

mativeness is also expected because consumers may

not actually pick up or fully observe the information

signals from prior subscribers (Ghose and Han 2011).

Figure 5 demonstrates that usage can substantially

decrease uncertainty about ultimate match quality. The

solid line presents sit if the consumer would have completed a three-month free trial in months 4, 5, etc.,

while the dotted curve shows the evolution of sit absent any service usage.12 For example, for a free trial ending

in month 8, sit equals 0.006, which is much (i.e., 25%) lower than the corresponding value without preceding

trial, i.e., 0.008. Note, however, that for trials later in

time, this uncertainty reduction decreases such that the

two lines tend to converge: The extra information value

of a trial decreases as consumers cumulate quality

signals from other sources.

Table 3 shows that - d¯ = d¯, the difference between

actual marketing bias and consumers' mean bias cor-

rection, is negative and significant p < 0 01 . Hence,

consumers not only discount but overcorrect the infor-

mation from advertising and direct marketing. Even

so, they trust their signal correction because the stan-

dard deviation of their belief about marketing bias is

insignificant p > 0 10 . The coefficient , which relates

the actual match quality

U it

to

the

percentage

of

onsite

12 In our computations, we use the overall average number of advertising, direct marketing, and usage signals, and take the average consumer's pattern of WOM signals.

­6
­8 2 4 6 8 10 12 14 16 18 20 22 24
Months since launch
repair interventions (see Equation (8)), is significant p < 0 01 and has the expected negative sign. The estimate of k¯ , which captures consumers' mean belief about the monthly quality improvements, is negative and significant p < 0 05 . Hence, consumers realize that the quality signaled by usage and WOM may be substantially below the ultimate match quality, especially shortly after service launch (see Equation (9)). Still, their belief is subject to considerable uncertainty because sk is relatively large p < 0 01 .
So even though consumers correct incoming signals in an attempt to learn about the ultimate match quality, the corrected signals do not necessarily have a unique, constant signal mean (see Mehta et al. 2008). This becomes clear in Figure 6, which portrays the corrected mean usage and WOM signal values i + · interventt - k¯ · max 0 T - t and the corrected mean advertising and direct marketing signals i + - d¯ for the average consumer. Figure 6 shows that, in the early months (especially before month 10), usage and WOM tend to generate less favorable corrected signals than advertising and direct marketing, while the opposite holds in later periods (especially after month 17). While learning through usage and WOM, consumers insufficiently correct for deficiencies experienced in the early stages and tend to take bad usage experiences as a signal of the service's ultimate match quality. As a result, whether and how much the free trial enhances or reduces perceived service benefits will strongly depend on the timing of the trial and the amount of learning. We address this more extensively in Section 6. Web Appendix 5 provides further checks on the validity of the estimation results.
6. Simulations
Though the parameter estimates give a flavor of the mechanisms driving the free-trial impact, the ultimate outcome depends on the number of customers gained and lost, whether through own trial usage or WOM (see Figure 2). In this section, we assess the net impact

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

823

Number of new adopters

Figure 7 100 80

Simulated Free-Trial Effect: Number of New Adopters Over Time
Baseline adoption Adoption in the presence of a free trial

60

40

20
Trial campaign 0
2 4 6 8 10 12 14 16 18 20 22 24 Months since launch

of free trials and use simulations to explore how this net impact changes with promotion timing and usage intensity.
For each scenario, we simulate 100 decision trajectories per consumer (i.e., we draw signals, trial acceptance, and adoption outcomes) during the first two years after launch while accounting for consumer interdependencies due to WOM. For the random coefficients, we use consumer-specific posterior values (Train 2009). To avoid confounding promotion effects, we assume away any discounts on the paid offer.13 We obtain the expected monthly number of paying service adopters by averaging across the 100 draws and adding across consumers.
6.1. Effect of a Free-Trial Promotion Over Time To illustrate the dynamic effects of a free trial, Figure 7 displays paid adoption over time for the baseline scenario in which no trial promotion takes place (dashed line), and for the scenario in which a three-month free-trial offer is available to all customers between months 9 and 11 (solid line). Figure 7 shows that during these months the number of paying adopters decreases because some consumers who would have become paying users in the absence of a trial now first take advantage of the free offer. Over the next three months, several consumers who have completed the trial or hear about the service become paying users; some of these would not have adopted without a trial promotion. In month 15, when the last trial subscriptions have

13 The values for the other background variables are set as follows. Advertising, direct marketing, and usage rates equal consumerlevel averages. For consumers who never subscribed to the service, we compute the usage rates as an exponential function of their sociodemographics, calibrated with the data of actual users. Note that, in reality, firms may adjust their direct marketing and advertising decisions as a function of the timing of the trial, such that our simulation results could be seen as lower bounds of the true results. Because the percentage of onsite repair interventions may be subject to learning on the part of the firm, we compute interventt as an exponential function of time and (simulated) number of subscribers calibrated on the data.

expired, the number of paying adopters drops sharply below the baseline. While this may be partly due to acceleration (consumers having adopted earlier), some consumers who would adopt the paid offer in the baseline scenario are truly lost. They subscribe to the trial but, being disappointed about the service's quality, defect for good, or they decide not to adopt because they receive negative WOM. The cumulative number of paying adopters by the end of month 24 is thus slightly lower than in the baseline scenario (495 versus 503). Further exploration shows that the difference between the baseline and free-trial scenario results from, on one hand, attracting 90 adopters who would not have adopted the service without the free trial and, on the other hand, losing 98 customers who would have adopted without the trial. The question then becomes: How can the company reduce the number of customers lost and/or increase the number of customers gained?
6.2. Impact of Promotion Timing and Usage Intensity
Using simulations, we show how appropriate timing and increased use rates can improve the performance of a free trial. We fix the length of the period during which the consumer can subscribe to the trial at three months and, as before, use a simulation horizon of two years after launch. Other promotion durations and time horizons lead to similar patterns. Our focal performance metric is the total number of adopters at the end of the planning horizon, but when relevant, we also report the total number of months of paid service usage across adopters. The latter measure takes the moment of paid adoption into account and attaches more weight to early adopters, who start generating revenue earlier in time (Bawa and Shoemaker 2004).
Impact of timing. Figure 8 shows how a change in the starting month of the trial campaign, influences the number of adopters.14 The lower part of the graph (Y -axis on the right) shows that early free-trial promotions (i.e., before month 10) lead to more customers lost than gained, while in later periods, the number of customers gained prevails. The upper part of the graph (Y -axis on the left) indicates that early trials thus substantially decrease the total number of adopters relative to the baseline (by up to 40%), whereas later free trials increase adoption. Two phenomena favor trials later in the decision window. First, in later periods, a free trial leads to more positive impressions than advertising or direct marketing because the technical service quality and corrected usage and WOM signals improve over
14 Note that month 19 is the last starting month for which we can assess the impact because the trial is available for three months (e.g., 19, 20, 21); trial subscribers make a final adoption decision only after three months of service usage (e.g., month 24 if they accept the trial in month 21).

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

824

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

Total number of adopters Adopters lost and gained due
to trial promotion Total number of paid adoption months
Paid adoption months lost and gained due to trial promotion

Figure 8 Simulated Impact of Timing on Total Number of Adopters

1,400

1,000

600

200

Baseline adoption

800

Adoption in the presence

600

of a free trial 400

200

0 2 4 6 8 10 12 14 16 18
First month of trial campaign

Gained after own trial usage Gained due to word of mouth

Lost after own trial usage Lost due to word of mouth

time (see Figure 6). Second, people who do not adopt after the trial are lost for good. As a result, an early free trial may eliminate many consumers who would otherwise have adopted the paid system in one of the remaining months. Trials at later points in time may also eliminate consumers, but the chance that these consumers would otherwise have adopted in one of the few remaining months is relatively small.
However, as shown in the lower part of Figure 8, the number of adopters gained levels off, and even slightly drops, at a certain point. First, in later months, subscribing to the free trial loses appeal because the expected uncertainty reduction (the option premium) decreases as the number of already collected advertising, direct marketing, and WOM signals grows. Second, consumers who do subscribe to the trial may barely update their quality beliefs, which may have already reached convergence. For the same reason, any additional WOM signals triggered by the free-trial campaign may leave consumers' beliefs largely unaffected. Consequently, there is a point in time (month 17 in this case) after which further delay in the trial campaign no longer enhances the total number of adopters. To assess the significance of the differences between the baseline and free-trial curve, we rerun the simulation for each of 100 draws from the parameter estimates' distributions. We derive the 95%-confidence intervals of the differences between the two curves and find that, except in month 9, all differences are significant.
Figure 9 shows the effect of timing on the number of paid adoption months. Analogous to Figure 8, the lower graph presents the number of paid adoption months lost and gained as a function of the starting month of the free-trial campaign. Paid months are lost when consumers do not adopt in the presence of a trial promotion but would have adopted otherwise, yet also when the free trial reaches consumers who would have been willing to immediately adopt the paid service (subsidization). In turn, paid months are

Figure 9

Simulated Impact of Timing on Total Number of Paid Adoption Months

10,000

6,000

2,000

Baseline performance Performance in the presence of a free trial

5,000 3,000

1,000
0 2 4 6 8 10 12 14 16 18
First month of trial campaign

Gained after own trial usage Gained due to word of mouth

Lost after own trial usage Lost due to word of mouth

gained when people who would not otherwise have subscribed adopt in the free-trial scenario, but also when the trial makes consumers adopt earlier than in the baseline scenario (acceleration). As the lower part of Figure 9 shows, the number of months gained starts to drop for trials offered in month 14. Although offering a free trial later in time may still increase the number of adopters (see Figure 8), it also reduces the number of paid months per attracted customer. That is, a trial later in time benefits less from accelerated payments while it continues to subsidize consumers who would have adopted anyway. The upper part of the graph shows that if the objective is to maximize the total number of adoption months, the trial campaign should be scheduled earlier (in month 14 in this case) than when the focus is on the number of adopters.15 As in Figure 8, all differences between the baseline and free-trial performance are significant at the 95% level, except in month 9.
Impact of usage intensity. To further improve free-trial performance, the firm can boost consumers' use rates during the trial, e.g., by temporarily giving them access to extra channels or granting them credit for a videoon-demand service. Figure 10(a) shows how changes in consumers' usage levels affect the total number of adopters for a campaign starting in month 17 (the optimal starting month according to Figure 8). As the graph shows, increased usage during the trial period enhances conversion into paid adopters, while lower usage rates (e.g., due to the temporary unavailability of certain channels) trigger the opposite effect. The higher the use rates, the more consumers learn from the trial. The multitude of experiences reduces uncertainty and, for trials starting in month 17 and later, also improves

15 Recent work by Datta et al. (2015) shows that customers attracted through free trials may exhibit higher churn rates. Therefore, we reran the simulation using the average retention rates reported in Datta et al. (2015), i.e., 0.93 for free-trial and 0.96 for regular customers. The resulting graph is similar to Figure 9.

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

825

Figure 10

Simulated Impact of Usage Intensity on Total Number of Adopters
(a) Trial campaign starting in month 17

1,200

Total number of adopters

1,000

800

Baseline adoption

600

Adoption in the presence of a free trial

400

­ 50

­ 30

­ 10

+ 10

+ 30

+ 50

Percentage change in usage levels (%)

(b) Trial campaign starting in month 5 600

Total number of adopters

500

400

300

200

­ 50

­ 30

­ 10

+ 10

+ 30

+ 50

Percentage change in usage levels (%)

consumers' mean belief about the ultimate service quality (as from month 17, the average corrected usage signal always exceeds the average corrected advertising or direct marketing signal; see Figure 6). By contrast, in earlier periods, learning through usage is not necessarily beneficial: Although it still reduces uncertainty, the resulting quality signals may lower consumers' mean quality beliefs. Hence, in those early stages, boosting consumers' usage intensity is not without risk. This is illustrated in Figure 10(b) which depicts the relationship between usage intensity during the trial and paid adoption for a free-trial campaign starting in month 5 (the least favorable starting month according to Figure 8). It shows that for trials offered early, if anything, increased usage lowers adoption. All differences between the baseline and free-trial performance are significant at the 95% level. The insights do not change when we measure performance in terms of paid adoption months.

7. Conclusion
Free trials have become common practice for a wide range of consumer services. Especially in the context of high-tech service contracts, marked by quality uncertainty and substantial setup costs, the opportunity to

try the service for free may appeal to a large number of potential customers. However, whether this also leads to more paying adopters, and how performance depends on the timing of the offer and usage intensity during the trial, has remained unclear. We address these questions by studying the effects of free trials for an IDTV service.
Our research contributes to a better understanding of the mechanisms that drive the performance of a trial promotion. We show that free trials enhance consumers' propensity to start using the service. The waiver of subscription and setup fees, along with the flexibility to cancel in case of dissatisfaction, entice consumers to take action and subscribe. These trial users may convert into paying adopters because, compared with adoption without prior trial, continuing the subscription does not entail any setup fee and implies lower decision and no installation efforts (the trial's inertia premium). At the same time, the free trial may reduce consumers' internal reference prices, such that the regular subscription fee appears more prohibitive. Our results suggest that the positive inertia effects outweigh the negative reference price effects.
However, the actual conversion rate also critically depends on the changes in perceived service benefits due to learning during the trial. We find that free trials are much more effective at conveying information about the service than advertising or direct communication: Actual usage reduces uncertainty and influences consumers' quality beliefs at a faster pace. Moreover, customers attracted through the trial may "spread the word," thus, current nonusers also learn about the service. As a result, if service quality is high, the free trial enhances the number of adopters but also accelerates many consumers' moment of adoption. However, if the service is not (yet) up to standards, the trial offer may be detrimental. Even when consumers realize that quality evolves over time, they may not sufficiently account for the temporary nature of any service deficiencies and take the bad usage experience as a signal of the service's ultimate quality. In such a case, the trial may alienate consumers and trigger adverse WOM effects, thus driving away customers who would have adopted now or later.
Fortunately, managers can avoid this through appropriate promotion timing. The trial promotion should take place after the service has been tried and tested in the field to ensure a better trial experience and lower the risk of prematurely eliminating customers. Moreover, for such well timed promotions, we show that stimulating usage intensity during the trial (for instance, by granting access to extra channels) may further enhance the subsequent conversion into paid adoption: Intensified usage enables triers to benefit more from uncertainty reduction and update their beliefs at a faster pace.

Foubert and Gijsbrechts: Free-Trial Promotions for High-Tech Service Adoption

826

Marketing Science 35(5), pp. 810­826, © 2016 INFORMS

Our research has several limitations that offer avenues for further research. First, additional work could enrich our findings through laboratory-based choice experiments. By including process measures, such experiments can help untangle some free-trial mechanisms (e.g., the inertia premium). Second, we use a "lost-for-good" framework: A consumer who defects after a trial does not return because opting out is an effortful and deliberate action. In settings in which consumers' choices are not sticky and dropouts can reenter the system, the optimal timing of free trials likely moves to earlier periods: Defection after a trial, which occurs especially in the earlier stages, becomes less detrimental. Third, we do not consider the possibility that consumers, once they have subscribed to the service, may use service options for extra charges, such as video-on-demand. This might affect the profitability of free trials. Finally, our model could be extended in several ways. In certain settings, usage intensity may vary with consumers' quality beliefs. Also, the company's direct marketing and advertising decisions may be related to the timing of the free-trial campaign. These interdependencies could be modeled and incorporated in policy simulations. We leave these extensions for future research.
Supplemental Material Supplemental material to this paper is available at http://dx .doi.org/10.1287/mksc.2015.0973.
Acknowledgments The authors thank Charlotte Rolef for her help with the data collection and Kathleen Cleeren and George Knox for their valuable comments. The authors also gratefully acknowledge the many constructive suggestions from the editor-in-chief, the associate editor, and the two reviewers.
References
Bawa K, Shoemaker R (2004) The effects of free sample promotions on incremental brand sales. Marketing Sci. 23(3):345­363.
Bicen P, Madhavaram S (2013) Research on smart shopper feelings. J. Marketing Theory Practice 21(2):221­234.
Chatterjee S, Carroll E, Spencer D (2009) Netflix. Case text, Ivey Business School, University of Western Ontario, London, Ontario, Canada.
Ching AT, Erdem T, Keane MP (2011) Learning models: An assessment of progress, challenges and new developments. Working paper, Rotman School of Management, University of Toronto, Toronto.
Ching AT, Erdem T, Keane MP (2013) Learning models: An assessment of progress, challenges, and new developments. Marketing Sci. 32(6):913­938.

Datta H, Foubert B, Van Heerde HJ (2015) The challenge of retaining customers acquired with free trials. J. Marketing Res. 52(2): 217­234.
Erdem T, Keane MP, Öncü TS, Strebel J (2005) Learning about computers: An analysis of information search and technology choice. Quant. Marketing Econom. 3(3):207­246.
Gauri DK, Pauler JG, Trivedi M (2009) Benchmarking performance in retail chains: An integrated approach. Marketing Sci. 28(3): 502­515.
Ghose A, Han SP (2011) A dynamic structural model of user learning on the mobile Internet. NET Institute Working paper, New York University, New York.
Halbheer D, Stahl F, Koenigsberg O, Lehmann DR (2014) Choosing a digital content strategy: How much should be free? Internat. J. Res. Marketing 31(2):192­206.
Heiman A, McWilliams B, Shen Z, Zilberman D (2001) Learning and forgetting: Modeling optimal product sampling over time. Management Sci. 47(4):532­546.
Ho T-H, Li S, Park S-E, Shen Z-JM (2012) Customer influence value and purchase acceleration in new product diffusion. Marketing Sci. 31(2):236­256.
Hoch SJ (2002) Product experience is seductive. J. Consumer Res. 29(3):448­454.
Jain D, Mahajan V, Muller E (1995) An approach for determining optimal product sampling for the diffusion of a new product. J. Product Innovation Management 12(2):124­135.
Manchanda P, Xie Y, Youn N (2008) The role of targeted communication and contagion in product adoption. Marketing Sci. 27(6):961­976.
Marks LJ, Kamins MA (1988) The use of product sampling and advertising: Effects of sequences of exposure and degree of advertising claim exaggeration on consumers' belief strength, belief confidence, and attitudes. J. Marketing Res. 25(3):266­281.
Mehta N, Chen XJ, Narasimhan O (2008) Informing, transforming, and persuading: Disentangling the multiple effects of advertising on brand choice decisions. Marketing Sci. 27(3):334­355.
Nam S, Manchanda P, Chintagunta PK (2010) The effect of signal quality and contiguous word of mouth on customer acquisition for a video-on-demand service. Marketing Sci. 29(4):690­700.
Narayanan S, Manchanda P (2009) Heterogeneous learning and the targeting of marketing communication for new products. Marketing Sci. 28(3):424­441.
Narayanan S, Manchanda P, Chintagunta PK (2005) Temporal differences in the role of marketing communication in new product categories. J. Marketing Res. 42(3):278­290.
Pauwels K, Weiss A (2008) Moving from free to fee: How online firms market to change their business model successfully. J. Marketing 72(3):14­31.
Sriram S, Chintagunta PK, Manchanda P (2015) Service quality variability and termination behavior. Management Sci. 61(11): 2739­2759.
Su X (2009) A model of consumer inertia with applications to dynamic pricing. Production Oper. Management 18(4):365­380.
Train KE (2009) Discrete Choice Methods with Simulation, 2nd ed. (Cambridge University Press, Cambridge, UK).
Wertenbroch K (1998) Consumption self-control by rationing purchase quantities of virtue and vice. Marketing Sci. 17(4):317­337.
Xu AJ, Wyer RS Jr (2010) Puffery in advertisements: The effects of media context, communication norms, and consumer knowledge. J. Consumer Res. 37(2):329­343.
Zhang J, Niu B (2014) Dynamic quality decisions of software-asa-service providers based on customer perception. Electronic Commerce Res. Appl. 13(3):151­163.

