http://pubsonline.informs.org/journal/mksc/

MARKETING SCIENCE
Vol. 36, No. 2, March­April 2017, pp. 195­213 ISSN 0732-2399 (print), ISSN 1526-548X (online)

A Cross-Cohort Changepoint Model for Customer-Base Analysis

Arun Gopalakrishnan,a Eric T. Bradlow,b Peter S. Faderb
a Olin Business School, Washington University in St. Louis, St. Louis, Missouri 63130; b The Wharton School, University of Pennsylvania, Philadelphia, Pennsylvania 19104 Contact: agopala@wustl.edu (AG); ebradlow@wharton.upenn.edu (ETB); faderp@wharton.upenn.edu (PSF)

Received: July 28, 2012 Revised: August 7, 2013; March 31, 2014; November 8, 2015; August 1, 2016 Accepted: August 12, 2016 Published Online in Articles in Advance: December 8, 2016
https://doi.org/10.1287/mksc.2016.1007
Copyright: © 2016 INFORMS

Abstract. We introduce a new methodology that can capture and explain differences across a series of cohorts of new customers in a repeat-transaction setting. More specifically, this new framework, which we call a vector changepoint model, exploits the underlying regime structure in a sequence of acquired customer cohorts to make predictive statements about new cohorts for which the firm has little or no longitudinal transaction data. To accomplish this, we develop our model within a hierarchical Bayesian framework to uncover evidence of (latent) regime changes for each cohort-level parameter separately, while disentangling cross-cohort changes from calendar-time changes. Calibrating the model using multicohort donation data from a nonprofit organization, we find that holdout predictions for new cohorts using this model have greater accuracy--and greater diagnostic value--compared to a variety of strong benchmarks. Our modeling approach also highlights the perils of pooling data across cohorts without accounting for crosscohort shifts, thus enabling managers to quantify their uncertainty about potential regime changes and avoid "old data" aggregation bias.

History: Preyas Desai served as the editor-in-chief and Scott Neslin served as associate editor for this article.
Funding: This work was supported by an AWS in Education Grant award by amazon.com and an ASA Travel award by the ASA Section on Statistics in Marketing.
Supplemental Material: The online appendix is available at https://doi.org/10.1287/mksc.2016.1007.

Keywords: changepoint · cross-cohort · hierarchical Bayesian · forecasting · customer-base analysis · customer lifetime value · reversible-jump MCMC

1. Introduction

"In times of rapid change, experience could be your

worst enemy"

--Jean Paul Getty

Managers in industries focused on repeat transactions such as Internet retailing, nonprofit fundraising, catalog marketing, and hospitality/travel services rely on customer-base analysis to track acquisition and retention performance and to make resource allocation decisions based on customer lifetime value (Jain and Singh 2002). Many data sets in such settings feature a time series of cohorts, a sequence in which each cohort contains a group of individuals who share a common feature (such as being acquired in the same year), and each successive cohort has a smaller number of time observations. Customer-base models have been successful in modeling within-cohort behaviors of interest such as customers' interpurchase times and churn propensities (Schmittlein et al. 1987), usage patterns of financial services (Allenby et al. 1999), and donor giving and dropout propensities (Fader et al. 2010, Netzer et al. 2008), providing managers with tools to understand and forecast the heterogeneous behavior of any given cohort with a sufficiently large number of time observations. However, existing customer-base

models remain largely silent on how to develop forecasts for new cohorts for which data are sparse, and how to allow for "regime changes" that differentially alter some cohorts' behaviors that make it inappropriate (and statistically "dangerous") to pool data across all cohorts. We illustrate the managerial questions that remain unaddressed as a result with the following example.
Consider Anita, a sales manager for an Internet retailer that has been in business since 2001. Each year, Anita is tasked with acquiring new customers and managing existing ones. Anita has come to view the set of customers acquired in a given year as a cohort that she can track over time, and she uses sophisticated models to understand and forecast the behavioral patterns of each cohort. However, she has little to no data on brand-new customers and is therefore unable to forecast their behavior, so she turns to several colleagues for advice. Bob, a data analyst, suggests pooling data from all cohorts to make an educated guess about the behavioral patterns of the newest cohort. By contrast, Colleen, the business intelligence manager, has the intuition that a competitor who entered the market in 2006 has been "skimming the best new customer prospects" such that the quality of newer

195

196

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

cohorts may be significantly different from pre-2006 ones. Colleen thinks it is important to understand what changes may have occurred and when. Bob is unsure whether and how to incorporate Colleen's insights to address Anita's needs. His conundrum is accentuated by the declining number of time observations across cohorts; while he could run a stand-alone model on older cohorts observed over a long period of time, new cohorts may feature a paucity of time observations, which are critical to identify any reasonable model.
From the above scenario, three managerial questions arise. First, is there evidence for discrete shifts or "regime changes" in a sequence of cohorts? Second, what aspects of cohort behavior drive these shifts, and can multiple potential drivers of aggregatelevel changes be teased apart, including separating cohort-level shifts from temporal effects that impact all cohorts? Third, how do we model and predict the behavior of new customer cohorts for which time observations are sparse?
In this paper we present two cross-cohort vector changepoint (VC) models that can provide guidance to these important managerial questions and address the limitations of existing customer-base models, which implicitly assume that individuals across all cohorts can be pooled to estimate a population-level model; an assumption that ignores the potentially changing behavioral patterns across cohorts. Importantly, we highlight the challenge posed in a multicohort setting of robustly estimating parameters for newer cohorts and demonstrate how accurate predictions of future behavior for such cohorts can be generated using the VC models.
Using a multicohort data set from a U.S. nonprofit organization, we compare our VC models to a number of strong benchmarks: (1) a single fully pooled model that assumes all cohorts share a base set of common parameters but allowing for heterogeneity using parametric cross-cohort effects, (2) a hierarchical Bayesian model without changepoints (HB-0) that assumes each cohort's parameters are drawn from a common hierarchical distribution, and (3) a classical changepoint model that places restrictions (i.e., a single changepoint location) on regime change patterns across all parameters (HB-CC). The results indicate that our proposed VC models outperform the benchmarks, with improved out-of-sample prediction for new cohort donations (the problem that Anita, our hypothetical sales manager, is facing), while providing new insights into the nature of the regime changes (i.e., what aspects of behavior are changing) that would be missed by these benchmarks, while also accounting for calendar-time effects common to all cohorts. Moreover, the "HB-0" and "HB-CC" benchmarks are themselves novel to the analysis of multicohort customer transactional data, and our work suggests that the VC models can be a superior choice for data of this kind.

We introduce two "flavors" of VC models in this paper. The first assumes cohort parameters are shared across cohorts but only within parameter-specific regimes that break up the sequence of cohorts using changepoints (B-VC model). The second VC model jointly estimates parameter-specific changepoints and cohort-specific parameters using an HB framework (HB-VC model). The key difference between the models is within-regime heterogeneity (which exists in the HB-VC and not within the B-VC), and we discuss what each model brings to the table in empirical settings such as the one we study in this paper. We emphasize that these VC models provide a new modeling twist on the conventional approach to modeling changepoints in a multidimensional parameter space. In particular, the VC models allow each parameter in a cohort-level model to be drawn from a regime-specific hierarchical distribution and the number of regimes to possibly differ across parameters. By contrast, the classical changepoint paradigm requires all cohort parameters to shift simultaneously across regimes (Bai 1997, Bhattacharya 1987). Furthermore, the classical changepoint model is inefficient if only a subset of parameters is affected by regime changes.
We also note that our VC framework is agnostic to the type of behavior being modeled and is compatible with any setting in which a sequence of customer cohorts exists, individual-level data is available, and a parametric cohort-level likelihood function can be defined. At the cohort level, we use a general discretetime model of donor attrition and transaction behavior that allows for a correlation between attrition and transaction propensities and time-varying covariates that nests the Beta-Geometric Beta-Bernoulli (BG/BB) model developed by Fader et al. (2010). A different cohort-level model can easily be accommodated in our framework, which can be applied to other settings such as doctor visits for age-cohorts of patients (Winkelmann 2004), online music purchasing (Fader et al. 2005), effects of aging on product consumption (Rentz and Reynolds 1991), and interpurchase times for financial products (Allenby et al. 1999).
Our work is related to four strands of literature. First, our Bayesian approach to detecting changepoints when the number of cohort regimes is unknown builds on the reversible-jump (R-J) Markov Chain Monte Carlo (MCMC) method introduced by Green (1995), which (i) allows for considerable flexibility in defining prior distributions for the number and location of changepoints; (ii) enables the researcher to specify a broad range of allowed moves from one model to the next; and (iii) uses a generalization of the Metropolis­ Hastings algorithm to estimate the posterior densities. We note that other approaches to changepoint detection, notably the product-partition method of Barry and Hartigan (1993) and Bayesian model selection

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

197

approach of Carlin and Chib (1995) are popular alternatives but do not allow for the flexibility in specifying priors and model moves that the R-J method enables.1 To date, the R-J method has had limited applications in marketing (Kim et al. 2007, Ebbes et al. 2015, Narayanan 2013) due to concerns about generating efficient proposal distributions for Bayesian computation. We show that appropriate choices of model moves can result in efficient traversal of large model spaces that can result from even a short sequence (e.g., 10) of cohorts.
A second literature stream uses mixture models (Richardson and Green 1997, Allenby et al. 1999) and semiparametric approaches (Ansari and Iyengar 2006) to model complex distributional shapes. However, since these models do not impose structure in the form of contiguous regimes of cohorts, they are not suitable for detecting regime changes, even if they are able to capture multimodal distributions in a fully pooled model.
A third stream of literature accounts for behavioral changes across cohorts by either explicitly specifying covariates that capture systematic differences across cohorts (Schweidel et al. 2008, Yang and Allenby 2003) or by introducing hierarchical priors that enable "information sharing" across spatially segmented cohorts (Hofstede et al. 2002, Hui and Bradlow 2012). Our approach is most closely related to these hierarchical prior approaches--however, while spatial segments are on a "level playing field" in terms of observations, the temporal structure of a sequence of cohorts ordered by time of acquisition results in successive cohorts having fewer time observations, which is an additional challenge in our setting. The main issues with parametric cross-cohort effects are over-fitting due to noisy data within-sample to the detriment of out-of-sample fit, and the inability to capture potentially multiple sharp transitions in cohort parameters parsimoniously. Our VC model flexibly allows for arbitrary cross-cohort patterns without imposing high-degree polynomial effects (as per one of our benchmarks above) that may predict implausible parameters for future cohorts.
Finally, we use a general discrete-time model of donor attrition and transaction behavior that nests the BG/BB model (Fader et al. 2010) to characterize cohort-level donation behavior, linking our work to the literature on "buy `til you die" (BTYD) models in noncontractual settings. Our approach provides a natural extension to such models by avoiding the extreme options of either estimating one model by fully pooling multicohort data (as Fader et al. 2010 did) or estimating cohort-specific models in isolation (which is virtually impossible for newer cohorts), while allowing for correlation between attrition and transaction propensities and time-varying covariates (e.g., calendar time effects).

The remainder of this paper is organized as follows. In Section 2 we present the model and the "technology" to estimate the posterior distributions of interest. We then discuss model identification in Section 3, and empirical results in Section 4. We conclude in Section 5 with managerial implications and suggestions for future work. The online appendices contain details and choices made to implement our computational approach that will allow for replication by other researchers interested in these methods.
2. Model Development
"You never change things by fighting the existing reality. To change something, build a new model that makes the existing model obsolete"
--Richard Buckminster Fuller
In this section, we specify the vector changepoint model starting with the cohort-level discrete-time model of donor attrition and transaction behavior in Section 2.1, followed by the changepoint model that drives the assignment of cohorts to regimes in Section 2.2. Since the R-J method is less well-known compared to the Metropolis­Hastings and Gibbs samplers, we provide a brief description of how it is used to estimate the model in Online Appendices A and B.
2.1. Cohort-Level Model Our nonprofit data set contains records of donations made over the history of each donor's association with the organization. In addition, we were able to obtain donor zip code data that may provide relevant information regarding donation behavior (e.g., distance from the organization's headquarters, median household income, and household size of zip code) and demonstrate how our cohort-level model (described in this section) can allow for time-invariant covariates. In the absence of covariates, the panel data of donation incidence across donors in the same cohort (started giving in the same year) can be described by a standard BTYD model such as the BG/BB, which captures donor transaction and latent attrition propensities while allowing for heterogeneity in this noncontractual setting.
The BG/BB model, however, has the following three limitations that make it less than fully appropriate for our problem: it (1) does not allow for correlation between transaction and attrition propensities; (2) does not allow for time-invariant covariates; and (3) does not allow for time-varying covariates. A hierarchical Bayesian BTYD model akin to Abe (2009) or Singh et al. (2009) defined for a discrete-time setting would relax the first two limitations but not the third. Therefore, we propose a more general discrete-time BTYD model that allows for the probability of transaction and attrition to vary by individual and time (cf. Schweidel and Knox 2013).

198

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

For customer i in cohort c observed over Tc repeat transaction opportunities (the initial transaction that
identifies the cohort an individual belongs to is
excluded), we define the attrition and transaction prob-
abilities as follows, where yict is the observed transaction incidence, and zict is a latent indicator of attrition (zict 0 connotes being alive, and zict 1 leads to the donor entering an absorbing state of no transactions):

Pr(zict 1 | zic, t-1 0, Xict , icz , z ) Pr(zict 1 | zic, t-1 1)
Pr(yict 1 | zict 0, Xict , ic y , y) Pr(yict 1 | zict 1)

(icz + Xict z), 1, (ic y + Xict y), 0.

The individual-specific random intercepts icz and icy are distributed multivariate normal with mean µc and covariance matrix c while the slopes z and y are common across individuals. We call this the mixed
correlated probit-normal/probit-normal (CPN/PN)
model given that the intercepts are heterogeneous and
the slopes are common (hence a mixed model), which
allows for the attrition and transaction intercepts to
be correlated. Furthermore, Xict can contain a combination of individual-specific time-invariant covariates
(e.g., demographics), cohort-specific time-invariant
covariates (i.e., to model cross-cohort effects), calendar-
time effects (i.e., modeling systematic changes over
time affecting all cohorts) in which case we denote the
models as HB-VCT and B-VCT (T for time effects), and
other time-varying covariates, as we demonstrate in
our application.
For an individual with observed incidences Yic { yict }  t and recency (time of most recent transaction), recic, the likelihood function is obtained by marginalizing the joint likelihood of Yic and unobserved lifetime Lic as shown in Equation (1). Lifetime cannot be lower than recency, since a BTYD model does not
allow transactions after attrition. When Lic Tc, the individual survived till the end of the observed time
periods without attrition. When Lic 0, the individual dropped out even before facing a single repeat trans-
action opportunity. For a given lifetime Lic, the joint likelihood is composed of three terms: the probability
of attrition (not included if we observe survival), the
probability of observing the transactional history over
this lifetime, and the probability of not having dropped
out prior to the duration of this lifetime

p(Yic | icz , ic y , z , y , {Xict })

Tc

(icz

+

Xic,

 )I(Lic <Tc)
Li +1 z

Lic recic

Lic

·

(ic y + Xict  y )yict

t min(1, Lic )
·(1 - (ic y + Xict  y ))1-yict

I(Lic >0)

·(1 - (icz + Xict z))

. (1)

By setting all of the elements of z and y to zero, and constraining the attrition and transaction intercepts
to be uncorrelated, the likelihood is analogous to the
BG/BB model reparameterized with a probit-link func-
tion in place of Bernoulli probabilities. The benefits of the mixed CPN/PN model are threefold. First, icz and icy can be correlated through the full covariance matrix c in the cohort-level prior, which provides the model with greater flexibility to fit data patterns where
such relationships may exist. Second, time-invariant
covariates can be incorporated in Xict, which would then apply across each time period for an individual.
Finally, Xict can include time-varying covariates such as common temporal shocks affecting all cohorts over
calendar time. These covariate effects can differentially
impact attrition and transaction propensities through slopes z and y, and we discuss identification restrictions relating to these in Section 3.1.
The likelihood function for all of the individuals in the cohort (total of Ic) as shown in Equation (2) is simply the product of individual-level likelihoods

p(Yc | {icz }, {icy }, z , y , {Xict })

Ic

p(Yic | icz , icy , z , y , {Xict }).

(2)

i1

The prior for the individual-level intercepts is the multivariate normal cohort-level distribution. The prior for the cohort-level distribution is obtained from the vector changepoint model (whose parameters we denote as MVC) that we define in Section 2.2, which allows for parameter- and regime-specific shrinkage based on imputed cross-cohort effects. The conjugate prior for the covariate slopes (z , y) is also multivariate normal, and we use standard hyperparameters that enable a diffuse prior. We now present the joint posterior distribution of the mixed CPN/PN model parameters conditional on MVC, Yc, and Xc

p({icz }, {icy }, z , y , µc , c | MVC , Yc , Xc)  p(Yc | {icz }, {icy }, z , y , {Xict }) ·p({icz }, {icy } | µc , c) · p(µc , c | MVC) · p(z) · p(y).

For our setting, the main cohort-level parameters

of interest are mean µc and covariance matrix c. To assign a multivariate normal prior to these parameters

(that allows for greater flexibility than the commonly

used normal-inverse Wishart prior), we take the log

transform of the two variance terms in c, and a logit

transformation

of

1 2

(z

y

+ 1),

where

zy

is

the

correla-

tion coefficient.

The following parameter vector c: {µcz , µcy ,

log(c2z

),

log(c2y

),

logit(

1 2

(z

y

+ 1))}

then

contains

the

same information as the cohort-level mean and covari-

ance matrix and is a convenient form that we exploit in

the VC model.

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

199

2.2. Vector Changepoint Model
The crux of this paper lies in the definition of p(c | MVC), where MVC represents the set of parameters in the VC models. As mentioned previously, c is a five-dimensional cohort-specific parameter vector
that completely specifies the CPN/PN model for each
cohort. We start with how these priors are defined for
two benchmark models (B-PE and HB-0), to build intu-
ition for how the VC models differ from these. Let c have a degenerate probability distribution
with all its mass at µg. This corresponds to a special case of the fully pooled B-PE model with cross-cohort effects absent, where MBPE {µg}. This constrains all cohorts to be represented by an identical CPN/PN model. In the HB-0 model, c  MVN(µg , g), where g is the covariance matrix capturing cross-cohort hetero-
geneity while assuming that all cohort-specific parameter vectors c are draws from the same distribution. This is the standard HB model that would be fit using
"Bayesian shrinkage 101."
The intent of the VC models is to allow each parameter d in c to have its own regime structure and therefore pool with "relevant peers"--i.e., parameter d's prior will depend on the number of changepoints Kd  {0, . . . , N - 1} in a sequence of N cohorts, the starting locations of any changepoints Qd and the set of parameters d associated with each of the (Kd + 1) regimes (hereafter interchangeably referred to as a block). The set {Kd , Qd , d } then defines the changepoint model for the dth parameter of the cohort sequence. When d is a set of univariate normal distribution parameters (i.e., cohort parameters are i.i.d. draws from the
regime-specific distribution), we refer to the model as
HB-VC to reflect Bayesian shrinkage at the cohort-level. When d is a set of parameters that are assumed to be constant within a regime, we refer to the model as
B-VC to reflect that there is no cohort-specific shrink-
age. Both are vector changepoint models, with the B-VC
model being an important special case of the HB-VC
model that may perform well under sparse-data situ-
ations where the identification of regime changes are
possible, but the exact identification of heterogeneous
parameters within a block is less so.
In the HB-VC model, we allow for dependence between cohort-level parameters in c through a correlation matrix R that is shared across regimes. Two points
are important to note regarding this correlation matrix:
(1) allowing the correlation matrix to be regime-specific will require aligning Kd , Qd  K, Q  d, which translates to the HB-CC classical changepoint model that
forces synchronized regime changes across parame-
ters, and (2) this correlation captures the relationship between pairs of cohort parameters such as the mean attrition and transaction propensity in a cohort, and is
entirely different from the individual-level correlation of attrition and transaction intercepts within a cohort

described in Section 2.1. The HB-VC model may, there-
fore, be relatively parsimonious compared with the
classical changepoint model as estimating a large set of
correlation coefficients reliably by regime is challenging
even for a moderate-sized cohort sequence. It is straightforward to see that Kd 0  d, d
{µgd , gd } collapses the HB-VC to the HB-0 model. Unlike the HB-0 model, the multivariate normal prior for c is constructed element-by-element, with mean and variance of each cohort parameter cd depending on the regime membership bcd of this parameter. Similar to the HB-0 model, the correlation matrix R
denoting the relationships between cohort parameters
is common across regimes.

In the HB-VC model, c  MVN

         

µ g1 , µ g2 , µ g3 ,
µ g4 , µ g5 ,

bc1 bc2 bc3 bc4 bc5

         

,

Sc

RSc

,

where Sc is a diagonal matrix whose diagonal elements are the standard deviations of normal distributions that serve as priors for cohort c's parameters, and µgd , bcd is the mean of the bcdth block for parameter d. We denote the model comprising the vector of changepoint models and the correlation matrix R as MVC  {{Kd , Qd , d }  d, R}. We illustrate with an example of a data generating process with differing regime structures by parameter in Figure 1. As can be observed, no two cohorts need to have the same multivariate normal prior unless all of their parameter-specific block memberships are exactly the same. Furthermore, even though cohorts have different priors, the elements corresponding to parameters with just one regime are the same across these priors. If a changepoint is found at cohort 6, as illustrated for parameter 1, cohorts are partitioned into two regimes (cohorts 1 through 5, and cohorts 6 through 10). Inference for all cohorts preand post-changepoint are affected by multiple regimes, since newer cohorts do not share information with older cohorts and vice versa. Importantly, the changepoint locations induce multiple regimes as opposed to either a cohort-only model or a single-regime hierarchical model (HB-0).
We now define hyperpriors for the parameters contained in MVC. We choose a uniform prior over Kd's support (from 0 to N - 1) and locations of changepoints Qd are also assumed noninformative conditional on Kd. In this manner, we let the data "speak" as to the locations and number of changepoints; however, in situations where informative priors exist they are easily incorporated. d consists of Kd + 1 normal distributions with corresponding means and variances. Each mean-variance pair is assumed to be normalinverse-chi-squared (NIX) distributed for conjugacy,

200

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

Figure 1. Example of Priors from the Vector Changepoint Model

Coh. 1

Coh. 2

Coh. 3

Par 1: Regime 1 ­ N ( g11, g211)

Par 2: Regime 1 ­ N ( g21, g221)

Coh. 4

Coh. 5

Coh. 6

Coh. 7

Coh. 8

Par 1: Regime 2 ­ N ( g12, g212)

Par 3: Regime 1 ­ N ( g31, g231) Par 4: Regime 1 ­ N ( g41, g241) Par 5: Regime 1 ­ N ( g51, g251)

Coh. 9 Coh. 10
Par 2: Regime 2 ­ N ( g22, g222)

Notes. No two cohorts need to have the same multivariate prior unless their parameter-specific block memberships are identical. Cohorts 1 through 5 have identical priors, but the prior for Cohort 6 differs from the first five cohorts due to the changepoint in parameter 1.

with relatively noninformative yet proper hyperpriors (Gelman 2006). The prior on correlation matrix R is defined such that the marginal distribution for each of the correlation coefficients is uniform (Barnard et al. 2000). It follows that

D
p(MVC)  p(R) p(d | Kd , Qd)p(Qd | Kd)p(Kd),
d1
where p(R) is the Barnard marginally uniform prior on the correlation coefficients, p(d | Kd , Qd) is the product of NIX distributions depending on the number and location of changepoints,

p(Qd | Kd)

N -1 Kd

-1
,

and p(Kd)

1. N

For our empirical setting, we focus on a more parsimonious nested version of the full HB-VC model in which R is set to the identity matrix, and we estimate the B-VC model for comparison.2 Alternative specifications that lie in between the HB-VC and HB-CC models are possible where synchronization of regime changes in subsets (e.g., pairs) of the parameter space are specified; this offers an important direction for future research.

In Equation (3) we specify the joint posterior distribution of the HB-VC and cohort-level model parameters that we seek to estimate

p({{icz }, {icy }, c }  c, z , y , MVC | {Yc , Xc }  c)

N
 p(Yc | {icz }, {icy }, z , y , {Xict })
c1
· p({icz }, {icy } | c) · p(c | MVC) · p(MVC)

· p(z) · p(y).

(3)

There are four layers for estimation inherent in the above specification: (i) the hierarchical changepoint model and its parameters, which we draw using R-J MCMC methods, (ii) the cohort-specific parameter vector c, which we draw using a randomwalk Metropolis­Hastings sampler for each cohort, (iii) individual-level intercepts within each cohort, which we draw using a partially collapsed Gibbs sampler (Park and van Dyk 2009) that augments additional random variables for computational efficiency and better mixing, and (iv) the common slopes for covariates, drawn using a Gibbs sampler. Online Appendix A contains computational details of how to implement our HB-VC model (including the full model that entails an additional layer to estimate the correlation matrix R).

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

201

Table 1. Summary of Models
Model Single fully pooled model (B-PE)
HB no-changepoint (HB-0) HB classical changepoint (HB-CC)
HB vector changepoint (HB-VC)
Vector changepoint without HB (B-VC) Single fully pooled model with
calendar-time effects (B-PET) Vector changepoint without HB and
with calendar-time effects (B-VCT)
HB vector changepoint (HB-VCT)

Description
Only one CPN/PN parameter vector across all cohorts (µg) plus a parametric cross-cohort effect using linear, quadratic, and log components
All cohorts pool under a single regime but each cohort i has its own parameter vector i All parameters share the same regime configuration and each cohort i has its own parameter
vector i Each parameter has its own regime configuration and each cohort i has its own parameter
vector i A special case of HB-VC where cohort parameters are constant within a regime Only one CPN/PN parameter vector across all cohorts (µg) plus parametric cross-cohort and
time effects using linear, quadratic, and log components Each parameter has its own regime configuration and each cohort's parameter vector i is a
function of the regime configuration plus time effects using linear, quadratic, and log components
Each parameter has its own regime configuration and each cohort i has its own parameter vector i, plus time effects using linear, quadratic, and log components

2.3. Summary of Models A summary of the models we feature in our empirical analysis is given in Table 1. The HB-VCT and B-VCT models allow for regime changes in cohort time as well as calendar-time effects. The HB-VC model is equivalent to HB-VCT with calendar-time effects turned off. B-VC is a special case of HB-VC with cohort parameters constant within regimes. HB-0 is equivalent to HB-VC with regime changes in cohort time turned off. HB-CC allows for changepoints in cohort time but constrains them to be the same across cohort-level parameters (i.e., a classic changepoint model). B-PET allows for parametric cohort and calendar-time effects, and B-PE is identical to B-PET with calendar-time effects turned off. However, B-PET and B-PE only allow for these effects on the attrition and transaction mean propensities (see Equation (1)). This provides a rich set of models to understand which model features improve performance.
All models include demographic covariates affecting attrition and transaction propensities. While we estimate our models using common slopes for the covariates across cohorts, cohort-specific slopes could be identified, if for instance, individual-level marketing variables were available that provided variation within a cohort above and beyond that driven by parameter heterogeneity. In this case, cohort-specific slopes could be straightforwardly incorporated into c and the changepoint model framework, and can be explored in future research with data sets including such covariates.
It is important to note that the HB-VCT and B-VCT models are able to separate regime changes in cohort time from calendar-time effects, which capture an alternate source of nonstationarity that affects customers in all cohorts over time. When all or a subset of newer cohorts' parameters are drawn from a different distribution than older cohorts, the VC models will estimate

the number and locations of these regime changes, along with the distributions that best describe each regime. Older cohorts' parameters do not experience changes due to a regime shift in cohort time. These parameters (governed by a CPN/PN model) already capture within-cohort nonstationary behavior through the absorbing attrition state and calendar-time effects (which we capture using linear, quadratic, and logtime terms similar to Khan et al. 2009). An interesting avenue for future research is to also allow for changepoints within cohorts over time (e.g., Fader et al. 2004), but in most cases would require much longer time series data.
What types of data characteristics would indicate the need for the VC models? Observed aggregate cohort behaviors over time (e.g., number of transactions, recency-frequency (RF) table) can be compared across cohorts after appropriate normalization for cohort size. Should there be considerable variation in these patterns across cohorts, the VC models would be the ideal approach to parse out what underlying regime changes may account for these differences. Other models, such as HB-0, do not allow for sufficient flexibility to capture richer cross-cohort changes, and models such as B-PE suffer from out-of-sample generalization issues due to the parametric form of cross-cohort effects. Even if aggregate patterns do not indicate cross-cohort changes, there may be underlying regime changes due to heterogeneity within a cohort that "cancel out" in aggregate data. Thus, visual inspection is not a sufficient condition to fit a simpler model. Furthermore, the VC models are parsimonious in that changepoints are not fit if there is insufficient signal in the data. If no changepoints are found across all parameters, the HBVC collapses to the HB-0 model, and the B-VC model collapses to a fully pooled model (i.e., B-PE without parametric cross-cohort effects).

202

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

3. Model Identification
We now discuss identification of the cohort-level CPN/PN model with common slopes (Section 3.1), and the hierarchical vector changepoint model (Section 3.2) given our interest in predicting the behavior of cohorts with very limited longitudinal data or a new cohort with no observed repeat transactional data at all. We then discuss the empirical recovery of the HB-VCT model using simulated data in Section 3.3.

3.1. Identification of the CPN/PN Model with Common Slopes
We separate the identification into two parts--first, the
identification of the CPN/PN model without covari-
ates, for which the RF table serves as sufficient statistics
(Fader et al. 2010). We then discuss the identifica-
tion of covariate coefficients (which then relies on the
relationship between individual-level parameters and
covariates).
For a given cohort observed over Tc repeat observations, Jc Tc(Tc + 1)/2 + 1 unique RF combinations exist. Identification is established if model parameters µc , c have a one-to-one mapping with the probability distribution over these Jc RF patterns; in other words, j(µ1, 1) j(µ2, 2)  µ1 µ2, 1 2, where j is the transformation mapping µc , c to p(RFj | µc , c) and is defined as



j(µc , c)

p(RFj | icz , icy , z 0, y 0, {Xict })

· p(icz , icz | µc , c) dicz dicz.

We first note that identification requires that Jc  5, since we have to estimate five parameters for the CPN/PN model without covariates, which implies that Tc  3 is required. As an illustration take Tc 1, which implies that there is only a single transaction period and thus the only outcomes are binary (0 or 1 repeat transactions). By turning off attrition (let the attrition mean approach negative infinity) and transaction-rate heterogeneity (let transaction-rate variance approach zero), we can explain the data with the transaction-rate mean alone. Adding these additional parameters leads to severe underidentification.
Suppose j(µ1, 1) j(µ2, 2)  j for two sets of model parameters and Jc  5. This would then imply that the multivariate normal mixing distributions p(icz , icz | µ1, 1) and p(icz , icz | µ2, 2) are identical, which is only possible if µ1 µ2 and 1 2. Thus, each set of CPN/PN model parameters generates a unique probability distribution of RF patterns and a given set of observed RF moments coincides with a unique set of model parameters.
Adding covariates means that the RF table of counts no longer serves as sufficient statistics. Slopes for time-invariant covariates such as demographics

would allow for changes to an individual's propensities and are identified through the covariation between observed covariates and imputed behavior. For instance, if customers with higher incomes were less likely to drop out, the data should reflect such patterns. Because we allow for differential effects on transaction and attrition propensities, it is possible that controlling for these covariates may reduce variances and correlation of the unobserved heterogeneity in intercepts.
Identification of slopes of time-varying covariates is considerably more nuanced in the case where these covariates do not vary across individuals in a cohort. For instance, suppose we wish to add (as we do in HB-VCT and B-VCT) a parametric calendar time effect to capture "common shocks" over time to all customers' propensities in that cohort. The absence of cross-sectional variation within a cohort makes it challenging (but not impossible) to pin down calendar time effects compared to the (already latent) attrition propensity. The inclusion of multiple cohorts to estimate common calendar time effects does provide variation due to differing cohort birth times and attrition rates, which helps identify such effects. Hence, we use common slopes across cohorts.
We discuss empirical recovery of the CPN/PN model with common slopes (essentially the B-PE model) using simulated data in Online Appendix C. The results show that cross-cohort and calendar-time effects can be teased apart in a sequence of 10 cohorts (akin to our data), along with the CPN/PN parameters.
3.2. Identification of Regime Changes Using the Changepoint Model
Our VC algorithm searches (in our case probabilistically samples) over the space of possible models ({Kd , Qd , d }  d) to identify the ones which best fit the data. The factors driving identification are conceptually similar to those that can distinguish models in a likelihood ratio test for model selection (Vuong 1989). For example, consider the null hypothesis as K 0 (a single regime) and what in the data would drive the selection of models where K > 0. If we postulate two regimes, a large difference between the means of the two regimes combined with low within-regime "noise" or variance would increase the odds of correctly rejecting the null hypothesis, akin to classical signal-to-noise ratio (SNR) research (e.g., Box 1988, Pelli and Farell 1999). In addition, the length of the second regime and within-regime variance can influence whether the cohort parameter values in the new regime are interpreted as a one-off statistical blip or a discrete shift.
We demonstrate empirical parameter recovery by simulating 10-cohort data sets in which we manipulate the number of regimes by parameter (either 1 or 2), length of the second regime, within-regime variance (same in both regimes for convenience), and size of the

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

203

mean shift, and estimate the HB-VC parameters from the generated data. The cohort-level parameters are held fixed for the MCMC estimation, in which we take 50,000 draws using the R-J method discarding the first 10,000 as burn-in. Only the first parameter has a regime shift, and the other four parameters are drawn from single regimes to contrast the recovery of true versus possibly spurious changepoints. We then compute the average posterior probabilities across 25 runs based on the true model parameters.
From Figures 2(a) and 2(e), we find that the SNR (defined here as the ratio of across-regime mean-shift to within-regime standard deviation) needs to be high enough to recover a true changepoint. Above an SNR of roughly 4, a true changepoint is detected with a high probability even for short new regimes. The patterns are similar for low (0.1) and high (0.75) mean shift, indicating that SNR is the primary driver for empirical recovery. For SNRs below 3, the probability of a true changepoint is attenuated and therefore downwardly biased. Importantly, this conservatism helps avoid false positives when there is no changepoint. In Figures 2(d) and 2(h), we show that for a parameter with no changepoints, the probability of a single regime is recovered cleanly (>90%) even for low SNRs. SNR also impacts recovery of changepoint location--at high SNRs, a true changepoint location is practically perfectly recovered, and this gets attenuated as SNR decreases, as shown in Figures 2(c) and 2(g).
These results indicate that the model is able to pick up changes even for short new regimes, as long as the SNR is high enough, which bodes well for "early detection" of regime changes in actual data sets.
Finally, correctly identifying the number and locations of changepoints leads to the recovery of the normal distribution parameters in each cohort-regime, since the correct parameters will be pooled to estimate the mean and variance of each distribution.
3.3. Empirical Recovery of the HB-VCT Model Using Simulated Data
Section 3.1 establishes the conditions to identify cohort-level parameters and discusses that cohort- and calendar-time effects can be teased apart in a sequence of cohorts. Section 3.2 demonstrates that regime changes underlying a sequence of cohorts can be accurately recovered as long as the SNR is high enough, by holding the cohort-level parameters as knowns in the analysis. In this section our focus is to demonstrate empirical recovery of the HB-VCT model using simulated data.
We simulate an 11-cohort sequence with a changepoint for one of the parameters at the seventh cohort. We then run the HB-VCT model on this data (detailed in Online Appendix D), holding out the final

cohort and making out-of-sample transaction predictions for each cohort (similar to our empirical setting). For cohorts included in the model estimation, the HB-VCT model computes posterior distributions for each cohort's parameters, which are used to compute the posterior predictive distributions for the number of transactions. Mean absolute percentage error (MAPE) calculations were performed at each iteration of the MCMC sampler and averaged across iterations to yield model performance measures for each cohort. Note that the posterior distribution for the held-out cohort is identical to the hierarchical prior distribution since its data are not used in the model estimation.
As we show in Online Appendix D, the HB-VCT model recovers the parameters of older and newer cohorts while separating out calendar-time effects and has an accurate in-sample and out-of-sample predictions for all cohorts, including the held-out 11th cohort.
4. Empirical Analysis
In this section we describe our data set (Section 4.1), discuss the criteria used for model convergence and fit assessment (Section 4.2), and present the results (Section 4.3).
4.1. Data Set The data set consists of donation records of individual donors from a U.S. nonprofit public television broadcaster. This organization regularly runs television campaigns in which a special show is broadcast (e.g., Andrea Bocelli's Love in Portofino), which contains many breaks for the station to request donations that can yield a souvenir item related to the show. These campaigns support a significant portion of the operating budget in contrast to competing cable channels that do not solicit for funds to operate the channel in the same way.
In addition, we were able to obtain donor zip code data that we were able to match with 1990 and 2000 census data to define distance from the organization's headquarters, median household income, and household size as potentially relevant covariates. We track the longitudinal giving history of donors who made their first donation between January 1, 1990 and December 31, 2000, where the history is available from the time of acquisition through December 31, 2006. Because of the annual cycle of fundraising programs, we divide donors into a sequence of 11 yearly cohorts from 1990 through 2000. Each individual within a cohort is then observed for Tc (2006 - YearAcquired) repeat observations, where each observation is annual donation incidence. We define a donor to have given if they made at least one donation in a calendar year. Since this is a noncontractual setting, we do not observe a donor's decision to churn, and only have access to transactional patterns. We randomly sampled 33% of

204

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

Figure 2. (Color online) Identification of HB-VC Model Using a Simulated Sequence of 10 Cohorts

(a) Par 1: True K = 1, True Q = 6 1.0 0.8 0.6

(b) Par 1: True K = 1, True Q = 6

1.0

Low mean shift

0.8

High mean shift

0.6

Pr(K = 0 for par 1)

Pr (K = 1 for par 1)

0.4

0.4

0.2

Low mean shift

High mean shift 0

1

2

3

4

5

6

7

8

SNR

0.2

0

1

2

3

4

5

6

7

8

SNR

Pr (Q = 6 for par 1)

1.0 0.8 0.6 0.4 0.2
0 1

(c) Par 1: True K = 1, True Q = 6

Low mean shift High mean shift

2

3

4

5

6

7

8

SNR

Pr (K = 0 for par 2­5)

1.0 0.8 0.6 0.4 0.2
0 1

(d) Par 2­5: True K = 0

Par 2 Par 3 Par 4 Par 5

2

3

4

5

6

7

8

SNR

Pr(K = 1 for par 1)

1.0 0.8 0.6 0.4 0.2
0 1

(e) Par 1: True K = 1, True Q = 9

Low mean shift High mean shift

2

3

4

5

6

7

8

SNR

Pr(K = 0 for par 1)

1.0 0.8 0.6 0.4 0.2
0 1

(f) Par 1: True K = 1, True Q = 9
Low mean shift High mean shift

2

3

4

5

6

7

8

SNR

(g) Par 1: True K = 1, True Q = 9 1.0

(h) Par 2­5: True K = 0 1.0

Pr (K = 0 for par 2­5)

Pr(Q = 9 for par 1)

0.8

0.8

0.6

0.6

0.4

0.4

0.2

Low mean shift

0.2

High mean shift

0

0

Par 2 Par 3 Par 4 Par 5

1

2

3

4

5

6

7

8

SNR

1

2

3

4

5

6

7

8

SNR

Notes. SNR is defined as the ratio of across-regime mean shift to within-regime standard deviation. A true changepoint is detected with a high probability when SNR is large enough as shown in Figure 2(a). The algorithm is conservative and prefers a false negative at low SNRs (Figure 2(b)) to ensure a low probability of false positives (Figure 2(d)). This also holds for the changepoint location and for various lengths of a new regime (Figures 2(e) to 2(h)). The magnitudes of low and high mean shifts are 0.1 and 0.75, respectively.

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

205

Table 2. Number of Initial Donors by Cohort (After Sampling 33% of Cohort)

Cohort 1990 Donors 5,085

1991 6,467

1992 5,851

1993 7,494

1994 5,223

1995 5,379

1996 5,989

1997 4,364

1998 2,876

1999 4,357

2000 3,338

the donors in each cohort for estimation, yielding a total of 56,423 donors across all cohorts. The breakdown of their cohort membership is given in Table 2.
For the remainder of this analysis, we focus on the observed data at the end of year 2002, at which point the final (year 2000) cohort would have had just two repeat transaction opportunities. This presents identification challenges as discussed in Section 3 and severe forecasting challenges for Anita, the hypothetical sales manager described in Section 1. In Figure 3, we show the percentage of active donors (those who gave in a given year) by cohort (normalized by cohort size for ease of comparison) up through 2002 which indicates the differing amounts of longitudinal data available for each cohort and the differing drop-offs in active donors across cohorts. For instance, less than 16% of the original cohort is still active for all but the 2000 cohort. As discussed in Section 3.1, variation in cohort birth times enables the identification of any possible calendar-time effects.
In Figure 4 we provide a different view of the same information, comparing cohorts since their year of acquisition, which more clearly highlights cross-cohort differences. Newer cohorts appear to have a steeper fall-off in donation incidence as compared to older cohorts. Using the classification tree approach of

Schwartz et al. (2014), the BG/BB model (which we extend to include covariates in the CPN/PN model) best fits the characteristics of each cohort's data as compared to other options such as Hidden Markov Models suggesting forward transitions to a nongiving ("death") state without periods of returning activity. One aspect of the cohort transaction curves, however, is worth noting as unusual--for many cohorts, the number of transactions in the most recent time period (2002) is flat or even slightly higher than the previous time period (2001). Latent attrition models such as CPN/PN or BG/BB would not fit this particular pattern because the number of active donors within a cohort must necessarily decrease over time. We point this feature out because of the implications if an analyst used data up to 2001 to forecast future time periods of existing and new cohorts; i.e., any latent attrition model will underforecast the actual transaction activity as it would never predict a flat or slight increase in this measure. We study the effect this would have on model estimation as a robustness check in Section 4.3.2.
Whether the overall patterns in Figure 4 can be attributed to multiple cohort regimes, a single regime with "noise," or a deterministic trend (e.g., a calendar-time effect) is unclear from visual observation. Our data set

Figure 3. (Color online) Percentage of Active Donors for Each Cohort in Calendar Time
Percentage of active donors from cohort acquisition through 2002 50

45

40

35

30

% 25

20

15

10

5

0

90

91

92

93

94

95

96

97

98

99

00

01

02

Year

Notes. Since cohorts are acquired at different points in time, this helps identify any calendar-time effects.

1990 cohort 1991 cohort 1992 cohort 1993 cohort 1994 cohort 1995 cohort 1996 cohort 1997 cohort 1998 cohort 1999 cohort 2000 cohort

206

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

Figure 4. (Color online) Percentage of Active Donors in Years Since Cohort Acquisition
40

35

30 25 % 20 15 10

1990 cohort 1991 cohort 1992 cohort 1993 cohort 1994 cohort 1995 cohort 1996 cohort 1997 cohort 1998 cohort 1999 cohort 2000 cohort

5

0

1

2

3

4

5

6

7

8

9

Years since cohort acquisition

Notes. Note that the 2000 cohort has only two repeat observations.

10

11

12

spans a duration in which the Telecommunications Act of 19963 was passed, which increased access to a larger number of television channels for consumers, thereby potentially affecting donation behavior to the public television broadcaster. In addition, prime time household ratings for public television (percentage of U.S. households viewing) fell from 2.3% in 1990 to 1.4% in 2006, a drop of 39%.4 It is, therefore, of particular interest to understand in what ways cohort behaviors may have changed, both from cohort to cohort as well as over the passage of calendar time for all cohorts.
4.2. Criteria for Assessing Model Convergence and Fit
We assess model convergence for the changepoint model using the nonparametric chi-squared test (Brooks et al. 2003) based on the counts of number of changepoints (K) and changepoint locations (Q) from two overdispersed MCMC chains. The null hypothesis is that both chains' counts come from the same underlying distribution, and a lack of evidence to reject the null is taken as the metric for showing convergence (i.e., p-value > 0.05).
We assess the convergence of cohort-level parameters (for all models) using the Gelman­Rubin test statistic (Gelman et al. 2004). The draws from two overdispersed chains are used to compute this statistic, and values less than 1.1 were used to reflect convergence.

As noted by Shirley et al. (2010), model selection criteria such as deviance information criterion (DIC) are well known to be problematic for complicated hierarchical models; therefore, we compare the performance of the eight models described in Table 1 using insample and out-of-sample MAPE. We compute MAPE by first drawing individual-level binary transaction patterns over time for each iteration. These are then aggregated to the cohort level to obtain the number of cohort transactions over time for a given iteration. MAPE is then calculated iteration by iteration for each cohort,5 and we report the average MAPE across iterations in accordance with prior literature (e.g., Netzer et al. 2008, Ascarza and Hardie 2013). For each cohort, we use in-sample MAPE as a "sanity check" for model fit but rely on holdout MAPE (for years 2003­2006) to gauge each model's predictive validity. In particular, we hold out the 2000 cohort from estimation and use years 2003­2006 to compare the forecasts arising from the VC models and benchmarks. Should there be evidence for changepoints, we expect the VC models to outperform the benchmarks in terms of increased accuracy for the held-out 2000 cohort.
In addition, we also conduct a "rolling time window" analysis, which is especially relevant for a multicohort data set. This analysis starts with the minimum number of cohorts and time observations to identify all models, and it holds out the next cohort at that point in time. For example, let us assume we have data until

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

207

year 1995. The 1992 cohort will have three repeat observations, which makes it the latest cohort that can be used in the model estimation (see Section 3.1 for why this is necessary for identification). We then compute MAPE using a four-period-ahead forecast for the 1993 cohort as a holdout cohort. The rolling time window arises from repeating this analysis by adding one more cohort and time period incrementally. This analysis allows the researcher to examine model performance under a limited number of cohorts and time observations and to study the effects of any data outliers on model performance. Given some of the data features in Figure 4, this analysis can help shed light on "what would happen" if the data set ended at 2001, instead of 2002, for example.
4.3. Results We obtain posterior inferences using 1,000 draws obtained from the MCMC procedure outlined in Online Appendix A by running each model for 400,000 iterations, treating the first 200,000 iterations as burn-in and thinning every 200 iterations to reduce autocorrelation in cohort parameter draws. The models' parameters converge per the tests outlined in Section 4.2.
4.3.1. Model Comparison (When 1990 Through 1999 Cohorts Are Included in the Data Set Until Time Period 2002, Holding Out the 2000 Cohort). In Table 3 we report the in-sample MAPEs for each cohort and model. The HB models generally fit better than the non-HB models in-sample since they allow for a more flexible cohort-level model. In other words, the B-PE

model allows cohorts to be different based on a parametric functional form while the HB models balance the cohort-level likelihood with the hierarchical prior. However, between the HB models, there is little difference in the model fit. All of these HB models seemingly provide sufficient flexibility in capturing in-sample data patterns for this data set. The B-VC model, as it does not allow for heterogeneity in cohort parameters within a regime, features higher in-sample MAPE than the HB models.
In Table 4 we compare out-of-sample MAPEs to understand how well each model generalizes for the 1990 through 1999 cohorts, and importantly for the held-out 2000 cohort whose prediction depends critically on the hierarchical assumptions of how cohorts "share" information under each model. We find that the B-PE model has a higher error for the 1998 and 1999 cohorts than HB-0. This arises from the parametric cross-cohort specification in B-PE while HB-0 is able to allow for more flexibility in the parameters for these cohorts. Interestingly, HB-CC and HB-0 have a similar performance as HB-CC finds little evidence for a changepoint (thus more or less collapsing to HB-0). As the specification of hierarchical priors (and hyperparameters) differs between these models, the results indicate convergent validity via robustness to the specifications. For the held-out 2000 cohort, however, B-PE, HB-0, and HB-CC all deliver high error. Under the B-PE, the 2000 cohort's parameters are obtained by extrapolating the flexible cross-cohort parametric form. Under HB-0/HB-CC, the hierarchical prior reflects a common distribution all cohorts are

Table 3. In-Sample MAPE by Cohort for Each Model

Model 1990 (%) 1991 (%) 1992 (%) 1993 (%) 1994 (%) 1995 (%) 1996 (%) 1997 (%) 1998 (%) 1999 (%)

B-PE

4.3

4.1

4.7

7.3

3.3

7.0

6.4

6.7

6.8

4.6

HB-0

4.5

3.3

4.2

3.5

3.8

4.7

5.6

5.6

6.3

4.4

HB-CC 4.5

3.4

4.2

3.4

3.8

4.7

5.7

5.5

6.4

4.4

B-VC

7.6

9.3

7.8

6.9

13.2 12.1

6.8

18.0 24.9 33.9

HB-VC 4.5

3.4

4.3

3.5

3.7

4.7

5.7

5.6

6.5

4.5

B-PET 4.5

4.5

4.8

7.3

3.4

7.0

6.4

6.5

6.6

4.4

B-VCT 7.4

3.6

4.9

5.4

4.3

7.7

6.3

5.4

6.6 14.9

HB-VCT 4.6

3.8

4.3

3.4

3.7

4.6

5.4

5.5

6.5

4.4

Table 4. Out-of-Sample MAPE by Cohort for the 2003­2006 Time Period for Each Model

Model 1990 (%) 1991 (%) 1992 (%) 1993 (%) 1994 (%) 1995 (%) 1996 (%) 1997 (%) 1998 (%) 1999 (%) 2000 (heldout) (%)

B-PE

7.0

11.0

9.8

5.1

10.4

14.5

9.8

10.2

23.5

21.2

39.8

HB-0

9.2

9.5

7.5

6.8

10.4

11.6

8.7

12.2

19.1

15.4

38.1

HB-CC

9.2

9.5

7.6

6.8

10.5

11.5

9.1

11.9

18.1

14.5

39.2

B-VC

11.6

15.6

10.4

9.9

20.5

15.9

6.8

16.7

15.0

22.5

25.4

HB-VC

8.7

9.1

7.6

7.0

10.6

12.2

9.0

12.7

19.7

15.4

22.6

B-PET

11.0

14.4

11.5

4.6

11.4

15.6

10.4

10.5

23.3

20.5

39.2

B-VCT

8.5

17.3

15.6

5.4

12.8

13.7

17.7

11.7

17.0

7.1

17.2

HB-VCT

9.3

9.3

8.2

7.3

10.2

12.4

8.8

11.3

16.5

12.9

15.2

Notes. The 2000 cohort is shaded to denote that its data are entirely held out from model estimation.

208

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

assumed to be drawn from. Both assumptions lead to poor predictions for the 2000 cohort.
The HB-VC model improves on the prediction of the 2000 cohort (MAPE of 22.6% versus 38% to 40% for the B-PE, HB-0, and HB-CC models), as it finds evidence for a changepoint at the 1996 cohort, thus changing the hierarchical prior that the 2000 cohort is assumed to be drawn from. In other words, this model suggests that cohorts acquired in 1996 and later are behaviorally different from pre-1996 cohorts, and thus the 2000 cohort is better estimated by reducing the influence of those older cohorts on its hierarchical prior. It should not be surprising, however, that the 1990 through 1999 cohorts' predictions are similar in error magnitude to the HB-0 model, since cohortlevel parameter estimates are much more influenced by the likelihood function for these cohorts (due to increased number of time points) than the hierarchical prior. The B-VC model also improves predictive performance for the 2000 cohort but performs worse than HB-VC for most in-sample cohorts due to its lack of within-regime heterogeneity. The inclusion of a calendar-time effect (HB-VCT) improves performance for the newer cohorts (1997 through 2000) relative to HB-VC. HB-VCT combines the benefits of regime changes across cohorts and time effects and is the "winning model" based on the 2000 cohort performance. The B-VCT model in which cohort parameters are constant within a regime (as opposed to drawn from a hierarchical prior like HB-VCT) is the "next best" model in terms of the 2000 cohort's performance. However, its poorer performance for several of the other relatively new cohorts is again due to its lack of cohort-level flexibility. B-PET does not improve performance substantially over B-PE as both model cross-cohort patterns for attrition and transaction mean propensities only, and therefore misses potential changes in other CPN/PN parameters.
Overall, the HB-VCT model provides the most general description of cohorts of customers over time, and the results demonstrate its efficacy, particularly for the

newer cohorts in a sequence. If the analyst is focused only on holdout cohort performance and wishes to run a non-HB model, the B-VCT model offers a reasonable alternative to the HB-VCT. As a robustness check, we estimated the HB-VCT model holding out both 1999 and 2000 cohorts (while using data up to year 2002 for the 1990 through 1998 cohorts) and obtain out-of-sample MAPEs of 19.0% and 12.9% for the 1999 and 2000 cohorts, while the MAPEs of other cohorts remain virtually unchanged. Across the suite of models, HB-VCT and B-VCT remain as the best performing models for both held-out cohorts. Given that data from the 1999 and 2000 cohorts are completely held out from model estimation, these prediction errors suggest the robustness of the changepoint model structure uncovered from the cohort sequence. We examine the estimates from the HB-VCT model in Section 4.3.3.
4.3.2. Rolling Time Window Analysis. As discussed in Section 4.2, it is helpful to study HB-VCT model performance under a subset of the full data set used in Section 4.3.1--which we term rolling time window analysis. We start by assuming we have data until year 1995 and include the 1990 through 1992 cohorts for model estimation. We then add one more year of data and one more cohort until we reach the full data set (which simply returns us to the analysis in Section 4.3.1). In Table 5 we present the out-of-sample MAPEs (always over a four-year predictive horizon) for each cohort (including the held-out one).
The bottom row of Table 5 describes the results including the first three cohorts and forecasting the fourth cohort. We find that forecasts are reasonable considering the limited amount of data used both in the number of cohorts and time observations. The forecasts continue to be reasonable (and slightly improve) with the addition of successive time observations and cohorts until the 1998 and 1999 time points when the held out cohort's forecast gets worse. This finding is consistent with a changepoint that causes postchangepoint cohorts to be different from previous ones.

Table 5. HB-VCT Four-Period-Ahead Out-of-Sample MAPE Using a Rolling Validation Time Window

Last time

Last cohort

Holdout

Out-of-sample MAPE by cohort (%)

period

used

periods

90

91

92

93

94

95

96

97

98

99

00

2002 2001 2000 1999 1998 1997 1996 1995

1999 1998 1997 1996 1995 1994 1993 1992

2003­2006

9.3

9.3

8.2

7.3 10.2 12.4

8.8 11.3 16.5 12.9 15.2

2002­2005 33.6 34.7 35.0 34.9 32.5 35.6 37.3 39.5 42.3 31.1

2001­2004 17.8 18.8 16.6 19.1 17.7 22.0 23.8 24.4 26.2

2000­2003 10.3 10.2 10.4 10.3

8.9 10.6 12.2 24.7

1999­2002 12.6 12.3 13.9 16.8 15.4 13.4 21.8

1998­2001 13.6 11.2 11.6 12.1 13.6 22.3

1997­2001 13.2 14.1 17.4 18.2 22.5

1996­1999 13.2 12.8 13.1 22.6

Notes. Grayed cells in each row refer to the held-out cohort. All other cohorts in the row were used for model estimation. Note that the results for the last time period (2002) corresponds exactly to the HB-VCT results in Table 4 and is replicated for ease of comparison.

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

209

At the 1998 and 1999 time points, there is insufficient statistical evidence for a regime change; therefore, the model considers all cohorts to be in the same regime (i.e., probability of a changepoint is practically zero)--which is statistically the appropriate inference (as discussed in Section 3.2)--but therefore does not accurately capture the future evolution of the heldout cohort.
When the 2001 time point is the last observation used, the probability of a changepoint at the 1996 cohort does increase. However, the MAPEs for all cohorts are substantially worse than other windows. The reason for this surprising uptick in MAPE is related to the data features discussed in Section 4.1 as relating to Figure 4. With several cohorts exhibiting an uptick in the number of transactions after 2001, the model estimated on data up to 2001 underforecasts future transactions since latent attrition models do not allow for "dead" customers to return--and are especially sensitive to the last period of transactions for inferring customer "death." Our initial analysis (which used data until the 2001 point) yielded this pattern of MAPEs, which enabled us to find this data outlier by adding the 2002 time point to the cohorts (which is the full data set used in Section 4.3.1). As can be seen from the first row of Table 5 (which is identical to the HB-VCT row of Table 4), MAPEs are significantly improved for all cohorts, while a high probability of a changepoint is inferred at the 1996 cohort (as we detail in Section 4.3.3).
The main lesson to draw from this analysis is that the rolling time window approach can be useful in multicohort data sets to parse out any unusual data patterns that may preclude accurate forecasts, especially those that occur at the end of a time series.
4.3.3. Model Estimates. The HB-VCT model estimates a 73% probability of at least one changepoint for the correlation between attrition and transaction propensities, with the modal location being the 1996 cohort (see Figure 5). The pre-1996 cohorts have a negative correlation (regime prior mean of -0.20) between attrition and transaction propensities, meaning that a customer in these cohorts who has a low probability of "death" also has a high probability of transacting while "alive." Conversely, this also indicates the double whammy of attrition-prone customers who are also less likely to transact. The post-changepoint cohorts essentially have a negligible correlation (regime prior mean of 0.01) between the attrition and transaction propensities and contain relatively "less polarized" customers within the cohort. The other parameters do not exhibit strong evidence for a changepoint in the cohort sequence. Figure 5(c) shows the prior and posterior means for each cohort parameter. The prior mean (dotted line) for

Figure 5. (Color online) HB-VCT Model Estimates: (a) There Is a 73% Probability of a Changepoint in the AttritionTransaction Correlation Parameter (with Most of This Mass at K 1 Changepoint); (b) The Most Probable Location of This Changepoint Is the 1996 Cohort; (c) The HB-VCT Prior Mean for Each Cohort Is Shown with Dotted Lines to Demonstrate the Mutual Consistency of K and Q with Priors
(a)

Posterior prob of K changepoints

0.8

0.4
0 0

2

4

6

8

Num changepoints (K )

(b)

Posterior prob of changepoint at q

0.4
0.2
0 1990

1992

1994

1996

Changepoint location (q )

1998

Mu-attr Mu-trans

Var-attr Var-trans

Corr(attr, trans)

(c) HB-VCT model

2

Cohort parameter

1

0

­1

1990

1992

1994

1996

Cohort

1998

Notes. The posterior cohort parameters are also shown in Figure 5(c) (solid lines).

the correlation between the attrition and transaction propensities, consistent with the estimated changepoint, shows a shift at the 1996 cohort. The posterior mean for each cohort parameter incorporates information from the cohort-level likelihood function and can therefore deviate from the prior mean due to cohort heterogeneity.

210

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

We find that demographic covariate effects are directionally intuitive for the most part (see Table 6). Attrition propensity decreases with income--indicating that wealthier households are less likely to end their relationship with the organization. Transaction propensity decreases with household size and increases with income--indicating that smaller and wealthier households are also more likely to donate. Attrition propensity increases with distance (which is directionally intuitive) as does transaction propensity (which is slightly counterintuitive but may be indicative of a nonlinear relationship). Importantly, the effect sizes for these demographic covariates are small, such that the other model parameters (and posterior predictive distributions) would be practically unchanged by their exclusion.
From Table 6 we find that the calendar-time effects are statistically significant for both the attrition and transaction propensities. In Figure 6, we show the net trend implied over time for each parameter. The attrition propensity trend increases with time and has a larger effect size than the transaction propensity trend, which exhibits less variation over time. The calendartime effects suggest that customers from any cohort (old or new) are more likely to experience attrition over time above and beyond that predicted by the CPN/PN model.
Our empirical findings suggest two different types of effects observed in the data. First, the 1996 changepoint in the correlation between attrition and transaction propensities points to a change in the mix of donors obtained from 1996 onwards. In older cohorts, donors on average seem more "polarized"--they are more likely to be long lifetime and frequent donors (both positively affecting customer lifetime value) or short lifetime infrequent donors. In newer cohorts, there is less evidence for such donors, with attrition and transaction behaviors largely uncorrelated. Second, attrition propensity increases over time for all cohorts. These findings highlight that changes in the

Table 6. HB-VCT Model Slope Parameter Estimates

Parameter
Attrition: Linear time Attrition: Quadratic time Attrition: Log time Trans: Linear time Trans: Quadratic time Trans: Log time Attrition: ln(distance + 1) Attrition: HH size Attrition: ln(HHIncome + 1) Trans: ln(distance + 1) Trans: HH size Trans: ln(HHIncome + 1)

Posterior mean (standard error)

-0.34 0.03 4.71
-1.58 0.07 4.45 0.09 0.01
-0.22 0.06
-0.04 0.18

(0.71) (0.03) (2.06) (0.27) (0.01) (0.69) (0.01) (0.01) (0.02) (0.01) (0.01) (0.02)

Figure 6. (Color online) Estimated Calendar-Time Trends from the HB-VCT Model

Calendar-time effect

2.0 1.5 1.0 0.5
0 1990

Calendar-time trend for attrition propensity

1995

2000

Calendar time

2005

Calendar-time effect

Calendar-time trend for transaction propensity

0.6 0.4 0.2
0 1990

1995

2000

Calendar time

2005

regulatory landscape (1996 Telecommunications Act) and substitution from public television programming to specialized cable channels likely had an effect on the mix of acquired donors and the declining likelihood of being "alive" as donors over calendar time. An interesting area for future research is to study the mechanisms by which viewership of public television programs affect donation behaviors.
In summary, the suite of models we used to fit the multicohort donor data has yielded the HB-VCT as offering the best out-of-sample performance for the 2000 cohort, as well as most other newer cohorts. As the HB-VCT is the most general model in our lineup, this suggests that having the flexibility to separate crosscohort regime changes by parameter while accounting for calendar-time effects offers promise as a method for future multicohort analyses.

5. Discussion and Future Work
5.1. Discussion The comparison of the vector changepoint models with the benchmarks shows that utilizing our approach yields new insights about the regime structure across cohorts that were not previously accessible. In addition, the regime structure plays a significant role in enhancing the predictive accuracy of the new 2000 cohort's behavior in holdout data, and our model helps tease apart data patterns driven by a cross-cohort changepoint versus a common calendar-time effect. Our findings suggest that simply using older cohorts as a proxy for predicting new cohorts without understanding any potential regime changes may lead to inaccurate predictions.
Returning to the managerial questions posed at the beginning of this paper, Bob, the data analyst, is now

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

211

able to draw parallels from the nonprofit data set to his own context. Using the vector changepoint models, he is able to determine which cohorts would be relevant peers for the new cohorts that Anita, the sales manager, is interested in. He realizes that pooling data from all cohorts would likely decrease the accuracy of his predictions as older cohorts may be part of a different regime as compared to the newest cohorts. Thus, decision making based on heuristics of what is relevant can be augmented with data-driven evidence of regime change. Furthermore, Bob is able to use the VC models to yield robust predictions of cohorts' future behaviors and tease apart calendar time effects as well.
Anita has also learned that she can examine the parameters that have shifted at changepoint locations to better understand the intuition of what cohort-level behavior is responsible for the shift. She may be able to confirm Colleen's intuition by analyzing what aspect of newer cohorts may have undergone a significant shift since the new competitor's entry, which she was previously unable to quantify. The bulk of the holdout transactions (2003­2006) for each cohort are contributed by donors with high in-sample recency. While this validates the attrition process inherent in a BTYD model, there may not be much Anita can do to bring back the customers who have already ended their relationship with the firm. Instead, she should focus her retention efforts on customers in newer cohorts, who may still be persuaded to remain active for a longer period of time through judicious use of targeted marketing communications and inducements (e.g., Khan et al. 2009). In addition, the acquisition strategy for new cohorts may need updating--if existing strategies are ineffective in bringing in the desired portfolio of customers (e.g., Lewis 2006), new acquisition channels (e.g., mobile advertising) and incentives such as referral programs (e.g., Schmitt et al. 2011) may be needed to attract better prospects.
Forecasts based on older cohorts' behavior, in the case of the nonprofit data set, would lead management to forecast less accurate donation figures as well. Management of startup companies whose valuations rely on customer acquisition may portray a distorted view of future growth if they project new cohorts to behave like the "average" of all previous cohorts. This can have ramifications for allocating marketing budgets and in reporting projections to stakeholders. Supposing that Anita's firm (from our example) uses projected transactions to provide guidance to investors, large inaccuracies can hurt credibility and valuation in the long run.
Furthermore, managers may discover signs of saturation in the market they are targeting, perhaps due to "over-fishing;" successive new cohorts may be less attractive than older ones in which the better prospects may already be captured. Such cross-cohort shifts can be easily missed when conducting analysis at the

aggregate level, such as tracking overall revenue across the entire customer base, and our approach is a means to avoiding aggregation bias in multicohort settings.
For researchers, these findings suggest that investigating cross-cohort patterns can be a powerful tool when dealing with a data set that has a multicohort structure. The vector changepoint models allow for more flexible and robust cross-cohort patterns than a model with parametric effects, can provide greater power to uncover parameter-specific regime changes than the classical changepoint model, and adds a low computational burden as compared to a no-changepoint hierarchical Bayesian model. Our findings suggest that our most general vector changepoint model with a hierarchical Bayesian structure can be a good starting point for multicohort data sets given its ability to tease apart cross-cohort regime changes, cohort heterogeneity, and global calendar-time effects. In addition, the "family tree" of simpler models that can be obtained by turning off features of our most general model is also available for researchers looking only for a subset of modeling features. For example, a researcher who has strong reasons to believe there are no cross-cohort effects, could use the nochangepoint hierarchical Bayesian model and also allow for calendar-time effects, which is a model that was not in our set of benchmarks but nevertheless may be useful in other research settings.
Our robustness checks reveal a cautionary note in using the most general changepoint model we propose along with calendar-time effects. In the presence of data outliers at the last observed time period, we show in our data setting that the model can lead to higher prediction errors than may be expected. It is difficult to provide general guidance on detection of such data outliers as much of the issue can be dependent on what the cohort-level behavior being modeled is. However, we recommend the rolling time window analysis as one method to detect if any given time end point leads to abnormally high prediction errors (relative to cutting off the data at other time points). This is not entirely different (conceptually) than the results of Van den Bulte and Lilien (1997), who show that the Bass model is highly sensitive to the observed diffusion in the last (few) data points of a time series.
More broadly, our approach provides a general framework for the model selection problem, which frequently arises in marketing. Instead of running thousands of possible models to determine the "best fitting one," our approach leverages Bayesian methods to deliver inferences that incorporate uncertainty in the model in a single framework. Other contexts in which there exist multiple models with varying number of parameters that could describe the data, could benefit from the broad steps we have presented in defining an R-J MCMC algorithm that can traverse the model space

212

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

efficiently and avoid the Davies problem (Davies 1987, Hansen 1996) that arises in classical hypothesis testing.
5.2. Future Work We discuss fruitful directions in which this work can be enhanced. First, it is possible that cohorts are not necessarily related to each other in contiguous temporal blocks. Returning to the idea of a more general model of relationships among cohorts (e.g., Hui and Bradlow 2012), the model could allow for cohorts exhibiting similar behaviors to be grouped together, akin to a latent class model, even if this breaks the temporal sequencing. This may be interesting if new cohorts follow a cyclical pattern of resembling earlier cohorts (perhaps due to economic cycles), or if the segmentation is not based on a period of acquisition. A more general segmentation of customers may not have a cohort sequence structure, but there can still be underlying patterns that can be uncovered. Extending the vector changepoint framework to Bayesian clustering methods (François et al. 2006, Green and Richardson 2002) while addressing the explosive increase in the number of possible groupings would enable such data structures to be appropriately modeled.
Second, the power of this modeling approach can be further exploited by richer models of customer behavior, which can allow for a range of behaviors such as timing, choice, and monetary amounts. A hybrid of the vector and classical changepoint models can then be used to appropriately partition the priors on the full parameter space. We suggest that further work in exploring alternative specifications lying in the spectrum between vector and classical changepoint models can help uncover when each type of model is best suited for analysis.
Third, a limitation of our modeling approach is the assumption that a changepoint at a given cohort does not affect the behavioral parameters of preceding ones. That is, while we explored changepoints across acquired cohorts, there may well be changepoints that occur in time that also differ across cohorts. This is an avenue for further research by integrating cross-cohort and time-changepoints into a single model.
Fourth, marketing covariates could be incorporated at the individual level, if available, to better understand the effect of targeted marketing on attrition and transaction behaviors. In particular, our model presents statistical evidence for regime changes that can enable this nonprofit organization to optimize their cohort-management strategies. An interesting area for future research would be to introduce time-varying marketing covariates (our model is general enough to accommodate these, but the data do not contain them) to help organizations understand the effectiveness of their implemented cohort-management strategies.

Cohort-specific slopes capturing response propensity can be added to the parameter space of the vector changepoint model to further generalize the model. Given that these marketing variables may be endogenously set with the customers' expected responses in mind, an appropriate model of firm-side decision making (e.g., Schweidel and Knox 2013) would need to be integrated with the vector changepoint model.
Fifth, it is possible that cross-cohort changepoints may occur at future cohorts not currently in the data set. Our model estimates changepoints based on patterns in cohorts included for estimation. Future work can investigate predicting the timing of future changepoints by incorporating an additional hierarchical layer above the changepoint model.
Sixth, a study of the mechanisms by which consumers of public television broadcasters across the United States may have changed as a function of the shifting television programming landscape is a substantive topic for exploration. As some of these changes are likely exogenous from the viewpoint of donation and viewership behavior (1996 Telecommunications Act), and there may be regression discontinuities in the rates of change of local television markets (see Hartmann et al. 2011), there is a potential for causal inferences to be drawn about changes in consumer behavior.
The perils of pooling data without accounting for cross-cohort shifts have been highlighted in this work. We hope our findings encourage further research in uncovering new structural patterns in customer databases that help managers make the most effective use of their data.
Acknowledgments The authors thank Yupeng Chen, Elea Feit, Bruce Hardie, Shane Jensen, Raghu Iyengar, Eric Schwartz, and Katie Yang for their feedback and suggestions, Hugh MacMullan and Paul Amos for computing and data support, as well as the nonprofit organization that generously allowed the authors to use its data. The authors thank seminar participants at the 2012 Marketing Science conference and 2012 Joint Statistical Meetings conference for their helpful comments.
Endnotes
1 The product-partition approach outlined by Barry and Hartigan (1993) is popular due to the simplicity of using data augmentation (Tanner and Wong 1987) for the presence or absence of changepoints in a sequence. However, priors are specified in a nonintuitive form of "prior cohesions," and there is limited flexibility in traversing the model space. 2 The B-VC model requires a more restrictive prior to avoid the boundary condition of fitting each cohort in its own regime (since parameters are constant within a regime). Hence, we use a prior that provides an upper bound on the number of changepoints and a lower bound on regime length, as discussed in Online Appendix B. The HB-VC fits each cohort with its own unique parameter vector (by design) and does not require these binding constraints. 3 https://www.fcc.gov/general/telecommunications-act-1996.

Gopalakrishnan, Bradlow, and Fader: A Cross-Cohort Changepoint Model Marketing Science, 2017, vol. 36, no. 2, pp. 195­213, © 2016 INFORMS

213

4 http://tvbythenumbers.zap2it.com/business/where-did-the-prime time-broadcast-tv-audience-go/.
5 For a given MCMC iteration and cohort c, the MAPE is the average percentage error between the aggregated actual and predicted time series.
References
Abe M (2009) "Counting your customers" one by one: A hierarchical Bayes extension to the Pareto/NBD model. Marketing Sci. 28(3):541­553.
Allenby GM, Leone RP, Jen L (1999) A dynamic model of purchase timing with application to direct marketing. J. Amer. Statist. Assoc. 94(446):365­374.
Ansari A, Iyengar R (2006) Semiparametric Thurstonian models for recurrent choices: A Bayesian analysis. Psychometrika 71(4): 631­657.
Ascarza E, Hardie BG (2013) A joint model of usage and churn in contractual settings. Marketing Sci. 32(4):570­590.
Bai J (1997) Estimation of a change point in multiple regression models. Rev. Econom. Statist. 79(4):551­563.
Barnard J, McCulloch R, Meng X-L (2000) Modeling covariance matrices in terms of standard deviations and correlations, with application to shrinkage. Statist. Sinica 10(4):1281­1311.
Barry D, Hartigan JA (1993) A Bayesian analysis for change point problems. J. Amer. Statist. Assoc. 88(421):309­319.
Bhattacharya PK (1987) Maximum likelihood estimation of a change-point in the distribution of independent random variables: General multiparameter case. J. Multivariate Anal. 23(2): 183­208.
Box G (1988) Signal-to-noise ratios, performance criteria, and transformations. Technometrics 30(1):1­17.
Brooks SP, Giudici P, Philippe A (2003) Nonparametric convergence assessment for MCMC model selection. J. Comput. Graphical Statist. 12(1):1­22.
Carlin BP, Chib S (1995) Bayesian model choice via Markov chain Monte Carlo methods. J. Roy. Statist. Soc. B 57(3):473­484.
Davies RB (1987) Hypothesis testing when a nuisance parameter is present only under the alternative. Biometrika 74(1):33­43.
Ebbes P, Liechty JC, Grewal R (2015) Attribute-level heterogeneity. Management Sci. 61(4):885­897.
Fader PS, Hardie BGS, Huang C-Y (2004) A dynamic changepoint model for new product sales forecasting. Marketing Sci. 23(1):50­65.
Fader PS, Hardie BGS, Lee KL (2005) "Counting your customers" the easy way: An alternative to the Pareto/NBD model. Marketing Sci. 24(2):275­284.
Fader PS, Hardie BGS, Shang J (2010) Customer-base analysis in a discrete-time noncontractual setting. Marketing Sci. 29(6): 1086­1108.
François O, Ancelet S, Guillot G (2006) Bayesian clustering using hidden Markov random fields in spatial population genetics. Genetics 174(2):805­816.
Gelman A (2006) Prior distributions for variance parameters in hierarchical models. Bayesian Anal. 1(3):515­533.
Gelman A, Carlin JB, Stern HS, Rubin DB (2004) Bayesian Data Analysis, 2nd ed. (Chapman and Hall, Boca Raton, FL).
Green PJ (1995) Reversible jump Markov chain Monte Carlo computation and Bayesian model determination. Biometrika 82(4): 711­732.
Green PJ, Richardson S (2002) Hidden Markov models and disease mapping. J. Amer. Statist. Assoc. 97(460):1055­1070.
Hansen BE (1996) Inference when a nuisance parameter is not identified under the null hypothesis. Econometrica 64(2):413­430.

Hartmann W, Nair HS, Narayanan S (2011) Identifying causal marketing mix effects using a regression discontinuity design. Marketing Sci. 30(6):1079­1097.
Hofstede FT, Wedel M, Steenkamp J-BE (2002) Identifying spatial segments in international markets. Marketing Sci. 21(2):160­177.
Hui SK, Bradlow ET (2012) Bayesian multi-resolution spatial analysis with applications to marketing. Quant. Marketing Econom. 10(4):419­452.
Jain D, Singh SS (2002) Customer lifetime value research in marketing: A review and future directions. J. Interactive Marketing 16(2):34­46.
Khan R, Lewis M, Singh V (2009) Dynamic customer management and the value of one-to-one marketing. Marketing Sci. 28(6):1063­1079.
Kim JG, Menzefricke U, Feinberg FM (2007) Capturing flexible heterogeneous utility curves: A Bayesian spline approach. Management Sci. 53(2):340­354.
Lewis M (2006) Customer acquisition promotions and customer asset value. J. Marketing Res. 43(2):195­203.
Narayanan S (2013) Bayesian estimation of discrete games of complete information. Quant. Marketing Econom. 11(1):39­81.
Netzer O, Lattin JM, Srinivasan V (2008) A hidden Markov model of customer relationship dynamics. Marketing Sci. 27(2):185­204.
Park T, van Dyk DA (2009) Partially collapsed Gibbs samplers: Illustrations and applications. J. Comput. Graphical Statist. 18(2): 283­305.
Pelli DG, Farell B (1999) Why use noise? J. Optical Soc. Amer. 16(3): 647­653.
Rentz JO, Reynolds FD (1991) Forecasting the effects of an aging population on product consumption: An age-period-cohort framework. J. Marketing Res. 28(3):355­360.
Richardson S, Green PJ (1997) On Bayesian analysis of mixtures with an unknown number of components. J. Roy. Statist. Soc. B 59(4):731­792.
Schmitt P, Skiera B, Van den Bulte C (2011) Referral programs and customer value. J. Marketing 75(1):46­59.
Schmittlein DC, Morrison DG, Colombo R (1987) Counting your customers: Who are they and what will they do next? Management Sci. 33(1):1­24.
Schwartz EM, Bradlow ET, Fader PS (2014) Model selection using database characteristics: Developing a classification tree for longitudinal incidence data. Marketing Sci. 33(2):188­205.
Schweidel DA, Knox G (2013) Incorporating direct marketing activity into latent attrition models. Marketing Sci. 32(3):471­487.
Schweidel DA, Fader PS, Bradlow ET (2008) Understanding service retention within and across cohorts using limited information. J. Marketing 72(1):82­94.
Shirley KE, Small DS, Lynch KG, Maisto SA, Oslin DW (2010) Hidden Markov models for alcoholism treatment trial data. Ann. Appl. Statist. 4(1):366­395.
Singh SS, Borle S, Jain DC (2009) A generalized framework for estimating customer lifetime value when customer lifetimes are not observed. Quant. Marketing Econom. 7(2):181­205.
Tanner MA, Wong WH (1987) The calculation of posterior distributions by data augmentation. J. Amer. Statist. Assoc. 82(398): 528­540.
Van den Bulte C, Lilien GL (1997) Bias and systematic change in the parameter estimates of macro-level diffusion models. Marketing Sci. 16(4):338­353.
Vuong QH (1989) Likelihood ratio tests for model selection and non-nested hypotheses. Econometrica 57(2):307­333.
Winkelmann R (2004) Health care reform and the number of doctor visits--An econometric analysis. J. Appl. Econometrics 19(4): 455­472.
Yang S, Allenby GM (2003) Modeling interdependent consumer preferences. J. Marketing Res. 40(3):282­294.

