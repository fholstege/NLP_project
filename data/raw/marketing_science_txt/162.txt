http://pubsonline.informs.org/journal/mksc/

MARKETING SCIENCE
Vol. 37, No. 3, May­June 2018, pp. 425­444 ISSN 0732-2399 (print), ISSN 1526-548X (online)

Learning from Online Social Ties

Yuchi Zhang,a David Godesb
a Leavey School of Business, Santa Clara University, Santa Clara, California 95053; b Robert H. Smith School of Business, University of Maryland, College Park, Maryland 20742 Contact: yzhang6@scu.edu, http://orcid.org/0000-0002-5419-8679 (YZ); dgodes@rhsmith.umd.edu (DG)

Received: June 5, 2013 Revised: October 8, 2014; October 7, 2016; July 22, 2017 Accepted: August 16, 2017 Published Online in Articles in Advance: April 30, 2018
https://doi.org/10.1287/mksc.2017.1076
Copyright: © 2018 INFORMS

Abstract. We ask whether online opinions impact consumers' decision quality and assess whether this impact occurs immediately or requires one to undergo learning first. We focus on a setting where consumers have multiple learning experiences using opinions from both uni- and bidirectional network ties. This allows us to investigate the impact of learning from both weak and strong ties. We find that, with sufficient experience, having more ties may lead to better decisions. However, the dynamic effects are dependent on the strength of the tie. Additional strong ties (operationalized as bidirectional links) lead to immediate positive effects on decision quality. However, additional weak ties (unidirectional, follower relationships) initially lead to lower decision quality. We find beneficial learning effects, however: adding more weak ties improves decision quality once one has sufficient experience in the community. Indeed, more-experienced consumers receive, ultimately, higher positive effects on decision quality from weak ties compared with strong ties. We interpret this as demonstrating that one needs to learn the norms of a new community before using the available information to improve decisions.

History: Preyas Desai served as the editor-in-chief and Fred Feinberg served as associate editor for this article.
Supplemental Material: Data and the online appendix are available at https://doi.org/10.1287/ mksc.2017.1076.
Keywords: word of mouth · social media · social networks · learning

1. Introduction
Consumers commonly read about others' purchase experiences and make decisions based on this information. This is especially prevalent on online platforms such as Amazon.com, Rottentomatoes.com, and Tripadvisor.com, where different opinions are accessible by a wide audience. Because of, in part, the importance of online opinions to consumers' decisionmaking processes, researchers have studied a great deal the impact of online opinions and have demonstrated that these opinions play a significant role in purchase decisions across a range of markets and settings (e.g., Chevalier and Mayzlin 2006, Du and Kamakura 2011, Chen et al. 2011, Moe and Trusov 2011, Shriver et al. 2013). While it is relatively clear that online opinions often influence consumers' purchase decisions, we have limited knowledge as to the outcomes of these decisions. Specifically, there has been no inquiry into the extent to which access to these opinions helps improve future decisions. From a rational perspective, we would expect that, on average, decisions should improve when facilitated by online opinions. This may be especially true for information from weak ties, as the previous literature (e.g., Granovetter 1973) suggests that these opinions may be more novel and beneficial. However, it is not obvious that all opinions will be equally helpful. In particular, we consider

the extent to which one needs to learn, in the form of decision-making experiences, before others' opinions become useful.
We expect that learning how to make use of online opinions may be critical because using another poster's opinions to infer one's own expected satisfaction with a product might be difficult. A consumer initially may be uncertain as to whether other users' opinions are consistent with their own preferences, because of, for example, limited previous interactions with the poster, knowledge of her preference structure, or experience in the purchase domain. We refer to the reader's ability to infer a mapping from the expressed opinions (e.g., online ratings) to her own preference structure as the "interpretability" of the opinions. All else equal, greater interpretability should help improve decisions. We expect that new community members will have a particularly difficult time mapping others' opinions to their preferences. As they develop experience in the community, however, they should learn to make better use of the information, learning how to interpret other's opinions.
In addition to interpretability, we also investigate the role of the opinion source--whether the opinions arrive from strong or weak ties--on decision quality. Researchers have defined strong ties as those characterized by higher frequency of interaction, greater trust,

425

426

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

and more familiarity (Granovetter 1973, Lin et al. 1981, Brown and Reingen 1987, Krackhardt 1992) as compared with weak ties. While the literature suggests that one may learn more from the latter, we expect the initial interpretability of information to be higher from the former: it should be easier ceteris paribus to assess the match between one's preferences and those of strong ties as compared with weak ties. However, opinions from weak ties may be particularly valuable because of the novel information they make available (Granovetter 1973), conditional on undergoing learning experiences that lead to improvements in interpretability.
To study the impact of social information on decision quality, we investigate the actions taken by a set of consumers from the time they join an online community. We explore this dynamic learning process by exploiting the unique characteristics of the online review platform Goodreads.com. Unlike the majority of online review websites such as Amazon.com, Goodreads provides not only ratings but also an organic social network that allows for interaction among users. We follow the actions of new users as they establish a network on the platform and learn how to make use of the information that network makes available. Goodreads members can form either bidirectional "friend" relationships or unidirectional "source" relationships. We assume that the former reflects more frequent interaction and a closer relationship, since both individuals observe each other's opinions. By contrast, the unidirectional relationships suggest more limited interactions, since one sees the opinions of one's sources but not vice versa. To capture the quantity of information available, we measure the evolving size of one's network over time. In this way, we assess the marginal impact on decision quality of accessing social information from a network.
After controlling for the ratings environment, individual-level factors such as scale usage, book-level dynamics, self-presentation effects, and, importantly, sources of potential endogeneity, we find that consumers initially experience higher decision quality-- that is, post higher ratings--the more bidirectional ties they have previously formed. We interpret this as suggesting that opinions drawn from a larger set of strong ties lead to better decisions. In comparison, this is not always true of weak ties. As consumers develop more unidirectional (weak) ties, their decision quality initially declines. However, as one develops more experience in the community, information from weak ties, in fact, improves decision quality. Indeed, the improvement effected by information from weak ties, for sufficiently experienced users, eventually outstrips that for strong ties. These results suggest that when one lacks experience using socially acquired information, friends

may initially be the better source of information. However, conditional on learning how to use information from social ties, information from weak ties may eventually be more useful than that from strong ties.
This paper offers several important contributions to the literature. To our knowledge, we are the first to explicitly address the impact on decision quality of the acquisition of information via the development of online ties. Moreover, learning how to use opinions from social ties in an online environment to improve decision quality has not been addressed in the literature. We also demonstrate that there is a significant and important difference between the value of information one accesses through deeper, stronger two-way relationships as compared with weaker one-way relationships. The extant literature on online reviews has implicitly treated all ties as equal, while it is clear from our results that this may not always be correct. Finally, our results suggest a dynamic process whereby consumers not only make better decisions as they forge more relationships but also learn to make increasingly better decisions as their community-specific expertise develops. In this sense, our results suggest that relationships, while beneficial, are not equally valuable to all. Those who invest in developing the expertise to use the information that their ties make available will benefit most from them.
This paper proceeds as follows. In Section 2, we review how our work fits into the relevant literature. In Section 3, we develop in more detail the theory behind our empirical inquiry. We describe the data set in Section 4. In Section 5, we develop our model and discuss the estimation approach. Sections 6 and 7 report the results, and Section 8 concludes.
2. Related Literature
Our paper relates to two streams in the existing literature: online opinions and learning. A variety of studies have shown that online opinions influence purchase decisions. Most existing research on online reviews may be categorized into one of two groups: works that study the impact of online opinions, on one hand, or the product-level dynamics of posted ratings, on the other. With respect to the former, there exists strong empirical evidence linking aggregate measures of online opinions (i.e., the valence, variance, dispersion, or volume) with choices for books (Chevalier and Mayzlin 2006, Li and Hitt 2008), movies (Liu 2006, Dellarocas et al. 2007, Duan et al. 2008, Chintagunta et al. 2010), beer (Clemons et al. 2006), cameras (Chen et al. 2011), and bath and beauty products (Moe and Trusov 2011). While these studies suggest that online opinions have a significant impact on choices, they provide no evidence with respect to their impact on the quality of these choices, which is the focus of the current study.

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

427

Researchers have also analyzed the impact of product-level dynamics in the time series of ratings (Li and Hitt 2008, Wu and Huberman 2008, Godes and Silva 2012, Moe and Schweidel 2012). Notably, there appears to be a robust downward dynamic pattern in ratings. While Li and Hitt (2008) argue that the root cause of the pattern is self-selection, Wu and Huberman (2008) suggest that it is driven by posters who post only when the review will have a sufficient impact. Godes and Silva (2012) decompose the effect into temporal and sequential dimensions and suggest that the latter is due to purchase errors increasing as more reviews arrive. Notably, their theory is tested based on the assumption that ratings are a proxy for decision quality. Though our model is a dynamic one, the nature of the dynamics we investigate is quite distinct from the existing literature. Specifically, these papers all study product-level dynamics; that is, they attempt to explain why, for a given item, ratings appear to exhibit a downward trend. On the contrary, we focus on individual-level dynamics: how does an individual's decision quality (as captured in her reported ratings) change as she develops the ability to make use of the available information?
Our work here also relates to the broader literature on learning. According to our theory, to improve decision quality, consumers learn how to use the opinions made available from their online social ties. We expect that consumers learn how to make better decisions over time, based on their experiences through "learning by doing" (Nokes and Ohlsson 2005, p. 770). Learning by doing places emphasis on repeated trials where individuals develop more efficient or more effective solutions (Anzai and Simon 1979). While researchers have not explored learning by doing with respect to online opinions from social ties, they have demonstrated the existence of such a process in other settings. For example, Foster and Rosenzweig (1995) show that farmers learn how to employ innovative farming techniques as their experience and their neighbors' experience increase. Borgatti and Cross (2003) show that scientists' decisions to seek information depend on whether they know what others know and the value of that information. Furthermore, Goettler and Clay (2011) and Miravete (2003) show that consumers learn about their own online grocery shopping and calling behaviors, respectively, and as a result, make better decisions. Specifically, Goettler and Clay (2011) use a Bayesian learning model to reveal that consumers, via experience, reduce their uncertainty about whether the online grocery subscription plan matches their own consumption behaviors. Miravete (2003) shows evidence of learning as a positive effect of self-reported call activities on tariff choice.1

Alba and Hutchinson (1987) argue that experienced individuals are better at evaluating information because they process it at a deeper level and distinguish between relevant and irrelevant information. Experience has also been shown to decrease cognitive costs involved in learning (Johnson et al. 2003). As a result, we expect that, with experience, consumers will learn how to use opinions from social ties, facilitating better purchase decisions. To our knowledge, we are the first to investigate the relationship between experience and the value of socially acquired information.
3. Theoretical Development
The behavioral process we propose is as follows. A focal consumer joins a new community and wants to "succeed" in it. In our context, this means finding good books to read. More generally, it might be learning how to fit in in a new town, how to get promoted at a new job, or how to earn respect in a new online group. These are all important outcomes that may be achieved with a higher likelihood via the acquisition of information from social ties. Of course, not all information acquired from social ties is equally useful. Researchers have typically considered the strength of a tie to be an important driving factor behind information value. Strong ties--often, "friends"--are characterized by a higher frequency of interaction, more trust, and the ability to work together more productively (Granovetter 1973, Lin et al. 1981, Brown and Reingen 1987, Krackhardt 1992). It has also been shown that, in established relationships, weaker ties are more often associated with the transmission of useful and valuable information because they are more likely to provide novel insights (Granovetter 1973, Brown and Reingen 1987, Levin and Cross 2004). We propose another dimension to the strong tie/weak tie distinction: interpretability, which we define as the extent to which information acquired from others can be readily applied to one's future decisions. Low interpretability is reflective of uncertainty as to how to best make use of information. This uncertainty might derive from, for example, not understanding the standards in the community, not appreciating others' preferences, or difficulty in identifying the best sources of information that match one's own tastes. We hypothesize that, in the early stages of a relationship, weak ties are disproportionately likely to provide information that is of lower interpretability--and are therefore likely to be less beneficial to decisions-- compared with strong ties. This follows, in part, from the impact of homophily: we typically form strong ties with those with whom we are most similar (Lin et al. 1981, McPherson et al. 2001). This suggests that the relative value of information from social ties is a function of two forces: interpretability and novelty. High interpretability renders opinions from strong ties more immediately useful. On the other hand, consistent with

428
extant theories (Granovetter 1973, Brown and Reingen 1987, Levin and Cross 2004), conditional on one's ability to resolve her uncertainty and thus interpret and make use of the information, weak ties should impact more positively one's decisions.
Consistent with Foster and Rosenzweig (1995), Goettler and Clay (2011), and Miravete (2003), we propose that this uncertainty is resolved, at least in part, through a learning-by-doing process. By engaging with the platform over repeated usage occasions and by putting to use previously acquired information, new members improve their ability to select, interpret, and benefit from information. Gradually, individuals will gain, at various rates, experience in the community, learning, for example, which ties are most useful, what the community's norms are, and how to map others' opinions to their own preferences. Based on this experience, they will become better able to make use of the information shared by their ties. Given sufficient learning, the role of novelty will dominate, implying that weaktie relationships will eventually deliver more valuable information.
The key implication of this theory is that strongtie relationships deliver information that is more immediately useful, while weak-tie relationships require a period of learning--within the community--before bearing fruit. Put differently, while we expect initial levels of interpretability (uncertainty) to favor strong ties, we expect that the dynamic improvement via learning by doing will be greater for weak ties. This theory is presented graphically in Figure 1. Here, we formally state the relationships among the core constructs: Information is provided by new ties, which should positively impact one's decisions. This process of improvement is moderated by interpretability (strength of the tie between the focal consumer and the provider of information). Finally, the nature of this moderation is itself moderated by learning experienced by the focal member. The impact of information from weak ties is expected to be low, relative to strong ties, early in a relationship but to improve as a function of learning by doing.
Figure 1. Moderation Model of Decision Quality
)NFORMATION SOURCE
STRENGTHOFTIE

)NFORMATION FROMSOCIALTIES

,EARNING HOWTOUSE INFORMATION
$ECISION QUALITY

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS
4. Data
Our data are collected from Goodreads.com, a book review platform that integrates online opinions with a social networking community. Since we expect learning to occur early in one's participation in the community, we perform the data collection from the individual's perspective rather than the book's. Because of the power law associated with learning, we expect that learning will increase rapidly at first, but future incremental improvements will require more time and effort (Newell and Rosenbloom 1981, Johnson et al. 2003). Our initial sample consists of the first 25,000 user IDs that were created by Goodreads in April 2010. Some of these IDs may not reflect an actual user if she did not complete the sign-up process. However, we collect all of the IDs because we are unsure ex ante which will eventually be active. Furthermore, as we are studying the evolution of users' social networks from their initial profile creation, these data cannot typically be collected retrospectively. Combined with the common phenomenon of attrition and lurking on online platforms, it is necessary to collect data on a large initial sample.2
Of the 25,000 in our initial sample, 5,389 posted at least one review. These, therefore, form our focal sample for analysis. One concern is the extent to which this attrition reflects an unobserved aspect of the relationship between social ties and decision quality. Specifically, were it the case that a significant portion of the 19,611 who did not post a review found that their social ties were not helpful to them, this would imply a meaningful potential bias in our analysis. However, only 27 of these 19,611 formed even a single tie. Thus, we are comfortable assuming that their attrition was not related to their perceptions of the usefulness of ties. Our large initial sample size means we are able to obtain social network data only every two days to comply with Goodreads' Application programming interface (API). Using these data, we track the dynamic social structure that evolved over 50 days in April and May of 2010 for each individual along with her posting activity.
The users in our sample produced 120,843 ratings across 16,595 books during the 50 days. We also collect every review written for each book in this set of 16,595 on Goodreads for a total of 47.7 million reviews. Using these data, we define VALENCEibt as the average (and VARIANCEibt as the variance) of the ratings for book b at time t before individual i posts her rating. These variables are meant to control for the potential influence of the prevailing ratings environment. Our primary dependent variable--decision quality--is operationalized as the rating given by individual i to book b at time t. We assume that better purchase decisions will lead, all else equal, to higher ratings. To ensure that all else is, indeed, equal, we control for individual- and

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

429

Figure 2. Network Ties

A

B

C
book-level factors that may also drive ratings behavior independent of decision quality. We discuss these factors in Section 5. To control for book-level dynamics, we create ORDERibt, calculated as the number of previously posted reviews for book b at time t (i.e., ratings volume).
The social network on Goodreads contains several types of relationships. Goodreads labels as "friends" those connected through bidirectional relationships, similar to the connection between A and B in Figure 2. Friends are able to easily view each other's posted reviews. Goodreads labels as "followers" those who follow one's reviews--connected through unidirectional ties. Finally, Goodreads also provides a list of people one is following, again through unidirectional ties, which we call "sources." In Figure 2, A is the follower, while C is the source; therefore, C provides information to A, while the reverse is not true. The final sample of 5,389 consumers established a total of 13,294 friends, 354 followers, and 960 sources by the end of the 50-day window. The sparse social network is consistent with other online review settings, where a large majority of users do not frequently participate (Nielson 2006, Moe and Schweidel 2012, Sun et al. 2014).
To check whether there may be other differences between the friends and sources who provide opinions to the reader (e.g., expertise), we analyze a set of observable characteristics of friends and sources who are connected to any of the 5,389 users in our sample. We remove all individuals who are both a friend (to one user) and a source (to another) from the comparison and evaluate only those who fall exclusively into one category to highlight any unambiguous differences between the two types of ties. For each, we calculate the average number of posted ratings, mean ratings, frequency of rating (ratings per day), time since they joined Goodreads, and number of ties (see Table 1).3 We find no significant difference across the types of ties in terms of average ratings, frequency of ratings, or number of ties. Since some studies propose that experts are more negative (Schlosser 2005, Moe and Schweidel 2012), it is noteworthy that Table 1 suggests no difference in expertise across types. However, sources post significantly more ratings than do friends. This seems to be due to their having been members of the site longer, on average, than friends since their rating frequency is not significantly different.

Table 1. Friends vs. Sources

Measures

Friends

Sources

Number of ratings Average rating Frequency of ratings (ratings/day) Time on site (days) Number of ties N

132.73a 4.01 0.53
419.21a 240.10
13,150

205.60a 4.05 0.49
549.18a 250.72
816

aIndicates a significant difference between the means of friends and sources using a two-sample t-test with 95% confidence.

The use of opinions from one's social network is facilitated on Goodreads, as the site prominently displays reviews from one's friends and sources on her home page in an "Updates" list (Figure 3). In addition, reviews from one's social network are shown first when a user navigates to the review section for a specific book (Figure 4). Given that previous research demonstrates that individuals tend to stay on the first page of search results and prioritize higher-ranked items (Granka et al. 2004, Morahan-Martin 2004), we expect to see a similar behavior on the Goodreads platform,

Figure 3. (Color online) Recent Updates

Figure 4. (Color online) Social Network Reviews

430

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

where consumers are likely to focus on the ratings from their social network since they are shown before other ratings.
We address here how we operationalize each of the main constructs in our theory. In an ideal world, we would observe clean, independent measures of each component in the model in Figure 1. Specifically, we would observe each purchase by a user and the specific information that influenced it, including the source of the information. We would also have access to a dynamic variable capturing each member's evolving ability to process and decode (learn from) this social information. Finally, we would observe an unbiased assessment of the ex post utility associated with each purchase (decision quality). However, as is true of settings faced by many researchers, these measures are not available to us. First, we discuss how we measure the amount, as well as the originator, of socially acquired information available to a user. With respect to the originator--in particular, tie strength--we observe two different types of relationships between individuals: unidirectional and bidirectional. In an online setting, a unidirectional relationship may form when one follows the opinions of--that is, "listens to"--another without the relationship being reciprocated. Such a relationship is shown in Figure 2, where A follows C but C does not follow A. We assume that such a unidirectional link ("source" in our data) represents a weaker tie than does a bidirectional link ("friends" in our data) since it is likely to be characterized by a lower degree of homophily and relatively limited interactions between the two individuals. Indeed, it seems reasonable to expect that a strong-tie relationship, such as that characterized by a "friend," would be reciprocated. Thus, in Figure 2, we expect A to have a more limited understanding of the views, biases, or preferences underlying the opinions offered by C and, therefore, find it more difficult to interpret the information transmitted via such a relationship in the absence of learning experiences.
With respect to the amount of socially acquired information available to individual i at time t, we define FRIENDSLit and SOURCESLit, which are the lagged numbers of friends and sources, respectively, where L denotes the length of the lag. This captures the foundational aspect of our theory: consumers with bigger networks have access to more information from their social ties. We investigate other information proxies in Section 6.2. We lag these variables in various specifications ranging from two days to two weeks to capture the fact that the information from social ties may take time to be reflected in decision quality: one needs time to read the book, form an evaluation, and write a review. This approach provides us with a reasonable set of lags that both (a) accounts for the delay between information acquisition and review and (b) preserves as much of our data as possible.

To form a proxy for learning, we rely on an approach in line with past research on learning by doing (Foster and Rosenzweig 1995, Goettler and Clay 2011, Miravete 2003) in which learning is measured as a count of observed decision-making experiences. As a proxy for the member's ability to interpret and make use of the socially acquired information, we focus on past reviews as decision-making experiences; that is, we assume that consumers are able to improve their decisionmaking ability as a function, in part, of the number of previous decision-making experiences they have had. This is not to suggest that this is the only way one may learn. We acknowledge that there are likely to be other, possibly less easily observable, learning mechanisms. It is important, however, to draw a distinction between reading the review itself--which represents the transfer of information about a book--on one hand, from learning how to use that information, on the other. It is the latter process that we are interested in. Thus, in our focal analysis, our measure of learning is the variable EXPERIENCELit, which is the number of "reviewing sessions" prior to time t (lagged to match the social network measures). Each reviewing session consists of a day where individual i posts one or more reviews. The first reviewing session occurs on the day that i posts her first review. This differs from the number of reviews written prior to time t in that a reviewing session may include multiple reviews. We prefer the number of reviewing sessions, as our goal is to capture learning effects. It is unlikely that the second of two reviews written in the same reviewing session would reflect learning that occurred since the first review.4 Given the importance of the choice of a learning proxy, we investigate alternative measures in Section 6.4.
One important issue to highlight is that Goodreads does not randomly present the user with reviews. On the contrary, the default algorithm presents the most recent social network (i.e., friends' and sources') activity on a news feed on a user's home page. It is important that this mechanism is accounted for. While Goodreads does not make available retrospectively a user's news feed at time t, we are able to recreate it for each user i at time t based on the posting and reviewing activity of their network.5 Using this, we create the dummy variable NEWSFEEDLibt, which is equal to 1 if a review or post about book b by one of i's friends or sources appeared in i's feed at time t - L. This is to account for instances in which an individual explicitly observes a tie's post for the focal book, which may imply a disproportionate influence on one's purchase and reviewing activity.
We also form the variable FOLLOWERSLit 2 by lagging the number of followers by two days. A few comments on this measure: First, we see this as a direct control for the impact of reputational concerns on rating behavior. While not a focus of our study, we would suggest

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

431

Table 2. Summary Statistics

Lag length

Lag 2

Lag 4

Lag 6

Lag 8

Lag 10

Lag 12

Lag 14

Number of observations 120,843

110,784

101,059

96,440

87,946

82,678

76,461

Mean Std. dev. Mean Std. dev. Mean Std. dev. Mean Std. dev. Mean Std. dev. Mean Std. dev. Mean Std. dev.

RATINGS
VALENCE
VARIANCE EXPERIENCEa
ORDER (/1,000) FRIENDSa FOLLOWERSa SOURCESa NEWSFEED a FRIENDSREVIEWSa SOURCESREVIEWSa FRIENDSPOST a SOURCESPOST a

3.870 1.090 3.874 1.086 3.883 1.083 3.888 1.084 3.888 1.084 3.887 1.083 3.890 1.080 3.895 0.285 3.895 0.286 3.895 0.287 3.894 0.287 3.894 0.288 3.893 0.288 3.893 0.288 1.002 0.234 1.000 0.235 0.998 0.235 0.999 0.236 0.998 0.236 0.997 0.236 0.997 0.236 0.664 1.789 0.667 1.775 0.670 1.751 0.639 1.694 0.641 1.672 0.607 1.613 0.586 1.569 8.551 10.473 8.382 10.420 8.269 10.395 8.308 10.409 8.247 10.389 8.144 10.347 8.127 10.344 1.388 4.689 1.185 4.408 0.998 4.173 0.735 3.699 0.582 3.473 0.463 2.489 0.369 2.052 0.107 0.876 0.117 0.914 0.111 0.917 0.106 0.922 0.110 0.953 0.117 0.982 0.124 1.017 0.272 1.476 0.207 1.323 0.176 1.212 0.153 1.139 0.138 1.074 0.121 1.008 0.101 0.947 0.017 0.131 0.014 0.118 0.012 0.109 0.009 0.096 0.008 0.090 0.007 0.084 0.006 0.079 28.59 550.08 27.98 549.57 24.86 563.71 22.20 566.02 22.39 584.67 20.22 567.91 15.49 277.62 16.81 240.70 17.95 247.11 15.46 245.47 14.53 246.62 13.62 225.73 13.55 230.38 12.16 220.85 0.187 0.813 0.125 0.753 0.077 0.435 0.072 0.432 0.070 0.438 0.066 0.440 0.063 0.436 0.019 0.146 0.015 0.131 0.015 0.129 0.015 0.129 0.016 0.134 0.017 0.137 0.018 0.142

aThe variable is lagged according to the column heading.

that our ability to control for these factors is somewhat novel. Concern for reputation may result, for example, in a negative adjustment in ratings for those who are concerned about self-image (Schlosser 2005, Moe and Schweidel 2012). FOLLOWERSLit 2 allows us to control for reputation precisely by serving as a proxy for the number of others who are reading i's reviews. By contrast, most existing research has used as proxies aspects of the review environment (such as valence, variance, and volume). Without a measure of the number of others "watching," it may be difficult to disentangle more substantive impacts of the environment (e.g., an anchoring effect of the prevailing mean or uncertainty induced by the prevailing variance) from true reputational concerns. Since we have separate measures for the environment and the number of followers, we are able to control for these potential confounds. Second, as a technical point, we note that the different lag on FOLLOWERSLit 2 compared with FRIENDSLit and SOURCESLit reflects the fact that this is an environmental variable assumed to

influence one's rating but not her purchase decision. The rating at time t is a function of purchase decisions influenced by the information provided by one's network at earlier time periods--captured by FRIENDS and SOURCES--along with more immediate reputational concerns, captured by FOLLOWERS.
Table 2 provides, for each lag, summary statistics for our data set. Note that the number of observations decreases as the lag increases. A side benefit of removing the observations from the first two days is that there is a significantly greater posting activity that occurs on these days, most likely reflective of favorite books or books that the individual has already read. (Goodreads encourages the posting of previously read books when the user creates her account.) Since we lag our network variables, our data include only reviews that are posted after the initial spike in posting activity. Figures 5(a) and 5(b) reports the evolution of ratings across time and experience.6 Figure 5(b), in particular, suggests a relatively large upward trend in ratings for those with

Figure 5. (a) Evolution of Ratings Across Time and (b) Evolution of Ratings Across Experience

(a) Evolution of ratings across time 5.0

(b) Evolution of ratings across experience 4.2

4.5

4.0

4.0

3.8

Ratings Ratings

3.5

3.6

3.0

3.4

2.5 2.0
1

All

With SN

With friends

With sources

5 9 13 17 21 25 29 33 37 41 45 49 Time

3.2

3.0

1

3

5

7

9

11

Experience

Notes. In panel (a), we report the average ratings across consumers on their nth day on Goodreads. Thus, for t 1, the reported ratings are the averages for users on their first day on the site. In panel (b), experience is operationalized as the number of reviewing sessions. Thus, for experience 1, we report the average ratings across all ratings posted by users in their first rating session.

432
sources. We also note that, as mentioned previously, the network data are sparse; that is, many individuals choose to have very few or no social ties (please see Figures D.1­D.3 in Online Appendix D for plots of the evolution of network ties and histograms of the number of individuals with each type of relationship). This sparseness presents some estimation challenges associated with unobserved heterogeneity, which we discuss below.
5. Model
Our main goal is to explore the impact of information from an evolving social network on decision quality. We use a consumer's posted rating as a proxy for decision quality under the assumption that, all else equal, higher reported ratings follow from better purchase decisions. The use of rating as a proxy for decision quality is consistent with previous work (Li and Hitt 2008, Moe and Schweidel 2012, Godes and Silva 2012). Of course, ratings may also be impacted by other factors--in addition to satisfaction--for which we must control (Li and Hitt 2008, Moe and Schweidel 2012, Godes and Silva 2012). Specifically, we are concerned about the following factors: (1) the ratings environment; (2) individual-level heterogeneity, including both scale usage and the tendency to rate more positively or negatively; (3) dynamic effects; and (4) reputation effects. Below, we discuss how we address these challenges.
The ratings environment--in particular, the prevailing mean and variance--may encourage individuals to adjust their ratings away from their true evaluations (Moe and Schweidel 2012). Following the literature, we control for these effects via observable variables (valence, variance, and volume or order).7 With respect to heterogeneity, we control for individual differences in positivity by including individual intercepts. To deal with scale usage heterogeneity (Rossi et al. 2001), we follow Ying et al. (2006) and estimate individual-level cutoff points that capture one's decision to use certain parts of the ratings scale (see Section 5.2 for details). As noted above, standard book-level dynamics are accounted for by ORDER. Finally, we control for reputation effects directly using FOLLOWERS, the observed number of users exposed to the individual's ratings at a lag of two days.
Our dependent variable, the posted rating EVALibt, is a discrete measure from one to five stars, where five represents the highest possible rating. This discrete ordered variable is appropriately modeled using the ordered probit model, where we specify individual i's continuous latent evaluation for book b at day t, as
EVALibt 0i + 1i · VALENCEibt + 2i · VARIANCEibt + 3i · EXPERIENCELit + 4i · EXPERIENCELit 2

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

+ 0b + 1b · ORDERibt + 1 · FRIENDSLit

+ 2 · FOLLOWERSLit 2 + 3 · SOURCESLit

+ 4 · EXPERIENCELit · FRIENDSLit

+ 5 · EXPERIENCELit 2 · FOLLOWERSLit 2

+ 6 · EXPERIENCELit · SOURCESLit

+ 7 · NEWSFEEDLibt + ibt ,

(1)

where ibt  N(0, 1). The term EVALibt is the latent evaluation. The book-level intercepts, 0b, capture baseline quality and other unobservable book-level, timeinvariant factors.
We test for the impact of the information made available by one's social network on reported purchase decision quality, as moderated by her level of accumulated learning. As such, our analysis focuses on the interactions of the variables FRIENDS and SOURCES, which capture information, with EXPERIENCE, which captures learning.8 The coefficients on these interactions capture the change in the marginal impact on decision quality of gaining access to more information (via adding new ties) as one learns how to use this information. As a technical point, we note that for lags greater than 2, FRIENDS and SOURCES have greater lags than FOLLOWERS. Thus, we also include in the model EXPERIENCELit 2 and interact this variable with FOLLOWERS so that the interaction is consistent with respect to the time lag.9

5.1. Endogeneity
There are a number of potential sources of endogeneity in this model.10 First, endogeneity may arise to the extent that the actions of agents within a network are driven by unobserved individual effects that influence both ratings and network decisions. For example, it may be the case that those who have a high ability to select good books also create more ties. People who have similar abilities may also tend to form ties with each other. If unaccounted for, this would cause FRIENDSLit to be correlated with it, leading to bias. To deal with this, as reflected above, we specify individual- and book-level random effects to control for individual-level and book-level differences (Hartmann et al. 2008, Nair et al. 2010). Thus, the estimates of  should be seen as conditional on an individual's baseline skill at selecting books.
Second, while our model reflects the impact of information from social ties, a user may also receive useful (but unobserved to the researcher) information from outside of her observed online network. This may raise identification concerns if FRIENDSLit (or any of the social network measures) is correlated with the out-ofnetwork information. Such a correlation might derive from the fact that both quantities (observed network ties and out-of-network information) may be driven by a third unobserved quantity such as the amount of

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

433

time one spends on the platform or online in general.11 Unfortunately, as is true of nearly every study of online ratings (e.g., Chintagunta et al. 2010, Godes and Silva 2012, Chevalier and Mayzlin 2006, Chen et al. 2011, Moe and Schweidel 2012), we do not observe users' review-reading activity or out-of-network information received, implying that these factors might enter via the error term. Having said this, we highlight that the current model contains EXPERIENCEit, which may be seen as a proxy for time spent on the platform under the assumption that people who post more reviews would, on average, be expected to spend more time on the platform. Given such an assumption, then, outof-network information may not represent a significant endogeneity threat.12 Nonetheless, the instrumental variable (IV) and latent instrumental variable (LIV) approaches we describe below also address any residual concern related to this issue.
Endogeneity may also arise if, in addition to the impact of networks on ratings (as captured in Equation (1)), it is also the case that posted ratings cause the formation of friendship ties. One's decision to form a bidirectional link with individual i may be a function of her previously posted ratings, for example. Indeed, Shriver et al. (2013) find that social network activities (e.g., blogging) influence the number of ties one makes. On one hand, our use of lagged social network variables may address reverse causality. Imagine, for example, that the (true-but-ignored) networkformation model is FRIENDSLit  · EVALi, t-L-1 + i, t-L; that is, people who have posted higher ratings in period t - 1 will form more friendship ties in period t (assuming that  > 0). Then, substituting in, we find that estimating a simplified model (with only the FRIENDS variable) is tantamount to estimating the following:

EVALit

i0 + 1 ·  · EVALi, t-L-1 + i, t-L + it i0 + 1 ·  · i0 + 1 · FRIENDSLi, t-L-1 + i, t-L-1
+ i, t-L + it , (2)

where L ranges from two days to two weeks. Thus, as in Bollinger and Gillingham (2012), an assumption limiting the order of autocorrelation in the errors (i.e., that
i, t-L-1  it) would be sufficient to ensure consistent estimates.
Since assumptions regarding the nature of timevarying unobservables (e.g., that the correlation between in- and out-of-network variables comes via time spent on the platform) and the order of serial correlation are difficult to verify, we employ two approaches in an effort to address directly these potential sources of endogeneity: LIVs and IVs. The LIV approach in this setting is attractive because the results do not depend on the validity of specific instruments. Following Ebbes (2004), Ebbes et al. (2005), Zhang et al. (2009), and

Rutz et al. (2012), we utilize data augmentation (Tanner and Wong 1987) to estimate a binary, latent instrumental variable to decompose the potentially endogenous network variables into two components, one that is uncorrelated and another that is correlated with it. To simplify notation, we discuss a simplified version of the model with one potentially endogenous variable as follows:

EVALit FRIENDSit

0 + 1 · FRIENDSit + it , Zit + it ,

(3)

where Zit is a latent categorical variable with category means of . We assume that Zit has two categories,13 is orthogonal to it and it, and follows a binomial distribution with probabilities (1, 2). Here, c is the
probability that the cth latent instrument is one (i.e.,

belongs to category C) and c c 1. Furthermore, we assume that the error terms follow a multivariate nor-

mal distribution with mean 0 and variance­covariance

matrix 

    

.14

Thus,

the

likelihood

function

is

specified as

p(kibt | , , )

(2)-1 ||-1/2 exp

-

1 2

(kit

-

uit

)

-1(kit

-

uit

)

,

(4)

where kit (EVALit , FRIENDSit) , and uit (0 + 1 FRIENDSit , Zit) . We use a block Gibbs sampler to draw the parameters in groups. Conditional on known
values for , Z, and , we follow Ebbes (2004) and
Rutz et al. (2012) and draw  from a normal distribution with mean V-1(D ( EVAL +  (D - Z)) + -0 10) and variance­covariance V  D D + -0 1, where Dit [1 FRIENDSit]. We also draw  from an inverse Wishart distribution with parameters (w0 + R0), ( i t(kit - uit)(kit - uit) + 0). The remaining parameters are drawn as follows:  can be drawn from MVN(a, S) where S (S0 + b D D)-1, a S(S0ao + b D FRIENDS), and b 1/(    ). The latent Zit are categorical variables drawn from the following pos-
terior probability:

p(Zit c)

c · L(kit | , , , Zit c)

c j

1 j

· L(kit

| , , , Zit

j)

,

(5)

where L( · ) is the likelihood specified in Equation (4) conditional on Zit c. We also draw c from a Dirichlet distribution: c | Z  Dirichlet(1 + 1(Z 1), 1 + 1(Z 2) · · · + 1 + 1(Z c)). In our model, following Ebbes et al.
(2005), Zhang et al. (2009), and Rutz et al. (2012),
we assume that there are two categories such that c {1, 2}.
In the IV approach, we use instruments that should
be correlated with FRIENDSit but uncorrelated with it. As an instrument for FRIENDSit, we use the size of individual i's friends' networks. This is analogous to the
method of Shriver et al. (2013), who use the number of

434

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

friend requests of i's friends as an instrument for the number of i's friend requests. Precisely, let ut  {set of friends of individual u at time t}. Then the instrument for FRIENDSit is Zit uit (N[uT ] - 1), where we define N[S] as the cardinality of set S (i.e., the number of individuals who are friends with u). Thus, for each individual i, we identify all individuals u who are friends of i at time t, and collect the total number of friends that each u will have by the end of the observation window.15 Our use of this instrument is in keeping with the goal of staying as close as possible to the existing literature (Shriver et al. 2013, Oestreicher-Singer and Sundararajan 2012). We obtain analogous instruments for FOLLOWERS and SOURCES. These instruments are positively correlated with the total number of network ties ( 0.79, 0.57, and 0.63 for friends, followers, and sources, respectively), as a greater number of ties is related to the network structure of those ties.
The validity of our instruments in dealing with reverse causality is dependent on two assumptions: (a) the size of one's network is correlated with the size of one's friends' networks, and (b) one's choice of ratings has no effect on the size of her friends' networks. Here, the latter seems reasonable given that only ratings from first-degree ties (i.e., immediate friends and followers) are easily accessible on the book review page, whereas opinions from second-degree ties are "hidden" with the other mass reviews. (Each book in our sample has, on average, 3,000 reviews.) The tie formation between i's friends (e.g., j) and others who are not connected to i (e.g., k) involves a joint decision by both j and k. We expect that individual k (and others not connected to i) will not be directly affected by i's ratings because those ratings are not readily observable. Even if they were observed, we would expect that i's ratings would be more likely to effect a potential tie between i and k than between other people (e.g., j and k). In a similar sense, we expect that the network sizes of i's friends do not directly impact i's ratings because i cannot easily observe those tie formations, alleviating concerns for potential reputation effects due to a larger group of second-degree ties.
Our LIV and IV approaches should also be effective in controlling for the possible presence of information from out-of-network sources. Analogous to the argument above, if one assumes that the number of friends formed by i's friends is not correlated with the amount of out-of-network information available to i, then our IV approach would be free from this potential source of inconsistency. Finally, the fact that both LIV and IV results (the former being free of assumptions regarding specific instruments) are consistent should serve as a demonstration of the robustness of our core results.
5.2. Estimation We use a Hierarchical Bayes method to estimate the model. Since the posted rating, EVALibt, is ordinal, we

use data augmentation to map the ordered ratings onto a continuous scale (Tanner and Wong 1987). To transform the evaluation from a five-point scale, we model the probability of an observed rating as

P(EVALibt 1) (1i - EVALibt ),

P(EVALibt 2) (2i - EVALibt ) - (1i - EVALibt ),

P(EVALibt 3) (3i - EVALibt ) - (2i - EVALibt ),

P(EVALibt 4) (4i - EVALibt ) - (3i - EVALibt ),

P(EVALibt 5) 1 - (4i - EVALibt),

(6)

where EVALibt is the latent evaluation of consumer i for book b at time t. We specify 1i, 2i, 3i, and 4i as unobserved individual-level cutoffs, which divide the latent utilities into discrete segments over the support of the normal distribution. We follow Ying et al. (2006) and assume that log(i)  MVN(¯ , ). This allows us to use Bayesian shrinkage to pool information across individuals when estimating the individual-level parameters. We assume that ¯ follows a diffuse normal prior and  follows an Inverse Wishart prior. As is standard (Albert and Chib 1993, Ying et al. 2006, Moe and Schweidel 2012), we identify the three cutoff points and one intercept per individual by setting 1i 0. To allow for heterogeneity across individuals and correlation among the individual-level parameters, we assume that i  MVN(¯, ). The i parameters include the individuallevel intercept from Equation (1). We also allow for heterogeneity across books and correlation among the book-level parameters and assume that b  N(¯ , ). The b parameters include the book-level intercept from Equation (1). The identification of the two separate intercepts--individual and book--presents a challenge. To appreciate this, note that one could add a constant to each individual-level intercept and subtract the same constant from each book-level intercept without changing the model. To address this, we set the first book-level intercept to 0. This allows us to identify the remaining cutoff points and intercepts. For the rest of the hierarchical model, we assume diffuse normal priors for the mean effects of the individual-level and book-level parameters in the model (i.e., ¯ and ¯). We also assume that  and  follow inverse Wishart priors. Furthermore, for the aggregate-level estimates on the social network variables (), we assume a diffuse normal prior:   N(¯0, 0). While there is sufficient individual-level variation within the ratings environment and user characteristics, the social network variables do not have adequate variation across time and within individual to identify individual-level estimates. As a result, we estimate  at the aggregate level. The proposed model requires us to estimate individual-level, book-level, and aggregate-level coefficients. To do so, we cycle through the Gibbs sampler (Gelfand and Smith 1990) and use a block Gibbs

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

435

sampler to iteratively estimate each set of parameters (individual-, book-, and aggregate-level parameters). The full conditional posteriors are available from the authors. We run 30,000 iterations, where the first 20,000 serve as the burn-in period and the remaining 10,000 iterations are used to obtain inferences about the posterior. The iterations quickly converge to a stable posterior, as assessed by examining the posterior iterations and the Gelman and Rubin diagnostic (Brooks and Gelman 1998, Gelman and Rubin 1992).
6. Results
Table 3 presents our main results. These models are estimated using the LIV method with each model differing in the length of lag (in days). As shown in Table D.1 in Online Appendix D, the results using IVs are qualitatively very similar, so we focus our discussion on the LIV results. (See Table D.2 in Online Appendix D for the posterior standard errors.16) We first focus on the results for the social network variables. First, as the amount of information from friends (as measured by the number of friends) increases, consumers post higher ratings about their past purchases over a range of lags. This suggests that one's decision quality increases as she develops more bidirectional relationships. Second, all else equal, as the consumer accesses more information from sources, her reported utility seems to decline. On one hand, this is consistent with our expectation that, initially, strong ties should provide information that is more beneficial. On the other hand, this suggests that, initially, basing decisions on information derived from weak ties may actually lower a consumer's decision quality before she develops experience on the platform. These findings demonstrate the importance of accounting explicitly for differences across tie types in terms of not only the novelty of the information received from ties (Granovetter 1973, Brown and Reingen 1987) but also the interpretability of that information. While the literature is clear in suggesting that information from weaker ties--here, unidirectional links--would be more valuable in driving decision quality, these results suggest that a consumer may be better initially at interpreting information from friends compared with less familiar acquaintances.
These results conflict with both the traditional view of weak ties and our observed empirical pattern of (online) tie formation: people build, and acquire information from, many weak ties. It would be surprising if these ties were not in some way beneficial. In fact, conditional on sufficient learning, they are. We find that the coefficient on EXPERIENCE × SOURCES is positive and significant, consistent with our expectation that learning by doing may be useful in leveraging information acquired from weak ties. Combining the main

and interaction effects together, the coefficients suggest that consumers benefit from increased weak-tie information once they have engaged in three to four reviewing sessions. In our empirical data, 19% of individuals achieve this level of experience over the 50-day observation window. This provides evidence of a rich dynamic consumer learning process.
As we predicted, these dynamic learning effects are more pronounced for weak than for strong ties. Indeed, the dynamics of information acquired from friends appear to be more complicated, as our model unexpectedly yields a negative coefficient on EXPERIENCE × FRIENDS. The coefficients suggest that the effects of an additional friend become negative for consumers who accumulate more than three reviewing sessions. We tentatively interpret this as potentially arising from reputational concerns. Unlike sources, friends are able to view one's ratings, so there is the potential for one to adjust ratings to manage reputation as more friends are added. Researchers have found that consumers tend to adjust their evaluations down when there is a concern for reputation (Moe and Schweidel 2012, Schlosser 2005). Thus, the EXPERIENCE × FRIENDS estimate may represent the net effect of an improvement due to learning and an adjustment due to reputational concerns.17 Unfortunately, we are unable to directly disentangle the two effects of friend formation in Model 1. In Section 6.1, we address this issue by studying the impact of sources that eventually evolve into friends. We stress, nonetheless, that our core results are consistent with the theory: information acquired from strong ties seems more immediately useful, while dynamic learning effects are strongest for weak ties. In particular, the latter provide evidence of decision-quality improvement due to learning effects.
For our control variables, the results suggest that VALENCE is significantly positive and VARIANCE is associated with lower posted ratings. These estimates are consistent with previous research (Chevalier and Mayzlin 2006, Dellarocas et al. 2007, Chintagunta et al. 2010, Moe and Trusov 2011) and suggest that consumers are more likely to indicate a higher rating for books that have been rated consistently higher by others in the community. We note that the effect size of VALENCE seems to decrease as the lag increases. Given that we drop more of the initial observations for each individual as the lag increases, this may be driven by users being less susceptible to environmental factors over time.18 Our book-level estimates are also consistent with Godes and Silva (2012), showing that posted ratings decrease as ORDER increases. Finally, we find some evidence that books that appeared on the news feed, on a respective lagged date, generated higher ratings, although this result is not significant for all lags. We caution, though, against drawing sharp conclusions from the variation across lags in the estimates

436

Table 3. Main Results (Model 1)

Lag (days)

Lag 2

Lag 4

Lag 6

Impact of sources' information EXPERIENCE · SOURCES
SOURCES
Impact of friends' information EXPERIENCE · FRIENDS
FRIENDS
Other variables EXPERIENCE
EXPERIENCE (Lag 2)
FOLLOWERS (Lag 2)
EXPERIENCE · FOLLOWERSd
VALENCE
VARIANCE
ORDER
NEWSFEED
Number of individuals Number of books Number of observations MAD RMSE

0.0131b [0.0016, 0.0419]
-0.064a [-0.178, -0.0169]
-0.0088 [-0.0351, 0.0043]
0.0021 [-0.0245, 0.0272]
0.4691 [-3.6171, 4.5618]
N/A
0.0047 [-0.0217, 0.0375]
-0.0002 [-0.0143, 0.0142]
1.8018b [0.0431, 3.5584]
-0.3592 [-0.9985, 0.2269]
-0.7911a [-2.7689, -0.1756]
0.0063c [0.0001, 0.0222]
4,991 16,118 120,843 1.0884 1.5257

0.0189a [0.0047, 0.0534]
-0.0508a [-0.1459, -0.0118]
-0.0216a [-0.0641, -0.0037]
0.0142 [-0.0086, 0.054]
-1.4928 [-5.7814, 3.098]
1.1872 [-3.3693, 5.9146]
-0.0051 [-0.0437, 0.0287]
-0.0017 [-0.0173, 0.011]
1.8010b [0.0569, 3.5629]
-0.3914 [-0.9788, 0.1964]
-0.6755a [-2.3208, -0.1494]
0.0109a [0.0017, 0.0359]
4,653 15,583 110,784 1.0935 1.5317

0.0177a [0.0045, 0.0515]
-0.0812a [-0.2291, -0.0224]
-0.0141c [-0.0483, 0.0008]
0.0284b [0.002, 0.0936]
-0.8652 [-4.8354, 3.2618]
0.4578 [-3.7495, 4.9037]
-0.0035 [-0.0443, 0.0307]
-0.0055 [-0.027, 0.0074]
1.7206b [0.0417, 3.4123]
-0.3469 [-0.9629, 0.2589]
-0.914a [-3.3024, -0.2076]
0.0061c [-0.0002, 0.0226]
4,635 15,246 101,059 1.0876 1.5267

Note. The 95% Bayesian credible intervals are reported in brackets. aIndicates that 0 is not contained in the 99% Bayesian credible interval. bIndicates that 0 is not contained in the 95% Bayesian credible interval. cIndicates that 0 is not contained in the 90% Bayesian credible interval. dEXPERIENCE and FOLLOWERS both have a 2 day lag in this interaction for all models.

Lag 8
0.0196a [0.0055, 0.0549]
-0.0635a [-0.1807, -0.0167]
-0.0164a [-0.0509, -0.0019]
0.0487a [0.0112, 0.1428]
-0.6396 [-4.4472, 3.1946]
-0.1821 [-4.1873, 3.8664]
0.0054 [-0.0378, 0.0581]
-0.0098 [-0.0402, 0.0055]
1.7030b [0.0001, 3.3915]
-0.3945 [-1.0546, 0.2127]
-0.7721a [-2.7471, -0.1751]
-0.0009 [-0.008, 0.0045]
4,598 14,800 96,440 1.0812 1.5210

Lag 10
0.0132a [0.0034, 0.0399]
-0.0503a [-0.1482, -0.0121]
-0.0118 [-0.0431, 0.003]
0.0489a [0.0099, 0.1497]
-0.5777 [-4.1104, 3.0796]
-0.3355 [-4.2012, 3.6554]
-0.0063 [-0.0661, 0.0386]
-0.0116 [-0.0453, 0.0049]
1.6042c [-0.0278, 3.194]
-0.4303 [-1.1201, 0.2266]
-0.9019a [-3.2183, -0.2101]
-0.0018 [-0.0105, 0.0042]
4,550 14,422 87,946 1.0838 1.5243

Lag 12
0.015a [0.004, 0.042]
-0.0195b [-0.0739, -0.0051]
-0.0161a [-0.0502, -0.0016]
0.0481a [0.0091, 0.1475]
-0.7166 [-3.9347, 2.66]
-0.0717 [-3.7368, 3.5366]
-0.0042 [-0.0553, 0.0354]
-0.0142 [-0.0534, 0.0024]
1.4600c [-0.0935, 3.0066]
-0.4177 [-1.0948, 0.2664]
-0.6037a [-2.1822, -0.1337]
0.0023 [-0.0028, 0.0108]
4,492 13,915 82,678 1.0883 1.5284

Lag 14
0.0092a [0.0018, 0.0276]
-0.0013 [-0.0369, 0.0324]
-0.0118a [-0.0364, -0.001]
0.0368a [0.0055, 0.1118]
-1.3796 [-4.3753, 1.7451]
0.8474 [-2.6062, 4.4737]
-0.0061 [-0.0637, 0.0379]
-0.0116 [-0.049, 0.0073]
1.5077c [-0.0485, 3.0606]
-0.4324 [-1.1831, 0.3239]
-0.8456a [-2.9096, -0.1992]
0.0085a [0.0011, 0.0256]
4,435 13,594 76,461 1.0875 1.5283

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

437

on NEWSFEED. As shown in Table 2, this is a very sparse binary variable: once we get to the longer lags, only about 7 of 1,000 observations record a 1. Thus, a relatively small number of observations may have a meaningful impact on the estimates, accounting, in part, for this instability.
6.1. Source-to-Friend Migration Our main results in Table 3 suggest that, as learning evolves, adding more friends (strong ties) leads to lower ratings. While unexpected, this result might be explained by the fact that individuals are concerned with their reputation as they add new friends. To investigate this, we isolate all ties that migrate within our 50-day window from a source to a friend. By doing so, we (a) hold constant the quality of the information received by the user since she receives the same information whether the tie is a source or a friend, and (b) isolate the effect of reputation, since this is relevant for a friend but not for a source. As a result, the primary impact on observed ratings of this transition should be driven by concern for reputation.
We create a distinct category of ties and analyze their impact on ratings both before the source-to-friend transition and after, which we label as PRE-S2Fit and POST-S2Fit, respectively.19 The term PRE-S2Fit represents the (lagged) number of ties of individual i who are sources at time t but who will eventually turn into friends, while the term POST-S2Fit represents the number of her ties that are friends at time t and were previously sources. The former (latter) captures the impact of these ties on decision quality before (after) the migration occurs. Our SOURCES and FRIENDS variables now capture the impact of those sources and friends that remain as such throughout the data observation window. In our data set, 14% of those classified as a source eventually become a friend.20
Our primary test of this explanation is whether EXPERIENCE · PRE-S2F is greater than EXPERIENCE · POST-S2F. Since the nature and quality of the information received is not changing, such a result would be consistent with an increased concern for reputation. Importantly, and consistent with our results throughout the study, these effects are expected to be most salient when the user has higher levels of experience in the community. It is then that one would be expected to care more about reputation. As shown in Table 4, we find that this is the case: the mean coefficients on EXPERIENCE · PRE-S2F are higher than those on EXPERIENCE · POST-S2F.21 While the information acquired from a source does not degrade when she becomes a friend, one nonetheless appears to adjust ratings downward, possibly to reflect concerns for reputation (Moe and Schweidel 2012, Schlosser 2005).

Table 4. Source-to-Friend Migration

Source turned into friends (lag 10)

Impact of sources' information EXPERIENCE · SOURCES EXPERIENCE · PRE-S2F
SOURCES
PRE-S2F
Impact of friends' information EXPERIENCE · FRIENDS EXPERIENCE · POST-S2F
FRIENDS
POST-S2F
Other variables EXPERIENCE
EXPERIENCE (Lag 2)
FOLLOWERS (Lag 2) EXPERIENCE · FOLLOWERSd
VALENCE
VARIANCE
ORDER
NEWSFEED
Number of individuals Number of books Number of observations

0.0147a [0.0038, 0.0418]
0.0216a [0.0056, 0.059]
-0.0636a [-0.1895, -0.0153]
-0.0329a [-0.0928, -0.0075]
-0.014c [-0.048, 0.0001]
-0.001 [-0.0159, 0.0116]
0.0427b [0.0042, 0.1401]
0.0273b [0.0024, 0.0872]
-0.3716 [-3.9681, 3.4031]
-0.0343 [-4.186, 3.9516]
0.0004 [-0.0497, 0.0447]
-0.0091 [-0.0392, 0.0062]
1.4791c [-0.1197, 3.1088]
-0.4857 [-1.1537, 0.1743]
-0.515a [-1.8834, -0.1068]
-0.0024 [-0.0121, 0.0036]
4,550 14,422 87,946

Note. The 95% Bayesian credible intervals are reported in brackets. aIndicates that 0 is not contained in the 99% Bayesian credible
interval. bIndicates that 0 is not contained in the 95% Bayesian credible
interval. cIndicates that 0 is not contained in the 90% Bayesian credible
interval. dEXPERIENCE and FOLLOWERS both have a 2 day lag in this
interaction.

6.2. Other Measures of Information While we expect that the number of friends and sources should represent fairly well the amount of information available, we consider here alternative measures. Our implicit assumption behind the use of this operationalization has been that members receive information from ties in many forms, well beyond simply reviews about specific books. For example, we expect that a members' ability to choose a good

438

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

book is impacted as well by her ties' reviews about other (unrelated) books and/or lists of books they have already read or would like to read. Thus, our conceptualization of information is fairly broad with respect to what actions by the "sender" constitute information. The analyses in this section are designed to assess the relative merits of using a more narrow definition of information. In the interest of exposition, we discuss these analyses here and include only the results for variables constructed using a 10-day lag. The results using other lags are presented in the online appendix. One alternative measure we consider is the number of reviews posted by friends and sources. We define FRIENDSREVIEWSLit (SOURCESREVIEWSLit) as the number of reviews posted by the friends (sources) of individual i on or before time t - L. The set of ties in this calculation is those who are connected to individual i at time t - L. We see these measures as both narrower and less precise than FRIENDSLit and SOURCESLit for two reasons. First, a new tie will provide substantially more information than observable reviews. For example, a new tie can also post in other forums and often have public "to-read" lists. Counting only reviews ignores these other dimensions that are implicitly captured in the number of ties. Second, as the role of information here is to help members figure out how to learn about new books (e.g., new genres or authors that the focal individual has not yet considered), there would seem to be an implied concavity in the value of reviews from a given tie. As an example, having five friends, each of whom has provided 10 reviews, should provide more useful information than one friend with 200 reviews, all else equal. While the number of reviews may be higher in the latter case of 200 reviews, the diversity of information provided in the former would, we believe, based on previous research (e.g., Granovetter 1973, Burt 1995), lead to more potential improvement in decision making. We also consider a yet narrower measure of whether a friend or source has previously reviewed the specific book b for which i is providing a rating. We create an indicator variable, FRIENDSPOSTLit (or SOURCESPOSTLit) that is equal to 1 if a friend (or source) of i has posted a review for the focal book by time t - L.22 The set of friends used in the calculation are those connected to individual i at time t - L. We stress that while this measure is intuitively appealing given its direct mapping to information transfer, we also see it as likely to pick up less of the information being made available by one's ties.
Since we see these alternative measures as weaker proxies for the information available to the focal user i, for the reasons outlined above, we expect ex ante to see, and indeed find, smaller (and less precise) estimated effects. In addition, the relative fit measures are clear in supporting the view that the use of the number of ties

as a proxy for information best explains our current data. Table 5 presents the LIV estimates for these models (lagged by 10 days). The results for the other lags are presented in Online Appendix A. In both models, information received from strong ties is initially more useful than that received from weak ties, although in the case of the count of reviews provided, a better interpretation may be that information from friends is less harmful than that received from sources. Importantly, in both models, as in our core model in Table 4, learning moderates these effects in that we find that experienced consumers benefit from the reviews posted by sources, as posted ratings increase with greater EXPERIENCE · SOURCESREVIEWS.23 We note that our results for SOURCESREVIEWS appear to be more robust (compared with those for FRIENDSREVIEWS) to the empirical operationalization of information. This may suggest that one is more likely to benefit from a broader set of information-providing actions chosen by friends (i.e., not captured with the number of reviews) compared to that chosen by sources.
In addition, the use of SAME_REVIEW_INDICATOR as a measure of information does not suffer from the same nonconcavity problem as does NUMBER_ OF_REVIEWS, and, in part because of this, the results match those in the main model more closely. Nonetheless, the narrow conceptualization of information that it implies is likely a core factor in the lower fit compared to the main model.24
6.3. Information Embedded in the Review Text According to our theory, information from strong ties should improve decisions relatively quickly, but learning is required before information from weak ties will have a beneficial impact. In this analysis, we test a straightforward corollary: these predictions should hold true--indeed, there should be improvement of any kind--only when the content provided by ties is, in fact, informative. Of course, identifying whether a given review is informative is challenging, given that the friends and sources in our data set generated over 900,000 reviews. To do so, we employ a combination of manual coding and text-based classification methods using machine learning. In short, we begin by asking individuals to manually code a training set of reviews as being informative or not. Based on this training, we then use an ensemble of supervised learning algorithms provided in the RTextTools R package (Jurka et al. 2013) to classify the informativeness of the rest of the corpus of reviews. Given that supervised learning and classification for text documents are well established in the computer science literature (e.g., Boser et al. 1992, Hsu et al. 2003, Cortes and Vapnik 1995, Collingwood and Wilkerson 2012), we refer readers to Online Appendix B for details of our procedures and to the referenced papers for details of the machine learning algorithms. The output of this approach is, for each

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

439

Table 5. Alternative Measures of Information

Number of reviews from friends/sources

Same review indicators from friends/sources

Lag 10

Lag 10

Impact of sources' information EXPERIENCE · SOURCES
SOURCES
Impact of friends' information EXPERIENCE · FRIENDS
FRIENDS
Other variables EXPERIENCE
EXPERIENCE (Lag 2)
FOLLOWERS (Lag 2)
EXPERIENCE · FOLLOWERSd
VALENCE
VARIANCE
ORDER
NEWSFEED
Number of individuals Number of books Number of observations MAD RMSE

0.0116a [0.0029, 0.0328]
-0.0354a [-0.1011, -0.0069]
-0.0013 [-0.0297, 0.0246]
-0.0066 [-0.0667, 0.0443]
-0.3539 [-3.8025, 3.3082]
0.1089 [-3.9342, 3.9681]
0.000 [-0.0445, 0.0466]
0.000 [-0.0168, 0.0162]
1.4713c [-0.132, 3.06]
-0.5109 [-1.186, 0.1264]
-0.3922a [-1.4066, -0.0833]
-0.0027 [-0.0115, 0.003]
4,550 14,422 87,946 1.0875 1.5289

0.0080a [0.0018, 0.0225]
-0.0178b [-0.0561, -0.0013]
0.0022 [-0.0101, 0.0216]
0.0260b [0.002, 0.0853]
-0.1209 [-3.6179, 3.5627]
-0.2357 [-3.8121, 3.5688]
0.0003 [-0.0502, 0.0529]
0.009 [-0.004, 0.0319]
1.4265c [-0.1553, 3.0062]
-0.5345c [-1.1409, 0.0785]
-0.2971a [-1.0512, -0.0702]
-0.0054 [-0.02, 0.0013]
4,550 14,422 87,946 1.0873 1.5291

Note. The 95% Bayesian credible intervals are reported in brackets. aIndicates that 0 is not contained in the 99% Bayesian credible interval. bIndicates that 0 is not contained in the 95% Bayesian credible interval. cIndicates that 0 is not contained in the 90% Bayesian credible interval. dEXPERIENCE and FOLLOWERS both have a 2 day lag in this interaction for all models.

review, a binary indicator representing whether the review was categorized as "informative" according to either of two criteria: the review contains informative text with respect to the specific book or it helps provide general information in selecting books. To maintain comparability with previous models, we aggregate to the level of the focal individual community member, creating two variables: (a) the number of informative reviews posted by friends (FRIENDSREVIEWTEXT) and (b) the number of informative reviews posted by sources (SOURCESREVIEWTEXT). We then use these measures (lagged accordingly) in our analysis, replacing, as a proxy for information, the number of friends and sources.
Our results (available in Online Appendix B) provide additional evidence that decisions may improve when

consumers are exposed to relevant information posted by their sources. To summarize, we find that, initially, informative reviews from sources lead to decreased ratings. While the effect of friends is not significant, this is consistent with the prediction that weak ties provide information that is initially not as beneficial as that from strong ties. Most importantly, for sources, we find evidence of the importance of learning. Specifically, the interaction between experience and the number of informative reviews from sources is both significant and positive. This suggests that consumers benefit from exposure to useful information from weak ties given that they have first developed sufficient experience. Overall, our results from this analysis provide additional evidence that it is indeed information that is being provided by weak ties that leads to improved

440

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

decisions. Moreover, this information is only useful conditional on sufficient learning.
6.4. Alternative Measures of Learning Our main results in Table 3 are derived using the number of rating sessions as a proxy for learning. As we describe in Section 3, we see this as a learning-bydoing process (Foster and Rosenzweig 1995) in which one "experiments" (uses some information, perhaps by paying specific attention to a small set of ties or trying a new genre she has never considered), learns, and then adjusts. This adjustment might mean listening more to some people than others and/or digging deeper into some genres or authors than others. According to the theory, this process leads to the most significant improvement the more the experimentation­learning­ adjustment loop iterates, reflecting the idea that the individual has learned and has put that learning to a test (reflected in a review session). Given this, we have chosen the number of reviewing sessions as the best dynamic measure of one's ability to use the information. Of course, however, as is the case of all proxies, the number of sessions is an imperfect means of capturing actual learning. Thus, here, we consider other possible proxies. For sake of exposition, we discuss here only the key results of this robustness investigation. The details, along with the results, can be found in Online Appendix C. One measure we consider is the cumulative total number of reviews the focal individual i has posted up to time t.25 As a second alternative, we collect all of individual i's activities on the platform. In addition to posting reviews and ratings, for example, individuals can also post the books they have read or are planning to read (i.e., without a rating). We then use the number of active sessions that an individual engages in. We expect this proxy to be somewhat less useful, as we assume that these nonrating activities may not necessarily be indicative of the experimentation­learning iteration loop. Other experience proxies we considered include the time since the user joined Goodreads, as well as an indicator capturing whether user i has made a social network tie up to time t. TIME_SINCE_JOINED is calculated as the time between individual i's Goodreads sign-up date and time t. We expect that these latter proxies may not accurately incorporate decision-making situations and thus the learning that comes with them. This detail is important because our theory is based on the assumption that decision making is most likely to improve as a result of feedback from previous choices and not just passing time.
The key takeaways from these analyses are that (a) models estimated using proxies of actual decisionmaking activities (i.e., the number of reviews and the number of review/posting sessions) yield results similar to those in Table 3, especially in terms of the

impact on decision quality of the formation of ties with sources, and (b) none of these models fits (using root mean squared error (RMSE) and mean absolute deviation (MAD) metrics) as well as the model using reviewing sessions as the learning proxy. Indeed, even the most-obvious and reasonable alternative to review sessions, number of reviews, is a less effective measure of learning. We expect that one reason for this is that it may give the member too much credit for learning in situations in which she has written many reviews in a short period of time. Such a pattern may imply fewer iterations of the experimentation­feedback cycle and less learning. For example, we expect that a member would likely have experienced more learning after posting five sequential reviews than would be the case had she posted five reviews all at once (the latter reflecting, by assumption, books purchased and read over a shorter period of time and thus less likely to have incorporated feedback from previous experiences). Note that the former would be coded as five review sessions, while the latter would be coded as only one review session. We highlight that a number of the measures--including, for example, a social network dummy--do not fit very well at all, at least in comparison. For this measure and the time since joined proxy, this is not necessarily surprising since, due to the lack of decision-making situations embedded in the measure, we do not expect that they capture well the underlying theoretical construct. Please see Online Appendix C for more details on, and the results of, these analyses.
7. Discussion: The Learning Process
While our results suggest that new members in a community undergo learning by doing before benefiting from the information they acquire, the specific nature of the learning process is not entirely clear. For example, learning may be about selecting better books and/or selecting better ties.26 We note that each mechanism is entirely consistent with our theory. While we are constrained by our limited observational data in conducting a rigorous analysis of the learning process, we present here an exploratory model-free investigation of the specific nature of the mechanism. A typical approach in the learning literature in studies using observational data is to plot the data to see if there is any change in behavior over time. For example, Goettler and Clay (2011) perform similar analyses and propose alternative explanations for the patterns they observe in the data. We take an analogous approach here. In Figure 6(a), we plot the average entropy across genres for books posted by the focal users across levels of experience. Entropy measures the dispersion of books across genres independent of the total volume of books (Godes and Mayzlin 2004) and helps us assess whether individuals are choosing a wider or narrower

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

441

Figure 6. (Color online) (a) Entropy of Books Posted by Focal Users and (b) Entropy of Books Posted by Friends and Sources

(a) Entropy of books across genres

1.4

1.2

1.0

0.8

0.6

0.4

R 2 = 0.5144

0.2

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21
Experience (# of review sessions)

(b) Entropy of books across genres from

newly acquired ties

4.5

4.0

R 2 = 0.7306

3.5

3.0

R 2 = 0.091

2.5

2.0 1.5

1.0

0.5
0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21

Experience (# of review sessions)

Focal users

Friends

Sources

Notes. Entropy measures the dispersion of books across genres and helps us assess whether individuals are choosing a wider or narrower

range of books as they accumulate experience. At each rating session (measured for each individual), in panel (a), we calculate the entropy for

all newly rated books posted by the focal user during the rating session associated with that level of experience as -

G g

1(BOOKig /BOOKi )

×

log(BOOKig/BOOKi), where BOOKig is the number of books in genre g, and BOOKi is the total number of books. In panel (b), entropy is

calculated for all newly rated books posted by the focal user's new friends and sources added during the rating session associated with that

level of experience. For each rating session, we report the average entropy for all individuals.

range of books as they accumulate experience. In Figure 6(b), on the other hand, we plot the entropy across genres of books reviewed by each new friend and new source added at each rating session period (calculated in the same manner as in Figure 6(a)). If consumers are learning how to select "better" friends or sources, then we might expect changes in the mix of books chosen by these friends or sources. Similarly, if there is learning with respect to book selection, then we would expect changes in the selection of books over time. Figure 6(a) and 6(b) show a decline in entropy in the books posted by the focal individual--converging to a narrower mix of genres--but no change in entropy of the books posted by one's sources. We do observe an increase in entropy of books posted by friends. One interpretation of this may be that learning is associated with a narrowing of the types of books purchased and a broadening of the types of ties formed. We stress that this is very exploratory and that learning about books and learning about ties are both consistent with our theory. We see this as a promising area of future research to identify contexts in which learning about one or the other would dominate.
8. Conclusion
In this paper, we study the relationship between one's online social network and decision quality: to what extent does forming new ties, and capturing information from those ties, lead to better decisions? We focus our investigation on two moderating factors: (i) learning and (ii) the source of the tie, which we suggest captures the interpretability of the information the tie provides. After controlling for the ratings environment, individual-level factors, book-level dynamics, reputation effects, and, importantly, the potential endogeneity

introduced by network variables, our results suggest that increasing the number of social network relationships may, in some cases, be associated with better decisions. Initially, as consumers add more friends (strong ties), they may experience higher decision quality, as seen in the positive coefficients on FRIENDS in Table 3. However, adding more sources (weak ties) may lead to lower decision quality, as shown in the negative coefficients on SOURCES in Table 3. Counter to the extant literature, this suggests that in the early days in one's membership in a community, weak ties may be less helpful than strong ties. In the long run, however, as one gains more experience in the network, forming more weak ties is associated with better decisions. This is captured in the positive coefficients on the EXPERIENCE × SOURCES interaction, where EXPERIENCE is a proxy for learning. We expect that this result derives from the fact that weak ties may be a good source for novel information, but that this information may also initially be more difficult to interpret and use compared with information from strong ties. Thus, weak ties provide more useful information than strong ties only for experienced users, those who have accumulated sufficient learning.
We suggest three implications for our findings. First, consumer learning leads to better decisions as a result of the formation of online ties. Second, we show that online opinions are not always beneficial to consumers in the short run, as opinions from weak ties may initially decrease decision quality. Third, information from new ties is most useful after consumers learn to interpret the information to make better decisions. This research, we believe, is the first to show these dynamic individual-level learning effects and to suggest a negative short-term impact associated with online opinions.

442

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

Our results suggest that managers who would like to improve consumer decision quality may invest in helping consumers to quickly learn how to process and make use of other consumers' opinions. Such investments may be as simple as building a social network, as we observe in Goodreads, or providing better online help utilities, more information about other members, and/or better search functionality.
Our research is, of course, not without its limitations. First, we are able to estimate only aggregate-level parameters for social network ties. A second important limitation is that we do not know which reviews are viewed, how these reviews are weighted, or the precise source of learning. It might be interesting to use modern eye-tracking techniques to identify the specific sources of information that go into the consumer's decision-making process as they develop their social network and make decisions based on others' opinions. Third, we acknowledge that our measures are imperfect. While we expect, for example, that the number of reviewing sessions is theoretically appealing given its reflection of learning by doing, it is unclear how much learning is captured using this proxy. Future research could try to identify better empirical measures. Fourth, it is interesting to note that our results for sources appear to be more robust (compared with those for friends) to the empirical operationalization of information. One possible explanation might be that consumers interact with their strong ties in many more ways than simply reading reviews. For example, one might call their friends on the phone to discuss the latest novels. Alternatively, a person might be able to better interpret other nonreview information posted by friends (such as a book added to a to-read list) and make decisions based on that information. This would be an interesting avenue for future research. Finally, we acknowledge that our use of rating as a proxy for decision quality is imperfect. It would be useful to identify both additional measures and alternative research settings (for example, experimental methods) that would allow for a more direct assessment of decision quality.
Acknowledgments The authors thank Ginger Jin, P. K. Kannan, Dina Mayzlin, Wendy Moe, Michael Trusov, Michel Wedel, and participants at the 2012 Marketing Science Conference, Georgetown University Marketing Seminar, Santa Clara University Marketing Seminar, Drexel Marketing Seminar, and Laurier Marketing Research Symposium for helpful feedback.
Endnotes
1 In another related paper, Zhao et al. (2013) find that consumers place more emphasis in a choice context on information from online reviews than past experiences with comparable products. Our papers should be seen as complements in that (i) Zhao et al. (2013) study the effects of reviews on choice, while the outcome with which we are interested is the quality of purchase decisions; and (ii) the learning effects in their paper are with respect to preferences

for products and product categories, while our conceptual model reflects learning about how to make use of the information made available by new network ties.
2 Most individuals passively observe (i.e., "lurk"), but do not actively participate in, online forums or discussions (see, e.g., the "90-9-1 rule for participation"; Nielson 2006).
3 We note that the measures in Table 1 may be different from those reported in our main sample of users because Table 1 reports characteristics of a set of consumers who have already formed connections. Consumers with ties may post higher or lower ratings, resulting in a difference in the reported statistics (compared with our main sample). The summary statistics for the main sample are reported later in Section 4.
4 Moreover, and perhaps more important, we only observe daily time stamps for a review, precluding our ability to accurately order reviews that arrived on the same day.
5 We thank the associate editor for this suggestion.
6 The majority (90%) of our users had fewer than 11 review sessions, so this defines the domain of Figure 5(b). We thank an anonymous reviewer for this suggestion.
7 It is also possible that consumers use a nonrandom "filter" to decide which experiences they will provide ratings for (Ying et al. 2006, Li and Hitt 2008, Moe and Schweidel 2012). We do not explicitly model this filter. However, as our focus is on the change in decision quality as one uses information from her social ties, we implicitly assume that each individual's filter remains constant throughout our study. In particular, we assume that neither experience with the platform nor the development of new ties will change this filter.
8 We mean center all variables in this paper.
9 We thank an anonymous reviewer for this suggestion.
10 Please refer to Hartmann et al. (2008) and Nair et al. (2010) for general treatments of identification issues in settings characterized by social interactions.
11 We thank an anonymous referee for highlighting this.
12 To be specific, let EXPERIENCEit TIMESPENTit + it and OUTNETit TIMESPENTit + it , where TIMESPENTit and OUTNETit represent the time spent on the platform and out-of-network information, respectively. Then, including EXPERIENCE but omitting OUTNET in a simplified estimation model implies EVALibt 0TH +  ·TIMESPENTit +1 ·FRIENDSLit +it , where the error term it  it +  · it + it . As long as neither the measurement error it nor it is correlated with the observed network variables, this would yield consistent estimates.
13 The number of categories needs to be equal to or greater than two for identification purposes; however, the model is robust against misspecification of the number of categories (Ebbes 2004). We follow Ebbes (2004), Ebbes et al. (2005), and Rutz et al. (2012) and set the number of categories to be two. For more details on identifiability of the LIV, please refer to Ebbes (2004) and Ebbes et al. (2005).
14 Note that, in the ordered probit model, we set  1 for identification purposes. However, this constraint prevents us from estimating  using the traditional Gibbs sampler. Therefore, we relax this constraint and let  vary and identify valid posterior estimates through postprocessing of the posterior draws (McCulloch and Rossi 1994, Edwards and Allenby 2003). While the posterior estimates for will not converge because  is not identifiable, the posterior for /  across all iterations is identified and converges. Thus, after estimation, we set  1 and scale all other parameters accordingly. Therefore, we report the values of the postprocessed  as the mean of the converged posterior for /  .
15 Note that this data collection was performed after the end of the observation period, and we are therefore unable to determine the timing of network formation for i's friends.

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

443

16 The variables in Table 3 are prestandardized. 17 Users may also modify their ratings because of reputational effects from sources as well because sources can potentially turn into friends. (We thank an anonymous reviewer for this insight.) As such, we recognize that the EXPERIENCE × SOURCES interaction may also potentially be affected by a reputational effect. Given that our results and the literature (e.g., Moe and Schweidel 2012, Schlosser 2005) consistently demonstrate that such factors elicit negative effects on reported ratings, the positive effect on sources may thus be an understatement of the effect on decision quality of information from weak ties. 18 From lag 2 to lag 12, zero is not contained in the 95%, 95%, 96%, 95%, 94%, 92%, or 93% Bayesian credible interval. Thus, the significance levels for the coefficient estimates, across lags, on this variable seem to be relatively comparable. 19 These variables are lagged 10 days. The results for shorter lags are similar (available from the authors). Longer lags do not yield significant results, possibly because of the increasingly fragmented data and reduced degrees of freedom. 20 These changes are migrations within a specific dyadic tie: those cases in which A was B's source and eventually became B's friend. 21 The 95% Bayesian confidence interval of the former does not overlap with that of the latter. In addition, a t-test between the differences of the means for each set of posterior estimates produces a p-value < 0.001. 22 We thank the reviewers for this suggestion. 23 Another potential source of dynamics in decision quality may relate to changes in the information made available by ties. In particular, the accuracy of the information provided by friends and sources may improve as their experience evolves. To test for this, we reestimate Model 3 and include separately the experience levels of friends and sources as control variables (also lagged). These variables thus capture the possibly improving value of the information provided by friends and sources. The results (see Table D.4 in Online Appendix D) show that these variables are generally not significant. Importantly, however, our core results remain even with these covariates included. 24 To compare the models, we forecast ratings for a holdout sample, as the deviance information criterion may be problematic for mixture models such as that used in the LIV approach (Spiegelhalter et al. 2002). We use all observations that occur within the first five weeks as calibration and the remaining observations (two weeks) as the holdout sample. We generate a ratings forecast for each holdout observation using the posterior from our model estimates. This is done for each set of posterior estimates across 5,000 iterations. We use the forecast to calculate MAD and RMSE and present the average MAD and RMSE across each of the 5,000 iterations and across all observations. 25 We thank an anonymous reviewer for this suggestion. 26 We thank an anonymous reviewer for raising this issue and providing helpful ideas to investigate.
References
Alba JW, Hutchinson JW (1987) Dimensions of consumer expertise. J. Consumer Res. 13(4):411­454.
Albert JH, Chib S (1993) Bayesian analysis of binary and polychotomous response data. J. Amer. Statist. Assoc. 88(422):669­679.
Anzai Y, Simon HA (1979) The theory of learning by doing. Psych. Rev. 86(2):124­140.
Bollinger B, Gillingham K (2012) Peer effects in the diffusion of solar photovoltaic panels. Marketing Sci. 31(6):900­912.
Borgatti SP, Cross R (2003) A relational view of information seeking and learning in social networks. Management Sci. 49(4):432­445.

Boser BE, Guyon IM, Vapnik VN (1992) A training algorithm for optimal margin classifiers. Proc. Fifth Annual Workshop Comput. Learning Theory (ACM, New York), 144­152.
Brooks SP, Gelman A (1998) General methods for monitoring convergence of iterative simulations. J. Comput. Graphical Statist. 7(4): 434­455.
Brown JJ, Reingen PH (1987) Social ties and word-of-mouth referral behavior. J. Consumer Res. 14(3):350­362.
Burt R (1995) Structural Holes: The Social Structure of Competition (Harvard University Press, Cambridge, MA).
Chen Y, Wang Q, Xie J (2011) Online social interactions: A natural experiment on word of mouth versus observational learning. J. Marketing Res. 48(2):238­254.
Chevalier J, Mayzlin D (2006) The effect of word of mouth on sales: Online book reviews. J. Marketing Res. 43(3):345­354.
Chintagunta PK, Gopinath S, Venkataraman S (2010) The effects of online user reviews on movie box office performance: Accounting for sequential rollout and aggregation across local markets. Marketing Sci. 29(5):944­957.
Clemons E, Gao G, Hitt L (2006) When online reviews meet hyperdifferentiation: A study of the craft beer industry. J. Management Inform. Systems 23(2):149­171.
Collingwood L, Wilkerson J (2012) Tradeoffs in accuracy and efficiency in supervised learning methods. J. Inform. Tech. Politics 9(3):298­318.
Cortes C, Vapnik V (1995) Support-vector networks. Machine Learning 20(3):273­297.
Dellarocas C, Zhang X, Awad NF (2007) Exploring the value of online product reviews in forecasting sales: The case of motion pictures. J. Interactive Marketing 21(4):23­45.
Du R, Kamakura W (2011) Measuring contagion in the diffusion of consumer packaged goods. J. Marketing Res. 39(2):28­47.
Duan W, Gu B, Whinston AB (2008) The dynamics of online wordof-mouth and product sales­an empirical investigation of the movie industry. J. Retailing 84(2):233­242.
Ebbes P (2004) Latent instrumental variables: A new method to solve endogeneity in marketing and economics. Unpublished doctoral thesis, University of Groningen, Groningen, Netherlands.
Ebbes P, Wedel M, Bockenholt U, Steerneman T (2005) Solving and testing for regressor-error (in)dependence when no instrumental variables are available: With new evidence for the effect of education on income. Quant. Marketing Econom. 3(4):365­392.
Edwards Y, Allenby G (2003) Multivariate analysis of multiple response data. J. Marketing Res. 40(3):365­392.
Foster AD, Rosenzweig MR (1995) Learning by doing and learning from others: Human capital and technical change in agriculture. J. Political Econom. 103(6):1176­1209.
Gelfand AE, Smith AFM (1990) Sampling-based approaches to calculating marginal densities. J. Amer. Statist. Assoc. 85(410):398­409.
Gelman A, Rubin D (1992) Inference from iterative simulation using multiple sequences. Statist. Sci. 7(4):457­472.
Godes D, Mayzlin D (2004) Using online conversations to study word-of-mouth communication. Marketing Sci. 23(4):545­560.
Godes D, Silva J (2012) Dynamics of online opinion. Marketing Sci. 31(3):448­473.
Goettler R, Clay K (2011) Tariff choice with consumer learning and switching costs. J. Marketing Res. 48(4):633­652.
Granka LA, Joachims T, Gay G (2004) Eye-tracking analysis of user behavior in WWW search. Proc. 27th Annual Internat. ACM SIGIR Conf. Res. Development Inform. Retrieval (ACM, New York), 478­479.
Granovetter MS (1973) The strength of weak ties. Amer. J. Sociol. 78(6): 1360­1380.
Hartmann W, Manchanda P, Nair H, Bothner M, Dodds P, Godes D, Hosanagar K, Tucker C (2008) Modeling social interactions: Identification, empirical methods and policy implications. Marketing Lett. 19(3/4):287­304.
Hsu CW, Chang CC, Lin CJ (2003) A practical guide to support vector classification. Working paper, National Taiwan University, Taipei, Taiwan.

444

Zhang and Godes: Learning from Online Social Ties Marketing Science, 2018, vol. 37, no. 3, pp. 425­444, © 2018 INFORMS

Johnson EJ, Bellman S, Lohse GL (2003) Cognitive lock-in and the power law of practice. J. Marketing 67(2):62­75.
Jurka TP, Collingwood L, Boydstun AE, Grossman E, van Atteveldt W (2013) RTextTools: A supervised learning package for text classification. R Journal 5(1):6­12.
Krackhardt D (1992) The strength of strong ties: The importance of philos in organizations. Nohria N, Eccles R, eds. Networks and Organizations: Structure, Form, and Action (Harvard Business School Press, Boston), 216­239.
Levin DZ, Cross R (2004) The strength of weak ties you can trust: The mediating role of trust in effective knowledge transfer. Management Sci. 50(11):1477­1490.
Li X, Hitt LM (2008) Self-selection and information role of online product reviews. Inform. Systems Res. 19(4):456­474.
Lin N, Ensel WM, Vaughn JC (1981) Social resources and strength of ties: Structural factors in occupational status attainment. Amer. Sociol. Rev. 46(4):393­405.
Liu Y (2006) Word of mouth for movies: Its dynamics and impact on box office revenue. J. Marketing 70(3):74­89.
McCulloch R, Rossi P (1994) An exact likelihood analysis of the multinomial probit model. J. Econometrics 64(1­2):207­240.
McPherson M, Smith-Lovin L, Cook JM (2001) Birds of a feather: Homophily in social networks. Annual Rev. Sociol. 27:415­444.
Miravete E (2003) Choosing the wrong calling plan? Ignorance and learning. Amer. Econom. Rev. 93(1):297­310.
Moe WW, Schweidel DA (2012) Online product opinions: Incidence, evaluation, and evolution. Marketing Sci. 31(3):372­386.
Moe WW, Trusov M (2011) The value of social dynamics in online product ratings forums. J. Marketing Res. 48(3):444­456.
Morahan-Martin JM (2004) How Internet users find, evaluate, and use online health information: A cross-cultural review. Cyberpsych. Behav. 7(5):497­510.
Nair HS, Manchanda P, Bhatia T (2010) Asymmetric social interactions in physician prescription behavior: The role of opinion leaders. J. Marketing Res. 47(5):883­895.
Newell A, Rosenbloom P (1981) Mechanisms of skill acquisition and the law of practice. Anderson JR, ed. Cognitive Skills and Their Acquisition (Lawrence Erlbaum Associates, Hillsdale, NJ), 1­55.
Nielson J (2006) The 90-9-1 rule for participation inequality in social media and online communities. Accessed April 16, 2018, https://www.nngroup.com/articles/participation-inequality/.

Nokes TJ, Ohlsson S (2005) Comparing multiple paths to mastery: What is learned? Cognitive Sci. 29(5):769­796.
Oestreicher-Singer G, Sundararajan A (2012) The visible hand? Demand effects of recommendation networks in electronic markets. Management Sci. 58(11):1963­1981.
Rossi PE, Gilula Z, Allenby GM (2001) Overcoming scale usage heterogeneity: A Bayesian hierarchical approach. J. Amer. Statist. Assoc. 96(453):20­31.
Rutz OJ, Bucklin RE, Sonnier GP (2012) A latent instrumental variables approach to modeling keyword conversion in paid search advertising. J. Marketing Res. 49(3):306­319.
Schlosser AE (2005) Posting versus lurking: Communicating in a multiple audience context. J. Consumer Res. 32(2):260­265.
Shriver S, Nair H, Hofstetter R (2013) Social ties and user-generated content: Evidence from an online social network. Management Sci. 59(6):1425­1443.
Spiegelhalter D, Best N, Carlin B, Van Der Linde A (2002) Bayesian measures of model complexity and fit. J. Roy. Statist. Soc.: Ser. B (Statist. Methodology) 64(4):583­639.
Sun M (2012) How does variance of product ratings matter? Management Sci. 58(4):696­707.
Sun N, Rau PPL, Ma L (2014) Understanding lurkers in online communities: A literature review. Comput. Human Behav. 38:110­117.
Tanner MA, Wong WH (1987) The calculation of posterior distributions by data augmentation. J. Amer. Statist. Assoc. 82(398): 528­540.
Toubia O, Stephen A (2013) Intrinsic versus image-related motivations in social media: Why do people contribute content to Twitter? Marketing Sci. 32(3):365­367.
Wu F, Huberman BA (2008) How public opinion forms. Internet Network Econom. 5385:334­341.
Ying Y, Feinberg F, Wedel M (2006) Leveraging missing ratings to improve online recommendation systems. J. Marketing Res. 43(3):355­365.
Zhang J, Wedel M, Pieters R (2009) Sales effects of attention to feature advertisements: A Bayesian mediation analysis. J. Marketing Res. 46(5):669­681.
Zhao Y, Yang S, Narayan V, Zhao Y (2013) Modeling consumer learning from online product reviews. Marketing Sci. 32(1):153­169.

