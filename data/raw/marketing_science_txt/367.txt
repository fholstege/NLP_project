Vol. 33, No. 2, March­April 2014, pp. 222­240 ISSN 0732-2399 (print) ISSN 1526-548X (online)

http://dx.doi.org/10.1287/mksc.2013.0835 © 2014 INFORMS

Analyzing Moment-to-Moment Data Using a
Bayesian Functional Linear Model:
Application to TV Show Pilot Testing
Sam K. Hui, Tom Meyvis, Henry Assael
Stern School of Business, New York University, New York, New York 10012 {khui@stern.nyu.edu, tmeyvis@stern.nyu.edu, hassael@stern.nyu.edu}
Researchers often collect continuous consumer feedback (moment-to-moment, or MTM, data) to understand how consumers respond to a variety of experiences (e.g., viewing a TV show, undergoing a colonoscopy). Analyzing how MTM judgments are integrated into overall evaluations allows researchers to determine how the structure of an experience influences consumers' post-experience satisfaction. However, this analysis is challenging because of the functional nature of MTM data. As such, previous research has typically been limited to identifying the influence of heuristics, such as relying on the average intensity, peak, and ending.
We develop a Bayesian functional linear model to study how the different "moments" in the MTM data contribute to the overall judgment. Our approach incorporates a (temporally) weighted average of MTM data as well as specific "patterns" such as peak and trough, thus nesting previous approaches such as the "peak-end" rule as special cases. We apply our methodology to analyze data on TV show pilots collected by CBS. Our results reveal several interesting empirical findings. First, the last quintile of a TV show is weighted about four times as much as each of the first four quintiles. Second, patterns such as peak and trough do not play substantial roles in driving overall evaluations for TV shows. Finally, the last quintile is more important for procedural dramas than for serial dramas. We discuss the managerial implications of our results and other potential applications of our general methodology.
Keywords: moment-to-moment data; functional data analysis; Bayesian functional linear model; TV show pilot testing; peak-end rule
History: Received: January 5, 2013; accepted: November 10, 2013; Preyas Desai served as the editor-in-chief and Michel Wedel served as associate editor for this article. Published online in Articles in Advance January 10, 2014.

1. Introduction
Marketing researchers often use continuous consumer feedback to track the progression of consumers' responses to a variety of experiences. This continuous feedback is then used to craft more effective advertisements or to create better consumer experiences. For instance, advertising researchers examine consumers' moment-to-moment emotional response to commercials to identify ways to design more effective ads (Baumgartner et al. 1997; Polsfuss and Hess 1991; Woltman Elpers et al. 2003, 2004). Similarly, television networks test new shows by asking viewers to provide real-time feedback using an electronic dial (e.g., Perception Analyzer; see http://www .perceptionanalyzer.com). Show producers then use these data to identify parts of the show that viewers like or dislike and fine-tune the script accordingly.
Aside from its use by marketing researchers to create more effective ads or more enjoyable consumer experiences, continuous consumer feedback is also used in other domains, such as politics and medicine. In politics, undecided voters who watch political

debates are asked to provide continuous ratings of their reactions, which are then used to assess voters' sentiments about various political issues (Correll et al. 2004, Kirk and Shrill 2011); in medicine, researchers continuously record the intensity of pain experienced by patients undergoing medical procedures to construct a "pain profile" and to find ways to minimize the remembered unpleasantness of the medical procedure (Lewis et al. 1995, Redelmeier et al. 2003).
Each of above examples involves the collection and analysis of continuous moment-to-moment (MTM) feedback, denoted as (x t t  0 T ), along with an overall evaluation y. As a concrete example, Figure 1 shows a few data samples collected during a TV show pilot test conducted by CBS that will be analyzed in our empirical application. Depending on the specific setting, the MTM measure may correspond to subjective liking, persuasiveness of an argument, or physical pain. By measuring consumers' reactions during the experience, researchers can identify parts of the experience that stand out (e.g., scenes from a show that are particularly enjoyable, parts of the medical procedure

222

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model Marketing Science 33(2), pp. 222­240, © 2014 INFORMS
Figure 1 Moment-to-Moment Dial Data for Five Individuals

80 60 40 20
0
90 70 50 30
0
80 60 40 20
0
80 60 40 20
0

500

1,000

1,500

2,000

500

1,000

1,500

2,000

500

1,000

1,500

2,000

500

1,000

1,500

2,000

223
Overall rating = 3 2,500
Overall rating = 3 2,500
Overall rating = 5 2,500
Overall rating = 1 2,500

70

50

30

0

500

1,000

Note. Data were collected from a TV show pilot study conducted by CBS.

1,500

2,000

Overall rating = 3

that are particularly painful). Moreover, by relating these MTM reactions to overall judgments, researchers can also determine how specific patterns and features of the experience influence subsequent judgments and behaviors (e.g., how does the enjoyment of a show over time influence viewers' attitude toward, and subsequent exposure to, that show?).
Understanding how MTM measurements x t are aggregated into an overall judgment y has important managerial implications. For instance, in the context of TV shows, if viewers systematically overweight later parts of a show, show producers may want to

devote more resources to improving the end of the show, including possibly shifting the funniest jokes or most exciting scenes toward the end. Similarly, in medical research, understanding how a pain profile is integrated into an overall pain assessment may help medical professionals adjust medical procedures to reduce patients' recalled averseness of the procedure. For instance, Redelmeier et al. (2003) observed that extending a colonoscopy by adding a less painful procedure at the end reduces the patient's overall pain assessment and increases his or her intention to return for another colonoscopy.

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

224

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

Estimating the relationship between x t and y is challenging because the independent variable x t is a function rather than a scalar, and thus it involves functional data analysis issues (Ramsay and Silverman 2005). Fundamentally, the biggest challenge is that x t is often of very high dimensionality, or even of infinite dimensionality in the case of truly continuous measurement. In the TV pilot show data that we analyze in §5, MTM dial ratings are recorded second by second, resulting in approximately 2,500 measurements in each profile. The high dimensionality of x t makes it difficult to accurately estimate the contribution of each moment to the overall evaluation. Furthermore, previous research suggests that y may be related to x t not only through the temporal average of x t but also through certain specific patterns of x t , such as the peak (maxt x t ), the trough (mint x t ), and the end (x T ). Because of these methodological challenges, previous research has typically bypassed the difficulty of specifying a formal statistical model of how x t is integrated into y; instead, such research has examined how y relates to summary descriptors of the x t function, such as the unweighted average of x t (Aaker et al. 1986, Polsfuss and Hess 1991, Thorson and Friestad 1989) or the "peak-end rule" (Baumgartner et al. 1997, Fredrickson and Kahneman 1993, Redelmeier and Kahneman 1996).
In this paper, we propose a formal Bayesian functional linear model to study how MTM data are aggregated into overall evaluations. We begin by assuming that the overall evaluation y is driven by a (temporally) weighted average of x t , where the weights are defined by a weighting function h t . We then approximate h t using a step function and specify a random walk prior (West and Harrison 1997) on the function value at each interval. This nonparametric specification puts a "smoothness prior" on h t , which allows us to estimate h t flexibly without making any a priori functional form assumptions. Next, we further extend our model to allow for the additional roles of specific patterns in x t (e.g., peak, trough). As such, our model nests existing models, such as the peak-end rule and the unweighted average, as special cases.
To ensure that our proposed approach is able to recover the weighting function h t and other model parameters given the available data, we conduct a set of simulation studies in §4. Next, we apply our proposed method to analyze data from 3,572 participants who took part in a series of TV show pilot tests conducted by CBS, a major national TV network. We demonstrate that our proposed approach outperforms alternative heuristics-based methods in a holdout prediction study. Our results reveal several empirical insights. First, the last quintile of the show

is weighted around four times as much as each of the first four quintiles. Second, in contrast to findings in the context of commercials (Baumgartner et al. 1997), we find that specific patterns such as the peak or trough do not play substantial roles in driving overall judgments in the context of TV shows. Third, the last quintile is more important for procedural dramas than for serial dramas.
Our paper aims to make both a methodological and a substantive contribution. At a methodological level, we develop a formal Bayesian functional modeling approach to analyze how MTM data are integrated into overall judgments. Our approach is general enough to be directly applied to other applications that involve the collection of MTM data. At a substantive level, we apply our proposed method to a real-world data set that captures MTM dial ratings from a TV show pilot test, allowing us to better understand how viewers' overall evaluation of a TV show may be improved by changing the temporal structure of the show. In doing so, we contribute to the ongoing debate about the generality and boundary conditions of peak and end effects (e.g., Miron-Shatz 2009). Moreover, our findings also have direct implications for broadcasters seeking to raise advertising revenues. We show that the show likeability ratings are strongly linked to subsequent Nielsen ratings, which are the currency for up-front negotiations regarding ad expenditures on TV shows. Thus, if an improvement in show structure succeeds in improving likeability, and thereby Nielsen ratings, then this has direct cost implications for advertisers and revenue implications for the network.
The remainder of the paper is organized as follows. Section 2 begins with an overview of MTM data and functional data analysis in marketing. In §3, we propose a Bayesian functional linear model to analyze MTM data. In §4, we conduct simulation studies to ensure that our proposed model is able to accurately recover the weighting function h t and other model parameters. In §5, we apply our proposed model to analyze actual data from CBS. Finally, §6 concludes with directions for future research.
2. Background: Moment-to-Moment Data and Functional Data Analysis
We provide an overview of previous research that has collected and analyzed MTM data (with a focus on marketing applications), followed by a brief review of functional data analysis.
2.1. Collection and Analysis of MTM Data in Marketing
Marketing researchers have long been collecting MTM data to better understand consumers' reactions to television commercials. Baumgartner et al. (1997) used

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

225

a computerized "feelings monitor" to track participants' MTM liking of a commercial and showed that overall ad judgment is strongly correlated with the peak emotional experience and the final moment of the series. Similarly, in Polsfuss and Hess (1991), participants used a wireless handheld device to indicate their MTM evaluations while viewing a commercial. The authors then used the resulting data to pinpoint the "key selling seconds" of a commercial and to predict the overall liking of the commercial. They found that the overall liking of a commercial advertisement is closely related to the average of MTM ratings. Finally, Ramanathan and McGill (2007) extended this research to the domain of social influences by studying how MTM evaluations of a commercial are affected by the social presence of other consumers. They found that joint consumption of an experience leads to similar MTM patterns and more positive retrospective evaluations.
MTM data are also used to capture concepts other than subjective liking. For instance, Woltman Elpers et al. (2003) collected MTM ratings of "entertainment" and "information" value as participants viewed a commercial; these authors showed that these two types of MTM ratings have a strong multiplicative effect on consumers' likelihood to continue watching a commercial. This is conceptually similar to the work by Hughes (1992), who continuously tracked consumers' affective and cognitive reactions to measure the wearout of a commercial over time. Other MTM measures that have been collected in the previous literature include humor (Woltman Elpers et al. 2004), warmth (Aaker et al. 1986, Vanden Abeele and MacLachlan 1994), and fear and hope (Madrigal and Bee 2005).
Recent technological advances have enabled marketing researchers to measure other types of MTM data beyond self-reported judgments. Using an automated facial-expression detection device, Teixeira et al. (2012) measured the MTM intensity of joy and surprise expressed by participants who were watching Internet video advertisements. The authors then related these MTM emotional intensities to attention and concentration (captured using eye-tracking data) as well as to viewing behavior (the timing of participants "zapping" the ad). Using a dynamic frailty model, they found that the emotions of surprise and joy effectively concentrate attention and retain viewers. Based on these results, Teixeira et al. derived the "optimal emotion trajectories" to aid effective TV advertisement designs.
In most of the above examples, the goal of the research is to study how MTM measures (e.g., humor, liking, warmth) are integrated into a scalar dependent variable of interest (e.g., humorousness of the ad, attitude toward the ad). Given that a standard,

off-the-shelf methodology that relates a functional independent variable x t to a scalar dependent variable y is generally unavailable, researchers have typically relied on heuristics-based approaches such as computing the overall average or using the peakend rule. However, analyzing how a continuous function is aggregated into a scalar dependent variable is closely related to an active research area in statistics known as functional data analysis, which suggests a more comprehensive alternative approach. We review this research next.
2.2. Applications of Functional Data Analysis in Marketing
Functional data analysis (Jank and Shmueli 2006, Ramsay and Silverman 2005) refers to the statistical analysis of data that are in the form of functions, most commonly functions of time. Functional data arise naturally in many diverse settings such as meteorology (e.g., Ramsay and Li 1998), medicine (e.g., Zhou et al. 2010), human biology (e.g., Ramsay and Silverman 2002), and finance (e.g., modeling of yield curves in Hays et al. 2012), among others.
The issue that is most central to the problem we address in this paper is how to analyze the relationship between a functional independent variable x t and a scalar dependent variable of interest y.1 For instance, Sood et al. (2009) used a functional principal component approach (fPCA) to analyze penetration (diffusion) curves, and they developed a functional regression model to predict the market penetration of new products. Their approach is based on a decomposition of the observed raw data into functional principal components, which are then used for regression and clustering. Sood et al. demonstrated that their proposed functional data analytic approach outperforms other models such as the Bass model and the Meta-Bass model. Using a similar fPCA approach, Foutz and Jank (2010) proposed a functional shape analysis approach to forecast the box office performance of motion pictures using the dynamic prerelease price patterns from virtual stock markets (e.g., the Hollywood Stock Exchange). Their proposed method automatically identifies a small number of specific "shapes" (which are essentially the functional principal components) from the prerelease price patterns and uses these shapes to predict box office revenue. Functional data analysis has also been applied to the study of online auctions, where it has been used to model price dynamics and to forecast the winning bid (e.g., Reithinger et al. 2008, Wang et al. 2008).
1 Note that the related problem of relating a functional independent variable x t and a functional dependent variable y t , which corresponds to the data structure of Teixeira et al. (2012), is not considered in this paper.

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

226

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

Note that the fPCA approach discussed above primarily has a predictive focus. Although the fPCA approach also attempts to understand the relationship between a function and a scalar, it does not directly speak to how MTM measures are integrated into a scalar measure. Rather, the focus is on identifying the major source of variations across the functional observations (i.e., the functional principal components) and then relating those features to the scalar dependent variable through a regression framework. Later in §5.2, we will compare the fit of our model to the fPCA approach.
In light of this brief review of the previous literature, we can now specify the key methodological and substantive contributions we intend to make with this paper. First, we develop a general Bayesian methodology to study how MTM data are integrated into an overall evaluation. This provides an "off-theshelf" method that researchers can directly use to analyze the aggregation of functional MTM measures into a scalar dependent variable of interest. Second, and substantively, we apply our method to analyze MTM data from participants in a TV show pilot test. TV shows are, of course, much more complex and longer-lasting than the commercials typically examined in previous studies, which results in findings that are substantially different from those found in previous research, as will be discussed in detail in §5.
3. Analysis of Moment-to-Moment
Data Using a Bayesian Functional
Linear Model
In this section, we develop a Bayesian functional linear model to analyze MTM data. Since we will be applying our methodology to analyze dial data for TV pilot shows in §5, we use the terminology of TV shows when describing our proposed method. As discussed earlier, our proposed model can be applied to other MTM data that are collected in marketing research.
3.1. Notations and Time Normalization Throughout this paper, we use the following notations: i (i = 1 I) indexes respondents, and t (t  0 Ti ) indexes the time during which the ith respondent is viewing a TV show. Thus, xi t denotes the value of the dial data for the ith respondent at time t; we assume that xi t  0 for all t. In the context of TV pilot testing, xi t refers to the MTM subjective liking of the TV show at time t. In most applications, xi t is measured either continuously or at a very high sampling frequency (e.g., second-to-second). The variable zi denotes the show that the ith respondent watches (in the empirical application in §5, a total of 19 shows are being tested). Finally, yi denotes the overall rating given by the ith respondent at the conclusion of the experience (i.e., an overall evaluation of the TV show).

We first normalize all Ti to 1 following James et al. (2009); i.e., the time in each show is scaled to the interval [0 1]. Therefore, t refers to the in-show time relative to the duration of the show, rather than absolute time; that is, at the 20-minute mark, t = 0 5 for a show that is 40 minutes long and t = 0 33 for a show that is an hour long. Our choice to analyze MTM data with respect to relative time instead of absolute time is based on both technical and theoretical considerations. First, by normalizing all Ti to 1, we have essentially "registered" or aligned each dial profile to the same time domain (t  0 1 ), which is an important and necessary preprocessing step for functional data analysis procedures (Ramsay and Silverman 2005). Furthermore, previous research on MTM data has typically found that participants demonstrate "duration neglect" (e.g., Baumgartner et al. 1997, Fredrickson and Kahneman 1993, Schreiber and Kahneman 2000), i.e., the total duration of the experience typically does not have a significant effect on overall evaluation, which supports conducting statistical analysis based on relative rather than absolute time. We will provide some empirical evidence in support of this assumption in §5.3.

3.2. Bayesian Functional Linear Model
Recall that the goal of our analysis is to understand
how functional MTM data xi t are aggregated into a scalar dependent variable yi (an overall rating). We begin with a functional linear model (Cardot et al.
1999, 2003; James et al. 2009) that links yi to the functional inner product of xi t and a coefficient function h t :

1

yi = + 0 xi t h t dt + zi + i

(1)

where h t  0 for all t for model identification2
and zi is an additive random effects term that captures any unobserved variations across different TV shows.3 Thus, Equation (1) specifies an integral
equation (Corduneanu 1991) between scalar yi and function xi t that serves to estimate the coefficient function h t .
To understand the intuition behind the integral
equation in Equation (1) and to facilitate further inter-
pretation, we reparametrize Equation (1) by defining

2 This identifying restriction is necessary because in a functional

linear model, h t is only identified up to an additive function g t ,

where

1 0

xi

tgt

dt = 0. That is, h~ t

=h t

+g t

gives the same

likelihood as h t .

3 In Equation (1), we are assuming that the coefficient function h t is homogeneous across shows. In §5.3, we present a model extension that allows h t to be heterogeneous across TV shows through a hierarchical specification.

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

227

ht =

h t , where h t  0 and

1 0

h

t

= 1.

Thus,

we have

1

yi = + 0 xi t h t dt + zi + i

(2)

As can be seen in Equation (2), we are modeling the
overall rating yi through a weighted temporal average of xi t , defined by the weighting function h t , which is itself a probability distribution function as
it integrates to 1 (Casella and Berger 1992). Thus,
through the estimate of h t , we can understand how
the different parts of xi t are being weighted and aggregated into an overall rating yi. For instance, if the later parts of xi t are more heavily weighted, we should find that h t increases over time. In contrast,
if the earlier parts of xi t are more heavily weighted, h t should decrease over time. Clearly, the special
case where yi is driven by the unweighted average of xi t can be captured by having h t = 1 for all t. Thus, the current approach nests unweighted averag-
ing (e.g., Aaker et al. 1986, Polsfuss and Hess 1991,
Thorson and Friestad 1989) as a special case.

3.3. Estimating the Coefficient Function h t We now estimate the coefficient function h t given the model in Equation (1) (or equivalently, h t in Equation (2)). First, we note that given any finite number of observations, h t is always underdetermined (Ramsay and Silverman 2005); that is, given that both x t and h t are of very high (or infinite) dimensionality, it would generally be possible for multiple h t 's to perfectly fit the dependent variables yi if no restrictions are placed on h t (James et al. 2009). In other words, it is necessary to put constraints or prior knowledge on h t in order to estimate it. To understand this intuition, consider a discretized case where S (equally spaced) measurements of x t are taken over the time horizon (t  0 1 ); i.e., xs (s = 1 2 S), where xs = x s/S . By also discretizing h t into hs (s = 1 2 S), where hs = h s/S , Equation (1) can now be written as yi = + s hsxs +
zi + i, which can then be estimated using a regression approach by treating xs (s = 1 2 S) as independent variables. The high dimensionality problem occurs when S > I (the number of observations), which results in the design matrix not having full rank, and hence h t is underdetermined.4 Another concern is that such an approach does not take into account the natural ordering of the indexes s that results from the functional nature of the data (Cardot et al. 2003, Hastie and Mallows 1993). More specifically, there is no reason for h t to have huge discrete

jumps over time, but such prior domain knowledge

is not reflected here.

Thus, in the context of our Bayesian framework,

the underdetermination of h t suggests that it is nec-

essary to specify an informative prior distribution

on h t . We motivate our choice of an appropriate

prior specification on h t by reviewing the "penal-

ization approach" (James et al. 2009), which estimates

parameters through minimizing a "penalized" objec-

tive function that incorporates both fit to the observed

data and some penalty associated with certain aspects

of h t . The penalization approach is closely related to

the ideas of putting a prior distribution on h t to rep-

resent prior knowledge and of "complexity control"

in machine learning (Evgeniou et al. 2007). The most

common form of this approach penalizes a function

based on the second derivative of h t , which corre-

sponds to encouraging smoothness in the coefficient

function, resulting in a penalized b-spline (e.g., Cardot

et al. 2003). Given that, in our application, h t repre-

sents the weight that consumers apply to the experi-

ence at time t, it is reasonable (from a psychological

perspective) to assume that h t does not have any

rapid jumps or discontinuities, which justifies incor-

porating smoothness into h t . Thus, we specify a

prior on h t that directly incorporates smoothness

over time, allowing us to accurately estimate h t .

We propose the following Bayesian approach based

on a random walk prior (West and Harrison 1997,

Choi et al. 2010). Following the approach of Cardot

et al. (2003) and James et al. (2009), we first divide

the time domain t  0 1 into a fine grid consisting

of M equally spaced intervals, where the jth inter-

val is denoted as Tj = j - 1 /M j/M . In both the simulation studies in §4 and the empirical application

in §5, we take M = 100.5 Thus, h t is now approxi-

mated by a step function that takes the value of qj > 0

in the interval Tj . Given the step-function approxima-

tion, 1/M

theMj=in1 tx¯ejgqjr,awl h0e1 rxe

t h t dt can now be written x¯j denotes the average value

as of

xi t within the interval Tj . With this representation,

Equation (1) now takes the form of a standard lin-

ear model, which allows for straightforward posterior

computations (to be discussed later).

To incorporate a smoothness prior into the prior

specification of h t , we specify that the function val-

ues qj (qj > 0) are linked together via a random walk prior (West and Harrison 1997); i.e., qj qj-1  N qj-1 v2 for j  1. Similar to the penalization approach discussed earlier, the random walk prior

specification discourages rapid changes in h t and

encourages it to vary smoothly over time (e.g., Choi

4 Of course, we can solve the underdetermination problem by taking S I. However, this defeats the purpose of having MTM data, as the approximation of hs to h t will be very crude.

5 In Appendix §A.2, we assess the robustness of our approach with respect to the choice of M by taking M = 50 and M = 200; the results remain substantially unchanged.

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

228

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

et al. 2010). In addition, all the conditional priors are Gaussian, allowing for efficient conjugate computations.

3.4. Incorporating Specific Patterns
(Peak and Trough) So far, we have assumed that the overall rating yi is driven only by the weighted aggregation of MTM dial ratings xi t . Previous literature in psychology and in marketing (Ariely 1998, Baumgartner et al. 1997, Fredrickson and Kahneman 1993, Kahneman et al. 1993, Varey and Kahneman 1992) has often argued that the overall rating yi is not only driven by the temporal aggregation of xi t but also by specific patterns of xi t that are not (directly) related to time t. For instance, as discussed earlier, Baumgartner et al. (1997) showed that the overall evaluation of an advertisement is dominated by the peak emotional experience as well as the final moment of the advertisement. Redelmeier and Kahneman (1996) showed that retrospective judgments of pain are strongly correlated with the peak intensity of pain and with the intensity of pain recorded during the last moments of the procedure. In a similar vein, Woltman Elpers et al. (2004) found that the overall perception of the humorous nature of a commercial is driven primarily by the peak moments in terms of surprise and humor.
To capture the additional role of specific patterns, we now extend our model by generalizing Equation (2) as follows:

1

1

yi = + xi t h t dt + k xi t gk t xi t k dt

0

k

0

+ zi + i

(3)

where

1 0

gk

t

xi

t

k dt = 1 and k  0. In Equa-

tion (3), the additional terms

k

1 0

xi

t

gk

t

xi

t

k dt

capture the role of specific patterns (e.g., peak,

trough) that are represented as a function of xi t . Specific patterns that are considered in previous

research include the peak, trough, beginning, end,

and trend/slope (Ariely 1998, Baumgartner et al.

1997, Schreiber and Kahneman 2000). Among these

patterns, the beginning and end patterns are related

to time and can thus be captured by the time-

dependent weighted average and the weighting func-

tion h t ; we therefore focus on capturing the effect

of the peak and the trough in our model. We return

to the issue of capturing the trend/slope below.

We represent the peak of the MTM dial data xi t with the following functional (as depicted in the left

panel of Figure 2):

g1 t xi t

1/ P if t  t - P /2 t + P /2

P= 0

otherwise

where t = arg max xi t (4)
t

That is, the peak measure of MTM dial data xi t is defined as the average dial rating within a time window centered on the time point where the maximum dial rating occurs.6 The length of the time period around the peak during which the peak functional is computed, which we refer to as the bandwidth parameter, is represented by P . We assume that
P is unknown and sample from its posterior distribution along with other model parameters. Thus, another important feature of our modeling framework is that the definitions of specific patterns are also data-driven, which provides some insight into how patterns should be defined. To reflect the prior knowledge (or intuition) that the peak should represent only a short duration around the maximum dial rating, we specify a Gamma(10 0 001) prior distribution on P . This prior distribution has a prior mean of 0.01, corresponding to 1% of the show, which is around half a minute, and puts more than 99% of the prior density on P being smaller than 0.02 (i.e., 2% of the show, which is about a minute).
We similarly define the trough functional as follows (depicted in the right panel of Figure 2):

g2 t xi t

1/ R if t  t - R/2 t + R/2

R= 0

otherwise

where t = arg min xi t (5)
t
As before, the bandwidth parameter R is assumed to be unknown and is given an informative Gamma(10 0 001) prior distribution; it is sampled along with other model parameters. Putting everything together, we specify our full model as follows:

1

1

yi = + xi t h t dt + k xi t gk t xi t

0

k

0

+ zi + i where

k dt (6)

iN 0 2

(7)

zi  N 0 2

(8)

M
h t = h t = qj 1 t  Tj
j =1

where Tj =

j-1 j MM

(9)

qj qj-1  N qj-1 v2 for j  1 qj  0

(10)

P R  Gamma 10 0 001

(11)

6 An alternative operationalization of the peak measure is to compute a sequence of moving averages (each with width P ) of the dial rating and define the peak as the maximum of such moving averages. This definition is much more computationally intensive; we leave it for future research.

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

229

Figure 2 The Peak and Trough Functionals

1
P

t

t*­ P t*+ P

2

2

Peak functional

1
R

t

t*­ R t*+ R

2

2

Trough functional

Note that in Equation (9), 1 t  Tj ) denotes the indicator function, which takes the value of 1 if t  Tj and 0 otherwise. To complete our Bayesian model

specification, we specify conjugate, weakly informa-

tive priors on all other model parameters (Gelman

et al. 2003). Specifically, and q0 (q0  0) are both given independent, weakly informative N 0 1002

prior distributions, and the variance parameters 2

and v2 are both given independent, weakly infor-

mative Inv - 2 0 001 1 prior distributions. The k's are given weakly informative truncated normal dis-

tributions with mean 0 and variance 1002. We sample

from the posterior distribution of all model param-

eters using a standard Markov chain Monte Carlo

(MCMC) procedure (Gelman et al. 2003), which was

coded in C++; the details of our computational pro-

cedure are described in Appendix §A.1.

We now return to the issue of incorporating

the trend/slope pattern. We argue that the model

described by Equation (6) has already incorporated

the time-varying effect of the first derivative x t .

To see this, assume that there is an additional addi-

tive term

1 0

xi

t

k

t

in Equation (6), where k t

denotes the contribution of trend/slope at time t

(i.e., x t ) that captures the time-varying effect of the

trend/slope on the overall rating. Using integration-

by-parts,

1 0

xi

t

k

we can write t dt. Thus, the

1 0

xi

t

k

t

second

dt = term

xi t k t

1 0

-

shows that

the contribution of the first derivative x t can be

absorbed into the term

1 0

xi

t

h

t

dt. In other words,

the time-varying effect of x t cannot be separately

identified from the time-varying effect of x t , and

thus our model is in effect estimating the "net contri-

bution" of each time point on the overall rating.

4. Simulation Study
We conduct a set of simulation studies to ensure that our proposed methodology is able to accurately recover all model parameters (in particular, the weighting function h t ), given the amount of data available in the data set used in our empirical application in §5. In each simulation, we take xi t to be

the dial ratings we obtained from I = 3 572 partici-

pants in the actual data set that we will analyze, and

we simulate overall ratings yi using a set of known model parameters and different specifications of the

weighting function h t .

We conduct six simulations, each using a differ-

ent weighting function h t . In each case, we take

= 1 0, = 0 04, and 2 = 0 6, which are chosen to

maximally replicate the actual data in our empirical

application. In addition, we set the bandwidth param-

eters for the peak and trough patterns ( P and R, respectively) to be both 0.01, which specifies that, as

discussed earlier, the peak (trough) rating is taken to

be the average of the dial ratings during the 1% of the

show centered around the max (min) value. Further-

more, we set the coefficients for peak and trough to

be 1 = 2 = 0 01. The six different specifications for h t are shown

by the solid lines in Figure 3. In Case 1, partici-

pants weigh each moment within the show equally;

i.e., h t = 1 for all t. Case 2 represents the situation

where participants weigh the beginning of a show

more heavily than other parts (Blacker 1998), which is

represented by the weighting function h t = 1 5 - t.

In Case 3, participants put greater weight on the mid-

dle of the show, with h t = 0 5 + 2t for t  0 5 and

h t = 1 5 - 2 t - 0 5 for t > 0 5. Next, in Case 4,

participants weigh the end of the show more, with a

weighting function h t = 0 5 + t. Case 5 is a com-

bination of Cases 2 and 4, where participants weigh

both the beginning and end more than the middle,

with h t = 1 5 + 2t for t  0 5 and h t = 0 5 +

2 t - 0 5 for t > 0 5. Finally, in Case 6, h t is simu-

lated from an arithmetic random walk. Note that in all

six cases, the normalizing constraint

1 0

h

t

dt = 1

is

satisfied.

The estimated model parameters, along with their

posterior 95% intervals, are shown in Table 1. The

estimated weighting functions h t are shown in Fig-

ure 3, along with pointwise 95% posterior intervals.

As can be seen in Table 1, in each case our methodol-

ogy is able to accurately recover all model parameters,

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

230

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

Table 1

Simulation Study: Estimated Posterior Means of Model Parameters, Along with 95% Posterior Intervals

Case 1

Case 2

Case 3

Case 4

Case 5

Case 6

1.080

1.089

1.074

0.899

0.955

0.896

(0.434, 1.743) (0.454, 1.720) (0.438, 1.707) (0.248, 1.517) (0.258, 1.595) (0.287, 1.476)

0.043

0.043

0.042

0.042

0.040

0.041

(0.031, 0.547) (0.031, 0.055) (0.031, 0.053) (0.031, 0.054) (0.027, 0.053) (0.032, 0.052)

1

0.008

0.008

0.008

0.009

0.010

0.010

(0.004, 0.012) (0.003, 0.012) (0.005, 0.012) (0.005, 0.014) (0.006, 0.014) (0.006, 0.013)

2

0.008

0.008

0.010

0.010

0.011

0.010

(0.005, 0.012) (0.005, 0.012) (0.006, 0.013) (0.007, 0.014) (0.007, 0.016) (0.007, 0.013)

P

0.014

0.014

0.011

0.012

0.012

0.012

(0.003, 0.028) (0.003, 0.028) (0.002, 0.024) (0.002, 0.025) (0.002, 0.028) (0.002, 0.027)

T

0.011

0.012

0.010

0.013

0.013

0.011

(0.003, 0.024) (0.003, 0.025) (0.002, 0.023) (0.003, 0.029) (0.002, 0.032) (0.003, 0.025)

Note. True values: = 1 0, = 0 04, 1 = 2 = 0 01, and P = T = 0 01.

Figure 3 Simulation Study: Posterior Estimates of the Weighting Function h t

(1) Uniform 3.0

(2) Beginning

3.0

3.0

(3) Middle

2.5

2.5

2.5

2.0

2.0

2.0

1.5

1.5

1.5

1.0

1.0

1.0

0.5

0.5

0.5

0.0

0.0

0.0

0.0 0.2 0.4 0.6 0.8 1.0

0.0 0.2 0.4 0.6 0.8 1.0

0.0 0.2 0.4 0.6 0.8 1.0

(4) End 3.0

(5) Beginning and end

3.0

3.0

(6) Random walk

2.5

2.5

2.5

2.0

2.0

2.0

1.5

1.5

1.5

1.0

1.0

1.0

0.5

0.5

0.5

0.0

0.0

0.0

0.0 0.2 0.4 0.6 0.8 1.0

0.0 0.2 0.4 0.6 0.8 1.0

0.0 0.2 0.4 0.6 0.8 1.0

Notes. The solid line depicts the known true h t , and the broken line is the posterior mean estimate of h t . The bounds are pointwise 95% posterior intervals.

and the posterior means of the model parameters are very close to the known true value, which always falls within the 95% posterior intervals. Furthermore, Figure 3 suggests that our proposed approach is also able to recover the weighting function h t reasonably well given the data in our empirical application.

5. Empirical Application: TV Show Pilot Testing
5.1. Data Overview We apply our proposed methodology to analyze MTM dial data collected during a series of TV show pilot tests conducted by CBS between April 2002

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

231

Table 2 Show-Level Summary Statistics

Duration

Mean dial rating

Avg. overall

Nielsen rating

ID

Show

(minutes) (across participant and time) evaluation (Live + 7 %HHs)

1 3 lbs OP

42 4

2 Century City OP

43 7

3 Close to Home OP

44 8

4 Clubhouse OS

43 8

5 Company Town PS

39 3

6 Criminal Minds PP

40 8

7 CSI: Miami PP

46 4

8 CSI: NY PP

44 3

9 Ghost Whisperer OP

43 6

10 Hack PS

45 7

11 Jericho OS

38 4

12 Joan of Arcadia OS

31 9

13 Presidio Med OP

45 3

14 Queens Supreme OP

41 1

15 Shark OP

44 4

16 Smith OS

62 0

17 The Unit PP

44 9

18 Threshold OS

35 8

19 Without a Trace PP

40 5

62 68 59 78 71 98 63 46 65 92 74 05 73 60 71 79 70 09 60 85 69 37 60 75 61 42 63 31 67 39 62 09 63 96 67 62 68 18

3 16

61

3 33

53

3 92

64

3 50

52

3 40

N/A

3 90

81

4 07

10 5

3 96

83

3 77

59

3 45

52

3 58

50

3 51

53

3 53

50

3 43

48

3 61

76

3 16

67

3 40

70

3 51

51

3 76

99

Notes. PP, police procedural; OP, other procedural; PS, police serial; OS, other serial. Nielsen ratings show the percentage of households (HHs) that watched the show live or time-delayed (DVR) within seven days of its original broadcast. The show Company Town did not air.

and May 2006. As listed in Table 2, 19 different TV show pilots with durations ranging from 32 minutes to 62 minutes, along with their genres ("police" versus "other") and types (procedural drama versus serial drama), were tested in the CBS Television City Research Center located at the MGM Grand hotel in Las Vegas. Participants were interested volunteers. They did not receive financial compensation for participating in the TV show pilot study.
A total of 3,572 participants took part in the TV pilot tests, with each participant watching only one pilot show that lasted, on average, about 45 minutes. While participants were watching the TV show, they recorded their MTM liking of the show on a 101-point scale using an electronic dial system (0 = "wouldn't watch it or turn off the TV," 50 = "neutral," 100 = "extremely interested"). This procedure is analogous to MTM measures used in prior marketing studies, such as electronic dial ratings to indicate affective reactions to a sequence of pictures (Pham et al. 2001), continuous computer mouse movements to indicate feelings elicited by a commercial (Baumgartner et al. 1997), and continuous adjustments of a slider scale to indicate enjoyment of a music video (Nelson et al. 2009). Examples of the resulting data are shown in Figure 1. At the end of the show, each participant filled out an exit survey indicating his or her overall evaluation of the TV show on a five-point scale, where 1 represents "poor" and 5 represents "excellent."7
7 We treat the 1-to-5 scale as if the data came from a continuous interval scale, which is consistent with the analysis performed

Figure 4 and Table 2 present several key show-level summary statistics. First, Figure 4 shows the mean MTM dial rating (across participants) over time for each of the 19 TV shows. Consistent with Baumgartner et al. (1997), MTM dial ratings generally increase over time during the show; a linear regression of mean dial rating versus time results in positive and statistically significant coefficients (p < 0 001) in all of the 19 shows in our data set. This suggests that participants, in general, gradually liked the TV show more as the show progressed. Our observed mean patterns over time, however, are much more complicated than those shown in Baumgartner et al., which is to be expected, given that TV shows are richer and more layered than the 90-second commercials studied in Baumgartner et al.
Next, Table 2 shows the average MTM dial rating (computed by averaging across participants and across time) for each TV show, along with its average overall evaluation across participants who viewed the show. As expected, at the show level, the correlation between average dial rating and overall evaluation is positive and statistically significant (r = 0 857, p < 0 001), providing some face validity for the MTM measurements. Next, we examine the relationship with the Nielsen ratings, which are available for all but one of the shows (as shown in the last column
in the previous literature (Wirtz et al. 2003). In Appendix §A.3, we develop a "cutpoint" formulation based on the ordered probit model (Greene 2011). The results remain substantially unchanged.

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

232

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

Figure 4 Mean Dial Ratings Across Participants in Each of 19 Pilot Shows

90 80 70 60 50 40
0.0
90 80 70 60 50 40
0.0

1
0.4 0.8 6
0.4 0.8

90 80 70 60 50 40
0.0
90 80 70 60 50 40
0.0

2
0.4 0.8 7
0.4 0.8

90 80 70 60 50 40
0.0
90 80 70 60 50 40
0.0

3
0.4 0.8 8
0.4 0.8

90 80 70 60 50 40
0.0

11 0.4 0.8

90 80 70 60 50 40
0.0

12 0.4 0.8

90 80 70 60 50 40
0.0

13 0.4 0.8

90 80 70 60 50 40
0.0

16 0.4 0.8

90 80 70 60 50 40
0.0

17 0.4 0.8

90 80 70 60 50 40
0.0

90 80 70 60 50 40
0.0
90 80 70 60 50 40
0.0
90 80 70 60 50 40
0.0 18
0.4 0.8

4
0.4 0.8 9
0.4 0.8 14
0.4 0.8 90 80 70 60 50 40 0.0

90 80 70 60 50 40
0.0
90 80 70 60 50 40
0.0
90 80 70 60 50 40
0.0 19
0.4 0.8

5
0.4 0.8 10
0.4 0.8 15
0.4 0.8

of Table 2).8 We find that the average overall rating (across respondents) is significantly correlated with the resulting Nielsen rating after the show was aired (r = 0 61, p = 0 007), which suggests that an improvement in likeability ratings may increase subsequent exposure to the show.
We now turn to the individual-level summary statistics in Table 3. As shown in the table, the mean overall evaluation is 3.59, with a standard deviation of 1.17. Across participants, the mean of the average MTM dial rating is 66.40, with a standard deviation of 19.95. As discussed earlier, we also compute three important features of each dial profile: the peak (maximum
8 One of the 19 shows did not air; hence its Nielsen rating is unavailable.

dial rating), the trough (minimum dial rating), and the end (final position of the dial). Across all participants, the peak, trough, and end are, on average, 91.34 (sd = 14 03), 25.42 (sd = 20 34), and 64.63 (sd = 27 95), respectively. Furthermore, Table 4 presents a correlation matrix that explores the relationships between

Table 3

Individual-Level Summary Statistics from the TV Pilot Show Data

Mean sd Min Max

Overall evaluation (1-to-5 scale)

3 59 1 17 1 00

5 00

Avg. dial rating

66 40 19 95 0 00 99 45

Max dial rating (peak)

91 34 14 03 0 00 100 00

Min dial rating (trough)

25 42 20 34 0 00 91 00

Final position of the dial rating (end) 64 63 27 95 0 00 100 00

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

233

Table 4

Correlation Matrix Between the Overall Evaluation, Average Dial Rating, Peak, Trough, and End Dial Rating

Evaluation

Average

Peak

Trough

End

Evaluation

1 00

Average

0 71

Peak

0 44

Trough

0 47

End

0 56

0 71

0 44

0 47

0 56

1 00

0 64

0 55

0 68

0 64

1 00

0 12

0 43

0 55

0 12

1 00

0 46

0 68

0 43

0 46

1 00

overall evaluation, average rating, peak, trough, and end. As can be seen, the overall evaluation is most strongly correlated with the average dial rating (r = 0 71), followed by the end dial rating (r = 0 56), the trough (r = 0 47), and the peak (r = 0 44); all four of the correlations are statistically significant (p < 0 001).

5.2. Empirical Results and Comparison to

Benchmark Methods

We apply our proposed model to actual data and

compare its performance, both in- and out-of-sample,

vis-à-vis several benchmark methods. Discussions

with executives at CBS reveal that one critical goal

of collecting MTM data is to understand the key

determinants of overall evaluations and thus iden-

tify the specific enjoyment patterns that will pro-

duce more favorable evaluations. In other words,

ideally the model should predict how overall enjoy-

ment changes if the show is altered based on feedback

using MTM measures (e.g., moving an early action

sequence to a later part of the show or selectively

investing to improve either the opening sequence or

ending). Given this goal, an out-of-sample test where

an entire TV show is being held out seems to be the

most appropriate test given the available data, as it

is in the spirit of predicting the liking of new shows

unseen in the data. Thus, when conducting an out-

of-sample prediction, we hold out entire TV shows

one by one using leave-one-out cross-validation, a

widely used method for accurately estimating predic-

tion error (Hastie et al. 2009).

For both the in-sample fit and out-of-sample pre-

diction, we compare our model against the following

models that are representative of the analyses per-

formed in the previous literature:

i. Temporal aggregation: The overall evaluation y is

modeled as a linear function of the unweighted aver-

age dial rating: yi =

1 0

xi

t

dt.

+ x¯i t + zi + i, where x¯i t =

ii. Peak-end rule equal weights : The overall evalu-

ation y is modeled as a function of an unweighted

average of the maximum and final position of the dial

rating: yi = +

1 2

max

xi

t

+

1 2

xi

T

+ zi + i.

iii. Peak-end rule unequal weights : We also con-

sider a generalization of (ii) where unequal weights

are allowed for the peak and end ratings: yi = + 1 max xi t + 2xi T + zi + i.

Table 5 Results for In-Sample Fit and Out-of-Sample Prediction

Method

In-sample MSE Out-of-sample MSE

Temporal aggregation Peak-end rule (equal weights) Peak-end rule (unequal weights) Functional PCA Proposed model without peak and
trough patterns Proposed model with peak and
trough patterns

0 665 0 828 0 827 0 638 0 630
0 629

0 681 0 860 0 860 0 667 0 646
0 647

iv. Functional PCA: Following Sood et al. (2009) and Foutz and Jank (2010), a smoothing spline is first applied to the raw MTM data. The overall evaluation of y is then modeled as a linear function of the first two functional principal components of x t and the first two functional principal components of the first derivative x t .
The fit of each benchmark model in terms of both in- and out-of-sample mean squared error (MSE), together with the results of our proposed model (with and without including peak and trough patterns), is shown in Table 5. Our results clearly indicate that the proposed model provides superior in-sample (0.629) and out-of-sample (0.647) MSE compared with all other methods. Among the four benchmark models, the functional PCA method performs the best, as expected, with an in-sample MSE (0.638) that is only slightly higher than that of the proposed method (p < 0 05) but with an out-of-sample MSE (0.667) that is substantially worse compared with the proposed method (p < 0 001).9 This suggests that fPCA, which is based on a decomposition of the available data, is able to adequately summarize the temporal patterns in the existing shows, yet it does not do as well for predicting new shows that are not in the sample because those patterns are unobserved in the available data. In contrast, our proposed Bayesian functional linear model directly models the "contribution" of each moment without having to rely on observed patterns (i.e., functional principal components) in the functional data. Thus, our proposed model is not pattern dependent and hence is more suitable for predicting the overall rating of new shows.
Among the other three benchmark methods, the temporal aggregation model performs better than the methods that are based on the peak-end rule. Given the complexity and multilayered nature of modern TV shows (Johnson 2005), this result is consistent with Ariely and Zauberman's (2000) finding that overall judgments of segmented (rather than continuous) hedonic experiences rely more on the average intensity of the experience and less on specific patterns.
9 The p-values here are two-sided, computed using the paired t-test.

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

234

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

Table 6
1 2 P T

Posterior Estimates for Model Parameters in the Proposed Model

Posterior mean

95% posterior interval

0 856 0 038 0 000 0 002 0 011 0 011

(0 365 1 312) (0 031 0 046) (0 000 0 001) (0 000 0 005) (0 005 0 019) (0 004 0 021)

This hypothesis is further supported by the observation that the predictive performance of the proposed model with peak and trough patterns is virtually indistinguishable from the performance of the model without those patterns, indicating that these patterns do not meaningfully contribute to the prediction of the overall evaluation. Stated more formally, the log Bayes factor in favor of the reduced model (i.e., without peak and trough effects), as computed using the Savage­Dickery density ratio (Rossi et al. 2005), is +34 0, which corresponds to "decisive" evidence in favor of the reduced model (Kass and Raftery 1995).
We now turn to the parameter estimates for our proposed model, which are shown in Table 6. The posterior mean estimate for is 0.856, with a 95% posterior interval of (0 365 1 312). The posterior mean estimate for is 0.038, with a 95% posterior interval of (0 031 0 046), indicating that, as expected, the overall evaluation is significantly related to a weighted average of the dial ratings. The posterior mean of the normalized weighting function h t is shown by the solid line in Figure 5, and the broken lines show the pointwise 95% posterior intervals. As can be seen in the figure, participants clearly place more weight on the later part of the show compared with

Figure 5 7

Estimated Normalized Weighting Function h t

6

5

4

3

2

1

0

0.0

0.2

0.4

0.6

0.8

1.0

Note. The solid line shows the posterior mean, and the broken lines are

pointwise 95% posterior intervals.

the earlier parts, with weights increasing dramatically

in the last quintile of the show. To further under-

stand this pattern, we compute the relative weight

of each quintile by computing the value of the inte-

grals

0 0

2

h

t

dt,

04 02

h

t

dt,

06 04

h

t

dt,

08 06

h

t

dt,

and

10 08

h

t

dt.

The

relative

weights

are

0.102,

0.120,

0.131, 0.151, and 0.496 for the first to fifth quintiles,

respectively. In other words, the last quintile of the

show is approximately four times as important as

each of the first four quintiles.

Next, we find that the estimated values of 1 and 2, which respectively correspond to the magnitude of the peak and trough effects, are very small.

The posterior mean of 1 (the coefficient for the peak effect) is 0.0003, with a 95% posterior inter-

val of (0 0000 0 0012), and the posterior mean of 2 (the coefficient of the trough effect) is 0.0022, with a

95% posterior interval of (0 0002 0 0048). Thus, these

results indicate that the peak and trough effects are

much smaller than the effect of the weighted tem-

poral aggregation. More specifically, the relative con-

tribution of the unweighted temporal aggregation is

/ + 1 + 2 = 93 7%, and the relative contribution of the peak and the trough is 0.8% and 5.5%,

respectively.

In sum, we find evidence for a very pronounced

end effect but little evidence for any incremental con-

tribution from the peak of the experience. The absence

of a peak effect (and the finding that the trough is

actually a better predictor than the peak) is intriguing

given that peak effects have been observed in many

previous studies using MTM ratings (e.g., Fredrickson

and Kahneman 1993, Redelmeier and Kahneman

1996), including a similar study by Baumgartner et al.

(1997) in which participants indicated their enjoy-

ment while watching a TV commercial. As such, our

findings suggest that peak experiences may be less

distinct and memorable for longer, multilayered stim-

uli such as TV shows than for shorter, less com-

plicated stimuli such as TV commercials. On the

other hand, the observance of a disproportionate end

effect is in line with previous findings (though it is

exceptionally pronounced in this case). Yet whereas

the end effect has often been demonstrated, many

recent studies have shown that it fails to obtain for

a variety of stimuli and in a variety of situations

(e.g., Montgomery and Unnava 2009, Robinson et al.

2011), including complex, multilayered experiences

(Miron-Shatz 2009). As such, that we observe such

a pronounced end effect for TV shows adds to this

ongoing debate and provides support for prior spec-

ulation that end effects may also occur for complex

experiences, but only when this experience forms a

cohesive unit (Miron-Shatz 2009).

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

235

5.3. Model Extension: Incorporating Heterogeneity of h t Across Shows
Up to this point, we have made the simplifying assumption that h t is homogeneous across all shows. The homogeneity of h t is arguably a reasonable assumption when consumers' response is instinctive and the context is less influential (e.g., patients' reactions to pain across medical procedures), but in the TV setting, h t may be different depending on the genre (e.g., police versus medical) or type (e.g., procedural drama versus serial drama) of show. We therefore introduce a model extension that incorporates heterogeneity of h t across shows through a hierarchical specification. We change our notation slightly in this section: i denotes the respondent, k denotes the show, and j denotes the time within a show. Also, as discussed above, because the reduced model (without peak and trough effects) provides a better fit to the data than the full model (based on Bayes factor), we start with the reduced model and incorporate heterogeneity into that specification. Formally stated, we specify the following model:

1

yik = + xik t hk t dt + k + ik

(12)

0

M
hk t = qkj I t  Tj
j =1

where Tj =

j -1 M

j M

(13)

qkj qk j-1  N qk j-1 + ~ j-1 2 for j  2

(14)

qk1  N q¯1 2

(15)

~ j  N 0 v2

(16)

Equations (14) and (15) allow for heterogeneity of

h t across shows. More specifically, for each show k,

the sequence qk1 qk2

qkM follows a random walk

specification where the mean increment ( ~ j ) in each

period is the same across shows, with variations

across shows captured by the variance parameter

2. Note that if 2  0, the above specification in

Equations (12)­(16) reduces to the specification in

Equations (6)­(11), where h t is assumed to be homo-

geneous across shows.

After estimating the model with MCMC, we com-

pute the posterior mean of hk t for each show. As can be seen in Figure 6, although there are some minor

differences across shows, the general pattern that the

final quintile carries the highest weight holds across

all 19 shows. The shape of the normalized weighting

function for each show is also very similar, thus pro-

viding some support for the homogeneity assumption

(which provided more statistical power to estimate

h t earlier).

Our new results also allow us to assess the validity

of our normalization procedure in §3.1, which scales

time in each show to the interval [0 1]. Specifically,

Figure 6

Estimated Normalized Weighting Function h t Across All 19 Shows Under the Specification That Allows for Heterogeneity

3.0

1

11

2

12

3

13

2.5

4

14

5

15

6

16

2.0

7 8

17 18

9

19

10

1.5

q[, 1]

1.0

0.5

0.0

0.2

0.4

0.6

0.8

1.0

(1:100)/100

we can look at the correlation between the aggre-

gate weight put on the final quintile of each show

(

1 08

hk

t

dt) and the duration of each show (shown in

Table 2). We find that the correlation is statistically

insignificant (r = -0 067, p = 0 78): the dispropor-

tionate impact of the final quintile does not depend

on the absolute length of this quintile. In contrast,

although the impact of this relative time interval does

not depend on the length of the show, the impact of

absolute intervals does. For instance, show length is

negatively correlated with the importance of the last

5 minutes (r = -0 62, p = 0 005) as well as the last

10 minutes (r = -0 65, p = 0 002). In other words, the

last 5 (or 10) minutes matter less if they are part of a

longer show and thus constitute a relatively smaller

part of the show. Together, this supports the assump-

tion behind our normalization procedure--i.e., that

the impact of a show segment depends on relative

time rather than absolute time.

Although the last quintile has a disproportion-

ate effect in each of the 19 shows, there is some

variation in the magnitude of this effect. Therefore,

another interesting question is how this end effect

varies across TV shows of different genres (police ver-

sus other) and types (procedural drama versus serial

drama), as denoted by the superscripts in Table 2.

Similar to the above analysis, we estimate a regression

with

the

final

quintile

of

each

show

(

1 08

hk

t

dt)

as

the dependent variable and with the genre and type

of the show as independent variables. The results are

shown in Table 7. Our results indicate that the end-

ing (i.e., final quintile) is even more important for

procedural dramas than for serial dramas ( = 0 029,

p < 0 1). Since procedural dramas (where a conflict is

resolved in each stand-alone episode) could be seen as

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

236

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

Table 7

Regression of the Weight of the Final Quintile on Genre and Type of TV Show

Estimated coefficient

se

p-value

Intercept Genre: Police Type: Procedural
R2

0 291 -0 015
0 029
0 194

0 013 0 016 0 016

0 000 0 365 0 085

p < 0 05; p < 0 10.

more cohesive than serial dramas (where each episode is part of a larger storyline), this provides further support for earlier suggestions that the cohesiveness of the experience is a key condition for obtaining end effects for complex experiences (Miron-Shatz 2009).
6. Discussion and Conclusion
In this paper, we develop a Bayesian functional analysis approach to analyze the relationship between MTM data and overall evaluations. Specifically, we develop a functional linear model to capture how MTM data xi t are aggregated into an overall rating yi through a weighting function h t . We extend our model to allow for the additional roles of specific patterns (peak and trough) in driving overall evaluations, and we apply our proposed model to a MTM dial data set collected from 3,572 participants during pilot TV show tests conducted by CBS. We find that our proposed model outperforms other approaches used in the previous literature, in terms of both in- and out-of-sample MSE. Furthermore, we demonstrate that (i) the final quintile of a TV show is weighted about four times as much as any of the other quintiles, (ii) the role of specific patterns (peak and trough) in driving overall evaluations is limited in the context of TV shows, and (iii) the final quintile is particularly important for procedural dramas. Interestingly, although previous research in the "thin slice" literature has shown that the popularity of, for instance, politicians (Todorov et al. 2005) and musical performances (Tsay 2013) can be well predicted from first impressions or minimal information, our findings indicate that the popularity of more complex narrative stimuli such as television shows is better predicted by the reaction to the end of the experience.
That being said, we want to raise a note of caution regarding any studies inferring end effects based on relationships between MTM ratings and overall evaluations (including past research as well as the current study). Specifically, the stronger relationship between later MTM ratings and the overall evaluation may be caused by not only later segments having a greater impact on evaluations but also later MTM ratings already partly reflecting overall evaluations. That is, as the show progresses, the MTM ratings may

be influenced not only by what is happening on the screen at the moment but also by what has happened on the screen so far. However, we would argue that, in this particular study, this issue is unlikely to fully account for the end effect since the increase in weight does not occur gradually over time (as one would expect if the MTM ratings reflect the continuously updated liking of the show), but rather is restricted to the final quintile.
Another potential alternative explanation of our findings is that the final dial rating is likely to be the most salient at the moment that the overall evaluation is made, which attributes the observed correlation to measurement artifacts. However, this recency effect explanation has been addressed by prior research (Baumgartner et al. 1997), which obtained similar results when the measure of the overall rating was delayed. Furthermore, the differences in weights of the final quintile for procedural drama versus serial drama indicate that this greater weighting of the end does not just reflect a recency effect but depends on the meaning of the end. Of course, the most definitive way of ruling out any measurement issues and establishing the greater causal impact of the final show fragments would be to compare two different cuttings of the same show where different parts are relocated based on the MTM dial profile and then compare their overall evaluations to validate the model predictions.
With the above caveats in mind, our results suggest that in the context of a television show, the final quintile is the most important and specific patterns have little impact on the overall evaluation. What are the implications of these findings for TV show producers seeking to maximize viewers' overall evaluation (given its positive correlation with Nielsen ratings)? First, our results imply that producers should not allocate resources to provide a particularly liked peak experience (e.g., a particularly exciting yet expensive car chase sequence). In fact, although prior research has focused on peak effects rather than trough effects, our results indicate that the latter are more important (albeit both effects are relatively small). That is, in the context of TV shows, it may be more important to avoid exceptionally disliked segments than to insert an exceptionally liked segment. However, although peak effects did not materialize, end effects turned out to be very substantial, especially for procedural dramas. This suggests that show makers may want to allocate more resources toward improving the quality of the show's ending. For instance, they could move sequences around so that the best sequences (e.g., funniest jokes, most exciting action sequence) appear toward the end of the show, or, alternatively, invest more resources in the final resolution of the plot rather than in making the preceding scenes more thrilling or entertaining.

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

237

As the first paper in marketing that introduces a Bayesian functional analysis framework to analyze MTM data, we have only scratched the surface of this active and growing research area--both in terms of methodological development and in terms of the substantive managerial insights that can be extracted from MTM data. Below, we conclude by discussing a few promising directions for future research in this area.
First, in this paper, we have focused on two specific patterns, a single peak and a single trough. Future research may look into the role of multiple peaks and troughs in MTM data. For instance, if there is a secondary peak in a dial profile, how much weight would be given to it compared with the primary peak? Also, does it matter when the peak occurs? Future research may consider incorporating these patterns into the functional analysis framework developed here.
Second, all participants in the current study watched the entire TV show from start to finish, as they were not given the option to stop and leave in the middle of a show. To more closely mimic TV viewing conditions in real life, TV networks may consider allowing participants to leave in the middle of a show (i.e., change the channel) if they do not wish to finish viewing the show. In such a setting, our model would need to be supplemented by a separate model that captures the attrition process (i.e., if a participant's utility drops below a certain threshold, she would leave the show at that point), perhaps adopting an approach similar to that of Teixeira et al. (2012). From a substantive perspective, we would speculate that our current finding that troughs matter more than peaks would be even more pronounced if people can choose to stop or switch channels, since viewers are more likely to notice the presence of a terrible segment than the absence of a great one.
Finally, the methodology developed in this paper is fully general and can be directly applied to other substantive areas, which includes all the areas mentioned in §§1 and §2.1. For instance, our method can be useful for the Home Shopping Network, which frequently runs moment-to-moment evaluations on its televised sales pitches of various products (Dialsmith 2013). In particular, the model extension that incorporates heterogeneity can be useful for capturing differences in weighting functions h t across different product categories. In addition, our methodology can be applied to analyze the relationship between a pain profile and an overall assessment of pain during a colonoscopy or the likelihood of returning for the next scheduled screening procedure. Similarly, our proposed method can also be used to analyze televised political debates and help formulate campaign strategies. In summary, we hope that our paper will

stimulate research in this area and that it provides a springboard for future research using MTM data.

Acknowledgments The authors thank CBS and David F. Poltrack, CBS Executive Vice President, Planning and Research, for contributing the TV pilot testing data used in the analysis.
Appendix

A.1. MCMC Computation
We describe the MCMC procedure we used to estimate
the Bayesian functional linear model described by Equa-
tions (6)­(11). We draw from the full conditional distribu-
tions of model parameters in the following order: , 1, 2, , q, P , R, v2, 2, and 2. Each step follows directly from
standard Bayesian posterior computations (Gelman et al.
2003) and is outlined as follows.
Step 1. Drawing : Recall that x¯j denotes the average value of xi t in the time interval Tj ; can be drawn using standard conjugate normal posterior computation (Gelman et al. 2003), where the prior is N 0 1002 and the data are
defined by

1M

1

yi

-

M

x¯j qj
j =1

-

1

0

xi t g1 t

xi t

P dt

1
- 2 xi t g2 t xi t 0

R dt - zi

Step 2. Drawing 1 and 2: To sample from the full

conditional distribution of 1, we first compute the data

quantities

1/

1 0

xi

t

g1

t

xi t

P dt yi - 1/M

M j =1

x¯j

qj

-

2

1 0

xi

t

g2

t

xi

t

R dt - zi ,

tion has precision proportional to

where the

1 0

xi

t

g1

t

ith xi t

observaP dt 2.

We then proceed with standard (truncated) normal poste-

rior computations to draw from the full conditional dis-

tribution of 1. Similarly, 2 can be sampled using an analogous procedure.

Step 3. Drawing 's: Similar to , l can be drawn using standard conjugate normal posterior computation, where the prior is given by N 0 2 and the data are given by

1M

1

yi -

-

M

x¯j qj
j =1

-

1

0

xi t g1 t

xi t

P dt

1
- 2 xi t g2 t xi t 0

R dt

where zi = l

Step 4. Drawing qj 's: First, note that given the random walk prior specification in Equation (10), qj has the following conditional prior distribution (see Choi et al. 2010, West

and Harrison 1997):

For j = 1 q1  N q2 v2

For 1 < j < M

qj  N

qj-1 + qj+1 2

v2 2

For j = M qM  N qM-1 v2 Next, we compute the data quantities

1

1

1

x¯j yi

-

M

x¯lql -
l=j

1

0

xi t g1 t

xi t

P dt

1
- 2 xi t g2 t xi t 0

R dt - zi

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

238

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

which have precisions proportional to x¯j 2. We then proceed with standard (truncated) normal posterior compu-

tations to sample from the full conditional distribution

of qj . Step 5. Drawing P and R: Because standard conjugate
computations are not available for the bandwidth parame-

ters P and R, we use a random walk Metropolis-Hastings algorithm to sample from their posterior distributions. For

each parameter, we use a Gaussian random walk pro-

posal distribution with the mean centered on the pre-

vious draw; the variance of the proposal distribution is

adjusted to achieve an acceptance rate close to 50% (Gelman

et al. 2003).

Step 6. Drawing v2, 2, and 2: Since, as stated earlier,

all the variance parameters are given conjugate, weakly

informative Inv - 2 0 001 1 prior distributions, we can

draw directly from their fully conditional distribution using

standard conjugate computations of variance parameters

(Gelman et al. 2003).

After sampling from the joint posterior distribution of

all model parameters, we postprocess the posterior sam-

ples by dividing each qj by the normalizing constant

1/M

M j =1

qj

and

setting

equal to the normalizing con-

stant. This allows us to separate the coefficient function

h t into a normalized weighting function h t , as depicted

in Figure 5, and the slope coefficient . We coded the

above MCMC procedure in C++, using the GNU Sci-

entific Library, and ran 40,000 iterations. The first 20,000

iterations were discarded as burn-in samples, leaving the

last 20,000 draws to summarize the posterior distribu-

tion (Gelman et al. 2003). Standard diagnostics confirmed

that convergence had been reached. The full C++ code

and posterior draws are available from the authors upon

request.

A.2. Robustness Check with Respect to M We explore the robustness of our results with respect to the choice of M by estimating the model with M = 50 and M = 200. Given that the peak and trough effects are

very small and that the reduced model (without peak and trough effects) provides a better fit to the data than the full model (based on Bayes factor), we focus on the specification that excludes peak and trough effects. The estimated h t under M = 50 and M = 200 are shown in the Figure A.1.
As can be seen in Figure A.1, the overall patterns are very similar to the one presented in the paper (with M = 100). We further compute the total weight of each quintile under M = 50 and M = 200. The results, which clearly indicate that our findings are robust with respect to M, are summarized in the following table.

First Second Third Fourth Fifth quintile quintile quintile quintile quintile

M = 50 M = 100 M = 200

0 096 0 102 0 108

0 120 0 120 0 121

0 130 0 131 0 132

0 159 0 151 0 150

0 495 0 496 0 488

A.3. Ordered Probit Formulation We developed a "cutpoint" formulation based on the ordered probit model (Greene 2011) to specifically account for the five-point Likert scale used to collect the overall ratings y. This allows us to assess the robustness of our analysis that treats the five-point scale as a continuous variable. Formally stated, we replace yi in Equation (6) with latent variables ui, where

 1   2 
yi = 3
4   5

if ui  1 5 if 1 5 < ui  c2 if c2 < ui  c3 if c3 < ui  4 5 if ui > 4 5

The cutpoints (c2 c3), along with the latent variables ui, are then sampled together with other model parameters using

Figure A.1 Robustness Check with Respect to M = 50 and M = 200

M = 50

6

6

M = 200

5

5

4

4

3

3

2

2

1

1

0

0

0.0

0.2

0.4

0.6

0.8

1.0

0.0

0.2

0.4

0.6

0.8

1.0

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

239

Figure A.2 6

Robustness Check Using an Ordered Probit Model

5

4

3

2

1

0

0.0

0.2

0.4

0.6

0.8

1.0

the MCMC procedure described in Albert and Chib (1993). The estimated h t under the cutpoint model is shown in Figure A.2.
Furthermore, we also computed the aggregate weights on each quintile; the aggregate weights of the first to fifth quintiles are 0.117, 0.130, 0.133, 0.151, and 0.469, respectively. Clearly, all the results remain substantially unchanged.

References
Aaker DA, Stayman DM, Hagerty MR (1986) Warmth in advertising: Measurement, impact, and sequence effects. J. Consumer Res. 12(4):365­381.
Albert JH, Chib S (1993) Bayesian analysis of binary and polychotomous response data. J. Amer. Statist. Assoc. 88(422):669­679.
Ariely D (1998) Combining experiences over time: The effects of duration, intensity changes and on-line measurements on retrospective pain evaluations. J. Behav. Decision Making 11(1):19­45.
Ariely D, Zauberman G (2000) On the making of an experience: The effects of breaking and combining experiences in their overall evaluation. J. Behav. Decision Making 13(2):219­232.
Baumgartner H, Sujan M, Padgett D (1997) Patterns of affective reactions to advertisements: The integration of moment-tomoment responses into overall judgement. J. Marketing Res. 34(2):219­232.
Blacker IR (1998) The Elements of Screenwriting (Macmillan, New York).
Cardot H, Ferraty F, Sarda P (1999) Functional linear model. Statist. Prob. Lett. 45(1):11­22.
Cardot H, Ferraty F, Sarda P (2003) Spline estimators for the functional linear model. Statistica Sinica 13:571­591.
Casella G, Berger RL (1992) Statistical Inference, 2nd ed. (Duxbury, Pacific Grove, CA).
Choi J, Hui SK, Bell DR (2010) Spatiotemporal analysis of imitation behavior across new buyers at an online grocery retailer. J. Marketing Res. 47(1):75­89.
Corduneanu C (1991) Integral Equations and Applications (Cambridge University Press, Cambridge, UK).
Correll J, Spencer SJ, Zanna MP (2004) An affirmed self and an open mind: Self-affirmation and sensitivity to argument strength. J. Experiment. Soc. Psych. 40(3):350­356.

Dialsmith (2013) Essentials of moment-to-moment research. Report, Dialsmith, Beaverton, OR. http://dialsmith.com/ _docs/Dialsmith-Essentials-of-MtM-eBook-070813.pdf.
Evgeniou T, Pontil M, Toubia O (2007) A convex optimization approach to modeling consumer heterogeneity in conjoint estimation. Marketing Sci. 26(6):805­818.
Foutz NZ, Jank W (2010) Prerelease demand forecasting for motion pictures using functional shape analysis of virtual stock markets. Marketing Sci. 29(3):568­579.
Fredrickson BL, Kahneman D (1993) Duration neglect in retrospective evaluations of affective episodes. J. Personality Soc. Psych. 65(1):45­55.
Gelman A, Carlin JB, Stern HS, Rubin DB (2003) Bayesian Data Analysis, 2nd ed. (Chapman & Hall/CRC Press, Boca Raton, FL).
Greene WH (2011) Econometric Analysis, 7th ed. (Prentice Hall, Upper Saddle River, NJ).
Hastie T, Mallows C (1993) [A statistical view of some chemometrics regression tools]: Discussion. Technometrics 35(2):140­143.
Hastie T, Tibshirani R, Friedman J (2009) The Elements of Statistical Learning: Data Mining, Inference, and Prediction, 2nd ed. (Springer, New York).
Hays S, Shen H, Huang JZ (2012) Functional dynamic factor models with application to yield curve forecasting. Ann. Appl. Statist. 6(3):870­894.
Hughes GD (1992) Realtime response measures redefine advertising wearout. J. Advertising Res. 32(3):61­77.
James GM, Wang J, Zhu J (2009) Functional linear regression that's interpretable. Ann. Statist. 37(5A):2083­2108.
Jank W, Shmueli G (2006) Functional data analysis in electronic commerce research. Statist. Sci. 21(2):155­166.
Johnson SB (2005) Everything Bad Is Good for You: How Today's Popular Culture Is Actually Making Us Smarter (Riverhead, New York).
Kahneman D, Fredrickson B, Schreiber C, Redelmeier D (1993) When more pain is preferred to less: Adding a better end. Psych. Sci. 4(6):401­405.
Kass RE, Raftery AE (1995) Bayes factor. J. Amer. Statist. Assoc. 90(430):773­795.
Kirk R, Shrill D (2011) A digital agora: Citizen participation in the 2008 presidential debates. Amer. Behav. Scientist 55(3):325­347.
Lewis B, Lewis D, Cumming G (1995) Frequent measurement of chronic pain: An electronic diary and empirical findings. Pain 60(3):341­347.
Madrigal R, Bee C (2005) Suspense as an experience of mixed emotions: Feelings of hope and fear while watching suspenseful commercials. Adv. Consumer Res. 32:561­567.
Miron-Shatz T (2009) Evaluating multiepisode events: Boundary conditions for the peak-end rule. Emotion 9(2):206­213.
Montgomery NV, Unnava HR (2009) Temporal sequence effects: A memory framework. J. Consumer Res. 36(1):83­92.
Nelson LD, Meyvis T, Galak J (2009) Enhancing the television viewing experience through commercial interruptions. J. Consumer Res. 36(August):160­172.
Pham MT, Cohen JB, Pracejus JW, Hughes GD (2001) Affect monitoring and the primacy of feelings in judgment. J. Consumer Res. 28(September):167­188.
Polsfuss M, Hess M (1991) Liking through moment-to-moment evaluation: Identifying key selling segments in advertising. Holman RH, Solomon MR, eds. Advances in Consumer Research, Vol. 18 (Assoication of Consumer Research, Provo, UT), 540­544.
Ramanathan S, McGill AL (2007) Consuming with others: Social influence on moment-to-moment and retrospective evaluations of an experience. J. Consumer Res. 34(4):506­524.
Ramsay JO, Li X (1998) Curve registration. J. Roy. Statist. Soc. Ser. B 60(2):351­363.

Hui, Meyvis, and Assael: Analyzing MTM Data Using a Bayesian Functional Linear Model

240

Marketing Science 33(2), pp. 222­240, © 2014 INFORMS

Ramsay JO, Silverman BW (2002) Applied Functional Data Analysis: Methods and Case Studies (Springer, New York).
Ramsay JO, Silverman BW (2005) Functional Data Analysis, 2nd ed. (Springer, New York).
Redelmeier DA, Kahneman D (1996) Patients' memories of painful medical treatments: Real-time and retrospective evaluations of two minimally invasive procedures. Pain 66(1):3­8.
Redelmeier DA, Katz J, Kahneman D (2003) Memories of colonoscopy: A randomized trial. Pain 104(1­2):187­194.
Reithinger F, Jank W, Tutz G, Shumeli G (2008) Smoothing sparse and unevenly sampled curves using semiparametric mixed models: An application to online auctions. J. Roy. Statist. Soc. Ser. C 57(2):127­148.
Robinson E, Blissett J, Higgs S (2011) Peak and end effects on remembered enjoyment in low and high restrained eaters. Appetite 57(1):207­212.
Rossi PE, Allenby GM, McCulloch R (2005) Bayesian Statistics and Marketing (John Wiley & Sons, Chichester, UK).
Schreiber CA, Kahneman D (2000) Determinants of the remembered utility of aversive sounds. J. Experiment. Psych.: General 129(1):27­42.
Sood A, James GM, Tellis GJ (2009) Functional regression: A new model for predicting market penetration of new products. Marketing Sci. 28(1):36­51.
Teixeira T, Wedel M, Pieters R (2012) Emotion-induced engagement in Internet video advertisements. J. Marketing Res. 49(2):144­159.
Thorson E, Friestad M (1989) The effects of emotion on episodic memory for television commercials. Cafferata P, Tybout A, eds. Cognitive and Affective Responses to Advertising (Lexington Books, Lexington, MA), 305­325.

Todorov A, Mandisodza AN, Goren A, Hall CC (2005) Inferences of competence from faces predict election outcomes. Science 308(5728):1623­1626.
Tsay C-J (2013) Sight over sound in the judgment of music performance. Proc. Natl. Acad. Sci. USA 110(36):14580­14585.
Vanden Abeele P, MacLachlan DI (1994) Process tracing of emotional responses to TV ads: Revisiting the warmth monitor. J. Consumer Res. 20(4):586­600.
Varey C, Kahneman D (1992) Experiences extended across time: Evaluation of moments and episodes. J. Behav. Decision Making 5(3):169­185.
Wang S, Jank W, Shmueli G, Smith P (2008) Explaining and forecasting online auction prices and their dynamics using functional data analysis. J. Bus. Econom. Statist. 26(2):144­160.
West M, Harrison J (1997) Bayesian Forecasting and Dynamic Models, 2nd ed. (Springer, New York).
Wirtz D, Kruger J, Scollon CN, Diener E (2003) The role of predicted on-line, and remembered experience in future choice. Psych. Sci. 14(5):520­524.
Woltman Elpers JLCM, Mukherjee A, Hoyer WD (2004) Humor in television advertising: A moment-to-moment analysis. J. Consumer Res. 31(3):592­598.
Woltman Elpers JLCM, Wedel M, Pieters R (2003) Why do consumers stop viewing television commericals? Two experiments on the influence of moment-to-moment entertainment and information value. J. Marketing Res. 40(4):437­453.
Zhou L, Huang J, Martinez JG, Maity A, Baladandayuthapani V, Carroll RJ (2010) Reduced rank mixed effects models for spatially correlated hierarchical functional data. J. Amer. Statist. Assoc. 105(489):390­400.

