Vol. 26, No. 4, July­August 2007, pp. 553­565 issn 0732-2399 eissn 1526-548X 07 2604 0553

informs ®
doi 10.1287/mksc.1060.0249 © 2007 INFORMS

The 2005 ISMS Practice Prize Winner
Customer Equity and Lifetime Management (CELM) Finnair Case Study
Giuliano Tirenni
IBM Research, Zurich Research Laboratory, Saeumerstrasse 4, 8803 Rueschlikon, Switzerland and Marc Brandis Strategic Consulting, Grafenauweg 3, 6300 Zug, Switzerland, giuliano.tirenni@alumni.unisg.ch
Abderrahim Labbi, Cesar Berrospi, André Elisseeff
IBM Research, Zurich Research Laboratory, Saeumerstrasse 4, 8803 Rueschlikon, Switzerland {abl@zurich.ibm.com, ceb@zurich.ibm.com, ael@zurich.ibm.com}
Timir Bhose, Kari Pauro, Seppo Pöyhönen
Finnair Oyj, Lentäjäntie 3, Helsinki Airport, 01053 Helsinki, Finland {timir.bhose@finnair.com, kari.pauro@finnair.com, seppo.poyhonen@finnair.com}
The Customer Equity and Lifetime Management (CELM) solution is based on a decision-support system that offers marketing managers a scientific framework for the optimal planning and budgeting of targeted marketing campaigns to maximize return on marketing investments. The CELM technology combines advanced models of Markov decision processes (MDPs), Monte Carlo simulation, and portfolio optimization. MDPs are used to model customer dynamics and to find optimal marketing policies that maximize the value generated by a customer over a given time horizon. Lifetime value optimization is achieved through dynamic programming algorithms that identify which marketing actions, such as cross-selling, up-selling, and loyalty marketing campaigns, transition customers to better value and loyalty states. The CELM technology can also be used to simulate the financial impact of a given marketing policy using Monte Carlo simulation. This allows marketing managers to simulate several targeting scenarios to assess budget requirements and the expected impact of a given marketing policy. The benefits of the solution are illustrated with the Finnair case study, where CELM has been used to optimize marketing planning and budgeting for Finnair's frequent-flyer program (FFP).
Key words: marketing optimization; loyalty programs; Markov decision processes; portfolio optimization; marketing budget allocation; customer equity; customer lifetime value
History: This paper was received August 29, 2005, and was with the authors 7 months for 2 revisions; processed by Gary Lilien.

1. Introduction
The airline industry has made great improvements in customer relationship management. It is awash in customer data, yet most frequent-flyer programs (FFPs) take a "one size fits all" approach to marketing and service differentiation within a given elite level. Despite technological advances and data abundance, most airlines continue to guess customer value, or use inaccurate models for customer valuation. Moreover, most airlines consider the upper tier of their FFP to be their most valuable customer segment. Yet most of today's FFPs are one-dimensional, concentrating primarily on miles flown or points accrued. Unfortunately, however, elite-level travelers are not necessarily the most profitable, nor may they even be the most loyal. Although they might accumulate the most miles, they may not pay the highest fares and may be very costly to serve (for an extensive general dis-

cussion of principles and pitfalls of Loyalty Programs, see Shugan 2005).
The emergence of low-cost carriers who have started targeting business travelers has applied more significant price pressure than ever before in the airline industry. The fight for a listing in corporate travel intranets and outsourcing partners' airline options leads airlines to sign extremely lean contracts with their corporate accounts.
With loyalty becoming more of a challenge and price changes a fact of everyday business, it is less evident who the loyal customers are and how much value they leave with an airline's FFP, which delivers rewards based primarily on miles flown, regardless of ticket price.
Finnair, a leading European airline, has offered an FFP called Finnair Plus for many years. As part of its FFP, Finnair conducts numerous marketing campaigns targeting more than 700,000 customers. Each

553

Tirenni et al.: Customer Equity and Lifetime Management Finnair Case Study

554

Marketing Science 26(4), pp. 553­565, © 2007 INFORMS

customer is exposed to dozens of campaigns per year. These campaigns have different goals, such as crossand up-selling, minimizing attrition, points accrual and redemption, and tier upgrade, and are delivered through various channels, such as mailings, in-cabin brochures, the Internet, and magazines. The driving business objective of Finnair was to reduce the costs of the FFP adequately while maximizing the lifetime value of its members.
To achieve these objectives, a team of Finnair marketing managers joined forces with IBM researchers and consultants to define a business transformation process. This included redesigning the marketing strategy around Finnair's FFP and implementing change management processes at several marketing functions, such as campaign management, marketing planning, and multichannel communication. The entire project, which was carried out from February 2003 to March 2005, was executed in three phases:
1. Gain deeper customer insight by deriving finer loyalty and value metrics and more homogeneous and customer profiles.
2. Better understand customer behaviors at various phases of the relationship and the underlying levers that Finnair could act upon at every customer contact.
3. Optimize marketing resource allocation to the FFP by focusing on processes where both cost and revenue can be optimized simultaneously.
The analytical steps underlying these phases can be summarized as follows:
· Introduce advanced value and loyalty metrics and enhance existing customer profiling to capture value, loyalty, and response behavior of customers instead of focusing exclusively on transactions and miles-based segmentations.
· Identify customers' different life cycle phases and dynamics using dynamic programming techniques (Markov decision processes (MDPs)).
· Estimate customer lifetime value and risk (volatility) over variable time horizons by combining MDP models and Monte Carlo simulations to estimate the value-risk profile of customers.
· Optimize the planning of campaign sequences per customer profile to avoid saturation, in an effort to maximize the value of customers over a given planning horizon.
· Optimize marketing budget allocation to balance the value-risk tradeoff of the overall portfolio of customers using portfolio diversification techniques. The remainder of the paper is organized as follows. In §2, we provide an overview of the literature and discuss the contributions of our approach. In §3, we describe how customer dynamics can be modeled using MDPs. Sections 4 and 5 deal with the estimation of such MDPs and their application details. Sections 6 and 7 address the issue of building an optimal

customer portfolio, taking into account the risk of the marketing investment. Section 8 provides an overview of the Customer Equity and Lifetime Management (CELM) technology. Finally, §9 summarizes the paper and the business impact of CELM for Finnair. Two technical appendixes provide details of the stochastic model used to optimize customer equity.
2. Literature Review and Contributions
Quantitative approaches to the allocation of marketing resources has recently attracted increased research interest, both in the marketing (e.g., Lilien and Rangaswamy 2003, Gupta et al. 2004, Rust et al. 2004, Rust and Verhoef 2005, Tirenni 2005) as well as in the data mining and statistics communities (e.g., Gelbrich and Nakhaeizadeh 2000, Drew et al. 2001, Pednault et al. 2002, Rosset et al. 2003, Tirenni et al. 2005). There is common agreement that marketing initiatives should be evaluated by measuring their impact on customer lifetime value (Rust et al. 2000, Blattberg et al. 2001, Jain and Singh 2002), i.e., the long-term value generated by a relationship with a customer. Customer lifetime value (CLV) is defined as the sum of the discounted cash flows that a customer generates during her relationship with the company (Berger and Nasr 1998).
In this paper, we focus our analysis on dynamic programming and MDP techniques for CLV maximization (the concept of MDP itself and its application in marketing originated from the catalog industry in the 1950s, Howard 2002). Several approaches to CLV estimation using dynamic programming techniques can be found in the marketing science literature (Bitran and Mondschein 1996, Gönül and Shi 1998, Pfeifer and Carraway 2000, Pednault et al. 2002, Ching et al. 2004). However, most of these approaches present several practical limitations that are usually very important in marketing practice. These limitations are mainly related to the following issues:
· Estimation of robust MDPs when modeling the customer relationship and the effects of marketing actions over variable time horizons. To the best of our knowledge, with the exception of Simester et al. (2006), most of the models found in the literature assume some ad hoc state representation, without providing any theoretical or practical justification for the choice of state definition. In most of these models, the definition of states is based on some variations of RFM segmentation. Whereas RFM segmentation is very popular in marketing practice (Kotler 2000), there is still little theoretical motivation to justify its use for state definitions when modeling long-term customer dynamics with MDPs.
· Scalability. Practice usually requires the analysis of large volumes of customer transactions, which are

Tirenni et al.: Customer Equity and Lifetime Management Finnair Case Study

Marketing Science 26(4), pp. 553­565, © 2007 INFORMS

555

Figure 1 Example of Customer Dynamics Modeling Using an MDP

0.4/0

Do nothing

Do nothing 0.2/0

0.6/20

0.3/­ 2 S1

0.3/­ 5

0.8/50

0.7/­ 27 S2

0.7/­100 S3

Special offer

Club membership

First time/

Repeated purchase

Loyal customer

not frequent customer

0.9/0

Do nothing

0.1/20

Legend

Probability/expected reward

S

State

Action

Notes. The customers are represented into three states. The effects of marketing actions are modeled by the transition probabilities and the expected values (usually referred to as rewards in dynamic programming literature).

tracked over time and stored in some data warehouse. Even if a sample data set is usually used to estimate a model of customer behavior, the sample size can still be large enough that traditional parametric approaches (e.g., Bitran and Mondschein 1996, Gönül and Shi 1998) are no longer computationally feasible.
· Addressing the value-risk tradeoff. Existing literature does not address the value-risk tradeoff when defining an optimal portfolio of customers to be targeted according to some marketing policy.1 Traditional approaches maximize the expected customer value but do not consider the risk, or uncertainty, caused by the stochastic nature of customer behavior as well as the estimated parameters of the model. In summary, the CELM methodology provides a framework that addresses such practical requirements and in which both the customer lifetime value and the risk are optimized. Lifetime value is optimized by finding the optimal marketing policy resulting from a robust2 MDP. The risk-adjusted marketing budget allocation is achieved using financial engineering techniques for portfolio diversification.
3. Modeling Customer Dynamics with MDPs
An MDP consists of a set of states, actions, transition probabilities, and value functions (Puterman 1994). When an action is applied to a given state, the process moves stochastically to another state and generates a value (e.g., cash flow). The probabilities of moving to a target state (given the original state and the applied action) and the expected values are part of the model specification. In this way, a random sequence of states,
1 A marketing policy is defined and used in this paper as a series of marketing actions over some time horizon.
2 Robustness is addressed in this paper from an experimental perspective only.

actions, and values can be modeled, and the expected cumulative value associated with a given state under a specified policy, i.e., a mapping from state to actions, can be computed.
We model the customer behavior over time taking into account the marketing actions performed by the company. Figure 1 depicts an example of an MDP modeling the dynamics of customers subject to a set of marketing actions.
In the example shown in Figure 1, customers are represented into states S1 (low-frequency customers), S2 (repeated-purchase customers), and S3 (loyal customers). According to the model defined in this example, if a special offer is sent to a customer in state S1, there is a 0.7 probability that the customer will respond to the offer. By responding, the customer will move to state S2 and generate an expected value of -27 (negative value, due to the cost of the promotion, which can be perceived as a long-term investment that would generate a higher value later on). If customers in state S1 are not targeted, they have a lower probability of moving to state S2, but the company will not allocate marketing budget to promote a special offer.
At each time step, e.g., each month, the company can decide to target customers with the marketing actions allowed in each state. The action "do nothing" is explicitly modeled, because it represents a decision that may have a different effect on the relationship than, for instance, sending a special offer. Once all the states, the transition probabilities, and the expected values are known, it is possible to find the marketing policy that maximizes the expected long-term value generated by the relationship with the customers.
For instance, assuming that customers in state S3 are very profitable (their immediate expected profit is 0 8 × 50 = 40), it can be appropriate to send a special offer to customers in state S1 and a club membership offer to those in state S2, even if the immediate expected values are negative. The expected value

556
Figure 2 Example of an Episode for a Given Customer

Tirenni et al.: Customer Equity and Lifetime Management Finnair Case Study Marketing Science 26(4), pp. 553­565, © 2007 INFORMS
Time horizon

Customer 667

State/action/reward State/action/reward State/action/reward State/action/reward ...

B/mail/­ 2

B/email/+30

A/do nothing/0 A/do nothing/+40 ...

Event

Episode
Notes. The initial customer state is B. After receiving a mailing, the generated value (reward) is -2 and the next state is still B. Then an e-mail campaign causes the customer to move to state A and a value of 30 is generated, and so on.

of sending a special offer to customers in state S1 is -27 × 0 7 - 2 × 0 3 = -20 4, whereas the expected value of sending a club membership offer to customers in state S2 is -100 × 0 7 - 5 × 0 3 = -71 5. Therefore, a short-sighted marketing policy would not send any offer to customers in states S1 and S2. Such a policy would not take into consideration the long-term value generated by upgrading customers to state S3. Once a marketing policy is fixed, the future customer dynamics can be simulated for a given time horizon and the distribution of the future values can be estimated.

4. Estimation of MDP
We assume that customers are represented into different states such as those defined in Appendix A and that customer historical data are available. For each customer, the historical data consist of a sequence of events. Each event is defined by a triplet s a r composed of a state s, an action a, and a value r. The next event is defined by the triplet s a r , where s is a potential new state after applying action a to s and so on. Each customer has an associated sequence of events, defined as an episode, that spans a given time window. Figure 2 defines the structure of an episode for a given customer.
To completely specify the MDP, we need to define the state space, the action space, the transition probabilities and the expected values. Given historical customer data D, the state and action spaces are obtained by considering, respectively, all the states and all the actions (as defined above) that appear in D. To estimate the transition probabilities, we can simply use the maximum likelihood estimator

ps

s

a

=

#

s #

s

s a

a

(1)

where # s s a is the total number of transitions from s to s if action a is applied, and # s a is the total number of times action a is applied to state s.

Because we are estimating the transition probabilities from a limited sample of data, we can assume that the absence of particular transitions does not necessarily imply that the real probabilities are zero or undefined. To address these two issues we adopt a Bayesian approach incorporating a prior model of transition probabilities p^s s a into Equation (1). This leads to the following estimator (Mitchell 1997) for the posterior probability

ps

s

a

# =

s

s a + m1p^s # s a + m1

sa

(2)

It is easy to verify that, when # s a = 0, the posterior and the prior probabilities are the same. The value of m1 can be interpreted as the number of instances following the prior probability that are injected into the data set D. The variable m1 acts therefore as a weight defining the relative importance of the prior probability with respect to the probability estimated from the data.
There are two possibilities to model the prior transition probability p^s s a: (a) adopt a state-driven approach, emphasizing the role of the origin state, or (b) adopt an action-driven approach, emphasizing the role of the action. In the state-driven case, the prior is modeled as follows3:

p^s s a = p s

#s s=

s + m2p^s s

# s + m2

(3)

where # s is the number of times state s appears in the data set D and # s s is the number of times a transition from state s to state s is observed. Finally, the nested prior p^s s is estimated as follows:

p^s s = p s

=

# s + m3p^ sS # s + m3

(4)

3 We used the Laplace estimator (Witten and Frank 1999) to estimate p^.

Tirenni et al.: Customer Equity and Lifetime Management Finnair Case Study

Marketing Science 26(4), pp. 553­565, © 2007 INFORMS

557

In the action-driven approach, the prior is modeled as follows:

p^s s a = p s

a

=

#

s

#

a a

+ m2p^s + m2

a

(5)

where # a is the number of times action a appears in the data set D and # s a is the number of times that a transition to state s is due to the application of action a.
The expected value r s a if action a is applied to state s can be estimated as follows:

rs a=

s a D r s a #s a

(6)

where r s a is the value observed in the data when action a is applied to state s. If # s a is zero or null, because action a has never been applied to state s, we can estimate the expected value considering either a state-driven approach or an action-driven approach. The state-driven estimate is

r s a = r s = s D r s a

(7)

#s

whereas the action-driven estimate is

r s a = r a = a D r s a

(8)

#a

5. Customer Portfolio Optimization

Approach

In the previous section, we showed how to model an

MDP and simulate a targeting policy over a given

time horizon. We imposed no constraints so far on the

total cost implied by such a policy. However in prac-

tice, marketing plans are usually subject to budgeting

constraints. Because some policies cannot be applied

to all customers, one has to determine the optimal

number of customers per state to be targeted at each

decision time. To answer this question, we adopt

the classical mean-variance formulation framework for

portfolio optimization. The following definitions will

be used to formule the optimization problem:

ast is the number of customers to target in state s, at time t, using action a. We will refer to these as

the target or decision variables in the optimization

problem.

rast is the average value generated by customers in state s, at time t, when targeted with action a.

2 ast

is the variance of the value generated by cus-

tomers in state s, at time t, when targeted with

action a.

cast is the average cost per customer in state s, at time t, when targeted with action a.

The mean and variance of the distribution of the value generated by an action a at time t can then be written as

Ra t =

astrasr and

s

2a t =

22 ast asr

(9)

s

The above definition assumes independence of values generated by different states at each decision time. This assumption can be motivated by the fact that customers are individuals whose responses to a targeted marketing action are independent from each other.
The budget-constrained optimization problem amounts to finding the optimal target variables ast that maximize the cumulated expected value R a t while minimizing the variance 2 a t over a and t. The expected targeting cost is constrained to be below a user-defined budget B and is represented as a linear constraint: a s t ast  B.
Additional constraints related to the total size of customer set are considered. These constraints can be divided into two categories:
1. Customer dynamics constraints: represent the fact that the total number of customers across all states is constant. Any customer moving out of a state at time t should be in another state at time t + 1. For such a purpose, the set of possible states should include future prospects and inactive customers to account for new acquisitions and defections. These constraints are represented as

as t+1 =

as t · P s s a for t > 0

(10)

a

as

The term as t · P s s a represents the number of customers expected to be in state s at time t + 1 after receiving action a and starting from state s . The sum of these numbers over all actions and all previous states s should be identical to the number of customers in state s at time t + 1, which is equal to
a as t+1 . 2. Initial state constraint: the previous set of inequalities would be ill-defined if there were no initial condition on the number of customers per state. Therefore, the number of customers in state s at time t = 0 is a constant in the optimization problem. This is simply measured by the initial distribution of customers across different states. This set of constraints is represented as

as0 = Ss

(11)

a

where Ss is the number of customers in state s at time t = 0.

Tirenni et al.: Customer Equity and Lifetime Management Finnair Case Study

558

Marketing Science 26(4), pp. 553­565, © 2007 INFORMS

Putting it all together yields the following optimization problem:

Maximize R a t - 2 a t

ast

at

=

ast rast -

22 ast ast

ast

ast

subject to -

ast  B

ast

(Budgeting constraint: B is the total

available budget)

- For all s

as0 = Ss

a

(Initial state constraints: Ss is the

cardinality of the state s at time t = 0)

- For all s and for t > 0

as t+1 =

as t · P s s a

a

as

(Customer dynamics constraints).

The parameter controls the trade-off between the

mean (expected) and the variance of the value gener-

ated by a policy.

The solution of this problem provides a natural

way to define a constrained marketing policy. Let us

denote by

 ast

the

optimal

value

for

the

target

vari-

able. The optimal policy  is defined as

 s a t = ast
ast a

where  s a t is the fraction of customers in state s

at time t to target with marketing action a. This policy

can be compared with the historical policy by replac-

ing the optimal target variable

 ast

by

some

value

derived from historical data. The latter can be derived

in different ways. Appendix B describes a possible

method when the marketing policy is assumed to be

stationary.

It is important to note that the optimization pro-

vides only the optimal number of customer to be tar-

geted in each state at each time. The customers who

will actually be targeted in each state are selected

using some scoring mechanism that can be driven by

any type of criteria (e.g., demographics, probability to

respond, etc.).

Most of the related existing marketing litera-

ture (e.g., Blattberg and Deighton 1996; Pfeifer and

Carraways 2000; Rust et al. 2000, 2004; Blattberg

et al. 2001; Gupta and Lehmann 2003; Lilien and

Rangaswamy 2003; Gupta et al. 2004; Johnson and

Selnes 2004) has focused on the allocation of mar-

keting resources to optimize the expected customer

equity or the expected customer lifetime value. How-

ever, if marketing investments are to be evaluated

from a financial perspective, for example as in Doyle

Table 1 Customer Characteristics

Customer characteristics

Description

rectrip freqtrip3 freqtrip12 value3
value3camp
value12 value12camp
miles3 miles12 longevity

Time elapsed since last trip Number of trips in the past 3 months Number of trips in the past 12 months Value generated by the customer in the
past 3 months Value generated from campaigns only
(in the past 3 months) Value generated in the past 12 months Value generated from campaigns only
(in the past 12 months) Miles flown in the past 3 months Miles flown in the past 12 months Number of days since first trip

(2000) and Srivastava et al. (1998), then the risk of the investment should be quantified and managed as in common financial engineering practice (Brealey and Myers 1996, Luenberger 1997).
The current formulation that we introduced in this study is a first attempt to encode the risk (measured by variance) information about the return4 on marketing actions. By changing the parameter , which controls the trade-off between maximizing the expected value and minimizing the variance, the user can derive a variety of marketing policies that would reflect the risk appetite of the decision maker.
6. Finnair Application Details
To optimize Finnair's marketing policies for its frequent flyers, we first needed to estimate a robust MDP model of customer dynamics. To estimate the model, we consider historical data for a period of 2 years (2002, 2003). The actual customer characteristics used by Finnair are not reported here for confidentiality reasons. To illustrate the CELM methodology, we represent a customer with the set of numerical characteristics defined in Table 1.
After removing outliers,5 we randomly extract a sample of 10,000 customers. The customers are then assigned randomly to two sets of size 5,000. These are the validation set used in the model selection phase, and the evaluation set, used to predict the future longterm value by simulating the historical and the optimal policies.
We define customer states as the clusters, resulting either from a discretization of certain variables (e.g., RFM), or from statistical clustering procedures. It is
4 Return on a marketing action is defined as the value generated by all customers who were targeted by that action.
5 We removed marketing actions that were applied very rarely and customers whose cumulative (historical) value is larger than the 99th percentile.

Tirenni et al.: Customer Equity and Lifetime Management Finnair Case Study

Marketing Science 26(4), pp. 553­565, © 2007 INFORMS

559

Table 2
Number
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27

List of Clustering Schemes Used

Clustering scheme

Characteristics used

RFM (10) RFM (20) RFM (30) RFM (10) RFM (20) RFM (30) ABC 10 10 80 ABC 10 20 70 ABC 10 10 80 ABC 10 20 70 VD 10 10 80 VD 10 20 70 VD 10 10 80 VD 10 20 70 RV 10 10 80 RV 10 20 70 RV 10 10 80 RV 10 20 70 Trees (10) Trees (29) K -means (10) K -means (15) K -means (20) K -means (30) SOM (3 × 3) SOM (3 × 5) SOM (4 × 5)

value3, freqtrip3, rectrip value3, freqtrip3, rectrip value3, freqtrip3, rectrip value12, freqtrip12, rectrip value12, freqtrip12, rectrip value12, freqtrip12, rectrip
value3 value3 value12 value12 value3, freqtrip3, rectrip value3, freqtrip3, rectrip value12, freqtrip12, rectrip value12, freqtrip12, rectrip value3, rectrip value3, rectrip value12, rectrip value12, rectrip
all all all all all all all all all

important to note that the states are defined in such a way that a transition between any pair of states is possible.
We perform model selection by evaluating the predictive performance of various MDPs based on the following clustering schemes for state definition (Table 2).
A detailed description of the different clustering schemes is given in Appendix A. The CLV is estimated using Monte Carlo simulation on the MDP estimated in §4. Monte Carlo simulation allows us to apply a given marketing policy to an MDP and obtain a distribution of lifetime value for each state. From this distribution, we can compute the expected value and variance (as a measure of risk). In the following experiments, customer lifetime value is estimated for the next 12 months. Therefore it does not incorporate any historical value or estimates beyond a 12-month horizon. Each model is tested using both the statedriven and the action-driven approaches including the validation set. In Figure 3, we report the mean absolute errors,6 computed using cross-validation,7
6 The error is defined as the predicted value minus the observed value.
7 Cross-validation refers to estimating and testing the model over several data partitions, then computing the mean and standard deviation of the estimation error.

of each model for the state-driven and the actiondriven approaches. The state-driven approach seems to slightly outperform the action-driven approach for all the state definitions considered here. Therefore, we focus on the state-driven approach in the remainder of this paper.
By examining Figure 3, one can notice that: · State definitions based on RFM segmentation (e.g., 1, 2, 3, 4, 5, 6), which has been largely used in the literature (Bitran and Mondschein 1996, Gönül and Shi 1998, Pfeifer and Carraway 2000, Ching et al. 2004), is not necessarily the optimal way to model customer dynamics. · MDPs using states which are derived from clustering-based techniques such as regression trees (e.g., 19, 20) and self-organizing maps (e.g., 27) usually outperform the RFM-based MDPs (e.g., 1, 2, 3, 4, 5, 6). · MDPs that use even simpler clustering criteria, which cluster only based on the historical value (e.g., 9, 10), result in performance comparable to that from using RFM-based MDPs. Figure 4 shows a comparison of the expected values per state, obtained by simulating the MDP for 12 months with 30 bootstrap samplings using the optimal and the historical8 policies. The optimal policy, obtained using dynamic programming, outperforms the short-sighted historical policy according to the model simulations. In states S1 and S3 significant gains are made by applying the optimal policy rather than the historical one. These gains in lifetime value are due to several reasons: customers in state S1 are characterized by having a high response rate to marketing campaigns that offer points accrual. For these customers, CELM has identified a set of sequential patterns, such as first sending a series of campaigns offering bonus points and subsequently sending campaigns offering points and cash offers, where customers can buy tickets with a combination of cash and points. The flight frequency of these customers is therefore significantly increased, resulting in a higher value and loyalty. Customers in state S3 are a subset of the upper tiers members, which are characterized by high loyalty (Gold and Platinum). However, despite their high flight frequency, these customers have low response rates to several kinds of campaigns. Some of these premium campaigns can be much more costly than the average campaign. These customers have also shown a stronger appetite for collecting bonus points. The optimal marketing policy produced by CELM targets these customers with a combination of cost aware marketing activities on the one hand (including the omission of some campaigns), and on the other hand
8 Estimation of the historical marketing policy is described in Appendix B.

Tirenni et al.: Customer Equity and Lifetime Management Finnair Case Study

560

Marketing Science 26(4), pp. 553­565, © 2007 INFORMS

Figure 3 Comparison of Mean Absolute Errors of Predicting the Value Generated in 12 Months for State-Driven and Action-Driven Approaches

4,000 3,500 3,000

State-driven Action-driven

Mean absolute error

Mean absolute error

2,500

2,000

1,500

1,000

500

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 Segment ID
Note. Segment ssID refers here to the clustering scheme used to define the states of the MDP.

cross-selling campaigns such as points accrual, and Top Club (all-inclusive travel packages), which allow these customers to earn and redeem large amounts of bonus points. The lifetime value of customers in state S2 is therefore maximized by minimizing targeting cost as well as maximizing cross-sell revenue.
Figure 5 shows the distribution of marketing campaigns for customers in state S3 during a given time period. The pie chart on the left corresponds to the campaign distribution as observed in historical data, whereas the chart on the right shows the optimal campaign distribution as estimated by CELM. The optimal policy suggests sending no campaigns to about 60% of the customers in state S3, whereas this decision applied to only 25% of customers if the historical policy is used. Reducing the frequency of such campaigns (e.g., points and cash), results in significant cost savings and avoids customer saturation, as high tier members of most loyalty programs tend to receive large amounts of campaigns. On the other hand, the

Figure 4

Comparison of the Expected Long-Term Value, Per State, Generated in 12 Months Using the Optimal and the Historical Policy

Value in 12 months

10,000 9,000 8,000 7,000 6,000

Optimal vs. historical policy

Historical Optimal

5,000 4,000 3,000 2,000

1,000 0 S1 S2 S3 S4 S5 S6 S7 S8 State

Note. The states are defined using decision trees (trees (10) in Table 2).

optimal policy recommends combining points and cash campaigns with Top Club campaigns. These are campaigns where customers can buy customized travel packages using points and cash. The optimal policy also strongly favors the points accrual campaigns, which offer bonus points (double or triple regular points). This may be explained by the fact that special benefits and campaigns targeting upper tiers require a large volume of accrued points, which may draw customers in S3 to respond to points accrual campaigns more frequently.
The optimized policy calculation and implementation is illustrated in Figure 6.
7. CELM Technology
In this section, we briefly describe the main functionalities and software components of the CELM system. CELM consists of the following main components:
· CELM data model: This component allows the selection of the customer historical data by connecting to various data sources where customers' behavioral and the demographic characteristics are stored. Moreover this component computes derived customer metrics such as loyalty indices, value, recency, frequency, etc. Some examples of these characteristics are reported in Table 1.
· State definition models: This component discretizes a high-dimensional customer characteristics space into a finite number of customer states. There is a list of proposed partitioning algorithms, including statistical clustering algorithms. Some of these algorithms are described in Table 2. Moreover, the system allows us to import other partitioning criteria, which can be defined by the end user. If the user has existing state definitions, then there is no need to perform this step.
· Customer dynamics modeling: Using some state definition, which can be derived in the previous step,

Tirenni et al.: Customer Equity and Lifetime Management Finnair Case Study

Marketing Science 26(4), pp. 553­565, © 2007 INFORMS

561

Figure 5

Comparison Between Historical (Left) and Optimal (Right) Marketing Action Distribution for State S3

From historical ...

... To optimal

Points and cash and points

No campaign

Points and cash and top club

No campaign

Points and cash

Points accrual

an MDP is estimated, which models the customer dynamics. By fixing a time horizon and using Monte Carlo simulations, the customer lifetime value generated by the historical marketing policy is computed. Moreover, using dynamic programming, the optimal marketing policy and the optimal customer lifetime value are estimated.
· Marketing budget allocation: Using the MDP estimated in the previous step, a time horizon (e.g., 12 months), and a marketing policy, the financial profile of each customer state is derived by means of Monte Carlo simulations. The optimal customer portfolio that maximizes expected future value while minimizing risk (variance) is then derived using the optimization framework described in §5. For each customer state, the amount of marketing budget to invest and the actions to be used are derived.
Figure 7 illustrates the main window of the graphical user interface (GUI) of the system and the wizard to create clustering models. The user is guided through the various steps.

Figure 6

For Each Customer, CELM Suggests an Optimal Marketing Plan (i.e. a Series of Marketing Actions) over the Time Horizon Considered, Which Would Maximize the Likelihood That the Customer Will Move to Better Value/Loyalty States

State: Medium loyalty and medium value Sequence of actions: PO campaign, PC campaign, PA campaign Exp. revenue: 850 $ Next state: High loyalty and high value

2 ­ CELM recommends a sequence of specific
campaigns

4 ­ The customer moves to a better state
PC PA

Loyalty index

CELM

Campaign plan Revenue

3 ­ The customer brings a benefit when she
responds to the campaign

PO
1 ­ A customer is in a given state
Value index

Figure 8 depicts the MDP modeling the customer dynamics. The user can explore the financial profile of each customer state in time (lower right panel). Moreover the most likely future path of each customer can be visualized and the probability of ending in a given state (e.g., defection state) is estimated.
The user can simulate the financial impact of several marketing actions over a given time horizon. It is in fact possible to derive the Markov chain that results from applying an arbitrary marketing policy to the MDP. In this way, several marketing scenarios can be simulated and evaluated.
Figure 9 shows the results of the optimization problem with a given marketing budget. The inset table displays the number of customers in every state that need to be targeted at every time period, according to the optimal policy. The user can explore the final distribution of the campaign budget and the expected results by means of the customer states (lower left chart) and the marketing campaigns (lower right chart).

Figure 7

Main Interface of the CELM System Showing the Clustering Models Wizard (for Definition of States to Be Later Used By the MDP)

Tirenni et al.: Customer Equity and Lifetime Management Finnair Case Study

562

Marketing Science 26(4), pp. 553­565, © 2007 INFORMS

Figure 8

MDP of Customer Dynamics in CELM. The Thick Red Line Shows the Trajectory Followed by the Customer 13080 (Selected in the Left Panel)

Note. The trajectory shows the states through which the customer has been moving together with the marketing actions (campaigns) that targeted such customer. Figure 9 Allocation of Marketing Budget According to the Optimal Policy
Note. The pie chart on the left shows the distribution of the expected costs (can display also revenue) over different states at any decision point. The pie on the right shows the distribution of costs over the different actions.

Tirenni et al.: Customer Equity and Lifetime Management Finnair Case Study

Marketing Science 26(4), pp. 553­565, © 2007 INFORMS

563

8. Summary and Business Impact
In this paper, we described the CELM solution and how it was applied to optimize Finnair's customer relationship management processes within their frequent-flyer program. The overall process behind the CELM solution can be divided in the following two main tasks:
· Optimize the customer lifetime value by modeling the customer dynamics and finding the optimal marketing plan (i.e., marketing policy) that maximizes the expected lifetime value of each customer and,
· Allocate the available marketing budget to maximize the total customer equity by optimizing the value-risk tradeoff over the customer portfolio. For the first point, we provide a rigorous methodology to estimate MDPs to model customer dynamics. Using cross-validation for model selection, we are able to build a robust MDP taking into account the uncertainty of the parameters of the model and its impact on the predictive performance. Finnair data showed that the popular RFM segmentation does not always lead to the best state definition model, both in terms of likelihood and prediction error. State definitions that are based on statistical clustering, such as regression trees and self-organizing maps, or simple partitioning criteria based on value generated in the previous 12 months, lead to MDPs with comparable performance to RFM-based MDPs.
As to the second point, our methodology explicitly considers the risk embedded in the targeting policies. As the distributions of future ROI can be estimated, the model allows for risk-sensitive resource allocation as expressed by the value-risk formulation of the optimization problem.
As a result of using CELM, Finnair has reported a significant impact on the planning of its marketing campaigns and the allocation of its marketing resources. CELM data has been used by Finnair to derive highly homogeneous and actionable customer profiles in its FFP. CELM has proved very effective in supporting Finnair's marketing managers to move from mileage-based to value-based management of frequent flyers. The benefits reported by Finnair have shown a significant reduction of marketing costs-- more than 20%--as well as improved response rates by up to 10% among members of its FFP.9 Finnair plans to integrate CELM into the new generation loyalty system that it is currently installing. In terms of IBM internal recognition, CELM was featured in the 2003 IBM Annual Report as a benchmark of innovation. It also received the IBM Research Award for Innovation in 2004.

Transportability. The CELM solution has also been adopted by IBM clients in other industries where loyalty and value-based marketing is an increasingly pressing and challenging issue (such as in telecommunications, retail, and banking). The solution is transportable to any industry where companies are able to identify their customers and engage in direct targeted marketing activities. Many CRM packages today allow companies to collect and store massive amounts of historical data about their marketing actions and customer reactions. CELM can be used as a solution to optimize future marketing activities based on best (and worst) experience. Therefore, the CELM solution is largely transportable and relevant to many industries.
Acknowledgments The authors extend greater thanks to our (ex)colleague Daniel Ramage for support with the implementation of CELM, as well as Tarja Ruuska, Kirsti Lindfors, and Chris Rospenda from IBM for their continuous support and advice during the whole project. We also thank Kari Heinonen and Toni Korppi for valuable insight on Finnair Plus Programme and support that contributed to the success of this project.
Appendix A. Defining Customer States for MDPs To build an MDP that models customer dynamics, one usually needs to discretize a high-dimensional customer characteristics space into a finite number of states. We propose a list of clustering (partitioning) criteria, which can be divided into two categories: (a) scoring-based clustering, and (b) statistical-based clustering.
Scoring-Based Clustering. These are usually obtained by using recency, frequency, and monetary value. Each clustering criterion can have several parameters. The clusters are defined as follows.
· RFM n : The global customer score is determined first by the recency score, then by the frequency score, and finally by the monetary value score. The ranked customers are then divided into n clusters of equal size. Each cluster is defined by an interval of values for recency, frequency, and monetary values.
· ABC a, b, c : This scores customers according to value, e.g., the value in the previous 3 months, and generates three clusters by assigning the first a% to cluster A, the next b% to cluster B, and the remaining c% to cluster C. Customers in clusters A and B usually account for most of the total generated value.
· VD a, b, c : The value-defectors clustering performs ABC a b c partitioning on value and loyalty characteristics.10 By discretizing both characteristics in three intervals (A B C), the resulting clusters are simple combinations of intervals (e.g., AA, AB, AC, etc.).
· RV a, b, c : Recency-value clustering is similar to VD but considers value and recency.

9 As reported in The New York Times Journal (Jan. 24, 2004) by Eero Ahola, Finnair's Senior Vice President for Business Development and Strategy.

10 The loyalty index is a function of the frequency and the longevity of a customer and has been used by IBM in different CRM projects as a metric for customer loyalty.

Tirenni et al.: Customer Equity and Lifetime Management Finnair Case Study

564

Marketing Science 26(4), pp. 553­565, © 2007 INFORMS

Statistical-Based Clustering. The following are statistical clustering-based state definitions that use all available customer characteristics.
· Trees n : Regression trees (Breiman et al. 1984) are used for supervised clustering. A regression tree is trained to predict the immediate value of each customer. The leaves of the tree correspond to the clusters, which define the states. The parameter n indicates the number of leaves in the final tree. Each leaf represents a region in the characteristics space. The characteristics space is partitioned to minimize the value prediction error and consequently the variance in each region.
· SOM n m : Self-organizing maps (Kohonen 1997) allows one to map a high-dimensional characteristics space into a two-dimensional map (an n × m grid). The main idea can be described as follows: each cell in the map has an associated vector wi, which has the same dimension as the characteristics space. In total there are n × m such vectors. The training is incremental and all weight vectors and training examples are assumed to be normalized before training starts. For each training example x, the Euclidean distance between all the weight vectors wi and x is computed. Then, the weight vector wj , which is closer to x, is selected, and all weight vectors wi that are neighbors of the winner wj are updated according to the Kohonen rule:

wi = wi + x - wi

(A1)

where the learning rate decreases slowly from 1 to 0. Neighbors are defined based on the position of the cells on the grid (we use all the cells that are adjacent to the winning cell). In practice, the self-organizing map has been shown to be less sensitive to various definitions of neighborhoods.
· K-means n : K-means clustering (Hastie et al. 2001) derives n clusters, which are the centers minimizing the total within-cluster variance V , defined as

V

=

1n 2 i=1 C m =i C m

=i

xm - xm

2

(A2)

where C m is the mapping that associates a cluster (indexed from 1 to n) to the mth training example xm, and the norm is computed using Euclidean distance. The following iterative algorithm can be used to minimize V :
(a) Initialize n cluster centers randomly, (b) Associate each data point to the nearest cluster center, (c) Recompute the cluster centers, (d) Repeat step b until a given stopping condition is met. Usually the stopping condition is specified by the maximum number of possible iterations. Moreover, if the centers do not change, the algorithm stops and assumes a solution has been found. It can be shown that this algorithm always decreases the within cluster variance V , but convergence to a global minimum is not guaranteed. In practice the algorithm starts from different randomly chosen initial configurations and selects the solution with lowest variance.

Appendix B. Estimation of the Historical Marketing Policy We define a historical marketing policy as the policy that has been used so far by the company to target customers.

Knowing the historical policy allows us to simulate the customer dynamics in the future if the same policy is applied again. In fact, once the MDP and the historical policy are estimated from the available data, it is possible to derive the Markov chain that allows us to model how customers are likely to transition over a given time horizon.
We learn from the available historical data a stochastic policy, assuming that it is stationary, and estimate the probability of applying action a to state s as follows:

a

s

#a =

s

+m

as

(B1)

# s +m

where # a s is the number of events with state s and action a, and # s is the number of events with state s. The quantity a s is the prior probability of applying action a to state s. We define the prior probability using the Laplace estimator as follows:

a s=p a =

# a +1 aA # a + A

(B2)

where # a is the total number of actions of type a in all the events and A is the number of available actions.
We consider the number of events in all decision epochs (i.e., time steps), because we do not condition on a particular epoch. However, we could estimate a time-dependent policy by computing the above probabilities for each individual time step.

References
Berger, P. D., N. I. Nasr. 1998. Customer lifetime value: Marketing models and applications. J. Interactive Marketing 12(1) 17­30.
Bitran, G. R., S. V. Mondschein. 1996. Mailing decisions in the catalog sales industry. Management Sci. 42(9) 1364­1381.
Blattberg, R., J. Deighton. 1996. Manage marketing by the customer equity test. Harvard Business Rev. 74(4) 136­144.
Blattberg, R. C., G. Getz, J. S. Thomas. 2001. Customer Equity: Building and Managing Relationships as Valuable Assets. Harvard Business School Press, Boston, MA.
Brealey, R., S. Myers. 1996. Principles of Corporate Finance. McGrawHill, New York.
Breiman, L., J. H. Friedman, R. A. Olshen, C. J. Stone. 1984. Classification and Regression Trees. Wadsworth Int. Group, Boca Raton, FL.
Ching, W. K., M. K. Ng, K. K. Wong, E. Altman. 2004. Customer lifetime value: Stochastic optimization approach. J. Oper. Res. Soc. 55 860­868.
IBM Corporation. 2003. IBM Annual Report, page 19. http://www. ibm.com/annualreport/2003/
Doyle, P. 2000. Value-based marketing. J. Strategic Marketing 8 299­311.
Drew, J. H., D. R. Mani, A. L. Betz, P. Datta. 2001. Targeting customers with statistical and data-mining techniques. J. Service Res. 3(3) 205­219.
Efron, B., R. J. Tibshirani. 1993. An Introduction to the Bootstrap. Chapman & Hall, New York.
Gelbrich, K., R. Nakhaeizadeh. 2000. Value miner: A data mining environment for the calculation of the customer lifetime value with application to the automotive industry. Proc. Eleventh Eur. Conf. Machine Learn., Vol. 1810. Springer-Verlag, Berlin, Germany, 154­161.
Gönül, F., M. Z. Shi. 1998. Optimal mailing of catalogs: A new methodology using estimable structural dynamic programming models. Management Sci. 44(9) 1249­1262.

Tirenni et al.: Customer Equity and Lifetime Management Finnair Case Study

Marketing Science 26(4), pp. 553­565, © 2007 INFORMS

565

Gupta, S., D. R. Lehmann. 2003. Customers as assets. J. Interactive Marketing 17(1) 9­24.
Gupta, S., D. R. Lehmann, J. A. Stuart. 2004. Valuing customers. J. Marketing Res. 41(1) 7­18.
Hastie, T., R. Tibshirani, J. H. Friedman. 2001. The Elements of Statistical Learning. Springer-Verlag, NY.
Howard, R. A. 2002. Comments on the origin and application of Markov Decision Processes. Oper. Res. 50(1) 100­102.
Jain, D., S. S. Singh. 2002. Customer lifetime value research in marketing: A review and future directions. J. Interactive Marketing 16(2) 34­46.
Johnson, M. D., F. Selnes. 2004. Customer portfolio management: Toward a dynamic theory of exchange relationships. J. Marketing 68 1­17.
Jorion, P. 2001. Value at Risk: The New Benchmark for Managing Financial Risk. McGraw-Hill, Boston, MA.
Kohonen, T. 1997. Self-Organizing Maps, 2nd ed. Springer-Verlag, Berlin, Germany.
Kotler, P. 2000. Marketing Management, 10th ed. Prentice-Hall, NJ.
Law, A. M., W. D. Kelton. 2000. Simulation Modeling and Analysis, 3rd ed. McGraw-Hill, Boston, MA.
Lilien, G. L., A. Rangaswamy. 2003. Marketing Engineering, 2nd ed. Prentice Hall, NJ.
Luenberger, D. G. 1997. Investment Science. Oxford University Press, Oxford, UK.
Markowitz, H. 1952. Portfolio selection. J. Finance 7 77­91.
McClave, J. T., G. P. Benson, T. Sincich. 1998. Statistics for Business and Economics, 7th ed. Prentice-Hall, Inc., Upper Saddle River, NJ.
Mitchell, T. M. 1997. Machine Learning. McGraw-Hill, Boston, MA.
Pednault, E., N. Abe, B. Zadrozny, H. Wang, W. Fan, C. Apte. 2002. Sequential cost-sensitive decision making with reinforcement learning. Proc. Eighth ACM SIGKDD Internat. Conf. Knowledge Discovery and Data Mining, ACM, Edmonton, Alberta, Canada, 259­268.

Pfeifer, P., R. Carraway. 2000. Modeling customer relationships as Markov chains. J. Interactive Marketing 14(2) 43­55.
Puterman, M. L. 1994. Markov Decision Processes: Discrete Stochastic Dynamic Programming. John Wiley & Sons, New York.
Rosset, S., E. Neumann, U. Eick, N. Vatnik, S. Idan. 2003. Lifetime value models for decision support. Data Mining Knowledge Discovery J. 7 321­339.
Rust, R., P. C. Verhoef. 2005. Optimizing the marketing interventions mix in intermediate-term CRM. Marketing Sci. 24(3) 477­489.
Rust, R., K. Lemon, V. Zeithalm. 2004. Return on marketing: Using customer equity to focus marketing strategy. J. Marketing 68 109­127.
Rust, R., V. Zeithaml, K. Lemon. 2000. Driving Customer Equity: How Customer Lifetime Value is Reshaping Corporate Strategy. Simon & Schuster, London, UK.
Shugan, S. M. 2005. Editorial: Brand loyalty programs: Are they shams? Marketing Sci. 24(2) 185­381.
Simester, D. I., P. Sun, J. N. Tsitsiklis. 2006. Dynamic catalog mailing policies. Management Sci. 52(5) 683­696.
Srivastava, R. K., T. A. Shervani, L. Fahey. 1998. Market-based assets and shareholder value: A framework for analysis. J. Marketing 62 2­18.
Sutton, R. S., A. G. Barto. 2000. Reinforcement Learning: An Introduction. The MIT Press, Cambdridge, MA.
Tirenni, G. 2005. Allocation of marketing resources to optimize customer equity. Ph.D. thesis, University of St. Gallen, Switzerland. http://www.unisg.ch/edis.
Tirenni, G., A. Labbi, A. Elisseeff, C. Berrospi. 2005. Efficient allocation of marketing resources using dynamic programming. Proc. Fifth SIAM Internat. Conf. Data Mining, April 21­23, 2005, Newport Beach, CA.
Witten, I. H., E. Frank. 1999. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufmann, San Francisco, CA.

