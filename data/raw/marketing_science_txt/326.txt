Vol. 34, No. 1, January­February 2015, pp. 1­19 ISSN 0732-2399 (print) ISSN 1526-548X (online)

http://dx.doi.org/10.1287/mksc.2014.0868 © 2015 INFORMS

Learning from Experience, Simply

Song Lin, Juanjuan Zhang, John R. Hauser
MIT Sloan School of Management, Massachusetts Institute of Technology, Cambridge, Massachusetts 02139 {songlin@mit.edu, jjzhang@mit.edu, hauser@mit.edu}
There is substantial academic interest in modeling consumer experiential learning. However, (approximately) optimal solutions to forward-looking experiential learning problems are complex, limiting their behavioral plausibility and empirical feasibility. We propose that consumers use cognitively simple heuristic strategies. We explore one viable heuristic--index strategies--and demonstrate that they are intuitive, tractable, and plausible. Index strategies are much simpler for consumers to use but provide close-to-optimal utility. They also avoid exponential growth in computational complexity, enabling researchers to study learning models in more complex situations.
Well-defined index strategies depend on a structural property called indexability. We prove the indexability of a canonical forward-looking experiential learning model in which consumers learn brand quality while facing random utility shocks. Following an index strategy, consumers develop an index for each brand separately and choose the brand with the highest index. Using synthetic data, we demonstrate that an index strategy achieves nearly optimal utility at substantially lower computational costs. Using IRI data for diapers, we find that an index strategy performs as well as an approximately optimal solution and better than myopic learning. We extend the analysis to incorporate risk aversion, other cognitively simple heuristics, heterogeneous foresight, and an alternative specification of brands.
Keywords: forward-looking experiential learning; index strategies; structural models; cognitive simplicity; heuristics; multi-armed bandit problems; restless bandit problems; indexability
History: Received: August 10, 2012; accepted: April 9, 2014; Preyas Desai served as the editor-in-chief and Teck Ho served as associate editor for this article. Published online in Articles in Advance September 5, 2014.

1. Introduction and Motivation
Considerable effort in marketing is devoted to studying the dynamics by which consumers learn from their consumption experience (e.g., Roberts and Urban 1988, Erdem and Keane 1996, Ching et al. 2013a). As an example, imagine new parents who have to shop for diapers, perhaps with little preexisting knowledge about this category. As these parents find out more about diaper brands through usage experience, they face a strategic choice. They can exploit their knowledge to date and select the most appealing brand. They can also explore further, which may entail sampling a currently less-than-ideal brand, so that they can make a more informed decision in the future.
Researchers have developed theory-rich models of optimizing forward-looking consumers who balance exploitation with exploration. Pillars of these models include an explicitly specified description of consumer utility and an explicitly specified process by which consumers learn. Most models assume consumers choose brands by solving a dynamic program that maximizes expected total utility taking learning into account. Researchers argue that theory-based models are more likely to uncover insight and be invariant for new-domain policy simulations (Chintagunta et al. 2006, p. 604). However, these advantages often come at

the expense of difficult problems and time-consuming solution methods.
The dynamic programs for forward-looking experiential learning models are, themselves, extremely difficult to solve optimally. We cite evidence below that the problems are PSPACE-hard--they are at least as hard to solve as any problem that requires PSPACE computational memory.1 This intractability presents both practical and theoretical challenges. Practically, researchers have had to rely on approximate solutions. Without explicit comparisons to the optimal solution, we do not know the impact of the approximations on estimation results. Moreover, the well-known "curse of dimensionality" prevents researchers from investigating problems with moderate or large numbers of brands or marketing variables, whereby even approximate solutions may not be feasible. Theoretically, it is reasonable to posit that a consumer cannot solve optimally in his or her head a dynamic problem that requires vast amounts of memory and computation. In fact,
1 PSPACE is the set of problems that use polynomial-sized memory-- memory proportional to n, where is a measure of the size of the problem and n can be extremely large. PSPACE-hard problems are at least as hard as NP-hard problems, which are themselves suspected of being unsolvable in polynomial time.

1

Lin, Zhang, and Hauser: Learning from Experience, Simply

2

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

well-developed theories in marketing, psychology, and economics suggest that observed consumer decision rules are often cognitively simple (e.g., Payne et al. 1988, 1993; Gigerenzer and Goldstein 1996).
We propose that consumers use cognitively simple heuristics to solve learning problems. As an example of the class of cognitively simple heuristics, we investigate an attractive candidate heuristic, index strategies, whereby a consumer develops a numerical score, or an index, for each brand separately and then chooses the brand with the largest index. Index strategies are a solution concept that decomposes an intractable problem into a set of tractable subproblems. We retain basic pillars of structural modeling such as an explicit description of consumer utility and the decision process and an assumption that consumers seek to optimize. We posit, in addition, a cost to solving complex problems (e.g., Shugan 1980, Johnson and Payne 1985). We assume the consumer chooses a strategy that optimizes expected discounted utility minus this cognitive cost. Whereas the cost of cognitive complexity might be observable in the laboratory, say through response latency, it is unobservable in vivo. Instead, we identify domains where index strategies are nearly optimal in the sense of maximizing expected discounted utility. If, in such domains, index strategies are substantially simpler for the consumer to implement, then it is likely that savings in cognitive costs exceed the slight deviation from optimality and, hence, provide the consumer with greater utility net of cognitive costs. In the special cases where index strategies provide optimal expected utility, we argue that index strategies are superior as a description of forward-looking learning. Following the same logic, we establish conditions where myopic learning strategies (i.e., exploiting posterior beliefs without exploration) suffice to model consumer behavior.
To motivate the viability of index strategies as a descriptive model of consumers we (1) establish whether well-defined index strategies exist, (2) explain why they are intuitive and hence might be used by consumers, (3) investigate when index strategies are (near) optimal solutions to the reduced problem of utility maximization, and whether they are computationally simpler than the approximately optimal solution,2 and (4) test whether index strategies explain observed consumer behavior at least as well as alternative models.
We address (1) analytically by proving the "indexability" property of canonical forward-looking experiential learning models. (Indexability is hard to establish in general.) We address (2) by examining the form and properties of index strategies and arguing they are behaviorally intuitive relative to the approximately optimal solution assumed in most forward-looking learning
2 We use computational simplicity as a surrogate for cognitive simplicity in this paper.

Figure 1

Index Strategies Balance Utility and Simplicity (Conceptual Diagram)

Utility

Optimal Approximately
optimal solution

Index strategy

Myopic learning

No learning
Simplicity
models. We address (3) using synthetic data. We address (4) by estimating alternative models using IRI data on the purchase of diapers, a product category where we expect to see forward-looking experiential learning.
Our basic hypothesis is that consumers can use a cognitively simple index strategy to solve forward-looking experiential learning problems. Figure 1 is a conceptual summary of our hypothesis. We demonstrate viability by showing that there exists a well-defined index that satisfies the four criteria. We do not argue that consumers actually use this well-defined index. Rather we argue that the well-defined index is a better "as if" description than the (approximately) optimal solution strategy.3
We first describe a canonical learning problem. We next briefly review literatures that address learning dynamics, cognitive simplicity, and related optimization problems. We then examine index strategies from the perspectives of theory, synthetic data, and empirical estimation. We close with extensions.
2. Canonical Forward-Looking Experiential Learning Problem
We consider the following canonical forward-looking experiential learning problem. A consumer sequentially chooses from a set A containing J brands. Let j index brands and t index purchase occasions. The consumer's utility, ujt, from choosing j at t has three components. The first component is quality, qjt, which can be defined to include enjoyment, fit with needs, weighted sum of brand features, etc. Quality is drawn independently from a distribution Fj qjt j with parameters j . The Fj distributions are independent across j. This independence assumption rules out learning about a brand by choosing another. The consumer, however, does not know the value of the parameters j and observes
3 An empirical search among heuristics would risk exploiting random variation in the data. Instead we demonstrate that an index strategy, and at least one other cognitively simple heuristic, performs well on the data.

Lin, Zhang, and Hauser: Learning from Experience, Simply

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

3

quality draws to infer the value of j . A quality draw of a brand is only realized after the consumer has chosen that brand.
The second component of utility is a set of observable shocks, xjt, such as advertising, price, promotion, and other control variables that are observable to the researcher and consumer. For simplicity, we assume that observable shocks affect utility directly, although the model is extendable to indirect effects through the quality component as in Erdem and Keane (1996), Ackerberg (2003), and Narayanan et al. (2005). The third component of utility is an unobservable shock, jt, which represents random fluctuations in realized utility that are observed by the consumer, but not by the researcher.
Consumer decision making depends on quality and the weighted sum of observable and unobservable
shocks, xjt + jt, where is a vector of weight parameters. We refer to this weighted sum as utility shocks. We let utility shocks be drawn from a joint distribution, Hj xjt jt , independently over purchase occasions with parameters, .4 The Hj 's are independent across j. The consumer knows the distribution Hj and the value of , observes the current utility shocks prior to making a purchase decision, but does not know future realizations of the shocks. Notice that, unlike the quality draws, the utility shocks of a brand are realized regardless of whether the consumer has chosen that brand. We make the conservative assumption that utility shocks are independent of qjt and thus do not help the consumer learn quality directly. However, utility shocks do shape learning indirectly by varying the consumer's utility from exploitation, which in turn affects the incentive for exploration.
In summary, we write the consumer's utility from choosing brand j at purchase occasion t as follows:

ujt = qjt + xjt + jt

(1)

For ease of exposition, in the main analysis, we assume
that the consumer is risk neutral. We extend the model
to incorporate risk aversion in §8.1.
We model each consumer as if the consumer uses
Bayes Theorem to update beliefs about the qual-
ity parameter j after each consumption experience (assumed to occur after choice but before the next
choice). Let sjt be the information set that summarizes the consumer's beliefs about j at purchase occasion t. At t = 0, beliefs about j are summarized by a prior distribution, Bj0 j sj0 , where sj0 is based on

4 Observable shocks can be independently distributed over purchase occasions for a number of reasons. For example, firms may intentionally randomize price promotions in response to competition. Such "mixed strategies" can generate observed prices that appear to be independently drawn at each purchase occasion from a known distribution (Narasimhan 1988).

all relevant prior experience. After the tth consump-

tion experience the consumer's posterior beliefs are

summarized by Bjt j sjt . When both Fj and prior beliefs are normal, Bayesian updating is naturally conju-

gate. We obtain sjt = ¯ jt ¯jt using standard updating formulae. The parameters of posterior beliefs, sjt  and the realized utility shocks, xjt  X and jt  E, summarize the state of information about brand j.

The collection of brand-specific states, st xt t =

s1t s2t

sJt x1t x2t

xJt 1t 2t

Jt represents

the set of states relevant to the decision problem at t.

We seek to model a decision strategy,

×

X × E J  A, that maps the state space to the choice

set. Without further assumptions, the consumer must

choose a decision strategy to maximize expected dis-

counted utility:

V st xt t

= max 

-t qj + xj + j st xt t

(2)

=t

where is the discount factor. The expectation  is taken over the stochastic process generated by the decision strategy (in particular, the transition between states that may depend on the consumer's brand choice). The infinite horizon can be justified either by consumption over a long horizon or by the consumer's subjective belief that the decision problem will end randomly.
The optimal solution to the consumer's decision problem can be characterized as the solution to the Bellman equation:

V st xt

t

= max j A

xjt + jt

+  qjt + V st+1 xt+1 t+1 st j

(3)

Although the Bellman equation is conceptually simple, the full solution is computationally difficult because, even after integrating out the utility shocks xt and t, it evolves on a state space of size J , where is the number of elements in . Not only is J exponential in the number of brands J , it becomes extremely large if contains many elements, even when the optimal solution is approximated by choosing discrete points to represent , as is common in the literature. We provide an illustrative example in §4.

3. Related Literatures
Before we introduce index strategies, it is helpful to review concepts from literatures on learning dynamics, cognitive simplicity, and related optimization problems.
3.1. Learning Dynamics Many influential papers study consumer learning dynamics and apply learning models to explain or forecast consumer choices in problems related to the

Lin, Zhang, and Hauser: Learning from Experience, Simply

4

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

canonical learning problem. For example, using data from automotive consumers, Roberts and Urban (1988) estimate a model in which consumers use Bayesian learning to integrate information from a variety of sources to resolve uncertainty about brand quality. Erdem and Keane (1996) build on the concept of Bayesian learning and include forward-looking consumers who trade off exploitation with exploration. For frequently purchased goods, their model fits data better than a no-learning model (reduced form of Guadagni and Little 1983) and the myopic learning model of Roberts and Urban.
These papers stimulated a line of research that estimates the dynamics of consumer learning--for a comprehensive review see Ching et al. (2013a). Some models focus on myopic consumers with Bayesian learning (e.g., Narayanan et al. 2005; Mehta et al. 2008; Chintagunta et al. 2009; Narayanan and Manchanda 2009; Ching and Ishihara 2010, 2012), whereas others explicitly model forward-looking consumers (e.g., Ackerberg 2003; Crawford and Shum 2005; Erdem et al. 2005, 2008). The computational complexity of forwardlooking learning has been one of the reasons that some applications assume myopic learning. However, if a theory is accurately descriptive, more-complex forwardlooking models should improve policy simulations.
Because forward-looking choice problems that involve continuous state space generally cannot be solved optimally, significant effort has been spent on developing approximate solutions. For example, Keane and Wolpin (1994) use Monte Carlo integration and interpolation, Rust (1997a) introduces a randomization approach, and Imai et al. (2009) develop an estimator that combines dynamic programming solutions with a Bayesian Markov chain Monte Carlo algorithm.5 Although these solution methods vary in speed, all attempt to approximate the Bellman equation to the overall problems and thus may suffer from the curse of dimensionality ( J .
At the same time of technical developments, there is a growing recognition of the need for richer theories of consumer behavior. For example, Chintagunta et al. (2006, p. 614) suggest that "the future development of structural models in marketing will focus on the interface between economics and psychology."
3.2. Cognitive Simplicity Parallel literatures in marketing, psychology, and economics provide evidence that consumers use decision rules that are cognitively simple. In marketing, Payne et al. (1988, 1993) and Bettman et al. (1998) present evidence that consumers use simple heuristic decision rules to evaluate products. For example, under

time pressure, consumers often use conjunctive rules (require a few "must have" features) rather than morecomplicated compensatory rules. Using simulated thinking costs with "elementary information processes," Johnson and Payne (1985) illustrate how heuristic decision rules can be rational when balancing utility and thinking costs. Methods to estimate the parameters of cognitively simple decision rules vary, but such rules often predict difficult consumer decisions as well as or better than compensatory rules (e.g., Bröder 2000, Gilbride and Allenby 2004, Kohli and Jedidi 2007, Yee et al. 2007, Hauser et al. 2010).
Building on Simon's (1955, 1956) theory of bounded rationality, researchers in psychology argue that human beings use cognitively simple rules that are "fast and frugal" (e.g., Gigerenzer and Goldstein 1996, Martignon and Hoffrage 2002). Fast and frugal rules evolve when consumers learn decision rules from experience. Consumers continue to use the decision rules because they lead to good outcomes in familiar environments (Goldstein and Gigerenzer 2002). For example, when judging the size of cities, "take the best" often leads to sound judgments.6 In 2010­2011, two issues of Judgment and Decision Making were devoted to the recognition heuristic alone (e.g., Marewski et al. 2010).
The costly nature of cognition has also received attention in economics (see Camerer 2003 for a review). A line of research looks to extend or revise standard dynamic decision making models with the explicit recognition that cognition is costly. For example, Gabaix and Laibson (2000) empirically test a behavioral solution to decision-tree problems, whereby decision makers actively eliminate low-probability branches to simplify the task. Gabaix et al. (2006) develop a "directed cognition model," in which a decision maker acts as if there is only one more opportunity to search. In the laboratory, the directed cognition model explains subjects' behavior better than a standard search model with costless cognition. Houser et al. (2004) provide further evidence that consumers might use heuristic rules to solve dynamic programs.
Cognitive process mechanisms are debated in the marketing, psychology, and economics literatures. Our hypothesis, that consumers use heuristics such as index strategies, need only the observation that consumers favor decision rules that are cognitively simple and that such rules often lead to good outcomes. The simplicity hypothesis assumes that consumers trade off utility gains versus cognitive costs, but does not require explicit measurement of cognitive costs.

5 There is a related literature on neuro-dynamic programming, which uses neural networks and other approximation architectures to overcome the curse of dimensionality (Bertsekas and Tsitsiklis 1996).

6 The take-the-best rule is, simply, if you recognize one city and not the other it is likely larger; if you recognize both use the most diagnostic feature to make the choice.

Lin, Zhang, and Hauser: Learning from Experience, Simply

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

5

3.3. Cognitively Simple Solutions to Complex Optimization Problems
If a ballplayer wants to catch a ball that is already high in the air and traveling directly toward the player, then all the player needs to do is gaze upon the ball, start running, and adjust his or her speed to maintain a constant gaze angle with the ball (Hutchinson and Gigerenzer 2005, p. 102).7 The gaze heuristic is an example where a cognitively simple rule accomplishes a task that might otherwise involve solving difficult differential equations. But the principle is more general: simple solutions often perform well in complex optimization problems.
There are many examples in marketing and economics where descriptive decision rules solve more-complex problems.8 In domains such as consumer budget allocation, the choice of which information source to search, and the evaluation of products via agendas, heuristic solutions appear to describe consumer behavior well (Hauser 1986, Hauser and Urban 1986, Hauser et al. 1993). Rust (1997b) argues that it is likely consumers solve problems requiring an "infeasibly large number of calculations" by using heuristic solutions such as decomposition into subproblems. He states that "[t]he challenge is to recognize whether or not a problem is nearly decomposable, and if so, to identify its approximately independent subproblems, [and] determine whether they can be solved separately (p. 18)." This view is closely related to our index approach to complex forward-looking learning problems.
3.4. Related Optimization Problems: Bandit Problems and Index Solutions
The model we formulate in §2 is closely related to the multi-armed bandit problem, a prototypical problem that illustrates the fundamental trade-off between exploration and exploitation in sequential decision making under uncertainty. In a bandit problem, the decision maker faces a finite number of choices, each of which yields an uncertain payoff. The decision maker must make choices, observe outcomes, and update beliefs with a sequential decision rule. The decision maker seeks to maximize expected discounted values.
The bandit problem was first formulated by the British in World War II, and, for over 30 years, no simple solution was known. Then Gittins and Jones (1974) demonstrated a simple index solution--develop an index for each "arm" (i.e., each choice alternative) by solving a subproblem that involves only that arm, then
7 Professional athletes use more-complicated heuristics that give them greater range, for example, in baseball, prepositioning based on prior tendencies and the expected pitch, and the sound as the bat hits the ball.
8 Of course, the empirical performance of descriptive solutions is not guaranteed. Gilovich et al. (2002) provide a comprehensive survey of human decision heuristics and their possible biases.

choose the arm with the largest index. This index solution reduces an exponentially complex problem to a set of one-dimensional problems. Gittins and Jones (1974) proved the surprising result that the index solution is the optimal solution to the classic bandit problem.9
However, the Gittins-Jones' striking result comes at the cost of a strict assumption that the states of the nonchosen choice alternatives do not evolve. When this assumption is violated, say because of random shocks, Gittins' index is no longer guaranteed to be optimal. Such problems are known as restless bandits (Whittle 1988) and, in general, are computationally intractable (Papadimitriou and Tsitsiklis 1999). In his seminal paper, Whittle (1988) proposes a tractable heuristic solution. The solution generalizes Gittins' index such that the problems can be solved optimally or near optimally by associating an index, referred to as Whittle's index, separately with each alternative and choosing the alternative with the largest index.
The existence of well-defined index solutions relies on a structural property called indexability, which is not guaranteed for all restless bandit problems. Whittle (1988, p. 292) wrote that "One would very much like to have simple sufficient conditions for indexability; at the moment, none are known" (see also Niño-Mora 2001). Gittins et al. (2011, p. 154) also lament that "the question of indexability is subtle, and a complete understanding is yet to be achieved."10 In an important class of marketing models, choice models, consumer utility tends to be restless over purchase occasions. For example, in most random-utility choice models there is an idiosyncratic "error term" as well as other changes in the choice environment (e.g., McFadden 1986).11 Without further study, we do not know whether
9 Hauser et al. (2009) apply Gittins' index to derive optimal "website morphing" strategies that match website design with customers' cognitive styles. Urban et al. (2014) field test morphing for AT&T's banner advertising on CNET and General Motors' banner advertising on a variety of websites. Other well-known applications of index strategies include job-match learning (Jovanovic 1979, Miller 1984) and pharmaceutical-product learning (Dickstein 2012). See Ching et al. (2013a) for a survey.
10 The indexability of restless bandits is problem specific. For example, Niño-Mora (2001) takes the achievable region approach (Bertsimas and Niño-Mora 2000) and establishes the indexability of a class of restless bandit problems with linear performance measures (e.g., queue input control). Glazebrook et al. (2006) show that a special class of restless bandit problems--stochastic scheduling--is indexable. To our knowledge, no general result analogous to Gittins' index theorem exists as of today.
11 The error term has been modeled as an unobserved (to the researcher) state variable in structural applications (Rust 1994, Chapter 51, §§3.1 and 3.2). This modeling approach "provides a natural way to `rationalize' discrepancies between observed behavior and the predictions of the discrete decision process model" (Rust 1994, p. 3101). This is different from the "optimal choice plus noise/measurement error" approach.

Lin, Zhang, and Hauser: Learning from Experience, Simply

6

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

an index strategy is a good solution to such restless problems.
We recognize that the canonical forward-looking experiential learning problem belongs to the general class of restless bandits because of the presence of utility shocks. In §5 we prove that the problem is indexable and, thus, a well-defined index solution exists in the sense of Whittle (1988). Moreover, we explore the key properties of such an index, which shed light on how consumers may behave in solving the learning problem.
4. An Index Strategy in the Absence of Utility Shocks
The learning problem we examine includes utility shocks, but it is easier to illustrate the intuition of index strategies using a problem without utility shocks. Temporarily assume both observable and unobservable shocks are zero for all j and t, although the same result holds when there is no intertemporal variation in xjt and jt. In this special case, the consumer's decision problem is a classic multi-armed bandit.
Gittins' insight is as follows. To evaluate a brand j, the consumer thinks as if he or she is choosing between this brand and a reward j that is fixed for all future purchase occasions. The consumer thus solves a subproblem at each purchase occasion--the consumer can either sample this brand to gain more information about it, or exploit the fixed reward j . In the latter case, the consumer's belief about brand j ceases to evolve, such that sj t+1 = sjt. The optimal solution to this subproblem is determined by a greatly simplified version of the Bellman equation:
V sjt j
= max j + V sjt j  qjt + V sj t+1 j sjt (4)

Notice that each subproblem only depends on the state evolution of a single brand, j. The subproblem is much simpler than the full problem specified in Equation (3).
Gittins' index, G sjt , is defined as the smallest value of j such that the consumer at purchase occasion t is just indifferent between experiencing brand j and receiving the fixed reward. That is, we obtain G sjt by equating the two terms inside the maximization operator of Equation (4). Gittins proposes that G sjt could be used as a measuring device for the value of exploring brand j--if there is more uncertainty about a brand left to explore, the consumer will demand a higher fixed reward to be willing to stop exploration. Naturally, Gittins' index is updated when new information arrives.
Gittins' surprising result is the Index Theorem. The optimal solution is to choose the brand with the highest index at each purchase occasion. A computationally difficult problem has thus been decomposed into J simpler subproblems.
Index Theorem (Gittins and Jones 1974). The optimal decision strategy when there are no utility shocks is
G st = arg maxjA G sjt .
Figure 2 illustrates intuitive properties of Gittins' index. We consider one brand. The solid line plots one realization of Gittins' index as it evolves when the brand is chosen repeatedly. The dashed line plots the consumer's posterior mean quality belief. It is updated by brand experience and converges toward the true brand quality. Myopic consumers would exploit experience and choose the brand that yields the highest posterior mean quality. Forward-looking consumers may want to explore further. The dotted curve, which is simply the difference between Gittins' index and the posterior mean quality, measures the value of exploration. This curve declines smoothly with experience because the value of exploration decreases as the

Figure 2

Gittins' Index, Posterior Mean Quality, and the Value of Exploration 1.8

1.6

1.4

1.2

Gittins' index

1.0

0.8

0.6

0.4

0.2

0

1

6

11

16

21

26

31

Purchase occasion

Gittins' index Posterior mean quality Value of exploration

36

41

46

Lin, Zhang, and Hauser: Learning from Experience, Simply

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

7

consumer learns more about brand quality. When we plot Gittins' index as a function of the consumer's posterior quality uncertainty ¯jt (not shown), it is also intuitive--the index increases with ¯jt because the value of exploration increases with the remaining amount of quality uncertainty. Figure 2 and the simple relationship between Gittins' index and posterior quality beliefs suggest that a consumer might intuit something close to the dotted curve if there were no utility shocks.
5. An Index Strategy in the Presence of Utility Shocks
We now allow utility shocks. Observable shocks xjt include effects that researchers observe and model, such as changes in advertising, price, or promotion. Unobservable shocks jt include effects that researchers do not observe and that do not provide a signal about quality. The presence of unobservable shocks is central to many empirical consumer choice models. Because shocks enter the utility function regardless of the consumer's decisions, the consumer may, in any purchase occasion, switch among brands.12
When the model includes utility shocks, the GittinsJones index theorem no longer applies because the states of nonchosen brands do not remain constant. With shocks, the consumer's problem belongs to the class of restless-bandit problems as introduced by Whittle (1988). In general, such optimization problems are PSPACE-hard (Papadimitriou and Tsitsiklis 1999, Theorem 4) making the problem extremely difficult, if not infeasible, to solve and making it implausible that the consumer would use a solution strategy based on Equation (3). Among other difficulties, PSPACE-hard problems require extremely large memory--a particularly scarce resource for consumers (e.g., Lindsay and Norman 1977, p. 306; Bettman 1979, p. 140). We develop a theoretical solution to this problem in this section. We show that the canonical forward-looking experiential learning problem is indexable and index strategies have intuitive properties.
5.1. The Canonical Forward-Looking Experiential Learning Problem Is Indexable
Whittle (1988) proposes a solution that generalizes Gittins' index. At each purchase occasion, to evaluate a brand j, the consumer thinks as if he or she must choose between brand j and a reward j that is fixed for all future purchase occasions. The Bellman equation
12 Even when there is no learning, a typical empirical model of consumer choices may include a shock, or an idiosyncratic error, jt, that is treated as unobservable by researchers. Without this shock, the model would predict that the consumer makes the same choice over purchase occasions if all other observable factors remain constant. In the context of learning, incorporating this shock allows for switching among brands even when the consumer has learned much about brand quality.

for the jth subproblem, which now includes utility shocks, becomes

V sjt xjt jt j

= max j +  V sjt xj t+1 j t+1 j

xjt + jt

+  qjt + V sj t+1 xj t+1 j t+1 j sjt

(5)

The index is defined as the smallest value of j such that the consumer at purchase occasion t is just
indifferent between choosing brand j and receiving
the fixed reward. For such an index to be well-defined
and meaningful, the indexability condition needs to
be satisfied (Whittle 1988). Let St j  × X × E be the set of states for which choosing j at purchase occasion t is optimal:

St j = sjt xjt jt  × X × E j

+  V sj t xj t+1 j t+1 +  qjt + V sj t+1 xj t+1

j  xjt + jt j t+1 j sjt (6)

Indexability is defined as follows:

Definition. A brand j is indexable if, for any t, St j  St j for any j < j .
Indexability requires that, as the fixed reward increases, the collection of states for which the fixed reward is optimal does not decrease. In other words, if in some state it is optimal to choose the fixed reward, it must also be optimal to choose a higher fixed reward. Indexability implies a consistent ordering of brands for any state, so an index strategy is meaningful. However, indexability need not always hold in general and cannot be taken for granted (Whittle 1988).13 Thus, before we can posit an index strategy as a consumer heuristic, we must establish indexability for a model that includes utility shocks. In Online Appendix A (available as supplemental material at http://dx.doi.org/10.1287/ mksc.2014.0868), we prove the following proposition.

Proposition 1 (Indexability). The canonical forwardlooking experiential learning problem defined in §2 is indexable.

Once the indexability condition is established, then a well-defined strategy is to choose at each purchase occasion the brand with the largest index. The index strategy breaks the curse of dimensionality by decomposing a problem with exponential complexity into J much simpler subproblems, each on a state space of
after integrating out the utility shocks xjt and jt. With this simplification, it is more plausible that the consumer might use the index strategy. As a bonus,

13 Whittle (1988, p. 297) provides a simple example where indexability fails.

Lin, Zhang, and Hauser: Learning from Experience, Simply

8

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

estimation is much faster. The difference in the size of the state space can be dramatic. For example, suppose we were interested in the mean and variance of quality and discretized them with M and N grid points, respectively. With J brands, the state space for index strategies is M × N for each brand, rather than M × N J for the original optimization problem given in Equation (3). For M = N = 10 and J = 6, this is the difference between a state space of 100 (for each of the six brands) and 1,000,000,000,000.

5.2. The Index Strategy Is Invariant to Scale and

Behaves Intuitively

Index strategies dramatically simplify the solution, but

can the consumer intuit (perhaps approximately) an

index strategy? We expect future laboratory experi-

ments to address this issue empirically. In this paper,

we argue that index strategies have intuitive properties

and that it is not unreasonable for the consumer to

intuit those properties.

An index strategy would be difficult for the con-

sumer to use if the strategy were not invariant to

permissible scale transformations. If it is invariant the

consumer can intuit (or learn) the basic shape of the

index function and use that intuited shape in many

situations. Invariance facilitates ecological rationality.14

The following results hold for fairly general distribu-

tions of quality, Fj qjt j , and joint distributions of utility shocks xjt and jt, as long as they have scale and location parameters and the quality belief Bjt j sjt is conjugate. To ease interpretation, we assume that

Fj and Bjt are normal distributions with parameters

defined earlier: j and j for true quality; ¯ jt and ¯jt

for posterior beliefs about quality; and

x j

and

x j

for utility shocks. In Online Appendix B we prove the

following proposition.

Proposition 2 (Invariance). Let W be Whittle's

index for the canonical forward-looking experiential learning

problem computed when the posterior mean quality ( ¯ jt) is

zero, the mean utility shock (

x j

) is zero, and the inherent

variation of quality ( j ) is one. Whittle's index for any

values of these parameters is the following simple function

of W :

Wj ¯ jt ¯jt

xjt + jt

j

x j

x j

= ¯ jt +

x j

+

j W j 0

¯jt

j

xjt + jt -

x j

10

x j

j

j

Proposition 2 implies that the consumer can simplify

his or her mental evaluations by decomposing the

index for each brand into (1) the mean utility gained

from myopic learning, ¯ jt +

x j

, which reflects the

exploitation of posterior beliefs, and (2) the incremental

14 Gittins' index exhibits invariance properties (Gittins 1989).

benefit of looking forward, j W , which captures quality information gained through exploration. To assess the value of exploration, the consumer need only intuit
the shape of W for a limited range of parameter values and scale it by j . Proposition 2 also helps researchers understand which parameters can be identified in the index-strategy model.
To provide further intuition, we prove the following proposition in Online Appendix C. The proposition shows that Whittle's index behaves as expected when the parameters of the problem vary. The consumer likes increases in quality and utility shocks, dislikes inherent uncertainty in quality and utility shocks, but values the ability to learn and, hence, resolve the uncertainty in posterior beliefs about quality.

Proposition 3 (Comparative Statics). Whittle's in-

dex for the canonical forward-looking experiential learning

problem (1) increases with the posterior mean of quality ( ¯ jt),

the observable utility shocks ( xjt), and the unobservable

utility shock ( jt); (2) weakly decreases with the inherent

uncertainty in quality ( j ) and the magnitude of uncertainty

in the utility shocks (

x j

); and (3) weakly increases with

the consumer's posterior uncertainty about quality ( ¯jt).

Figure 3 illustrates Whittle's index where we set

the posterior mean quality to zero, so that the curve

represents the value of exploration. (More generally,

Whittle's index fluctuates with the posterior mean

quality in a way similar to Figure 2.) As was the case

for Gittins' index, the value-of-exploration component

of Whittle's index is a smooth decreasing function

of experience because experience reduces posterior

quality uncertainty. With sufficient experience, the

value of exploration converges toward zero implying

that, asymptotically, the value of a brand is based on

the posterior mean of quality (Proposition 2). Unlike

Gittins' index, Whittle's index is a function of the

magnitude of utility shocks (

x j

. As the magnitude

of utility shocks becomes larger, it is less important for

the consumer to explore, and the value of exploration

decreases as shown in Figure 3. These properties and

the shape of the curve itself, are intuitive.

Figure 3 and Proposition 3 suggest that, other things

being equal, when the magnitude of the uncertainty

in utility shocks is larger, the realized utility shocks

are more likely to be the deciding factor in consumers'

brand choices. For example, as the depth of price

promotions increases, consumers are more likely to

base their purchase decisions on price. When

x j

=5

(compared with inherent quality uncertainty normal-

ized as j = 1 , Whittle's index is almost flat implying an almost myopic strategy. To formalize this insight,

we state the following corollary to Proposition 3:

Corollary. (1) As the consumer's posterior uncertainty in quality increases relative to the magnitude of the utility

Lin, Zhang, and Hauser: Learning from Experience, Simply

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

9

Figure 3

Whittle's Index as Experience and Utility Shock Magnitude Vary 0.8

0.7

Whittle's index

0.6

Shock magnitude = 0.01

0.5

Shock magnitude = 0.1

Shock magnitude = 1.0 0.4
Shock magnitude = 5.0

0.3

0.2

0.1

0

1

6

11

16

21

26

31

36

41

46

Purchase occasion

Notes. Posterior mean quality is set to zero in this figure, so that Whittle's index captures the value of exploration. Inherent quality uncertainty j is normalized as 1.

shocks, the value to the consumer from looking forward increases. (2) As the magnitude of the utility shocks increases relative to the consumer's posterior uncertainty in quality, the value from looking forward decreases. In this latter case, a myopic leaning strategy (i.e., exploiting posterior beliefs) may suffice, and could be the optimal strategy if it is cognitively simpler than a forward-looking learning strategy.
These results highlight the intricate relationship between the consumer's uncertainty in quality and uncertainty caused by utility shocks. The two types of uncertainty complement each other in driving the consumer's value of exploitation, but may compete with each other in shaping the consumer's value of exploration. The index solution offers an intuitive description of this relationship. In §§6 and 7, we examine the empirical performance of the index strategy.
6. Examination of the Near Optimality of an Index Strategy (Synthetic Data)
We now examine whether an index strategy implies a reasonable trade-off between optimality and simplicity. Indexability guarantees existence of a well-defined index strategy but does not guarantee its optimality.15 For the canonical forward-looking experiential learning problem, the performance of the index strategy is an empirical question. Cognitive costs remain unobservable, but §§4 and 5 suggest that an index strategy could be substantially simpler than the direct solution of the Bellman equation to the overall problem. To examine whether the loss in utility is small, we switch from analytic derivations to synthetic data because the loss in utility is an issue of magnitude rather than
15 Many performance bounds have been developed in different contexts. See Gittins et al. (2011) for a review of recent developments.

direction. Synthetic data establish existence (rather than universality) of situations where index strategies are close to optimal.
For concreteness we examine the special case when Fj and Bjt are normal distributions. From the perspective of consumer decision making, what matters is the joint distribution of observable shocks (xjt and unobservable shocks ( jt . Therefore, for the synthetic-data analysis we set observable shocks to zero without loss of generality. Practically, even if there are no observable shocks (e.g., no price promotions), unobservable shocks (e.g., idiosyncratic taste fluctuations) are still likely to prevail in most choice models. We allow for both observable and unobservable shocks in the field-data analysis.
We compare four decision strategies that the consumer might use.
1. No learning. The consumer chooses the brand based only on the consumer's prior beliefs of quality and the current utility shocks. This strategy provides a baseline to evaluate the incremental value of learning.
2. Myopic learning. The consumer chooses the brand based only on the consumer's posterior quality beliefs and the current utility shocks. This strategy exploits the consumer's posterior knowledge about brand quality. The corollary predicts that this strategy will suffice when the magnitude of utility shocks is relatively high compared with posterior quality uncertainty.
3. Index strategy. This strategy assumes the consumer can intuit the shape of Whittle's index. As per Proposition 2, this strategy improves on the myopic learning strategy to take into account the exploration value of learning. Brand choices reflect the consumer's trade-off between exploitation and exploration.
4. Approximately optimal. The PSPACE-hard forwardlooking experiential learning problem cannot be solved

Lin, Zhang, and Hauser: Learning from Experience, Simply

10

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

optimally, hence researchers resort to approximate solutions (e.g., Keane and Wolpin 1994, Erdem and Keane 1996, Rust 1997a, Ackerberg 2003, Crawford and Shum 2005, Imai et al. 2009, Ching 2010, Ching et al. 2013b). Although approximation methods vary (see Online Appendix G for a review), discrete optimization is a representative method and should converge to the optimal solution with a larger number of grids (Chow and Tsitsiklis 1991, Rust 1996).
We choose parameters that illustrate the phenomena and are empirically plausible. The simulation requires a finite horizon; we select T = 50 purchase occasions. If the discount factor is = 0 90, truncation to such a finite horizon is negligible. We discretize the state space, sjt = ¯ jt ¯jt into a set of M × N grid points for each of J brands. We choose M × N = 200 × 50 = 104, which should be close to optimal in the continuous problem.16 To simplify integration we draw the utility shocks from a Gumbel distribution with parameters
j j and normalize the location parameter such that the utility shocks have zero unconditional means (Rust 1987, 1994). Inherent uncertainties in quality for both brands, j , are equal and normalized to one.
The index strategy evolves on a state space of size M × N for each of the J brands, whereas the approximately optimal solution evolves on a state space of size M × N J . We choose J = 2 for a conservative test of the relative simplicity of the index strategy.
We vary the parameter values to capture three possibilities: (1) the means and uncertainty both favor one brand, (2) the means are the same but uncertainty favors one brand, and (3) the means and uncertainty favor different brands. Because quality beliefs are relative, we fix the prior mean quality belief of brand 1 as ¯ 10 = 0 and vary the prior mean quality belief for brand 2 as ¯ 20  -0 3 0 0 3 . We normalize the standard deviation of brand 2's prior quality belief as ¯20 = 1 and the standard deviation of brand 1's prior quality belief as ¯10 = 0 5. Finally, to test the corollary we allow the uncertainty in shocks to vary from relatively small to relatively large: 1 = 2  0 1 1 .
We compute the indices and the consumer's expected total utilities for 50 purchase occasions under the four decision strategies. Details are provided in Online Appendices D and E. Table 1 summarizes the results.
We first examine computation time as a surrogate for cognitive complexity. As expected, the no-learning and myopic learning strategies impose negligible computation time, the index strategy requires moderate
16 We choose M = 200 grid points for the posterior mean quality. Meanwhile, we fix each brand's prior quality variance. Posterior quality variance evolves deterministically following Bayesian updating formulae. Because there are T = 50 purchase occasions, a brand's posterior quality variance has N = T = 50 possible values, depending on how many times this brand has been chosen. Therefore, the size of the state space for the index strategy is M × N = 200 × 50 = 104.

computation time, and the approximately optimal solution is substantially slower--600 times as time consuming as the index strategy even for this basic problem. Faster approximation algorithms would reduce the computational time for the approximately optimal solution (Keane and Wolpin 1994, Rust 1997a, Imai et al. 2009), but they would also expedite the index strategy because we use the same algorithm for solving the Bellman equations in both models (see Online Appendix G for implementation details). Moreover, faster approximation algorithms do not address the curse of dimensionality. The ratio of computational time in Table 1 could be made arbitrarily large with finer grid points or with a larger number of brands.
We next examine the consumer's expected utilities. In all cases, the no-learning strategy leads to the lowest utility, which suggests that learning is valuable. Furthermore, the index strategy is statistically indistinguishable from the approximately optimal strategy. As long as cognitive simplicity matters even a little, the index strategy will be better on utility minus complexity.
Finally, the results are consistent with the corollary. When there is relatively low uncertainty in utility shocks (upper panel of Table 1), the index strategy and the approximately optimal strategy generate higher utility than myopic learning, and, in two of the three cases, significantly higher utility. When there is relatively high uncertainty in utility shocks (lower panel of Table 1), the myopic learning model performs virtually the same as either the index strategy or the approximately optimal strategy. The differences are not significant. In this case, the consumer might achieve the best utility minus complexity with a myopic strategy, among the models tested.
Analysis of synthetic data never covers all cases. Table 1 is best interpreted as providing evidence that (1) there exist reasonable situations where an index solution is better than the approximately optimal solution on utility minus complexity and (2) there exist domains where myopic learning is best on utility minus complexity. We now examine field data.
7. Field Estimation of an Index Strategy (IRI Data on Diaper Purchases)
We examine how an index solution fits and predicts behaviors compared with an approximately optimal solution and myopic learning. As a first test, we seek a product category and sample where consumers are likely to be forward looking. Even if an index solution does no better than an approximately optimal solution, we consider the result promising because an index solution is cognitively simpler. As a test of face validity, we expect learning strategies to outperform no-learning strategies and, because we focus on a situation that favors forward-looking behavior, we expect forwardlooking strategies to outperform myopic learning.

Lin, Zhang, and Hauser: Learning from Experience, Simply

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

11

Table 1 Comparing Decision Strategies on Utility and Simplicity (Synthetic Data)

Expected discounted utility (standard errors in parentheses)

No learning

Myopic learning

Index strategy

Approximately optimal

Size of state space Computation time (surrogate for cognitive complexity)a

N/A Negligible

N/A Negligible

Mean of prior quality beliefs (brand 1, brand 2) ( ¯ 10 ¯ 20 = 0 0 -0 3

Relatively low uncertainty in utility shocks ( 1 = 2 = 0 1)

0 041 0 003

1 801 0 043

( ¯ 10 ¯ 20 = 0 0 0 0

0 618 0 003

3 352 0 049

( ¯ 10 ¯ 20 = 0 0 0 3

3 036 0 003

5 298 0 056

Mean of prior quality beliefs (brand 1, brand 2) ( ¯ 10 ¯ 20 = 0 0 -0 3

Relatively high uncertainty in utility shocks ( 1 = 2 = 1

4 919 0 026

5 762 0 047

( ¯ 10 ¯ 20 = 0 0 0 0

6 182 0 027

7 150 0 050

( ¯ 10 ¯ 20 = 0 0 0 3

7 946 0 026

8 912 0 054

104 102 seconds
1 992 0 045 3 544 0 052 5 323 0 056
5 767 0 047 7 190 0 052 8 911 0 054

108 6 × 104 seconds
1 996 0 045 3 547 0 052 5 327 0 056
5 768 0 047 7 190 0 052 8 912 0 054

aThis is the time required to compute one utility function using a university computing system based on Sun Grid Engine and Red Hat Enterprise Linux.

7.1. IRI Data on Diaper Purchases We select the diaper category from the IRI Marketing Data Set that is maintained by IRI (formerly SymphonyIRI Group) and available to academic researchers (Bronnenberg et al. 2008).17 Diaper consumers are likely to be learning and forward looking. Parents typically begin purchasing diapers based on a discrete birth event, and their entry to the category is arguably exogenous (Ching et al. 2010, 2012). Even if the birth is a second or subsequent child, diaper quality may have changed. Informal qualitative interviews suggest that parents learn about whether diaper brands match their needs through experience (with often more than one purchase), that diapers are sufficiently important that parents take learning seriously, and that parents often try multiple brands before settling on a favorite brand. In fact, Ching et al. (2012) find that diaper consumers conduct strategic trials of various brands.18 There are observable shocks due to price promotions and shocks due to unobservable events.
17 In comparison, durable goods may induce different learning dynamics. Because of the low purchase frequency, consumers may not have the opportunity to learn by sampling. Also, because the stakes are often high, consumers may have the motivation to acquire other types of information (e.g., Consumer Reports reviews) prior to purchase. The INFORMS Society of Marketing Science durables goods data set (Ni et al. 2012) provides a good resource to study these learning dynamics.
18 Ching et al. (2012) use a quasi-structural approach, where they model the consumer's expected future payoffs as a function of state variables. Their model detects strategic trial if the coefficients of expected future payoffs are significant and if model fit improves significantly over the myopic model.

For example, a baby might go through a stage where a different brand is best suited to the parent/child's needs. Finally, diapers have the advantage of being regular purchases, where the no-choice option is less of a concern, and consumers tend to be in the market for many purchase occasions.
To isolate a situation favoring forward-looking learning, we apply the following sample screening criteria. First, to focus on consumers whose purchases are likely triggered by a birth event, we select households whose first purchase occurs 30 weeks after the start of data collection (73% of the entire sample). Second, we focus on frequent buyers. Compared with occasional buyers who might be shopping for a baby shower, frequent buyers are more likely to have both the motivation and the opportunity to explore different diaper brands. Therefore, we select households who have made at least five purchases during the observation window (39% of the entire sample).19 Third, to focus further, we eliminate any consumers who have purchased private labels and restrict attention to consumers who buy exclusively branded products (64% of the entire sample). To the extent that private label buyers are more price sensitive (Hansen et al. 2006), they may be less interested in learning about product quality. (In §8.4, we reanalyze the data by including private labels.) After applying these screening criteria, the data
19 Analyses based on a random selection of buyers rather than frequent buyers are available from the authors. The myopic learning model does better on this random selection of buyers than on frequent buyers because infrequent buyers have less incentive or opportunity to learn.

Lin, Zhang, and Hauser: Learning from Experience, Simply

12

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

contain 262 households who made 3,379 purchases (13 purchases per household on average).20 We randomly select 131 households for estimation and 131 households for validation.
The market is dominated by three major brands, Pampers, Huggies, and Luvs. We aggregate all other branded purchases as "other brands" and do not model the no-purchase option. As a first-order view, Table 2(a) compares market-shared-weighted switching behavior during the first 13 purchases with that after the first 13 purchases.21 There is a noticeable change in switching patterns. For example, the relative brand loyalty of Huggies increases after 13 purchases. This suggests that consumers may learn about brand quality from experience. Although the category is chosen as a likely test bed for consumer learning, high brand loyalty, even during the initial 13 purchases, suggests that there is no guarantee a forward-looking strategy will fit the data.

7.2. Empirical Specification

We denote households by i and denote by Ti household i's purchase-occasion horizon. We assume that

the quality and quality-belief distributions, Fj and Bijt, are normal and that unobservable shock distributions are Gumbel. For this initial test of an index

solution, we limit xjt to the weekly average prices. The decision strategies are specified below ( and xjt are now scalars):

No learning: N = arg maxj ¯ j0 + xjt + ijt .

Myopic learning: M = argmaxj ¯ ijt + xjt + ijt .

Index strategy:

W = arg maxj ¯ ijt +

x j

+

j W j 0 ¯ijt/ j

xjt + ijt -

x j

/j 10

x j

/

j

.

Approximately optimal: A = arg maxj ¯ ijt + xjt +

ijt +  V si t+1 xt+1 i t+1 sit j .

7.3. Issues of Identification Although we would like to identify all parameters of the various models, we cannot do so from choice data alone because utility is only specified to an affine

20 The data only record the week, as opposed to the exact time, of purchase. Therefore, if a consumer makes multiple purchases during the same week, we do not observe the sequence of brands purchased. Rather than make potentially erroneous assumptions about the data, we remove consumers who make multiple-brand purchases in any week of the observation window (11% of the entire sample). An alternative analysis strategy might have been to randomize purchase orders. However, there is no reason to expect that removing consumers who make multiple purchases a week will affect the comparison between the index strategy and the approximately optimal solution. We also do not model purchase quantity decisions. Instead we assume that consumers update their quality beliefs after each purchase (and consumption) occasion.
21 We define market share at the purchase level across the observation window, so that market shares before and after the first 13 purchases add up to 100%. For readers who wish to normalize Table 2 in other ways, the raw counts are obtained by multiplying the percentages in Table 2 by 1,407, the total number of purchases in the estimation sample except the last purchase of each household.

Table 2 Switching Among Diaper Brands

Percent of times that row brand is purchased at occasion t and column brand is purchased at occasion t + 1a (%)
Pampers Huggies Luvs Other brands

(a) Actual switching matrix

Within the first 13 purchases

Pampers

20 3

39 29

05

Huggies

38

21 5 1 6

02

Luvs

25

2 4 12 6

03

Other brands

06

04 03

10

After the first 13 purchases

Pampers

63

09 07

01

Huggies

07

11 2 0 2

01

Luvs

09

00 40

00

Other brands

01

01 00

00

(b) Predicted switching matrix--Index strategy model

Within the first 13 purchases

Pampers

20 3

30 19

02

Huggies

20

26 1 1 3

01

Luvs

16

1 6 15 2

01

Other brands

03

01 01

09

After the first 13 purchases

Pampers

46

05 04

00

Huggies

03

15 0 0 1

00

Luvs

05

02 34

00

Other brands

00

00 00

01

aSwitching percentages are weighted by market share so that the percentages in the same table add up to 100%.

transformation, and because many of the parameters

that matter are relative parameters. For the no-learning

model we can identify only the relative means of prior

beliefs, as well as the price sensitivity parameter . For

the myopic learning model we can identify only the

relative means of prior beliefs, the relative uncertainties

of prior beliefs, the true means of quality, and price

sensitivity. For the no-learning and myopic learning

models time discounting does not matter.

For the index strategy and approximately optimal

strategy we set the mean prior belief of one brand ( ¯ 10 to zero and normalize its variance of quality ( 1 to one to set the scale of quality. (Only ¯j0/ j matters.) We cannot simultaneously identify a brand-specific mean of

quality and a brand-specific mean of the unobservable

shock, so we set the latter to zero ( j = 0). The standard

deviation of xjt is observed in the data. We can then

compute

x j

from

j because the observable and unob-

servable shocks are independent. As in most dynamic

discrete choice processes (Rust 1994), the discount factor

is difficult to estimate; we set it to 0 90.22

22 Sensitivity analyses with other discount rates (e.g., 0.95 and 0.99) yield almost identical log-likelihood statistics and similar parameter estimates for the index strategy model. Anticipating the results of §7.4, we expect a similar lack of sensitivity for the approximately optimal strategy. The ease with which such sensitivity checks can be run is a benefit of the computational tractability of the index strategy model.

Lin, Zhang, and Hauser: Learning from Experience, Simply

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

13

Finally, as in Erdem and Keane (1996), we suppress "parameter heterogeneity" among households. We continue to allow each household's quality beliefs to evolve idiosyncratically, but we do not attempt to estimate heterogeneity in prior beliefs, true mean quality, or the magnitude of utility shocks. We abstract away from parameter heterogeneity for the following reasons. First, there are, on average, only 13 purchases per household. We would overly strain the model by attempting to estimate heterogeneity in all of the parameters.23 Second, we wish to focus on behavioral heterogeneity that arises endogenously from forward-looking learning. Even if households start with exogenously homogeneous prior beliefs, different quality realizations and utility shocks lead to different posterior beliefs, different exploitation-versus-exploration trade-offs, and different learning paths (e.g., Ching et al. 2013a). We seek to evaluate heterogeneous learning dynamics based on the data, rather than using heterogeneous parameters to fit the data. For an initial test of an index strategy, this simplification is conservative because it biases against a good model fit.
We estimate each model's parameters with maximum simulated likelihood estimation. Estimation details are provided in Online Appendices F and G.
7.4. Estimation Results Table 3 summarizes the fit statistics for the 1,538 diaper purchases in the in-sample estimation and the 1,841 purchases in the out-of-sample validation. An information-theoretic measure, U 2, calculates the percent of uncertainty explained by the model (Hauser 1978); the Akaike Information Criterion (AIC) and the Bayesian Information Criterion (BIC) attempt to correct the likelihood function based on the number of parameters in the in-sample estimation, BIC more so than AIC. (There are no free parameters in the out-of-sample validation.)
For comparability, we estimate the index strategy in two ways. The first estimation discretizes the state space in the same manner as the approximately optimal model M = N = 5 . This enables an "apples-to-apples" comparison. Then, because the index model does not suffer from the curse of dimensionality, we reestimate the model with a finer grid (M = 200 N = 75 . There are only trivial differences. For example, U 2 = 88 18% for both estimations, and parameter values are not significantly different (nor different from the approximately optimal model). We report the results associated with the finer grid for the rest of the paper.
23 Doing so is technically feasible, but would likely over-parameterize the model and exploit noise in the data. More importantly, our goal is to demonstrate that an index solution is a viable representation of cognitive simplicity and that cognitive simplicity is a phenomenon worth studying in structural models. We leave explicit modeling of parameter heterogeneity to future research. Section 8.3 explores foresight heterogeneity.

First, on all measures there are sizable gains to

learning--all learning models explain and predict

brand choices substantially better than the no-learning

strategy. Second, the index strategy improves in-sample

fit and out-of-sample predictions relative to myopic

learning. The likelihood is significantly better (Vuong

test significance is p = 0 0002 in-sample and 0 0429

out-of-sample).24 This result is consistent with our

expectation that frequent buyers of branded diapers

are forward looking. Third, the index strategy per-

forms as well as the approximately optimal solution in

terms of both in-sample fit and out-of-sample predic-

tions. This result is consistent with the synthetic-data

analysis--when two strategies yield almost the same

expected utilities and hence predict almost the same

brand choices, they are observationally equivalent and

statistically indistinguishable.

As a further visualization of model fit, Table 2(b)

reports the predicted market-share-weighted switch-

ing patterns. The predicted switching patterns are

qualitatively similar to actual switching patterns in

Table 2(a). For example, the index strategy model picks

up the fact that consumers are more loyal to Huggies

than to the other brands because, as we discuss below,

the true mean quality is higher for Huggies and it is

likely more rewarding to learn about Huggies (

x j

being relatively small). Although predictions are not

perfect and could be improved if other x-variables

were observed, the overall mean absolute error (MAE)

is within 0 8% of actual switching. Moreover, the pre-

dicted switching patterns from the index strategy

model are virtually identical to those from the approx-

imately optimal solution model (reported in Online

Appendix H). The market-share-weighted MAE is

approximately 3/100ths of 1%.

Table 4 summarizes the estimated parameter values.

As expected, the price sensitivity coefficient is negative

in every model. Across all learning models, all four

brands increase in mean quality relative to prior beliefs,

which implies that diaper buyers learn to appreciate

these brands more through experience. These results

are consistent with the switching patterns in Table 2(a).

Forward-looking models identify the magnitude of

utility shocks relative to inherent quality uncertainty

(last panel of Table 4). Because the relative shock uncer-

tainty varies across brands, the index curve implies

different behavior than myopic learning for those

brands. This explains why forward-looking models fit

and predict better than myopic learning. For example,

Huggies has lower relative shock uncertainty than

other brands, which may provide greater incentives for

consumers to explore Huggies. Because the myopic

learning model ignores this difference, it compensates

by overestimating the mean prior belief of Huggies.

24 We use the Vuong test to compare nonnested models (Vuong 1989).

Lin, Zhang, and Hauser: Learning from Experience, Simply

14

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

Table 3 In-Sample and Out-of-Sample Fit Statistics for Diaper Data

Myopic Index Approximately Myopic learning Index strategy One-period Heterogeneous

No learning learning strategy

optimal with risk aversion with risk aversion look-ahead foresight

Calibration sample Log likelihood U2 (%) AIC BIC No. of parameters No. of observations
Hold-out sample Log likelihood U2 (%) No. of observations
Computation time in secondsa

-1 760 26 79 36
3 528 53 3 549 88
4 1,538
-1 998 25 80 43
1,841 Negligible

-1 051 39 -1 008 19

87 67 88 18

2 126 77 2 048 39

2 190 83 2 133 80

12

16

1,538 1,538

-1 165 47 -1 126 87

88 58 88 96

1,841 1,841

2

1.4 (22)

-1 008 95 88 17
2 049 89 2 135 31
16 1,538
-1 127 35 88 96
1,841 104

-1 051 39 87 67
2 128 77 2 198 17
13 1,538
-1 165 47 88 58
1,841 2

-1 008 01 88 18
2 050 02 2 140 77
17 1,538
-1 124 31 88 99
1,841 23

-1 023 30 88 00
2 072 61 2 142 00
13 1,538

-989 06 88 40
2 036 12 2 190 93
29 1,538

-1 115 04 89 08
1,841 11

-1 113 96 89 09
1,841 22

aThis is the time required to compute one likelihood function using a university computing system based on Sun Grid Engine and Red Hat Enterprise Linux. The approximately optimal model is estimated using the original grid (M = N = 5). For the index strategy model, the computation time is 1.4 seconds for the original grid and 22 seconds for the finer grid (M = 200, N = 75 .

Managerially, Huggies has a higher true mean quality than Pampers and Luvs, but also higher inherent relative uncertainty in quality across consumption. (The table reports the ratio of shock uncertainty to quality uncertainty--a smaller number means higher relative quality uncertainty.)
Both the index strategy and the approximately optimal strategy lead to similar parameter estimates. Parameter estimates of either model are usually within confidence regions of the alternative model. This result is consistent with the synthetic-data analysis, which suggests that both strategies lead to near optimal utility. The index strategy will be a more plausible description of consumer behavior if it is cognitively simpler. We explore this last point below.
Computation time in the embedded optimization problem is one surrogate for cognitive complexity. The last row of Table 3 reports the time necessary to compute one likelihood function in each model. For the index strategy model we report the computation time for both the original grid (M = N = 5 and the finer grid (M = 200, N = 75 --the latter is in parentheses. Consistent with the synthetic-data analysis, the index strategy is substantially faster than the approximately optimal strategy (74-to-1 ratio based on the same grid density of M = N = 5 .
The size of the state space is another surrogate for cognitive complexity (e.g., a consumer's memory). The state space for the approximately optimal strategy is 15,625 times as large as the state space for the index strategy given the same grid density of M = N = 5. Computational-time ratios are not equal to state-space ratios because of computational overhead. Nonetheless, if we were to attempt to use the finer grid of M = 200, N = 75 for the approximately optimal strategy, we would increase the state space of the approximately optimal solution by a factor of 130 billion. It is unlikely

that approximately optimal computations would be feasible for the finer grid. Detailed calculations are presented in Online Appendix G.
In summary, using IRI data on diaper purchases we find that (1) learning models fit and predict substantially better than the no-learning model; (2) forwardlooking learning models fit and predict significantly better than the myopic learning model; (3) the index strategy and the approximately optimal solution achieve similar in-sample fit and out-of-sample forecasts, as well as reasonably close parameter estimates; and (4) computational (and cognitive) simplicity favors the index strategy model relative to the approximately optimal model.
8. Further Explorations
We have shown that the canonical forward-looking experiential learning model is indexable and that an index strategy performs well. We now extend the analysis to explore consumer risk aversion, other cognitively simple heuristics, heterogeneous consumer foresight, and private labels.
8.1. Risk Aversion For ease of exposition, in previous sections we assumed that consumers are risk neutral. However, risk aversion can be an important issue for decision making under uncertainty (see Ching et al. 2013a for a review). We generalize our model to incorporate risk aversion following the standard discounted-utility approach (e.g., Samuelson 1937, Erdem and Keane 1996). At each purchase occasion t, the consumer maximizes =t -tu w , where w is the net payoff the consumer receives at purchase occasion , and u · is the consumer's utility function. Utility increases with net payoff (i.e., u > 0 . In addition, the curvature of the utility function captures general risk preferences: the consumer is risk

Lin, Zhang, and Hauser: Learning from Experience, Simply

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

15

Table 4

Parameter Estimates for Diaper Data

Myopic

Index

Myopic Index Approximately learning with strategy with One-period

Heterogeneous foresight

No learning learning strategy optimal risk aversion risk aversion look-ahead (Myopic learning) (Index strategy)

Pampers Huggies Luvs Other brands

0 000 --
0 095 0 059
-0 716 0 081
-3 223 0 190

Pampers

--

--

Huggies

--

--

Luvs

--

--

Other brands

--

--

Pampers

--

--

Huggies

--

--

Luvs

--

--

Other brands

--

--

Pampers Huggies Luvs Other brands Price sensitivity ( ) Risk aversion (r ) % forward looking

-- --
-- --
-- --
-- --
-0 126 0 020
-- --
-- --

0 000 --

0 000 --

Relative mean of prior beliefs ( ¯j0 1

0 000

0 000

0 000

--

--

--

0 000 --

0 079 -0 798 0 156 0 717

-0 198 0 194

0 007 0 151

-0 346 0 036

-0 014 0 092

-0 641 -2 351 0 177 1 626

-1 381 0 534

-0 627 0 163

-1 941 1 079

-0 819 0 224

-2 761 -3 143 0 321 2 107

-2 978 0 853

-2 474 0 488

-3 211 2 566

-2 744 0 300

Uncertainty of prior beliefs ( ¯j0) relative to inherent quality uncertainty ( j )

0 734 0 694

0 724

0 734

0 699

0 564

0 099 0 118

0 119

0 099

0 116

0 038

0 476 0 066

0 455 0 294

0 494 0 153

0 476 0 066

0 463 0 362

0 424 0 074

0 773 0 139

1 126 0 730

1 394 0 600

0 773 0 138

1 215 0 940

0 740 0 064

1 332 0 491

1 428 1 750

1 394 0 818

1 333 0 487

1 423 1 931

0 779 0 146

3 902 0 329

3 686 2 092

True mean quality ( j 2

3 551

3 777

0 844

0 361

3 585 2 571

3 991 0 182

5 852 0 688

8 438 5 088

7 850 2 192

5 728 0 703

8 189 5 914

6 374 1 404

3 666 0 502

2 724 1 544

2 544 0 704

3 542 0 499

2 569 1 857

2 956 0 276

1 630 0 820

1 343 1 080

1 364 0 856

1 504 0 824

1 293 1 239

1 985 0 961

Magnitude of

utility

shocks (

x j

--

0 837

0 836

--

0 508

0 221

3 relative to inherent quality uncertainty ( j )

--

1 081

0 273

--

0 813

0 021

--

0 138

--

0 084

0 151 0 040

--

0 141

0 271

--

0 106

0 020

--

0 316

--

0 192

0 347 0 092

--

0 317

0 275

--

0 238

0 022

--

1 272

--

0 772

1 347 0 357

--

1 090

0 275

--

0 820

0 022

-0 128 -0 152 0 026 0 094

-0 153 0 048

-0 128 0 026

-0 152 0 115

-0 160 0 028

--

--

--

--

--

--

0 463

0 084

--

0 305

0 039

--

--

--

--

--

--

--

--

--

--

--

--

--

0 000 --
-0 479 0 774
-1 686 1 412
-7 169 3 195
0 142 0 018 3 404 2 898 0 623 0 428 0 666 11 452
11 660 1 905 0 226 3 164 2 774 2 460 2 247 9 340
-- -- -- -- -- -- -- -- -0 274 0 077 -- -- -- --

0 000 --
-1 169 1 776
-3 926 5 717
-2 253 2 419
0 887 0 356 0 545 0 237 1 397 1 806 1 391 5 697
3 954 0 841 9 083 3 164 2 908 0 974 2 058 0 921
0 885 0 219 0 128 0 032 0 227 0 057 1 156 0 289 -0 081 0 045
-- -- 0 773 0 091

Note. For identification: 1 ¯10 = 0. 2

j = 0. 3

x j

observed

in

the

data,

j estimated, and

x j

computed from the two via independence.

neutral if u = 0, risk averse if u < 0, and risk seeking if u > 0. The Bellman equation for the subproblem of the jth brand (Equation (5)) is generalized as
V sjt xjt jt j
= max u j +  V sjt xj t+1 j t+1 j

 u xjt + jt + qjt sjt

+  V sj t+1 xj t+1 j t+1 j sjt

(7)

We prove in Online Appendix A.2 that the generalized canonical forward-looking experiential learning model is indexable. This is true for all consumer utility functions satisfying u > 0.

Lin, Zhang, and Hauser: Learning from Experience, Simply

16

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

The indexability result allows us to test for risk aversion at low computational costs. We do so using the diaper data. To parameterize the test, we assume that consumers exhibit constant absolute risk aversion: u w = 1 - e-rw, where r > 0 measures the degree of risk aversion (e.g., Roberts and Urban 1988).25 Based on this utility function, we reestimate the index strategy model. In addition, we reestimate the myopic learning model to see whether general risk preferences as opposed to the exploration incentive suffice to explain consumer choices.26
Table 3 reports the fit statistics. Allowing for risk aversion brings little improvement to the likelihood and U 2, and worsens the AIC and BIC because of the extra risk-aversion parameter. Table 4 reports the parameter estimates. The risk-aversion parameter is insignificant for the myopic learning model; it is marginally significant for the index strategy model but the magnitude is small. Diaper buyers in our sample do not seem to be strongly risk averse. Because the approximately optimal model provides parameter estimates that are close to the index model for the risk neutral case, we expect similar results if we were to estimate the approximately optimal model for the risk averse case.

8.2. Other Cognitively Simple Heuristics The canonical forward-looking experiential learning model assumes that consumers have perfect foresight. But the degree of foresight is an empirical question. Ho and Chong (2003) find that a parsimonious myopic model accurately describes and predicts stock keeping unit (SKU) demand.27 Models in which the decision maker looks one period ahead sometimes explain choices well (Hauser et al. 1993, Gabaix et al. 2006, Che et al. 2007). In the bandit literature, Ny and Feron (2006) explore one-period look-ahead heuristics as approximate solutions to restless bandits with switching costs. A one-period look-ahead model is arguably simpler than the full dynamic optimization problem, and is a heuristic consumers might use. For a one-period look-ahead model, the Bellman equation (Equation (3)) is modified as

V st xt

t

= max j A

xjt + jt

+  qjt +

max kA

qk

t+1 +

xk t+1 + k t+1

st j

(8)

Tables 3 and 4 report the empirical results. The oneperiod look-ahead model has worse in-sample fit than the index strategy model (Vuong test p = 0 0244)

25 For constant risk aversion, u w  w as r  0. Erdem and Keane (1996) express risk aversion with a quadratic utility function.
26 The risk aversion parameter cannot be separately identified from the mean prior beliefs in the no-learning model.
27 The model was used by Procter and Gamble to predict SKU purchases.

and approximately the same out-of-sample prediction (Vuong test p = 0 2529). The one-period look-ahead model fits better than the myopic learning model both in-sample (Vuong test p = 0 0033 and out-of-sample (Vuong test p = 0 0009 . These results suggest that diaper consumers are not myopic, although they may not be perfectly forward looking.
We could easily estimate a variety of cognitively simple heuristics including Tl-period look-ahead models for Tl < T , Gittins'-index models modified to allow for utility shocks,28 and various heuristics such as those proposed by Bertsimas and Niño-Mora (2000). For example, a modified-Gittins'-index model (U 2 = 88 09% in-sample; U 2 = 88 84% out-of-sample) does better than myopic learning, but not as well as the index strategy model (which is based on Whittle's index). We strongly caution against choosing a best-predicting model based on a single data set. Unrestricted search among models would likely exploit random variation. However, from the good fit and predictive ability of the three tested heuristics (Whittle's index, one-period look-ahead, and modified Gittins' index), we are comfortable in our hypotheses that (1) cognitively simple heuristics are plausible alternatives to modeling forward-looking behavior and (2) an index strategy is one viable model.
8.3. Heterogeneous Foresight In an alternative approach we allow for heterogeneous consumer foresight. We assume there are two latent consumer segments that represent the two "extremes" of the foresight spectrum. One segment engages in myopic learning and the other segment has perfect foresight. Because the index strategy and the approximately optimal solution are observationally indistinguishable, we assume that the perfect-foresight segment follows the computationally favorable index strategy. We use the latent class method (Kamakura and Russell 1989) to estimate the fraction of consumers belonging to each segment, as well as the set of parameters associated with each segment.
Not surprisingly, as Table 3 shows, the latent class model generates higher likelihood and U 2 than both the myopic learning model (p < 0 0001 in-sample; p < 0 0001 out-of-sample) and the index strategy model (p = 0 0003 in-sample; p = 0 018 out-of-sample). The flexibility of the latent class model comes at the cost of extra parameters. It produces a slightly better AIC but a worse BIC than the index strategy model.
The last two columns of Table 4 report the parameter estimates of the latent class model. The parameter estimates associated with the respective segments indicate
28 Specifically, the modified Gittins' index assumes that the consumer at purchase occasion t chooses the brand with the highest value of G sjt + xjt + jt, where G sjt is Gittins' index derived from the optimization problem in the absence of utility shocks (see §4). The modified Gittins' index is an ad hoc solution relative to the Whittle's-index model.

Lin, Zhang, and Hauser: Learning from Experience, Simply

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

17

Table 5 In-Sample and Out-of-Sample Fit Statistics for Diaper Data (Private Labels Included)

Myopic Index Approximately Myopic learning Index strategy One-period Heterogeneous

No learning learning strategy

optimal with risk aversion with risk aversion look-ahead foresight

Calibration sample Log likelihood U2 (%) AIC BIC No. of parameters No. of observations

-3 301 57 -1 955 16 -1 853 22

76 58

86 13 86 85

6 611 14 3 934 33 3 738 45

6 634 50 4 004 41 3 831 90

4

12

16

2,542

2,542 2,542

Hold-out sample Log likelihood U2 (%) No. of observations

-3 173 91 -1 935 58 -1 855 17

76 87

85 90 86 48

2,475

2,475 2,475

Computation time in secondsa Negligible

1

1.5 (23)

-1 857 04 86 83
3 746 08 3 839 53
16 2,542
-1 859 30 86 45
2,475 146

-1 955 16 86 13
3 936 33 4 012 26
13 2,542
-1 935 59 85 90
2,475 1

-1 852 43 86 86
3 738 86 3 838 15
17 2,542
-1 852 32 86 50
2,475 24

-1 862 60 86 79
3 751 20 3 827 12
13 2,542

-1 814 66 87 13
3 687 31 3 856 69
29 2,542

-1 861 23 86 44
2,475
6

-1 870 81 86 37
2,475
24

aThis is the time required to compute one likelihood function using a university computing system based on Sun Grid Engine and Red Hat Enterprise Linux. The approximately optimal model is estimated using the original grid (M = N = 5). For the index strategy model, the computation time is 1.5 seconds for the original grid and 23 seconds for the finer grid (M = 200, N = 75).

similar qualitative comparisions across brands relative to the homogeneous-foresight models. Meanwhile, 77% of diaper buyers are forward looking. This finding echoes the result from the one-period look-ahead model that the average diaper buyers are neither myopic nor perfectly forward looking.
8.4. Private Labels Our primary analyses eliminated any consumer who purchased a private label during the observation window. This restriction allowed us to focus on a case where we expected forward-looking learning. The decision was also driven by the curse of dimensionality inherent in the approximately optimal solution--adding another brand increases the size of the state space by M × N = 25 times. As a robustness check, we repeat our estimations replacing "other brands" with private labels. Table 5 presents the fit statistics. The relative fit and predictive accuracies are the same as in Table 3. Furthermore, the (unreported) parameter estimates for Pampers, Huggies, and Luvs are not significantly different when comparing the index strategy and approximately optimal models in Tables 3 and 5.
9. Summary, Conclusions, and Future Research
Models of forward-looking experiential learning are important to marketing. These theory-driven models examine how consumers make trade-offs between exploiting and exploring brand information. Managerially, these models enable researchers to investigate effects due to quality uncertainty, learning, and the variation in utility shocks. However, the consumer problem in these models is computationally intractable (PSPACE-hard). Existing solutions via the Bellman equation require vast computational resources (time and

memory) that may contradict cognitive simplicity theories of consumers.
In this paper we propose that consumers use cognitively simple heuristics to solve forward-looking experiential learning problems. We explore one viable heuristic--index strategies. Index strategies represent a solution concept that decomposes a complex problem into a set of much simpler subproblems. We prove analytically that an index strategy exists for canonical forward-looking experiential learning models and that the index function has simple properties that consumers might intuit. Using synthetic data, we demonstrate that a well-defined index solution achieves near optimal expected utility and is fast to compute. Using IRI data on diaper purchases, we show that at least one index solution fits the data and predicts out-of-sample significantly better than either a no-learning model or a myopic learning model. Compared with an approximately optimal solution, the index strategy fits equally well, produces similar estimation results (and hence managerial implications), requires significantly lower computational costs and, we believe, is more likely to describe consumer behavior.
We address many issues, but many issues remain. We do not model advertising as a quality signal (the IRI data set for the diaper category does not track advertising). The consequence of incorporating advertising signals depends on how consumers learn. We abstract away from inventory problems. Inventory effects are found to be insignificant in previous research (Ching et al. 2012), but nevertheless add a dimension to consumers' dynamic planning. We study standard settings where consumers do not learn from nonchosen alternatives. It would be interesting to model correlated learning or extend index strategies to incorporate hypothetical reinforcement of nonchosen options (Camerer and Ho 1999). Technically, it would also be interesting

Lin, Zhang, and Hauser: Learning from Experience, Simply

18

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

to examine the indexability of learning models when there are switching costs.29
Diaper buyers are likely forward looking, but consumers in other product categories may not be. Our theory suggests that consumers are most likely to be forward looking when shock uncertainty is small compared with quality uncertainty; we expect myopic learning models to do well when shock uncertainty is large. This prediction is testable using cross-category analysis. For instance, shock uncertainty may be large in hedonic goods categories where consumption value swings with idiosyncratic mood. Shock uncertainty may also be dominant in markets characterized by volatile marketing mix variables. The recent rise of flash sales introduced remarkable price volatility to categories such as food, gadgets, and apparel. It will be interesting to study whether this change serves to promote myopic purchase behaviors.
Finally, an index solution appears to be a reasonable trade-off for diaper consumers, but our basic hypothesis is that consumers use cognitively simple heuristic strategies. Other cognitively simple heuristics might explain consumer behavior even better than index strategies. Section 8.2 suggests testable alternatives. Future research can explore these and other heuristics using either field data or laboratory experiments.
Supplemental Material Supplemental material to this paper is available at http://dx .doi.org/10.1287/mksc.2014.0868.
Acknowledgments The authors gratefully acknowledge the helpful comments from Andrew Ching, Nathan Fong, Jacob Gramlich, Eric Schwartz, Qiaowei Shen, Duncan Simester, Olivier Toubia, Catherine Tucker; seminar participants at Massachusetts Institute of Technology and the University of North Carolina at Chapel Hill; and attendees of the 2012 INFORMS International Conference, 2012 Marketing Science Conference, 2013 Allied Social Science Associations Annual Meeting, and 2013 Marketing Dynamics Conference. The authors thank the editor, associate editor, and reviewers for their constructive comments that improved the paper.
References
Ackerberg DA (2003) Advertising, learning, and consumer choice in experience good markets: An empirical examination. Internat. Econom. Rev. 44(3):1007­1040.
Banks JS, Sundaram RK (1994) Switching costs and the Gittins index. Econometrica 62(3):687­694.
Bertsimas D, Niño-Mora J (2000) Restless bandits, linear programming relaxations, and a primal-dual index heuristic. Oper. Res. 48(1): 80­90.
29 Banks and Sundaram (1994) prove that there is no consistent way to define an optimal index in the presence of switching costs among choice alternatives. However, a bandit problem with switching cost can be reformulated as a restless bandit problem, which could be indexable (Glazebrook et al. 2006, Niño-Mora 2008).

Bertsekas D, Tsitsiklis J (1996) Neuro-Dynamic Programming (Athena Scientific Press, Cambridge, MA).
Bettman JR (1979) An Information Processing Theory of Consumer Choice (Addison-Wesley, Reading, MA).
Bettman JR, Luce MF, Payne JW (1998) Constructive consumer choice processes. J. Consumer Res. 25(3):187­217.
Bröder A (2000) Assessing the empirical validity of the "take the best" heuristic as a model of human probabilistic inference. J. Experiment. Psych.: Learning, Memory, Cognition 26(5):1332­1346.
Bronnenberg BJ, Kruger MW, Mela CF (2008) The IRI marketing data set. Marketing Sci. 27(4):745­748.
Camerer CF (2003) Behavioral Game Theory: Experiments in Strategic Interaction, Roundtable Series in Behavioral Economics (Princeton University Press, Princeton, NJ).
Camerer CF, Ho TH (1999) Experience-weighted attraction learning in normal form games. Econometrica 67(4):827­874.
Che H, Sudhir K, Seetharaman PB (2007) Bounded rationality in pricing under state-dependent demand: Do firms look ahead, and if so, how far? J. Marketing Res. 44(3):434­449.
Ching A (2010) A dynamic oligopoly structural model for the prescription drug market after patent expiration. Internat. Econom. Rev. 51(4):1175­1207.
Ching A, Erdem T, Keane M (2010) How much do consumers know about the quality of products? Evidence from the diaper market. Working paper, University of Toronto, Toronto.
Ching A, Erdem T, Keane M (2012) A simple approach to estimate the roles of learning, inventory and experimentation in consumer choice. Working paper, University of Toronto, Toronto.
Ching A, Erdem T, Keane M (2013a) Learning models: An assessment of progress, challenges and new developments. Marketing Sci. 32(6):913­938.
Ching A, Erdem T, Keane M (2013b) Online appendix of "Learning models: An assessment of progress, challenges and new developments." Marketing Sci. http://pubsonline.informs.org/doi/ suppl/10.1287/mksc.2013.0805.
Ching A, Ishihara M (2010) The effects of detailing on prescribing decisions under quality uncertainty. Quant. Marketing Econom. 8(2):123­165.
Ching A, Ishihara M (2012) Measuring the informative and persuasive roles of detailing on prescribing decisions. Management Sci. 58(7):1374­1387.
Chintagunta P, Jiang R, Jin GZ (2009) Information, learning, and drug diffusion: The case of Cox-2 inhibitors. Quant. Marketing Econom. 7(4):399­443.
Chintagunta P, Erdem T, Rossi PE, Wedel M (2006) Structural modeling in marketing: Review and assessment. Marketing Sci. 25(6):604­616.
Chow C-S, Tsitsiklis JN (1991) An optimal one-way multigrid algorithm for discrete-time stochastic control. IEEE Trans. Automatic Control AC-36(8):898­914.
Crawford GS, Shum M (2005) Uncertainty and learning in pharmaceutical demand. Econometrica 73(4):1137­1173.
Dickstein M (2012) Efficient provision of experience goods: Evidence from antidepressant choice. Working paper, Stanford University, Palo Alto, CA.
Erdem T, Keane MP (1996) Decision making under uncertainty: Capturing dynamic brand choice processes in turbulent consumer goods markets. Marketing Sci. 15(1):1­20.
Erdem T, Keane MP, Sun B (2008) A dynamic model of brand choice when price and advertising signal product quality. Marketing Sci. 27(6):1111­1125.
Erdem T, Keane MP, Öncü T, Strebel J (2005) Learning about computers: An analysis of information search and technology choice. Quant. Marketing Econom. 3(3):207­247.
Gabaix X, Laibson D (2000) A boundedly rational decision algorithm. Amer. Econom. Rev. 90(2):433­438.

Lin, Zhang, and Hauser: Learning from Experience, Simply

Marketing Science 34(1), pp. 1­19, © 2015 INFORMS

19

Gabaix X, Laibson D, Moloche G, Weinberg S (2006) Costly information acquisition: Experimental analysis of a boundedly rational model. Amer. Econom. Rev. 96(4):1043­1068.
Gigerenzer G, Goldstein DG (1996) Reasoning the fast and frugal way: Models of bounded rationality. Psych. Rev. 103(4):650­669.
Gilbride TJ, Allenby GM (2004) A choice model with conjunctive, disjunctive, and compensatory screening rules. Marketing Sci. 23(3):391­406.
Gilovich T, Griffin D, Kahneman D (2002) Heuristics and Biases: The Psychology of Intuitive Judgment (Cambridge University Press, Cambridge, UK).
Gittins J (1989) Multi-Armed Bandit Allocation Indices (John Wiley & Sons, New York).
Gittins J, Jones D (1974) A dynamic allocation index for the sequential design of experiments. Gani J, Sarkadi K, Vince I, eds. Progress in Statistics (North-Holland, Amsterdam), 241­266.
Gittins J, Glazebrook K, Weber R (2011) Multi-Armed Bandit Allocation Indices, 2nd ed. (John Wiley & Sons, Hoboken, NJ).
Glazebrook K, Ruiz-Hernandez D, Kirkbride C (2006) Some indexable families of restless bandit problems. Adv. Appl. Probab. 38(3): 643­672.
Goldstein DG, Gigerenzer G (2002) Models of ecological rationality: The recognition heuristic. Psych. Rev. 109(1):75­90.
Guadagni PM, Little JDC (1983) A logit model of brand choice calibrated on scanner data. Marketing Sci. 2(3):203­238.
Hansen K, Singh V, Chintagunta P (2006) Understanding the store-brand purchase behavior across categories. Marketing Sci. 25(1):75­90.
Hauser JR (1978) Testing the accuracy, usefulness and significance of probabilistic models: An information theoretic approach. Oper. Res. 26(3):406­421.
Hauser JR (1986) Agendas and consumer choice. J. Marketing Res. 23(3):199­212.
Hauser JR, Urban GL (1986) The value priority hypotheses for consumer budget plans. J. Consumer Res. 12(4):446­462.
Hauser JR, Urban GL, Weinberg BD (1993) How consumers allocate their time when searching for information. J. Marketing Res. 30(4):452­466.
Hauser JR, Urban GL, Liberali G, Braun M (2009) Website morphing. Marketing Sci. 28(2):202­223.
Hauser JR, Toubia O, Evgeniou T, Befurt R, Dzyabura D (2010) Disjunctions of conjunctions, cognitive simplicity, and consideration sets. J. Marketing Res. 47(3):485­496.
Ho T-H, Chong J-K (2003) A parsimonious model of stockkeepingunit choice. J. Marketing Res. 40(3):351­365.
Houser D, Keane MP, McCabe K (2004) Behavior in a dynamic decision problem: An analysis of experimental evidence using Bayesian type classification algorithm. Econometrica 72(3):781­822.
Hutchinson JMC, Gigerenzer G (2005) Simple heuristics and rules of thumb: Where psychologists and behavioural biologists might meet. Behavioural Processes 69(2):97­124.
Imai S, Jain N, Ching A (2009) Bayesian estimation of dynamic discrete choice models. Econometrica 77(6):1865­1899.
Johnson EJ, Payne JW (1985) Effort and accuracy in choice. Management Sci. 31(4):395­414.
Jovanovic B (1979) Job matching and the theory of turnover. J. Political Econom. 87(5):972­990.
Kamakura W, Russell G (1989) A probabilistic choice model for market segmentation and elasticity structure. J. Marketing Res. 26(4):379­390.
Keane M, Wolpin K (1994) The solution and estimation of discrete choice dynamic programming models by simulation and interpolation: Monte Carlo evidence. Rev. Econom. Statist. 76(4):648­672.
Kohli R, Jedidi K (2007) Representation and inference of lexicographic preference models and their variants. Marketing Sci. 26(3): 380­399.
Lindsay PH, Norman DA (1977) Human Information Processing: An Introduction to Psychology (Academic Press, New York).

Marewski JN, Pohl RF, Vitouch O (2010) Recognition-based judgments and decisions: Introduction to the special issue (Vol. 1). Judgment Decision Making 5(4):207­215.
Martignon L, Hoffrage U (2002) Fast, frugal, and fit: Simple heuristics for paired comparisons. Theory Decision 52(1):29­71.
McFadden D (1986) The choice theory approach to market research. Marketing Sci. 5(4):275­297.
Mehta N, Chen XJ, Narasimhan O (2008) Informing, transforming, and persuading: Disentangling the multiple effects of advertising on brand choice decisions. Marketing Sci. 27(3):334­355.
Miller R (1984) Job matching and occupational choice. J. Political Econom. 92(6):1086­1120.
Narasimhan C (1988) Competitive promotional strategies. J. Bus. 61(4):427­449.
Narayanan S, Manchanda P (2009) Heterogeneous learning and the targeting of marketing communication for new products. Marketing Sci. 28(3):424­441.
Narayanan S, Manchanda P, Chintagunta PK (2005) Temporal differences in the role of marketing communication in new product categories. J. Marketing Res. 42(3):278­290.
Ni J, Neslin SA, Sun B (2012) Database submission--The ISMS durable goods data sets. Marketing Sci. 31(6):1008­1013.
Niño-Mora J (2001) Restless bandit, partial conservation laws and indexability. Adv. Appl. Probab. 33(1):76­98.
Niño-Mora J (2008) A faster index algorithm and a computational study for bandits with switching costs. INFORMS J. Comput. 20(2):255­269.
Ny JL, Feron E (2006) Restless bandits with switching costs: Linear programming relaxations, performance bounds and limited lookahead policies. Proc. 2006 Amer. Control Conf., Minneapolis.
Papadimitriou CH, Tsitsiklis JN (1999) The complexity of optimal queuing network control. Math. Oper. Res. 24(2):293­305.
Payne JW, Bettman JR, Johnson EJ (1988) Adaptive strategy selection in decision making. J. Experiment. Psych.: Learning, Memory, Cognition 14(3):534­552.
Payne JW, Bettman JR, Johnson EJ (1993) The Adaptive Decision Maker (Cambridge University Press, Cambridge, UK).
Roberts JH, Urban GL (1988) Modeling multiattribute utility, risk, and belief dynamics for new consumer durable brand choice. Management Sci. 34(2):167­185.
Rust J (1987) Optimal replacement of GMC bus engines: An empirical model of Harold Zurcher. Econometrica 55(5):999­1033.
Rust J (1994) Structural estimation of Markov decision processes. Engle RF, McFadden DF, eds. Handbook of Econometrics (North Holland, Amsterdam).
Rust J (1996) Numerical dynamic programming in economics. Amman HM, Kendrick DA, Rust J, eds. Handbook of Computational Economics, Vol. 1 (North Holland, Amsterdam).
Rust J (1997a) Using randomization to break the curse of dimensionality. Econometrica 65(3):487­516.
Rust J (1997b) Dealing with the complexity of economic calculations. Working paper, Yale University, New Haven, CT.
Samuelson PA (1937) A note on measurement of utility. Rev. Econom. Stud. 4(2):155­161.
Shugan SM (1980) The cost of thinking. J. Consumer Res. 7(2):99­111.
Simon HA (1955) A behavioral model of rational choice. Quart. J. Econom. 69(1):99­118.
Simon HA (1956) Rational choice and the structure of the environment. Psych. Rev. 63(2):129­138.
Urban GL, Liberali G, MacDonald E, Bordley R, Hauser JR (2014) Morphing banner advertising. Marketing Sci. 33(1):27­46.
Vuong QH (1989) Likelihood ratio tests for model selection and non-nested hypotheses. Econometrica 57(2):307­333.
Whittle P (1988) Restless bandits: Activity allocation in a changing world. J. Appl. Probab. 25(2):287­298.
Yee M, Dahan E, Hauser JR, Orlin J (2007) Greedoid-based noncompensatory inference. Marketing Sci. 26(4):532­549.

