Vol. 25, No. 6, November­December 2006, pp. 622­624 issn 0732-2399 eissn 1526-548X 06 2506 0622

informs ®
doi 10.1287/mksc.1050.0186 © 2006 INFORMS

Invited Commentary
Structural Modeling in Marketing: Some Future Possibilities
Girish Punj
School of Business, University of Connecticut, 2100 Hillside Road, Storrs, Connecticut 06269, girish.punj@business.uconn.edu
Key words: structural models; marketing models; behavioral theory History: This paper was received September 26, 2005; processed by Steven Shugan.

The growing interest in using structural modeling to test theories of consumer and firm behavior stems from the increased availability of market data at the individual level (both longitudinal and crosssectional) for a variety of products. The emergence of online consumer panels, where data on behavioral intentions can be collected, and the availability of retail transactional data from online stores can be expected to only accelerate the trend. Hence, the recent review article by Chintagunta et al. (2006) is a timely contribution to the structural modeling, along with other recent contributions by Wittink (2005), Franses (2005a, b), Van Heerde et al. (2005), and Bronnenberg et al. (2005).
Chintagunta et al. (2006) and the other authors mentioned discuss the state of the art in the development and application of structural models in marketing. They discuss the advantages and disadvantages of using structural modeling to test marketplace theories and the cautions to be observed in the validation of structural models. The recommendations they offer suggest the potential for further use of structural models in marketing. The purpose of this commentary is to take some of the recommendations offered by Chintagunta et al. (2006) and use them to discuss some future possibilities.
First, there is the issue of how much behavioral theory should be included in a structural model. At one extreme, no data are needed to develop a theoretical model (Moorthy 1993). In fact, data could be considered a "distraction" or even irrelevant (Shugan
Although invited commentaries are not formally peer-reviewed and represent the opinion of the author, authors were carefully chosen based on their outstanding expertise in the areas of their respective commentaries.

2002a). Theoretical models that do not rely on data are developed from both behavioral (i.e., substantive) assumptions and those made for analytical tractability (Moorthy 1993). With that distinction in mind, theoretical models could be adequate to provide a preliminary "test" of behavioral theories (Shugan 2002b). Likewise, a theoretical supermodel with economic primitives that are invariant to strategy/policy change could be used to initially evaluate alternative (i.e., competing) strategy/policy regimes that are contained within it (Moorthy 1993). The nested structure of a theoretical model could be used to eliminate some strategy/policy regimes (Moorthy 1993). Eventually, an econometric specification of the supermodel (or the "winning" nested model) would need to be developed. Yet, the use of logical experimentation at the front end could alleviate some of the estimation and inference difficulties created by starting with a single tightly parameterized structural model. The ideal situation would be where some degree of modularity could be achieved between a theoretical supermodel and tightly parameterized structural models that are nested within it.
Second, there is the matter of how to validate structural model. Chintagunta et al. (2006) specify the use of modeling criteria such as plausibility, interpretability, fit, and predictive validity to evaluate a structural model. Some of these criteria are necessarily subjective. Franses (2005a) mentions that structural models pass diagnostic tests have out-of-sample predictive validity and exhibit parameter stability. There is little debate that reduced-form models should meet diagnostic tests, which can be applied in check-list fashion. Reduced-form models can exploit the biasvariance trade-off to achieve excellent predictive performance, hence more demanding predictive tests are

622

Punj: Invited Commentary: Structural Modeling in Marketing

Marketing Science 25(6), pp. 622­624, © 2006 INFORMS

623

needed. But such a check-list approach to measuring model performance might be less useful for structural models (Shugan 2004). Some diagnostic tests might not be applicable, others might not be available, and even when a diagnostic test is failed it might not alter the managerial implications that can be drawn from a model (Wittink 2005). The substantive insights provided by a structural model can only be compared to those from a simpler model or even subjective managerial judgment. A model can satisfy diagnostic tests but still not be useful for strategy/policy simulation (Bronnenberg et al. 2005). Conversely, a structural model can perform poorly on diagnostic tests but still be useful for strategy/policy evaluation (Wittink 2005) if there is confidence that the model primitives are strategy/policy invariant. Furthermore, efforts to improve the predictive performance of a structural model could make it theoretically worse. Thus, regarding reduced-form and structural models as the end-points of a continuum might not be appropriate, without the recognition that modeling criteria change along the continuum and are not incremental.
Third, there is a debate about how to best incorporate forward-looking behavior by consumers into a structural model. Consumers can be expected to form (rational) expectations about the future actions of firms and incorporate them into their own behavior. Franses (2005a) presents three scenarios relating to the potential impact of consumer expectations. Consumers might have no information on future policy/ strategy (marketing instrument) changes, or they foresee policy/strategy changes, incorporate them into their expectations, but do not change behavior, or consumers foresee policy/strategy changes, incorporate them into their expectations and change behavior. In the latter instance, additional equations are normally added to the model specification to capture the impact of expectations. However, whether the additional specification accurately captures forwardlooking behavior if often not tested. Chintagunta et al. (2006) advocate the use of survey data on expectations to test behavioral assumptions, as do Bronnenberg et al. (2005).
A future possibility is to attempt to directly measure behavioral intentions using online consumer panels and combine them with retail POS data. Some marketing research suppliers already offer such a service (Veraart 2004). While the quality of expectations data gathered from an online consumer panel might not be the best, there is an unmistakable trend toward the development of larger (2.5 to 5 million) and more heterogeneous panels. The modeling challenge would be to merge passive (historical) data with (stated) intentions or expectations data, similar to the challenge encountered in the case of scanner data (Winer 1999). Behavioral theories could continue to be relied

on when intentions data are nonexistent or sparse and are removed as more become available (Shugan 2002a). Structural models in the I/O literature have adapted well as newer and better forms of data have become available. A similar approach could be successful in marketing.
Fourth, controlled experimentation is more feasible in marketing than in economics (Swait and Andrews 2003, Van Heerde et al. 2005). Retail transaction data generated from online stores offer the opportunity for controlled experimentation relating to incremental changes in marketing instrument variables. With the use of the Internet as an additional distribution channel by firms, such data are likely to become more available in the future (Johnson 2001, Lohse et al. 2000). Anecdotal accounts of online stores using controlled experimentation to test alternative pricing levels have been reported, but not without controversy (Streitfeld 2000). Because forward-looking behavior by consumers is context dependent (i.e., is specific to product categories, time periods, etc.), direct measurement of the effects of a "strong" instrumental variable might be a better option than an additional econometric specification using a "weak" instrument. The endogeneity bias in structural models cannot be overcome if "weak" instrumental variables are used.
Fifth, as Chintagunta et al. (2006) note, a strength of the structural modeling approach is the ability to predict the effects of a strategy/policy change that is beyond the historical data used in developing the model. In so doing, several challenges have to be overcome, including the Lucas critique. One approach to capturing the effects of a strategy/policy change is to use time-varying response parameters, which have the benefit of fewer (less restrictive) behavioral assumptions (Van Heerde et al. 2005). However, time-varying parameter models still assume that the relationship between policy/strategy and response parameters remains constant. Hence, they merely shift the problem of assuming constant parameters to assuming a constant relationship between policy/strategy and response parameters (Van Heerde et al. 2005). Furthermore, time-invariant parameters could be due to a constant strategy/policy regime. Also, time-varying parameters could be due to something other than a change in a strategy/policy (Bronnenberg et al. 2005). Hence, using time-dependent parameters or other similar surrogate approaches might not always be adequate to predict the effects of a strategy/policy change.
Sixth, how often do firms make discrete (i.e., significant) changes in strategy/policy? Probably not very often. Two often-cited examples in the literature are the Marlboro price drop (Van Heerde et al. 2005) and the Procter and Gamble adoption of an EDL strategy (Ailawadi et al. 2001). Ironically, both these strategy/

Punj: Invited Commentary: Structural Modeling in Marketing

624

Marketing Science 25(6), pp. 622­624, © 2006 INFORMS

policy changes relate to the marketing mix element that is viewed as the easiest to change, which leads to the rhetorical question of how critical it is for a structural model to be able to predict the effects of a change in policy/strategy well beyond the historical data. Such changes, when they occur, are most likely to influence the behavior of consumers and the competitive interaction among competitors. Hence structural models with a limited focus on modeling marketing-mix changes or testing theories of competition might be an option.
For testing theories of competition, Chintagunta et al. (2006) draw attention to the models of Shaffer and Zhang (1995), Besanko et al. (2003), and Sudhir et al. (2005). Likewise, Franses (2005a) and Van Heerde et al. (2005) make mention of the efforts of Sun et al. (2003) and Erdem et al. (2003) for capturing the effects of a marketing-mix change. These "exemplar models" (and several others not mentioned here) provide good opportunities for extension (and replication) that expand or test the boundary conditions in these models. In other words, these models could be considered as "centers" around which a "model cluster" that shares model specifications, behavioral assumptions, and perhaps even the same product categories (e.g., ketchup, photo film) could be developed. Expansion of these clusters can then occur with refinements and extensions that expand a particular model cluster. Such directed growth of related structural models could be more productive than efforts to build comprehensive structural models with more complexity (e.g., Reiss and Wolak 2004). An advantage of such an evolutionary approach would be the ability to systematically expand boundary conditions and test alternative specifications or assumptions (e.g., the mechanism for expectations formation).
References
Ailawadi, Kusum L., Donald R. Lehmann, Scott A. Neslin. 2001. Market response to a major policy change in the marketing mix: Learning from Procter & Gamble's value pricing strategy. J. Marketing 65(1) 44­61.
Besanko, David, Jean-Pierre Dube, Sachin Gupta. 2003. Competitive price discrimination strategies in a vertical channel using aggregate retail data. Management Sci. 49(9) 1121­1238.
Bronnenberg, Bart J., Peter E. Rossi, Naufel J. Vilcassim. 2005. Struc-

tural modeling and policy simulation. J. Marketing Res. 42(1) 22­26.
Chintagunta, Pradeep, Tulin Erdem, Peter Rossi, Michel Wedel. 2006. Structural modeling in marketing: Review and assessment. Marketing Sci. 25(6) 604­616.
Erdem, Tülin, Susumu Imai, Michael P. Keane. 2003. Brand and quantity choice dynamics under price uncertainty. Quant. Marketing Econom. 1(1) 5­64.
Franses, Philip Hans. 2005a. On the use of econometric models for policy simulation in marketing. J. Marketing Res. 42(1) 4­14.
Franses, Philip Hans. 2005b. Diagnostics, expectations, and endogeneity. J. Marketing Res. 42(1) 27­29.
Johnson, Eric J. 2001. Digitizing consumer research. J. Consumer Res. 28(2) 331­336.
Lohse, Gerald L., Steven Bellman, Eric J. Johnson. 2000. Consumer buying behavior on the Internet: Findings from panel data. J. Interactive Marketing 14(1) 15­29.
Moorthy, K. Sridhar. 1993. Theoretical modeling in marketing. J. Marketing 57(2) 92­106.
Reiss, Peter C., Frank A. Wolak. 2004. Structural econometric modelling: Rationales and examples from industrial organization. Handbook of Econometrics, Vol. 5. North Holland, Amsterdam, The Netherlands.
Shaffer, Greg, Z. John Zhang. 1995. Competitive coupon targeting. Marketing Sci. 14(4) 395­416.
Shugan, Steven M. 2002a. Editorial: Marketing science, models, monopoly models, and why we need them. Marketing Sci. 21(3) 223­228.
Shugan, Steven M. 2002b. In search of data: An editorial. Marketing Sci. 21(4) 369­377.
Shugan, Steven M. 2004. Endogeneity in marketing decision models. Marketing Sci. 23(1) 1­3.
Streitfeld, David. 2000. On the Web, price tags blur; what you pay could depend on who you are. Washington Post (September 27) A1.
Sudhir, K., Pradeep K. Chintagunta, Vrinda Kadiyali. 2005. Timevarying competition. Marketing Sci. 24(1) 96­109.
Sun, Baohong, Scott A. Neslin, Kannan Srinivasan. 2003. Measuring the impact of promotions on brand switching when consumers are forward looking. J. Marketing Res. 40(4) 389­405.
Swait, Joffre, Rick L. Andrews. 2003. Enriching scanner panel models with choice experiments. Marketing Sci. 22(4) 442­460.
Van Heerde, Harald J., Marnik G. Dekimpe, William P. Putsis, Jr. 2005. Marketing models and the Lucas critique. J. Marketing Res. 42(1) 15­21.
Veraart, Pamela. 2004. An overview of NPD's online panel. NPD Group Insights (accessed through www.npdinsights.com).
Winer, Russell S. 1999. Experimentation in the 21st century: The importance of external validity. J. Acad. Marketing Sci. 27(3) 349­358.
Wittink, Dick R. 2005. Econometric models for marketing decisions. J. Marketing Res. 42(1) 1­3.

