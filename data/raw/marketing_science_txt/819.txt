Vol. 26, No. 2, March­April 2007, pp. 268­280 issn 0732-2399 eissn 1526-548X 07 2602 0268

informs ®
doi 10.1287/mksc.1050.0116 © 2007 INFORMS

User Design of Customized Products
Taylor Randall
David Eccles School of Business, University of Utah, 1645 E Campus Center Drive, Salt Lake City, Utah 84112, taylor.randall@business.utah.edu
Christian Terwiesch, Karl T. Ulrich
The Wharton School, University of Pennsylvania, 500 Huntsman Hall, Philadelphia, Pennsylvania 19104 {terwiesch@wharton.upenn.edu, ulrich@wharton.upenn.edu}
User design offers tantalizing potential benefits to manufacturers and consumers, including a closer match of products to user preferences, which should result in a higher willingness to pay for goods and services. There are two fundamental approaches that can be taken to user design: parameter-based systems and needsbased systems. With parameter-based systems, users directly specify the values of design parameters of the product. With needs-based systems, users specify the relative importance of their needs, and an optimization algorithm recommends the combination of design parameters that is likely to maximize user utility. Through an experiment in the domain of consumer laptop computers, we show that for parameter-based systems, outcomes, including measures for comfort and fit, increase with the expertise of the user. We also show that for novices, the needs-based interface results in better outcomes than the parameter-based interface.
Key words: user design; product design; product development; user needs; customer needs; design decisions; customization
History: This paper was received August 5, 2003, and was with the authors 7 months for 2 revisions; processed by Gene Anderson.

1. Introduction
User design is a particular form of product customization that allows the user to specify the properties of a product. Consider three examples. At Cmax.com, athletes can design a running shoe to their specifications, selecting almost every element of the shoe from the material of the sole to the color of the shoelace. General Mills experimented with an on-line service in which consumers could design a customized breakfast cereal. Consumers can design a customized computer from Dell, using the company's website. User design has emerged as a mechanism that can be used to build brand loyalty, to fit products to the heterogeneous needs of a market, and to differentiate the offerings of a manufacturer (Dahan and Hauser 2002, Wind and Rangaswamy 2001). The use of computing and the Internet in consumer decision making makes user design and customization particularly relevant today (Winer et al. 1997).
User design is especially challenging if the user has little or no background in the underlying technical domain. For example, a particular consumer might actually prefer a specific level of computer gaming performance, e.g., at least a 50 frames-per-second refresh rate on Motocross Madness. However, is the consumer really well equipped to evaluate and optimize potentially interacting design decisions concerning the microprocessor, video processor, and display resolution to achieve this goal?

Hence, we observe a dilemma inherent to product customization. The user has the most information concerning his or her utility function but typically only has a partial understanding of the technical domain underlying the design problem. In contrast, the manufacturer typically understands the technical domain well but has only partial information about the user's preferences.
In this article, we present and evaluate a novel approach to user design, in which the user expresses needs directly and leaves to the manufacturer the translation of needs into parameter choices. We refer to this approach as the needs-based approach. The needs-based approach provides an alternative to the traditional user design approach--the parameter-based approach--in which the user directly manipulates design parameters.
Our research compares the parameter-based approach and the needs-based approach in the context of the consumer laptop business. In collaboration with Dell, we developed two user interfaces. The first one largely resembles Dell's current user design approach (parameter-based) while the second one provides an alternative, needs-based approach. We use these two systems to control and monitor a simulated purchase experience (Brucks 1988, Mandel and Johnson 2002).
The objective of this article is to demonstrate the strengths and limitations of these two approaches and to outline several opportunities for the improvement

268

Randall, Terwiesch, and Ulrich: User Design of Customized Products

Marketing Science 26(2), pp. 268­280, © 2007 INFORMS

269

of user-design interfaces. We believe that we make several unique contributions. First, we believe that this is the first paper to articulate the two approaches to user design. Second, we believe that the needsbased system that we have designed, built, and tested offers solutions to several limitations of the parameter-based approach. Third, we believe that ours is the first empirical research testing any approaches to user design.
The remainder of this article is organized as follows. In §2, we develop theory and hypotheses. In §3, we describe the design of the two user interfaces we test. In §4, we describe the experimental design. In §5 we present the results. Finally, §6 contains discussion and concluding remarks.
2. Theory and Hypotheses
For customized products, a design problem can be thought of as a search for a set of values for the product design parameters that maximizes user utility (Ulrich and Eppinger 2004). This problem can be represented by the causal network in Figure 1, in which the design parameters on the left drive product performance specifications, which in turn relate to user needs, which underlie user utility (Ramaswamy and Ulrich 1993).
Typically, a professional product designer is in charge of understanding this causal network and linking design parameters to user needs. Furthermore, the professional designer will elicit the relative importance of needs from the potential user of a product. Based on this information, the product designer, who is typically equipped with professional training and substantial experience, then searches

for values of the design parameters that are likely to maximize user utility. Finding the best (utilitymaximizing) design solution constitutes a challenging information-processing task.
With user-design systems, the professional designer is replaced by the user. However, under the parameter-based approach to user design, the same information-processing challenges persist. The user must understand the causal network relating design parameters to user needs and must understand his or her own needs. Given that the user in a consumer setting typically does not have substantial technical domain knowledge or access to analytical tools, the parameter-based approach inherently bears the risk of what we call a design defect--a choice of design parameters that does not maximize user utility. A design defect reflects a misfit between the product designed and the utility-maximizing product that might have been designed, despite the fact that the user is in control of all the design decisions.
Design defects can arise for several reasons. First, utility may depend on subjective user needs, whose potential satisfaction is hard to communicate to the consumer, especially if the user design is executed over the Internet (Degeratu et al. 1999, Lal and Sarvary 1999, Srinivasan et al. 1997, Dahan and Srinivasan 2000). Design defects can also result from holistic user needs, the case in which several design parameters interact in determining a product performance specification, thus creating a complex mapping from design parameters to user needs (Ulrich and Ellison 1999, Terwiesch and Loch 2004). For example, the ability of a laptop to deliver good video gaming performance is driven by an interaction between

Figure 1

Causal Structure Relating Design Parameters to User Utility for Laptop Computers

Design variables

Performance specifications

Processor

Price

Display Memory

Weight
Frames/ second

Package

Resolution

XGA/SXGA/UXGA Video card

HD capacity
Viewable area

Hard drive

RAM
Compute speed

User needs Portability
Display density Viewing distance
MS-office performance
Affordability
Gaming
Data storage Integrated devices

User utility

Randall, Terwiesch, and Ulrich: User Design of Customized Products

270

Marketing Science 26(2), pp. 268­280, © 2007 INFORMS

the central processor and the video processor. These interactions can create mathematical complexity from the combinatorics of the design space and from nonmonotonicity of utility (Hann and Terwiesch 2003).
An alternative approach to the design problem for customized products is to specify the relative importance of the user needs for a particular individual and then allow an automated system, with an embedded model of the causal network, to find a feasible set of design parameters to maximize the user's utility, given the relative importance of the needs. We call this the needs-based approach.
Essentially, the difference between the parameterbased approach and the needs-based approach is the "knobs" that are made available to the designer. While in the parameter-based approach the knobs are design parameters (left side of Figure 1), the knobs in the needs-based approach are actual user needs (right side of Figure 1), which are closer to the user's utility function and thereby typically require less knowledge about the underlying design space. Each approach offers some potential advantages and disadvantages.
· The parameter-based approach allows direct and predictable navigation of the design space. This approach also allows fine tuning of a design with small perturbations of design parameters, whereas the needs-based approach allows fine perturbation of the relative importance of a need, but such a perturbation in the "needs space" may require large and discontinuous changes to several design parameters by the embedded optimization system.
· The parameter-based approach requires that the designer know the technical language of the domain, whereas the needs-based approach requires only that the designer be able to express the relative importance of user needs.
· The parameter-based approach is transparent to the user, whereas the needs-based approach requires an automated optimization procedure, which is typically a "black box" to the user.
Expertise in consumer decision making in general has been established as an important element of transaction success (Sujan 1985, Bettman and Sujan 1987, Mandel and Johnson 2002, Wood and Lynch 2002). Prior research has shown that information "depth" and "interactivity" are important factors underlying satisfaction, yet the ability to absorb information is likely to depend heavily on expertise (Shankar et al. 2000). Therefore, it would not be surprising if expertise plays a critical role in user design systems. The potential strengths and weaknesses of the two approaches to user design lead us to hypothesize that neither approach will dominate for all users and that domain expertise will play a critical role in determining satisfaction and the quality of actual outcomes.

There are at least three dimensions of outcome performance for user-design systems: the optimality or fit of the resulting product with respect to the user's utility function, the comfort of the user with the design process, and the speed with which a user can design a product. We pose three hypotheses.
Hypothesis 1. For the parameter-based interface, fit, comfort, and speed increase with the expertise of the user.
Hypothesis 2. The advantage of the needs-based interface relative to the parameter-based interface decreases with the user's expertise.
Hypothesis 3. For novices, the needs-based interface results in better fit, comfort, and speed than the parameterbased interface.
Hypothesis 1 is the baseline hypothesis that novices face difficulties with parameter-based interfaces. Hypothesis 2 focuses on the relationship between expertise and the magnitude of relative advantage of the needs-based system. Note that, technically, we do not imply with Hypothesis 2 that the needsbased system is always better; we imply only that as user expertise increases, the relative advantage of the needs-based system declines. In the event that the needs-based system is worse than the parameterbased system, Hypothesis 2 implies that this disadvantage increases with the expertise of the user. Hypothesis 3 explicitly posits that for novices, the needs-based interface is better than the parameterbased interface.
3. Parameter-Based and Needs-Based Systems for Laptop Computers
A parameter-based system forms the baseline against which we test the needs-based system. The current Web-based user interface for Dell Computer's consumer laptop business is essentially a parameterbased system. The system requires the user to specify the values of design parameters such as the microprocessor type, microprocessor speed, memory size, hard drive size, and video processor type.
For experimental purposes, we designed a parameter-based system (Figure 2) similar to Dell's regular commercial site.1 In addition to the main screen, the system includes a "shopping list"--a separate Web page with a table to which the user can add product configurations for comparison. When the user finds a
1 Our experimental system differs in at least two ways from the typical Dell shopping experience. First, many Dell consumers first explore the website but then call a sales representative who helps the consumer configure his or her computer. Second, Dell offers several standard products that a consumer can select and thereby bypass the user design problem altogether.

Randall, Terwiesch, and Ulrich: User Design of Customized Products

Marketing Science 26(2), pp. 268­280, © 2007 INFORMS

271

Figure 2 The Main Screen for the Experimental Parameter-Based Interface

desirable configuration, it can be added to the shopping list and can then be "purchased." We encoded essentially Dell's entire consumer laptop computer product line with this system, so that a user could, in theory, design any consumer laptop product offered by Dell.
We also designed and built a needs-based system for the Dell consumer laptop product line. The main screen of this interface is shown in Figure 3. Using the needs-based system, the user first positions slider bars to indicate the relative importance of nine user needs, such as "My computer is light enough that I can easily carry it in my bag." This approach directly explicates the relative importance of needs. This is distinct from a conjoint approach in which users would be presented with distinct, fully articulated product alternatives and asked to express their preferences for the overall products (Green and Krieger 1991).
Once the values are set for the relative importance of the needs, the user clicks "Recommend Computer" and the system displays a laptop computer with its associated product performance specifications, including price. Exactly the same product performance specifications are displayed for a computer in both the parameter-based and needs-based systems.

To recommend a configuration, the needs-based system computes performance specifications for each configuration in the design space and then estimates the utility of each of these configurations, using a linear multiattribute utility model, with the values of the slider bars (0­99) as the weights in the utility function.
To navigate the design space, the user can either reset the slider bars and click for another recommendation, or he or she can incrementally improve or diminish the performance of the current recommendation with respect to one of the product performance specifications. For example, if the recommended configuration is too expensive, the user can simply click on "less" (price) to see one that is less expensive. This feature is implemented by finding the configuration with the next highest utility that also is an incremental improvement in the desired direction with respect to the user's input.
The incremental navigation of the "needs space" proved to be an important feature of our implementation of the needs-based approach, as it has several advantages. Iterating in this fashion allows the consumer to test the sensitivity of price with respect to performance. Given that the system restricts incremental recommendations to those computers with high scores on the utility function, it is possible to

Randall, Terwiesch, and Ulrich: User Design of Customized Products

272

Marketing Science 26(2), pp. 268­280, © 2007 INFORMS

Figure 3 The Main Screen for the Experimental Needs-Based Interface

explore the marginal impact of one need (e.g., portability), holding everything else nearly constant. Furthermore, complex design spaces exhibit local optima, leading to an overall rugged solution landscape. In such an environment, using design parameters as the knobs is likely to lead to local optimization in one area of the solution space. In contrast, our implementation of the needs-based approach allows for jumps from one local optimum to another, if so desired by the user.
4. Experimental Design
Figure 4 summarizes the design of our experiment, described in greater detail as follows. In the initial survey, we gathered data about the demographics of the subjects and their prior experience purchasing computers. We also measured the computer expertise of the subjects with a set of nine multiple-choice questions. In the second part of the experiment, we randomly assigned subjects to either the parameterbased system or the needs-based system. Subjects were asked to use the assigned interface and design a laptop computer to meet their own preferences. When the subject pressed the "buy" button, a "receipt" of the simulated purchase was printed and the subject was then asked to fill out a second survey.

The second survey collected information about the users' satisfaction, both with respect to their experiences using the interface as well as their satisfaction with the configurations they selected. Following the second survey, the subjects were directed to a simulated showroom, where they were told that they would be provided with additional information and given an opportunity to revise any of the choices they had made with the Web-based system. The role of the showroom was to measure how well the laptop configurations selected by the subjects actually fit their needs. In the showroom, we provided a display comprised of ten laptop computers. The ten laptops were chosen so that they would cover all physical dimensions of Dell laptops, all screen sizes, and all video cards and would span the range of microprocessor and memory choices. While this approach does not provide the subject with the exact postpurchase experience one would get if he or she actually purchased a computer, it has the advantage that it demonstrates to the subject the alternative choices for each design parameter.
In addition to the ten laptops we obtained from Dell, we provided the subjects with information about laptops, both verbally and graphically (supported by posters). This information covered: (a) disk

Randall, Terwiesch, and Ulrich: User Design of Customized Products

Marketing Science 26(2), pp. 268­280, © 2007 INFORMS

273

Figure 4 Process Flow Diagram for Experiment

Parameterbased system

First survey

Random assignment

Second survey

Showroom

Needsbased system

Treatment

drive characteristics, (b) processor performance, and (c) memory performance.
During their time in the showroom, subjects were shown alternative configurations (e.g., cheaper/ lower-performing configurations, more-expensive/ higher-performance configurations, lighter/heavier configurations). Subjects were given the opportunity to modify any of their previous decisions. The extent to which they engaged in change at this step was used as a measure-of-fit between the initial customized design and the subjects' actual needs.
Subjects Subjects for the experiment were recruited from the students and staff of a large research university. The characteristics of the sample are provided in Table 1 (Panel A). The experiment took about 1 hour on average, and subjects were given $10 for their time.
Measures In the following paragraphs we describe the dependent and independent variables used in the experiment. Throughout the discussion, we refer to descriptive statistics of each variable found in Table 1 (Panel B).
Dependent Variables. Perceived Fit Perceived fit is an aggregate construct based on the average response to these three statements: (1) From the computers available on the system, I believe I found the one that would be best for me. (2) If I were to buy a Dell computer in the near future, I would purchase essentially the one I selected. (3) I'm satisfied that the computer I selected would meet my needs. Question 3 and the 9-point scale were adapted from Häubl and Trifts (2000). The Cronbach alpha score for the combined measure is 0.83, which exceeds acceptable limits on construct validity (Nunnally and Bertstein 1994).

Perceived Comfort Perceived comfort is an aggregate construct based on the average response of a subject to these five statements: (1) I felt it was easy to explore the alternatives that were available to me. (2) I felt that I was able to easily find a computer that would meet my needs. (3) I wish an independent

Table 1 Descriptive Statistics

Panel A: Subject descriptive statistics

Total Subjects Subjects not responding to fit and comfort questions Total subjects for analysis with fit and comfort outcomes Subjects with model changes Total subjects for changes outcomes
Percent female Median age Median household income Percent married Percent with children Median number of times purchased a laptop Median number of times purchased a desktop Percent that previously purchased computers via the Internet

164 3
161 31
130
36.7% 24
$25,000 46.4% 16.4%
1 0 18.9%

Panel B: Study variable descriptive statistics

Percentiles

Mean Std. dev. 10th 50th 90th

Dependent variables

Perceived Fit

7.29 1.29 5.67 7.33 9.00

Perceived Comfort

6.52 1.42 4.60 6.80 8.20

Time Spent

293 157 130 262 480

Absolute Value of Price Change 233 262

0 170 575

Sum of Absolute Value of

214 250

0 129.5 524

Price Changes

Number of Changesa

2.01 1.71

0

2

5

Perceived Bias

4.40 2.24

1

5

7

Independent variables Answers Correct Answers Attempted Weighted Answers Correct

2.70 1.97

0

3

6

5.66 2.42

2

6

9

4.14 2.02 1.43 3.86 7.04

a Due to exclusion of observations with model changes, statistics for number of changes are for a subsample of 130 subjects.

Randall, Terwiesch, and Ulrich: User Design of Customized Products

274

Marketing Science 26(2), pp. 268­280, © 2007 INFORMS

Table 2 Pearson Correlation Coefficients

Variables

Perceived Perceived Absolute value of Sum of absolute value

fit

comfort price change

of price change

Time spent

Number of Number Number Weighted changes correct attempted correct

Perceived Fit Perceived Comfort Absolute Value of
Price Change Sum of Absolute Value
of Price Change Time Spent Number of Changes Number Correct Number Attempted Weighted Correct

1 0 54 -0 07
-0 02
-0 12 -0 03
0 03 0 06 0 04

1 -0 10
-0 14
-0 21 -0 07
0 23 0 23 0 25

1
0 88
0 13 0 59 -0 20 -0 12 -0 19

1
0 14 0 65 -0 22 -0 17 -0 21

1

0 13

1

-0 21 -0 08

1

-0 22 -0 01

0 72

1

-0 19 -0 07

0 91

0 91

1

, , and  indicate values significant at p < 0 01, 0.05, and 0.10 levels, respectively. For Number of Changes, n = 161 and n = 130.

person could have helped me select the right computer (reverse coded). (4) I felt confused during the selection process (reverse coded). (5) I felt comfortable with the process of selecting a computer. The Cronbach alpha score for the construct is 0.72, which exceeds acceptable limits for construct validity.
Absolute Value of Price Change This variable is measured as the absolute value of the net price changes a subject made while in the showroom. For example, a change from an Inspiron 600m to a Latitude 200 increases the base price of the computer by $250.
Sum of Absolute Value of Price Changes The previous measure of price change only accounts for the net effect of price changes. It does not account for the total dollar value of changes made by participants. For example, a subject might increase RAM by 256 MB at a cost of $150 but decrease the hard drive capacity by 30 GB at a gain of $199. The previous measure would measure this as a $49 change in the absolute value of price. The Sum of the Absolute Value of Price Changes in this example would be $349.
Time Spent The elapsed time used to select a computer configuration from the website.
Number of Changes The number of changes is the raw quantity of changes a subject made to their chosen computer configuration when in the showroom. A value of zero implies the best fit. In our analysis of number of changes, we exclude the subjects who make a model change because a model change almost always requires a change to many other attributes of the computer. For example, a subject that changes from the Latitude 200 to the Inspiron 8500 is forced to change screen size, screen resolution, processor, and video processor, whether or not these other changes are desired, because the same values of these parameters are not available on the Inspiron 8500.
Independent Variables. Treatment Subjects were randomly assigned to the parameter-based system or the needs-based system. In the analysis that follows, the assigned system is

coded as an indicator variable with Treatment = 1 for the needs-based system and Treatment = 0 for the parameter-based system. We observe no statistically significant differences between groups in terms of expertise, age, gender, income and education.
Expertise Number Correct, Weighted Correct, Number Attempted When measuring expertise, it is important to distinguish between objective and subjective expertise (Brucks 1988). Whereas objective expertise relates to actual knowledge, subjective expertise measures to what extent subjects perceive themselves to be knowledgeable.
We use two variables to measure objective expertise. First, we use the number of correct answers to a nine-question multiple-choice test consisting of specific questions in the domain of laptop computers (Number Correct). This approach is adapted from the instruments reported by Sujan (1985) and Bettman and Sujan (1987). Secondly, we use a variant on the number-correct measure that gives partial credit for "close" answers (Weighted Correct). For example, one question asks for the thickness dimension of the thinnest laptop computers. The correct answer was "less than 1 inch." However, the response "1 inch to 1.25 inch" is more correct than the response "1.5 to 2 inches." The measure Weighted Correct provides partial credit for wrong answers and thus reduces some of the random variability in the expertise measure.
We also measure subjective expertise. For each question a respondent could answer "I don't know." We use the Number Attempted, defined as nine less the number of "I don't know" responses, as a measure of subjective expertise.

5. Results
To test Hypotheses 1 and 2, we estimate the following model,

Y = + 1 × Treatment + 2 × Expertise

+ 3 × Treatment × Expertise + Controls +

(1)

Randall, Terwiesch, and Ulrich: User Design of Customized Products

Marketing Science 26(2), pp. 268­280, © 2007 INFORMS

275

where Y is one of the dependent variables described in the previous section and age and gender are control variables. The equation is estimated using ordinary least squares for the dependent variables Perceived Fit, Perceived Comfort, Absolute Value of Price Change, Sum of Absolute Value of Price Change, and Time Spent.2 For the Number of Changes outcome measure, we estimate the equation using Poisson regression, which is suggested by Greene (1997) when the data represent counts of events.3 We mean center the expertise measure in our analysis.
This formulation provides two equations to interpret results based on the two different treatments. For subjects using the parameter-based interface (Treatment = 0), the relevant model is:

Y = + 2 × Expertise + Controls +

(2)

For subjects using the needs-based interface (Treatment = 1), the relevant model is:

Y = + 1 + 2 + 3 × Expertise

+ Controls +

(3)

Under our hypotheses, the above equations can be represented with a graph as shown in Figure 5.
Assuming a more-is-better dependent variable such as Perceived Fit and Perceived Comfort, 2 must be significant and positive for Hypothesis 1 to hold. This would indicate that as a subject's expertise increases, the quality of outcome using a parameter-based interface increases. For Hypothesis 2 to hold, we expect
3 to be significant and negative. This would indicate that the relative advantage of the needs-based interface decreases with the user's expertise ( 2 > 2 + 3 . Note that Hypothesis 2 does not strictly posit that the outcome for the needs-based interface decreases with expertise ( 2 + 3 < 0), although it is shown this way in Figure 5, only that the relative advantage of the needs-based interface decreases with expertise. For a less-is-better dependent variable, such as Time Spent, Absolute Value of Price Change, Sum of Absolute Value of Price Changes, or Number of Changes, the signs in the preceding argument would be reversed.

2 The variables Absolute Value of Price Change and Sum of Absolute Value of Price Change are truncated at zero. However, the truncation at zero does not imply the use of truncated regression techniques such as Tobit (Maddala 1991). Instead, we use the OLS estimator. The errors from this regression are not normal and, hence, the estimates are not the best unbiased estimator; however, these estimates are the best linear unbiased estimator (Gujarati 1995). The net result is that the coefficients are unbiased, but our test statistics are less efficient.
3 We also estimated the Number of Changes equation using NBD regression. Results do not differ from the results reported using Poisson regression.

Figure 5 Outcome

Graphical Representation of Equations 2 and 3

 + 1 

2 + 3

Needs-based interface (Treatment = 1)

Parameter-based

2

interface (Treatment = 0)

Novice

Expert

Expertise

Panels A, B, and C of Table 3 report results of the regression analysis for our three different expertise measures. To facilitate the discussion of these results, we show plots in Figure 6 of the outcomes as a function of expertise using the coefficient estimates from the regression models in Panel C only.
Consistent with Hypothesis 1, we report positive and significant coefficients for 2 across all measures of expertise in models for Perceived Comfort and a negative and significant coefficient for the Absolute Value of Price Change, Sum of Absolute Value of Price Changes, Time Spent, and the Number of Changes. We do not report a significant positive coefficient for 2 in the Perceived Fit model.
Consistent with Hypothesis 2, across all panels we report negative and significant coefficients for 3 in models for Perceived Comfort and positive and significant coefficients for Time Spent. Results for other outcome measures vary according to the measure of expertise used in the analysis. Consistent with Hypothesis 2, we report positive and significant coefficients for 3 in the models for Absolute Value of Price Change and Sum of Absolute Value of Price Changes in Panel B and Panel C but not in Panel A. Consistent with Hypothesis 2, we report negative and significant coefficients for Perceived Fit in Panel A but not in Panels B and C. We do not find a significant coefficient for 3 in the model for the Number of Changes.
Figure 6 graphically illustrates the results for Hypotheses 1 and 2 based on the values for coefficients reported in Panel C. We see that for Perceived Fit, Perceived Comfort, Absolute Value of Price Change, Time Spent, and Number of Changes, the relationship between outcome and expertise is consistent with our hypotheses. That is, we observe that fit, comfort, and time for the parameter-based interface improve with expertise and that compared to the parameter-based interface, the relative advantage of the needs-based interface decreases with the user's expertise.
We formally test Hypothesis 3 using multivariate analysis of variance that tests for mean differences between novices and experts while controlling for a subject's age and gender. For this test we dichotomize

Randall, Terwiesch, and Ulrich: User Design of Customized Products

276

Marketing Science 26(2), pp. 268­280, © 2007 INFORMS

Table 3 The Relation Between Outcomes, Expertise, and Design Interface

Dependent variable

Perceived fit

Perceived comfort

Absolute value of price change

Sum of absolute value of price change

Time spent

Number of changes

Panel A: Expertise = Number of Answers Correct

Intercept

6 91

0 48

Treatment (Needs = 1)

0 20

0 35

Expertise

0 07

0 07

Expertise × Needs Interface

-0 19

0 11

Age

0 01

0 02

Male

0 09

0 23

Significance statistic1

1 13

Adjusted R-squared

0 00

N

162

Statistical method used

OLS

6 67 0 50
0 19 0 21 0 25 0 07 -0 26 0 11
-0 01 0 02
0 12 0 25
3 10 0 06 161 OLS

472 28 93 25 -147 19 69 98 -35 37 13 43
29 26 21 21
-3 51 3 22
-28 97 45 45
2 77 0 05 163 OLS

489 42 93 40 -155 31 72 52 -39 69 14 82
29 70 21 99
-5 02 3 14
-1 57 47 85
3 02 0 07 134 OLS

355 22 54 01
4 45 24 12 -24 21
8 02 29 65 12 67
-1 55 1 92
-36 29 27 27
3 11 0 06 162 OLS

0 94 0 37
-0 15 0 15
-0 09 0 05
0 06 0 08
-0 02 0 01
-0 06 0 17
128 34 -- 130
Poisson

Panel B: Expertise = Number of Attempted Answers

Intercept

7 17

0 46

Treatment (Needs = 1)

-0 30

0 20

Expertise

0 08

0 06

Expertise × Needs Interface

-0 10

0 09

Age

0 01

0 02

Male

0 04

0 22

Significance statistic Adjusted R-squared N Statistical method used

0 93 -0 002
162 OLS

6 66 0 49
0 16 0 22 0 25 0 06 -0 27 0 09
-0 01 0 02
0 18 0 24
3 75 0 08 161 OLS

389 07 89 60
-61 87 40 05
-29 90 11 76 45 46 16 56
-3 59 3 20
-56 44 44 44
3 10 0 06 163 OLS

398 92 91 04
-67 18 41 97
-32 49 12 40 37 86 17 07 -5 32 3 13
-27 64 46 18
3 01 0 07 134 OLS

352 70 53 82
8 85 24 03 -22 82
7 04 23 78 9 91
-1 60 1 92
-37 78 26 73
3 30 0 07 162 OLS

1 00 0 37
-0 12 0 15
-0 09 0 04
0 10 0 06
-0 02 0 01
-0 12 0 16
128 92 -- 130
Poisson

Panel C: Expertise = Weighted Answers Correct

Intercept

7 20

0 47

Treatment (Needs = 1)

-0 27

0 20

Expertise

0 09

0 07

Expertise × Needs Interface

-0 18

0 10

Age

0 01

0 02

Male

0 07

0 23

Significance statistic Adjusted R-squared N Statistical method used

1 10 0 003 161 OLS

6 75 0 50
0 18 0 22 0 27 0 07 -0 26 0 11
-0 01 0 02
0 11 0 24
3 57 0 07 160 OLS

323 91 93 96 -77 84 43 29 -59 91
3 87 58 95 21 73
-2 93 3 27
-7 35 49 19
4 52 0 12 162 OLS

378 62 91 82
-67 42 42 31
-45 29 15 12 45 73 21 23
-4 99 3 19
-5 77 48 07
3 36 0 08 133 OLS

356 66 54 20
10 04 24 22 -22 76
8 22 26 34 12 13
-1 76 1 94
-35 64 27 39
2 76 0 05 161 OLS

0 95 0 37
-0 12 0 15
-0 11 0 05
0 11 0 08
-0 02 0 01
-0 08 0 17
128 57 -- 129
Poisson

Notes. Standard errors are in parentheses. p < 0 10 one tailed tests, p < 0 05 one-tailed tests, p < 0 01. 1The model significance statistic is the F statistic from ordinary least squares models for the perceived fit, perceived comfort, and time spent models.
The model significance statistic is the Pearson chi-square statistic from a Poisson regression for the number of changes model. Note that with the Pearson chi-square test, we compare the estimated model with a fully saturated model and, hence, expect no significance in the statistic.

Randall, Terwiesch, and Ulrich: User Design of Customized Products Marketing Science 26(2), pp. 268­280, © 2007 INFORMS

Figure 6

Perceived Comfort

Graphical Representation of Estimated Models for Needs-Based and Parameter-Based Interfaces

9

9

Perceived Fit

8

Parameter-based

8

8

7

7

Needs-based

7

6

Parameter-based Needs-based

Abs Value of Price Change

6 Expertise

600

500

400

Parameter-based

300

200

100

Needs-based

0 Expertise

Sum Abs Value of Changes

5 Expertise
500

400

300

Parameter-based

200 Needs-based
100

0 Expertise

Time Spent

400 Parameter-based
350
300 250 Needs-based 200
150 100
Expertise

Number of Changes

1.0
0.8 Parameter-based
0.6
0.4
0.2 Needs-based
0.0 Expertise

277

the expertise variable at the median score for expertise. Subjects answering three or fewer questions correctly are categorized as novice.4 We then compare outcomes for novice subjects using the parameterbased system and novice subjects using the needsbased system. The results are shown in Table 4.
In support of Hypothesis 3, we report that the Perceived Comfort level is higher while the Absolute Value of Price Change and Sum of Absolute Value of Price Change are lower in the needs interface for novice users across all three panels. We report fewer changes made by novices in Panel C. We report no significant difference in Perceived Fit or Time Spent.
Table 5 summarizes the results of our hypothesis tests for each of the dependent variables.
6. Discussion
The experimental results provide substantial support for our hypotheses. Novices are less comfortable with
4 We also use a mean cutoff to classify subjects as novice. Results of these tests are qualitatively the same as those reported in Table 4.

parameter-based systems and achieve better fit in less time with needs-based systems. In this section, we discuss some limitations of our study, along with several issues related to application of needs-based systems in industrial practice.
Limitations of the Study Our sample is not fully representative of the overall consumer population, as college-educated consumers, especially business students, are overrepresented. Therefore, inferences about all consumers may not be valid. However, we conjecture that most consumers are, in fact, likely to be less well suited to parameterbased approaches than college students of business.
Our study focuses on a single product domain, laptop computers. We would expect similar results for other technology-based goods. For simple domains, say, the design of a sandwich or a pizza, or for domains in which even more modular architectures are prominent, we expect that parameter-based systems exhibit fewer disadvantages relative to needsbased systems (Ulrich 1995).

Randall, Terwiesch, and Ulrich: User Design of Customized Products

278

Marketing Science 26(2), pp. 268­280, © 2007 INFORMS

Table 4 Differences in Outcomes for Novice Users

Variables

Needs Parameter-based Hotelling's

interface

interface

T-square P -value

Panel A: Expertise = Number of Answers Correct n = 84

Perceived Fit Perceived Comfort Time Spent Absolute Value of
Price Change Sum of Absolute Value
of Price Change Number of Changes

7 23 6 60 296 93 176 15
163 91
1 78

7 37 5 95 340 01 342 37
327 38
2 34

0 33

0 57

4 45

0 03

1 12

0 27

7 05

0 01

5 59

0 02

2 57

0 11

Panel B: Expertise = Number of Answers Attempted n = 94

Perceived Fit Perceived Comfort Time Spent Absolute Value of
Price Change Sum of Absolute Value
of Price Change Number of Changes

7 21 6 63 302 25 183 76
172 74
1 85

7 37 6 02 344 23 314 96
310 17
2 23

0 53

0 47

4 34

0 04

1 28

0 26

5 00

0 03

4 99

0 03

1 33

0 25

Panel C: Expertise = Weighted Answers Correct n = 93

Perceived Fit Perceived Comfort Time Spent Absolute Value of
Price Change Sum of Absolute Value
of Price Change Number of Changes

7 14 6 73 340 07 185 24
164 68
1 67

7 37 5 95 288 08 342 39
327 39
2 35

0 78

0 38

6 26

0 01

1 55

0 21

5 84

0 02

5 34

0 02

3 69

0 06

Several additional domains seem especially promising for needs-based approaches, including retirement planning, medical plan choice, and product selection in categories with hundreds of products, such as automobiles and cameras. Another avenue of research that appears promising is to study how the alternatives presented to consumers shape the user design process (Huber et al. 1982).
Hybrid Systems In testing our hypotheses, we chose to create a clear distinction between the parameter-based system and the needs-based system. A simple hybrid system could offer the user the choice of a parameter-based interface or a needs-based interface. A more sophisticated

hybrid system could allow the same interface to work in both ways. That is, either parameters or needs could be directly manipulated. One such system would be equivalent to the needs-based system we developed, with the additional feature that any parameter (e.g., amount of memory) could be directly manipulated with the resulting impact on the customer needs shown immediately (Ramaswamy and Ulrich 1997).
Conclusion
User design offers tantalizing potential benefits to manufacturers and consumers, including a closer match of products to user preferences, which should result in a higher willingness to pay for goods and services. However, the user design experience can suffer from a mismatch between preferences and the resulting product. Design defects can result from overwhelming confusion for novice users and daunting design complexity.
There are two fundamental approaches that can be taken to user design: parameter-based systems and needs-based systems. In parameter-based systems, users directly specify the values of design parameters of the product. In needs-based systems, users specify the relative importance of their needs, and an optimization algorithm recommends the combination of design parameters that is likely to maximize the user's utility.
Through an experiment in the domain of consumer laptop computers, we show that for parameter-based systems, comfort and fit increase with the expertise of the user. We also show that for novices, the needsbased interface results in better fit, comfort, and speed than the parameter-based interface.
Acknowledgments The authors acknowledge the substantial contributions of Rachel Nation, Gabe Silvasi, Johnny Lee, Martha Eining, Chetan Salian, Noah Springer, Ryan Sundquist, and Matthias Kellmer. The authors also thank Dell Computer. The comments of three anonymous reviewers are greatly appreciated.
Appendix. Tobit Analysis Table A1 shows the results of Tobit regression models for the price change variables. There are no qualitative differences between these results and the OLS results reported

Table 5 Summary of Results of Hypothesis Tests
Perceived fit
H1: Fit, comfort, and time improve with expertise for parameter-based interface
H2: Relative advantage of needs-based interface decreases with expertise
H3: For novices, fit, comfort, and time are better with needs-based interface

Perceived comfort

Time spent

Absolute value of price change

Sum of absolute value of price change

Number of changes

Randall, Terwiesch, and Ulrich: User Design of Customized Products

Marketing Science 26(2), pp. 268­280, © 2007 INFORMS

279

Table A1 Tobit Analysis of Price Change Variables

Expertise measures

Number of Answers Correct

Number of Answers Attempted

Weighted Answers Correct

Dependent variable

Absolute Value of Sum of Absolute Value Absolute Value of Sum of Absolute Value Absolute Value of Sum of Absolute Value

Price Change

of Price Change

Price Change

of Price Change

Price Change

of Price Change

Intercept
Treatment (Needs = 1)
Expertise
Expertise × Needs Interface
Age
Male
Likelihood ratio test N

387 88 111 18
-60 23 49 82
-44 17 16 76 28 91 26 35
-5 86 4 05
-28 85 55 98
13 38 163

413 28 123 69
-68 34 55 91
-52 77 20 19 36 15 29 57
-8 59 4 37
-8 91 63 57
14 73 134

399 87 110 61
-50 96 49 53
-37 69 14 53 55 59 20 35
-5 74 4 03
-66 82 54 82
14 68 163

431 84 123 13
-56 87 56 02
-43 25 16 53 49 54 22 64
-8 80 4 36
-45 51 62 14
14 88 134

381 90 111 29
-49 84 49 81
-50 80 17 02 50 82 24 98
-5 82 4 08
-33 09 56 08
28 52 162

404 23 124 04
-57 28 56 08
-60 53 20 38 57 99 28 28
-8 39 4 39
-15 38 63 34
29 94 133

Note. Standard errors are in parentheses. p < 0 05 one-tailed tests. p < 0 01.

in the body of this paper. Opinions differ on the applicability of Tobit in situations similar to ours. We share the positions of Sigelman and Zheng (1999) and Maddala (1991) that Tobit is not the right specification in the absence of explicit censoring; however, we believe that the results of the Tobit analysis reported in Table A1 are an indication of the robustness of our basic results.
We offer these comments on Tobit for the interested reader. Maddala distinguishes between two types of censoring. First, there are situations in which the dependent variable can take on negative values in theory but for which such values are actually observed as zeroes. Such cases qualify as true censoring for which Tobit is appropriate. However, in a second situation, the dependent variable cannot, even in theory, take on negative variables, as is the case for automobile expenditures, hours worked, or wages. This second situation holds for our various change measures. In such situations, Maddala (1992, p. 341) states that Tobit models are inappropriate. Specifically, he states:
"Every time we have some zero observations in the sample, it is tempting to use the Tobit model. However, it is important to understand what the model really says. What we have [with Tobit] is a situation where [the dependent variable] can, in principle, take on negative values. However, we do not observe them because of censoring. Thus zero values are due to non-observability. This is not the case with automobile expenditures, hours worked or wages. These variables cannot, in principle, assume negative values."
Sigelman and Zheng (1999) state that "if no censoring has occurred or if censoring has occurred but not at zero, then the standard Tobit specification is inappropriate."
Researchers have suggested remedies to several situations where Tobit models were used incorrectly with data

limited at zero. See, as examples, Cragg (1971) and Nelson and Olson (1978). However, these situations do not apply specifically to our situation. Based on these arguments, we believe OLS is our best reasonable alternative. The OLS estimates are still BLUE, but not BUE (Gujarati 1995).
References
Bettman, J., M. Sujan. 1987. Effects of framing on evaluation of comparable and noncomparable alternatives by expert and novice consumers. J. Consumer Res. 15 141­153.
Brucks, M. 1988. Search monitor: An approach for computercontrolled experiments involving consumer information search. J. Consumer Res. 15(1) 117­121.
Cragg, J. 1971. Some statistical models for limited dependent variables with application to the demand for durable goods. Econometrica 39 829­844.
Dahan, E., J. R. Hauser. 2002. The virtual customer. J. Product Innovation Management 19(5) 332­353.
Dahan, E., V. S. Srinivasan. 2000. The predictive power of Internetbased product concept testing using visual depiction and animation. J. Product Innovation Management 17(March) 99­109.
Degeratu, A., A. Rangaswamy, J. Wu. 2001. Consumer choice behavior in online and traditional supermarkets: The effects of brand name, price, and other search attributes. Internat. J. Res. Marketing 17(1) 55­78.
Green, P. E., A. M. Krieger. 1991. Conjoint analysis: Methods and applications. M. J. Houston, ed. Handbook of Marketing Research. McGraw-Hill, New York.
Green, W. H. 1997. Econometrics Analysis. Macmillan, New York. Gujarati, D. 1995. Basic Econometrics. McGraw-Hill, New York. Hann, I-H., C. Terwiesch. 2003. Measuring the frictional costs of
online transactions: The case of a name-your-own-price channel. Management Sci. 49(11) 1563­1569. Häubl, G., V. Trifts. 2000. Consumer decision making in online shopping environments: The effects of interactive decision aids. Marketing Sci. 19(1) 4­21.

Randall, Terwiesch, and Ulrich: User Design of Customized Products

280

Marketing Science 26(2), pp. 268­280, © 2007 INFORMS

Huber, J., J. W. Payne, C. Puto. 1982. Adding asymmetrically dominated alternatives: Violations of regularity and the similarity hypothesis. J. Consumer Res. 9(1) 90­98.
Lal, R., M. Sarvary. 1999. When and how is the Internet likely to decrease price competition? Marketing Sci. 18(4) 485­503.
Leigh, T. W., D. B. McKay, J. O. Summers. 1984. Reliability and validity of conjoint analysis and self-explicated weights: A comparison. J. Marketing Res. 21 456­462.
Maddala, G. 1991. A perspective on the use of limited-dependent and qualitative variables models in accounting research. Accounting Rev. 66(4) 788­807.
Maddala, G. 1992. Introduction to Econometrics, 2nd ed. Macmillan, New York.
Mandel, N., E. J. Johnson. 2002. When Web pages influence choice: Effects of visual primes on experts and novices. J. Consumer Res. 29 235­245.
Nelson, F., L. Olson. 1978. Specification and estimation of a simultaneous-equation model with limited dependent variables. Internat. Econom. Rev. 19(3) 695­709.
Nunnally, J. C., I. H. Bernstein. 1994. Psychometric Theory. McGrawHill, New York.
Pullman, M., K. J. Dodson, W. L. Moore. 1999. A comparison of conjoint methods when there are many attributes. Marketing Lett. 10(2) 123­138.
Ramaswamy, R., K. Ulrich. 1993. Augmenting the house of quality with engineering models. Res. Engrg. Design 5(2) 70­79.
Ramaswamy, R., K. Ulrich. 1997. A designer's spreadsheet. ASME J. Mech. Design 119(1) 48­56.
Shankar, V., A. K. Smith, A. Rangaswamy. 2000. Customer satisfac-

tion and loyalty in online and offline environments. Working paper, Smeal College of Business, Pennsylvania State University, University Park, PA.
Sigelman, L., L. Zheng. 1999. Analyzing censored and sampleselected data with Tobit and Heckit models. Political Anal. 8(2) 167­182.
Srinivasan, V., W. S. Lovejoy, D. Beach. 1997. Integrated product design for marketability and manufacturing. J. Marketing Res. 34 154­163.
Sujan, M. 1985. Consumer knowledge: Effects on evaluation strategies mediating consumer judgements. J. Consumer Res. 12 31­46.
Terwiesch, C., C. H. Loch. 2004. Collaborative prototyping and the pricing of custom designed products. Management Sci. 50(2) 145­158.
Ulrich, K. 1995. The role of product architecture in the manufacturing firm. Res. Policy 24 419­440.
Ulrich, K., D. Ellison. 1999. Holistic customer requirements and the design-select decision. Management Sci. 45(5) 641­658.
Ulrich, K., S. Eppinger. 2004. Product Design and Development, 3rd ed. McGraw-Hill, New York.
Wind, J., A. Rangaswamy. 2001. Customerization: The next revolution in mass customization. J. Interactive Marketing 15(1) 13­32.
Winer, R. S., J. Deighton, S. Gupta, E. J. Johnson, B. Mellers, V. G. Morwitz, T. O'Guinn, A. Rangaswamy, A. G. Sawyer. 1997. Choice in computer-mediated environments. Marketing Lett. 8(3) 287­296.
Wood, S., J. Lynch. 2002. Prior knowledge and complacency in new product learning. J. Consumer Res. 29 416­426.

