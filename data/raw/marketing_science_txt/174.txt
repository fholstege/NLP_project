http://pubsonline.informs.org/journal/mksc/

MARKETING SCIENCE
Vol. 37, No. 1, January­February 2018, pp. 153­171 ISSN 0732-2399 (print), ISSN 1526-548X (online)

A Flexible Method for Protecting Marketing Data: An Application to Point-of-Sale Data

Matthew J. Schneider,a Sharan Jagpal,b Sachin Gupta,c Shaobo Li,d Yan Yue
a LeBow College of Business, Drexel University, Philadelphia, Pennsylvania 19104; b Rutgers Business School, Rutgers University, Newark, New Jersey 07102; c S.C. Johnson Graduate School of Management, Cornell University, Ithaca, New York 14853; d School of Business, University of Kansas, Lawrence, Kansas 66045; e Lindner College of Business, University of Cincinnati, Cincinnati, Ohio 45221
Contact: matt.schneider@drexel.edu, http://orcid.org/0000-0001-5667-4707 (MJS); jagpal@rutgers.edu (SJ); sg248@cornell.edu (SG); shaobo.li@ku.edu (SL); yuyu@ucmail.uc.edu (YY)

Received: December 31, 2013 Revised: September 7, 2015; April 1, 2016; September 6, 2016; January 11, 2017; April 4, 2017; June 20, 2017 Accepted: June 28, 2017 Published Online in Articles in Advance: January 8, 2018
https://doi.org/10.1287/mksc.2017.1064
Copyright: © 2018 INFORMS

Abstract. We develop a flexible methodology to protect marketing data in the context of a business ecosystem in which data providers seek to meet the information needs of data users, but wish to deter invalid use of the data by potential intruders. In this context we propose a Bayesian probability model that produces protected synthetic data. A key feature of our proposed method is that the data provider can balance the trade-off between information loss resulting from data protection and risk of disclosure to intruders. We apply our methodology to the problem facing a vendor of retail point-of-sale data whose customers use the data to estimate price elasticities and promotion effects. At the same time, the data provider wishes to protect the identities of sample stores from possible intrusion. We define metrics to measure the average and maximum loss of protection implied by a data protection method. We show that, by enabling the data provider to choose the degree of protection to infuse into the synthetic data, our method performs well relative to seven benchmark data protection methods, including the extant approach of aggregating data across stores.

History: Yuxin Chen served as the senior editor and Harald van Heerde served as associate editor for this article.
Supplemental Material: Data are available at https://doi.org/10.1287/mksc.2017.1064.

Keywords: data protection · privacy · statistical disclosure limitation · marketing mix models · point-of-sale data

1. Introduction
Businesses routinely share marketing data with their employees, suppliers, customers, and regulators as well as the general public. Widely known examples include data on customer purchasing histories, media viewership, and web browsing behaviors gathered by market research companies and sold to their clients; product sales ranks released by Amazon to its vendors and to the general public; movie viewing histories of Netflix subscribers released to the general public in a contest to design a better movie recommendation engine; and the channel partnership between Walmart and Procter & Gamble based on information sharing in the supply chain (Grean and Shaw 2002). In all these cases the data provider stands to benefit by sharing the data, but also seeks to actively protect certain aspects of the data from disclosure. This paper proposes a framework and statistical approach to help firms (vendors) share marketing data while limiting the risk of disclosure. In particular, we address a Marketing Science Institute (2016) research priority and show how firms can trade off privacy concerns against the commercial value of their data.
To motivate the importance of data protection and to provide context, we begin with a classic example

of widely used market research data. AC Nielsen, the largest marketing research company in the world, sells point-of-sale scanner data to manufacturers and retailers of consumer packaged goods. The data are obtained from a sample of retail stores to whom AC Nielsen provides a contractual assurance that their identities will not be revealed to data users. There are at least two important reasons for AC Nielsen to protect the identities of sample stores and their sales volumes. The first reason is to prevent tampering with market research results (e.g., by artificially inflating or deflating sales in sample stores to skew volumes).1 The second reason is to prevent data users from taking strategic actions based on the identities of stores, such as locating a new competing store close to a highperforming retail store in the sample.
AC Nielsen currently protects the identities of sample stores primarily through data aggregation. In particular, most AC Nielsen clients are not provided with store-level data, but only with data aggregated to a higher level, such as market-level data. Market-level sales data are linearly aggregated (i.e., summed) sales; in addition, volume-weighted average prices and promotions are provided across stores in the market.

153

154

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

Bucklin and Gupta (1999, p. 261) analyzed data from a survey of academics and practitioners and concluded that "While Nielsen and IRI have store- and accountlevel data, third-party consultants such as MMA usually conduct their analysis on the market-level data to which they are given access." This aggregation process has a dual effect. On one hand, it raises the cost of identifying sample stores sufficiently so that the data protection goal of AC Nielsen is accomplished; on the other hand, it significantly reduces the commercial value of the data for users.
The goal of manufacturers and retailers who buy AC Nielsen data is to optimize marketing decisions by using estimates of important metrics such as price elasticities and promotion lift factors, derived from a sales response or marketing-mix model. Estimates of price elasticities and promotion effects based on the aggregated data are subject to aggregation bias, which can be very large in magnitude (Christen et al. 1997). For instance, aggregation to the market-level typically leads to an overstatement of the effects of promotional variables such as in-store displays and retailer feature advertising (Christen et al. 1997). Approaches to ameliorate aggregation bias in the price elasticities and promotion effects have been suggested (e.g., Link 1995, Tenn 2006) but the bias is difficult to eliminate. This trade-off between data protection and commercial value lies at the heart of the problem that we study in this paper.
We use the AC Nielsen prototypical example to illustrate key elements of business situations in which the need for protecting marketing data arises. In these situations, a "data provider" (for example, AC Nielsen) obtains data from "data subjects" (retail stores) and provides these data to "data users" (consumer packaged goods manufacturers and retailers), but does not disclose certain aspects that we term "confidential data" (store identities). The goal of data users is to benefit from the data (for example, by estimating price elasticities and promotional effects for business decisions). Typically, these benefits are derived from the use of the data in a "data user's model" (a sales response or marketing-mix model). As noted earlier, the data user may derive additional benefit from learning the confidential data; we term such use "invalid use" (learning store identities and linking them to sales).
Often the attempt to make invalid use of the data is performed by "data intruders" who may be third parties who have access to the data. In this paper we do not distinguish between invalid use by data users or by data intruders. The task facing the data provider is to use "data protection" methods that will permit valid use but deter or make difficult invalid use of the data by users or intruders. A primary goal of our paper is to propose a data protection method that allows the data

provider to choose a preferred data protection strategy after explicitly evaluating the trade-off between commercial value and data protection.
In Figure 1, we use the AC Nielsen example to conceptualize a Marketing Data Privacy Ecosystem that identifies relationships among key players, their business goals, and the data protection imperatives that follow. An important aspect to emphasize is that data providers may be motivated to protect data not simply because of legal or contractual obligations to data subjects, but also because preserving privacy may be a key pillar of the data provider's brand positioning. When this is the case, the cost of invalid use may be very high because it damages trust in the data provider's brand.
Data protection situations that fit this ecosystem are common in marketing research; consequently, the choice of data protection method can have a major effect on decision-making by the data user. For instance, AC Nielsen and IRI collect data from household panels and provide them to their clients. IMS Health collects data on prescriber behavior from physician panels and provides it to pharmaceutical firms. It also collects prescription sales information from retail pharmacies to sell to clients. Another broad context in which data protection needs arise is when firms supply information to buyers of their products or services to help them evaluate the product or service. For instance, Google provides data to advertisers on the click-through behavior of search-engine users in response to sponsored search advertising. Google chooses to not provide impression-level data to its clients, but instead aggregates the data to the daily level to increase privacy. As in our AC Nielsen example, this leads to potential aggregation bias in the estimated effects of advertising, making it more difficult for advertisers to optimize their advertising spending (Abhishek et al. 2015).
Firms currently choose from a wide spectrum of data protection methods. At one extreme, the firm can elect to accurately reveal highly disaggregated customer data (e.g., Netflix). At the other extreme, the firm may destroy customer data for reasons of privacy, by choice or to comply with regulatory or contractual obligations, implicitly foregoing any potential gains from data sharing, as well as the opportunity to benefit in the future from analysis of a complete historical data set. In the middle of the spectrum, aggregation is commonly used to mask the data, as is the case in the AC Nielsen and Google examples. In all these cases, the firm is implicitly making a trade-off between commercial value and data protection.
In this paper, we seek to make several contributions to the marketing literature. First, we conceptualize the need for data protection in the context of a business ecosystem that is widely prevalent in marketing (Figure 1). A key distinction in this framework relative to

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

155

Figure 1. (Color online) Marketing Data Privacy Ecosystem for Point-of-Sale Data

Data subjects (retail stores)

Raw POS data

$, privacy guarantee

Goal 1: Provide data to enable data users' valid use goals

Data provider (AC Nielsen)

Goal 2: Protect data subjects' identities

Model: Data protection model to generate synthetic data that enable valid use and deter invalid use

Protected data

Revenue $

Valid use Goal : Estimate brand price elasticities
and promotion effects
Model : Marketing Mix or Sales Response model

Data users (CPG manufacturers)

Invalid use (by data user or data intruder ) Goal : Discover subjects' identities Model : To predict subjects' identities

the privacy literature in statistics and computer science is that we explicitly recognize the business goals of the data user as reflected in the data user's model, and incorporate these into the data provider's model. By contrast, to our knowledge, almost all of the extant literature on data protection, which is outside marketing, does not explicitly specify the goals of the data user (we discuss this point in detail in Section 1.1). This is in part because the literature on statistical disclosure has largely taken the perspective of governmental agencies such as the U.S. Census Bureau, who release data for a diffuse set of users, typically the general public.
Second, we contribute to the statistical disclosure literature by proposing a new approach to incorporate the data provider's data protection preferences into a Bayesian model through a prior distribution controlled by a single parameter (in this paper, we characterize the "prior" as a privacy-preserving prior distribution found in Schneider and Abowd 2015). In particular, we include a parameter kappa () in the prior distribution that can be changed by the data provider to manage the trade-off between information loss to the data user and loss of protection from invalid use. The prior distribution is then used to generate synthetic but representative data from a protected posterior predictive distribution. We propose a rigorous methodology for data protection within a single formal probability

model which is discussed in detail (see Figure 2). This modeling strategy provides a key managerial benefit: The model allows the data provider to explicitly manage the trade-off between data protection and commercial value given the data provider's risk-return preference. This is in contrast with standard approaches such as top-coding, swapping, rounding, and aggregation, which may be considered ad hoc in this regard (these methods are discussed later in Table 1).
Finally, and perhaps most important, we propose new measures of identification risk inherent in a data set--Average Loss of Protection (ALP) and Maximum Loss of Protection (MLP)--and explore the theoretical and empirical relationships of these to standard measures, i.e., the Gini Coefficient and Entropy. MLP measures the highest probability of store identification across stores, and hence can be interpreted as the minimum level of privacy across stores. It is associated with the probability of just one store being identified, which may result in large losses due to, for instance, a lawsuit or a decrease in trust for the data provider. Note that MLP is a viable risk management measure for comparing minimum privacy levels across different data protection approaches applied to a data set.
We illustrate the proposed methodology using AC Nielsen point-of-sale data for brands of a consumer packaged good. We find that the parameter  assists

156

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

the data provider in choosing an appropriate prior distribution. We also find that our method performs well compared to a set of seven benchmark data protection methods, including no protection and the aggregation approach used by AC Nielsen. The main limitation of the proposed identification disclosure risk model in this empirical application is that the estimated probabilities of an observation belonging to stores in a given time period do not sum to 100%. We discuss the implications of not having this constraint in Section 2.4.1.
1.1. Privacy Literature The academic literature in marketing has explored a few themes in data privacy. An important theme is the relationship between privacy and targetability of marketing actions. Goldfarb and Tucker (2011), for instance, explores the impact on advertising effectiveness of privacy regulations in Europe that restrict the collection and use of customer data. Similarly, Conitzer et al. (2011) considers the impacts of a customer's choice of maintaining anonymity on firms' ability to price discriminate and on consumer welfare. The use of aggregation to mask sensitive consumer information has been recognized by, for instance, Steenburgh et al. (2003, p. 40) who propose an approach to use "massively categorical" variables such as zip codes in choice models. As the number of categories increases, the number of consumers in each category decreases, thereby increasing the risk of disclosure of individual data. de Jong et al. (2010) use randomized response designs in survey data collection to protect respondents' identities while allowing for unbiased aggregate inferences. Our approach is fundamentally different from this stream of research because we focus on data protection ex post, not ex ante.
Because much of the work on data protection is outside the marketing literature, we focus on the relevant literature in statistics. Standard data protection methods in use at a variety of agencies include aggregating, swapping, rounding, and top-coding (we define these methods in Section 3 and Table 1). The goal of data protection is usually to limit disclosure risk at an observational level (e.g., individual) while preserving as much of the information as possible. Some examples of disclosure risk measures in use include the number of unique populations in a data set or the probability of identification of a single observation. Reiter (2005) used probabilities of identification as the disclosure risk measure and applied standard data protection methods to unprotected data. A later paper (Reiter 2009) found that aggregation was more effective than swapping. However, standard data protection methods are so extreme that for many analyses, protected data have limited utility. Little (1993, p. 422) recognized the disadvantages of simply providing the sufficient statistics needed for particular analyses (i.e., aggregation).

These include "lack of flexibility in the choice of variables to be analyzed, and the relative inability to do exploratory analysis and model-checking."
In response to the limitations and ad hoc nature of standard data protection methods, the data privacy community shifted to the use of synthetic data, which are simulated data generated from a probability distribution. Synthetic data provide an important advantage: They can allow theoretical guarantees of privacy. The first theoretical data protection model using synthetic data was a Dirichlet­Multinomial model that was applied to count data from the U.S. Census Bureau (Machanavajjhala et al. 2008). However, due to the strong theoretical requirements for privacy, the protection "rendered the synthetic data useless" (Machanavajjhala et al. 2008, p. 277). Although this and subsequent papers (e.g., Charest 2011) have advanced the theoretical knowledge of synthetic data protection methods, from a practical point of view, their synthetic data were of little use or were too highly aggregated (e.g., into a single count).
Part of the problem is that these applications do not use covariates in the data protection model. Covariates allow the synthetic dependent variable to vary across observations, which improves utility for the data user. Recent literature has sought to advance data protection methods by extending them to analyze richer data with covariates. Abowd et al. (2013) used covariates in a regression model for U.S. Census Bureau data, but found that the strict theoretical guarantees of privacy were still too strong to be met in a multiple regression model, and only succeeded in a simple regression model with one covariate. Those authors suggested the use of more relaxed measures of privacy to increase data utility.
Recent data protection models have relaxed theoretical guarantees of privacy to generate synthetic data for more general real-world regression problems that include several covariates. For instance, Hu et al. (2014) generated synthetic data with a Dirichlet­Multinomial regression model with 14 categorical covariates. More recently, Schneider and Abowd (2015) developed a privacy-preserving prior distribution from the data provider's perspective for use with a zero-inflated regression model. Their goal was to provide an alternative approach to the protection method used by the U.S. Census Bureau that was based on suppression of zeros. They found that synthetic data released from their models had a similar fit to simpler models; however, importantly, their models allowed the provider to achieve a greater level of privacy. Our paper differs from Schneider and Abowd (2015) most notably in having a different goal, i.e., developing a data provider's model that is consistent with the Data Privacy Marketing Ecosystem in Figure 1. In other words, our method generates protected data that are useful for specified

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS
data users. Our model is also different in terms of protecting the estimated parameters of continuous variables (such as price) by adjusting the multivariate Normal prior and parsimoniously controlling the entire protection mechanism by using a single parameter .
In sum, although recent work has advanced the use of synthetic data, nearly all of the work has been done from the perspective of a governmental agency that is required to release and protect data for a diffuse group (the public). These data protection methods do not allow the decision maker to balance potentially conflicting goals in a decision-theoretic framework. For example, the firm that sells data needs to balance the incremental profits from more accurate data disclosure and the potential costs of a data breach (including hidden costs such as those resulting from a loss in consumer trust in the firm).
The literature review indicates that there is a strong unmet need for a synthetic data model that incorporates three parties with different goals, i.e., the data provider as a commercial supplier who protects data with a data protection method, the data user as a customer, and the potential data intruder. As discussed, such a framework is especially needed in marketing applications. Our paper proposes one such framework. Philosophically, we agree with Reiter (2009, p. 225) who notes that "synthetic data reflect only those relationships included in the data generation models." Thus, we gear our synthetic data and data protection method toward the business goal of enabling valid use by the data user.
One notable aspect of our paper is that the Marketing Data Privacy Ecosystem focuses on the data user's need to make important marketing decisions using the data. These needs then drive the development of the data protection method by the data provider. Prior research (Reiter 2005, Machanavajjhala et al. 2008, Charest 2011, Abowd et al. 2013, Hu et al. 2014, Reiter et al. 2014, Schneider and Abowd 2015) used data from the U.S. Census Bureau, the Bureau of Justice Statistics or simulation. These choices obviated the need to incorporate a customer of the synthetic data, i.e., the data user, into the data protection strategy. By contrast, in our paper, we explicitly model all three players in the Marketing Ecosystem, i.e., the data provider, the data user, and the potential intruder.
The rest of the paper is organized as follows. In Section 2 we discuss the data user's model and a model to quantify the risk of disclosure, and propose an algorithm for generating synthetic protected data. In Section 3, we provide an empirical application of the algorithm to a specific data user model and discuss results, including a comparison with benchmark models. Section 4 discusses conclusions and proposes directions for future research.

157

2. Models Used by the Data User and Data Provider
We believe it is useful to illustrate the proposed methodology in a specific model-based application context. In Section 2.1, we return to the example of the data provider, AC Nielsen, sharing point-of-sale data with data users and present a well known marketresponse model that is used by its data users to estimate brand price elasticities and promotion effects. In Section 2.2, we introduce a model to predict the risk of disclosure of the identities of stores who provided the data to AC Nielsen. In Section 2.3, we propose a data protection method for use by data providers such as AC Nielsen. In Section 2.4, we propose several new criteria to measure the performance of any data protection method. We also illustrate (in Section 2.4.1) the application of the identification disclosure model by the data provider, and discuss how an intruder may use additional data to predict store identities.

2.1. Data User's Model We illustrate our method using SCAN*PRO (Leeflang et al. 2013), a market-response model that is widely used by consumer goods manufacturers and by AC Nielsen. This model quantifies the short-term effects on a brand's unit sales of such retailers' activities as in-store prices, special displays, and feature advertising. Van Heerde et al. (2002) reported that as of the date of their article, SCAN*PRO and its variants had already been used in over 3,000 different commercial applications.
The fundamental model specification in SCAN*PRO involves a multiplicative or log-log relationship between a brand's unit sales volume, and own and competitive brand prices and promotions. The model is specified at the store-level and is estimated using weekly data. To maintain sharp focus on our data protection method, we use a version of the full SCAN*PRO model. The model is estimated separately by brand, and includes store fixed effects, an own-price effect, and three own-promotion effects. The three own-promotion effects are own-display only, own-feature only, and both own-display and own-feature.2 Hence the market response model is

Sijt

i j Pijjt

L

 Dl i j t lj

e ijt , i

1, . . . , n;

l1

t 1, . . . , T, (1)

where S represents sales volume, P is price, and the Ds represent indicator variables for three kinds of promotions indexed by l, i.e., Display only, Feature only, and both Display and Feature. In the model, i indexes stores, j indexes brands, and t indexes weeks. As is well known, in this multiplicative model the own-price effects j represent own-price elasticities, the lj represent own-promotion effects, and the ijt represent the

158

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

error terms. The promotion effects are interpretable as promotion multipliers or the factors by which baseline sales increase under promotion. We assume that the primary goal of the data user is to obtain accurate estimates of own-price elasticities and own-promotion effects; these are critical quantities for characterizing product markets as well as for determining optimal mark-ups or conducting what-if simulations.
Although AC Nielsen collects weekly store-level data from a random sample of stores, it is reluctant to release store-level data to data users. As discussed previously, this is in large part because of the concern that data users may be able to predict or guess the identities of sample stores, information which AC Nielsen is contractually bound to protect from data users. In addition, the identity of a sample store is more likely to be discovered and more damaging when the exact storelevel sales quantities are known. To fulfill its contractual obligations, AC Nielsen has typically aggregated the store-level data to market levels before release to users, thus protecting the store identities and the storelevel sales quantities.

2.2. Model for Identification Disclosure Risk We assume that the key risk that the data provider wishes to guard against is the risk of disclosing the confidential information, i.e. , the true store identities (e.g., "this weekly point-of-sale observation is from the Kroger on Thompson Road in Indianapolis") to a data user or potential data intruder. To quantify the predictability of the identification disclosure risk for various released (protected) data sets relative to the original true data, we specify the following multinomial logit model, where the response variable is the store ID and the predictor variables are ln(sales), ln(price), and promotion indicators, for each store i, week t, and brand j.
The multinomial logit model is

ln

P(Y^it P(Y^it

IDi | Sit , Pit , Dit ) ID1 | Sit , Pit , Dit )

J

J

JL

ai j ln Sijt + bi j ln Pijt +

cli j Dlijt ,

j1

j1

j1 l1

i, 1, . . . , n; i 2, . . . , n; t 1, . . . , T, (2)

where Yit is a random variable that represents the store ID taking values {ID1 . . . , IDn}; ID1 is the store ID of Store 1, which serves as a reference or base alternative in the multinomial logit model; and P(Y^it IDi | Sit , Pit , Dit) is the fitted probability in week t that Store i has ID equal to IDi , i 2, . . . , n, given sales, prices, and promotions of all brands.3
Note that the data provider has all of the information
required to estimate this model, including the store
identities, true and protected sales data, and prices and

promotions. Evaluating the relative identification disclosure risk of the true data versus any kind of protected data (i.e., the probability that the store is the Kroger on Thompson Road in Indianapolis, given the prices, promotions, and true sales of Tide 147 ounces, versus the probability that the store is the Kroger on Thompson Road in Indianapolis, given the prices, promotions, and synthetic sales of Tide 147 ounces) is equivalent to measuring the predictive abilities of the multinomial logit models built on true data versus the protected data. To measure predictive ability we use leave-one (week)-out cross validation, where the risk of store identification is measured using the predicted probability of store identification in hold-out observations. For example, the potential data intruder might say "based on my available data, I estimate a 25% probability that this observation is from the Kroger on Thompson Road in Indianapolis." We present further details in Section 2.4.1 including the kinds of data to which potential intruders may have access in real life.
2.3. Proposed Data Protection Model We propose a Bayesian random effects model for protecting data through the use of a flexible prior distribution that reflects the data provider's risk-return preferences. To begin, we discuss some pertinent questions about the data provider's process of developing the protected data. First, the data provider's goal is to release useful yet privacy-protected data to data users. As discussed previously, in our analysis the data provider assesses the identity disclosure risks by measuring the predictability of store identities based on various forms of protected data compared to the true data.
Second, which variables in the data gathered from stores should not be released, and hence protected by transformation into synthetic data? We use the decision criterion that variables with the most power to predict store IDs in the training data should be protected. As discussed later in Section 3, we choose to protect sales quantities but not price or promotion data. We chose these variables based on analysis that is reported in detail in Appendix C, and is conceptually described here. In our available sample of AC Nielsen data, we use the multinomial logit model specified in Section 2.2 to compute the ability of variables such as prices, promotions, and sales volumes to predict store IDs. Our analysis shows that using prices alone leads to an average loss of protection of 0.062, while using sales volumes alone leads to a much higher average loss of protection of 0.511. (See Equation (7) and the related discussion for the definition of Loss of Protection in Section 2.4.1.) Consequently, we chose to protect sales quantities in our data protection method. Why do we not protect the prices and promotions as well? There are two reasons over and above their limited ability to

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

159

Figure 2. (Color online) Data Provider's Process for Generating Synthetic Data for Release to the Data User

Data provider's protection preference
(k )

Prior on variance components
Prior on fixed effects

Covariate data (prices,
features, displays)
True sales quantities

Model estimates (random and fixed effects, variance components) and covariate
data

Protected deviations,
error variance, and
covariate data
Synthetic sales data
and covariate
data (released)

predict store IDs. One, prices and promotions provide valuable information to data users, such as the distribution of retail prices of own and competing products: Protection would distort this information. Two, unlike brand sales volumes, prices and promotions are publicly available information that can be observed in the store. Therefore, a determined intruder could obtain such data with sufficient effort and hence these data are less necessary to protect. While price and promotion information can also be protected, this would add greater complexity to the models. We discuss this idea as a future research opportunity in Section 4.
Third, in developing the protected data, we propose the use of a random effects model instead of a model-free noise approach (e.g., simply adding a random number to sales). We implement the model-free noise approach as a benchmark method for comparison. In a random effects model, the distribution of the dependent variable, i.e., sales quantities, can be altered with little difficulty to incorporate non-normally distributed data, thus allowing modeling flexibility across types of data. Additionally, and perhaps most important, it is common for estimates of random effects (e.g., store effects) to rely on only a few observations each. The privacy-preserving prior distribution naturally protects the estimates of the random effects from discovery by an intruder by scaling the estimates of the random effects toward zero, or no information.4
Figure 2 summarizes the process by which the data provider generates protected data to release to the data user. The protection mechanism we propose shrinks the values of the estimated random effects and fixed effects toward zero (i.e., the limiting case of no information) through the use of a privacy-preserving prior

distribution on the variances of the random effects and fixed effects. This is managerially important because the data provider prevents the data intruder from knowing or approximating the true arithmetic mean of q observations in a small group. Instead, the protection mechanism scales the estimated values of the q observations toward their greater group means (e.g., overall intercept of all observations). Our proposed method is nonstandard because it first protects the random and fixed effects and then adds noise centered at the protected deviations. After controlling for all variables and shrinking the estimates of the random and fixed effects toward zero, we generate the synthetic sales quantities.
We describe the base modeling set-up and the likelihood in Section 2.3.1. A description of our flexible protective prior distribution is given in Section 2.3.2. Computational details for generating synthetic data are provided in Section 2.3.3.
2.3.1. Base Model. We observe a response variable, sales Sijt for store i 1, . . . , n, brand j 1, . . . , J, and time t 1, . . . , T. Additionally, price, Pijt, and promotion indicators Dlijt are covariates that affect the response. Based on Equation (1), for each brand j, we model ln Sijt using a random effects model
L
ln Sijt µ j + uij +  j ln Pijt + (ln l j)Dlijt + ijt , (3)
l1
where µj is the overall intercept of the brand-specific model for brand j, uij is the random (store) effect that is assumed to be normally distributed with zero mean, and constant variance u2 , j, and ln(l j) are the fixed effects of price and promotions, respectively, and ijt

160

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

is the observation-specific error term that is normally distributed with constant variance, 2j .
Note that model (3) is brand-specific, meaning that
the model is fitted separately for each brand j. For sim-
plicity, we omit the subscript j in the rest of Section 2.3
unless otherwise indicated. A natural way to estimate
the random effects model is through Bayesian modeling
with conjugate priors. The Bayesian approach to gener-
ate protected (synthetic) data through a posterior pre-
dictive distribution can be traced back to Rubin (1993).
For the prior distribution of all model parameters in (3), the overall intercept term µ is assumed to fol-
low a normal distribution with zero mean and a large constant variance K2 so that the prior is diffuse. The variance of the random effect, u2 , is assumed to be distributed according to an inverse-Gamma distribution. The fixed effects vector (, ln ) is assumed to be
jointly distributed as multivariate normal with a mean
vector of zeros and diagonal covariance matrix b. In effect, we assume that each of the fixed effects, (, ln ),
has the same prior distribution, i.e., independent normal with zero mean and variance b2.5 The variance of model error 2 is assumed to follow an inverse-Gamma
distribution with fixed shape and scale parameters. Formally, we have µ N(0, K2); 2  IG(a0, b0); u2 
IG(0/2, V0/2); (, ln )  MVN(0, b2I). Among the hyperparameters (K2, a0, b0, V0, 0, b2), K is set to be a large positive number; a0 and b0 are fixed positive numbers; and V0 and 0 are functions of a single new protection parameter; we elaborate further on this in Sec-
tion 2.3.2. To implement the random effects model (3),
we use freely available software, an R package MCMC-
glmm (Hadfield 2010). Details of the specification of
hyperparameters are discussed next.

2.3.2. Flexible Prior Distribution. The random effects

model can be interpreted as a mean model (McCul-

loch and Searle 2001). Thus, posterior samples of a

function of the unprotected parameters, ui +  ln Pit +

L l

1

(ln

l)Dlit ,

represent

unprotected

"deviations"

from the intercept of all observations, µ. These devi-

ations are linear combinations of the data provider's

continuous and categorical variables and the estimated

coefficients (which are conditional on the original

unprotected data). Since posterior samples of the linear

predictor ui +  ln Pit +

L l

1

(ln

l )Dlit

can

be

predictive

of the identity of store i, they require protection.

To achieve data protection, the flexible prior dis-

tribution takes information away from the unpro-

tected deviations by tuning the hyperparameters of the

prior on the variance components. It scales the unpro-

tected deviations toward no information, as a mecha-

nism for data protection. The priors on the variable-

specific fixed effects and random effects shrink their

posterior estimates toward zero through an adjustable

protection parameter. This is motivated by the fact that
the Bayesian estimator with an informative prior is a
shrinkage estimator.
To see how the protection parameter controls the
protection level, we start from our prior distributions
of fixed effects and the variance of the random effect.
Specifically, we introduce a single protection tuning parameter  that is defined as the inverse of the prior variance of the fixed effect (, ln ). That is,  : 1/b2, where the fixed effect vector has prior distribution (, ln ) MVN(0, b2I). This is a conjugate prior; hence we can derive the conditional posterior mean and variance of (, ln ) as follows:

Ab (XT X + 2I)-1XT (ln S - µ1nT - Zu);

Bb 2(XT X + 2I)-1,

(4)

where, for each brand, using matrix notation, X [ln P, D1, . . . , DL], ln S is an nT-dimensional response vector, X is an nT × (1 + L)-dimensional covariates matrix
for brand j, u is an n-dimensional random effect vector, and Z is an nT × n-dimensional indicator matrix for store i such that Zu [u1, . . . , u1, . . . , ui , . . . , ui , . . . , un , . . . , un] is a nT-dimensional vector.
We illustrate the role of  in generating synthetic
data through the posterior form (4). Note that by using (4) we can shrink the fixed-effect estimates of (, ln ) toward 0 by increasing the parameter . At the other extreme, when  tends to zero or equivalently the prior variance b2 goes to infinity, we obtain a diffuse prior, in which case (4) becomes equivalent to the ordinary
least squares (OLS) estimator. Hence the single tuning parameter  can capture the
preference of the data provider with regard to trad-
ing off data protection (privacy) versus information loss. A smaller value of  (equivalently, a larger value of hyperparameter b2) results in a weaker protection. A larger value of  (equivalently, a smaller value of the hyperparameter b2) results in a stronger protection. Hence, , the data privacy protection parameter, and each value of  corresponds to a particular implicit
trade-off between information loss and privacy.
The conjugate prior distribution of the variance of
the random effect is an inverse-Gamma distribution u2  IG(0/2, V0/2) with mean V0/(0 - 2) and variance 2V02/((0 - 2)2(0 - 4)). The conditional posterior of u2 is ~ u2 | u IG((n + 0)/2, (u u + V0)/2). To incorporate the privacy protection parameter , we set V0 1/(100) and 0 1,000, which makes the mean arbitrarily close to zero as  increases. With this specification of hyperparameters, a larger value of  is equivalent to stronger informative priors for (, ln ) and u2 . Since the means of (, ln ) and u2 are 0 and V0/(0 - 2), respectively, a stronger informative prior shrinks the posteriors
toward their respective means.

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

161

Note that one can specify different forms of V0 and 0 to incorporate . Generally, a stronger protection cor-
responds to a smaller value of V0 and a larger value of 0 such that the mean and variance of ~ u2 tend to 0, and equivalently, the posterior samples of the random
effect, ui, scale toward zero. The full conditionals for the other model parameters can be easily derived ana-
lytically. We present details in Appendix B.

2.3.3. Protected Data for Release to Data User. The

proposed data protection method generates protected

synthetic values of ln Sit for valid use by data users. These synthetic values, ln S~it, are generated by sampling from the protected posterior predictive distribu-

tion, which contains the protected model parameters, (~, ln ~ ) and u~ . To do this, we first run the Markov

Chain Monte Carlo (MCMC) with a set number of iter-

ations as a burn-in. Then, for the remaining iterations,

m 1, . . . , M, all posterior samples of the protected

model parameters are saved. After verifying conver-

gence of the posterior samples of all parameters, for

each iteration m and each observation it, the protected

deviation, u~ i + ~ ln Pit +

L l

1(ln

~l)Dlit ,

is

calculated.

Then, a disturbance term it is sampled from a normal

distribution with mean zero and variance ~2, the pos-

terior sample of residual variance. The sum of the pro-

tected deviation and the disturbance results in a sin-

gle protected synthetic value. Together, for each brand

j, the protected deviation, disturbance, and associated

intercepts and covariates determine the protected pos-

terior predictive distribution for each observation it

Fipt ()

p(lnS~it | S, P, D, , a0, b0, K)

p(lnS~it | ;ln Pit , Dit)× p( | H , S, P, D) d,

(5)

where  (µ, , ln , u, u2 , 2) is the vector of model parameters, and H is the vector of hyperparameters for priors.
This process can be repeated for a desired number of protected synthetic vectors for all brands, ln S~ , of length n × J × T. We suggest that the data provider release only one vector of synthetic data to the data user so that it can reduce the chance of protected model parameters being subject to invalid use. For a detailed discussion, see Reiter et al. (2014), who found that multiple releases of synthetic data are more informative of the confidential data. In this regard, note that multiple releases of synthetic data for the same time period are similar to releasing all of the parameters of a model and disclosing the entire posterior distribution.

2.4. Criteria to Measure Performance of Data Protection Method
As noted, all data protection methods imply a trade-off between two criteria, i.e., identity disclosure risk and

information loss. This trade-off can be analyzed using a Risk-Utility curve (Duncan et al. 2004), which represents the natural trade-off between data protection and the utility of valid use. We discuss these two criteria in detail next.

2.4.1. Measures of Identification Disclosure Risk. To

evaluate the identification disclosure risk of the pro-

tected data versus the true data, we adopt a leave-one

(week)-out cross validation approach. Figure 3 is a flow

chart that describes the steps to compute measures of

identification disclosure risk for various released data

sets as well as true data.

Specifically, for each week k, k 1, . . ., T, a multino-

mial logit model (2) is estimated using T - 1 weeks of available data A {Yit , S~ it , Pit , Dit }, i 1, . . . , n stores, and t 1, . . . , (-k), . . . , T weeks. Yit is the true store ID of Store i in week t, S~ it represents the J-vector of pro-
tected sales (using the proposed method or any bench-

mark method), Pit is the J-vector of prices, and Dit is the L × J vector of promotions. Here (-k) indicates

that information for week k is not used for estimat-

ing the multinomial logit model (2). The probabilities P(Y^ik IDi ) of the left-out kth-week store ID are then
calculated for the fitted model (2) using the explanatory variables {S~ ik , Pik , Dik }, i 1, . . . , n. For the special
case in which the identity disclosure risk of true data

is evaluated, the true sales Sit are used. Note that in our particular empirical application

(discussed in Section 3), for each held-out week we

obtain an n × n predicted conditional probability ma-

trix, which is calculated by plugging in values of co-

variates (sales, prices, and promotions) into the esti-

mated multinomial logit model (2). In this case, the

predictive model has the limitation that it does not

incorporate the information that the hold-out sample

contains exactly n distinct masked entities, and there

are n distinct entities in the training sample. In other

words, the column sum of the probability matrix, i.e.,

n i

P(Y^i

k

IDi ), is not guaranteed to be 1. In practice,

however, in the data multiple records for a brand in a

given period could be from the same store depending

on, for instance, how stock keeping units are aggre-

gated. Not imposing the constraint implies that there

are measurement errors associated with sales so that

multiple samples of the same store for the same period

may result in different sales measures. Note that fre-

quently, in practice, the number of stores whose iden-

tity is to be predicted is very likely to be smaller

than the number of stores used in the training sample.

Therefore, the constraint should not be imposed in gen-

eral. Despite this limitation of the predictive model in

our application, it appears to be a natural first attempt

in identifying store identities.

For each Store i, the predicted probability that its

store ID is i is computed as the mean of the predicted

162

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

Figure 3. (Color online) Leave-One (Week)-Out Cross Validation Process for True Data and Various Released (Protected) Data
Start
Data provider has all observations with sales (true or protected), prices, promotions, and store IDs
Leave out kth week observations, k = 1, ..., T, and build a
multinomial logit model using the remaining (T ­ 1) weeks
of data
Predict store ID probability for each store i, i = 1, ..., n for held-out week k. Retain these predicted probabilities

Update week k = k + 1
No Is k = T ?
Yes Compute mean store ID probabilities for
each store, across weeks. Use these values to compute LPi, i = 1, ..., n

Obtain summary measures from distribution of LPi : MLP and ALP

probability vector across held-out weeks to obtain the n-vector {P(Y^i ID1), . . . , P(Y^i IDn)}

P(Y^i

IDi )

1 T

T
P(Y^ik
k1

IDi ),

(6)

where P(Y^ik IDi ) is the predicted probability that Store i is Store i , i 2, . . . , n, in the held-out week k.

The proposed method uses a (pseudo) out-of-sample fit criterion to avoid overfitting and to mimic the prediction problem for the potential intruder: Synthetic sales and covariates are known, and the objective is to predict store identities. One way to do this is to use data for T - 1 weeks and predict the data for the omitted week. To avoid capitalizing on the idiosyncrasies of just one week, the method repeatedly leaves out one week at a time (k 1, . . . , T) and uses T - 1 observations to predict store IDs for week k. An alternative way is to split the data into an estimation sample (weeks 1, 2, . . . , T ) and a validation sample (weeks T + 1, . . . , T). Both hold-out methods are used in the robustness check in Section 3.5.
We define the following measure, called Loss of Protection (LPi), for Store i:

n

LPi

n [P(Y^i IDi )]2 - 1.

(7)

i1

In summary, LPi measures the intruder's confidence in the ability of the available data to identify Store i.

LPi also has a natural lower bound of 0 guessing the identity of store i where P(Y^i ID2) · · · P(Y^i IDn) 1/n. It

for randomly P(Y^i ID1) has an upper

bound of n - 1 if one store identification probability is

100% and each of the other probabilities is 0%. In gen-

eral, a smaller value of LPi implies that the individual store is better protected. LPi thus captures the variability of store identification probabilities (or intruder

confidence).

Note that for market-level data, LPi cannot be computed because there is no store information at all in the

data. Therefore, we define the LPi of market-level data as 0. Our proposed LPi measure is closely related to, but distinct from, popular measures in the literature

on information theory, such as Gini impurity, which is

commonly used in classification trees (Breiman et al.

1984), and Entropy.6 The use of Gini impurity and

Entropy in classification trees, however, is very differ-

ent from use of the proposed LPi measure, although there is a strong similarity in the formulae. Gini impu-

rity and Entropy are mainly used to measure the impu-

rity of a node in decision trees; however, the proposed

LPi statistic is a measure of loss of protection based on estimated probabilities of store identification.

As a measure of the protection level for the full set of

stores, we propose using MLP, which is calculated as

MLP max{LP1, . . . , LPn }.

(8)

MLP is useful in measuring the minimum level of privacy across all stores; this measure is especially useful to a data provider concerned with the problems arising from the identification of any store. In addition to MLP, one can use other statistics such as average, median,

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

163

and minimum LPi. For example, ALP can be used as an overall measure of the protection level for the full set of stores.
The leave-one (week)-out cross validation approach we use helps the data provider to evaluate the out-ofsample predictability of store IDs based on the released protected data versus the true data. An alternative view of this process is that the data user or intruder has access to training data with protected or true sales, and the true store IDs. The data user or intruder can then use these data as a training sample to build a predictive multinomial logit model of store IDs. In the AC Nielsen context, potential sources of such training data are individual retailers, and retail chains or wholesalers who directly sell or share their own data, and/or allow store identities to be observed.7 This model can then be used to predict store identities in newly released data in which store IDs have been disguised.
To make this idea more precise, say the data user or intruder has access to historical released data (with protected or true sales) with true store identities (e.g., "these are the prices and the (synthetic) sales of Tide 147 at the Kroger on Thompson Road in Indianapolis"): A {Yit , S~ it(or Sit), Pit , Dit }, t 1, 2, . . . , T . The data user or intruder builds a predictive multinomial logit model on A and uses the estimates to predict the store identities, Y^i(t T +1, ..., T) in newly released data R {S~ it , Pit , Dit }, t T + 1, . . . , T. Note that the subscript i indicates that the data user receives a hashed version of store IDs in the newly released data so that it does not know the store identities, but knows which weekly observations belong to the same store. We provide empirical results based on this type of analysis in Section 3.5. Importantly, the results from using this method are qualitatively consistent with those from the leave-one (week)-out cross validation approach.

2.4.2. Measures of Information Loss Due to Data Protection. In our discussion of information loss from data protection, our empirical analysis focuses mainly on the estimated own-price elasticities; similar ideas apply to the estimated promotion effects. Because price elasticities are a key metric in determining optimal mark-ups and profitability, and for conducting "what if" analyses, we assume that an important goal of data users is to correctly estimate these own price elasticities. The estimates from the "unprotected" (true) store-level data are taken to be the true elasticities j. Information loss under any data protection method is measured as the Mean Absolute Percentage Deviation (MAPD) of the estimated price elasticities based on the protected data, ^j, from the true j

MAPD

1J J j1

^ j -  j j

×100%.

(9)

Additionally, MSE is defined as the Mean Squared Error of parameter estimates from using protected data compared to the corresponding parameter estimates from using the original data

MSE

1 J

J
(^ j -  j)2.
j1

In our paper, we disregard estimation uncertainty; consequently, we assume that the original, unprotected store-level data has a MAPD and MSE of 0%. Because an important managerial use of estimated elasticities is determining optimal prices (e.g., Reibstein and Gatignon 1984), we also compute for each brand the optimal mark-up over marginal cost (MC), defined as

Optimal MUj%

Pricej - MCj × 100% MC j

|



j

1 |-

1

×

100%.

(10)

Additionally, we compute the deviations from optimal

profits (i.e., maximum profit using the true data) as

another measure of the loss of information. For the

SCAN*PRO model, which is a constant elasticity sales

response model, the assumption of constant marginal

cost for any brand yields the following expression for

the ratio of optimal profits relative to the no protection

case (the j subscript has been suppressed throughout

in the expression for simplification; the derivation of

this formula is shown in Appendix D):

^ 

(P^ ) (P)

P^ - C P^  P-C P

 + 1  + 1 ^  ^ + 1 ^ + 1  ,

(11)

where ^ and P^ are the optimal profit and optimal price, respectively, based on the estimated price elasticities from protected data, whereas  and P are the optimal profit and optimal price, respectively, based on the price elasticities estimated using unprotected data.
Note that estimates of elasticities that are of absolute magnitude smaller than 1 result in meaningless estimates of the optimal markup and the deviation from optimal profits. We point out these cases in our discussion of empirical results as indications of the lack of face validity of the estimated elasticities.

3. Empirical Application
We apply the model (1) to AC Nielsen point-of-sale scanner data for five brand-sizes of powdered detergents from the three largest brands in the market, i.e., 72 and 147-ounce packs of Tide and Oxydol and the 72-ounce pack of Cheer. The data are weekly store-level sales, prices, and promotions in 34 stores in Sioux Falls, SD, and Springfield, MO, collected over 102 weeks. These data have also been used in Christen et al. (1997).
To compute measures of loss of protection, we conduct analysis similar to leave-one (week)-out cross validation as discussed in Section 2.4.1. We use all-but-one

164

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

Table 1. Definition of Benchmark Protection Methods

Benchmark method

Description

1 "True" or Unprotected Original store-level sales data

store-level data

without any protection

2 Random noise

Observations are binned into deciles

based on sales, and random noise

is added to the sales in each decile

3 Rounding

Sales are rounded to the nearest

hundred

4 Top coding

Sales greater than the 95th percentile

are truncated

5 20% swapping

20% of observations are divided into

two groups and their sales data are

exchanged

6 50% swapping

50% of observations are divided into

two groups and their sales data are

exchanged

7 Market-level

For each week, sales are summed

and prices and promotions are

averaged across stores to the

market level

week of observations of data (A {Yit , S~ it , Pit , Dit }, i 1, . . . , n stores and t 1, . . . , (-k), . . ., T weeks) to predict the store ID for the leave-one (week)-out observation. We repeat this process for all weeks and compute all reported measures of loss of protection.
We compare the performance of the proposed method with the performances of seven benchmark data protection methods. Benchmark Method 1 is the unprotected, store-level data, where we have no information loss by definition, and the largest loss of protection. Benchmark Methods 2­6, respectively, are as follows: adding random noise, rounding, top coding, 20% swapping, and 50% swapping. Finally, Benchmark Method 7 is based on using (aggregated) market-level data, which reflects the type of data AC Nielsen offers its clients. See the definitions in Table 1.
For adding random noise, due to the large variance of original sales, we first bin observations into deciles based on sales, and then separately add random noise for each bin using its empirical variance. For rounding, the unprotected sales are simply rounded to the nearest hundred. For top coding, any observation in which sales is greater than the 95th percentile is truncated so that extreme values can be protected. For swapping, we chose a specified percentage of observations (20% and 50% in our analysis) at random and divided these observations into two groups at random. Then the values of sales were exchanged between these two groups. The remaining variables, i.e., store ID, prices, displays, and feature were unchanged.
3.1. Trade-Off Between Information Loss and Loss of Protection
We focus first on the loss of information with respect to estimates of the own-price elasticities of the five brandsizes as measured by MAPD, and loss of protection as

measured by our proposed measure, MLP. The reason to focus on MLP (instead of ALP) is that this measure corresponds to a worst case scenario and reflects the largest potential cost to the data provider from disclosure of even one store's ID. Figure 4 shows the results of our proposed method as we vary  from 0.1 to 15, as well as those for the seven benchmark methods.8
As discussed, in the proposed method,  is a managerially determined parameter that reflects the tradeoff between the level of protection and information loss. As expected, increasing  leads to greater information loss, and reduces the ability of the data user to accurately estimate price elasticities. In addition, it protects the data by lowering the risk of identification of store IDs. The choice of  reflects the criterion selected by the data provider to choose the preferred trade-off between the level of protection across all stores and the implicit degree of precision in estimating elasticities that the data provider chooses to offer its clients.
Figure 4 shows that there are considerable differences in the performances of the different methods using the two criteria, i.e., information loss and loss of protection. Importantly, Figure 4 makes it clear that the choice of a data protection strategy requires the firm to make a trade-off between these criteria. We note that while AC Nielsen's extant approach of aggregating data to the market-level is the most effective in terms of protection, it leads to a substantial loss of information with an MAPD of 43.7%. This result is consistent with the literature on aggregation bias (Christen et al. 1997) which reports large biases in parameter estimates due to aggregation.
Note that none of the benchmark methods dominates (i.e., lies to the southwest of) the proposed method at any level of . By using the proposed method, the data provider has the choice of giving up protection to provide more information. For instance, a data provider who faces strong competition from rival data providers who promise clients higher data quality may decide to pursue that option by choosing smaller values of .
We see from Figure 4 that random noise, top coding, and rounding offer the same levels of protection as the original store-level data, but lead to a greater loss of information. Thus, given our data, it would not be prudent for the data provider to use these methods. Although 50% swapping and 20% swapping provide greater protection than store-level data, they imply a considerable loss of information. Nevertheless, both methods dominate providing market-level data and hence are reasonable options for the data provider to consider. Our proposed method allows the decision maker the flexibility through the choice of  to choose a data protection strategy that dominates 20% swapping and 50% swapping. For illustrative purposes, the results shown henceforth for the proposed method assume  1.

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

Figure 4. (Color online) Performance of Alternative Data Protection Methods

0.500

0.450 0.400

Market-level

50% swapping

Information loss (MAPD_beta)

0.350

0.300

0.250 0.200

20% swapping

0.150 0.100 0.050
0 0

Proposed, k =15 k = 7

k = 1

k = 0.5

0.500

1.000

1.500

Maximum loss of protection (MLP)

k = 0.1 2.000

165
Top coding Random noise Rounding TRUE 2.500

As an illustration, we show in Figure 5 the average predicted probabilities from the estimated multinomial logit model where the observed prices, promotions, and sales come from each of the 34 stores. The probabilities are shown for the true sales data and synthetic sales data (generated using the proposed method with  1) and are based on Equation (6). Note that the data, in fact, come from Store 12. The figure shows that the true data give the intruder relatively high confidence (average predicted probability is about 25% and the largest among the 34 probabilities) that the released data are from Store 12. By contrast, the synthetic data give the intruder much lower confidence (average predicted probability is about 5%) that the released data are from Store 12. Note that 5% is close to the outcome from random guessing, which has a corresponding identification probability of 1/34 (2.9%). From a managerial perspective, this drastic change in intruder confidence about the discoverability of store ID (25% to 5%) could imply the difference between the intruder taking an undesirable action (from the data provider's perspective) or not.
3.2. Price Elasticities and Implied Optimal Markups and Profits
Table 2 reports the profit-maximizing percentage markups over marginal cost based on the estimated price elasticities from the proposed and benchmark methods, for each of the five brand-sizes. If the estimated price elasticity is smaller than one in absolute value, the optimal mark-up is "not meaningful," which we indicate as NM in the table. Taking the optimal mark-ups in the "Unprotected (True)" row to be the true mark-ups, we find that the extent of deviation from the true mark-ups for the other methods roughly corresponds with the loss of information indicated by the MAPD in Figure 4. However, we see some systematic deviations.

Rounding and random noise lead to small deviations as expected based on their close-to-zero MAPDs. We find that Top Coding, 20% Swapping, 50% Swapping, and Market-level data each have at least one instance of "not meaningful" mark-ups, with 50% Swapping leading to NM results for all five brand-sizes. Such results would lead data users to question the validity of the protection method. Furthermore, Top Coding and 20% Swapping lead to larger-than-true optimal mark-ups in all cases when the results are meaningful. By contrast, market-level data lead to smaller-than-true optimal mark-ups for the four brand-sizes for which results are meaningful. This is consistent with past literature (e.g., Christen et al. 1997) which shows that marketlevel data often overestimate the magnitude of the own price elasticity.
The mark-up results for the proposed method are reasonable ranging from the worst case of Tide 147 where the estimated mark-up is 65% of the true value in the first row of Table 2, to the best case of Oxydol 147 with a mark-up of 108% of the true value. For all brands, the estimated mark-ups are closer to the true markups than those implied by market-level data.
Table 3 shows the ratios of optimal profits computed under each data protection method relative to optimal profits under the unprotected scenario. Consistent with the results on optimal mark-ups, we see that rounding and random noise lead to close to optimal profits for all five brand-sizes. In cases where the optimal mark-up shown in Table 2 is not meaningful (NM), the ratios of optimal profits cannot be computed and are shown as not available (NA) in Table 3. Disregarding those cases, the ratios under top coding are close to 100% with the exception of one brand (Tide 147) where the ratio is about 51%. Under 20% swapping we find poor results for four of five brands, and under marketlevel data we find poor results for three of five brands.

166

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

Figure 5. (Color online) Average Predicted Probabilities That Observed Point-of-Sale Data from Store 12 Came from Each of the 34 Stores
0.30
True Proposed 0.25

Predicted probability

0.20

0.15

0.10

0.05

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 Predicted store ID

Table 2. Optimal Mark-Up Percentages Implied by Estimated Price Elasticities

Tide 72

Unprotected (true) Random noise Rounding Top coding 20% swapping 50% swapping Market-level Proposed method
( 1)

144.0 128.3 137.5 183.9 405.3 NM 115.1 120.3

Note. NM, Not meaningful.

Tide 147
267.9 121.3 237.9 NM NM NM 77.9 175.5

Cheer 147
168.9 176.7 133.9 193.8 272.0 NM 74.8 113.9

Oxydol 72
186.7 153.1 186.5 213.0 478.4 NM NM 117.6

Oxydol 147
214.8 225.5 172.6 234.5 491.4 NM 153.8 232.0

Table 3. Ratio of Optimal Profits Relative to Unprotected Case

Tide Tide Cheer Oxydol Oxydol 72 (%) 147 (%) 147 (%) 72 (%) 147 (%)

Unprotected (true) Random noise Rounding Top coding 20% swapping 50% swapping Market-level Proposed method
( 1)

100.00 99.94 99.96 98.80 81.98 NA 98.97 99.59

100.00 99.13 99.80 50.87 NA NA 78.87 98.90

100.00 99.19 98.99 99.65 96.08 NA 87.91 95.88

100.00 99.44
100.00 99.70 87.19 NA NA 99.87

100.00 99.98 99.23 99.88 90.78 NA 98.17 99.51

Note. NA, Not available.

Under the proposed method we find good results for four of five brands; the worst case brand is Cheer 147 with a ratio of about 96%. Note that in the current empirical application (a constant elasticity demand function with constant marginal costs), the profit function for many of the brands appears to be quite flat near the maximum, suggesting that the cost to the user of imprecision in elasticities is relatively small. This finding may not hold in more complex models.
3.3. Comparison with Market-Level Data In Table 4 we compare the estimated price and promotion effects for AC Nielsen's extant method of data protection, i.e., market-level data, with the corresponding estimates for the proposed data protection method.

We find that the absolute averages of the relative differences for each of price, display only, feature only, and display and feature effects are substantially, and in some cases dramatically, smaller for the proposed method than the corresponding effects computed using market-level data. For the promotion effects in particular, some of the deviations of marketlevel estimates are unreasonably large, similar to the results of Christen et al. (1997). See, for instance, the estimates of the effects of display only and feature only for the two sizes of Oxydol, and the estimate of feature and display for Cheer 147. These results suggest that our proposed method can relatively easily dominate the extant approach of aggregating data to the market level in terms of information if the data provider

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

167

Table 4. Estimates of Price and Promotion Effects: Comparison of Results from Market-Level Data and Proposed Method

Coefficient estimates

Relative differencea

Store- Market- Proposed Market- Proposed

level level

( 1) level (%) ( 1) (%)

Tide 72 Tide 147 Cheer 147 Oxydol 72 Oxydol 147 Absolute
averageb
Tide 72 Tide 147 Cheer 147 Oxydol 72 Oxydol 147 Absolute
averageb
Tide 72 Tide 147 Cheer 147 Oxydol 72 Oxydol 147 Absolute
averageb
Tide 72 Tide 147 Cheer 147 Oxydol 72 Oxydol 147 Absolute
averageb Adjusted R2
(avg.)

-1.69 -1.37 -1.59 -1.54 -1.47

-1.87 -2.28 -2.34 -0.27 -1.65

Price
-1.80 -1.42 -1.95 -1.59 -1.55

10.3 66.3 46.8 -82.4 12.6 43.7

2.56 2.41 10.75 4.91 4.47

5.68 3.52 9.40 34.78 36.33

Feature only

2.63

121.9

2.11

46.0

9.69

-12.6

5.49

609.1

4.04

712.7

300.5

2.61 20.59 2.44 13.09 5.83 14.34 3.48 23.08 5.00 121.25

Display only

2.88

688.9

2.21

436.5

5.68

146.0

3.38

562.9

5.65 2,325.4

831.9

4.51 5.74 14.94 6.10 6.16

Feature and display

0.97

3.93

3.22

6.58

3.29E + 13 9.57

0.18

5.29

0.00

7.63

-78.4 -44.0
-97.0 -99.9
79.9c

0.958 0.522

0.957

6.5 3.9 22.4 3.5 5.7 8.4
2.8 -12.4 -9.9
11.7 -9.7
9.3
10.5 -9.2 -2.6 -2.8 13.1
7.6
-12.9 14.7
-36.0 -13.3
23.9 16.2c

aRelative difference (Estimate - Store-level estimate)/Store-level estimate.
bAbsolute average is defined as the average of absolute value of relative difference.
cAbsolute averages for Feature and Display do not include brandsize Cheer 147 because of the unreasonably large estimated effect for market-level data.

is willing to tolerate a somewhat higher level of risk of disclosure of store identities.

3.4. Impact of Kappa In Figure 6 we show the values of model parameters as the data protection parameter  changes. We find that all parameters tend toward zero as  increases, further demonstrating the trade-off between data protection and information.

3.5. Robustness of Findings We conducted several additional analyses to assess the robustness of our findings and report the results in

Table 5. First, we report the results for ALP as an alter-

native to MLP. ALP is an overall average measure of

the store identification risk in a given data set, whereas

MLP is a worst case scenario across all stores in a data

set. Second, we use an alternative measure of infor-

mation loss in addition to Mean Absolute Percentage

Deviation: MSE. We compute these measures for price

elasticities (betas), promotion effects (gammas), and for

both. In all cases we find that the performance of the

proposed method relative to any of the benchmark

methods remains substantially unchanged from that

shown in Figure 4 and Table 4. Thus, the proposed

method continues to dominate the standard method of

providing market-level data.

As a robustness check we also considered a situation

in which the data user or intruder has access to some

historical true sales data with true store identities, as

discussed in Section 2.4.1 where the available train-

ing data A predict the

{Yit , store

Sit , Pit , Dit identities,

}, t Y^i(t

1, 2, . . . , T is used to T +1, ..., T) using newly

released data R {S~ it , Pit , Dit }, t T + 1, . . . , T. Table 6

gives the ALP and MLP estimates based on the pro-

posed method and benchmark methods when half of

true sales data from week 1 till week T 51 are used

to estimate a multinomial logit model for store-ID pre-

diction, and predictions of store IDs are made in the

remaining weeks 52 to T 102. In addition, we con-

ducted analyses when different proportions of data or protected data A {Yit , S~ it (or Sit), Pit , Dit } are used to build the multinomial logit model. Overall, the results

are qualitatively consistent with those from the leave-

one (week)-out cross validation.

4. Conclusions and Future Research Directions
This paper proposes a synthetic data methodology that captures the roles of three parties, i.e., the data provider as a commercial supplier who protects data with a data protection method, the data user as a customer, and the potential data intruder. A key distinguishing feature of our framework relative to the privacy literature in statistics and computer science is that we explicitly recognize the business goals of the data user as reflected in the data user's model, and incorporate these into the data provider's model for protecting data. We propose a flexible Bayesian methodology in which the decision maker uses a tuning parameter () to analyze the trade-off between the conflicting goals of profitability and risk of data disclosure (confidentiality). We measure information loss using the MAPD criterion. In addition, we propose two new metrics to measure the risk of data disclosure, i.e., ALP and MLP.
We test the proposed methodology using retail point-of-sale data marketed by a vendor to its commercial customers. The vendor sells data but seeks

168

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

Figure 6. (Color online) Shrinkage Plots of Fixed and Random Effects as Protection Increases

Beta Store (random) effect

0 - 0.5 -1.0 -1.5

Tide 72 Tide 147 Cheer 147 Oxydol 72 Oxydol 147

1.0 0.5
0 - 0.5 -1.0

- 2.0

-2

0

2

4

6

8

log(kappa)

-1.5

-2

0

2

4

6

8

log(kappa)

Table 5. Robustness Check Using Different Measures

Loss of protection

MLP

ALP

MAPD beta

Information loss

MSE beta

MAPD gamma

MSE gamma

MAPD both

MSE both

Unprotected (true)a Random noise Rounding Top coding 20% swapping 50% swapping Market-levelb Proposed method
( 1)

2.250 2.269 2.260 2.277 1.471 1.025
0 1.566

0.796 0.797 0.795 0.787 0.425 0.180
0 0.478

0 0.053 0.046 0.093 0.243 0.445 0.437 0.084

0 0.008 0.008 0.032 0.141 0.498 0.610 0.026

0 0.026 0.008 0.303 0.266 0.437 1.995 0.115

0 0.003 0.000 0.484 0.261 0.487 60.630 0.130

0 0.032 0.017 0.250 0.260 0.439 1.606 0.108

0 0.005 0.002 0.371 0.231 0.490 45.625 0.104

aFor unprotected, the metrics for information loss are 0 by definition. bFor market-level data, we assume that the predicted probabilities for each store ID are equal; that is, 1/n for n 34
stores. Therefore, by the definition of the loss of protection metrics, we have MLP ALP 0.

Table 6. Robustness Analysis for the Scenario When the Intruder Has True Historical Sales Data and True Store IDs

Protection method
Unprotected (true) Random noise Rounding Top coding 20% swapping 50% swapping Proposed

ALP
0.773 0.754 0.776 0.766 0.556 0.412 0.419

MLP
1.649 1.641 1.628 1.649 1.058 0.994 1.143

to protect the identities of sample stores from potential intruders (confidentiality). By contrast, commercial customers use the data to estimate brand-level price elasticities to determine optimal mark-ups, and the sales effects of promotions. We show that by enabling the data provider to choose the degree of protection to infuse into the synthetic data, our method performs well relative to seven benchmark data protection methods, including the extant approach of aggregating data across stores (e.g., AC Nielsen).

An important limitation of the proposed identification disclosure risk model in the empirical application reported in this paper is that the estimated probabilities of an observation belonging to stores in a given time period do not sum to 100%. Development of estimation approaches that can incorporate this constraint when needed is an important area for future research. Furthermore, it is important to recognize that our framework and approach are most relevant when it is possible for a data provider to identify a primary valid use model of data users. In our application, we used the SCAN*PRO model that is widely used by users of AC Nielsen retail data. In such situations our proposed method allows the data provider to protect the data taking account of its data users' business goals. In other situations where the data user's primary purpose is to use the data to conduct exploratory analysis, implying that data users' models are not well structured, or that data users have very different models, our framework is not as directly applicable. An example of exploratory analysis is examining the distribution of sales volumes across stores for the purpose

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

169

of creating retail segments. Although our framework was not specifically geared toward such analysis, we found (results are not shown in this paper) that using synthetic store-level data produced similar results to using the true store-level data. Note that such retail segmentation analysis cannot be performed using the market-level data currently released by vendors such as AC Nielsen. Additionally, a data user may be interested in knowing the precision of the synthetic data relative to the true data. When the measures of precision are for market-level statistics such as brand sales or brand market shares, we do not expect such additional information to change the level of protection. However, if data users desire measures of precision that may reveal additional store-level information, such as information about precision of ranks of stores based on sales volumes, the level of protection will be reduced, regardless of method. We conjecture that the relative rankings of different data protection methods will be unchanged. We leave a detailed investigation of this issue to future research.
We believe several extensions and generalizations of the models presented in this paper should be of interest to academics and practitioners alike. We discuss some of these possibilities next. In this paper, we considered a single random effect in the data provider's model. Generalization of the data provider's model to more than one group of random effects, or variable-specific effects, should be of interest when the data provider would like to choose different levels of data protection for different market segments (subgroups of data). For example, in the context we have modeled, one group of store IDs (e.g., large stores) may be highly confidential and require high levels of protection, whereas another group of store IDs (e.g., small stores) may require lower levels of protection. Our data protection methodology readily extends to more general cases wherein random effects are hierarchical or it is necessary to distinguish M groups, each with its own variance. By using the hierarchical framework of the Bayesian random effects model, our methodology will allow the data provider to choose which groups of effects or segments require more protection.
Additionally, a data user may be interested in other marketing mix models that include competition or more general interactions among marketing mix elements. One weakness of the current framework is that the synthetic data only contain information about the variables that are included in the data generating process in the data provider's model. An adjustment of the data provider's model is certainly possible to accommodate other variables. In this regard note that Schneider and Abowd (2015) found that a much stronger prior was needed to achieve the same privacy levels in a model with three-way interactions, although the fit of the resulting model on the protected data was

similar to that of a model with no interactions. Our findings in this paper are similar in that there is an inherent trade-off between data protection and commercial value, but we leave the investigation of more complex marketing mix models to future research.
In the current paper we assumed that only the sales data needed to be protected, whereas data on the covariates, prices and promotions, could be released without protection since they were much less informative about the confidential data. Our recommendation is that this approach is most suitable for stores that belong to one chain with a uniform pricing and promotion strategy. If in fact the covariates are informative and not publicly available, one would want to generate "triply synthetic" data for multiple variables, such as sales, prices, and promotions. This would result in multiple conditional models, with the added challenge that the collection of conditional distributions may not result in a proper joint distribution (Reiter 2009). We leave the investigation of this problem to future research.9
In our application we used continuous sales data, hence a log-linear model with additive Gaussian errors was appropriate. Marketing data, however, are often categorical in nature. A prototypical example is consumer brand choice data gathered from household panels. The appropriate statistical models for such data are multinomial logit and probit models. When the data user's model is a generalized linear model, the data provider's base model (3) can be extended to a generalized linear mixed effects model (GLMM) g(E(ln Yijt)) µj+uij+ j Xijt, where g( · ) is a link function, such as the logistic link or probit link and E( · ) denotes the conditional expectation. In terms of estimation, the MCMCglmm R package used in this paper can also be used for categorical dependent variables (Hadfield 2010).
Even though the analytical results such as full conditionals we have presented in Appendix A are no longer available for non-Gaussian GLMM, the proposed Bayesian MCMC framework remains valid; however, such cases will require more intensive computation. We can use a similar algorithm as in Section 2 and draw protected (synthetic) data from the appropriate nonnormal conditional distributions. For example, for the logistic link g(E(ln yijt)) ln((E(ln yijt))/(1-E(ln yijt))) with binary choice response, the protected (synthetic) response can be drawn from Bernoulli trials with mean probability g-1(µj+uij+ j Xijt). The empirical performance of such data protection methods should be of great interest to marketing practitioners and academics.
Acknowledgments The authors would like to gratefully acknowledge the input of the senior editor, former senior editor Fred Feinberg, an anonymous associate editor, and three anonymous reviewers. This work was completed while Shaobo Li was a Ph.D. student at the University of Cincinnati.

170

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

Appendix: Key Theoretical Results and Algorithm for Data Protection Method Appendix A. Full Conditionals of Other Model
Parameters The full conditionals for other model parameters can be analytically derived as shown below

~ 2 | · · ·  IG(an , bn); u~ | · · ·  MVN(Au , Bu); µ~ | · · ·  N(Aµ , Bµ);

where

an

a0

+

nT 2

,

bn b0 + ((ln S - µ1nT - X[, ln ] - Zu)T

· (ln S - µ1nT - X[, ln ] - Zu))/2,

Au

ZT Z +

2 u2 I

-1
ZT (ln(S) - µ1nT - X[, ln ]);

Bu

2

ZT Z

+

2 u2

I

-1
,

Aµ

K2

(ln

S

- X[, ln 2 + nT

] - × K2

Zu)T

1nT

;

Bµ

2

K22 + nT ×

K

2

.

Using matrix notation, ln(S) is an nT dimensional response
vector, X [ln PD1, . . . , DL] is an nT × (L + 1) matrix, u is an n-dimensional random effect vector, Z is an nT ×
n dimensional indicator matrix such that Zu [u1, . . . , u1, . . . , ui , . . . , ui , . . . , un , . . . , un] is an nT dimensional vector.

Appendix B. Algorithm for Proposed Data

Protection Method

Model Estimation Procedure (Based on the MCMCglmm

Package in R). Given the conjugate prior of overall intercept

µ, fixed effect  and random effect u, and the variance of error term 2 and variance of random effect u2 , we can derive the full conditional distribution for each model parameter.

1. MCMC procedure by Gibbs sampling: Based on the full

conditional distributions, the model parameters can be sam-

pled for thousands of iterations. In particular

1.1. Start from a set of initial values µ(0), [, ln ](0),

u(0) , 2(0) ,

then

draw

2(1) u

from

its

conditional

distribution

2(1) u

|

µ(0) ,

[,

ln ](0),

u(0) ,

2(0) .

Do

the

same

for

µ(1), [, ln ](1),

u(1) , 2(1) .

1.2. Given kth draw of parameters: µ(k)[, ln ](k), u(k),

2(k) ,

2(k) u

,

make

the

(k

+

1)th

draw

based

on

the

full

condi-

tional distributions.

2. Burn-in a certain number of samples from the begin-

ning, and use the remaining samples for Bayesian estimation

and inference.

Data Generating Procedure. 1. Take a draw of all parameters from the MCMC samples.
Then draw the response based on its conditional distribution

ln S | µ, , ln , u, 2, u2 ; X, Z  MVN(µ1 + X[, ln ] + Zu, 2).

2. Step 1 generates a column of synthetic responses, which is called protected data. To generate another column of synthetic response, we take another draw of parameters, and use the same procedure.

Note that in general Bayesian estimation and inference we need to average the MCMC draws of parameters. The mean values are treated as estimated parameters. However, in a data protection framework, we only take one draw of parameters as estimates instead of averaging all MCMC draws. The reason is that averaged values contain much more information than one draw; the result is that the generated values are close to the true values. Consequently, averaging may result in worse protection.
Appendix C. Analysis of Key Variables to Protect We analyze different variables and their combinations to identify key variables to protect. A natural way for intruders to predict the store ID is via a multinomial logistic regression modeling approach using a training data set at hand with variables such as sales, price, and promotion, and their combinations.
Table C.1 shows the overall average, median, and maximum loss of protection (LP). The ALP with Sales-only is 0.511 compared with 0.062 with Price-only, 0.015 with Promo-only, and 0.104 with Price + Promo combinations. A similar qualitative finding holds for median and maximum LP measures. This shows that sales has the strongest predictive power of store ID; hence sales may be the most important variable to protect.

Table C.1. Comparison of Loss of Protection Measures with Different Variables

Variable

Average loss of protection

Median loss of protection

Maximum loss of protection

Sales only Price only Promo only Sales + Price Sales + Promo Price + Promo Sales + Price + Promo

0.511 0.062 0.015 0.678 0.601 0.104 0.796

0.409 0.026 0.011 0.624 0.535 0.062 0.830

1.420 0.741 0.051 1.918 1.452 0.874 2.250

Appendix D. Derivation of Formula for Deviation from Optimal Profit
Let  be the profit, C be the marginal cost, P be the price, and S be the sales. Then we have

(P) (P - C) · S.

By substituting SCAN*PRO model (1) for each brand, we

have

(P) (P - C)P F .

(D.1)

Here we drop the subscripts for simplicity. It is easy to see that (P) is a concave function of P. By taking the first-order derivative of (D.1) with respect to P, and setting to 0, we have

P-1F[(1 + )P - C] 0.

(D.2)

We solve Equation (D.2) for P, and find the optimal price P as

P

1

C + 1/

.

(D.3)

Schneider et al.: A Flexible Method for Protecting Marketing Data Marketing Science, 2018, vol. 37, no. 1, pp. 153­171, © 2018 INFORMS

Denote P^ as the optimal price based on the estimated price elasticity ^, which is obtained from protected data. Substituting (D.3) into (D.1), by simple algebra, we see that the ratio (P^ )/(P) has the following form:

^ 

(P^ ) (P)

P^ - C P^  P-C P

 + 1  + 1 ^  ^ + 1 ^ + 1  .

Endnotes

1 This concern is similar to the one faced by the New York Times Best

Sellers List of books, which is based on a survey of a closely guarded

set of retail booksellers. Despite the secrecy, several cases have been

reported in the media of authors or their agents making "strategic

purchases" of books at retail stores to artificially boost their own

rankings.

2 We omit competitive price and promotion effects to maintain par-

simony of specification for this application. Inclusion of competi-

tive effects would require four additional parameters per competing

product in the model for each brand. As we discuss in Section 3 (see

Table 4), model fit does not suffer much due to this omission since the average (across brands) adjusted R2 of fitted models exceeds 0.95.

3 Note that the data used in this multinomial logit model are a dif-

ferent configuration of the same data that are used in the data user's

model (1), plus store identities. The data set has nT observations.

The response variable Yit is the ID of Store i in week t, and the predictors are ln(prices), promotions, and ln(sales) of all brands in store i in week t. Thus, we have 5 × J predictors in this model.

4 Previous research (Bleninger et al. 2011) has shown that a data

intruder can strategically uncover sensitive data (e.g., sales quanti-

ties of specific observations) when the data protection method is to

simply add noise.

5 When the covariance matrix b takes a general form, it is not immediately obvious how to incorporate the protection parameter even

though the full conditionals can still be analytically derived. We leave

this extension as a future research opportunity.

6 In our particular case, Gini impurity for store i can be written

as Ginii

1-

n i

P(Y^i

IDi )2. It is easy to see the link between LP

and Gini impurity: LPi

n

n i

1 P(Y^i

IDi )2 - 1

Entropy log2 P(Y^i

for Store IDi )].

i

is

defined

as

Entropyi

-

n(1-Ginii) - 1.

n i

1[P(Y^i

IDi ) ·

7 Some examples of retailers' data sharing programs include Retail

Link (Walmart), Partners Online (Target), Workbench (Sears), and

Vendor Dart (Lowe's). The primary goals of such programs are to

facilitate better management of shipments, inventory, out-of-stocks,

and forecasts, often at the store level. Note that these data are typ-

ically not a substitute for retail data provided by syndicated data

providers such as AC Nielsen, which are based on careful samplings

of stores and hence provide the benefits of projecting sales volumes,

market shares, prices, and promotional activities to regional and

national markets.

8 We thank an anonymous reviewer for useful suggestions on the

presentation of Figure 4 and its interpretation.

9 Across all protection methods, results are qualitatively similar to

those presented in the paper when we used protected sales and

added a normally distributed random noise to protect the price data.

References
Abhishek V, Hosanagar K, Fader PS (2015) Aggregation bias in sponsored search data: The curse and the cure. Marketing Sci. 34(1): 59­77.
Abowd JM, Schneider MJ, Vilhuber L (2013) Differential privacy applications to Bayesian and linear mixed model estimation. J. Privacy Confidentiality 5(1):73­105.

171
Bleninger P, Drechsler J, Ronning G (2011) Remote data access and the risk of disclosure from linear regression: An empirical study. Statist. Oper. Res. Trans. (Special Issue: PSD 2010), 7­24.
Breiman L, Friedman J, Stone CJ, Olshen RA (1984) Classification and Regression Trees (Chapman and Hall/CRC, Boca Raton, FL).
Bucklin R, Gupta S (1999) Commercial use of UPC scanner data: Industry and academic perspectives. Marketing Sci. 18(3): 247­273.
Charest AS (2011) How can we analyze differentially-private synthetic data sets? J. Privacy Confidentiality 2(2):21­33.
Christen M, Gupta S, Porter JC, Staelin R, Wittink DR (1997) Using market-level data to understand promotion effects in a nonlinear model. J. Marketing Res. 34(3):322­334.
Conitzer V, Taylor CR, Wagman L (2011) Hide and seek: Costly consumer privacy in a market with repeat purchases. Marketing Sci. 31(2):271­292.
de Jong MG, Pieters R, Fox J-P (2010) Reducing social desirability bias through item randomized response: An application to measure underreported desires. J. Marketing Res. 47:14­27.
Duncan GT, Keller-McNulty SA, Stokes SL (2004) Disclosure risk vs. data utility: The RU confidentiality map. Chance 17(3):16­20.
Goldfarb A, Tucker C (2011) Privacy regulation and online advertising. Marketing Sci. 57(1):57­71.
Grean M, Shaw MJ (2002) Supply-chain partnership between P&G and Wal-Mart. Shaw MJ, ed. E-Business Management, Integrated Series Inform. Systems, Vol. 1 (Springer, Boston), 155­171.
Hadfield J (2010) MCMC methods for multi-response generalised linear mixed models: The MCMCglmm R package. J. Statist. Software 33(2):1­22.
Hu J, Reiter JP, Wang Q (2014) Disclosure risk evaluation for fully synthetic categorical data. Domingo-Ferrer J, ed. Privacy in Statistical Databases, Lecture Notes Comput. Sci., Vol. 8744 (Springer International Publishing, Cham, Switzerland), 185­199.
Leeflang PSH, Wittink DR, Wedel M, Naert PA (2013) Building Models for Marketing Decisions (Springer, New York).
Link R (1995) Are aggregate scanner data models biased? J. Advertising Res. 35(Sept­Oct):8­12.
Little RJA (1993) Statistical analysis of masked data. J. Official Statist. 9:407­426.
Machanavajjhala A, Kifer D, Abowd J, Gehrke J, Vilhuber L (2008) Privacy: Theory meets practice on the map. ICDE 2008. IEEE 24th Internat. Conf. Data Engrg., Istanbul, 277­286.
Marketing Science Institute (2016) 2016­2018 research priorities. Cambridge, MA, http://www.msi.org/uploads/articles/MSI _RP16-18.pdf.
McCulloch CE, Searle SR (2001) Generalized, Linear, and Mixed Models. Wiley Series Probab. Statist. (Wiley, New York).
Reibstein DJ, Gatignon H (1984) Optimal product line pricing: The influence of elasticities and cross-elasticities. J. Marketing Res. 21(3):259­267.
Reiter JP (2005) Estimating risks of identification disclosure in microdata. J. Amer. Statist. Assoc. 100:1103­1112.
Reiter JP (2009) Multiple imputation for disclosure limitation: Future research challenges. J. Privacy Confidentiality 1(2):223­233.
Reiter JP, Wang Q, Zhang B (2014) Bayesian estimation of disclosure risks for multiply imputed, synthetic data. J. Privacy Confidentiality 6(1):17­33.
Rubin DB (1993) Discussion: Statistical disclosure limitation. J. Official Statist. 9:462­468.
Schneider MJ, Abowd JM (2015) A new method for protecting interrelated time series with Bayesian prior distributions and synthetic data. J. Roy. Statist. Soc. Ser. A Statist. Soc. 178(4): 963­975.
Steenburgh TJ, Ainslie A, Engebretson PH (2003) Massively categorical variables: Revealing the information in zip codes. Marketing Sci. 22(1):40­57.
Tenn S (2006) Avoiding aggregation bias in demand estimation: A multivariate promotional disaggregation approach. Quant. Marketing Econom. 4:383­405.
Van Heerde H, Leeflang PSH, Wittink DR (2002) How promotions work: SCAN*PRO-based evolutionary model building. Schmalenbach Bus. Rev. 54:198­220.

