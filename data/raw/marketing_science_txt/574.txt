Vol. 29, No. 6, November­December 2010, pp. 988­993 issn 0732-2399 eissn 1526-548X 10 2906 0988

informs ®
doi 10.1287/mksc.1100.0581 © 2010 INFORMS

Commentary
Bidders' Experience and Learning in Online Auctions: Issues and Implications

Kannan Srinivasan
Tepper School of Business, Carnegie Mellon University, Pittsburgh, Pennsylvania 15213, kannans@andrew.cmu.edu
Xin Wang
International Business School, Brandeis University, Waltham, Massachusetts 02454, xinwang@brandeis.edu
This study explores the implications of rejecting the sealed-bid abstraction proposed by Zeithammer and Adams [Zeithammer, R., C. Adams. 2010. The sealed-bid abstraction in online auctions. Marketing Sci. 29(6) 964­987]. Using a conditional order statistic model that relies on the joint distribution of the top two proxy bids of an auction, Zeithammer and Adams show that inexperienced bidders' reactive bidding is the main cause of the rejection of the sealed-bid abstraction. Their empirical study suggests that a large percentage of bidders reactively bid, and there is weak evolutionary pressure for bidders to converge to sealed bidding. We discuss theoretical implications of this rejection and the role of bidder experience, as well as inferences about bidder learning. Tracking an inexperienced bidder's bidding behavior over time, we show that bidders learn and their bidding strategy gravitates toward rational bidding. Potential biases in bidder experience measurement and bidder learning can be assessed using a cross-sectional, time-series data set that tracks a random sample of new eBay bidders. Learning speed is faster with their complete bidding history rather than feedback ratings or winning observations only. We highlight the importance of proper measures of bidder experience and its effect on bidding strategy evolutions, both of which play important roles in clarifying bidding behavior in online auctions.
Key words: auctions; online; learning; bidding History: Received: March 26, 2010; accepted: March 29, 2010. Published online in Articles in Advance
August 11, 2010.

Introduction
Zeithammer and Adams (2010) propose empirical methods to test a fundamental, widely adopted assumption in established auction theory, namely, sealed bidding. By testing the bidding time and bid increments of the top two proxy bids in three product categories on eBay, they find that the sealedbid abstraction cannot be supported by eBay bidding data, a result they attribute to "less experienced bidders" who bid in a reactive fashion rather than submitting sealed bids, which is the equilibrium bidding strategy prescribed by auction theory. Using this new finding, these authors provide an empirical model to estimate the demand function of a product that can account for heterogeneity in bidders' bidding strategies (or styles) and valuation distributions. The resulting valuation distribution has a higher mean and variance when inexperienced bidders' reactive biddings are included than when they are not.
The work of Zeithammer and Adams (2010) makes significant contribution to online auction literature. It

is the first study, to our knowledge, to test empirically the "sealed bidding" assumption using actual eBay bidding data. Their work sheds much-needed light on the potential gap between theory and empirical work in the field of online auctions. Furthermore, their work builds on a conditional order statistic approach that does not require inferences about the potential number of bidders, which can be quite complex in an online auction setting. Instead, their empirical tests and estimation model rely on bidding information (bid value and timing) about only the top two bids in each auction. Finally, their study notes the potential for bias if reactive bidding is not explicitly considered in a demand estimation model in auction research.
In this commentary, we discuss the rejection of the sealed-bid assumption and its theoretical implications. The root cause of such a rejection, as indicated by Zeithammer and Adams (2010), relates to bidder experience. Therefore, we review the issues associated with experience measures and extant conclusions about them. Our analysis is based on the complete

988

Srinivasan and Wang: Bidders' Experience and Learning in Online Auctions

Marketing Science 29(6), pp. 988­993, © 2010 INFORMS

989

bidding history of novice bidders and shows that bidders learn faster according to proper experience measures and an analysis of the complete bidding history. This realization alleviates, at least to some extent, the problem caused by the rejection of the sealed-bid abstraction.
Sealed-Bid Abstraction and Asymmetry in Bidders' Experience
Zeithammer and Adams (2010) argue that the rejection of the sealed-bid assumption is largely caused by inexperienced bidders' reactive bidding. Thus, these bidders do not behave rationally in the manner prescribed by established auction theory. Reactive bidders tend to submit multiple bids and never bid up to their valuation initially. Their incremental bids likely get submitted throughout the course of the auction instead of near the end. The link between the bidders' lack of experience and the failure to support sealedbid abstraction is a central point. Bidder experience is an essential concept to validate the assumption and has direct implications for ongoing theoretical and empirical research.
That is, the reason for rejecting the sealed bidding abstraction leads to the violation of another major assumption in auction theory, namely, bidder symmetry. Bidder symmetry refers to "their preference parameters (i.e., their `types') [that] are drawn from a symmetric joint probability distribution Thus if two buyers are of the same type they will have the same beliefs about the remaining buyers' preferences. Given this symmetry, there will exist a symmetric equilibrium" (Maskin and Riley 2000, p. 414). This symmetry is clearly not the case when bidders have different types, bid according to different rules (strategies), and have different valuation distributions. Experienced bidders tend to bid more rationally or in a sealed fashion; inexperienced bidders do not. In view of the coexistence of inexperienced and experienced bidders, Bajari and Hortaçsu (2003) and Roth and Ockenfels (2002) show that for both private and common value auctions, late bidding is the best response to irrational bidding behavior, such as multiple bidding, because it protects private information about product value.
As with any theoretical offerings, online auction theories often rely on stylized assumptions. Without the sealed-bid assumption or the symmetry assumption, model development inevitably would become more intractable. Auction literature has long recognized that a small deviation from bidder symmetry leads to various predictions. Therefore, since the 1980s, economists began to address various issues that arise from bidder asymmetry, often by relying on numeric solutions to compute bidding strategies

or establish theoretical properties that can handle the complexity of the problem (e.g., Hausch 1987, Marshall et al. 1994, Maskin and Riley 2000).
Without the symmetry assumption, established auction principles and findings that seemed powerful become fragile. For example, in an asymmetric case, the order of revenues from English, second-price, and first-price auctions would not be as unambiguous as in a symmetric case. The revenue from a second-price auction may exceed that of an English auction. The linkage principle also would fail; the release of public information could decrease auction revenues if bidders had asymmetric valuations. Bidders no longer have symmetric and pure bidding strategies. Krishna (2002) provides a thorough discussion of these topics.
Inexperienced bidders are likely to be present in any auction. We investigate whether these novices can learn quickly, and in doing so, we ensure the overall robustness of the equilibrium predictions. In effect, we examine if the sealed-bid assumption holds asymptotically. Because Zeithammer and Adams (2010) use cross-sectional data from different product categories on eBay, they cannot directly address these questions.
Bidder Experience and Learning in Online Auctions
Several recent empirical studies have found that inexperienced and experienced bidders exhibit different bidding behaviors. To infer bidder experience, most of previous research uses the amount of feedback a bidder has received and relies on cross-sectional data from selected product categories. Few studies systematically consider bidders' learning or bidding strategy evolution over time. For example, Wilcox (2000) finds that experienced bidders are less likely to submit multiple bids and tend to bid late; in common value auctions, such effects are more pronounced. Ockenfels and Roth (2006) find that a bidder's feedback ratings reduce multiple bidding but do not induce late bidding. Borle et al. (2006) empirically examine 15 product categories at eBay and find that experienced bidders submit fewer bids, but they bid either at the beginning or the end of an auction. The empirical analysis of Zeithammer and Adams (2010) looks at the relationship between bidder experience (as measured by feedback ratings) and the probability of reactive bidding. Using the inferred probability of reactive bidding, they estimate a mixture model to calibrate the bidder's valuation distribution for a product. Feedback ratings relate negatively to the probability of reactive multiple bidding, yet their analysis uses winners' observations only (mainly because of the conditional order statistical model their study adopts), so it may cause potential biases, as we address in the next section.

Srinivasan and Wang: Bidders' Experience and Learning in Online Auctions

990

Marketing Science 29(6), pp. 988­993, © 2010 INFORMS

Recently, Wang and Hu (2009) began to track new bidders and examine their bidding strategy dynamics over time. These authors show that novice bidders learn from their experiences (particularly losing experiences) and converge to rational bidding behavior in terms of both the number of incremental bids (i.e., submitting fewer bids) and bid timing (i.e., bidding later). They follow the convention of learning literature (e.g., Darr et al. 1995) and define experience as the actual number of auctions in which a person participates. Therefore, Wang and Hu (2009) can infer bidder learning directly from prior experiences and even classify experiences into various types, such as within-category versus out-of-category or winning versus losing experiences, according to the bidder's complete auction participation history. If they control for losing experience, winning experience does not help the bidding strategy converge to rational behavior. Furthermore, bidder learning seems to transcend categories rather than be limited to a certain product category. In other words, all auction experiences count, regardless of the product category. Using crosssectional data from a given category likely causes biases in assessments of the actual experience effect.
With cross-sectional data (usually of a particular product category), which do not allow researchers to observe the total auction participation history of a bidder, it is impossible to gauge the effect of the bidder's experience on bidding strategy properly. Therefore, researchers often rely on feedback ratings posted on eBay as a proxy. If the feedback rating is a random subset of total experience, the problems of using it may not be severe. However, feedback ratings suffer from several major problems. First, a bidder can receive a rating only after winning an auction or purchasing something. By definition then, feedback can be a proxy measure only for winning experiences at best. Second, eBay only allows sellers to rate a bidder when the transaction experience is positive (whereas a bidder can leave positive, negative, or neutral ratings for a seller). Ratings of eBay members also may reflect transactions in which they acted as sellers. Therefore, feedback ratings are not a good proxy, because their accuracy varies from bidder to bidder, they underestimate experience, it is hard to separate buying from selling experiences, and it only records partial winning experiences for bidders.
Wang and Hu (2009) show that winning experiences do not reduce multiple or late bidding, whereas losing experiences do. However, feedback rating as a proxy indicates the misleading result that a winning experience (or a subset of it) can induce rational behaviors. For these reasons, although Zeithammer and Adams (2010) find that feedback rating relates negatively to the chance of reactive bidding, the interpretation of this result and its implied conclusions

about the relationship between bidder experience and bidding strategy (or style) remains open to question. It also ignores issues such as bidder learning and speed of learning.
In the following analysis, we show that bidding strategy changes over time as a result of accumulating experience, regardless of whether the bidder wins or not. Our cross-category analysis, which marks another significant difference from most literature on bidder experience, enables us to analyze the number of bids submitted in an auction by a bidder; such multiple bidding is the focal point of the empirical analysis of Zeithammer and Adams (2010). We compare the differences between the use of winning observations, losing observations, and the complete bidding history when inferring the effects of experience on multiple bidding.
New Data
In this section, we compare the effect of experience based on bidders' complete bidding history with conventional experience measures that use feedback ratings. The data set we use is the same as that in Wang and Hu (2009). It tracks the whole bidding history of novice bidders on eBay over a period of six months (December 2004­May 2005) and contains auction and product characteristics, bidders' behavior (i.e., bids, number of bids, bid amount, and bidding timing), and the auction outcome. The 131 randomly selected new bidders in our sample participated in varying numbers of auctions, from 3 to 244, during the observation period. Detailed descriptions of the data appear in Wang and Hu (2009). To compare the results derived from winning observations only and those from the complete bidding history, we select bidders who won at least once, which yields a total of 102 bidders and 2,808 auction participation observations. The auctions cover a wide spectrum of product categories, such as apparel, electronics, tools, toys, collectibles, gift certificates, and vacation packages.
To study multiple bidding, we perform Poisson regressions and control for auction characteristics (e.g., number of unique bidders, seller reputation score, minimum bid required), product characteristics (private versus common value, value of the auctioned item), and bidder heterogeneity according to bidder-specific fixed effects. We present the results in panel a of Table 1. Compared with model 2, which uses the total number of actual experiences to measure bidders' experience, the feedback-based model 1 underestimates the experience effect. According to simulations in which we allow feedback and total experience to vary from 1 to 15, the marginal effect of learning is severely underestimated by the feedback ratings by as much as three times the actual level. For

Srinivasan and Wang: Bidders' Experience and Learning in Online Auctions

Marketing Science 29(6), pp. 988­993, © 2010 INFORMS

991

Table 1 Poisson Regression Results

Model 1

Model 2

Model 3

(a) Complete observations N = 2 808
Intercept ln(No. of unique bidders) ln(Minimum bid) Private value ln(Winning price) ln(Seller reputation) ln(Bidder feedback) ln(Total experience) ln(Winning experience) ln(Losing experience) LL
(b) Winning observations only N = 779
Intercept ln(No. of unique bidders) ln(Minimum bid) Private value ln(Winning price) ln(Seller reputation) ln(Bidder feedback) ln(Total experience) ln(Winning experience) ln(Losing experience) LL
(c) Losing observations only N = 2 029
Intercept ln(No. of unique bidders) ln(Minimum bid) Private value ln(Winning price) ln(Seller reputation) ln(Bidder feedback) ln(Total experience) ln(Winning experience) ln(Losing experience) LL

0 36 (0.06) 0 00 (0.03) -0 06 (0.01) -0 03 (0.04) 0 17 (0.01) -0 02 (0.01) -0 05 (0.02)
-5,354
0 20 (0.13) 0 29 (0.05) -0 16 (0.03) -0 07 (0.09) 0 26 (0.03) -0 05 (0.01) 0 02 (0.06)
-1,178
0 66 (0.08) 0 29 (0.04) -0 07 (0.01) -0 03 (0.05) 0 21 (0.02) 0 00 (0.01) -0 10 (0.03)
-3,985

0 57 (0.07) -0 01 (0.03) -0 06 (0.01) -0 05 (0.04)
0 16 (0.01) -0 01 (0.01)
-0 11 (0.01)
-5,322
0 24 (0.15) 0 28 (0.05) -0 16 (0.03) -0 08 (0.09) 0 26 (0.03) -0 05 (0.01)
-0 01 (0.03)
-1,178
0 89 (0.08) -0 30 (0.04) -0 06 (0.01) -0 07 (0.05)
0 21 (0.02) 0 01 (0.01)
-0 14 (0.01)
-3,948

0 56 (0.06) -0 01 (0.03) -0 06 (0.01) -0 05 (0.04)
0 16 (0.01) -0 01 (0.01)
0 04 (0.03) -0 15 (0.03)
-5,321
0 29 (0.15) 0 28 (0.05) -0 16 (0.03) -0 08 (0.09) 0 26 (0.03) -0 05 (0.01)
0 03 (0.07) -0 05 (0.07)
-1,178
0 85 (0.08) -0 30 (0.04) -0 06 (0.01) -0 07 (0.05)
0 21 (0.02) 0 01 (0.01)
0 03 0.03 -0 16 0.03
-3,948

Notes. The dependent variable is the number of bids submitted in an auction. Standard errors are in parentheses. LL, log likelihood. Significant at 0.05; significant at 0.001.

a closer look at the total experience effect, we estimate model 3, in which we categorize total experiences into winning and losing experiences. The result suggests that most of the significant effect that reduces multiple bidding comes from losing experiences (-0 15, p < 0 001) rather than winning experiences (0.03, not significant). Therefore, using feedback to measure experience (model 1) has at least two serious problems: it underestimates the experience effect (i.e., bidders' learning), and it provides misleading results that suggest winning experiences reduce multiple bidding, when in actuality they do not. We also find a large variation in the estimated bidder's intrinsic tendencies for submitting multiple bids (individual-specific effects omitted from Table 1), such that the difference between the highest (1.37) and lowest bidder -0 61 can be as much as 1.98. These insights emerge only when the bidders' complete bidding history can be

observed and analyzed, which is not possible using cross-sectional data. Correctly measuring experience and assessing the experience effect has important implications for auction theory as well as empirical work, especially for examining fundamental assumptions such as sealed bidding.
A key feature of the empirical tests proposed by Zeithammer and Adams (2010) is that they do not require knowledge of the number of latent bidders. Instead, their method relies only on the joint distribution of the top two proxy bids of an auction, as does the proposed empirical model to estimate the valuation distributions. However, to infer experience effects, additional bias may enter the model if only winning observations are examined. As we show in Figure 1, for the samples in our data set, winning tends to occur when people gain more experience. Figure 1(a) shows that 18.6% of our tracked

Srinivasan and Wang: Bidders' Experience and Learning in Online Auctions

992

Marketing Science 29(6), pp. 988­993, © 2010 INFORMS

Figure 1 20

Histograms: Number of Auction Participations Prior To (a) the First Win and (b) Any Winning Observations
(a) The first win (N = 102)

15

Frequency

10

5

0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 More

Frequency

(b) Any winning observations (N = 779) 120
100
80
60
40
20
0 5 15 25 35 45 55 65 75 85 95 More
bidders won in their first auction participation, but as many as 30% of them did not win their first auction until their 10th­15th participation. Of the total 779 winning observations, only 14.6% of them happened within the first five observations; the remaining 85.4% occurred after the bidders had experienced eBay auctions at least five times. Thus, it is likely that using winning observations to infer experience effects causes biases, and these biased results will be difficult to generalize to the overall bidder population. Intuitively, if people win more as they become more experienced, additional experience help them less. In addition, the number of bids, which is the key variable of interest, is significantly different across the winning and losing observations. For the winning observations, the tracked bidders submitted an average of 1.94 bids (standard deviation = 2 06; max = 19; median = 1; min = 1), whereas for the losing observations, the mean is 2.59 (standard deviation = 2 71; max = 35; median = 2; min =1). Therefore, winning observations have a lower mean with regard to the number of bids submitted compared with the losing observations; the difference is significant (p < 0 001).
As we show in panel b of Table 1, if we analyze only winning observations, the experience effect does not seem to reduce multiple bidding. As mentioned, the winning observations exhibit a lower mean and smaller variation than do losing ones in multiple bidding. More variation can be explained by auction and product characteristics than experience. If winners are

more likely to have greater experience, then selecting winning observations for the analysis will underestimate the experience effect, particularly if it uses feedback ratings. Zeithammer and Adams (2010) find that feedback ratings reduce the chance of reactive bidding, but there is no "strong evolutionary pressure against reactive bidders" (p. 982), and almost 70% of the winners are estimated as reactive bidders. The biases we have outlined likely mean that the bidders' experience indicates a weaker effect for reducing the chance of multiple bidding than it actually has.
For comparison purposes, we also conduct Poisson regressions using losing observations only (see panel c of Table 1). The experience effects qualitatively resemble those in panel a of Table 1, with the full bidding history. Again, we see that feedback ratings underestimate the learning effect and provide the misleading result that winning experiences reduce multiple bidding. Our analysis offers three key implications: (1) inexperienced bidders learn from their experiences and become more sophisticated in bidding, (2) their learning speed is not as slow as suggested by an analysis based on feedback ratings, and (3) to gauge experience and learning effects properly, it is imperative to use the complete bidding history, because selecting winning experiences or losing experiences alone is likely to cause major biases in the conclusions.
Conclusions and Further Research
Zeithammer and Adams (2010) document interesting empirical findings that should spur further theoretical and empirical work that advances our knowledge and understanding of online auctions, especially with regard to the bidding process. We also note the importance of modeling different types of bidders and the bidding data generation process. It is useful to know what experience bidders have and their resulting bidding strategies, which could have big impacts on key auction assumptions, such as sealed bidding. However, the knowledge that bidders' learning progresses toward sealed bidding over time (and that they learn faster than we might have believed) somewhat alleviates the problem of the rejection of sealed-bid abstraction, as well as bidder asymmetry. Theoretical researchers, who are not primarily concerned with the bidding process per se but rather with models that warrant sealed bidding auctions in an asymptotic sense, likely can maintain this stylized assumption and focus on modeling auction phenomenon in a steady state. Bidding strategies converge to rational bidding behavior, as predicted by established auction theory.
We are not suggesting that all inexperienced bidders inevitably become rational bidders after a certain level of participation in auctions. In reality, at

Srinivasan and Wang: Bidders' Experience and Learning in Online Auctions

Marketing Science 29(6), pp. 988­993, © 2010 INFORMS

993

any point of time, we may find new bidders who adopt and bid in online auctions. Even experienced bidders might change their bidding strategies from time to time, such that their learning would exhibit a zigzag pattern. In our analysis, we find bidders with different intrinsic tendencies to submit multiple bids; they likely learn at different rates too. Our goal is to advocate proper measures of bidder experience and the learning effect, because online auction research repeatedly shows that these factors have important implications for bidding behavior and auction revenues. As we show, bidders learn faster according to actual experience measures than feedback measures would imply and when the measure relies on their full bidding history rather than just a certain type of it.
Understanding bidder experience effects and strategy evolutions has important implications for both researchers and practitioners. For researchers, as Zeithammer and Adams (2010) demonstrate, bidder experience can aid tests of fundamental auction theories and assumptions. Online auction research has become increasingly more sophisticated, with more attention devoted to modeling the intricacies of the data generation process (e.g., Bradlow and Park 2007), the auction context, bidder behavior, and the discrepancy between established auction theory and actual observations in the field. Bidders' experience represents at least some of the bidder heterogeneity that can explain varied bidding behavior. For online auction websites and sellers, asymmetrically informed bidders and the amount of public information they have released have significant influences on auction revenue.
Further research therefore has many unanswered questions to address. Beyond willingness to pay, will experience help bidders win over time? How does

bidders' behavior and learning transcend categories? What can sellers or online auction sites do strategically to make use of bidders' experience and earn more revenue? These relevant and interesting questions have not been studied in-depth. To find the answers, we call for careful measures of experience and well-designed studies.
References
Bajari, P., A. Hortaçsu. 2003. The winner's curse, reserve prices, and endogenous entry: Empirical insights from eBay auctions. RAND J. Econom. 34(2) 329­355.
Borle, S., P. Boatwright, J. B. Kadane. 2006. The timing of bid placement and exten of multiple bidding: An empirical investigation using eBay online auctions. Statist. Sci. 21(2) 194­205.
Bradlow, E. T., Y.-H. Park. 2007. Bayesian estimation of bid sequences in Internet auctions using a generalized recordbreaking model. Marketing Sci. 26(2) 218­229.
Darr, E. D., L. Argote, D. Epple. 1995. The acquisition, transfer, and depreciation of knowledge in service organizations: Productivity in franchises. Management Sci. 41(11) 1750­1762.
Hausch, D. B. 1987. An asymmetric common-value auction model. RAND J. Econom. 18(4) 611­621.
Krishna, V. 2002. Auction Theory, 1st ed. Academic Press, San Diego. Marshall, R. C., M. J. Meurer, J.-F. Richard, W. Stromquist. 1994.
Numerical analysis of asymmetric first price auctions. Games Econom. Behav. 7(2) 193­220. Maskin, E., J. Riley. 2000. Asymmetric auctions. Rev. Econom. Stud. 67(3) 413­438. Ockenfels, A., A. E. Roth. 2006. Late and multiple bidding in second price Internet auctions: Theory and evidence concerning different rules for ending an auction. Games Econom. Behav. 55(2) 297­320. Roth, A. E., A. Ockenfels. 2002. Last-minute bidding and the rules for ending second-price auctions: Evidence from eBay and Amazon auctions on the Internet. Amer. Econom. Rev. 92(4) 1093­1103. Wang, X., Y. Hu. 2009. The effect of experience on Internet auction bidding dynamics. Marketing Lett. 20(3) 245­261. Wilcox, R. T. 2000. Experts and amateurs: The role of experience in Internet auctions. Marketing Lett. 11(4) 363­374. Zeithammer, R., C. Adams. 2010. The sealed-bid abstraction in online auctions. Marketing Sci. 29(6) 964­987.

